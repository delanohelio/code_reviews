{"pr_number": 530, "pr_title": "KOGITO-3763 - Improved numeric feature handling", "pr_createdAt": "2020-11-09T09:06:13Z", "pr_url": "https://github.com/kiegroup/kogito-apps/pull/530", "merge_commit": "fae3e0ba7ac4e7d113e1cf11e10ba5ff0949b3fe", "timeline": [{"oid": "25b6ab01d9ef0f19869a5f0890252cba8c852d84", "url": "https://github.com/kiegroup/kogito-apps/commit/25b6ab01d9ef0f19869a5f0890252cba8c852d84", "message": "KOGITO-3769 - Make LimeExplainer optionally generate more diverse samples", "committedDate": "2020-11-09T09:00:11Z", "type": "commit"}, {"oid": "d83ae430183c0a39b631680f4bc919cc1754dacf", "url": "https://github.com/kiegroup/kogito-apps/commit/d83ae430183c0a39b631680f4bc919cc1754dacf", "message": "KOGITO-3763 - improved numeric feature encoding", "committedDate": "2020-11-09T09:01:27Z", "type": "commit"}, {"oid": "9fa407fac9f898d2b1d07152f1dae9e55282c309", "url": "https://github.com/kiegroup/kogito-apps/commit/9fa407fac9f898d2b1d07152f1dae9e55282c309", "message": "KOGITO-3763 - improved numeric feature encoding", "committedDate": "2020-11-09T09:01:58Z", "type": "commit"}, {"oid": "d35eed92e8cb7c7c4c1c771a531bfd794fef05a2", "url": "https://github.com/kiegroup/kogito-apps/commit/d35eed92e8cb7c7c4c1c771a531bfd794fef05a2", "message": "KOGITO-3763 - do not integrate KOGITO-3769 changes in here", "committedDate": "2020-11-09T09:24:02Z", "type": "commit"}, {"oid": "72baf99f09b97389a72cf3eea8bf0b4099545143", "url": "https://github.com/kiegroup/kogito-apps/commit/72baf99f09b97389a72cf3eea8bf0b4099545143", "message": "KOGITO-3763 - minor tweaks to tests, reduced stdDev in numeric feature gen", "committedDate": "2020-11-09T14:59:45Z", "type": "commit"}, {"oid": "112de8a1330b52012a4d5c415b396855bc2f16af", "url": "https://github.com/kiegroup/kogito-apps/commit/112de8a1330b52012a4d5c415b396855bc2f16af", "message": "KOGITO-3763 - fixing dmn and pmml tests", "committedDate": "2020-11-10T10:11:44Z", "type": "commit"}, {"oid": "4f84ff071b86089deb226af075d1bbddc5150596", "url": "https://github.com/kiegroup/kogito-apps/commit/4f84ff071b86089deb226af075d1bbddc5150596", "message": "KOGITO-3763 - reduced kernel size for weighting samples, fixed tests", "committedDate": "2020-11-11T15:35:13Z", "type": "commit"}, {"oid": "85160944f1e5d484bc5220ae97847ad52393c73d", "url": "https://github.com/kiegroup/kogito-apps/commit/85160944f1e5d484bc5220ae97847ad52393c73d", "message": "KOGITO-3763 - improved stability metric API: no need to predict", "committedDate": "2020-11-11T15:56:28Z", "type": "commit"}, {"oid": "f82a27d12710a5450bc169c00b7d88291e8624ff", "url": "https://github.com/kiegroup/kogito-apps/commit/f82a27d12710a5450bc169c00b7d88291e8624ff", "message": "KOGITO-3763 - removed useless commented code in DatasetEncoder", "committedDate": "2020-11-11T16:01:34Z", "type": "commit"}, {"oid": "346374af6a7c33f16b191a3246f80fd82fa7f911", "url": "https://github.com/kiegroup/kogito-apps/commit/346374af6a7c33f16b191a3246f80fd82fa7f911", "message": "KOGITO-3763 - resolved bugs reported by sonarcloud", "committedDate": "2020-11-12T09:04:19Z", "type": "commit"}, {"oid": "123b5a88866e17cfc986d1239146a9ea3900713b", "url": "https://github.com/kiegroup/kogito-apps/commit/123b5a88866e17cfc986d1239146a9ea3900713b", "message": "KOGITO-3763 - reduced cognitive complexity, reported by sonarcloud", "committedDate": "2020-11-12T09:08:06Z", "type": "commit"}, {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "url": "https://github.com/kiegroup/kogito-apps/commit/7db39c4c33c84eca961e21a8c1a0a24628d379e2", "message": "KOGITO-3763 - removed useless comment", "committedDate": "2020-11-12T09:20:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYyNDQ2NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528624465", "body": "do we need `finalK`?", "bodyText": "do we need finalK?", "bodyHTML": "<p dir=\"auto\">do we need <code>finalK</code>?</p>", "author": "r00ta", "createdAt": "2020-11-23T11:07:05Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODcyOTEyNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528729124", "bodyText": "it seems so, as we use k in the stream, but k value changes across iterations for (k=0; k < ...", "author": "tteofili", "createdAt": "2020-11-23T14:10:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYyNDQ2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5OTc1OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528799758", "bodyText": "Sorry, I did not see it was used in the lambda", "author": "r00ta", "createdAt": "2020-11-23T15:45:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYyNDQ2NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMDAyMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528630022", "body": "If I've got it properly this can be replaced by something like\r\n```\r\nMap.Entry maxEntry = Collections.max(collect.entrySet(), Map.Entry.comparingByValue());\r\n```", "bodyText": "If I've got it properly this can be replaced by something like\nMap.Entry maxEntry = Collections.max(collect.entrySet(), Map.Entry.comparingByValue());", "bodyHTML": "<p dir=\"auto\">If I've got it properly this can be replaced by something like</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"Map.Entry maxEntry = Collections.max(collect.entrySet(), Map.Entry.comparingByValue());\"><pre><code>Map.Entry maxEntry = Collections.max(collect.entrySet(), Map.Entry.comparingByValue());\n</code></pre></div>", "author": "r00ta", "createdAt": "2020-11-23T11:17:25Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;\n+                // get the top k positive features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKPositive = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getPositiveFeatures(finalK));\n+                // get the most frequent list of positive features\n+                Pair<List<String>, Long> positiveMostFrequent = getMostFrequent(topKPositive);\n+                double positiveFrequencyRate = (double) positiveMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // get the top k negative features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKNegative = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getNegativeFeatures(finalK));\n+                // get the most frequent list of negative features\n+                Pair<List<String>, Long> negativeMostFrequent = getMostFrequent(topKNegative);\n+                double negativeFrequencyRate = (double) negativeMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // decision stability at k\n+                List<String> positiveFeatureNames = positiveMostFrequent.getKey();\n+                List<String> negativeFeatureNames = negativeMostFrequent.getKey();\n+                saliencyStability.add(decision, k, positiveFeatureNames, positiveFrequencyRate, negativeFeatureNames, negativeFrequencyRate);\n+            }\n+        }\n+        return saliencyStability;\n+    }\n+\n+    /**\n+     * Get multiple saliencies, aggregated by decision name.\n+     *\n+     * @param model                  the model used to perform predictions\n+     * @param prediction             the prediction to explain\n+     * @param saliencyLocalExplainer a local explainer that generates saliences\n+     * @param runs                   the no. of explanations to be generated\n+     * @return the generated saliencies, aggregated by decision name, across the different runs\n+     */\n+    private static Map<String, List<Saliency>> getMultipleSaliencies(PredictionProvider model, Prediction prediction,\n+                                                                     LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                     int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = new HashMap<>();\n+        int skipped = 0;\n+        for (int i = 0; i < runs; i++) {\n+            Map<String, Saliency> saliencyMap = saliencyLocalExplainer.explainAsync(prediction, model)\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            for (Map.Entry<String, Saliency> saliencyEntry : saliencyMap.entrySet()) {\n+                // aggregate saliencies by output name\n+                List<FeatureImportance> topFeatures = saliencyEntry.getValue().getTopFeatures(1);\n+                if (!topFeatures.isEmpty() && topFeatures.get(0).getScore() != 0) { // skip empty or 0 valued saliencies\n+                    if (saliencies.containsKey(saliencyEntry.getKey())) {\n+                        List<Saliency> localSaliencies = saliencies.get(saliencyEntry.getKey());\n+                        List<Saliency> updatedSaliencies = new ArrayList<>(localSaliencies);\n+                        updatedSaliencies.add(saliencyEntry.getValue());\n+                        saliencies.put(saliencyEntry.getKey(), updatedSaliencies);\n+                    } else {\n+                        saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n+                    }\n+                } else {\n+                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    skipped++;\n+                }\n+            }\n+        }\n+        LOGGER.debug(\"skipped {} useless saliencies\", skipped);\n+        return saliencies;\n+    }\n+\n+    private static Map<List<String>, Long> getTopKFeaturesFrequency(List<Saliency> saliencies, Function<Saliency, List<FeatureImportance>> saliencyListFunction) {\n+        return saliencies.stream().map(saliencyListFunction)\n+                .map(l -> l.stream().map(f -> f.getFeature().getName())\n+                        .collect(Collectors.toList()))\n+                .collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+    }\n+\n+    private static Pair<List<String>, Long> getMostFrequent(Map<List<String>, Long> collect) {\n+        long max = 0L;\n+        Pair<List<String>, Long> topK = Pair.of(Collections.emptyList(), 0L);\n+        for (Map.Entry<List<String>, Long> entry : collect.entrySet()) {\n+            if (entry.getValue() >= max) {\n+                topK = Pair.of(entry.getKey(), entry.getValue());\n+                max = entry.getValue();\n+            }\n+        }\n+        return topK;\n+    }", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc0MzM5NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528743394", "bodyText": "much better, thanks!", "author": "tteofili", "createdAt": "2020-11-23T14:30:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMDAyMg=="}], "type": "inlineReview", "revised_code": {"commit": "77ce1f4010b6feb315a66ae99173d54472d3819a", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\nindex 5e1b65312..d508f860a 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n", "chunk": "@@ -234,14 +234,7 @@ public class ExplainabilityMetrics {\n     }\n \n     private static Pair<List<String>, Long> getMostFrequent(Map<List<String>, Long> collect) {\n-        long max = 0L;\n-        Pair<List<String>, Long> topK = Pair.of(Collections.emptyList(), 0L);\n-        for (Map.Entry<List<String>, Long> entry : collect.entrySet()) {\n-            if (entry.getValue() >= max) {\n-                topK = Pair.of(entry.getKey(), entry.getValue());\n-                max = entry.getValue();\n-            }\n-        }\n-        return topK;\n+        Map.Entry<List<String>, Long> maxEntry = Collections.max(collect.entrySet(), Map.Entry.comparingByValue());\n+        return Pair.of(maxEntry.getKey(), maxEntry.getValue());\n     }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMjc0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528632746", "body": "Do we need `public` or can we keep it internal?", "bodyText": "Do we need public or can we keep it internal?", "bodyHTML": "<p dir=\"auto\">Do we need <code>public</code> or can we keep it internal?</p>", "author": "r00ta", "createdAt": "2020-11-23T11:22:33Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LocalSaliencyStability.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Local {@code Saliency} stability evaluation result.\n+ */\n+public class LocalSaliencyStability {", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI1MTUxNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r529251517", "bodyText": "same reasoning as ExplainabilityMetrics#getLocalSaliencyStability, being this the result of the evaluation, it should be public for evaluators to consume it.", "author": "tteofili", "createdAt": "2020-11-24T07:22:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMjc0Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzOTk0OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528639948", "body": "I have some questions around the `getPositiveStabilityScore` and `getNegativeStabilityScore`, what do they represent? Since they are rates how can they be both greater than `0.5`? ", "bodyText": "I have some questions around the getPositiveStabilityScore and getNegativeStabilityScore, what do they represent? Since they are rates how can they be both greater than 0.5?", "bodyHTML": "<p dir=\"auto\">I have some questions around the <code>getPositiveStabilityScore</code> and <code>getNegativeStabilityScore</code>, what do they represent? Since they are rates how can they be both greater than <code>0.5</code>?</p>", "author": "r00ta", "createdAt": "2020-11-23T11:36:03Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);\n+            assertFalse(predictionOutputs.isEmpty());\n+            PredictionOutput output = predictionOutputs.get(0);\n+            assertNotNull(output);\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n                 assertNotNull(saliency);\n-                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getPositiveFeatures(2));\n+                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertEquals(1d, v);\n             }\n+            int topK = 1;\n+            LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+            for (int i = 1; i <= topK; i++) {\n+                for (String decision : stability.getDecisions()) {\n+                    double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                    double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                    assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                    assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI1NjE1NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r529256155", "bodyText": "data about positive and negative stability are kept separate because we want to separately check that the top k negative features are always the same as well as the top k positive features are always the same; it can happen that the negatives are stable whereas this is not true for the positive features.\nHowever I think rate is wrong here, ratio is more accurate (it's basically the number of times the most frequent positive/negative features appear divided by the number of explanations drawn for that decision).", "author": "tteofili", "createdAt": "2020-11-24T07:32:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzOTk0OA=="}], "type": "inlineReview", "revised_code": {"commit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\nindex df7983a8a..555059238 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n", "chunk": "@@ -91,28 +95,20 @@ class PmmlLimeExplainerTest {\n             });\n             List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-            assertNotNull(predictionOutputs);\n-            assertFalse(predictionOutputs.isEmpty());\n+            assertThat(predictionOutputs).isNotNull();\n+            assertThat(predictionOutputs).isNotEmpty();\n             PredictionOutput output = predictionOutputs.get(0);\n-            assertNotNull(output);\n+            assertThat(output).isNotNull();\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n-                assertNotNull(saliency);\n+                assertThat(saliency).isNotNull();\n                 double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n-                assertEquals(1d, v);\n-            }\n-            int topK = 1;\n-            LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n-            for (int i = 1; i <= topK; i++) {\n-                for (String decision : stability.getDecisions()) {\n-                    double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n-                    double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n-                    assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                    assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                }\n+                assertThat(v).isEqualTo(1d);\n             }\n+            assertDoesNotThrow(() -> ValidationUtils.validateLocalSaliencyStability(model, prediction, limeExplainer, 1,\n+                                                                                    0.5, 0.5));\n         }\n     }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY0MTAzNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528641035", "body": "Do we need `public` or can we keep it internal?", "bodyText": "Do we need public or can we keep it internal?", "bodyHTML": "<p dir=\"auto\">Do we need <code>public</code> or can we keep it internal?</p>", "author": "r00ta", "createdAt": "2020-11-23T11:38:15Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc0NDc3NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528744774", "bodyText": "being a metric, I supposed it would have made sense to keep it public, however at this stage it's not \"used\" by other components, so we can do both.", "author": "tteofili", "createdAt": "2020-11-23T14:32:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY0MTAzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwNTg1MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528805851", "bodyText": "np, if it was intented to be a public api let's keep it as it is. Just wanted to be sure it was not just for our internal testing", "author": "r00ta", "createdAt": "2020-11-23T15:53:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY0MTAzNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4Njk4OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528786989", "body": "I think it would be good to use assertj also here. It provides much better messages when test fails.", "bodyText": "I think it would be good to use assertj also here. It provides much better messages when test fails.", "bodyHTML": "<p dir=\"auto\">I think it would be good to use assertj also here. It provides much better messages when test fails.</p>", "author": "jiripetrlik", "createdAt": "2020-11-23T15:29:29Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "44d81236cdf89672b9823098bbd812620311a7e3", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\nindex df7983a8a..05ae83399 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n", "chunk": "@@ -91,17 +88,17 @@ class PmmlLimeExplainerTest {\n             });\n             List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-            assertNotNull(predictionOutputs);\n-            assertFalse(predictionOutputs.isEmpty());\n+            assertThat(predictionOutputs).isNotNull();\n+            assertThat(predictionOutputs).isNotEmpty();\n             PredictionOutput output = predictionOutputs.get(0);\n-            assertNotNull(output);\n+            assertThat(output).isNotNull();\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n-                assertNotNull(saliency);\n+                assertThat(saliency).isNotNull();\n                 double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n-                assertEquals(1d, v);\n+                assertThat(v).isEqualTo(1d);\n             }\n             int topK = 1;\n             LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n", "next_change": {"commit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\nindex 05ae83399..555059238 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n", "chunk": "@@ -100,16 +107,8 @@ class PmmlLimeExplainerTest {\n                 double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertThat(v).isEqualTo(1d);\n             }\n-            int topK = 1;\n-            LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n-            for (int i = 1; i <= topK; i++) {\n-                for (String decision : stability.getDecisions()) {\n-                    double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n-                    double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n-                    assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                    assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                }\n-            }\n+            assertDoesNotThrow(() -> ValidationUtils.validateLocalSaliencyStability(model, prediction, limeExplainer, 1,\n+                                                                                    0.5, 0.5));\n         }\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4NzI4MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528787281", "body": "Please use assertj.", "bodyText": "Please use assertj.", "bodyHTML": "<p dir=\"auto\">Please use assertj.</p>", "author": "jiripetrlik", "createdAt": "2020-11-23T15:29:47Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);\n+            assertFalse(predictionOutputs.isEmpty());\n+            PredictionOutput output = predictionOutputs.get(0);\n+            assertNotNull(output);\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n                 assertNotNull(saliency);\n-                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getPositiveFeatures(2));\n+                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertEquals(1d, v);", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "44d81236cdf89672b9823098bbd812620311a7e3", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\nindex df7983a8a..05ae83399 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n", "chunk": "@@ -91,17 +88,17 @@ class PmmlLimeExplainerTest {\n             });\n             List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-            assertNotNull(predictionOutputs);\n-            assertFalse(predictionOutputs.isEmpty());\n+            assertThat(predictionOutputs).isNotNull();\n+            assertThat(predictionOutputs).isNotEmpty();\n             PredictionOutput output = predictionOutputs.get(0);\n-            assertNotNull(output);\n+            assertThat(output).isNotNull();\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n-                assertNotNull(saliency);\n+                assertThat(saliency).isNotNull();\n                 double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n-                assertEquals(1d, v);\n+                assertThat(v).isEqualTo(1d);\n             }\n             int topK = 1;\n             LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n", "next_change": {"commit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\nindex 05ae83399..555059238 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n", "chunk": "@@ -100,16 +107,8 @@ class PmmlLimeExplainerTest {\n                 double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertThat(v).isEqualTo(1d);\n             }\n-            int topK = 1;\n-            LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n-            for (int i = 1; i <= topK; i++) {\n-                for (String decision : stability.getDecisions()) {\n-                    double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n-                    double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n-                    assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                    assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                }\n-            }\n+            assertDoesNotThrow(() -> ValidationUtils.validateLocalSaliencyStability(model, prediction, limeExplainer, 1,\n+                                                                                    0.5, 0.5));\n         }\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4NzcxNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528787717", "body": "Please use assertj also here.", "bodyText": "Please use assertj also here.", "bodyHTML": "<p dir=\"auto\">Please use assertj also here.</p>", "author": "jiripetrlik", "createdAt": "2020-11-23T15:30:18Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java", "diffHunk": "@@ -294,6 +294,27 @@ void testEncode(Type type) {\n         }\n     }\n \n+    @Test\n+    void testEncodeNumericSymmetric() {\n+        for (int seed = 0; seed < 5; seed++) {\n+            Random random = new Random();\n+            random.setSeed(seed);\n+            PerturbationContext perturbationContext = new PerturbationContext(random, random.nextInt());\n+            Value<?> target = Type.NUMBER.randomValue(perturbationContext);\n+            Value<?>[] values = new Value<?>[6];\n+            for (int i = 0; i < values.length / 2; i++) {\n+                values[i] = new Value<>(target.asNumber() + target.asNumber() * (1 + i) / 100d);\n+                values[values.length - 1 - i] = new Value<>(target.asNumber() - target.asNumber() * (1 + i) / 100d);\n+            }\n+            List<double[]> vectors = Type.NUMBER.encode(target, values);\n+            assertNotNull(vectors);\n+            assertEquals(values.length, vectors.size());\n+            for (int i = 0; i < vectors.size() / 2; i++) {\n+                assertEquals(vectors.get(i)[0], vectors.get(vectors.size() - 1 - i)[0]);", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f02ace0c1d64abb65a2299dfb0483e4ba34bae87", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java\nindex 12a890fb6..890d7e6b5 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java\n", "chunk": "@@ -310,7 +310,7 @@ class TypeTest {\n             assertNotNull(vectors);\n             assertEquals(values.length, vectors.size());\n             for (int i = 0; i < vectors.size() / 2; i++) {\n-                assertEquals(vectors.get(i)[0], vectors.get(vectors.size() - 1 - i)[0]);\n+                assertThat(vectors.get(i)[0]).isEqualTo(vectors.get(vectors.size() - 1 - i)[0]);\n             }\n         }\n     }\n", "next_change": {"commit": "839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java\nindex 890d7e6b5..6d619013c 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java\n", "chunk": "@@ -315,6 +330,22 @@ class TypeTest {\n         }\n     }\n \n+    @Test\n+    void testEncodeNaN() {\n+        Random random = new Random();\n+        random.setSeed(4);\n+        PerturbationContext perturbationContext = new PerturbationContext(random, 1);\n+        Value<?> target = Type.NUMBER.randomValue(perturbationContext);\n+        Value<?>[] values = new Value<?>[6];\n+        for (int i = 0; i < values.length - 1; i++) {\n+            values[i] = Type.NUMBER.randomValue(perturbationContext);\n+        }\n+        values[5] = new Value<>(Double.NaN);\n+        List<double[]> vectors = Type.NUMBER.encode(target, values);\n+        assertThat(vectors).isNotEmpty();\n+        assertThat(vectors).doesNotContain(new double[]{Double.NaN});\n+    }\n+\n     @ParameterizedTest\n     @EnumSource\n     void testRandomValue(Type type) {\n", "next_change": null}]}}]}}, {"oid": "77ce1f4010b6feb315a66ae99173d54472d3819a", "url": "https://github.com/kiegroup/kogito-apps/commit/77ce1f4010b6feb315a66ae99173d54472d3819a", "message": "KOGITO-3763 - simplified EM#getMostFrequent", "committedDate": "2020-11-24T07:20:18Z", "type": "commit"}, {"oid": "44d81236cdf89672b9823098bbd812620311a7e3", "url": "https://github.com/kiegroup/kogito-apps/commit/44d81236cdf89672b9823098bbd812620311a7e3", "message": "KOGITO-3763 - using assertJ in PmmlLimeExplainerTest", "committedDate": "2020-11-24T08:36:56Z", "type": "commit"}, {"oid": "f02ace0c1d64abb65a2299dfb0483e4ba34bae87", "url": "https://github.com/kiegroup/kogito-apps/commit/f02ace0c1d64abb65a2299dfb0483e4ba34bae87", "message": "KOGITO-3602 - using assertJ in TypeTest", "committedDate": "2020-11-24T08:38:30Z", "type": "commit"}, {"oid": "920cf37dd04455741bd1be6ab4c449a7cdfce38a", "url": "https://github.com/kiegroup/kogito-apps/commit/920cf37dd04455741bd1be6ab4c449a7cdfce38a", "message": "KOGITO-3763 - using assertJ in PmmlLimeExplainerTest", "committedDate": "2020-11-24T15:50:10Z", "type": "commit"}, {"oid": "9f24519754bc0dda092095eeeea00f49da91b75f", "url": "https://github.com/kiegroup/kogito-apps/commit/9f24519754bc0dda092095eeeea00f49da91b75f", "message": "Merge branch 'master' of github.com:kiegroup/kogito-apps into KOGITO-3763", "committedDate": "2020-12-02T15:42:52Z", "type": "commit"}, {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e", "url": "https://github.com/kiegroup/kogito-apps/commit/3580d487a5dd0f45d40be5a8886a4ee68a30c10e", "message": "Merge branch 'master' of github.com:kiegroup/kogito-apps into KOGITO-3763", "committedDate": "2020-12-02T15:45:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0NDE1MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r522444151", "body": "Is this based on some euristic/rule?", "bodyText": "Is this based on some euristic/rule?", "bodyHTML": "<p dir=\"auto\">Is this based on some euristic/rule?</p>", "author": "danielezonca", "createdAt": "2020-11-12T21:42:31Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java", "diffHunk": "@@ -27,7 +27,7 @@\n  */\n class SampleWeighter {\n \n-    private static final double SIGMA = 0.75;\n+    private static final double SIGMA = 0.675;", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk4Mjc4MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540982780", "bodyText": "this softens the proximity function \"strictness\", some of the changes in this PR are somewhat correlated as we have improved the locality of the generated samples (in Type.NUMBER), so that the algo benefits from having less strict proximity function (here the width controls how strict the similarity between two vectors is) and similarity threshold (the CLUSTER_THRESHOLD in Type.NUMBER).", "author": "tteofili", "createdAt": "2020-12-11T14:24:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0NDE1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f24519754bc0dda092095eeeea00f49da91b75f", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java\nindex 61c416dcf..3d799f39e 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java\n", "chunk": "@@ -17,9 +17,10 @@ package org.kie.kogito.explainability.local.lime;\n \n import java.util.Arrays;\n import java.util.Collection;\n+import java.util.List;\n \n import org.apache.commons.lang3.tuple.Pair;\n-import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Feature;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n /**\n", "next_change": null}, {"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java\nindex 61c416dcf..3d799f39e 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java\n", "chunk": "@@ -29,8 +30,14 @@ class SampleWeighter {\n \n     private static final double SIGMA = 0.675;\n \n-    static double[] getSampleWeights(PredictionInput targetInput, Collection<Pair<double[], Double>> training) {\n-        int noOfFeatures = targetInput.getFeatures().size();\n+    /**\n+     * Obtain sample weights for a training set, given a list of target input features to compare with.\n+     * @param targetInputFeatures target input features\n+     * @param training the (sparse) training set\n+     * @return a eeight for each sample in the training set\n+     */\n+    static double[] getSampleWeights(List<Feature> targetInputFeatures, Collection<Pair<double[], Double>> training) {\n+        int noOfFeatures = targetInputFeatures.size();\n         double[] x = new double[noOfFeatures];\n         Arrays.fill(x, 1);\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MTYyMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r525371620", "body": "Can you add a test to cover this branch?", "bodyText": "Can you add a test to cover this branch?", "bodyHTML": "<p dir=\"auto\">Can you add a test to cover this branch?</p>", "author": "danielezonca", "createdAt": "2020-11-17T17:59:06Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -162,7 +162,7 @@ static Feature doubleToFeature(double d) {\n                 perturbationSize = lowerBound;\n             }\n             else if (upperBound > lowerBound) {\n-                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, upperBound).findFirst().orElse(1);\n+                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, 1 + upperBound).findFirst().orElse(1);", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk1MTQ2MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540951460", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-12-11T13:36:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MTYyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTAxNDc3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r541014773", "bodyText": "actually this is already covered in DataUtils#testPerturbDropNumericTwo and DataUtils#testPerturbDropNumericThree.\nwe can't control the actual number being generated unless we induce the generation with a custom Random test-impl (e.g. the FakeRandom class we had).", "author": "tteofili", "createdAt": "2020-12-11T15:10:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MTYyMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NzE3NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r527057174", "body": "Why are you adding `originalValue` to feature scaling? Can you please clarify?", "bodyText": "Why are you adding originalValue to feature scaling? Can you please clarify?", "bodyHTML": "<p dir=\"auto\">Why are you adding <code>originalValue</code> to feature scaling? Can you please clarify?</p>", "author": "danielezonca", "createdAt": "2020-11-19T17:12:09Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;\n             for (Value<?> v : values) {\n                 doubles[i] = v.asNumber();\n                 i++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[i] = originalValue; // include target number in feature scaling", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk1MTIxMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540951210", "bodyText": "as per issue description:\n\nincluded the original feature value in min / max scaling (which is performed during sparse encoding), this fixes cases where the original value doesn't fall in the value range of the sampled perturbed values (which is rare but can still happen)", "author": "tteofili", "createdAt": "2020-12-11T13:36:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NzE3NA=="}], "type": "inlineReview", "revised_code": {"commit": "53696c9d78ef55cb9ae5a76c354ab4db9311cf8d", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex d01e09ea6..1cf2c5f0f 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -166,19 +166,19 @@ public enum Type {\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n             double[] doubles = new double[values.length + 1];\n-            int i = 0;\n+            int valueIndex = 0;\n             for (Value<?> v : values) {\n-                doubles[i] = v.asNumber();\n-                i++;\n+                doubles[valueIndex] = v.asNumber();\n+                valueIndex++;\n             }\n             double originalValue = target.asNumber();\n-            doubles[i] = originalValue; // include target number in feature scaling\n+            doubles[valueIndex] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n \n             // feature scaling\n             List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n-            double scaledOriginalValue = scaledValues.remove(i); // extract the scaled original value (it must not appear in encoded values)\n+            double scaledOriginalValue = scaledValues.remove(valueIndex); // extract the scaled original value (it must not appear in encoded values)\n \n             // kernel based clustering\n             double sigma = 1;\n", "next_change": {"commit": "839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex 1cf2c5f0f..dadf67e41 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -184,7 +184,7 @@ public enum Type {\n             double sigma = 1;\n             double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n             List<Double> clusteredValues = scaledValues.stream()\n-                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n+                    .map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n             List<Double> encodedValues = clusteredValues.stream()\n                     .map(d -> (Math.abs(d - threshold) < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NzUyMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r527057520", "body": "```suggestion\r\n            int valueIndex = 0;\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        int i = 0;\n          \n          \n            \n                        int valueIndex = 0;", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"pl-k\">int</span> <span class=\"x x-first x-last\">i</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            <span class=\"pl-k\">int</span> <span class=\"x x-first x-last\">valueIndex</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>;</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "danielezonca", "createdAt": "2020-11-19T17:12:43Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;", "originalCommit": "7db39c4c33c84eca961e21a8c1a0a24628d379e2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "53696c9d78ef55cb9ae5a76c354ab4db9311cf8d", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex d01e09ea6..1cf2c5f0f 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -166,19 +166,19 @@ public enum Type {\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n             double[] doubles = new double[values.length + 1];\n-            int i = 0;\n+            int valueIndex = 0;\n             for (Value<?> v : values) {\n-                doubles[i] = v.asNumber();\n-                i++;\n+                doubles[valueIndex] = v.asNumber();\n+                valueIndex++;\n             }\n             double originalValue = target.asNumber();\n-            doubles[i] = originalValue; // include target number in feature scaling\n+            doubles[valueIndex] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n \n             // feature scaling\n             List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n-            double scaledOriginalValue = scaledValues.remove(i); // extract the scaled original value (it must not appear in encoded values)\n+            double scaledOriginalValue = scaledValues.remove(valueIndex); // extract the scaled original value (it must not appear in encoded values)\n \n             // kernel based clustering\n             double sigma = 1;\n", "next_change": {"commit": "839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex 1cf2c5f0f..dadf67e41 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -184,7 +184,7 @@ public enum Type {\n             double sigma = 1;\n             double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n             List<Double> clusteredValues = scaledValues.stream()\n-                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n+                    .map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n             List<Double> encodedValues = clusteredValues.stream()\n                     .map(d -> (Math.abs(d - threshold) < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTMwNjA5NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r535306095", "body": "Magic number?", "bodyText": "Magic number?", "bodyHTML": "<p dir=\"auto\">Magic number?</p>", "author": "danielezonca", "createdAt": "2020-12-03T14:59:14Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -130,7 +130,7 @@\n     },\n \n     NUMBER(\"number\") {\n-        private static final double CLUSTER_THRESHOLD = 1e-3;\n+        private static final double CLUSTER_THRESHOLD = 1e-1;", "originalCommit": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk4NDgwNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540984807", "bodyText": "see comment above for SampleWeighter.SIGMA", "author": "tteofili", "createdAt": "2020-12-11T14:27:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTMwNjA5NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r535905184", "body": "I see the same \"pattern\" in all the tests (not only PMML but all the others too) with only number of samples, topK and positive/negative stability score as difference.\r\nDoes it make sense to move it to a common method?\r\nAre all of them magic numbers? Like why 300/500 samples? Why the last assertion is >= 0.5/0.8?", "bodyText": "I see the same \"pattern\" in all the tests (not only PMML but all the others too) with only number of samples, topK and positive/negative stability score as difference.\nDoes it make sense to move it to a common method?\nAre all of them magic numbers? Like why 300/500 samples? Why the last assertion is >= 0.5/0.8?", "bodyHTML": "<p dir=\"auto\">I see the same \"pattern\" in all the tests (not only PMML but all the others too) with only number of samples, topK and positive/negative stability score as difference.<br>\nDoes it make sense to move it to a common method?<br>\nAre all of them magic numbers? Like why 300/500 samples? Why the last assertion is &gt;= 0.5/0.8?</p>", "author": "danielezonca", "createdAt": "2020-12-04T08:00:34Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -131,16 +144,29 @@ void testPMMLRegressionCategorical() throws Exception {\n             }\n             return outputs;\n         });\n-        PredictionOutput output = model.predictAsync(List.of(input))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                .get(0);\n+        List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        assertThat(predictionOutputs).isNotNull();\n+        assertThat(predictionOutputs).isNotEmpty();\n+        PredictionOutput output = predictionOutputs.get(0);\n+        assertThat(output).isNotNull();\n         Prediction prediction = new Prediction(input, output);\n         Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n         for (Saliency saliency : saliencyMap.values()) {\n-            assertNotNull(saliency);\n-            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(1));\n-            assertEquals(1d, v);\n+            assertThat(saliency).isNotNull();\n+            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n+            assertThat(v).isEqualTo(1d);\n+        }\n+        int topK = 1;\n+        LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+        for (int i = 1; i <= topK; i++) {\n+            for (String decision : stability.getDecisions()) {\n+                double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n+            }", "originalCommit": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk5MjM4NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540992385", "bodyText": "Sure it makes sense to have a common method in TestUtils, I'll do that.\nFor the specific settings: I've set a minimum expected stability rate to 0.5 for the models having more than 5 features (when linearized) including ones of Type.NUMBER since they're harder.\nI've set a high minimum (0.8) for OpenNLP ITs since the input only consists of 4 words that can only be set to empty String when perturbed, resulting in a low no. of possible perturbed inputs and hence an higher stability.", "author": "tteofili", "createdAt": "2020-12-11T14:37:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTAzNTcxOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r541035719", "bodyText": "a practical problem with such a test method is that we need to inject a test classified version of explainability-core into the IT modules, which I think it's a bit overkill given the fact that we just need a few lines of code to check the expected stability scores.", "author": "tteofili", "createdAt": "2020-12-11T15:38:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTA3NzM5Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r541077393", "bodyText": "I've moved the boilerplate to validate local saliency stability in a ValidationUtils#validateLocalSaliencyStability method so that it can be re-used easily in ITs as well.", "author": "tteofili", "createdAt": "2020-12-11T16:39:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA=="}], "type": "inlineReview", "revised_code": {"commit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\nindex 25bcc2434..555059238 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java\n", "chunk": "@@ -158,16 +152,8 @@ class PmmlLimeExplainerTest {\n             double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n             assertThat(v).isEqualTo(1d);\n         }\n-        int topK = 1;\n-        LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n-        for (int i = 1; i <= topK; i++) {\n-            for (String decision : stability.getDecisions()) {\n-                double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n-                double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n-                assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n-                assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n-            }\n-        }\n+        assertDoesNotThrow(() -> ValidationUtils.validateLocalSaliencyStability(model, prediction, limeExplainer, 1,\n+                                                                                0.5, 0.5));\n     }\n \n     @Test\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0MjM1OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540942358", "body": "Why fixed value?", "bodyText": "Why fixed value?", "bodyHTML": "<p dir=\"auto\">Why fixed value?</p>", "author": "danielezonca", "createdAt": "2020-12-11T13:21:49Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;\n             for (Value<?> v : values) {\n                 doubles[i] = v.asNumber();\n                 i++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[i] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n-            // feature scaling + kernel based clustering\n-            double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min), 0, 1);\n-            List<Double> encodedValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n-                    .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(d -> DataUtils.gaussianKernel(d, 0, 1))\n-                    .map(d -> (d - threshold < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n+\n+            // feature scaling\n+            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n+            double scaledOriginalValue = scaledValues.remove(i); // extract the scaled original value (it must not appear in encoded values)\n+\n+            // kernel based clustering\n+            double sigma = 1;", "originalCommit": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk5OTk4OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540999989", "bodyText": "this has not changed, previously the gaussian filter was centered in 0 with a stdDev of 1, now its centered around the original value with the same stdDev (as per PR description).\nthis way the encoding mechanism sets to 1 those scaled numbers that fall close to the center of the gaussian (= the original feature value).", "author": "tteofili", "createdAt": "2020-12-11T14:48:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0MjM1OA=="}], "type": "inlineReview", "revised_code": {"commit": "53696c9d78ef55cb9ae5a76c354ab4db9311cf8d", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex d01e09ea6..1cf2c5f0f 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -166,19 +166,19 @@ public enum Type {\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n             double[] doubles = new double[values.length + 1];\n-            int i = 0;\n+            int valueIndex = 0;\n             for (Value<?> v : values) {\n-                doubles[i] = v.asNumber();\n-                i++;\n+                doubles[valueIndex] = v.asNumber();\n+                valueIndex++;\n             }\n             double originalValue = target.asNumber();\n-            doubles[i] = originalValue; // include target number in feature scaling\n+            doubles[valueIndex] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n \n             // feature scaling\n             List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n-            double scaledOriginalValue = scaledValues.remove(i); // extract the scaled original value (it must not appear in encoded values)\n+            double scaledOriginalValue = scaledValues.remove(valueIndex); // extract the scaled original value (it must not appear in encoded values)\n \n             // kernel based clustering\n             double sigma = 1;\n", "next_change": {"commit": "839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex 1cf2c5f0f..dadf67e41 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -184,7 +184,7 @@ public enum Type {\n             double sigma = 1;\n             double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n             List<Double> clusteredValues = scaledValues.stream()\n-                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n+                    .map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n             List<Double> encodedValues = clusteredValues.stream()\n                     .map(d -> (Math.abs(d - threshold) < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0Mzk2MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540943960", "body": "What about make both of them `warn` or `debug`?", "bodyText": "What about make both of them warn or debug?", "bodyHTML": "<p dir=\"auto\">What about make both of them <code>warn</code> or <code>debug</code>?</p>", "author": "danielezonca", "createdAt": "2020-12-11T13:24:33Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,102 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;\n+                // get the top k positive features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKPositive = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getPositiveFeatures(finalK));\n+                // get the most frequent list of positive features\n+                Pair<List<String>, Long> positiveMostFrequent = getMostFrequent(topKPositive);\n+                double positiveFrequencyRate = (double) positiveMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // get the top k negative features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKNegative = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getNegativeFeatures(finalK));\n+                // get the most frequent list of negative features\n+                Pair<List<String>, Long> negativeMostFrequent = getMostFrequent(topKNegative);\n+                double negativeFrequencyRate = (double) negativeMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // decision stability at k\n+                List<String> positiveFeatureNames = positiveMostFrequent.getKey();\n+                List<String> negativeFeatureNames = negativeMostFrequent.getKey();\n+                saliencyStability.add(decision, k, positiveFeatureNames, positiveFrequencyRate, negativeFeatureNames, negativeFrequencyRate);\n+            }\n+        }\n+        return saliencyStability;\n+    }\n+\n+    /**\n+     * Get multiple saliencies, aggregated by decision name.\n+     *\n+     * @param model                  the model used to perform predictions\n+     * @param prediction             the prediction to explain\n+     * @param saliencyLocalExplainer a local explainer that generates saliences\n+     * @param runs                   the no. of explanations to be generated\n+     * @return the generated saliencies, aggregated by decision name, across the different runs\n+     */\n+    private static Map<String, List<Saliency>> getMultipleSaliencies(PredictionProvider model, Prediction prediction,\n+                                                                     LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                     int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = new HashMap<>();\n+        int skipped = 0;\n+        for (int i = 0; i < runs; i++) {\n+            Map<String, Saliency> saliencyMap = saliencyLocalExplainer.explainAsync(prediction, model)\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            for (Map.Entry<String, Saliency> saliencyEntry : saliencyMap.entrySet()) {\n+                // aggregate saliencies by output name\n+                List<FeatureImportance> topFeatures = saliencyEntry.getValue().getTopFeatures(1);\n+                if (!topFeatures.isEmpty() && topFeatures.get(0).getScore() != 0) { // skip empty or 0 valued saliencies\n+                    if (saliencies.containsKey(saliencyEntry.getKey())) {\n+                        List<Saliency> localSaliencies = saliencies.get(saliencyEntry.getKey());\n+                        List<Saliency> updatedSaliencies = new ArrayList<>(localSaliencies);\n+                        updatedSaliencies.add(saliencyEntry.getValue());\n+                        saliencies.put(saliencyEntry.getKey(), updatedSaliencies);\n+                    } else {\n+                        saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n+                    }\n+                } else {\n+                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    skipped++;\n+                }\n+            }\n+        }\n+        LOGGER.debug(\"skipped {} useless saliencies\", skipped);", "originalCommit": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk5MjczNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540992735", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-12-11T14:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0Mzk2MA=="}], "type": "inlineReview", "revised_code": {"commit": "b59a83e1c4e624334d9e8616ecfb9a538d7d8975", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\nindex d508f860a..d935aa669 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n", "chunk": "@@ -217,7 +217,7 @@ public class ExplainabilityMetrics {\n                         saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n                     }\n                 } else {\n-                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    LOGGER.debug(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n                     skipped++;\n                 }\n             }\n", "next_change": null}]}}, {"oid": "b59a83e1c4e624334d9e8616ecfb9a538d7d8975", "url": "https://github.com/kiegroup/kogito-apps/commit/b59a83e1c4e624334d9e8616ecfb9a538d7d8975", "message": "KOGITO-3763 - consistent debug level in metrics", "committedDate": "2020-12-11T14:42:15Z", "type": "commit"}, {"oid": "53696c9d78ef55cb9ae5a76c354ab4db9311cf8d", "url": "https://github.com/kiegroup/kogito-apps/commit/53696c9d78ef55cb9ae5a76c354ab4db9311cf8d", "message": "KOGITO-3763 - renamed index", "committedDate": "2020-12-11T14:58:56Z", "type": "commit"}, {"oid": "6713f89de9a5f3718465b8e66d2571ff208712b0", "url": "https://github.com/kiegroup/kogito-apps/commit/6713f89de9a5f3718465b8e66d2571ff208712b0", "message": "KOGITO-3763 - checking stability on dummy models", "committedDate": "2020-12-11T15:40:00Z", "type": "commit"}, {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "url": "https://github.com/kiegroup/kogito-apps/commit/4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "message": "KOGITO-3763 - added validation utils to validate local saliency stability", "committedDate": "2020-12-11T16:37:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM2OTE2MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542369161", "body": "Would it be possible make \"0.01\" a constant and move it somewhere up to be more visible. I think it is better to have constants visible rather than hidden inside mothods etc.", "bodyText": "Would it be possible make \"0.01\" a constant and move it somewhere up to be more visible. I think it is better to have constants visible rather than hidden inside mothods etc.", "bodyHTML": "<p dir=\"auto\">Would it be possible make \"0.01\" a constant and move it somewhere up to be more visible. I think it is better to have constants visible rather than hidden inside mothods etc.</p>", "author": "jiripetrlik", "createdAt": "2020-12-14T13:08:01Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value", "originalCommit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQzMDgwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542430800", "bodyText": "I am thinking of placing all those parameters inside LimeConfig so that they are centralized, configurable and visible frome one place. I will make a new PR for that.", "author": "tteofili", "createdAt": "2020-12-14T14:34:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM2OTE2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQzMzE1MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542433151", "bodyText": "here's the Jira issue: https://issues.redhat.com/browse/FAI-342", "author": "tteofili", "createdAt": "2020-12-14T14:37:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM2OTE2MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3MDczNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542370737", "body": "Same here. Can we make \"1d\" a constant and move it to more visible place?", "bodyText": "Same here. Can we make \"1d\" a constant and move it to more visible place?", "bodyHTML": "<p dir=\"auto\">Same here. Can we make \"1d\" a constant and move it to more visible place?</p>", "author": "jiripetrlik", "createdAt": "2020-12-14T13:10:32Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value\n+                normalDistributionSample = normalDistributionSample * originalFeatureValue + stDev;\n             }\n             if (intValue) {\n                 normalDistributionSample = (int) normalDistributionSample;\n                 if (normalDistributionSample == originalFeatureValue) {\n-                    normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    normalDistributionSample = (int) normalDistributionSample + 1d;", "originalCommit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQzMzQ4MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542433480", "bodyText": "I'd resolve this also as part of https://issues.redhat.com/browse/FAI-342", "author": "tteofili", "createdAt": "2020-12-14T14:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3MDczNw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ2ODkyNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542468924", "body": "just wondering.. if `Double.isNan(d)` is true the previous call at line 180\r\n```\r\n            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\r\n```\r\nshould have crashed right? ", "bodyText": "just wondering.. if Double.isNan(d) is true the previous call at line 180\n            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n\nshould have crashed right?", "bodyHTML": "<p dir=\"auto\">just wondering.. if <code>Double.isNan(d)</code> is true the previous call at line 180</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"            List&lt;Double&gt; scaledValues = DoubleStream.of(doubles).map(d -&gt; (d - min) / (max - min)).boxed().collect(Collectors.toList());\"><pre><code>            List&lt;Double&gt; scaledValues = DoubleStream.of(doubles).map(d -&gt; (d - min) / (max - min)).boxed().collect(Collectors.toList());\n</code></pre></div>\n<p dir=\"auto\">should have crashed right?</p>", "author": "r00ta", "createdAt": "2020-12-14T15:22:33Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n-            int i = 0;\n+            double[] doubles = new double[values.length + 1];\n+            int valueIndex = 0;\n             for (Value<?> v : values) {\n-                doubles[i] = v.asNumber();\n-                i++;\n+                doubles[valueIndex] = v.asNumber();\n+                valueIndex++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[valueIndex] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n-            // feature scaling + kernel based clustering\n-            double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min), 0, 1);\n-            List<Double> encodedValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n-                    .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(d -> DataUtils.gaussianKernel(d, 0, 1))\n-                    .map(d -> (d - threshold < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n+\n+            // feature scaling\n+            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n+            double scaledOriginalValue = scaledValues.remove(valueIndex); // extract the scaled original value (it must not appear in encoded values)\n+\n+            // kernel based clustering\n+            double sigma = 1;\n+            double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n+            List<Double> clusteredValues = scaledValues.stream()\n+                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());", "originalCommit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjU0MTUzMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542541532", "bodyText": "good catch, it doesn't actually catch but the fact that there's a NaN makes all the values become NaN too in the feature scaling.\nI've fixed it and added a test to cover this case.", "author": "tteofili", "createdAt": "2020-12-14T16:52:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ2ODkyNA=="}], "type": "inlineReview", "revised_code": {"commit": "839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "changed_code": [{"header": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\nindex 1cf2c5f0f..dadf67e41 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java\n", "chunk": "@@ -184,7 +184,7 @@ public enum Type {\n             double sigma = 1;\n             double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n             List<Double> clusteredValues = scaledValues.stream()\n-                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n+                    .map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());\n             List<Double> encodedValues = clusteredValues.stream()\n                     .map(d -> (Math.abs(d - threshold) < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTkzMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542471931", "body": "```suggestion\r\n    void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {\n          \n          \n            \n                void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">void</span> <span class=\"x x-first x-last\">testPrequalificationDMNExplanation1</span>() throws <span class=\"pl-smi\">ExecutionException</span>, <span class=\"pl-smi\">InterruptedException</span>, <span class=\"pl-smi\">TimeoutException</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">void</span> <span class=\"x x-first x-last\">testPrequalificationDMNExplanation</span>() throws <span class=\"pl-smi\">ExecutionException</span>, <span class=\"pl-smi\">InterruptedException</span>, <span class=\"pl-smi\">TimeoutException</span> {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "r00ta", "createdAt": "2020-12-14T15:26:11Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.explainability.integrationtests.dmn;\n+\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n+import org.junit.jupiter.api.Test;\n+import org.kie.dmn.api.core.DMNRuntime;\n+import org.kie.kogito.decision.DecisionModel;\n+import org.kie.kogito.dmn.DMNKogito;\n+import org.kie.kogito.dmn.DmnDecisionModel;\n+import org.kie.kogito.explainability.Config;\n+import org.kie.kogito.explainability.local.lime.LimeConfig;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.PerturbationContext;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+import org.kie.kogito.explainability.utils.ValidationUtils;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class PrequalificationDmnLimeExplainerTest {\n+\n+    @Test\n+    void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {", "originalCommit": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MzQyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542473421", "bodyText": "And rename Prequalification-1 file?", "author": "r00ta", "createdAt": "2020-12-14T15:27:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTkzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjUxMzgyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542513821", "bodyText": "sure, thanks :)", "author": "tteofili", "createdAt": "2020-12-14T16:18:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTkzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "b4f49c55decbc6258ece0a5376082bbed9252a53", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\nindex 5885d6831..edb534877 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n", "chunk": "@@ -52,7 +52,7 @@ import static org.junit.jupiter.api.Assertions.assertNotNull;\n class PrequalificationDmnLimeExplainerTest {\n \n     @Test\n-    void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {\n+    void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {\n         DMNRuntime dmnRuntime = DMNKogito.createGenericDMNRuntime(new InputStreamReader(getClass().getResourceAsStream(\"/dmn/Prequalification-1.dmn\")));\n         assertEquals(1, dmnRuntime.getModels().size());\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "fae3e0ba7ac4e7d113e1cf11e10ba5ff0949b3fe", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\nindex 5885d6831..edb534877 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n", "chunk": "@@ -52,7 +52,7 @@ import static org.junit.jupiter.api.Assertions.assertNotNull;\n class PrequalificationDmnLimeExplainerTest {\n \n     @Test\n-    void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {\n+    void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {\n         DMNRuntime dmnRuntime = DMNKogito.createGenericDMNRuntime(new InputStreamReader(getClass().getResourceAsStream(\"/dmn/Prequalification-1.dmn\")));\n         assertEquals(1, dmnRuntime.getModels().size());\n \n", "next_change": {"commit": "d526a5b102313d804d1906c1520b5495d729f2c5", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\nindex edb534877..45e7a8f91 100644\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n+++ b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n", "chunk": "@@ -53,36 +60,22 @@ class PrequalificationDmnLimeExplainerTest {\n \n     @Test\n     void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {\n-        DMNRuntime dmnRuntime = DMNKogito.createGenericDMNRuntime(new InputStreamReader(getClass().getResourceAsStream(\"/dmn/Prequalification-1.dmn\")));\n-        assertEquals(1, dmnRuntime.getModels().size());\n+        PredictionProvider model = getModel();\n \n-        final String NS = \"http://www.trisotech.com/definitions/_f31e1f8e-d4ce-4a3a-ac3b-747efa6b3401\";\n-        final String NAME = \"Prequalification\";\n-        DecisionModel decisionModel = new DmnDecisionModel(dmnRuntime, NS, NAME);\n-\n-        final Map<String, Object> borrower = new HashMap<>();\n-        borrower.put(\"Monthly Other Debt\", 1000);\n-        borrower.put(\"Monthly Income\", 10000);\n-        final Map<String, Object> contextVariables = new HashMap<>();\n-        contextVariables.put(\"Appraised Value\", 500000);\n-        contextVariables.put(\"Loan Amount\", 300000);\n-        contextVariables.put(\"Credit Score\", 600);\n-        contextVariables.put(\"Borrower\", borrower);\n-        List<Feature> features = new LinkedList<>();\n-        features.add(FeatureFactory.newCompositeFeature(\"context\", contextVariables));\n-        PredictionInput predictionInput = new PredictionInput(features);\n-\n-        PredictionProvider model = new DecisionModelWrapper(decisionModel);\n+        PredictionInput predictionInput = getTestInput();\n \n         Random random = new Random();\n-        random.setSeed(4);\n-        LimeConfig limeConfig = new LimeConfig().withSamples(3000)\n-                .withPerturbationContext(new PerturbationContext(random, 3));\n+\n+        random.setSeed(0);\n+        PerturbationContext perturbationContext = new PerturbationContext(random, 1);\n+        LimeConfig limeConfig = new LimeConfig()\n+                .withSamples(10)\n+                .withPerturbationContext(perturbationContext);\n         LimeExplainer limeExplainer = new LimeExplainer(limeConfig);\n \n         List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(predictionInput))\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-        Prediction prediction = new Prediction(predictionInput, predictionOutputs.get(0));\n+        Prediction prediction = new SimplePrediction(predictionInput, predictionOutputs.get(0));\n         Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n         for (Saliency saliency : saliencyMap.values()) {\n", "next_change": {"commit": "bbb22c06d37e77b97aae6496d74abe43a8cfc965", "changed_code": [{"header": "diff --git a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java b/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\ndeleted file mode 100644\nindex 45e7a8f91..000000000\n--- a/explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n+++ /dev/null\n", "chunk": "@@ -1,152 +0,0 @@\n-/*\n- * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *       http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.kie.kogito.explainability.explainability.integrationtests.dmn;\n-\n-import java.io.InputStreamReader;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Random;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeoutException;\n-\n-import org.assertj.core.api.AssertionsForClassTypes;\n-import org.junit.jupiter.api.Test;\n-import org.kie.dmn.api.core.DMNRuntime;\n-import org.kie.kogito.decision.DecisionModel;\n-import org.kie.kogito.dmn.DMNKogito;\n-import org.kie.kogito.dmn.DmnDecisionModel;\n-import org.kie.kogito.explainability.Config;\n-import org.kie.kogito.explainability.local.lime.LimeConfig;\n-import org.kie.kogito.explainability.local.lime.LimeExplainer;\n-import org.kie.kogito.explainability.local.lime.optim.LimeConfigOptimizer;\n-import org.kie.kogito.explainability.model.DataDistribution;\n-import org.kie.kogito.explainability.model.Feature;\n-import org.kie.kogito.explainability.model.FeatureFactory;\n-import org.kie.kogito.explainability.model.FeatureImportance;\n-import org.kie.kogito.explainability.model.PerturbationContext;\n-import org.kie.kogito.explainability.model.Prediction;\n-import org.kie.kogito.explainability.model.PredictionInput;\n-import org.kie.kogito.explainability.model.PredictionInputsDataDistribution;\n-import org.kie.kogito.explainability.model.PredictionOutput;\n-import org.kie.kogito.explainability.model.PredictionProvider;\n-import org.kie.kogito.explainability.model.Saliency;\n-import org.kie.kogito.explainability.model.SimplePrediction;\n-import org.kie.kogito.explainability.utils.DataUtils;\n-import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n-import org.kie.kogito.explainability.utils.ValidationUtils;\n-\n-import static org.assertj.core.api.Assertions.assertThat;\n-import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;\n-import static org.junit.jupiter.api.Assertions.assertEquals;\n-import static org.junit.jupiter.api.Assertions.assertNotNull;\n-\n-class PrequalificationDmnLimeExplainerTest {\n-\n-    @Test\n-    void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {\n-        PredictionProvider model = getModel();\n-\n-        PredictionInput predictionInput = getTestInput();\n-\n-        Random random = new Random();\n-\n-        random.setSeed(0);\n-        PerturbationContext perturbationContext = new PerturbationContext(random, 1);\n-        LimeConfig limeConfig = new LimeConfig()\n-                .withSamples(10)\n-                .withPerturbationContext(perturbationContext);\n-        LimeExplainer limeExplainer = new LimeExplainer(limeConfig);\n-\n-        List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(predictionInput))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-        Prediction prediction = new SimplePrediction(predictionInput, predictionOutputs.get(0));\n-        Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-        for (Saliency saliency : saliencyMap.values()) {\n-            assertNotNull(saliency);\n-            List<FeatureImportance> topFeatures = saliency.getTopFeatures(2);\n-            if (!topFeatures.isEmpty()) {\n-                assertThat(ExplainabilityMetrics.impactScore(model, prediction, topFeatures)).isPositive();\n-            }\n-        }\n-\n-        assertDoesNotThrow(() -> ValidationUtils.validateLocalSaliencyStability(model, prediction, limeExplainer, 1,\n-                0.3, 0.3));\n-\n-        String decision = \"LLPA\";\n-        List<PredictionInput> inputs = new ArrayList<>();\n-        for (int n = 0; n < 10; n++) {\n-            inputs.add(new PredictionInput(DataUtils.perturbFeatures(predictionInput.getFeatures(), perturbationContext)));\n-        }\n-        DataDistribution distribution = new PredictionInputsDataDistribution(inputs);\n-        int k = 2;\n-        int chunkSize = 2;\n-        double f1 = ExplainabilityMetrics.getLocalSaliencyF1(decision, model, limeExplainer, distribution, k, chunkSize);\n-        AssertionsForClassTypes.assertThat(f1).isBetween(0.5d, 1d);\n-\n-    }\n-\n-    @Test\n-    void testExplanationStabilityWithOptimization() throws ExecutionException, InterruptedException, TimeoutException {\n-        PredictionProvider model = getModel();\n-\n-        List<PredictionInput> samples = DmnTestUtils.randomPrequalificationInputs();\n-        List<PredictionOutput> predictionOutputs = model.predictAsync(samples.subList(0, 10)).get();\n-        List<Prediction> predictions = DataUtils.getPredictions(samples, predictionOutputs);\n-        LimeConfigOptimizer limeConfigOptimizer = new LimeConfigOptimizer().withSampling(false);\n-        Random random = new Random();\n-        random.setSeed(0);\n-        LimeConfig initialConfig = new LimeConfig().withSamples(10);\n-        LimeConfig optimizedConfig = limeConfigOptimizer.optimize(initialConfig, predictions, model);\n-        assertThat(optimizedConfig).isNotSameAs(initialConfig);\n-\n-        LimeExplainer limeExplainer = new LimeExplainer(optimizedConfig);\n-        PredictionInput testPredictionInput = getTestInput();\n-        List<PredictionOutput> testPredictionOutputs = model.predictAsync(List.of(testPredictionInput))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n-        Prediction instance = new SimplePrediction(testPredictionInput, testPredictionOutputs.get(0));\n-\n-        assertDoesNotThrow(() -> ValidationUtils.validateLocalSaliencyStability(model, instance, limeExplainer, 1,\n-                0.4, 0.4));\n-    }\n-\n-    private PredictionInput getTestInput() {\n-        final Map<String, Object> borrower = new HashMap<>();\n-        borrower.put(\"Monthly Other Debt\", 1000);\n-        borrower.put(\"Monthly Income\", 10000);\n-        final Map<String, Object> contextVariables = new HashMap<>();\n-        contextVariables.put(\"Appraised Value\", 500000);\n-        contextVariables.put(\"Loan Amount\", 300000);\n-        contextVariables.put(\"Credit Score\", 600);\n-        contextVariables.put(\"Borrower\", borrower);\n-        List<Feature> features = new LinkedList<>();\n-        features.add(FeatureFactory.newCompositeFeature(\"context\", contextVariables));\n-        return new PredictionInput(features);\n-    }\n-\n-    private PredictionProvider getModel() {\n-        DMNRuntime dmnRuntime = DMNKogito.createGenericDMNRuntime(new InputStreamReader(getClass().getResourceAsStream(\"/dmn/Prequalification-1.dmn\")));\n-        assertEquals(1, dmnRuntime.getModels().size());\n-\n-        final String NS = \"http://www.trisotech.com/definitions/_f31e1f8e-d4ce-4a3a-ac3b-747efa6b3401\";\n-        final String NAME = \"Prequalification\";\n-        DecisionModel decisionModel = new DmnDecisionModel(dmnRuntime, NS, NAME);\n-        return new DecisionModelWrapper(decisionModel);\n-    }\n-}\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "fae3e0ba7ac4e7d113e1cf11e10ba5ff0949b3fe", "message": "Merge commit", "committedDate": null}, {"oid": "cd5adebe96ccc6779dae7fce94d0e9abb8230e69", "committedDate": "2021-01-22 16:24:34 +0100", "message": "KOGITO-4007 - Investigate PmmlLimeExplainerTest memory consumption issues (#583)"}, {"oid": "c0612b33d89568c8550170ac5264c1317e62ca80", "committedDate": "2021-04-09 10:29:32 +0200", "message": "FAI-399 - add precision / recall metrics for local saliency eval (#676)"}, {"oid": "9937cfb617ee653620bebf8f36fb8be15daf6fb5", "committedDate": "2021-04-17 00:45:05 +1000", "message": "FAI-468 - Reduced timing for LIME related tests (#766)"}, {"oid": "c4671ff98bd70b01d586df2529fbe88044142190", "committedDate": "2021-04-30 18:40:55 +0100", "message": "FAI-467 Implement stateless CF explainer (#780)"}, {"oid": "d526a5b102313d804d1906c1520b5495d729f2c5", "committedDate": "2021-06-28 17:39:30 +0200", "message": "FAI-475 - Automatically optimize LIME hyperparameters for stability (#820)"}, {"oid": "9c8750b567dac3f9f14947c214225984ec8778c7", "committedDate": "2021-07-14 10:57:30 +0200", "message": "FAI-494 - adding impact-score LIME optimizer (#923)"}, {"oid": "fe63c2216e2a04f0172c1cb48e4ff6d5957078b6", "committedDate": "2021-07-20 10:02:02 +0200", "message": "FAI-495 - positive vs negative weighting for stability score calculation (#919)"}, {"oid": "c9090e26255fe85aded7cc9f4bbd6eb293f02605", "committedDate": "2021-09-29 09:12:38 +0200", "message": "FAI-555 - make it possible to run LIME config optimization deterministically (#1000)"}, {"oid": "b1bf2326cfec0ff5dcf1d87fe62f7a7d99fcc4a4", "committedDate": "2022-01-12 23:46:44 +0100", "message": "KOGITO-6385 - use a fixed no. of optimization steps in ITs that use OP (#1168)"}, {"oid": "bbb22c06d37e77b97aae6496d74abe43a8cfc965", "committedDate": "2022-06-29 09:29:46 +0200", "message": "Delete TrustyAI Explainability library from kogito-apps (#1384)"}]}, {"oid": "b4f49c55decbc6258ece0a5376082bbed9252a53", "url": "https://github.com/kiegroup/kogito-apps/commit/b4f49c55decbc6258ece0a5376082bbed9252a53", "message": "Update explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java\n\nCo-authored-by: Jacopo Rota <jacopo.r00ta@gmail.com>", "committedDate": "2020-12-14T16:17:39Z", "type": "commit"}, {"oid": "839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "url": "https://github.com/kiegroup/kogito-apps/commit/839f28843cc3c2e8f6df4c6bfea037eb55de4fbb", "message": "KOGITO-3763 - fixed NaN encoding issue", "committedDate": "2020-12-14T16:48:43Z", "type": "commit"}]}