{"pr_number": 9758, "pr_title": "MINOR: remove FetchResponse.AbortedTransaction and redundant construc\u2026", "pr_author": "chia7712", "pr_createdAt": "2020-12-16T08:52:35Z", "pr_url": "https://github.com/apache/kafka/pull/9758", "timeline": [{"oid": "b3e592f8e22b60e781e3037a266c3d060432a5fb", "url": "https://github.com/apache/kafka/commit/b3e592f8e22b60e781e3037a266c3d060432a5fb", "message": "MINOR: remove FetchResponse.AbortedTransaction and duplicate constructors of PartitionData", "committedDate": "2021-01-13T13:50:26Z", "type": "commit"}, {"oid": "f217bb53ee96972d639a85348dd862f99e529f42", "url": "https://github.com/apache/kafka/commit/f217bb53ee96972d639a85348dd862f99e529f42", "message": "remove unnecessary changes and remove partitionData", "committedDate": "2021-01-13T13:50:26Z", "type": "commit"}, {"oid": "3f219e5951133f791ab0cc546bb33fcbc199a608", "url": "https://github.com/apache/kafka/commit/3f219e5951133f791ab0cc546bb33fcbc199a608", "message": "remove PartitionData", "committedDate": "2021-01-13T13:51:15Z", "type": "commit"}, {"oid": "83a26f0b0b86af15516556f84130a46deb0ea6a9", "url": "https://github.com/apache/kafka/commit/83a26f0b0b86af15516556f84130a46deb0ea6a9", "message": "add isDivergingEpoch and isPreferredReplica", "committedDate": "2021-01-13T13:51:15Z", "type": "commit"}, {"oid": "7c386a0a9504489fd8db5871d84abfef2dff270d", "url": "https://github.com/apache/kafka/commit/7c386a0a9504489fd8db5871d84abfef2dff270d", "message": "remove unused import", "committedDate": "2021-01-13T13:53:24Z", "type": "commit"}, {"oid": "7c386a0a9504489fd8db5871d84abfef2dff270d", "url": "https://github.com/apache/kafka/commit/7c386a0a9504489fd8db5871d84abfef2dff270d", "message": "remove unused import", "committedDate": "2021-01-13T13:53:24Z", "type": "forcePushed"}, {"oid": "c010e4e154931d6474d89d9bee50be1b594dfff3", "url": "https://github.com/apache/kafka/commit/c010e4e154931d6474d89d9bee50be1b594dfff3", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-14T06:16:14Z", "type": "commit"}, {"oid": "30695f8563a2ebb0eb235d35a652d66aac5c42ad", "url": "https://github.com/apache/kafka/commit/30695f8563a2ebb0eb235d35a652d66aac5c42ad", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-15T19:18:48Z", "type": "commit"}, {"oid": "9122aee548963feca3f50fcebd6b59479a1a07aa", "url": "https://github.com/apache/kafka/commit/9122aee548963feca3f50fcebd6b59479a1a07aa", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-16T19:10:53Z", "type": "commit"}, {"oid": "4106d2fab6241bb5bdbb0706681e16f819114f62", "url": "https://github.com/apache/kafka/commit/4106d2fab6241bb5bdbb0706681e16f819114f62", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-18T17:31:14Z", "type": "commit"}, {"oid": "d97de8ac517e40c4981c2e33a50e547c4d9d0ff6", "url": "https://github.com/apache/kafka/commit/d97de8ac517e40c4981c2e33a50e547c4d9d0ff6", "message": "fix checkstyle", "committedDate": "2021-01-18T17:38:10Z", "type": "commit"}, {"oid": "13f7710839530ffa780d84c24099d4cc0f138bbe", "url": "https://github.com/apache/kafka/commit/13f7710839530ffa780d84c24099d4cc0f138bbe", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-18T19:21:18Z", "type": "commit"}, {"oid": "52ab1569ba84f7ea96253c08acc2817fd7cd6a65", "url": "https://github.com/apache/kafka/commit/52ab1569ba84f7ea96253c08acc2817fd7cd6a65", "message": "tweak style", "committedDate": "2021-01-18T19:25:27Z", "type": "commit"}, {"oid": "cb157fe1696414f0840d1ed8c619bda1f2c240a2", "url": "https://github.com/apache/kafka/commit/cb157fe1696414f0840d1ed8c619bda1f2c240a2", "message": "rename dataByTopicPartition to responseData", "committedDate": "2021-01-18T19:30:34Z", "type": "commit"}, {"oid": "9627cd99d569b90868ae436b43bcc9f53d564a79", "url": "https://github.com/apache/kafka/commit/9627cd99d569b90868ae436b43bcc9f53d564a79", "message": "rename recordSet to records", "committedDate": "2021-01-18T19:41:39Z", "type": "commit"}, {"oid": "e15ee0cc6e57ab00a70c0ed099ce86a7ba778d6e", "url": "https://github.com/apache/kafka/commit/e15ee0cc6e57ab00a70c0ed099ce86a7ba778d6e", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-19T10:19:26Z", "type": "commit"}, {"oid": "868ff0ceb01ecbb8313839554c302c48a6d095e7", "url": "https://github.com/apache/kafka/commit/868ff0ceb01ecbb8313839554c302c48a6d095e7", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-19T16:40:01Z", "type": "commit"}, {"oid": "ef45f01869c65f68be019c9f833d3ad2a15a4ba6", "url": "https://github.com/apache/kafka/commit/ef45f01869c65f68be019c9f833d3ad2a15a4ba6", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-21T04:11:38Z", "type": "commit"}, {"oid": "bc5c494c16a750c8624fd6440cc68149550de4be", "url": "https://github.com/apache/kafka/commit/bc5c494c16a750c8624fd6440cc68149550de4be", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-27T07:55:25Z", "type": "commit"}, {"oid": "ce991c36425c1941127c69b701c9dc814ddd047e", "url": "https://github.com/apache/kafka/commit/ce991c36425c1941127c69b701c9dc814ddd047e", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-01T07:42:04Z", "type": "commit"}, {"oid": "4a83601ad09c96081fded8cf9118e372fff21938", "url": "https://github.com/apache/kafka/commit/4a83601ad09c96081fded8cf9118e372fff21938", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-02T08:48:00Z", "type": "commit"}, {"oid": "3b55cd7bbb53f221ac2e30e6eaf8689f7a39b09b", "url": "https://github.com/apache/kafka/commit/3b55cd7bbb53f221ac2e30e6eaf8689f7a39b09b", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-12T19:51:05Z", "type": "commit"}, {"oid": "cd1c981d487be38f19ee2b116995650af8c5257f", "url": "https://github.com/apache/kafka/commit/cd1c981d487be38f19ee2b116995650af8c5257f", "message": "fix build", "committedDate": "2021-02-12T19:54:46Z", "type": "commit"}, {"oid": "fbca0494018d96d583bbef4c146d01dd00ca1db6", "url": "https://github.com/apache/kafka/commit/fbca0494018d96d583bbef4c146d01dd00ca1db6", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-17T05:21:06Z", "type": "commit"}, {"oid": "4077553bb23057cd41a80db90998343fa5b1354b", "url": "https://github.com/apache/kafka/commit/4077553bb23057cd41a80db90998343fa5b1354b", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-18T03:25:37Z", "type": "commit"}, {"oid": "d513d855ad7990371d80792255f7c46143726f34", "url": "https://github.com/apache/kafka/commit/d513d855ad7990371d80792255f7c46143726f34", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-20T03:17:01Z", "type": "commit"}, {"oid": "9e17a7eeac81d554a43917a0022ede41e4a8ff5e", "url": "https://github.com/apache/kafka/commit/9e17a7eeac81d554a43917a0022ede41e4a8ff5e", "message": "fix build error", "committedDate": "2021-02-20T03:23:07Z", "type": "commit"}, {"oid": "568d8f56fc0a9c052031d87f4b506c27383442ae", "url": "https://github.com/apache/kafka/commit/568d8f56fc0a9c052031d87f4b506c27383442ae", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-23T10:02:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA0NDU1Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581044552", "body": "`FetchablePartitionResponse` is a bit long and redundant. Could we find a shorter name for it now that `PartitionData` is gone?", "bodyText": "FetchablePartitionResponse is a bit long and redundant. Could we find a shorter name for it now that PartitionData is gone?", "bodyHTML": "<p dir=\"auto\"><code>FetchablePartitionResponse</code> is a bit long and redundant. Could we find a shorter name for it now that <code>PartitionData</code> is gone?</p>", "author": "ijuma", "createdAt": "2021-02-23T13:43:52Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -290,7 +291,7 @@ public void onSuccess(ClientResponse resp) {\n                             Set<TopicPartition> partitions = new HashSet<>(response.responseData().keySet());\n                             FetchResponseMetricAggregator metricAggregator = new FetchResponseMetricAggregator(sensors, partitions);\n \n-                            for (Map.Entry<TopicPartition, FetchResponse.PartitionData<Records>> entry : response.responseData().entrySet()) {\n+                            for (Map.Entry<TopicPartition, FetchResponseData.FetchablePartitionResponse> entry : response.responseData().entrySet()) {", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA4ODY4MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581088681", "bodyText": "sure. I reuse the name PartitionData", "author": "chia7712", "createdAt": "2021-02-23T14:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA0NDU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA1NDAzOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581054038", "body": "Could we encapsulate this cast in a utility method?", "bodyText": "Could we encapsulate this cast in a utility method?", "bodyHTML": "<p dir=\"auto\">Could we encapsulate this cast in a utility method?</p>", "author": "ijuma", "createdAt": "2021-02-23T13:56:24Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -1257,7 +1259,7 @@ private CompletedFetch initializeCompletedFetch(CompletedFetch nextCompletedFetc\n \n                 log.trace(\"Preparing to read {} bytes of data for partition {} with offset {}\",\n                         partition.records().sizeInBytes(), tp, position);\n-                Iterator<? extends RecordBatch> batches = partition.records().batches().iterator();\n+                Iterator<? extends RecordBatch> batches = ((Records) partition.records()).batches().iterator();", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA1ODE2Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581058162", "body": "Maybe we can remove the defaults from this and every other place where we build `FetchablePartitionResponse`", "bodyText": "Maybe we can remove the defaults from this and every other place where we build FetchablePartitionResponse", "bodyHTML": "<p dir=\"auto\">Maybe we can remove the defaults from this and every other place where we build <code>FetchablePartitionResponse</code></p>", "author": "ijuma", "createdAt": "2021-02-23T14:01:46Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetchsession/FetchSessionBenchmark.java", "diffHunk": "@@ -70,24 +70,26 @@ public void setUp() {\n         handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n         FetchSessionHandler.Builder builder = handler.newBuilder();\n \n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> respMap = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> respMap = new LinkedHashMap<>();\n         for (int i = 0; i < partitionCount; i++) {\n             TopicPartition tp = new TopicPartition(\"foo\", i);\n             FetchRequest.PartitionData partitionData = new FetchRequest.PartitionData(0, 0, 200,\n                     Optional.empty());\n             fetches.put(tp, partitionData);\n             builder.add(tp, partitionData);\n-            respMap.put(tp, new FetchResponse.PartitionData<>(\n-                    Errors.NONE,\n-                    0L,\n-                    0L,\n-                    0,\n-                    null,\n-                    null));\n+            respMap.put(tp, new FetchResponseData.FetchablePartitionResponse()\n+                            .setPartition(tp.partition())\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setHighWatermark(0)\n+                            .setLastStableOffset(0)\n+                            .setLogStartOffset(0)\n+                            .setAbortedTransactions(null)\n+                            .setRecords(null)\n+                            .setPreferredReadReplica(FetchResponse.INVALID_PREFERRED_REPLICA_ID));", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA2NDY2OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581064669", "body": "I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.", "bodyText": "I think it would be better to make this a static factory method and keep the constructor for the case where we receive FetchResponseData.", "bodyHTML": "<p dir=\"auto\">I think it would be better to make this a static factory method and keep the constructor for the case where we receive <code>FetchResponseData</code>.</p>", "author": "ijuma", "createdAt": "2021-02-23T14:09:15Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -57,238 +55,51 @@\n  *     the fetch offset after the index lookup\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n-public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n-\n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+public class FetchResponse extends AbstractResponse {\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    private final LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData;\n \n     @Override\n     public FetchResponseData data() {\n         return data;\n     }\n \n-    public static final class AbortedTransaction {\n-        public final long producerId;\n-        public final long firstOffset;\n-\n-        public AbortedTransaction(long producerId, long firstOffset) {\n-            this.producerId = producerId;\n-            this.firstOffset = firstOffset;\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            AbortedTransaction that = (AbortedTransaction) o;\n-\n-            return producerId == that.producerId && firstOffset == that.firstOffset;\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            int result = Long.hashCode(producerId);\n-            result = 31 * result + Long.hashCode(firstOffset);\n-            return result;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(producerId=\" + producerId + \", firstOffset=\" + firstOffset + \")\";\n-        }\n-\n-        static AbortedTransaction fromMessage(FetchResponseData.AbortedTransaction abortedTransaction) {\n-            return new AbortedTransaction(abortedTransaction.producerId(), abortedTransaction.firstOffset());\n-        }\n-    }\n-\n-    public static final class PartitionData<T extends BaseRecords> {\n-        private final FetchResponseData.FetchablePartitionResponse partitionResponse;\n-\n-        // Derived fields\n-        private final Optional<Integer> preferredReplica;\n-        private final List<AbortedTransaction> abortedTransactions;\n-        private final Errors error;\n-\n-        private PartitionData(FetchResponseData.FetchablePartitionResponse partitionResponse) {\n-            // We partially construct FetchablePartitionResponse since we don't know the partition ID at this point\n-            // When we convert the PartitionData (and other fields) into FetchResponseData down in toMessage, we\n-            // set the partition IDs.\n-            this.partitionResponse = partitionResponse;\n-            this.preferredReplica = Optional.of(partitionResponse.preferredReadReplica())\n-                .filter(replicaId -> replicaId != INVALID_PREFERRED_REPLICA_ID);\n-\n-            if (partitionResponse.abortedTransactions() == null) {\n-                this.abortedTransactions = null;\n-            } else {\n-                this.abortedTransactions = partitionResponse.abortedTransactions().stream()\n-                    .map(AbortedTransaction::fromMessage)\n-                    .collect(Collectors.toList());\n-            }\n-\n-            this.error = Errors.forCode(partitionResponse.errorCode());\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             Optional<FetchResponseData.EpochEndOffset> divergingEpoch,\n-                             T records) {\n-            this.preferredReplica = preferredReadReplica;\n-            this.abortedTransactions = abortedTransactions;\n-            this.error = error;\n-\n-            FetchResponseData.FetchablePartitionResponse partitionResponse =\n-                new FetchResponseData.FetchablePartitionResponse();\n-            partitionResponse.setErrorCode(error.code())\n-                .setHighWatermark(highWatermark)\n-                .setLastStableOffset(lastStableOffset)\n-                .setLogStartOffset(logStartOffset);\n-            if (abortedTransactions != null) {\n-                partitionResponse.setAbortedTransactions(abortedTransactions.stream().map(\n-                    aborted -> new FetchResponseData.AbortedTransaction()\n-                        .setProducerId(aborted.producerId)\n-                        .setFirstOffset(aborted.firstOffset))\n-                    .collect(Collectors.toList()));\n-            } else {\n-                partitionResponse.setAbortedTransactions(null);\n-            }\n-            partitionResponse.setPreferredReadReplica(preferredReadReplica.orElse(INVALID_PREFERRED_REPLICA_ID));\n-            partitionResponse.setRecordSet(records);\n-            divergingEpoch.ifPresent(partitionResponse::setDivergingEpoch);\n-\n-            this.partitionResponse = partitionResponse;\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, preferredReadReplica,\n-                abortedTransactions, Optional.empty(), records);\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, Optional.empty(), abortedTransactions, records);\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            PartitionData that = (PartitionData) o;\n-\n-            return this.partitionResponse.equals(that.partitionResponse);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return this.partitionResponse.hashCode();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(error=\" + error() +\n-                    \", highWaterMark=\" + highWatermark() +\n-                    \", lastStableOffset = \" + lastStableOffset() +\n-                    \", logStartOffset = \" + logStartOffset() +\n-                    \", preferredReadReplica = \" + preferredReadReplica().map(Object::toString).orElse(\"absent\") +\n-                    \", abortedTransactions = \" + abortedTransactions() +\n-                    \", divergingEpoch =\" + divergingEpoch() +\n-                    \", recordsSizeInBytes=\" + records().sizeInBytes() + \")\";\n-        }\n-\n-        public Errors error() {\n-            return error;\n-        }\n-\n-        public long highWatermark() {\n-            return partitionResponse.highWatermark();\n-        }\n-\n-        public long lastStableOffset() {\n-            return partitionResponse.lastStableOffset();\n-        }\n-\n-        public long logStartOffset() {\n-            return partitionResponse.logStartOffset();\n-        }\n-\n-        public Optional<Integer> preferredReadReplica() {\n-            return preferredReplica;\n-        }\n-\n-        public List<AbortedTransaction> abortedTransactions() {\n-            return abortedTransactions;\n-        }\n-\n-        public Optional<FetchResponseData.EpochEndOffset> divergingEpoch() {\n-            FetchResponseData.EpochEndOffset epochEndOffset = partitionResponse.divergingEpoch();\n-            if (epochEndOffset.epoch() < 0) {\n-                return Optional.empty();\n-            } else {\n-                return Optional.of(epochEndOffset);\n-            }\n-        }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        public T records() {\n-            return (T) partitionResponse.recordSet();\n-        }\n-    }\n-\n-    /**\n-     * From version 3 or later, the entries in `responseData` should be in the same order as the entries in\n-     * `FetchRequest.fetchData`.\n-     *\n-     * @param error             The top-level error code.\n-     * @param responseData      The fetched data grouped by partition.\n-     * @param throttleTimeMs    The time in milliseconds that the response was throttled\n-     * @param sessionId         The fetch session id.\n-     */\n     public FetchResponse(Errors error,", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA2OTA3MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581069071", "body": "This isn't needed when we return a fetch from the broker, right? If this is true, can we remove it from the fetch response and build it on the client when needed?", "bodyText": "This isn't needed when we return a fetch from the broker, right? If this is true, can we remove it from the fetch response and build it on the client when needed?", "bodyHTML": "<p dir=\"auto\">This isn't needed when we return a fetch from the broker, right? If this is true, can we remove it from the fetch response and build it on the client when needed?</p>", "author": "ijuma", "createdAt": "2021-02-23T14:14:28Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -57,238 +55,51 @@\n  *     the fetch offset after the index lookup\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n-public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n-\n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+public class FetchResponse extends AbstractResponse {\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    private final LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData;\n \n     @Override\n     public FetchResponseData data() {\n         return data;\n     }\n \n-    public static final class AbortedTransaction {\n-        public final long producerId;\n-        public final long firstOffset;\n-\n-        public AbortedTransaction(long producerId, long firstOffset) {\n-            this.producerId = producerId;\n-            this.firstOffset = firstOffset;\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            AbortedTransaction that = (AbortedTransaction) o;\n-\n-            return producerId == that.producerId && firstOffset == that.firstOffset;\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            int result = Long.hashCode(producerId);\n-            result = 31 * result + Long.hashCode(firstOffset);\n-            return result;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(producerId=\" + producerId + \", firstOffset=\" + firstOffset + \")\";\n-        }\n-\n-        static AbortedTransaction fromMessage(FetchResponseData.AbortedTransaction abortedTransaction) {\n-            return new AbortedTransaction(abortedTransaction.producerId(), abortedTransaction.firstOffset());\n-        }\n-    }\n-\n-    public static final class PartitionData<T extends BaseRecords> {\n-        private final FetchResponseData.FetchablePartitionResponse partitionResponse;\n-\n-        // Derived fields\n-        private final Optional<Integer> preferredReplica;\n-        private final List<AbortedTransaction> abortedTransactions;\n-        private final Errors error;\n-\n-        private PartitionData(FetchResponseData.FetchablePartitionResponse partitionResponse) {\n-            // We partially construct FetchablePartitionResponse since we don't know the partition ID at this point\n-            // When we convert the PartitionData (and other fields) into FetchResponseData down in toMessage, we\n-            // set the partition IDs.\n-            this.partitionResponse = partitionResponse;\n-            this.preferredReplica = Optional.of(partitionResponse.preferredReadReplica())\n-                .filter(replicaId -> replicaId != INVALID_PREFERRED_REPLICA_ID);\n-\n-            if (partitionResponse.abortedTransactions() == null) {\n-                this.abortedTransactions = null;\n-            } else {\n-                this.abortedTransactions = partitionResponse.abortedTransactions().stream()\n-                    .map(AbortedTransaction::fromMessage)\n-                    .collect(Collectors.toList());\n-            }\n-\n-            this.error = Errors.forCode(partitionResponse.errorCode());\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             Optional<FetchResponseData.EpochEndOffset> divergingEpoch,\n-                             T records) {\n-            this.preferredReplica = preferredReadReplica;\n-            this.abortedTransactions = abortedTransactions;\n-            this.error = error;\n-\n-            FetchResponseData.FetchablePartitionResponse partitionResponse =\n-                new FetchResponseData.FetchablePartitionResponse();\n-            partitionResponse.setErrorCode(error.code())\n-                .setHighWatermark(highWatermark)\n-                .setLastStableOffset(lastStableOffset)\n-                .setLogStartOffset(logStartOffset);\n-            if (abortedTransactions != null) {\n-                partitionResponse.setAbortedTransactions(abortedTransactions.stream().map(\n-                    aborted -> new FetchResponseData.AbortedTransaction()\n-                        .setProducerId(aborted.producerId)\n-                        .setFirstOffset(aborted.firstOffset))\n-                    .collect(Collectors.toList()));\n-            } else {\n-                partitionResponse.setAbortedTransactions(null);\n-            }\n-            partitionResponse.setPreferredReadReplica(preferredReadReplica.orElse(INVALID_PREFERRED_REPLICA_ID));\n-            partitionResponse.setRecordSet(records);\n-            divergingEpoch.ifPresent(partitionResponse::setDivergingEpoch);\n-\n-            this.partitionResponse = partitionResponse;\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, preferredReadReplica,\n-                abortedTransactions, Optional.empty(), records);\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, Optional.empty(), abortedTransactions, records);\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            PartitionData that = (PartitionData) o;\n-\n-            return this.partitionResponse.equals(that.partitionResponse);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return this.partitionResponse.hashCode();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(error=\" + error() +\n-                    \", highWaterMark=\" + highWatermark() +\n-                    \", lastStableOffset = \" + lastStableOffset() +\n-                    \", logStartOffset = \" + logStartOffset() +\n-                    \", preferredReadReplica = \" + preferredReadReplica().map(Object::toString).orElse(\"absent\") +\n-                    \", abortedTransactions = \" + abortedTransactions() +\n-                    \", divergingEpoch =\" + divergingEpoch() +\n-                    \", recordsSizeInBytes=\" + records().sizeInBytes() + \")\";\n-        }\n-\n-        public Errors error() {\n-            return error;\n-        }\n-\n-        public long highWatermark() {\n-            return partitionResponse.highWatermark();\n-        }\n-\n-        public long lastStableOffset() {\n-            return partitionResponse.lastStableOffset();\n-        }\n-\n-        public long logStartOffset() {\n-            return partitionResponse.logStartOffset();\n-        }\n-\n-        public Optional<Integer> preferredReadReplica() {\n-            return preferredReplica;\n-        }\n-\n-        public List<AbortedTransaction> abortedTransactions() {\n-            return abortedTransactions;\n-        }\n-\n-        public Optional<FetchResponseData.EpochEndOffset> divergingEpoch() {\n-            FetchResponseData.EpochEndOffset epochEndOffset = partitionResponse.divergingEpoch();\n-            if (epochEndOffset.epoch() < 0) {\n-                return Optional.empty();\n-            } else {\n-                return Optional.of(epochEndOffset);\n-            }\n-        }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        public T records() {\n-            return (T) partitionResponse.recordSet();\n-        }\n-    }\n-\n-    /**\n-     * From version 3 or later, the entries in `responseData` should be in the same order as the entries in\n-     * `FetchRequest.fetchData`.\n-     *\n-     * @param error             The top-level error code.\n-     * @param responseData      The fetched data grouped by partition.\n-     * @param throttleTimeMs    The time in milliseconds that the response was throttled\n-     * @param sessionId         The fetch session id.\n-     */\n     public FetchResponse(Errors error,\n-                         LinkedHashMap<TopicPartition, PartitionData<T>> responseData,\n                          int throttleTimeMs,\n-                         int sessionId) {\n-        super(ApiKeys.FETCH);\n-        this.data = toMessage(throttleTimeMs, error, responseData.entrySet().iterator(), sessionId);\n-        this.responseDataMap = responseData;\n+                         int sessionId,\n+                         LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData) {\n+        this(new FetchResponseData()\n+            .setSessionId(sessionId)\n+            .setErrorCode(error.code())\n+            .setThrottleTimeMs(throttleTimeMs)\n+            .setResponses(responseData.entrySet().stream().map(entry -> new FetchResponseData.FetchableTopicResponse()\n+                .setTopic(entry.getKey().topic())\n+                .setPartitionResponses(Collections.singletonList(entry.getValue().setPartition(entry.getKey().partition()))))\n+                .collect(Collectors.toList())));\n     }\n \n     public FetchResponse(FetchResponseData fetchResponseData) {\n         super(ApiKeys.FETCH);\n         this.data = fetchResponseData;\n-        this.responseDataMap = toResponseDataMap(fetchResponseData);\n+        this.responseData = new LinkedHashMap<>();", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eddfffd349a34cc26ddc5db284b5526c40f5fcc8", "url": "https://github.com/apache/kafka/commit/eddfffd349a34cc26ddc5db284b5526c40f5fcc8", "message": "rename FetchablePartitionResponse to PartitionData; add helper method to construct FetchResponse; add helper method to cast records", "committedDate": "2021-02-23T15:15:35Z", "type": "commit"}, {"oid": "9b7637645b76d04eed4a606e75580aa8d1c1a2d0", "url": "https://github.com/apache/kafka/commit/9b7637645b76d04eed4a606e75580aa8d1c1a2d0", "message": "rename index to partitionIndex", "committedDate": "2021-02-23T15:29:46Z", "type": "commit"}, {"oid": "7d5a5a3800ebf01665fe97c935428fb2e0ec2601", "url": "https://github.com/apache/kafka/commit/7d5a5a3800ebf01665fe97c935428fb2e0ec2601", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-25T15:36:24Z", "type": "commit"}, {"oid": "a4edde39d57282bb0acb018ff3eb91a5cf1321e8", "url": "https://github.com/apache/kafka/commit/a4edde39d57282bb0acb018ff3eb91a5cf1321e8", "message": "fix broken build", "committedDate": "2021-02-25T15:42:50Z", "type": "commit"}, {"oid": "b929215cae4ebcfb5e104d4d387c9c48b507fdf1", "url": "https://github.com/apache/kafka/commit/b929215cae4ebcfb5e104d4d387c9c48b507fdf1", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-26T04:07:38Z", "type": "commit"}, {"oid": "e6e1478661e398fb813c8ca77f9d25bc5bd37d86", "url": "https://github.com/apache/kafka/commit/e6e1478661e398fb813c8ca77f9d25bc5bd37d86", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-27T15:20:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584141887", "body": "This is not thread-safe and requests are typically thread-safe. What's the thinking here?", "bodyText": "This is not thread-safe and requests are typically thread-safe. What's the thinking here?", "bodyHTML": "<p dir=\"auto\">This is not thread-safe and requests are typically thread-safe. What's the thinking here?</p>", "author": "ijuma", "createdAt": "2021-02-27T15:32:17Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -57,238 +56,39 @@\n  *     the fetch offset after the index lookup\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n-public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n-\n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+public class FetchResponse extends AbstractResponse {\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    // we build responseData when needed.\n+    private LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = null;", "originalCommit": "e6e1478661e398fb813c8ca77f9d25bc5bd37d86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MjA3NA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584142074", "bodyText": "Looks like this method is used only Fetcher.sendFetches outside of tests, benchmaks, etc.. Also once in errorCounts, but we can change that code. Maybe we can remove this altogether. Thoughts?", "author": "ijuma", "createdAt": "2021-02-27T15:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MjE4Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584142186", "bodyText": "I think I would move the method to a test utility so that tests can use that instead.", "author": "ijuma", "createdAt": "2021-02-27T15:35:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0ODgxNw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584148817", "bodyText": "It is used by FetchSessionHandler also. I prefer to rewrite that code by another PR to avoid big patch :(\nIt seems to me using synchronization block can resolve the thread issue. Also, I will file a jira as follow-up. WDYT?", "author": "chia7712", "createdAt": "2021-02-27T15:58:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE1MTcxNg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584151716", "bodyText": "Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.", "author": "ijuma", "createdAt": "2021-02-27T16:18:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE2NTAzMw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584165033", "bodyText": "jira: https://issues.apache.org/jira/browse/KAFKA-12385\n\nyou can use a volatile field and synchronize on the assignment if still null.\n\nupdated", "author": "chia7712", "createdAt": "2021-02-27T17:40:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}], "type": "inlineReview"}, {"oid": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "url": "https://github.com/apache/kafka/commit/ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "message": "make FetchResponse thread-safe", "committedDate": "2021-02-27T17:40:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjE3Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172177", "body": "Can we update this not to use `responseData`? Then we at least have the right behavior for the broker and we can fix the clients in the subsequent PR.", "bodyText": "Can we update this not to use responseData? Then we at least have the right behavior for the broker and we can fix the clients in the subsequent PR.", "bodyHTML": "<p dir=\"auto\">Can we update this not to use <code>responseData</code>? Then we at least have the right behavior for the broker and we can fix the clients in the subsequent PR.</p>", "author": "ijuma", "createdAt": "2021-02-27T18:30:35Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -304,58 +108,12 @@ public int sessionId() {\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n         updateErrorCounts(errorCounts, error());\n-        responseDataMap.values().forEach(response ->\n-            updateErrorCounts(errorCounts, response.error())\n-        );\n+        responseData().values().forEach(response -> updateErrorCounts(errorCounts, Errors.forCode(response.errorCode())));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjQ0NQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172445", "body": "Aren't many of these set automatically by the generated classes?", "bodyText": "Aren't many of these set automatically by the generated classes?", "bodyHTML": "<p dir=\"auto\">Aren't many of these set automatically by the generated classes?</p>", "author": "ijuma", "createdAt": "2021-02-27T18:33:25Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +123,70 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+                .setPartitionIndex(partition)\n+                .setErrorCode(error.code())\n+                .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(MemoryRecords.EMPTY);", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMTY2MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584221661", "bodyText": "you are right. Except for HighWatermark, other args have default value. remove duplicate assignment!", "author": "chia7712", "createdAt": "2021-02-28T02:50:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjUzMA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172530", "body": "Does this ever fail? If so, it would be good to explain under which conditions it can fail. Also \"This is used to eliminate duplicate code of type casting.\" seems a bit redundant.", "bodyText": "Does this ever fail? If so, it would be good to explain under which conditions it can fail. Also \"This is used to eliminate duplicate code of type casting.\" seems a bit redundant.", "bodyHTML": "<p dir=\"auto\">Does this ever fail? If so, it would be good to explain under which conditions it can fail. Also \"This is used to eliminate duplicate code of type casting.\" seems a bit redundant.</p>", "author": "ijuma", "createdAt": "2021-02-27T18:34:16Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +123,70 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+                .setPartitionIndex(partition)\n+                .setErrorCode(error.code())\n+                .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(MemoryRecords.EMPTY);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. This is used to eliminate duplicate code of type casting.", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMTAzNg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584221036", "bodyText": "the data from KRPC always use MemoryRecords so it should never fail if the data is from KRPC. I will add more comments for this case.", "author": "chia7712", "createdAt": "2021-02-28T02:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjUzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjYwNg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172606", "body": "Nit: indenting seems excessive.", "bodyText": "Nit: indenting seems excessive.", "bodyHTML": "<p dir=\"auto\">Nit: indenting seems excessive.</p>", "author": "ijuma", "createdAt": "2021-02-27T18:35:10Z", "path": "clients/src/test/java/org/apache/kafka/clients/FetchSessionHandlerTest.java", "diffHunk": "@@ -150,22 +150,23 @@ private static void assertListEquals(List<TopicPartition> expected, List<TopicPa\n \n     private static final class RespEntry {\n         final TopicPartition part;\n-        final FetchResponse.PartitionData<MemoryRecords> data;\n+        final FetchResponseData.PartitionData data;\n \n         RespEntry(String topic, int partition, long highWatermark, long lastStableOffset) {\n             this.part = new TopicPartition(topic, partition);\n-            this.data = new FetchResponse.PartitionData<>(\n-                Errors.NONE,\n-                highWatermark,\n-                lastStableOffset,\n-                0,\n-                null,\n-                null);\n+\n+            this.data = new FetchResponseData.PartitionData()\n+                        .setErrorCode(Errors.NONE.code())", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjkzNw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172937", "body": "Are some of these redundant? (eg `setAbortedTransactions(null)`)", "bodyText": "Are some of these redundant? (eg setAbortedTransactions(null))", "bodyHTML": "<p dir=\"auto\">Are some of these redundant? (eg <code>setAbortedTransactions(null)</code>)</p>", "author": "ijuma", "createdAt": "2021-02-27T18:37:41Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -2377,14 +2378,19 @@ private ListOffsetsResponse listOffsetsResponse(Map<TopicPartition, Long> partit\n                     builder.append(0L, (\"key-\" + i).getBytes(), (\"value-\" + i).getBytes());\n                 records = builder.build();\n             }\n-            tpResponses.put(partition, new FetchResponse.PartitionData<>(\n-                    Errors.NONE, highWatermark, FetchResponse.INVALID_LAST_STABLE_OFFSET,\n-                    logStartOffset, null, records));\n+            tpResponses.put(partition,\n+                    new FetchResponseData.PartitionData()\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setHighWatermark(highWatermark)\n+                            .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                            .setLogStartOffset(logStartOffset)\n+                            .setAbortedTransactions(null)\n+                            .setRecords(records));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3Mjk4NA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172984", "body": "Are some of these redundant? (eg setAbortedTransactions(null))", "bodyText": "Are some of these redundant? (eg setAbortedTransactions(null))", "bodyHTML": "<p dir=\"auto\">Are some of these redundant? (eg setAbortedTransactions(null))</p>", "author": "ijuma", "createdAt": "2021-02-27T18:38:01Z", "path": "clients/src/test/java/org/apache/kafka/clients/FetchSessionHandlerTest.java", "diffHunk": "@@ -150,22 +150,23 @@ private static void assertListEquals(List<TopicPartition> expected, List<TopicPa\n \n     private static final class RespEntry {\n         final TopicPartition part;\n-        final FetchResponse.PartitionData<MemoryRecords> data;\n+        final FetchResponseData.PartitionData data;\n \n         RespEntry(String topic, int partition, long highWatermark, long lastStableOffset) {\n             this.part = new TopicPartition(topic, partition);\n-            this.data = new FetchResponse.PartitionData<>(\n-                Errors.NONE,\n-                highWatermark,\n-                lastStableOffset,\n-                0,\n-                null,\n-                null);\n+\n+            this.data = new FetchResponseData.PartitionData()\n+                        .setErrorCode(Errors.NONE.code())\n+                        .setHighWatermark(highWatermark)\n+                        .setLastStableOffset(lastStableOffset)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(null)\n+                        .setRecords(null);", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MzE1Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584173156", "body": "Are some of these redundant? (eg `setAbortedTransactions(null)`). Other examples in the same file.", "bodyText": "Are some of these redundant? (eg setAbortedTransactions(null)). Other examples in the same file.", "bodyHTML": "<p dir=\"auto\">Are some of these redundant? (eg <code>setAbortedTransactions(null)</code>). Other examples in the same file.</p>", "author": "ijuma", "createdAt": "2021-02-27T18:39:09Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -1270,13 +1271,24 @@ public void testFetchPositionAfterException() {\n \n         assertEquals(1, fetcher.sendFetches());\n \n-        Map<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> partitions = new LinkedHashMap<>();\n-        partitions.put(tp1, new FetchResponse.PartitionData<>(Errors.NONE, 100,\n-            FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, null, records));\n-        partitions.put(tp0, new FetchResponse.PartitionData<>(Errors.OFFSET_OUT_OF_RANGE, 100,\n-            FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, null, MemoryRecords.EMPTY));\n-        client.prepareResponse(new FetchResponse<>(Errors.NONE, new LinkedHashMap<>(partitions),\n-            0, INVALID_SESSION_ID));\n+\n+        Map<TopicPartition, FetchResponseData.PartitionData> partitions = new LinkedHashMap<>();\n+        partitions.put(tp1, new FetchResponseData.PartitionData()\n+                .setErrorCode(Errors.NONE.code())\n+                .setHighWatermark(100)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(records));\n+        partitions.put(tp0, new FetchResponseData.PartitionData()\n+                .setErrorCode(Errors.OFFSET_OUT_OF_RANGE.code())\n+                .setHighWatermark(100)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(MemoryRecords.EMPTY));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjU2NQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584186565", "body": "We can remove some redundant set calls?", "bodyText": "We can remove some redundant set calls?", "bodyHTML": "<p dir=\"auto\">We can remove some redundant set calls?</p>", "author": "ijuma", "createdAt": "2021-02-27T20:24:50Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetchsession/FetchSessionBenchmark.java", "diffHunk": "@@ -70,24 +70,25 @@ public void setUp() {\n         handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n         FetchSessionHandler.Builder builder = handler.newBuilder();\n \n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> respMap = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> respMap = new LinkedHashMap<>();\n         for (int i = 0; i < partitionCount; i++) {\n             TopicPartition tp = new TopicPartition(\"foo\", i);\n             FetchRequest.PartitionData partitionData = new FetchRequest.PartitionData(0, 0, 200,\n                     Optional.empty());\n             fetches.put(tp, partitionData);\n             builder.add(tp, partitionData);\n-            respMap.put(tp, new FetchResponse.PartitionData<>(\n-                    Errors.NONE,\n-                    0L,\n-                    0L,\n-                    0,\n-                    null,\n-                    null));\n+            respMap.put(tp, new FetchResponseData.PartitionData()\n+                            .setPartitionIndex(tp.partition())\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setHighWatermark(0)\n+                            .setLastStableOffset(0)\n+                            .setLogStartOffset(0)\n+                            .setAbortedTransactions(null)\n+                            .setRecords(null));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMjQ0OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584222449", "bodyText": "updated", "author": "chia7712", "createdAt": "2021-02-28T03:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjU2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjYxOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584186619", "body": "We can remove some redundant setters?", "bodyText": "We can remove some redundant setters?", "bodyHTML": "<p dir=\"auto\">We can remove some redundant setters?</p>", "author": "ijuma", "createdAt": "2021-02-27T20:25:10Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetcher/ReplicaFetcherThreadBenchmark.java", "diffHunk": "@@ -174,8 +173,14 @@ public int sizeInBytes() {\n                     return null;\n                 }\n             };\n-            initialFetched.put(tp, new FetchResponse.PartitionData<>(Errors.NONE, 0, 0, 0,\n-                    new LinkedList<>(), fetched));\n+            initialFetched.put(tp, new FetchResponseData.PartitionData()\n+                    .setPartitionIndex(tp.partition())\n+                    .setErrorCode(Errors.NONE.code())\n+                    .setHighWatermark(0)\n+                    .setLastStableOffset(0)\n+                    .setLogStartOffset(0)", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMjE4Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584222186", "bodyText": "I will remove redundant setter setHighWatermark(0). Other values are different from default value in KRPC.", "author": "chia7712", "createdAt": "2021-02-28T02:57:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjY4Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584186687", "body": "We can remove some redundant setters?", "bodyText": "We can remove some redundant setters?", "bodyHTML": "<p dir=\"auto\">We can remove some redundant setters?</p>", "author": "ijuma", "createdAt": "2021-02-27T20:25:28Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/common/FetchResponseBenchmark.java", "diffHunk": "@@ -78,19 +78,25 @@ public void setup() {\n         for (int topicIdx = 0; topicIdx < topicCount; topicIdx++) {\n             String topic = UUID.randomUUID().toString();\n             for (int partitionId = 0; partitionId < partitionCount; partitionId++) {\n-                FetchResponse.PartitionData<MemoryRecords> partitionData = new FetchResponse.PartitionData<>(\n-                    Errors.NONE, 0, 0, 0, Optional.empty(), Collections.emptyList(), records);\n+                FetchResponseData.PartitionData partitionData = new FetchResponseData.PartitionData()\n+                                .setPartitionIndex(partitionId)\n+                                .setErrorCode(Errors.NONE.code())\n+                                .setHighWatermark(0)\n+                                .setLastStableOffset(0)\n+                                .setLogStartOffset(0)", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMjQwOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584222409", "bodyText": "updated", "author": "chia7712", "createdAt": "2021-02-28T03:00:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjY4Nw=="}], "type": "inlineReview"}, {"oid": "0e9e84739ea59f6ad2aaba99f5926bf469adf8a9", "url": "https://github.com/apache/kafka/commit/0e9e84739ea59f6ad2aaba99f5926bf469adf8a9", "message": "remove duplicate assignments; batch data; add more comments", "committedDate": "2021-02-28T04:09:03Z", "type": "commit"}, {"oid": "033b9338f148ed87c22206e08ede12f16d2ead35", "url": "https://github.com/apache/kafka/commit/033b9338f148ed87c22206e08ede12f16d2ead35", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-01T10:41:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxMjU1Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584812552", "body": "Aborted transactions is empty by default.", "bodyText": "Aborted transactions is empty by default.", "bodyHTML": "<p dir=\"auto\">Aborted transactions is empty by default.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:36:47Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -791,15 +791,18 @@ public void produceRequestGetErrorResponseTest() {\n \n     @Test\n     public void fetchResponseVersionTest() {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n \n         MemoryRecords records = MemoryRecords.readableRecords(ByteBuffer.allocate(10));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(\n-                Errors.NONE, 1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET,\n-                0L, Optional.empty(), Collections.emptyList(), records));\n-\n-        FetchResponse<MemoryRecords> v0Response = new FetchResponse<>(Errors.NONE, responseData, 0, INVALID_SESSION_ID);\n-        FetchResponse<MemoryRecords> v1Response = new FetchResponse<>(Errors.NONE, responseData, 10, INVALID_SESSION_ID);\n+        responseData.put(new TopicPartition(\"test\", 0),\n+                new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxNTI4OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584815289", "body": "Do we need to set the partition id here? There are a few other cases in this file that are similar.", "bodyText": "Do we need to set the partition id here? There are a few other cases in this file that are similar.", "bodyHTML": "<p dir=\"auto\">Do we need to set the partition id here? There are a few other cases in this file that are similar.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:39:13Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -808,22 +811,32 @@ public void fetchResponseVersionTest() {\n \n     @Test\n     public void testFetchResponseV4() {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.readableRecords(ByteBuffer.allocate(10));\n \n-        List<FetchResponse.AbortedTransaction> abortedTransactions = asList(\n-                new FetchResponse.AbortedTransaction(10, 100),\n-                new FetchResponse.AbortedTransaction(15, 50)\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = asList(\n+                new FetchResponseData.AbortedTransaction().setProducerId(10).setFirstOffset(100),\n+                new FetchResponseData.AbortedTransaction().setProducerId(15).setFirstOffset(50)\n         );\n-        responseData.put(new TopicPartition(\"bar\", 0), new FetchResponse.PartitionData<>(Errors.NONE, 100000,\n-                FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, Optional.empty(), abortedTransactions, records));\n-        responseData.put(new TopicPartition(\"bar\", 1), new FetchResponse.PartitionData<>(Errors.NONE, 900000,\n-                5, FetchResponse.INVALID_LOG_START_OFFSET, Optional.empty(), null, records));\n-        responseData.put(new TopicPartition(\"foo\", 0), new FetchResponse.PartitionData<>(Errors.NONE, 70000,\n-                6, FetchResponse.INVALID_LOG_START_OFFSET, Optional.empty(), emptyList(), records));\n-\n-        FetchResponse<MemoryRecords> response = new FetchResponse<>(Errors.NONE, responseData, 10, INVALID_SESSION_ID);\n-        FetchResponse<MemoryRecords> deserialized = FetchResponse.parse(response.serialize((short) 4), (short) 4);\n+        responseData.put(new TopicPartition(\"bar\", 0),\n+                new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setAbortedTransactions(abortedTransactions)\n+                        .setRecords(records));\n+        responseData.put(new TopicPartition(\"bar\", 1),\n+                new FetchResponseData.PartitionData()", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxNzQ5Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584817492", "body": "No need to set aborted transactions.", "bodyText": "No need to set aborted transactions.", "bodyHTML": "<p dir=\"auto\">No need to set aborted transactions.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:40:40Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1159,47 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxODk0Mw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584818943", "body": "Aborted transactions is empty by default.", "bodyText": "Aborted transactions is empty by default.", "bodyHTML": "<p dir=\"auto\">Aborted transactions is empty by default.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:41:34Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1159,47 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(abortedTransactions));\n+        return FetchResponse.of(Errors.NONE, 25, sessionId, responseData);\n+    }\n+\n+    private FetchResponse createFetchResponse(boolean includeAborted) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgyNjUxOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584826519", "body": "Redundant.", "bodyText": "Redundant.", "bodyHTML": "<p dir=\"auto\">Redundant.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:46:18Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/common/FetchResponseBenchmark.java", "diffHunk": "@@ -78,19 +78,23 @@ public void setup() {\n         for (int topicIdx = 0; topicIdx < topicCount; topicIdx++) {\n             String topic = UUID.randomUUID().toString();\n             for (int partitionId = 0; partitionId < partitionCount; partitionId++) {\n-                FetchResponse.PartitionData<MemoryRecords> partitionData = new FetchResponse.PartitionData<>(\n-                    Errors.NONE, 0, 0, 0, Optional.empty(), Collections.emptyList(), records);\n+                FetchResponseData.PartitionData partitionData = new FetchResponseData.PartitionData()\n+                                .setPartitionIndex(partitionId)\n+                                .setLastStableOffset(0)\n+                                .setLogStartOffset(0)\n+                                .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgyNjg3Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584826872", "body": "Redundant.", "bodyText": "Redundant.", "bodyHTML": "<p dir=\"auto\">Redundant.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:46:31Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetcher/ReplicaFetcherThreadBenchmark.java", "diffHunk": "@@ -174,8 +173,12 @@ public int sizeInBytes() {\n                     return null;\n                 }\n             };\n-            initialFetched.put(tp, new FetchResponse.PartitionData<>(Errors.NONE, 0, 0, 0,\n-                    new LinkedList<>(), fetched));\n+            initialFetched.put(tp, new FetchResponseData.PartitionData()\n+                    .setPartitionIndex(tp.partition())\n+                    .setLastStableOffset(0)\n+                    .setLogStartOffset(0)\n+                    .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgzNjEwOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584836108", "body": "There is one place in this PR that we check for null when computing the records size, maybe we can use this utility function there.", "bodyText": "There is one place in this PR that we check for null when computing the records size, maybe we can use this utility function there.", "bodyHTML": "<p dir=\"auto\">There is one place in this PR that we check for null when computing the records size, maybe we can use this utility function there.</p>", "author": "ijuma", "createdAt": "2021-03-01T15:57:20Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,92 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. KRPC converts the byte array to MemoryRecords so this method\n+     * never fail if the data is from KRPC.\n+     *\n+     * @param partition partition data\n+     * @return Records or empty record if the records in PartitionData is null.\n+     */\n+    public static Records records(FetchResponseData.PartitionData partition) {", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTIzNTU4Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585235586", "bodyText": "good point. will copy that", "author": "chia7712", "createdAt": "2021-03-02T04:15:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgzNjEwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTIxNA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584841214", "body": "Suggestion:\r\n\r\n```text\r\nReturns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\r\n\r\nIf this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire).\r\n```\r\n```", "bodyText": "Suggestion:\nReturns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\n\nIf this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire).", "bodyHTML": "<p dir=\"auto\">Suggestion:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\n\nIf this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire).\"><pre lang=\"text\"><code>Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\n\nIf this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire).\n</code></pre></div>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"\"><pre><code></code></pre></div>", "author": "ijuma", "createdAt": "2021-03-01T16:03:25Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,92 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. KRPC converts the byte array to MemoryRecords so this method\n+     * never fail if the data is from KRPC.", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTIyNjY2Mw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585226663", "bodyText": "good one. will copy that", "author": "chia7712", "createdAt": "2021-03-02T03:46:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTIxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTYxNQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584841615", "body": "Instead of casting blindly, can we include a reasonable error message if the cast fails?", "bodyText": "Instead of casting blindly, can we include a reasonable error message if the cast fails?", "bodyHTML": "<p dir=\"auto\">Instead of casting blindly, can we include a reasonable error message if the cast fails?</p>", "author": "ijuma", "createdAt": "2021-03-01T16:03:57Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,92 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. KRPC converts the byte array to MemoryRecords so this method\n+     * never fail if the data is from KRPC.\n+     *\n+     * @param partition partition data\n+     * @return Records or empty record if the records in PartitionData is null.\n+     */\n+    public static Records records(FetchResponseData.PartitionData partition) {\n+        return partition.records() == null ? MemoryRecords.EMPTY : (Records) partition.records();", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTIyOTg2MA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585229860", "bodyText": "will copy that", "author": "chia7712", "createdAt": "2021-03-02T03:56:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTYxNQ=="}], "type": "inlineReview"}, {"oid": "8263bda330b3736447900a86728e779699eaeaf8", "url": "https://github.com/apache/kafka/commit/8263bda330b3736447900a86728e779699eaeaf8", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-02T03:14:56Z", "type": "commit"}, {"oid": "529d81df199555611e7721753ba2ea29cbef3880", "url": "https://github.com/apache/kafka/commit/529d81df199555611e7721753ba2ea29cbef3880", "message": "remove redundant code; add more comment for casting; use helper method to get records size", "committedDate": "2021-03-02T04:17:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NjExMQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585656111", "body": "No `else` needed since we used `return` for both other cases. For the exception, I think we can just throw `ClassCastException` since `IllegalStateException` doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more `Records` subtypes. For example:\r\n\r\n```java\r\n\"The record type is \" + partition.records().getClass().getSimpleName() + \", which is not a subtype of \" +\r\nRecords.class.getSimpleName() + \". This method is only safe to call if the `FetchResponse` was\r\ndeserialized from bytes.\"", "bodyText": "No else needed since we used return for both other cases. For the exception, I think we can just throw ClassCastException since IllegalStateException doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more Records subtypes. For example:\n\"The record type is \" + partition.records().getClass().getSimpleName() + \", which is not a subtype of \" +\nRecords.class.getSimpleName() + \". This method is only safe to call if the `FetchResponse` was\ndeserialized from bytes.\"", "bodyHTML": "<p dir=\"auto\">No <code>else</code> needed since we used <code>return</code> for both other cases. For the exception, I think we can just throw <code>ClassCastException</code> since <code>IllegalStateException</code> doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more <code>Records</code> subtypes. For example:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"&quot;The record type is &quot; + partition.records().getClass().getSimpleName() + &quot;, which is not a subtype of &quot; +\nRecords.class.getSimpleName() + &quot;. This method is only safe to call if the `FetchResponse` was\ndeserialized from bytes.&quot;\"><pre><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>The record type is <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> partition<span class=\"pl-k\">.</span>records()<span class=\"pl-k\">.</span>getClass()<span class=\"pl-k\">.</span>getSimpleName() <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>, which is not a subtype of <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span>\n<span class=\"pl-smi\">Records</span><span class=\"pl-k\">.</span>class<span class=\"pl-k\">.</span>getSimpleName() <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>. This method is only safe to call if the `FetchResponse` was</span>\n<span class=\"pl-s\">deserialized from bytes.<span class=\"pl-pds\">\"</span></span></pre></div>", "author": "ijuma", "createdAt": "2021-03-02T15:21:38Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,98 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\n+     *\n+     * If this response was deserialized after a fetch, this method should never fail. An example where this would\n+     * fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and\n+     * sent on the wire).\n+     *\n+     * @param partition partition data\n+     * @return Records or empty record if the records in PartitionData is null.\n+     */\n+    public static Records records(FetchResponseData.PartitionData partition) {\n+        if (partition.records() == null) return MemoryRecords.EMPTY;\n+        else if (partition.records() instanceof Records) return (Records) partition.records();\n+        else throw new IllegalStateException(\"the record type is \" + partition.records().getClass().getSimpleName() +", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY2MDk2Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585660962", "bodyText": "One more thing, let's call this recordsOrFail to make it clear that the operation is not necessarily safe.", "author": "ijuma", "createdAt": "2021-03-02T15:26:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NjExMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY3NDQyMA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585674420", "bodyText": "Will address those nice comments", "author": "chia7712", "createdAt": "2021-03-02T15:41:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NjExMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1Njc5MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585656791", "body": "Set partition id.", "bodyText": "Set partition id.", "bodyHTML": "<p dir=\"auto\">Set partition id.</p>", "author": "ijuma", "createdAt": "2021-03-02T15:22:21Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -791,15 +791,17 @@ public void produceRequestGetErrorResponseTest() {\n \n     @Test\n     public void fetchResponseVersionTest() {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n \n         MemoryRecords records = MemoryRecords.readableRecords(ByteBuffer.allocate(10));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(\n-                Errors.NONE, 1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET,\n-                0L, Optional.empty(), Collections.emptyList(), records));\n-\n-        FetchResponse<MemoryRecords> v0Response = new FetchResponse<>(Errors.NONE, responseData, 0, INVALID_SESSION_ID);\n-        FetchResponse<MemoryRecords> v1Response = new FetchResponse<>(Errors.NONE, responseData, 10, INVALID_SESSION_ID);\n+        responseData.put(new TopicPartition(\"test\", 0),\n+                new FetchResponseData.PartitionData()", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NzExOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657119", "body": "Set partition id.", "bodyText": "Set partition id.", "bodyHTML": "<p dir=\"auto\">Set partition id.</p>", "author": "ijuma", "createdAt": "2021-03-02T15:22:43Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NzI3OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657279", "body": "Set partition id.", "bodyText": "Set partition id.", "bodyHTML": "<p dir=\"auto\">Set partition id.</p>", "author": "ijuma", "createdAt": "2021-03-02T15:22:52Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NzU1NQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657555", "body": "Set partition id.", "bodyText": "Set partition id.", "bodyHTML": "<p dir=\"auto\">Set partition id.</p>", "author": "ijuma", "createdAt": "2021-03-02T15:23:08Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(abortedTransactions));\n+        return FetchResponse.of(Errors.NONE, 25, sessionId, responseData);\n+    }\n+\n+    private FetchResponse createFetchResponse(boolean includeAborted) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1Nzc2OA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657768", "body": "Set partition id.", "bodyText": "Set partition id.", "bodyHTML": "<p dir=\"auto\">Set partition id.</p>", "author": "ijuma", "createdAt": "2021-03-02T15:23:20Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(abortedTransactions));\n+        return FetchResponse.of(Errors.NONE, 25, sessionId, responseData);\n+    }\n+\n+    private FetchResponse createFetchResponse(boolean includeAborted) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n \n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-                1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.emptyList();\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.emptyList();\n         if (includeAborted) {\n             abortedTransactions = Collections.singletonList(\n-                    new FetchResponse.AbortedTransaction(234L, 999L));\n+                    new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n         }\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-                1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9f8e97b9822c12c0e56e4bc37a07a48f27993769", "url": "https://github.com/apache/kafka/commit/9f8e97b9822c12c0e56e4bc37a07a48f27993769", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-02T15:32:44Z", "type": "commit"}, {"oid": "4fa69c58ffe3e9a40dbb3556da92ed8a30f23936", "url": "https://github.com/apache/kafka/commit/4fa69c58ffe3e9a40dbb3556da92ed8a30f23936", "message": "fix build error", "committedDate": "2021-03-02T15:37:19Z", "type": "commit"}, {"oid": "55b35ab5764d8129e23f386229eb350603b7b0aa", "url": "https://github.com/apache/kafka/commit/55b35ab5764d8129e23f386229eb350603b7b0aa", "message": "set partition index; add recordsSize;", "committedDate": "2021-03-02T16:22:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzE5MTAwOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r587191008", "body": "Is this an additional copy compared to previous behavior?", "bodyText": "Is this an additional copy compared to previous behavior?", "bodyHTML": "<p dir=\"auto\">Is this an additional copy compared to previous behavior?</p>", "author": "ijuma", "createdAt": "2021-03-04T06:33:33Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,105 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));", "originalCommit": "55b35ab5764d8129e23f386229eb350603b7b0aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzIxNjQxOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r587216418", "bodyText": "nice question. will revert to previous code :)", "author": "chia7712", "createdAt": "2021-03-04T07:32:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzE5MTAwOA=="}], "type": "inlineReview"}, {"oid": "821c307389bf613b15c92bd868cdeeac557b39d4", "url": "https://github.com/apache/kafka/commit/821c307389bf613b15c92bd868cdeeac557b39d4", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-04T07:29:06Z", "type": "commit"}, {"oid": "ae25551171fd4e3b889ca94d494e3207545320e5", "url": "https://github.com/apache/kafka/commit/ae25551171fd4e3b889ca94d494e3207545320e5", "message": "revert sizeOf", "committedDate": "2021-03-04T07:33:05Z", "type": "commit"}]}