{"pr_number": 8568, "pr_title": "KAFKA-9176: Retry on getting local stores from KafkaStreams", "pr_author": "guozhangwang", "pr_createdAt": "2020-04-28T04:58:55Z", "pr_url": "https://github.com/apache/kafka/pull/8568", "timeline": [{"oid": "f936848a86992d779fa37703c4a4a7b83fc30727", "url": "https://github.com/apache/kafka/commit/f936848a86992d779fa37703c4a4a7b83fc30727", "message": "wrap around getting stores", "committedDate": "2020-04-28T04:49:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzMzNQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327335", "body": "This is fix 2).", "bodyText": "This is fix 2).", "bodyHTML": "<p dir=\"auto\">This is fix 2).</p>", "author": "guozhangwang", "createdAt": "2020-04-28T04:59:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -210,16 +210,21 @@ public static void cleanStateAfterTest(final EmbeddedKafkaCluster cluster, final\n                                                             final Properties producerConfig,\n                                                             final Headers headers,\n                                                             final Time time,\n-                                                            final boolean enableTransactions)\n-        throws ExecutionException, InterruptedException {\n-        for (final KeyValue<K, V> record : records) {\n-            produceKeyValuesSynchronouslyWithTimestamp(topic,\n-                Collections.singleton(record),\n-                producerConfig,\n-                headers,\n-                time.milliseconds(),\n-                enableTransactions);\n-            time.sleep(1L);\n+                                                            final boolean enableTransactions) {\n+\n+        try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzM4Ng==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327386", "body": "Those functions are not used anywhere, ditto below.", "bodyText": "Those functions are not used anywhere, ditto below.", "bodyHTML": "<p dir=\"auto\">Those functions are not used anywhere, ditto below.</p>", "author": "guozhangwang", "createdAt": "2020-04-28T04:59:36Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -599,13 +595,6 @@ public static void waitForCompletion(final KafkaStreams streams,\n         return waitUntilFinalKeyValueRecordsReceived(consumerConfig, topic, expectedRecords, waitTime, false);\n     }\n \n-    public static <K, V> List<KeyValueTimestamp<K, V>> waitUntilFinalKeyValueTimestampRecordsReceived(final Properties consumerConfig,", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNzEyNg==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416927126", "bodyText": "thanks for the cleanup", "author": "vvcephei", "createdAt": "2020-04-28T21:14:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzM4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzY3MQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327671", "body": "This is a minor fix, that we should retry this condition.", "bodyText": "This is a minor fix, that we should retry this condition.", "bodyHTML": "<p dir=\"auto\">This is a minor fix, that we should retry this condition.</p>", "author": "guozhangwang", "createdAt": "2020-04-28T05:00:29Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/OptimizedKTableIntegrationTest.java", "diffHunk": "@@ -163,8 +159,10 @@ public void shouldApplyUpdatesToStandbyStore() throws Exception {\n         // Assert that all messages in the second batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch2NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n \n-        // Assert that the current value in store reflects all messages being processed\n-        assertThat(newActiveStore.get(key), is(equalTo(totalNumMessages - 1)));\n+        TestUtils.retryOnExceptionWithTimeout(100, 60 * 1000, () -> {", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzg4MQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327881", "body": "This is a fix to the test itself: with caching the records are delayed sending to the sink topics.", "bodyText": "This is a fix to the test itself: with caching the records are delayed sending to the sink topics.", "bodyHTML": "<p dir=\"auto\">This is a fix to the test itself: with caching the records are delayed sending to the sink topics.</p>", "author": "guozhangwang", "createdAt": "2020-04-28T05:01:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/OptimizedKTableIntegrationTest.java", "diffHunk": "@@ -227,10 +225,11 @@ private Properties streamsConfiguration() {\n         config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         config.put(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, 1);\n+        config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        config.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgwOTQ2OQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416809469", "body": "`OptimizedKTableIntegrationTest.shouldApplyUpdatesToStandbyStore` still failed on [one of the builds](https://builds.apache.org/job/kafka-pr-jdk14-scala2.13/149/testReport/junit/org.apache.kafka.streams.integration/OptimizedKTableIntegrationTest/shouldApplyUpdatesToStandbyStore/) at this line :/\r\nBut, at least we got farther into the test before it failed so I'd say this is still an improvement \ud83d\ude04 ", "bodyText": "OptimizedKTableIntegrationTest.shouldApplyUpdatesToStandbyStore still failed on one of the builds at this line :/\nBut, at least we got farther into the test before it failed so I'd say this is still an improvement \ud83d\ude04", "bodyHTML": "<p dir=\"auto\"><code>OptimizedKTableIntegrationTest.shouldApplyUpdatesToStandbyStore</code> still failed on <a href=\"https://builds.apache.org/job/kafka-pr-jdk14-scala2.13/149/testReport/junit/org.apache.kafka.streams.integration/OptimizedKTableIntegrationTest/shouldApplyUpdatesToStandbyStore/\" rel=\"nofollow\">one of the builds</a> at this line :/<br>\nBut, at least we got farther into the test before it failed so I'd say this is still an improvement <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>", "author": "ableegoldman", "createdAt": "2020-04-28T17:52:25Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/OptimizedKTableIntegrationTest.java", "diffHunk": "@@ -163,8 +159,10 @@ public void shouldApplyUpdatesToStandbyStore() throws Exception {\n         // Assert that all messages in the second batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch2NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgxNDE2Mw==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416814163", "body": "Why do we have to check for null now?", "bodyText": "Why do we have to check for null now?", "bodyHTML": "<p dir=\"auto\">Why do we have to check for null now?</p>", "author": "ableegoldman", "createdAt": "2020-04-28T17:59:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java", "diffHunk": "@@ -158,8 +158,9 @@ public void shouldKStreamGlobalKTableLeftJoin() throws Exception {\n \n         produceGlobalTableValues();\n \n-        final ReadOnlyKeyValueStore<Long, String> replicatedStore =\n-            kafkaStreams.store(StoreQueryParameters.fromNameAndType(globalStore, QueryableStoreTypes.keyValueStore()));\n+        final ReadOnlyKeyValueStore<Long, String> replicatedStore = IntegrationTestUtils\n+            .getStore(globalStore, kafkaStreams, QueryableStoreTypes.keyValueStore());\n+        assertNotNull(replicatedStore);", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkxMDcyNQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416910725", "bodyText": "Since previously we would just throw the exception with the un-wrapped call, here asserting it is not null is equal to make sure that the store is indeed returned.", "author": "guozhangwang", "createdAt": "2020-04-28T20:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgxNDE2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyMTk3MQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416921971", "body": "```suggestion\r\n            .getStore(300_000L, storeName, streams, QueryableStoreTypes.keyValueStore());\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        .getStore(300000L, storeName, streams, QueryableStoreTypes.keyValueStore());\n          \n          \n            \n                        .getStore(300_000L, storeName, streams, QueryableStoreTypes.keyValueStore());", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            .getStore(<span class=\"pl-c1 x x-first x-last\">300000L</span>, storeName, streams, <span class=\"pl-smi\">QueryableStoreTypes</span><span class=\"pl-k\">.</span>keyValueStore());</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            .getStore(<span class=\"pl-c1 x x-first x-last\">300_000L</span>, storeName, streams, <span class=\"pl-smi\">QueryableStoreTypes</span><span class=\"pl-k\">.</span>keyValueStore());</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "vvcephei", "createdAt": "2020-04-28T21:05:30Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java", "diffHunk": "@@ -810,21 +808,9 @@ private void writeInputData(final List<KeyValue<Long, Long>> records) throws Exc\n     }\n \n     private void verifyStateStore(final KafkaStreams streams,\n-                                  final Set<KeyValue<Long, Long>> expectedStoreContent) {\n-        ReadOnlyKeyValueStore<Long, Long> store = null;\n-\n-        final long maxWaitingTime = System.currentTimeMillis() + 300000L;\n-        while (System.currentTimeMillis() < maxWaitingTime) {\n-            try {\n-                store = streams.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n-                break;\n-            } catch (final InvalidStateStoreException okJustRetry) {\n-                try {\n-                    Thread.sleep(5000L);\n-                } catch (final Exception ignore) { }\n-            }\n-        }\n-\n+                                  final Set<KeyValue<Long, Long>> expectedStoreContent) throws InterruptedException {\n+        final ReadOnlyKeyValueStore<Long, Long> store = IntegrationTestUtils\n+            .getStore(300000L, storeName, streams, QueryableStoreTypes.keyValueStore());", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0Mjk5Mg==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416942992", "bodyText": "Ack.", "author": "guozhangwang", "createdAt": "2020-04-28T21:45:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyMTk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNTgxMw==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416925813", "body": "not a huge deal, but technically, these should have brackets.", "bodyText": "not a huge deal, but technically, these should have brackets.", "bodyHTML": "<p dir=\"auto\">not a huge deal, but technically, these should have brackets.</p>", "author": "vvcephei", "createdAt": "2020-04-28T21:12:18Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreUpgradeIntegrationTest.java", "diffHunk": "@@ -337,8 +336,11 @@ public void shouldProxyKeyValueStoreToTimestampedKeyValueStoreUsingPapi() throws\n         TestUtils.waitForCondition(\n             () -> {\n                 try {\n-                    final ReadOnlyKeyValueStore<K, V> store =\n-                        kafkaStreams.store(StoreQueryParameters.fromNameAndType(STORE_NAME, QueryableStoreTypes.keyValueStore()));\n+                    final ReadOnlyKeyValueStore<K, V> store = IntegrationTestUtils.getStore(STORE_NAME, kafkaStreams, QueryableStoreTypes.keyValueStore());\n+\n+                    if (store == null)\n+                        return false;", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0MzkwNw==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416943907", "bodyText": "ack.", "author": "guozhangwang", "createdAt": "2020-04-28T21:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNTgxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNjk4NQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416926985", "body": "I guess the flush at the end makes it synchronous anyway?", "bodyText": "I guess the flush at the end makes it synchronous anyway?", "bodyHTML": "<p dir=\"auto\">I guess the flush at the end makes it synchronous anyway?</p>", "author": "vvcephei", "createdAt": "2020-04-28T21:14:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -269,24 +271,20 @@ public static void cleanStateAfterTest(final EmbeddedKafkaCluster cluster, final\n      * @param <K>                 Key type of the data records\n      * @param <V>                 Value type of the data records\n      */\n-    @SuppressWarnings(\"WeakerAccess\")\n     public static <K, V> void produceKeyValuesSynchronouslyWithTimestamp(final String topic,\n                                                                          final Collection<KeyValue<K, V>> records,\n                                                                          final Properties producerConfig,\n                                                                          final Headers headers,\n                                                                          final Long timestamp,\n-                                                                         final boolean enableTransactions)\n-            throws ExecutionException, InterruptedException {\n+                                                                         final boolean enableTransactions) {\n \n         try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n             if (enableTransactions) {\n                 producer.initTransactions();\n                 producer.beginTransaction();\n             }\n             for (final KeyValue<K, V> record : records) {\n-                final Future<RecordMetadata> f = producer.send(\n-                    new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));\n-                f.get();\n+                producer.send(new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0NDM5Mg==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416944392", "bodyText": "Previously we wait after sending each record, here we only wait once after sending all records, so it is more efficient.", "author": "guozhangwang", "createdAt": "2020-04-28T21:48:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNjk4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0NzgwMA==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416947800", "bodyText": "Thanks. That's what I was asking for confirmation on. I realize now the structure of my sentence was ambiguous.\nI agree that the method contract is that the batch should be synchronously produced, not that each record should be synchronously produced, so this change looks good to me.", "author": "vvcephei", "createdAt": "2020-04-28T21:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNjk4NQ=="}], "type": "inlineReview"}, {"oid": "4bb8463e529e5e9c631c7dd05b3427d6320e98a9", "url": "https://github.com/apache/kafka/commit/4bb8463e529e5e9c631c7dd05b3427d6320e98a9", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9176-get-store-with-exception", "committedDate": "2020-04-28T21:44:42Z", "type": "commit"}, {"oid": "57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf", "url": "https://github.com/apache/kafka/commit/57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf", "message": "github comments", "committedDate": "2020-04-28T22:02:40Z", "type": "commit"}]}