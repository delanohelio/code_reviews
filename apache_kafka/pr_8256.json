{"pr_number": 8256, "pr_title": "KAFKA-9675: Fix bug that prevents RocksDB metrics to be updated", "pr_createdAt": "2020-03-09T13:18:42Z", "pr_url": "https://github.com/apache/kafka/pull/8256", "merge_commit": "0c256e16ab33b58c8306502401e2c992018a1781", "timeline": [{"oid": "a652b378d51c3a83b71758d191d439457123b6ba", "url": "https://github.com/apache/kafka/commit/a652b378d51c3a83b71758d191d439457123b6ba", "message": "KAFKA-9675: Fix bug that prevents RocksDB metrics to be updated", "committedDate": "2020-03-09T12:22:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTY4NDM4MQ==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r389684381", "body": "This is the fix. For an explanation read the commit message.", "bodyText": "This is the fix. For an explanation read the commit message.", "bodyHTML": "<p dir=\"auto\">This is the fix. For an explanation read the commit message.</p>", "author": "cadonna", "createdAt": "2020-03-09T13:46:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java", "diffHunk": "@@ -188,11 +188,12 @@ void openDB(final ProcessorContext context) {\n             throw new ProcessorStateException(fatal);\n         }\n \n+        // Setup metrics before the database is opened, otherwise the metrics are not updated\n+        // with the measurements from Rocks DB\n+        maybeSetUpMetricsRecorder(context, configs);\n+\n         openRocksDB(dbOptions, columnFamilyOptions);\n         open = true;\n-\n-        // Do this last because the prior operations could throw exceptions.\n-        maybeSetUpMetricsRecorder(context, configs);", "originalCommit": "a652b378d51c3a83b71758d191d439457123b6ba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTY4OTkyNw==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r389689927", "body": "This verifies that the metrics are updated when the measurements in the statistics object change. Unfortunately, the tests the use this verification run more than a minute, because the thread that triggers the recordings of the RocksDB metrics takes some time to record its first value. ", "bodyText": "This verifies that the metrics are updated when the measurements in the statistics object change. Unfortunately, the tests the use this verification run more than a minute, because the thread that triggers the recordings of the RocksDB metrics takes some time to record its first value.", "bodyHTML": "<p dir=\"auto\">This verifies that the metrics are updated when the measurements in the statistics object change. Unfortunately, the tests the use this verification run more than a minute, because the thread that triggers the recordings of the RocksDB metrics takes some time to record its first value.</p>", "author": "cadonna", "createdAt": "2020-03-09T13:51:37Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -283,13 +333,38 @@ private void verifyRocksDBMetrics(final KafkaStreams kafkaStreams, final String\n         checkMetricByName(listMetricStore, NUMBER_OF_FILE_ERRORS, 1);\n     }\n \n-    private void checkMetricByName(final List<Metric> listMetric, final String metricName, final int numMetric) {\n+    private void checkMetricByName(final List<Metric> listMetric,\n+                                   final String metricName,\n+                                   final int numMetric) {\n         final List<Metric> metrics = listMetric.stream()\n             .filter(m -> m.metricName().name().equals(metricName))\n             .collect(Collectors.toList());\n-        Assert.assertEquals(\"Size of metrics of type:'\" + metricName + \"' must be equal to \" + numMetric + \" but it's equal to \" + metrics.size(), numMetric, metrics.size());\n-        for (final Metric m : metrics) {\n-            Assert.assertNotNull(\"Metric:'\" + m.metricName() + \"' must be not null\", m.metricValue());\n+        assertThat(\n+            \"Size of metrics of type:'\" + metricName + \"' must be equal to \" + numMetric + \" but it's equal to \" + metrics.size(),\n+            metrics.size(),\n+            is(numMetric)\n+        );\n+        for (final Metric metric : metrics) {\n+            assertThat(\"Metric:'\" + metric.metricName() + \"' must be not null\", metric.metricValue(), is(notNullValue()));\n         }\n     }\n-}\n+\n+    private void verifyThatBytesWrittenTotalIncreases(final KafkaStreams kafkaStreams,\n+                                                      final String metricsScope) throws InterruptedException {\n+        final List<Metric> metric = getRocksDBMetrics(kafkaStreams, metricsScope).stream()\n+            .filter(m -> BYTES_WRITTEN_TOTAL.equals(m.metricName().name()))\n+            .collect(Collectors.toList());\n+        TestUtils.waitForCondition(\n+            () -> (double) metric.get(0).metricValue() > 0,\n+            TIMEOUT,\n+            () -> \"RocksDB metric bytes.written.total did not increase in \" + TIMEOUT + \" ms\"\n+        );\n+    }", "originalCommit": "a652b378d51c3a83b71758d191d439457123b6ba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTY5MDUyMQ==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r389690521", "body": "This is one of the tests that verifies the fix. See my comment in `verifyThatBytesWrittenTotalIncreases()`.", "bodyText": "This is one of the tests that verifies the fix. See my comment in verifyThatBytesWrittenTotalIncreases().", "bodyHTML": "<p dir=\"auto\">This is one of the tests that verifies the fix. See my comment in <code>verifyThatBytesWrittenTotalIncreases()</code>.</p>", "author": "cadonna", "createdAt": "2020-03-09T13:52:12Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n+    }\n+\n+    @Test\n+    public void shouldVerifyThatMetricsGetMeasurementsFromRocksDBForNonSegmentedStateStore() throws Exception {\n+        final Properties streamsConfiguration = streamsConfig();\n+        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n+        final StreamsBuilder builder = builderForNonSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            IntegerDeserializer.class,\n+            StringDeserializer.class,\n+            this::verifyThatBytesWrittenTotalIncreases,\n+            metricsScope\n         );\n+    }", "originalCommit": "a652b378d51c3a83b71758d191d439457123b6ba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e145830422a24c6802bb1d7cef9e80008025c182", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex fd352b7bfb..34cc428bb9 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -183,7 +187,7 @@ public class RocksDBMetricsIntegrationTest {\n         final StreamsBuilder builder = builderForNonSegmentedStateStore();\n         final String metricsScope = \"rocksdb-state-id\";\n \n-        cleanUpStateRunAndVerify(\n+        cleanUpStateRunVerifyAndClose(\n             builder,\n             streamsConfiguration,\n             IntegerDeserializer.class,\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r390645941", "body": "Do I read this right, that we're doing the exact same thing twice?", "bodyText": "Do I read this right, that we're doing the exact same thing twice?", "bodyHTML": "<p dir=\"auto\">Do I read this right, that we're doing the exact same thing twice?</p>", "author": "vvcephei", "createdAt": "2020-03-10T22:22:32Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java", "diffHunk": "@@ -142,21 +155,58 @@ public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailur\n         final Properties streamsConfiguration = streamsConfig();\n         IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n         final StreamsBuilder builder = builderForSegmentedStateStore();\n+        final String metricsScope = \"rocksdb-window-state-id\";\n+\n+        cleanUpStateRunAndVerify(\n+            builder,\n+            streamsConfiguration,\n+            LongDeserializer.class,\n+            LongDeserializer.class,\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );\n \n         cleanUpStateRunAndVerify(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n             LongDeserializer.class,\n-            \"rocksdb-window-state-id\"\n+            this::verifyThatRocksDBMetricsAreExposed,\n+            metricsScope\n+        );", "originalCommit": "a652b378d51c3a83b71758d191d439457123b6ba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgxOTAyOA==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r390819028", "bodyText": "As the test name says shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailureWithEmptyStateDir() this test verifies that the metrics are still there after a failure and an empty state dir (see https://issues.apache.org/jira/browse/KAFKA-9355).\nI basically simulate a failure by closing the app, wiping out the state, re-starting the app, verifying the exposure of the metrics, and closing the app. That results in doing twice the same thing.", "author": "cadonna", "createdAt": "2020-03-11T08:48:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE2NjE4OQ==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r391166189", "bodyText": "Oh, I see. Definitely wasn't obvious by reading the test.", "author": "vvcephei", "createdAt": "2020-03-11T18:07:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ5OTkxOQ==", "url": "https://github.com/apache/kafka/pull/8256#discussion_r391499919", "bodyText": "I tried to make the tests clearer.", "author": "cadonna", "createdAt": "2020-03-12T09:39:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY0NTk0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "e145830422a24c6802bb1d7cef9e80008025c182", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex fd352b7bfb..34cc428bb9 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -166,7 +168,9 @@ public class RocksDBMetricsIntegrationTest {\n             metricsScope\n         );\n \n-        cleanUpStateRunAndVerify(\n+        // simulated failure\n+\n+        cleanUpStateRunVerifyAndClose(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "0c256e16ab33b58c8306502401e2c992018a1781", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex fd352b7bfb..34cc428bb9 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -166,7 +168,9 @@ public class RocksDBMetricsIntegrationTest {\n             metricsScope\n         );\n \n-        cleanUpStateRunAndVerify(\n+        // simulated failure\n+\n+        cleanUpStateRunVerifyAndClose(\n             builder,\n             streamsConfiguration,\n             LongDeserializer.class,\n", "next_change": {"commit": "fcf45e1fac88238b1d3dbcfa1f324674939706f3", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex 34cc428bb9..e9ac2f443c 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -145,72 +143,7 @@ public class RocksDBMetricsIntegrationTest {\n         cleanUpStateRunVerifyAndClose(\n             builder,\n             streamsConfiguration,\n-            IntegerDeserializer.class,\n-            StringDeserializer.class,\n-            this::verifyThatRocksDBMetricsAreExposed,\n-            metricsScope\n-        );\n-    }\n-\n-    @Test\n-    public void shouldExposeRocksDBMetricsForSegmentedStateStoreBeforeAndAfterFailureWithEmptyStateDir() throws Exception {\n-        final Properties streamsConfiguration = streamsConfig();\n-        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n-        final StreamsBuilder builder = builderForSegmentedStateStore();\n-        final String metricsScope = \"rocksdb-window-state-id\";\n-\n-        cleanUpStateRunVerifyAndClose(\n-            builder,\n-            streamsConfiguration,\n-            LongDeserializer.class,\n-            LongDeserializer.class,\n-            this::verifyThatRocksDBMetricsAreExposed,\n-            metricsScope\n-        );\n-\n-        // simulated failure\n-\n-        cleanUpStateRunVerifyAndClose(\n-            builder,\n-            streamsConfiguration,\n-            LongDeserializer.class,\n-            LongDeserializer.class,\n-            this::verifyThatRocksDBMetricsAreExposed,\n-            metricsScope\n-        );\n-    }\n-\n-    @Test\n-    public void shouldVerifyThatMetricsGetMeasurementsFromRocksDBForNonSegmentedStateStore() throws Exception {\n-        final Properties streamsConfiguration = streamsConfig();\n-        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n-        final StreamsBuilder builder = builderForNonSegmentedStateStore();\n-        final String metricsScope = \"rocksdb-state-id\";\n-\n-        cleanUpStateRunVerifyAndClose(\n-            builder,\n-            streamsConfiguration,\n-            IntegerDeserializer.class,\n-            StringDeserializer.class,\n-            this::verifyThatBytesWrittenTotalIncreases,\n-            metricsScope\n-        );\n-    }\n-\n-    @Test\n-    public void shouldVerifyThatMetricsGetMeasurementsFromRocksDBForSegmentedStateStore() throws Exception {\n-        final Properties streamsConfiguration = streamsConfig();\n-        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n-        final StreamsBuilder builder = builderForSegmentedStateStore();\n-        final String metricsScope = \"rocksdb-window-state-id\";\n-\n-        cleanUpStateRunVerifyAndClose(\n-            builder,\n-            streamsConfiguration,\n-            LongDeserializer.class,\n-            LongDeserializer.class,\n-            this::verifyThatBytesWrittenTotalIncreases,\n-            metricsScope\n+            this::verifyThatRocksDBMetricsAreExposed\n         );\n     }\n \n", "next_change": {"commit": "fbd8cf0d861dec5b7bac237e8221cfae51bec14a", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex e9ac2f443c..394eeed051 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -149,7 +154,10 @@ public class RocksDBMetricsIntegrationTest {\n \n     private Properties streamsConfig() {\n         final Properties streamsConfiguration = new Properties();\n-        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, \"test-application\");\n+        final String suffix = name.getMethodName()\n+            .replace('[', '_')\n+            .replace(']', '_');\n+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, \"test-application-\" + suffix);\n         streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());\n         streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n", "next_change": {"commit": "dc4d439825b2d117707b01c7c64769e700246fc6", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex 394eeed051..af7dad0650 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -154,10 +155,8 @@ public class RocksDBMetricsIntegrationTest {\n \n     private Properties streamsConfig() {\n         final Properties streamsConfiguration = new Properties();\n-        final String suffix = name.getMethodName()\n-            .replace('[', '_')\n-            .replace(']', '_');\n-        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, \"test-application-\" + suffix);\n+        final String safeTestName = safeUniqueTestName(getClass(), testName);\n+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, \"test-application-\" + safeTestName);\n         streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());\n         streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n", "next_change": {"commit": "c04000cab1e98c206c5410ef68d00df1d9129182", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex af7dad0650..5917faa032 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -163,6 +185,7 @@ public class RocksDBMetricsIntegrationTest {\n         streamsConfiguration.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, Sensor.RecordingLevel.DEBUG.name);\n         streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n         return streamsConfiguration;\n     }\n \n", "next_change": {"commit": "14c6030c6ad70997863070f5b93c817ea8829425", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex 5917faa032..725b38612a 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -185,7 +198,7 @@ public class RocksDBMetricsIntegrationTest {\n         streamsConfiguration.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, Sensor.RecordingLevel.DEBUG.name);\n         streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.STATESTORE_CACHE_MAX_BYTES_CONFIG, 0);\n         return streamsConfiguration;\n     }\n \n", "next_change": {"commit": "67cf187603f54ba4f53f0b9eb93b269430f829db", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex 725b38612a..c698d06772 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -198,7 +198,7 @@ public class RocksDBMetricsIntegrationTest {\n         streamsConfiguration.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, Sensor.RecordingLevel.DEBUG.name);\n         streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-        streamsConfiguration.put(StreamsConfig.STATESTORE_CACHE_MAX_BYTES_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n         return streamsConfiguration;\n     }\n \n", "next_change": {"commit": "0924fd3f9f75c446310ed1e97b44bbc3f33c6c31", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex c698d06772..725b38612a 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -198,7 +198,7 @@ public class RocksDBMetricsIntegrationTest {\n         streamsConfiguration.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, Sensor.RecordingLevel.DEBUG.name);\n         streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.STATESTORE_CACHE_MAX_BYTES_CONFIG, 0);\n         return streamsConfiguration;\n     }\n \n", "next_change": {"commit": "38b08dfd3384a04b73e236c83f1e3ce0fffeda45", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex 725b38612a..17610c8450 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -198,7 +200,7 @@ public class RocksDBMetricsIntegrationTest {\n         streamsConfiguration.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, Sensor.RecordingLevel.DEBUG.name);\n         streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-        streamsConfiguration.put(StreamsConfig.STATESTORE_CACHE_MAX_BYTES_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n         return streamsConfiguration;\n     }\n \n", "next_change": {"commit": "9a793897ec486df550367dee43078e463b234294", "changed_code": [{"header": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\nindex 17610c8450..2d667839fa 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RocksDBMetricsIntegrationTest.java\n", "chunk": "@@ -200,7 +200,7 @@ public class RocksDBMetricsIntegrationTest {\n         streamsConfiguration.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, Sensor.RecordingLevel.DEBUG.name);\n         streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.STATESTORE_CACHE_MAX_BYTES_CONFIG, 0);\n         return streamsConfiguration;\n     }\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "0c256e16ab33b58c8306502401e2c992018a1781", "message": "Merge commit", "committedDate": null}, {"oid": "73ec7304b9e13cf4b9da05f215bd356a84efe0e7", "committedDate": "2020-04-09 10:57:10 -0700", "message": "KAFKA-9748: Extend Streams integration tests for EOS beta (#8441)"}, {"oid": "a0173ec45d83a38512c724b801d8c176c1f510db", "committedDate": "2020-04-17 10:49:40 -0700", "message": "KAFKA-9881: Convert integration test to verify measurements from RocksDB to unit test (#8501)"}, {"oid": "fcf45e1fac88238b1d3dbcfa1f324674939706f3", "committedDate": "2020-04-20 11:00:58 -0700", "message": "MINOR: Further reduce runtime for metrics integration tests (#8514)"}, {"oid": "fbd8cf0d861dec5b7bac237e8221cfae51bec14a", "committedDate": "2020-04-22 14:29:23 -0700", "message": "KAFKA-9388: Refactor integration tests to always use different application ids (#8530)"}, {"oid": "dc4d439825b2d117707b01c7c64769e700246fc6", "committedDate": "2020-04-29 17:11:49 -0500", "message": "KAFKA-9875: Make integration tests more resilient (#8578)"}, {"oid": "9da32b6bd014f1bdeeee5da8fcd00995a5916323", "committedDate": "2020-08-27 18:04:28 -0500", "message": "KAFKA-9924: Add RocksDB metric num-entries-active-mem-table (#9177)"}, {"oid": "c04000cab1e98c206c5410ef68d00df1d9129182", "committedDate": "2020-09-02 15:32:17 -0700", "message": "KAFKA-9924: Add remaining property-based RocksDB metrics as described in KIP-607 (#9232)"}, {"oid": "9af81955c497b31b211b1e21d8323c875518df39", "committedDate": "2021-03-25 01:04:39 +0800", "message": "KAFKA-12173 Migrate streams:streams-scala module to JUnit 5 (#9858)"}, {"oid": "3805f3706f8f3ebba81b80915c9259590525fb05", "committedDate": "2021-04-28 13:22:15 -0700", "message": "KAFKA-12574: KIP-732, Deprecate eos-alpha and replace eos-beta with eos-v2 (#10573)"}, {"oid": "b3905d9f71d48a60f2a9ee38014582d7ec7bc3c2", "committedDate": "2021-06-30 17:09:19 -0700", "message": "KAFKA-8613: New APIs for Controlling Grace Period for Windowed Operations (#10926)"}, {"oid": "14c6030c6ad70997863070f5b93c817ea8829425", "committedDate": "2022-01-27 21:19:04 -0800", "message": "KAFKA-13152: Replace \"buffered.records.per.partition\" with \"input.buffer.max.bytes\" (#11424)"}, {"oid": "67cf187603f54ba4f53f0b9eb93b269430f829db", "committedDate": "2022-02-01 14:08:11 -0800", "message": "Revert \"KAFKA-13152: Replace \"buffered.records.per.partition\" with \"input.buffer.max.bytes\" (#11424)\""}, {"oid": "0924fd3f9f75c446310ed1e97b44bbc3f33c6c31", "committedDate": "2022-03-21 17:16:00 -0700", "message": "KAFKA-13152: Replace \"buffered.records.per.partition\" with \"input.buffer.max.bytes\" (#11796)"}, {"oid": "4c9eeef5b2dff9a4f0977fbc5ac7eaaf930d0d0e", "committedDate": "2022-05-31 14:22:13 -0700", "message": "MINOR: add timeouts to streams integration tests (#12216)"}, {"oid": "38b08dfd3384a04b73e236c83f1e3ce0fffeda45", "committedDate": "2022-07-07 11:19:37 -0700", "message": "MINOR: revert KIP-770 (#12383)"}, {"oid": "9a793897ec486df550367dee43078e463b234294", "committedDate": "2022-10-20 17:03:50 -0700", "message": "KAFKA-13152: KIP-770, cache size config deprecation (#12758)"}, {"oid": "0601fa0935b03318ed08bfc578685fc4155ee948", "committedDate": "2023-01-22 15:57:58 -0800", "message": "MINOR: fix flaky integrations tests by using 60s default timeout for startup (#13141)"}]}, {"oid": "e145830422a24c6802bb1d7cef9e80008025c182", "url": "https://github.com/apache/kafka/commit/e145830422a24c6802bb1d7cef9e80008025c182", "message": "Clarify some tests", "committedDate": "2020-03-12T09:38:38Z", "type": "commit"}]}