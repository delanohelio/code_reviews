{"pr_number": 9615, "pr_title": "KAFKA-10500: Add thread option", "pr_author": "wcarlson5", "pr_createdAt": "2020-11-18T18:54:55Z", "pr_url": "https://github.com/apache/kafka/pull/9615", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2MTgwNA==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529461804", "body": "Please adjust indentation:\r\n\r\n```suggestion\r\n            mkMap(\r\n                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\r\n                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\r\n                mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\r\n                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\r\n                mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\r\n                mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\r\n            )\r\n```", "bodyText": "Please adjust indentation:\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            mkMap(\n          \n          \n            \n                                    mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n          \n          \n            \n                                    mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n          \n          \n            \n                                    mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n          \n          \n            \n                                    mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n          \n          \n            \n                                    mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n          \n          \n            \n                                    mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n          \n          \n            \n                            )\n          \n          \n            \n                        mkMap(\n          \n          \n            \n                            mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n          \n          \n            \n                            mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n          \n          \n            \n                            mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n          \n          \n            \n                            mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n          \n          \n            \n                            mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n          \n          \n            \n                            mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n          \n          \n            \n                        )", "bodyHTML": "<p dir=\"auto\">Please adjust indentation:</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"x x-first x-last\">    </span>mkMap(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">        </span>mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>BOOTSTRAP_SERVERS_CONFIG</span>, <span class=\"pl-c1\">CLUSTER</span><span class=\"pl-k\">.</span>bootstrapServers()),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">        </span>mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>APPLICATION_ID_CONFIG</span>, appId),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">        </span>mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>STATE_DIR_CONFIG</span>, <span class=\"pl-smi\">TestUtils</span><span class=\"pl-k\">.</span>tempDirectory()<span class=\"pl-k\">.</span>getPath()),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">        </span>mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>NUM_STREAM_THREADS_CONFIG</span>, <span class=\"pl-c1\">2</span>),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">        </span>mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>DEFAULT_KEY_SERDE_CLASS_CONFIG</span>, <span class=\"pl-smi\">Serdes</span><span class=\"pl-k\">.</span><span class=\"pl-smi\">StringSerde</span><span class=\"pl-k\">.</span>class),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">        </span>mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>DEFAULT_VALUE_SERDE_CLASS_CONFIG</span>, <span class=\"pl-smi\">Serdes</span><span class=\"pl-k\">.</span><span class=\"pl-smi\">StringSerde</span><span class=\"pl-k\">.</span>class)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"x x-first x-last\">    </span>)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            mkMap(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>BOOTSTRAP_SERVERS_CONFIG</span>, <span class=\"pl-c1\">CLUSTER</span><span class=\"pl-k\">.</span>bootstrapServers()),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>APPLICATION_ID_CONFIG</span>, appId),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>STATE_DIR_CONFIG</span>, <span class=\"pl-smi\">TestUtils</span><span class=\"pl-k\">.</span>tempDirectory()<span class=\"pl-k\">.</span>getPath()),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>NUM_STREAM_THREADS_CONFIG</span>, <span class=\"pl-c1\">2</span>),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>DEFAULT_KEY_SERDE_CLASS_CONFIG</span>, <span class=\"pl-smi\">Serdes</span><span class=\"pl-k\">.</span><span class=\"pl-smi\">StringSerde</span><span class=\"pl-k\">.</span>class),</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                mkEntry(<span class=\"pl-smi\">StreamsConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>DEFAULT_VALUE_SERDE_CLASS_CONFIG</span>, <span class=\"pl-smi\">Serdes</span><span class=\"pl-k\">.</span><span class=\"pl-smi\">StringSerde</span><span class=\"pl-k\">.</span>class)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            )</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "cadonna", "createdAt": "2020-11-24T11:07:26Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )", "originalCommit": "2d44bce5251dbb94c8751739b75424f9e043c0ba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2MTk3NQ==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529461975", "body": "wrong indentation", "bodyText": "wrong indentation", "bodyHTML": "<p dir=\"auto\">wrong indentation</p>", "author": "cadonna", "createdAt": "2020-11-24T11:07:45Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);", "originalCommit": "2d44bce5251dbb94c8751739b75424f9e043c0ba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDE4Mw==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529464183", "body": "We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.", "bodyText": "We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.", "bodyHTML": "<p dir=\"auto\">We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.</p>", "author": "cadonna", "createdAt": "2020-11-24T11:11:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            kafkaStreams.addStreamThread();\n+            produceMessages(0L, inputTopic, \"A\");\n+\n+            assertThat(kafkaStreams.localThreadsMetadata().size(), equalTo(oldThreadCount + 1));", "originalCommit": "2d44bce5251dbb94c8751739b75424f9e043c0ba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcxNjE2OQ==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529716169", "bodyText": "we can wait for it to be added to the thread meta data. I assume that is what you mean", "author": "wcarlson5", "createdAt": "2020-11-24T16:36:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDE4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDcxMw==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529464713", "body": "Do we need this line?", "bodyText": "Do we need this line?", "bodyHTML": "<p dir=\"auto\">Do we need this line?</p>", "author": "cadonna", "createdAt": "2020-11-24T11:12:09Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AdjustStreamThreadCountTest.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category(IntegrationTest.class)\n+public class AdjustStreamThreadCountTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+        builder.stream(inputTopic);\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    private void produceMessages(final long timestamp, final String streamOneInput, final String msg) {\n+        IntegrationTestUtils.produceKeyValuesSynchronouslyWithTimestamp(\n+                streamOneInput,\n+                Collections.singletonList(new KeyValue<>(\"1\", msg)),\n+                TestUtils.producerConfig(\n+                        CLUSTER.bootstrapServers(),\n+                        StringSerializer.class,\n+                        StringSerializer.class,\n+                        new Properties()),\n+                timestamp);\n+    }\n+\n+    @Test\n+    public void shouldAddStreamThread() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+            final int oldThreadCount = kafkaStreams.localThreadsMetadata().size();\n+\n+            kafkaStreams.addStreamThread();\n+            produceMessages(0L, inputTopic, \"A\");", "originalCommit": "2d44bce5251dbb94c8751739b75424f9e043c0ba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcwOTU5NQ==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529709595", "bodyText": "no, we don't", "author": "wcarlson5", "createdAt": "2020-11-24T16:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ2NDcxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxODQwMw==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529518403", "body": "```suggestion\r\n            synchronized (stateLock) {\r\n                if (isRunningOrRebalancing()) {\r\n                    streamThread.start();\r\n                    return Optional.of(streamThread.getName());\r\n                } else {\r\n                    return Optional.empty();\r\n                }\r\n            }\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        synchronized (stateLock) {\n          \n          \n            \n                            if (isRunningOrRebalancing()) {\n          \n          \n            \n                                streamThread.start();\n          \n          \n            \n                            } else {\n          \n          \n            \n                                return Optional.empty();\n          \n          \n            \n                            }\n          \n          \n            \n                        }\n          \n          \n            \n                        return Optional.of(streamThread.getName());\n          \n          \n            \n                        synchronized (stateLock) {\n          \n          \n            \n                            if (isRunningOrRebalancing()) {\n          \n          \n            \n                                streamThread.start();\n          \n          \n            \n                                return Optional.of(streamThread.getName());\n          \n          \n            \n                            } else {\n          \n          \n            \n                                return Optional.empty();\n          \n          \n            \n                            }\n          \n          \n            \n                        }", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"pl-k\">synchronized</span> (stateLock) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"pl-k\">if</span> (isRunningOrRebalancing()) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                    streamThread<span class=\"pl-k\">.</span>start();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first\">} </span><span class=\"pl-k x\">else</span><span class=\"x x-last\"> {</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first\">    </span><span class=\"pl-k x\">return</span><span class=\"x\"> </span><span class=\"pl-smi x\">Optional</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">empty();</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"x x-first x-last\">}</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            }</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"pl-k x x-first\">return</span><span class=\"x\"> </span><span class=\"pl-smi x\">Optional</span><span class=\"pl-k x\">.</span><span class=\"x\">of(streamThread</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">getName());</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            <span class=\"pl-k\">synchronized</span> (stateLock) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                <span class=\"pl-k\">if</span> (isRunningOrRebalancing()) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                    streamThread<span class=\"pl-k\">.</span>start();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                <span class=\"x x-first\">    </span><span class=\"pl-k x\">return</span><span class=\"x\"> </span><span class=\"pl-smi x\">Optional</span><span class=\"pl-k x\">.</span><span class=\"x\">of(streamThread</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">getName());</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                <span class=\"x x-first\">} </span><span class=\"pl-k x\">else</span><span class=\"x x-last\"> {</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                <span class=\"x x-first\">    </span><span class=\"pl-k x\">return</span><span class=\"x\"> </span><span class=\"pl-smi x\">Optional</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">empty();</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            <span class=\"x x-first x-last\">    </span>}</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            <span class=\"x x-first x-last\">}</span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "cadonna", "createdAt": "2020-11-24T12:46:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -894,19 +885,88 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+                internalTopologyBuilder,\n+                config,\n+                clientSupplier,\n+                adminClient,\n+                processId,\n+                clientId,\n+                streamsMetrics,\n+                time,\n+                streamsMetadataState,\n+                cacheSizePerThread,\n+                stateDirectory,\n+                delegatingStateRestoreListener,\n+                threadIdx,\n+                KafkaStreams.this::closeToError,\n+                streamsUncaughtExceptionHandler\n+        );\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     *\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@code cache.max.bytes.buffering}.\n+     *\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        if (isRunningOrRebalancing()) {\n+            final int threadIdx = getNextThreadIndex();\n+            final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1);\n+            resizeThreadCache(cacheSizePerThread);\n+            final StreamThread streamThread = createStreamThread(cacheSizePerThread, threadIdx);\n+            streamThread.setStateListener(streamStateListener);\n+            synchronized (stateLock) {\n+                if (isRunningOrRebalancing()) {\n+                    streamThread.start();\n+                } else {\n+                    return Optional.empty();\n+                }\n+            }\n+            return Optional.of(streamThread.getName());", "originalCommit": "2d44bce5251dbb94c8751739b75424f9e043c0ba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcxMzc2NA==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r529713764", "bodyText": "sure", "author": "wcarlson5", "createdAt": "2020-11-24T16:32:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxODQwMw=="}], "type": "inlineReview"}, {"oid": "dfbd9f47becff83cde4092e46ba180a9f6c49eb0", "url": "https://github.com/apache/kafka/commit/dfbd9f47becff83cde4092e46ba180a9f6c49eb0", "message": "ThreadCache Resizes", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "dc4fcb8572b7dd4bb9e99a0879a4ea0a0ad28524", "url": "https://github.com/apache/kafka/commit/dc4fcb8572b7dd4bb9e99a0879a4ea0a0ad28524", "message": "comments", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "5b2df7e44c52b54943fb09bd860215f803a7147e", "url": "https://github.com/apache/kafka/commit/5b2df7e44c52b54943fb09bd860215f803a7147e", "message": "improved names and checks", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "82f307c87ea2484c6bf75f0f376dd620255fb246", "url": "https://github.com/apache/kafka/commit/82f307c87ea2484c6bf75f0f376dd620255fb246", "message": "make helper for cache size", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "65f237dd9336ef3bacae8516b7d1b402242199f8", "url": "https://github.com/apache/kafka/commit/65f237dd9336ef3bacae8516b7d1b402242199f8", "message": "remove redundant check", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "c0a94e3c006e044b96f3c00682fab938efdbea85", "url": "https://github.com/apache/kafka/commit/c0a94e3c006e044b96f3c00682fab938efdbea85", "message": "add thread", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "ad38800664d81cbe0c57fabd8f6be4c980e28482", "url": "https://github.com/apache/kafka/commit/ad38800664d81cbe0c57fabd8f6be4c980e28482", "message": "add thread tests", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "d43bb5e1eb2f0519cfa11e27198dc3531ca54115", "url": "https://github.com/apache/kafka/commit/d43bb5e1eb2f0519cfa11e27198dc3531ca54115", "message": "remove extra methods", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "d8793d6115eec1445d15b03cb8bd202e098add8e", "url": "https://github.com/apache/kafka/commit/d8793d6115eec1445d15b03cb8bd202e098add8e", "message": "add line", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "9f77626c0185e474f491cdbcb4327525817439c1", "url": "https://github.com/apache/kafka/commit/9f77626c0185e474f491cdbcb4327525817439c1", "message": "fix tests", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "c42551a49580dd658f141a5b294a30df66eb4d79", "url": "https://github.com/apache/kafka/commit/c42551a49580dd658f141a5b294a30df66eb4d79", "message": "add start and gets name properly", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "acd65f2cf50c3066e8b6841f4df660a577d31ddd", "url": "https://github.com/apache/kafka/commit/acd65f2cf50c3066e8b6841f4df660a577d31ddd", "message": "need to add an int test", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "8fdaca11be2ac8c30179a9043a236e9a78913579", "url": "https://github.com/apache/kafka/commit/8fdaca11be2ac8c30179a9043a236e9a78913579", "message": "added int test", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "a698a6826c5eecce1e6123fecabbebb4503197eb", "url": "https://github.com/apache/kafka/commit/a698a6826c5eecce1e6123fecabbebb4503197eb", "message": "address comments", "committedDate": "2020-12-03T19:09:25Z", "type": "commit"}, {"oid": "df25f11e53608e91c29573a199656fd7ee7cf36b", "url": "https://github.com/apache/kafka/commit/df25f11e53608e91c29573a199656fd7ee7cf36b", "message": "reduce line size", "committedDate": "2020-12-03T19:09:26Z", "type": "commit"}, {"oid": "6d394a3bf204905931c42d273a8b34bab9023c41", "url": "https://github.com/apache/kafka/commit/6d394a3bf204905931c42d273a8b34bab9023c41", "message": "address comments", "committedDate": "2020-12-03T19:09:26Z", "type": "commit"}, {"oid": "d818144143e5faaf61916c14c6b862b7a818709d", "url": "https://github.com/apache/kafka/commit/d818144143e5faaf61916c14c6b862b7a818709d", "message": "address comments pt 2", "committedDate": "2020-12-03T19:09:26Z", "type": "commit"}, {"oid": "99649b9faf95282e0c3a0f8c533e9cc99191b20f", "url": "https://github.com/apache/kafka/commit/99649b9faf95282e0c3a0f8c533e9cc99191b20f", "message": "wait for running in test", "committedDate": "2020-12-03T19:09:26Z", "type": "commit"}, {"oid": "17d8ca4ff8e91736de49ff8499ad57cd4486bfd4", "url": "https://github.com/apache/kafka/commit/17d8ca4ff8e91736de49ff8499ad57cd4486bfd4", "message": "shutdown thread", "committedDate": "2020-12-03T19:09:26Z", "type": "commit"}, {"oid": "af3e5674f77037796801afcd445e126c1aa7f6b0", "url": "https://github.com/apache/kafka/commit/af3e5674f77037796801afcd445e126c1aa7f6b0", "message": "Add tests for thread names", "committedDate": "2020-12-03T19:09:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4NTUwNQ==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r536285505", "body": "Why do we need this new lock-object? Would it not be simpler to just reuse `stateLock` ?", "bodyText": "Why do we need this new lock-object? Would it not be simpler to just reuse stateLock ?", "bodyHTML": "<p dir=\"auto\">Why do we need this new lock-object? Would it not be simpler to just reuse <code>stateLock</code> ?</p>", "author": "mjsax", "createdAt": "2020-12-04T18:11:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -845,67 +856,118 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 time,\n                 globalThreadId,\n                 delegatingStateRestoreListener,\n-                this::defaultStreamsUncaughtExceptionHandler\n+                streamsUncaughtExceptionHandler\n             );\n             globalThreadState = globalStreamThread.state();\n         }\n \n         // use client id instead of thread client id since this admin client may be shared among threads\n         adminClient = clientSupplier.getAdmin(config.getAdminConfigs(ClientUtils.getSharedAdminClientId(clientId)));\n \n-        final Map<Long, StreamThread.State> threadState = new HashMap<>(numStreamThreads);\n-        final ArrayList<StreamThreadStateStoreProvider> storeProviders = new ArrayList<>();\n-        for (int i = 0; i < numStreamThreads; i++) {\n-            final StreamThread streamThread = StreamThread.create(\n-                internalTopologyBuilder,\n-                config,\n-                clientSupplier,\n-                adminClient,\n-                processId,\n-                clientId,\n-                streamsMetrics,\n-                time,\n-                streamsMetadataState,\n-                cacheSizePerThread,\n-                stateDirectory,\n-                delegatingStateRestoreListener,\n-                i + 1,\n-                KafkaStreams.this::closeToError,\n-                this::defaultStreamsUncaughtExceptionHandler\n-            );\n-            threads.add(streamThread);\n-            threadState.put(streamThread.getId(), streamThread.state());\n-            storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n-        }\n-\n-        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n-            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n-\n-        final StreamStateListener streamStateListener = new StreamStateListener(threadState, globalThreadState);\n+        threadState = new HashMap<>(numStreamThreads);\n+        storeProviders = new ArrayList<>();\n+        streamStateListener = new StreamStateListener(threadState, globalThreadState);\n         if (hasGlobalTopology) {\n             globalStreamThread.setStateListener(streamStateListener);\n         }\n-        for (final StreamThread thread : threads) {\n-            thread.setStateListener(streamStateListener);\n+        for (int i = 1; i <= numStreamThreads; i++) {\n+            createStreamThread(cacheSizePerThread, i);\n         }\n \n+        ClientMetrics.addNumAliveStreamThreadMetric(streamsMetrics, (metricsConfig, now) ->\n+            Math.toIntExact(threads.stream().filter(thread -> thread.state().isAlive()).count()));\n+\n         final GlobalStateStoreProvider globalStateStoreProvider = new GlobalStateStoreProvider(internalTopologyBuilder.globalStateStores());\n         queryableStoreProvider = new QueryableStoreProvider(storeProviders, globalStateStoreProvider);\n \n         stateDirCleaner = setupStateDirCleaner();\n-        oldHandler = false;\n         maybeWarnAboutCodeInRocksDBConfigSetter(log, config);\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private StreamThread createStreamThread(final long cacheSizePerThread, final int threadIdx) {\n+        final StreamThread streamThread = StreamThread.create(\n+            internalTopologyBuilder,\n+            config,\n+            clientSupplier,\n+            adminClient,\n+            processId,\n+            clientId,\n+            streamsMetrics,\n+            time,\n+            streamsMetadataState,\n+            cacheSizePerThread,\n+            stateDirectory,\n+            delegatingStateRestoreListener,\n+            threadIdx,\n+            KafkaStreams.this::closeToError,\n+            streamsUncaughtExceptionHandler\n+        );\n+        streamThread.setStateListener(streamStateListener);\n+        threads.add(streamThread);\n+        threadState.put(streamThread.getId(), streamThread.state());\n+        storeProviders.add(new StreamThreadStateStoreProvider(streamThread));\n+        return streamThread;\n+    }\n+\n+    /**\n+     * Adds and starts a stream thread in addition to the stream threads that are already running in this\n+     * Kafka Streams client.\n+     * <p>\n+     * Since the number of stream threads increases, the sizes of the caches in the new stream thread\n+     * and the existing stream threads are adapted so that the sum of the cache sizes over all stream\n+     * threads does not exceed the total cache size specified in configuration\n+     * {@link StreamsConfig#CACHE_MAX_BYTES_BUFFERING_CONFIG}.\n+     * <p>\n+     * Stream threads can only be added if this Kafka Streams client is in state RUNNING or REBALANCING.\n+     *\n+     * @return name of the added stream thread or empty if a new stream thread could not be added\n+     */\n+    public Optional<String> addStreamThread() {\n+        synchronized (changeThreadCount) {", "originalCommit": "af3e5674f77037796801afcd445e126c1aa7f6b0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMxODczNw==", "url": "https://github.com/apache/kafka/pull/9615#discussion_r536318737", "bodyText": "We thought it would be better use a separate lock because it is serving a different purpose. It will also use used in remove thread. It might be simpler to reuse the statelock but I don\u2019t think that would be cleaner. We are really locking on the thread cache access and the thread indexes", "author": "wcarlson5", "createdAt": "2020-12-04T19:11:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4NTUwNQ=="}], "type": "inlineReview"}]}