{"pr_number": 9648, "pr_title": "KAFKA-10758: ProcessorTopology should only consider its own nodes when updating regex source topics", "pr_author": "ableegoldman", "pr_createdAt": "2020-11-24T01:20:02Z", "pr_url": "https://github.com/apache/kafka/pull/9648", "timeline": [{"oid": "dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "url": "https://github.com/apache/kafka/commit/dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "message": "refactor upDateSourceTopics, fix up test", "committedDate": "2020-11-24T02:07:53Z", "type": "commit"}, {"oid": "dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "url": "https://github.com/apache/kafka/commit/dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "message": "refactor upDateSourceTopics, fix up test", "committedDate": "2020-11-24T02:07:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4MDA3Mg==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529280072", "body": "Could you also add a unit test that verifies that the issue is gone?", "bodyText": "Could you also add a unit test that verifies that the issue is gone?", "bodyHTML": "<p dir=\"auto\">Could you also add a unit test that verifies that the issue is gone?</p>", "author": "cadonna", "createdAt": "2020-11-24T08:17:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorTopology.java", "diffHunk": "@@ -149,24 +149,30 @@ public boolean hasPersistentGlobalStore() {\n         return false;\n     }\n \n-    public void updateSourceTopics(final Map<String, List<String>> sourceTopicsByName) {\n-        if (!sourceTopicsByName.keySet().equals(sourceNodesByName.keySet())) {\n-            log.error(\"Set of source nodes do not match: \\n\" +\n-                \"sourceNodesByName = {}\\n\" +\n-                \"sourceTopicsByName = {}\",\n-                sourceNodesByName.keySet(), sourceTopicsByName.keySet());\n-            throw new IllegalStateException(\"Tried to update source topics but source nodes did not match\");\n-        }\n+    public void updateSourceTopics(final Map<String, List<String>> allSourceTopicsByNodeName) {", "originalCommit": "dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc5ODE0MA==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529798140", "bodyText": "I modified the existing test rather than add a new one, and verified that the modified test does fail without the changes. Since the original test wasn't actually testing anything prior to the modifications I thought it made sense to fix the test rather than add a new one and retain a useless test in addition", "author": "ableegoldman", "createdAt": "2020-11-24T18:40:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4MDA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTg0NjU0Mw==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529846543", "bodyText": "The scope of an integration test and of a unit test are quite different. The integration test specifically tests the pattern subscription whereas the unit test just tests the update of the source topics. Probably at the moment the update of the source topics is only called when pattern subscription is used, but that assumption seems rather brittle to me because   it may change in future. I think that neither of the tests is useless. If one were useless, I would keep the unit test for test execution performance reasons.", "author": "cadonna", "createdAt": "2020-11-24T20:06:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4MDA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTkyODU2Ng==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529928566", "bodyText": "Added a unit test", "author": "ableegoldman", "createdAt": "2020-11-24T22:15:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4MDA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI5Mjk2OA==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529292968", "body": "I would add the following assert here to ensure we have more than one sub-topology:\r\n\r\n```\r\n            final Topology topology = builder.build();\r\n            assertThat(topology.describe().subtopologies().size(), greaterThan(1));\r\n            streams = new KafkaStreams(topology, streamsConfiguration);\r\n```\r\n\r\nJust to make it clear that we want to test with multiple sub-topologies.", "bodyText": "I would add the following assert here to ensure we have more than one sub-topology:\n            final Topology topology = builder.build();\n            assertThat(topology.describe().subtopologies().size(), greaterThan(1));\n            streams = new KafkaStreams(topology, streamsConfiguration);\n\nJust to make it clear that we want to test with multiple sub-topologies.", "bodyHTML": "<p dir=\"auto\">I would add the following assert here to ensure we have more than one sub-topology:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"            final Topology topology = builder.build();\n            assertThat(topology.describe().subtopologies().size(), greaterThan(1));\n            streams = new KafkaStreams(topology, streamsConfiguration);\n\"><pre><code>            final Topology topology = builder.build();\n            assertThat(topology.describe().subtopologies().size(), greaterThan(1));\n            streams = new KafkaStreams(topology, streamsConfiguration);\n</code></pre></div>\n<p dir=\"auto\">Just to make it clear that we want to test with multiple sub-topologies.</p>", "author": "cadonna", "createdAt": "2020-11-24T08:37:43Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -198,9 +200,16 @@ public void testRegexRecordsAreProcessedAfterReassignment() throws Exception {\n \n             final StreamsBuilder builder = new StreamsBuilder();\n             final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n-            pattern1Stream.to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));\n+            final KStream<String, String> otherStream = builder.stream(Pattern.compile(\"not-a-match\"));\n+\n+            pattern1Stream\n+                .selectKey((k, v) -> k)\n+                .groupByKey()\n+                .aggregate(() -> \"\", (k, v, a) -> v)\n+                .toStream().to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));\n+\n             streams = new KafkaStreams(builder.build(), streamsConfiguration);", "originalCommit": "dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc5ODIxNg==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529798216", "bodyText": "Ack good call", "author": "ableegoldman", "createdAt": "2020-11-24T18:40:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI5Mjk2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI5NDMzNw==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529294337", "body": "I would even add `otherStream` like:\r\n```suggestion\r\n                .toStream()\r\n                .merge(otherStream)\r\n                .to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));\r\n```", "bodyText": "I would even add otherStream like:\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            .toStream().to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));\n          \n          \n            \n                            .toStream()\n          \n          \n            \n                            .merge(otherStream)\n          \n          \n            \n                            .to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));", "bodyHTML": "<p dir=\"auto\">I would even add <code>otherStream</code> like:</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"211\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                .toStream()<span class=\"pl-k x x-first\">.</span><span class=\"x\">to(outputTopic, </span><span class=\"pl-smi x\">Produced</span><span class=\"pl-k x\">.</span><span class=\"x\">with(</span><span class=\"pl-smi x\">Serdes</span><span class=\"pl-k x\">.</span><span class=\"x\">String(), </span><span class=\"pl-smi x\">Serdes</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">String()));</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"211\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                .toStream()</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"212\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                .merge(otherStream)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"213\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                .to(outputTopic, <span class=\"pl-smi\">Produced</span><span class=\"pl-k\">.</span>with(<span class=\"pl-smi\">Serdes</span><span class=\"pl-k\">.</span>String(), <span class=\"pl-smi\">Serdes</span><span class=\"pl-k\">.</span>String()));</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "cadonna", "createdAt": "2020-11-24T08:39:49Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -198,9 +200,16 @@ public void testRegexRecordsAreProcessedAfterReassignment() throws Exception {\n \n             final StreamsBuilder builder = new StreamsBuilder();\n             final KStream<String, String> pattern1Stream = builder.stream(Pattern.compile(\"TEST-TOPIC-\\\\d\"));\n-            pattern1Stream.to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));\n+            final KStream<String, String> otherStream = builder.stream(Pattern.compile(\"not-a-match\"));\n+\n+            pattern1Stream\n+                .selectKey((k, v) -> k)\n+                .groupByKey()\n+                .aggregate(() -> \"\", (k, v, a) -> v)\n+                .toStream().to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));", "originalCommit": "dfdf63573ba083b6d186a2bd4bb7c2d39a4b6156", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc5NjQ3NA==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529796474", "bodyText": "But if we merge then won't that merge the subtopologies as well? (We would still have two subtopologies due to the upstream key-changing operation/repartition, but I wanted the test to cover different \"kinds\" of subtopologies like this)", "author": "ableegoldman", "createdAt": "2020-11-24T18:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI5NDMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTg0MDA3OA==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529840078", "bodyText": "You would have a source node in one sub-topology an a source node in the other sub-topology. I thought that was the pattern in the bug report, but I now realized that the bug report uses a pattern similar to the one you specified. Wouldn't it make sense to test both?", "author": "cadonna", "createdAt": "2020-11-24T19:54:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI5NDMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTkzMjQ0OQ==", "url": "https://github.com/apache/kafka/pull/9648#discussion_r529932449", "bodyText": "There are two ways to have more than one source node: either reading from a different input topic/pattern, or via a repartition. I agree that we should test both of these cases, but I'd prefer to do so in a single integration test rather than in two separate integration tests, to avoid making the test suite even longer", "author": "ableegoldman", "createdAt": "2020-11-24T22:19:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI5NDMzNw=="}], "type": "inlineReview"}, {"oid": "46f2a32dd8cc5638df3ca6b8413059df0704ae11", "url": "https://github.com/apache/kafka/commit/46f2a32dd8cc5638df3ca6b8413059df0704ae11", "message": "review feedback", "committedDate": "2020-11-24T18:42:58Z", "type": "commit"}, {"oid": "46f2a32dd8cc5638df3ca6b8413059df0704ae11", "url": "https://github.com/apache/kafka/commit/46f2a32dd8cc5638df3ca6b8413059df0704ae11", "message": "review feedback", "committedDate": "2020-11-24T18:42:58Z", "type": "forcePushed"}, {"oid": "60b95760213142ba1159d79bb1c1b1765d6ecb6b", "url": "https://github.com/apache/kafka/commit/60b95760213142ba1159d79bb1c1b1765d6ecb6b", "message": "add unit test", "committedDate": "2020-11-24T22:12:31Z", "type": "commit"}]}