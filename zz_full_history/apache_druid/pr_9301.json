{"pr_number": 9301, "pr_title": "Join filter pushdown initial implementation", "pr_author": "jon-wei", "pr_createdAt": "2020-01-31T21:48:24Z", "pr_url": "https://github.com/apache/druid/pull/9301", "merge_commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "timeline": [{"oid": "3c1c6749a3f94f0f8abf617cfafabd10973df9eb", "url": "https://github.com/apache/druid/commit/3c1c6749a3f94f0f8abf617cfafabd10973df9eb", "message": "Join filter pushdown initial implementation", "committedDate": "2020-02-01T00:25:29Z", "type": "commit"}, {"oid": "443d7274a49c71429d87afce3667b96d35dba517", "url": "https://github.com/apache/druid/commit/443d7274a49c71429d87afce3667b96d35dba517", "message": "Fix test and spotbugs check", "committedDate": "2020-02-01T00:25:29Z", "type": "commit"}, {"oid": "443d7274a49c71429d87afce3667b96d35dba517", "url": "https://github.com/apache/druid/commit/443d7274a49c71429d87afce3667b96d35dba517", "message": "Fix test and spotbugs check", "committedDate": "2020-02-01T00:25:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI3OTk1MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374279951", "body": "Do you want to add a unit test to `AndFilterTest` that uses `EqualsVerifier` (similar to https://github.com/apache/druid/blob/master/processing/src/test/java/org/apache/druid/query/QueryDataSourceTest.java#L142)", "bodyText": "Do you want to add a unit test to AndFilterTest that uses EqualsVerifier (similar to https://github.com/apache/druid/blob/master/processing/src/test/java/org/apache/druid/query/QueryDataSourceTest.java#L142)", "bodyHTML": "<p dir=\"auto\">Do you want to add a unit test to <code>AndFilterTest</code> that uses <code>EqualsVerifier</code> (similar to <a href=\"https://github.com/apache/druid/blob/master/processing/src/test/java/org/apache/druid/query/QueryDataSourceTest.java#L142\">https://github.com/apache/druid/blob/master/processing/src/test/java/org/apache/druid/query/QueryDataSourceTest.java#L142</a>)</p>", "author": "ccaominh", "createdAt": "2020-02-03T18:58:03Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/AndFilter.java", "diffHunk": "@@ -234,4 +235,23 @@ public ReadableVectorMatch match(final ReadableVectorMatch mask)\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjQ5OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996498", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:14:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI3OTk1MQ=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "40e84a171b8be8e87db20b0c5c189aef1b860f41", "committedDate": "2020-04-05 22:29:41 -0700", "message": "Eliminate common subfilters when converting it to a CNF (#9608)"}, {"oid": "8b808c48799b04b53e763fd49c766e1e6a26d1cb", "committedDate": "2021-01-20 08:59:20 -0800", "message": "Retain order of AND, OR filter children. (#10758)"}, {"oid": "4cd4a22f87616ad6b4a722a8a47bad9ce25fa790", "committedDate": "2021-03-16 11:46:50 -0700", "message": "expression filter support for vectorized query engines (#10613)"}, {"oid": "9e5a940cf1fc04b00f9cb0216ec8766d8fed0ee2", "committedDate": "2022-05-11 11:57:08 +0530", "message": "remake column indexes and query processing of filters (#12388)"}, {"oid": "4b1ffbc452831178dccd38456ed9b2cdf2521d13", "committedDate": "2023-03-10 16:42:08 +0530", "message": "Various changes and fixes to UNNEST. (#13892)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDUwNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280504", "body": "Similar comment about testing with `EqualsVerifier`", "bodyText": "Similar comment about testing with EqualsVerifier", "bodyHTML": "<p dir=\"auto\">Similar comment about testing with <code>EqualsVerifier</code></p>", "author": "ccaominh", "createdAt": "2020-02-03T18:59:07Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/BoundFilter.java", "diffHunk": "@@ -306,4 +307,26 @@ private boolean doesMatch(String input)\n     }\n     return (lowerComparing >= 0) && (upperComparing >= 0);\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjUyNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996525", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:14:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDUwNA=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "16d293d6e0d81963af3b3d468efd658317d91052", "committedDate": "2020-05-08 23:45:35 -0700", "message": "Directly rewrite filters on RHS join columns into LHS equivalents (#9818)"}, {"oid": "b0167295d7c621bfa9722b7203bc7ca08fc76495", "committedDate": "2020-05-13 14:23:04 -0700", "message": "Fail incorrectly constructed join queries (#9830)"}, {"oid": "8b808c48799b04b53e763fd49c766e1e6a26d1cb", "committedDate": "2021-01-20 08:59:20 -0800", "message": "Retain order of AND, OR filter children. (#10758)"}, {"oid": "6c0c6e60b3604515571db062915767e9550b52cf", "committedDate": "2021-01-29 09:30:09 -0800", "message": "Vectorized theta sketch aggregator + rework of VectorColumnProcessorFactory. (#10767)"}, {"oid": "4cd4a22f87616ad6b4a722a8a47bad9ce25fa790", "committedDate": "2021-03-16 11:46:50 -0700", "message": "expression filter support for vectorized query engines (#10613)"}, {"oid": "9cfb23935ffc3eace79b526dd84d912d129a9b1c", "committedDate": "2022-03-09 13:30:58 -0800", "message": "push value range and set index get operations into BitmapIndex (#12315)"}, {"oid": "9e5a940cf1fc04b00f9cb0216ec8766d8fed0ee2", "committedDate": "2022-05-11 11:57:08 +0530", "message": "remake column indexes and query processing of filters (#12388)"}, {"oid": "18937ffee210fb230737aac20e48ede9601b8096", "committedDate": "2022-06-17 15:29:23 -0700", "message": "split out null value index (#12627)"}, {"oid": "189e8b9d18b1f9266215ff4a6811b9b571e78aa0", "committedDate": "2022-07-29 18:58:49 -0700", "message": "add NumericRangeIndex interface and BoundFilter support (#12830)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDY3Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280677", "body": "Similar comment about testing with `EqualsVerifier`", "bodyText": "Similar comment about testing with EqualsVerifier", "bodyHTML": "<p dir=\"auto\">Similar comment about testing with <code>EqualsVerifier</code></p>", "author": "ccaominh", "createdAt": "2020-02-03T18:59:30Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/InFilter.java", "diffHunk": "@@ -235,4 +236,26 @@ public DruidDoublePredicate makeDoublePredicate()\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjU1Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996553", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDY3Nw=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": {"commit": "b0167295d7c621bfa9722b7203bc7ca08fc76495", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java b/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java\nindex 54ad64b506..dfc4d711d4 100644\n--- a/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java\n", "chunk": "@@ -194,47 +225,7 @@ public class InFilter implements Filter\n \n   private DruidPredicateFactory getPredicateFactory()\n   {\n-    return new DruidPredicateFactory()\n-    {\n-      @Override\n-      public Predicate<String> makeStringPredicate()\n-      {\n-        if (extractionFn != null) {\n-          return input -> values.contains(extractionFn.apply(input));\n-        } else {\n-          return input -> values.contains(input);\n-        }\n-      }\n-\n-      @Override\n-      public DruidLongPredicate makeLongPredicate()\n-      {\n-        if (extractionFn != null) {\n-          return input -> values.contains(extractionFn.apply(input));\n-        } else {\n-          return longPredicateSupplier.get();\n-        }\n-      }\n-\n-      @Override\n-      public DruidFloatPredicate makeFloatPredicate()\n-      {\n-        if (extractionFn != null) {\n-          return input -> values.contains(extractionFn.apply(input));\n-        } else {\n-          return floatPredicateSupplier.get();\n-        }\n-      }\n-\n-      @Override\n-      public DruidDoublePredicate makeDoublePredicate()\n-      {\n-        if (extractionFn != null) {\n-          return input -> values.contains(extractionFn.apply(input));\n-        }\n-        return input -> doublePredicateSupplier.get().applyDouble(input);\n-      }\n-    };\n+    return new InFilterDruidPredicateFactory(extractionFn, values, longPredicateSupplier, floatPredicateSupplier, doublePredicateSupplier);\n   }\n \n   @Override\n", "next_change": {"commit": "170031744e8a2ed5fc4c06062df014bcfcfe2e1f", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java b/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java\ndeleted file mode 100644\nindex dfc4d711d4..0000000000\n--- a/processing/src/main/java/org/apache/druid/segment/filter/InFilter.java\n+++ /dev/null\n", "chunk": "@@ -1,336 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.apache.druid.segment.filter;\n-\n-import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.base.Predicate;\n-import com.google.common.base.Supplier;\n-import com.google.common.collect.ImmutableSet;\n-import it.unimi.dsi.fastutil.ints.IntIterable;\n-import it.unimi.dsi.fastutil.ints.IntIterator;\n-import org.apache.druid.collections.bitmap.ImmutableBitmap;\n-import org.apache.druid.java.util.common.IAE;\n-import org.apache.druid.query.BitmapResultFactory;\n-import org.apache.druid.query.extraction.ExtractionFn;\n-import org.apache.druid.query.filter.BitmapIndexSelector;\n-import org.apache.druid.query.filter.DruidDoublePredicate;\n-import org.apache.druid.query.filter.DruidFloatPredicate;\n-import org.apache.druid.query.filter.DruidLongPredicate;\n-import org.apache.druid.query.filter.DruidPredicateFactory;\n-import org.apache.druid.query.filter.Filter;\n-import org.apache.druid.query.filter.FilterTuning;\n-import org.apache.druid.query.filter.ValueMatcher;\n-import org.apache.druid.query.filter.vector.VectorValueMatcher;\n-import org.apache.druid.query.filter.vector.VectorValueMatcherColumnProcessorFactory;\n-import org.apache.druid.segment.ColumnSelector;\n-import org.apache.druid.segment.ColumnSelectorFactory;\n-import org.apache.druid.segment.DimensionHandlerUtils;\n-import org.apache.druid.segment.IntIteratorUtils;\n-import org.apache.druid.segment.column.BitmapIndex;\n-import org.apache.druid.segment.vector.VectorColumnSelectorFactory;\n-\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Objects;\n-import java.util.Set;\n-\n-/**\n- * The IN filter.\n- * For single-valued dimension, this filter returns true if the dimension value matches to one of the\n- * given {@link #values}.\n- * For multi-valued dimension, this filter returns true if one of the dimension values matches to one of the\n- * given {@link #values}.\n- *\n- * In SQL-compatible null handling mode, this filter is equivalent to {@code (dimension IN [values])} or\n- * {@code (dimension IN [non-null values] OR dimension IS NULL)} when {@link #values} contains nulls.\n- * In default null handling mode, this filter is equivalent to {@code (dimension IN [values])} or\n- * {@code (dimension IN [non-null values, ''])} when {@link #values} contains nulls.\n- */\n-public class InFilter implements Filter\n-{\n-  private final String dimension;\n-  private final Set<String> values;\n-  private final ExtractionFn extractionFn;\n-  private final FilterTuning filterTuning;\n-  private final Supplier<DruidLongPredicate> longPredicateSupplier;\n-  private final Supplier<DruidFloatPredicate> floatPredicateSupplier;\n-  private final Supplier<DruidDoublePredicate> doublePredicateSupplier;\n-\n-  public InFilter(\n-      String dimension,\n-      Set<String> values,\n-      Supplier<DruidLongPredicate> longPredicateSupplier,\n-      Supplier<DruidFloatPredicate> floatPredicateSupplier,\n-      Supplier<DruidDoublePredicate> doublePredicateSupplier,\n-      ExtractionFn extractionFn,\n-      FilterTuning filterTuning\n-  )\n-  {\n-    this.dimension = dimension;\n-    this.values = values;\n-    this.extractionFn = extractionFn;\n-    this.filterTuning = filterTuning;\n-    this.longPredicateSupplier = longPredicateSupplier;\n-    this.floatPredicateSupplier = floatPredicateSupplier;\n-    this.doublePredicateSupplier = doublePredicateSupplier;\n-  }\n-\n-  @Override\n-  public <T> T getBitmapResult(BitmapIndexSelector selector, BitmapResultFactory<T> bitmapResultFactory)\n-  {\n-    if (extractionFn == null) {\n-      final BitmapIndex bitmapIndex = selector.getBitmapIndex(dimension);\n-      return bitmapResultFactory.unionDimensionValueBitmaps(getBitmapIterable(bitmapIndex));\n-    } else {\n-      return Filters.matchPredicate(\n-          dimension,\n-          selector,\n-          bitmapResultFactory,\n-          getPredicateFactory().makeStringPredicate()\n-      );\n-    }\n-  }\n-\n-  @Override\n-  public double estimateSelectivity(BitmapIndexSelector indexSelector)\n-  {\n-    if (extractionFn == null) {\n-      final BitmapIndex bitmapIndex = indexSelector.getBitmapIndex(dimension);\n-      return Filters.estimateSelectivity(\n-          bitmapIndex,\n-          IntIteratorUtils.toIntList(getBitmapIndexIterable(bitmapIndex).iterator()),\n-          indexSelector.getNumRows()\n-      );\n-    } else {\n-      return Filters.estimateSelectivity(\n-          dimension,\n-          indexSelector,\n-          getPredicateFactory().makeStringPredicate()\n-      );\n-    }\n-  }\n-\n-  private Iterable<ImmutableBitmap> getBitmapIterable(final BitmapIndex bitmapIndex)\n-  {\n-    return Filters.bitmapsFromIndexes(getBitmapIndexIterable(bitmapIndex), bitmapIndex);\n-  }\n-\n-  private IntIterable getBitmapIndexIterable(final BitmapIndex bitmapIndex)\n-  {\n-    return () -> new IntIterator()\n-    {\n-      final Iterator<String> iterator = values.iterator();\n-\n-      @Override\n-      public boolean hasNext()\n-      {\n-        return iterator.hasNext();\n-      }\n-\n-      @Override\n-      public int nextInt()\n-      {\n-        return bitmapIndex.getIndex(iterator.next());\n-      }\n-    };\n-  }\n-\n-  @Override\n-  public ValueMatcher makeMatcher(ColumnSelectorFactory factory)\n-  {\n-    return Filters.makeValueMatcher(factory, dimension, getPredicateFactory());\n-  }\n-\n-  @Override\n-  public VectorValueMatcher makeVectorMatcher(final VectorColumnSelectorFactory factory)\n-  {\n-    return DimensionHandlerUtils.makeVectorProcessor(\n-        dimension,\n-        VectorValueMatcherColumnProcessorFactory.instance(),\n-        factory\n-    ).makeMatcher(getPredicateFactory());\n-  }\n-\n-  @Override\n-  public boolean canVectorizeMatcher()\n-  {\n-    return true;\n-  }\n-\n-  @Override\n-  public Set<String> getRequiredColumns()\n-  {\n-    return ImmutableSet.of(dimension);\n-  }\n-\n-  @Override\n-  public boolean supportsRequiredColumnRewrite()\n-  {\n-    return true;\n-  }\n-\n-  @Override\n-  public Filter rewriteRequiredColumns(Map<String, String> columnRewrites)\n-  {\n-    String rewriteDimensionTo = columnRewrites.get(dimension);\n-    if (rewriteDimensionTo == null) {\n-      throw new IAE(\"Received a non-applicable rewrite: %s, filter's dimension: %s\", columnRewrites, dimension);\n-    }\n-\n-    return new InFilter(\n-        rewriteDimensionTo,\n-        values,\n-        longPredicateSupplier,\n-        floatPredicateSupplier,\n-        doublePredicateSupplier,\n-        extractionFn,\n-        filterTuning\n-    );\n-  }\n-\n-  @Override\n-  public boolean supportsBitmapIndex(BitmapIndexSelector selector)\n-  {\n-    return selector.getBitmapIndex(dimension) != null;\n-  }\n-\n-  @Override\n-  public boolean shouldUseBitmapIndex(BitmapIndexSelector selector)\n-  {\n-    return Filters.shouldUseBitmapIndex(this, selector, filterTuning);\n-  }\n-\n-  @Override\n-  public boolean supportsSelectivityEstimation(ColumnSelector columnSelector, BitmapIndexSelector indexSelector)\n-  {\n-    return Filters.supportsSelectivityEstimation(this, dimension, columnSelector, indexSelector);\n-  }\n-\n-  private DruidPredicateFactory getPredicateFactory()\n-  {\n-    return new InFilterDruidPredicateFactory(extractionFn, values, longPredicateSupplier, floatPredicateSupplier, doublePredicateSupplier);\n-  }\n-\n-  @Override\n-  public boolean equals(Object o)\n-  {\n-    if (this == o) {\n-      return true;\n-    }\n-    if (o == null || getClass() != o.getClass()) {\n-      return false;\n-    }\n-    InFilter inFilter = (InFilter) o;\n-    return Objects.equals(dimension, inFilter.dimension) &&\n-           Objects.equals(values, inFilter.values) &&\n-           Objects.equals(extractionFn, inFilter.extractionFn) &&\n-           Objects.equals(filterTuning, inFilter.filterTuning);\n-  }\n-\n-  @Override\n-  public int hashCode()\n-  {\n-    return Objects.hash(dimension, values, extractionFn, filterTuning);\n-  }\n-\n-  @VisibleForTesting\n-  static class InFilterDruidPredicateFactory implements DruidPredicateFactory\n-  {\n-    private final ExtractionFn extractionFn;\n-    private final Set<String> values;\n-    private final Supplier<DruidLongPredicate> longPredicateSupplier;\n-    private final Supplier<DruidFloatPredicate> floatPredicateSupplier;\n-    private final Supplier<DruidDoublePredicate> doublePredicateSupplier;\n-\n-    InFilterDruidPredicateFactory(\n-        ExtractionFn extractionFn,\n-        Set<String> values,\n-        Supplier<DruidLongPredicate> longPredicateSupplier,\n-        Supplier<DruidFloatPredicate> floatPredicateSupplier,\n-        Supplier<DruidDoublePredicate> doublePredicateSupplier\n-    )\n-    {\n-      this.extractionFn = extractionFn;\n-      this.values = values;\n-      this.longPredicateSupplier = longPredicateSupplier;\n-      this.floatPredicateSupplier = floatPredicateSupplier;\n-      this.doublePredicateSupplier = doublePredicateSupplier;\n-    }\n-\n-    @Override\n-    public Predicate<String> makeStringPredicate()\n-    {\n-      if (extractionFn != null) {\n-        return input -> values.contains(extractionFn.apply(input));\n-      } else {\n-        return input -> values.contains(input);\n-      }\n-    }\n-\n-    @Override\n-    public DruidLongPredicate makeLongPredicate()\n-    {\n-      if (extractionFn != null) {\n-        return input -> values.contains(extractionFn.apply(input));\n-      } else {\n-        return longPredicateSupplier.get();\n-      }\n-    }\n-\n-    @Override\n-    public DruidFloatPredicate makeFloatPredicate()\n-    {\n-      if (extractionFn != null) {\n-        return input -> values.contains(extractionFn.apply(input));\n-      } else {\n-        return floatPredicateSupplier.get();\n-      }\n-    }\n-\n-    @Override\n-    public DruidDoublePredicate makeDoublePredicate()\n-    {\n-      if (extractionFn != null) {\n-        return input -> values.contains(extractionFn.apply(input));\n-      }\n-      return input -> doublePredicateSupplier.get().applyDouble(input);\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      InFilterDruidPredicateFactory that = (InFilterDruidPredicateFactory) o;\n-      return Objects.equals(extractionFn, that.extractionFn) &&\n-             Objects.equals(values, that.values);\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(extractionFn, values);\n-    }\n-  }\n-}\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "75e2051195075c14171d5b8ab7f97abef79e80a0", "committedDate": "2020-03-09 22:50:38 -0700", "message": "Convert array_contains() and array_overlaps() into native filters if possible (#9487)"}, {"oid": "6674d721bcc93ff959ae6d63c3eb71255179363d", "committedDate": "2020-05-06 15:26:36 -0700", "message": "Avoid sorting values in InDimFilter if possible (#9800)"}, {"oid": "16d293d6e0d81963af3b3d468efd658317d91052", "committedDate": "2020-05-08 23:45:35 -0700", "message": "Directly rewrite filters on RHS join columns into LHS equivalents (#9818)"}, {"oid": "b0167295d7c621bfa9722b7203bc7ca08fc76495", "committedDate": "2020-05-13 14:23:04 -0700", "message": "Fail incorrectly constructed join queries (#9830)"}, {"oid": "170031744e8a2ed5fc4c06062df014bcfcfe2e1f", "committedDate": "2020-08-06 18:34:21 -0700", "message": "Combine InDimFilter, InFilter. (#10119)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDg1OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280859", "body": "Similar comment about testing with `EqualsVerifier`", "bodyText": "Similar comment about testing with EqualsVerifier", "bodyHTML": "<p dir=\"auto\">Similar comment about testing with <code>EqualsVerifier</code></p>", "author": "ccaominh", "createdAt": "2020-02-03T18:59:53Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/OrFilter.java", "diffHunk": "@@ -218,4 +219,23 @@ public ReadableVectorMatch match(final ReadableVectorMatch mask)\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjY0MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996640", "bodyText": "There was no OrFilterTest class, I added one and an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:15:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDg1OQ=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "40e84a171b8be8e87db20b0c5c189aef1b860f41", "committedDate": "2020-04-05 22:29:41 -0700", "message": "Eliminate common subfilters when converting it to a CNF (#9608)"}, {"oid": "a82910e06532429c90937584db67d663104a0a7d", "committedDate": "2021-01-14 23:28:13 -0800", "message": "OrFilter: Properly handle child matchers that return the original mask. (#10754)"}, {"oid": "8b808c48799b04b53e763fd49c766e1e6a26d1cb", "committedDate": "2021-01-20 08:59:20 -0800", "message": "Retain order of AND, OR filter children. (#10758)"}, {"oid": "4cd4a22f87616ad6b4a722a8a47bad9ce25fa790", "committedDate": "2021-03-16 11:46:50 -0700", "message": "expression filter support for vectorized query engines (#10613)"}, {"oid": "9e5a940cf1fc04b00f9cb0216ec8766d8fed0ee2", "committedDate": "2022-05-11 11:57:08 +0530", "message": "remake column indexes and query processing of filters (#12388)"}, {"oid": "4b1ffbc452831178dccd38456ed9b2cdf2521d13", "committedDate": "2023-03-10 16:42:08 +0530", "message": "Various changes and fixes to UNNEST. (#13892)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MTA0OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374281048", "body": "Similar comment about testing with `EqualsVerifier`", "bodyText": "Similar comment about testing with EqualsVerifier", "bodyHTML": "<p dir=\"auto\">Similar comment about testing with <code>EqualsVerifier</code></p>", "author": "ccaominh", "createdAt": "2020-02-03T19:00:19Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/SelectorFilter.java", "diffHunk": "@@ -127,4 +128,35 @@ public String toString()\n   {\n     return StringUtils.format(\"%s = %s\", dimension, value);\n   }\n+\n+  public String getDimension()\n+  {\n+    return dimension;\n+  }\n+\n+  public String getValue()\n+  {\n+    return value;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjY3MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996670", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:15:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MTA0OA=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "6674d721bcc93ff959ae6d63c3eb71255179363d", "committedDate": "2020-05-06 15:26:36 -0700", "message": "Avoid sorting values in InDimFilter if possible (#9800)"}, {"oid": "16d293d6e0d81963af3b3d468efd658317d91052", "committedDate": "2020-05-08 23:45:35 -0700", "message": "Directly rewrite filters on RHS join columns into LHS equivalents (#9818)"}, {"oid": "6c0c6e60b3604515571db062915767e9550b52cf", "committedDate": "2021-01-29 09:30:09 -0800", "message": "Vectorized theta sketch aggregator + rework of VectorColumnProcessorFactory. (#10767)"}, {"oid": "4cd4a22f87616ad6b4a722a8a47bad9ce25fa790", "committedDate": "2021-03-16 11:46:50 -0700", "message": "expression filter support for vectorized query engines (#10613)"}, {"oid": "9e5a940cf1fc04b00f9cb0216ec8766d8fed0ee2", "committedDate": "2022-05-11 11:57:08 +0530", "message": "remake column indexes and query processing of filters (#12388)"}, {"oid": "18937ffee210fb230737aac20e48ede9601b8096", "committedDate": "2022-06-17 15:29:23 -0700", "message": "split out null value index (#12627)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwNTgwNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374305806", "body": "Maybe use `Collections.singletonList()` instead", "bodyText": "Maybe use Collections.singletonList() instead", "bodyHTML": "<p dir=\"auto\">Maybe use <code>Collections.singletonList()</code> instead</p>", "author": "ccaominh", "createdAt": "2020-02-03T19:50:56Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjcyNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996725", "bodyText": "Changed to Collections.singletonList()", "author": "jon-wei", "createdAt": "2020-02-05T00:15:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwNTgwNg=="}], "type": "inlineReview", "revised_code": {"commit": "2150436af7691541d0462c39a9caa5e9a46e5c29", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c44a3eca23 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n", "chunk": "@@ -83,8 +92,7 @@ public class JoinFilterAnalyzer\n     if (normalizedFilter instanceof AndFilter) {\n       normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n     } else {\n-      normalizedOrClauses = new ArrayList<>();\n-      normalizedOrClauses.add(normalizedFilter);\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n     }\n \n     // Pushdown filters, rewriting if necessary\n", "next_change": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 53%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex c44a3eca23..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -99,7 +111,7 @@ public class JoinFilterAnalyzer\n     List<Filter> leftFilters = new ArrayList<>();\n     List<Filter> rightFilters = new ArrayList<>();\n     List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n-    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+    Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache = new HashMap<>();\n \n     for (Filter orClause : normalizedOrClauses) {\n       JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 51%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -83,28 +108,27 @@ public class JoinFilterAnalyzer\n     if (normalizedFilter instanceof AndFilter) {\n       normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n     } else {\n-      normalizedOrClauses = new ArrayList<>();\n-      normalizedOrClauses.add(normalizedFilter);\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n     }\n \n     // Pushdown filters, rewriting if necessary\n     List<Filter> leftFilters = new ArrayList<>();\n     List<Filter> rightFilters = new ArrayList<>();\n     List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n-    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+    Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache = new HashMap<>();\n \n     for (Filter orClause : normalizedOrClauses) {\n       JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n-          baseAdapter,\n+          hashJoinSegmentStorageAdapter,\n           orClause,\n           prefixes,\n           equiconditions,\n           correlationCache\n       );\n       if (joinFilterAnalysis.isCanPushDown()) {\n-        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n-        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n-          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        leftFilters.add(joinFilterAnalysis.getPushDownFilter().get());\n+        if (!joinFilterAnalysis.getPushDownVirtualColumns().isEmpty()) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushDownVirtualColumns());\n         }\n       }\n       if (joinFilterAnalysis.isRetainAfterJoin()) {\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwODM2MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374308360", "body": "Similar comment about testing with `EqualsVerifier`", "bodyText": "Similar comment about testing with EqualsVerifier", "bodyHTML": "<p dir=\"auto\">Similar comment about testing with <code>EqualsVerifier</code></p>", "author": "ccaominh", "createdAt": "2020-02-03T19:56:02Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5Njg1Ng==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996856", "bodyText": "Added an EqualsVerifier test in the new JoinFilterAnalyzerTest class", "author": "jon-wei", "createdAt": "2020-02-05T00:15:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwODM2MA=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 52%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -113,91 +133,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n-\n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n \n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 51%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -113,91 +137,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n-\n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n \n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMDEzNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374310135", "body": "Can `AllNullColumnSelectorFactory` be made a private class variable so it does not need to be allocated each time?", "bodyText": "Can AllNullColumnSelectorFactory be made a private class variable so it does not need to be allocated each time?", "bodyHTML": "<p dir=\"auto\">Can <code>AllNullColumnSelectorFactory</code> be made a private class variable so it does not need to be allocated each time?</p>", "author": "ccaominh", "createdAt": "2020-02-03T19:59:22Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param filter           Filter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      Filter filter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    assert (filter instanceof SelectorFilter);\n+    SelectorFilter selectorFilter = (SelectorFilter) filter;\n+\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            filter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filter,\n+        filter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;\n+          if (adapter.isBaseColumn(identifier)) {\n+            terminate = true;\n+            correlatedBaseColumns.add(findMappingFor);\n+          }\n+        }\n+      }\n+\n+      if (correlatedBaseColumns.isEmpty() && correlatedBaseExpressions.isEmpty()) {\n+        return null;\n+      }\n+\n+      correlations.add(\n+          new JoinFilterColumnCorrelationAnalysis(\n+              rhsColumn,\n+              correlatedBaseColumns,\n+              correlatedBaseExpressions\n+          )\n+      );\n+    }\n+\n+    return correlations;\n+  }\n+\n+  private static boolean filterMatchesNull(Filter filter)\n+  {\n+    ValueMatcher valueMatcher = filter.makeMatcher(new AllNullColumnSelectorFactory());", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzA2Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997063", "bodyText": "Whoops, made a private static AllNullColumnSelectorFactory", "author": "jon-wei", "createdAt": "2020-02-05T00:16:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMDEzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2150436af7691541d0462c39a9caa5e9a46e5c29", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c44a3eca23 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n", "chunk": "@@ -589,7 +597,7 @@ public class JoinFilterAnalyzer\n \n   private static boolean filterMatchesNull(Filter filter)\n   {\n-    ValueMatcher valueMatcher = filter.makeMatcher(new AllNullColumnSelectorFactory());\n+    ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n \n", "next_change": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 53%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex c44a3eca23..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -600,148 +489,4 @@ public class JoinFilterAnalyzer\n     ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n-\n-  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory\n-  {\n-    @Override\n-    public DimensionSelector makeDimensionSelector(DimensionSpec dimensionSpec)\n-    {\n-      return DimensionSelector.constant(null);\n-    }\n-\n-    @Override\n-    public ColumnValueSelector<?> makeColumnValueSelector(String columnName)\n-    {\n-      return NilColumnValueSelector.instance();\n-    }\n-\n-    @Override\n-    public ColumnCapabilities getColumnCapabilities(String columnName)\n-    {\n-      return null;\n-    }\n-  }\n-\n-  /**\n-   * Holds information about:\n-   * - whether a filter can be pushed down\n-   * - if it needs to be retained after the join,\n-   * - a reference to the original filter\n-   * - a potentially rewritten filter to be pushed down to the base table\n-   * - a list of virtual columns that need to be created on the base table to support the pushed down filter\n-   */\n-  private static class JoinFilterAnalysis\n-  {\n-    private final boolean canPushDown;\n-    private final boolean retainAfterJoin;\n-    private final Filter originalFilter;\n-    private final Filter pushdownFilter;\n-    private final List<VirtualColumn> pushdownVirtualColumns;\n-\n-    public JoinFilterAnalysis(\n-        boolean canPushDown,\n-        boolean retainAfterJoin,\n-        Filter originalFilter,\n-        @Nullable Filter pushdownFilter,\n-        @Nullable List<VirtualColumn> pushdownVirtualColumns\n-    )\n-    {\n-      this.canPushDown = canPushDown;\n-      this.retainAfterJoin = retainAfterJoin;\n-      this.originalFilter = originalFilter;\n-      this.pushdownFilter = pushdownFilter;\n-      this.pushdownVirtualColumns = pushdownVirtualColumns;\n-    }\n-\n-    public boolean isCanPushDown()\n-    {\n-      return canPushDown;\n-    }\n-\n-    public boolean isRetainAfterJoin()\n-    {\n-      return retainAfterJoin;\n-    }\n-\n-    public Filter getOriginalFilter()\n-    {\n-      return originalFilter;\n-    }\n-\n-    @Nullable\n-    public Filter getPushdownFilter()\n-    {\n-      return pushdownFilter;\n-    }\n-\n-    @Nullable\n-    public List<VirtualColumn> getPushdownVirtualColumns()\n-    {\n-      return pushdownVirtualColumns;\n-    }\n-\n-    /**\n-     * Utility method for generating an analysis that represents: \"Filter cannot be pushed down\"\n-     *\n-     * @param originalFilter The original filter which cannot be pushed down\n-     *\n-     * @return analysis that represents: \"Filter cannot be pushed down\"\n-     */\n-    public static JoinFilterAnalysis createNoPushdownFilterAnalysis(Filter originalFilter)\n-    {\n-      return new JoinFilterAnalysis(\n-          false,\n-          true,\n-          originalFilter,\n-          null,\n-          null\n-      );\n-    }\n-  }\n-\n-  /**\n-   * Represents an analysis of what base table columns, if any, can be correlated with a column that will\n-   * be filtered on.\n-   * <p>\n-   * For example, if we're joining on a base table via the equiconditions (id = j.id AND f(id2) = j.id2),\n-   * then we can correlate j.id with id (base table column) and j.id2 with f(id2) (a base table expression).\n-   */\n-  private static class JoinFilterColumnCorrelationAnalysis\n-  {\n-    private final String joinColumn;\n-    private final List<String> baseColumns;\n-    private final List<Expr> baseExpressions;\n-\n-    public JoinFilterColumnCorrelationAnalysis(\n-        String joinColumn,\n-        List<String> baseColumns,\n-        List<Expr> baseExpressions\n-    )\n-    {\n-      this.joinColumn = joinColumn;\n-      this.baseColumns = baseColumns;\n-      this.baseExpressions = baseExpressions;\n-    }\n-\n-    public String getJoinColumn()\n-    {\n-      return joinColumn;\n-    }\n-\n-    public List<String> getBaseColumns()\n-    {\n-      return baseColumns;\n-    }\n-\n-    public List<Expr> getBaseExpressions()\n-    {\n-      return baseExpressions;\n-    }\n-\n-    public boolean supportsPushDown()\n-    {\n-      return !baseColumns.isEmpty() || !baseExpressions.isEmpty();\n-    }\n-  }\n-\n }\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 51%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -584,156 +510,12 @@ public class JoinFilterAnalyzer\n       );\n     }\n \n-    return correlations;\n+    return Optional.of(correlations);\n   }\n \n   private static boolean filterMatchesNull(Filter filter)\n   {\n-    ValueMatcher valueMatcher = filter.makeMatcher(new AllNullColumnSelectorFactory());\n+    ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n-\n-  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory\n-  {\n-    @Override\n-    public DimensionSelector makeDimensionSelector(DimensionSpec dimensionSpec)\n-    {\n-      return DimensionSelector.constant(null);\n-    }\n-\n-    @Override\n-    public ColumnValueSelector<?> makeColumnValueSelector(String columnName)\n-    {\n-      return NilColumnValueSelector.instance();\n-    }\n-\n-    @Override\n-    public ColumnCapabilities getColumnCapabilities(String columnName)\n-    {\n-      return null;\n-    }\n-  }\n-\n-  /**\n-   * Holds information about:\n-   * - whether a filter can be pushed down\n-   * - if it needs to be retained after the join,\n-   * - a reference to the original filter\n-   * - a potentially rewritten filter to be pushed down to the base table\n-   * - a list of virtual columns that need to be created on the base table to support the pushed down filter\n-   */\n-  private static class JoinFilterAnalysis\n-  {\n-    private final boolean canPushDown;\n-    private final boolean retainAfterJoin;\n-    private final Filter originalFilter;\n-    private final Filter pushdownFilter;\n-    private final List<VirtualColumn> pushdownVirtualColumns;\n-\n-    public JoinFilterAnalysis(\n-        boolean canPushDown,\n-        boolean retainAfterJoin,\n-        Filter originalFilter,\n-        @Nullable Filter pushdownFilter,\n-        @Nullable List<VirtualColumn> pushdownVirtualColumns\n-    )\n-    {\n-      this.canPushDown = canPushDown;\n-      this.retainAfterJoin = retainAfterJoin;\n-      this.originalFilter = originalFilter;\n-      this.pushdownFilter = pushdownFilter;\n-      this.pushdownVirtualColumns = pushdownVirtualColumns;\n-    }\n-\n-    public boolean isCanPushDown()\n-    {\n-      return canPushDown;\n-    }\n-\n-    public boolean isRetainAfterJoin()\n-    {\n-      return retainAfterJoin;\n-    }\n-\n-    public Filter getOriginalFilter()\n-    {\n-      return originalFilter;\n-    }\n-\n-    @Nullable\n-    public Filter getPushdownFilter()\n-    {\n-      return pushdownFilter;\n-    }\n-\n-    @Nullable\n-    public List<VirtualColumn> getPushdownVirtualColumns()\n-    {\n-      return pushdownVirtualColumns;\n-    }\n-\n-    /**\n-     * Utility method for generating an analysis that represents: \"Filter cannot be pushed down\"\n-     *\n-     * @param originalFilter The original filter which cannot be pushed down\n-     *\n-     * @return analysis that represents: \"Filter cannot be pushed down\"\n-     */\n-    public static JoinFilterAnalysis createNoPushdownFilterAnalysis(Filter originalFilter)\n-    {\n-      return new JoinFilterAnalysis(\n-          false,\n-          true,\n-          originalFilter,\n-          null,\n-          null\n-      );\n-    }\n-  }\n-\n-  /**\n-   * Represents an analysis of what base table columns, if any, can be correlated with a column that will\n-   * be filtered on.\n-   * <p>\n-   * For example, if we're joining on a base table via the equiconditions (id = j.id AND f(id2) = j.id2),\n-   * then we can correlate j.id with id (base table column) and j.id2 with f(id2) (a base table expression).\n-   */\n-  private static class JoinFilterColumnCorrelationAnalysis\n-  {\n-    private final String joinColumn;\n-    private final List<String> baseColumns;\n-    private final List<Expr> baseExpressions;\n-\n-    public JoinFilterColumnCorrelationAnalysis(\n-        String joinColumn,\n-        List<String> baseColumns,\n-        List<Expr> baseExpressions\n-    )\n-    {\n-      this.joinColumn = joinColumn;\n-      this.baseColumns = baseColumns;\n-      this.baseExpressions = baseExpressions;\n-    }\n-\n-    public String getJoinColumn()\n-    {\n-      return joinColumn;\n-    }\n-\n-    public List<String> getBaseColumns()\n-    {\n-      return baseColumns;\n-    }\n-\n-    public List<Expr> getBaseExpressions()\n-    {\n-      return baseExpressions;\n-    }\n-\n-    public boolean supportsPushDown()\n-    {\n-      return !baseColumns.isEmpty() || !baseExpressions.isEmpty();\n-    }\n-  }\n-\n }\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjExMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374312112", "body": "Would you still need this if `JoinFilterAnalyzerTest` was created and had unit tests for `JoinFilterAnalyzer`?", "bodyText": "Would you still need this if JoinFilterAnalyzerTest was created and had unit tests for JoinFilterAnalyzer?", "bodyHTML": "<p dir=\"auto\">Would you still need this if <code>JoinFilterAnalyzerTest</code> was created and had unit tests for <code>JoinFilterAnalyzer</code>?</p>", "author": "ccaominh", "createdAt": "2020-02-03T20:03:25Z", "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java", "diffHunk": "@@ -52,6 +54,11 @@\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n \n+  // A reference to the last JoinFilterSplit created during a makeCursors call,\n+  // saved and exposed so that tests can verify the filter splitting behavior.\n+  @VisibleForTesting\n+  private JoinFilterAnalyzer.JoinFilterSplit previousJoinFilterSplitForTesting;", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5ODAyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374998023", "bodyText": "I restructured the tests in JoinFilterAnalyzerTest to call JoinFilterAnalyzer.splitFilter directly, and got rid of this testing hook.\nThis means the filter split would be calculated twice in the tests (since I still call verifyCursors later), but I think that's fine for tests.", "author": "jon-wei", "createdAt": "2020-02-05T00:20:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjExMg=="}], "type": "inlineReview", "revised_code": {"commit": "2150436af7691541d0462c39a9caa5e9a46e5c29", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex f016b73bd3..2f7d1ac588 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -54,11 +52,6 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n \n-  // A reference to the last JoinFilterSplit created during a makeCursors call,\n-  // saved and exposed so that tests can verify the filter splitting behavior.\n-  @VisibleForTesting\n-  private JoinFilterAnalyzer.JoinFilterSplit previousJoinFilterSplitForTesting;\n-\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n       List<JoinableClause> clauses\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex f016b73bd3..b269ec216e 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -54,11 +54,6 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n \n-  // A reference to the last JoinFilterSplit created during a makeCursors call,\n-  // saved and exposed so that tests can verify the filter splitting behavior.\n-  @VisibleForTesting\n-  private JoinFilterAnalyzer.JoinFilterSplit previousJoinFilterSplitForTesting;\n-\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n       List<JoinableClause> clauses\n", "next_change": {"commit": "b2c00b3a791555e35d2ac92d35e02aafe5c09721", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex b269ec216e..d378849148 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -53,6 +54,7 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n+  private final boolean enableFilterPushDown;\n \n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n", "next_change": {"commit": "5ce9c81b6823a2c2aa647ca382bb62563d0b2462", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex d378849148..932da6ff4b 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -56,25 +57,30 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n   private final List<JoinableClause> clauses;\n   private final boolean enableFilterPushDown;\n \n+  /**\n+   * @param baseAdapter A StorageAdapter for the left-hand side base segment\n+   * @param clauses The right-hand side clauses. The caller is responsible for ensuring that there are no\n+   *                duplicate prefixes or prefixes that shadow each other across the clauses\n+   * @param enableFilterPushDown Whether to enable filter push down optimizations to the base segment\n+   */\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses\n+      List<JoinableClause> clauses,\n+      final boolean enableFilterPushDown\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.enableFilterPushDown = QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN;\n+    this.enableFilterPushDown = enableFilterPushDown;\n   }\n \n+  @VisibleForTesting\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses,\n-      final boolean enableFilterPushDown\n+      List<JoinableClause> clauses\n   )\n   {\n-    this.baseAdapter = baseAdapter;\n-    this.clauses = clauses;\n-    this.enableFilterPushDown = enableFilterPushDown;\n+    this(baseAdapter, clauses, QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN);\n   }\n \n   @Override\n", "next_change": {"commit": "0136dba95d5271027b2ee0d0266a8a66fe88d4ca", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex 932da6ff4b..f590099533 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -80,7 +83,12 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n       List<JoinableClause> clauses\n   )\n   {\n-    this(baseAdapter, clauses, QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN);\n+    this(\n+        baseAdapter,\n+        clauses,\n+        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN,\n+        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE\n+    );\n   }\n \n   @Override\n", "next_change": {"commit": "b1847364b0816cfc3c2ac376cd888033a06fb93f", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex f590099533..40ed7fe627 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -55,40 +54,22 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n-  private final boolean enableFilterPushDown;\n-  private final boolean enableFilterRewrite;\n+  private final JoinFilterPreAnalysis joinFilterPreAnalysis;\n \n   /**\n    * @param baseAdapter          A StorageAdapter for the left-hand side base segment\n    * @param clauses              The right-hand side clauses. The caller is responsible for ensuring that there are no\n    *                             duplicate prefixes or prefixes that shadow each other across the clauses\n-   * @param enableFilterPushDown Whether to enable filter push down optimizations to the base segment\n    */\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n       List<JoinableClause> clauses,\n-      final boolean enableFilterPushDown,\n-      final boolean enableFilterRewrite\n+      final JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.enableFilterPushDown = enableFilterPushDown;\n-    this.enableFilterRewrite = enableFilterRewrite;\n-  }\n-\n-  @VisibleForTesting\n-  HashJoinSegmentStorageAdapter(\n-      StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses\n-  )\n-  {\n-    this(\n-        baseAdapter,\n-        clauses,\n-        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN,\n-        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE\n-    );\n+    this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n   }\n \n   @Override\n", "next_change": {"commit": "37e150c0755c0efba609601b1122cd6bc8a271fb", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex 40ed7fe627..8e2518e5cc 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -54,22 +54,23 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n-  private final JoinFilterPreAnalysis joinFilterPreAnalysis;\n+  private final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup;\n \n   /**\n    * @param baseAdapter          A StorageAdapter for the left-hand side base segment\n    * @param clauses              The right-hand side clauses. The caller is responsible for ensuring that there are no\n-   *                             duplicate prefixes or prefixes that shadow each other across the clauses\n+   * @param joinFilterPreAnalysisGroup Pre-analysis group that holds all of the JoinFilterPreAnalysis results within\n+   *                                   the scope of a query\n    */\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n       List<JoinableClause> clauses,\n-      final JoinFilterPreAnalysis joinFilterPreAnalysis\n+      final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n+    this.joinFilterPreAnalysisGroup = joinFilterPreAnalysisGroup;\n   }\n \n   @Override\n", "next_change": {"commit": "5faa897a342096b2ac88587ad62e6e15022b01dd", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex 8e2518e5cc..e23a2d4df2 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -54,23 +55,22 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n-  private final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup;\n+  private final JoinFilterPreAnalysis joinFilterPreAnalysis;\n \n   /**\n-   * @param baseAdapter          A StorageAdapter for the left-hand side base segment\n-   * @param clauses              The right-hand side clauses. The caller is responsible for ensuring that there are no\n-   * @param joinFilterPreAnalysisGroup Pre-analysis group that holds all of the JoinFilterPreAnalysis results within\n-   *                                   the scope of a query\n+   * @param baseAdapter           A StorageAdapter for the left-hand side base segment\n+   * @param clauses               The right-hand side clauses. The caller is responsible for ensuring that there are no\n+   * @param joinFilterPreAnalysis Pre-analysis for the query we expect to run on this storage adapter\n    */\n   HashJoinSegmentStorageAdapter(\n-      StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses,\n-      final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup\n+      final StorageAdapter baseAdapter,\n+      final List<JoinableClause> clauses,\n+      final JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.joinFilterPreAnalysisGroup = joinFilterPreAnalysisGroup;\n+    this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n   }\n \n   @Override\n", "next_change": {"commit": "1a15987432fab044fc83a99af8ab497d887aeda1", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex e23a2d4df2..7d3cde3236 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -67,8 +70,25 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n       final List<JoinableClause> clauses,\n       final JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n+  {\n+    this(baseAdapter, null, clauses, joinFilterPreAnalysis);\n+  }\n+\n+  /**\n+   * @param baseAdapter           A StorageAdapter for the left-hand side base segment\n+   * @param baseFilter            A filter for the left-hand side base segment\n+   * @param clauses               The right-hand side clauses. The caller is responsible for ensuring that there are no\n+   * @param joinFilterPreAnalysis Pre-analysis for the query we expect to run on this storage adapter\n+   */\n+  HashJoinSegmentStorageAdapter(\n+      final StorageAdapter baseAdapter,\n+      final Filter baseFilter,\n+      final List<JoinableClause> clauses,\n+      final JoinFilterPreAnalysis joinFilterPreAnalysis\n+  )\n   {\n     this.baseAdapter = baseAdapter;\n+    this.baseFilter = baseFilter;\n     this.clauses = clauses;\n     this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n   }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex b269ec216e..d378849148 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -61,6 +63,18 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n+    this.enableFilterPushDown = QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN;\n+  }\n+\n+  HashJoinSegmentStorageAdapter(\n+      StorageAdapter baseAdapter,\n+      List<JoinableClause> clauses,\n+      final boolean enableFilterPushDown\n+  )\n+  {\n+    this.baseAdapter = baseAdapter;\n+    this.clauses = clauses;\n+    this.enableFilterPushDown = enableFilterPushDown;\n   }\n \n   @Override\n", "next_change": {"commit": "5ce9c81b6823a2c2aa647ca382bb62563d0b2462", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex d378849148..932da6ff4b 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -56,25 +57,30 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n   private final List<JoinableClause> clauses;\n   private final boolean enableFilterPushDown;\n \n+  /**\n+   * @param baseAdapter A StorageAdapter for the left-hand side base segment\n+   * @param clauses The right-hand side clauses. The caller is responsible for ensuring that there are no\n+   *                duplicate prefixes or prefixes that shadow each other across the clauses\n+   * @param enableFilterPushDown Whether to enable filter push down optimizations to the base segment\n+   */\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses\n+      List<JoinableClause> clauses,\n+      final boolean enableFilterPushDown\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.enableFilterPushDown = QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN;\n+    this.enableFilterPushDown = enableFilterPushDown;\n   }\n \n+  @VisibleForTesting\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses,\n-      final boolean enableFilterPushDown\n+      List<JoinableClause> clauses\n   )\n   {\n-    this.baseAdapter = baseAdapter;\n-    this.clauses = clauses;\n-    this.enableFilterPushDown = enableFilterPushDown;\n+    this(baseAdapter, clauses, QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN);\n   }\n \n   @Override\n", "next_change": {"commit": "0136dba95d5271027b2ee0d0266a8a66fe88d4ca", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex 932da6ff4b..f590099533 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -80,7 +83,12 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n       List<JoinableClause> clauses\n   )\n   {\n-    this(baseAdapter, clauses, QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN);\n+    this(\n+        baseAdapter,\n+        clauses,\n+        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN,\n+        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE\n+    );\n   }\n \n   @Override\n", "next_change": {"commit": "b1847364b0816cfc3c2ac376cd888033a06fb93f", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex f590099533..40ed7fe627 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -55,40 +54,22 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n-  private final boolean enableFilterPushDown;\n-  private final boolean enableFilterRewrite;\n+  private final JoinFilterPreAnalysis joinFilterPreAnalysis;\n \n   /**\n    * @param baseAdapter          A StorageAdapter for the left-hand side base segment\n    * @param clauses              The right-hand side clauses. The caller is responsible for ensuring that there are no\n    *                             duplicate prefixes or prefixes that shadow each other across the clauses\n-   * @param enableFilterPushDown Whether to enable filter push down optimizations to the base segment\n    */\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n       List<JoinableClause> clauses,\n-      final boolean enableFilterPushDown,\n-      final boolean enableFilterRewrite\n+      final JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.enableFilterPushDown = enableFilterPushDown;\n-    this.enableFilterRewrite = enableFilterRewrite;\n-  }\n-\n-  @VisibleForTesting\n-  HashJoinSegmentStorageAdapter(\n-      StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses\n-  )\n-  {\n-    this(\n-        baseAdapter,\n-        clauses,\n-        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_PUSH_DOWN,\n-        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE\n-    );\n+    this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n   }\n \n   @Override\n", "next_change": {"commit": "37e150c0755c0efba609601b1122cd6bc8a271fb", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex 40ed7fe627..8e2518e5cc 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -54,22 +54,23 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n-  private final JoinFilterPreAnalysis joinFilterPreAnalysis;\n+  private final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup;\n \n   /**\n    * @param baseAdapter          A StorageAdapter for the left-hand side base segment\n    * @param clauses              The right-hand side clauses. The caller is responsible for ensuring that there are no\n-   *                             duplicate prefixes or prefixes that shadow each other across the clauses\n+   * @param joinFilterPreAnalysisGroup Pre-analysis group that holds all of the JoinFilterPreAnalysis results within\n+   *                                   the scope of a query\n    */\n   HashJoinSegmentStorageAdapter(\n       StorageAdapter baseAdapter,\n       List<JoinableClause> clauses,\n-      final JoinFilterPreAnalysis joinFilterPreAnalysis\n+      final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n+    this.joinFilterPreAnalysisGroup = joinFilterPreAnalysisGroup;\n   }\n \n   @Override\n", "next_change": {"commit": "5faa897a342096b2ac88587ad62e6e15022b01dd", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex 8e2518e5cc..e23a2d4df2 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -54,23 +55,22 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n {\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n-  private final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup;\n+  private final JoinFilterPreAnalysis joinFilterPreAnalysis;\n \n   /**\n-   * @param baseAdapter          A StorageAdapter for the left-hand side base segment\n-   * @param clauses              The right-hand side clauses. The caller is responsible for ensuring that there are no\n-   * @param joinFilterPreAnalysisGroup Pre-analysis group that holds all of the JoinFilterPreAnalysis results within\n-   *                                   the scope of a query\n+   * @param baseAdapter           A StorageAdapter for the left-hand side base segment\n+   * @param clauses               The right-hand side clauses. The caller is responsible for ensuring that there are no\n+   * @param joinFilterPreAnalysis Pre-analysis for the query we expect to run on this storage adapter\n    */\n   HashJoinSegmentStorageAdapter(\n-      StorageAdapter baseAdapter,\n-      List<JoinableClause> clauses,\n-      final JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup\n+      final StorageAdapter baseAdapter,\n+      final List<JoinableClause> clauses,\n+      final JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n     this.baseAdapter = baseAdapter;\n     this.clauses = clauses;\n-    this.joinFilterPreAnalysisGroup = joinFilterPreAnalysisGroup;\n+    this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n   }\n \n   @Override\n", "next_change": {"commit": "1a15987432fab044fc83a99af8ab497d887aeda1", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\nindex e23a2d4df2..7d3cde3236 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java\n", "chunk": "@@ -67,8 +70,25 @@ public class HashJoinSegmentStorageAdapter implements StorageAdapter\n       final List<JoinableClause> clauses,\n       final JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n+  {\n+    this(baseAdapter, null, clauses, joinFilterPreAnalysis);\n+  }\n+\n+  /**\n+   * @param baseAdapter           A StorageAdapter for the left-hand side base segment\n+   * @param baseFilter            A filter for the left-hand side base segment\n+   * @param clauses               The right-hand side clauses. The caller is responsible for ensuring that there are no\n+   * @param joinFilterPreAnalysis Pre-analysis for the query we expect to run on this storage adapter\n+   */\n+  HashJoinSegmentStorageAdapter(\n+      final StorageAdapter baseAdapter,\n+      final Filter baseFilter,\n+      final List<JoinableClause> clauses,\n+      final JoinFilterPreAnalysis joinFilterPreAnalysis\n+  )\n   {\n     this.baseAdapter = baseAdapter;\n+    this.baseFilter = baseFilter;\n     this.clauses = clauses;\n     this.joinFilterPreAnalysis = joinFilterPreAnalysis;\n   }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "b2c00b3a791555e35d2ac92d35e02aafe5c09721", "committedDate": "2020-02-11 15:31:34 -0800", "message": "Add query context option to disable join filter push down (#9335)"}, {"oid": "cab08f941d28266a65a39bd62e7e9487067573b1", "committedDate": "2020-02-19 15:51:05 -0800", "message": "Fix join filter push down post-join virtual column handling (#9373)"}, {"oid": "5ce9c81b6823a2c2aa647ca382bb62563d0b2462", "committedDate": "2020-02-25 18:17:23 -0800", "message": "Add join prefix duplicate/shadowing check (#9384)"}, {"oid": "ef3d24e88668c150f65b844574cad665b6d498c4", "committedDate": "2020-02-26 22:07:33 -0800", "message": "Add javadocs for enableFilterPushDown. (#9423)"}, {"oid": "0136dba95d5271027b2ee0d0266a8a66fe88d4ca", "committedDate": "2020-03-09 17:36:07 -0700", "message": "Add option to control join filter rewrites (#9472)"}, {"oid": "b1847364b0816cfc3c2ac376cd888033a06fb93f", "committedDate": "2020-03-16 22:16:14 -0700", "message": "More efficient join filter rewrites (#9516)"}, {"oid": "0ff926b1a1367be88fb6f5f4baaa74ca849bd8bf", "committedDate": "2020-04-11 01:18:11 -0700", "message": "fix issue with group by limit pushdown for extractionFn, expressions, joins, etc (#9662)"}, {"oid": "7510e6e722fa3829d809e7151b870ebcf947194c", "committedDate": "2020-04-29 11:03:13 -0700", "message": "Fix potential NPEs in joins (#9760)"}, {"oid": "b0167295d7c621bfa9722b7203bc7ca08fc76495", "committedDate": "2020-05-13 14:23:04 -0700", "message": "Fail incorrectly constructed join queries (#9830)"}, {"oid": "37e150c0755c0efba609601b1122cd6bc8a271fb", "committedDate": "2020-06-18 21:32:29 -0700", "message": "Fix join filter rewrites with nested queries (#10015)"}, {"oid": "5faa897a342096b2ac88587ad62e6e15022b01dd", "committedDate": "2020-06-30 19:14:22 -0700", "message": "Join filter pre-analysis simplifications and sanity checks. (#10104)"}, {"oid": "170031744e8a2ed5fc4c06062df014bcfcfe2e1f", "committedDate": "2020-08-06 18:34:21 -0700", "message": "Combine InDimFilter, InFilter. (#10119)"}, {"oid": "7620b0c54e31ed466adf149b2b7fbd815c4c70ce", "committedDate": "2020-08-20 14:12:39 -0700", "message": "Segment backed broadcast join IndexedTable (#10224)"}, {"oid": "567e38170500d3649cbfaa28cf7aa6f5275d02e7", "committedDate": "2020-10-12 13:04:55 -0700", "message": "Any virtual column on \"__time\" should be a pre-join virtual column (#10451)"}, {"oid": "1a15987432fab044fc83a99af8ab497d887aeda1", "committedDate": "2021-03-04 10:39:21 -0800", "message": "Supporting filters in the left base table for join datasources (#10697)"}, {"oid": "c66951a59e2963369bbb447dba51ea7651a1cdb1", "committedDate": "2021-03-09 13:07:34 -0800", "message": "Add flag in SQL to disable left base filter optimization for joins (#10947)"}, {"oid": "202c78c8f32bd3ec5e70e021b1494d878f38d678", "committedDate": "2021-04-14 10:49:27 -0700", "message": "Enable rewriting certain inner joins as filters. (#11068)"}, {"oid": "8ba7f6a48c95074a6632b14fa93447487923b18c", "committedDate": "2021-07-31 15:55:49 -0700", "message": "Fix incorrect result of exact topN on an inner join with limit (#11517)"}, {"oid": "187df58e303c9338e7c2e107d7725b4638404bb1", "committedDate": "2021-10-19 01:47:25 -0700", "message": "better types (#11713)"}, {"oid": "6c196a5ea2100b5b5c5e81fe75b30ad5d3a63f83", "committedDate": "2021-11-09 15:18:07 -0800", "message": "Remove StorageAdapter.getColumnTypeName. (#11893)"}, {"oid": "5e168b861a333c68141cacceca155b280fdc427a", "committedDate": "2021-11-24 13:14:25 -0800", "message": "StorageAdapter: Add getRowSignature method. (#11953)"}, {"oid": "af700bba0c8408d63de7374d77f681bf8fdeb2f7", "committedDate": "2022-08-13 16:26:24 +0530", "message": "Fix hasBuiltInFilters for joins (#12894)"}, {"oid": "4b1ffbc452831178dccd38456ed9b2cdf2521d13", "committedDate": "2023-03-10 16:42:08 +0530", "message": "Various changes and fixes to UNNEST. (#13892)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjc1OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374312758", "body": "Can remove since this method never returns `null`", "bodyText": "Can remove since this method never returns null", "bodyHTML": "<p dir=\"auto\">Can remove since this method never returns <code>null</code></p>", "author": "ccaominh", "createdAt": "2020-02-03T20:04:48Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzcyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997723", "bodyText": "Removed the unnecessary @Nullable", "author": "jon-wei", "createdAt": "2020-02-05T00:19:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjc1OA=="}], "type": "inlineReview", "revised_code": {"commit": "b31fbddcd678b5f9faf705a2def1864072188929", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..2a83d8133f 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n", "chunk": "@@ -261,7 +269,6 @@ public class JoinFilterAnalyzer\n    *\n    * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n    */\n-  @Nullable\n   private static JoinFilterAnalysis rewriteOrFilter(\n       HashJoinSegmentStorageAdapter adapter,\n       OrFilter orFilter,\n", "next_change": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -265,7 +210,8 @@ public class JoinFilterAnalyzer\n    * @param orFilter         OrFilter to be rewritten\n    * @param prefixes         Map of table prefixes to clauses\n    * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Column correlation analysis cache\n+   * @param correlationCache Column correlation analysis cache. This will be potentially modified by adding\n+   *                         any new column correlation analyses to the cache.\n    *\n    * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n    */\n", "next_change": null}, {"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -274,7 +220,7 @@ public class JoinFilterAnalyzer\n       OrFilter orFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     boolean retainRhs = false;\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 51%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -257,17 +214,17 @@ public class JoinFilterAnalyzer\n    * @param orFilter         OrFilter to be rewritten\n    * @param prefixes         Map of table prefixes to clauses\n    * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Column correlation analysis cache\n+   * @param correlationCache Column correlation analysis cache. This will be potentially modified by adding\n+   *                         any new column correlation analyses to the cache.\n    *\n    * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n    */\n-  @Nullable\n   private static JoinFilterAnalysis rewriteOrFilter(\n       HashJoinSegmentStorageAdapter adapter,\n       OrFilter orFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     boolean retainRhs = false;\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDM4MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374314381", "body": "Can `rewriteSelectorFilter`'s `filter` parameter be of type `SelectorFilter` instead?", "bodyText": "Can rewriteSelectorFilter's filter parameter be of type SelectorFilter instead?", "bodyHTML": "<p dir=\"auto\">Can <code>rewriteSelectorFilter</code>'s <code>filter</code> parameter be of type <code>SelectorFilter</code> instead?</p>", "author": "ccaominh", "createdAt": "2020-02-03T20:08:22Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param filter           Filter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      Filter filter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    assert (filter instanceof SelectorFilter);\n+    SelectorFilter selectorFilter = (SelectorFilter) filter;", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzUzNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997535", "bodyText": "Changed to SelectorFilter", "author": "jon-wei", "createdAt": "2020-02-05T00:18:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDM4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "b31fbddcd678b5f9faf705a2def1864072188929", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..2a83d8133f 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n", "chunk": "@@ -326,15 +333,12 @@ public class JoinFilterAnalyzer\n    */\n   private static JoinFilterAnalysis rewriteSelectorFilter(\n       HashJoinSegmentStorageAdapter baseAdapter,\n-      Filter filter,\n+      SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n       Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n   )\n   {\n-    assert (filter instanceof SelectorFilter);\n-    SelectorFilter selectorFilter = (SelectorFilter) filter;\n-\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n       if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n", "next_change": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -336,13 +282,13 @@ public class JoinFilterAnalyzer\n       SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n-        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n+        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n             prefixAndClause.getKey(),\n             p -> findCorrelatedBaseTableColumns(\n                 baseAdapter,\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 51%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 8bcfc16ab3..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -317,28 +273,26 @@ public class JoinFilterAnalyzer\n    * Rewrites a selector filter on a join table into an IN filter on the base table.\n    *\n    * @param baseAdapter      The adapter for the join\n-   * @param filter           Filter to be rewritten\n+   * @param selectorFilter   SelectorFilter to be rewritten\n    * @param prefixes         Map of join table prefixes to clauses\n    * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses. This will be potentially modified by adding\n+   *                         any new column correlation analyses to the cache.\n    *\n    * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n    */\n   private static JoinFilterAnalysis rewriteSelectorFilter(\n       HashJoinSegmentStorageAdapter baseAdapter,\n-      Filter filter,\n+      SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n-    assert (filter instanceof SelectorFilter);\n-    SelectorFilter selectorFilter = (SelectorFilter) filter;\n-\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n-        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n+        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n             prefixAndClause.getKey(),\n             p -> findCorrelatedBaseTableColumns(\n                 baseAdapter,\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxOTkyOQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374319929", "body": "The test coverage of the filter push down code is great!\r\n\r\nWhat do you think about making many of these test cases as unit tests in `JoinFilterAnalyzerTest` instead? That way it's more straightforward to map the test case to the relevant code.", "bodyText": "The test coverage of the filter push down code is great!\nWhat do you think about making many of these test cases as unit tests in JoinFilterAnalyzerTest instead? That way it's more straightforward to map the test case to the relevant code.", "bodyHTML": "<p dir=\"auto\">The test coverage of the filter push down code is great!</p>\n<p dir=\"auto\">What do you think about making many of these test cases as unit tests in <code>JoinFilterAnalyzerTest</code> instead? That way it's more straightforward to map the test case to the relevant code.</p>", "author": "ccaominh", "createdAt": "2020-02-03T20:20:14Z", "path": "processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java", "diffHunk": "@@ -1288,103 +1313,1163 @@ public void test_makeCursors_errorOnNonKeyBasedJoin()\n     );\n   }\n \n-  private JoinableClause factToCountryNameUsingIsoCodeLookup(final JoinType joinType)\n+  // Filter push down tests", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzQ5Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997493", "bodyText": "Thanks!\nI split out the segment setup and some helper methods out of HashJoinSegmentStorageAdapterTest into BaseHashJoinSegmentStorageAdapterTest since the JoinFilterAnalyzer needs a HashJoinSegmentStorageAdapter, both JoinFilterAnalyzerTest and HashJoinSegmentStorageAdapterTest now extend the base.\nThe filter push down tests have been moved into JoinFilterAnalyzerTest", "author": "jon-wei", "createdAt": "2020-02-05T00:18:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxOTkyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "2150436af7691541d0462c39a9caa5e9a46e5c29", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex 74732f4666..5455fdd43e 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -1312,1164 +1247,4 @@ public class HashJoinSegmentStorageAdapterTest\n         ImmutableList.of()\n     );\n   }\n-\n-  // Filter push down tests\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnChannel()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, null},\n-            new Object[]{\"Peremptory norm\", \"New South Wales\", \"Australia\"},\n-            new Object[]{\"President of India\", \"California\", \"United States\"},\n-            new Object[]{\"Glasgow\", \"Kingston upon Hull\", \"United Kingdom\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"California\", \"United States\"},\n-            new Object[]{\"Sarah Michelle Gellar\", \"Ontario\", \"Canada\"},\n-            new Object[]{\"DirecTV\", \"North Carolina\", \"United States\"},\n-            new Object[]{\"Carlo Curti\", \"California\", \"United States\"},\n-            new Object[]{\"Giusy Ferreri discography\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Roma-Bangkok\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"},\n-            new Object[]{\"Cream Soda\", \"Ainigriv\", \"States United\"},\n-            new Object[][]{new Object[]{\"Orange Soda\", null, null}}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-        null,\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionExprToCountryLeftFilterOnCountryName()\n-  {\n-    JoinableClause regionExprToCountry = new JoinableClause(\n-        REGION_TO_COUNTRY_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"reverse(\\\"%scountryIsoCode\\\") == \\\"%scountryIsoCode\\\"\",\n-                FACT_TO_REGION_PREFIX,\n-                REGION_TO_COUNTRY_PREFIX\n-            ),\n-            REGION_TO_COUNTRY_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionExprToCountry\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Cream Soda\", \"Ainigriv\", \"United States\"}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnChannelAndCountryName()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"rtc.countryName\", \"United States\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"President of India\", \"California\", \"United States\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"California\", \"United States\"},\n-            new Object[]{\"DirecTV\", \"North Carolina\", \"United States\"},\n-            new Object[]{\"Carlo Curti\", \"California\", \"United States\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"US\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnNullColumns()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"countryIsoCode\", null),\n-                    new SelectorFilter(\"countryNumber\", null),\n-                    new SelectorFilter(\"rtc.countryName\", null),\n-                    new SelectorFilter(\"r1.regionName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        NullHandling.sqlCompatible() ?\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, null},\n-            new Object[]{\"Rallicula\", null, null},\n-            new Object[]{\"Apamea abruzzorum\", null, null},\n-            new Object[]{\"Atractus flammigerus\", null, null},\n-            new Object[]{\"Agama mossambica\", null, null}\n-        ) :\n-        ImmutableList.of() // when not running in SQL compatible mode, countryNumber does not have nulls\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"countryIsoCode\", null),\n-                new SelectorFilter(\"countryNumber\", null),\n-                new SelectorFilter(\"rtc.countryName\", null),\n-                new SelectorFilter(\"r1.regionName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnInvalidColumns()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"baseTableInvalidColumn\", \"abcd\"),\n-                    new SelectorFilter(\"rtc.invalidColumn\", \"abcd\"),\n-                    new SelectorFilter(\"r1.invalidColumn\", \"abcd\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new SelectorFilter(\"baseTableInvalidColumn\", \"abcd\"),\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"rtc.invalidColumn\", \"abcd\"),\n-                new SelectorFilter(\"r1.invalidColumn\", \"abcd\")\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnChannelVirtualColumn()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"v1\", \"virtual-column-#en.wikipedia\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.create(\n-                ImmutableList.of(\n-                    new ExpressionVirtualColumn(\n-                        \"v1\",\n-                        \"concat('virtual-column-', \\\"channel\\\")\",\n-                        ValueType.STRING,\n-                        TestExprMacroTable.INSTANCE\n-                    )\n-                )\n-            ),\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, null},\n-            new Object[]{\"Peremptory norm\", \"New South Wales\", \"Australia\"},\n-            new Object[]{\"President of India\", \"California\", \"United States\"},\n-            new Object[]{\"Glasgow\", \"Kingston upon Hull\", \"United Kingdom\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"California\", \"United States\"},\n-            new Object[]{\"Sarah Michelle Gellar\", \"Ontario\", \"Canada\"},\n-            new Object[]{\"DirecTV\", \"North Carolina\", \"United States\"},\n-            new Object[]{\"Carlo Curti\", \"California\", \"United States\"},\n-            new Object[]{\"Giusy Ferreri discography\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Roma-Bangkok\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"},\n-            new Object[]{\"Cream Soda\", \"Ainigriv\", \"States United\"},\n-            new Object[][]{new Object[]{\"Orange Soda\", null, null}}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new SelectorFilter(\"v1\", \"virtual-column-#en.wikipedia\"),\n-        null,\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterNormalizedAlreadyPushDownVariety()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#fr.wikipedia\"),\n-                    new BoundFilter(new BoundDimFilter(\n-                        \"page\",\n-                        \"Les Argonautes\",\n-                        \"Les Argonautes\",\n-                        false,\n-                        false,\n-                        null,\n-                        null,\n-                        null\n-                    )),\n-                    new SelectorFilter(\"rtc.countryName\", \"Canada\"),\n-                    new BoundFilter(new BoundDimFilter(\n-                        \"rtc.countryName\",\n-                        \"Canada\",\n-                        \"Canada\",\n-                        false,\n-                        false,\n-                        null,\n-                        null,\n-                        null\n-                    )),\n-                    new OrFilter(\n-                        ImmutableList.of(\n-                            new SelectorFilter(\"namespace\", \"main\"),\n-                            new BoundFilter(new BoundDimFilter(\n-                                \"user\",\n-                                \"24.122.168.111\",\n-                                \"24.122.168.111\",\n-                                false,\n-                                false,\n-                                null,\n-                                null,\n-                                null\n-                            ))\n-                        )\n-                    ),\n-                    new OrFilter(\n-                        ImmutableList.of(\n-                            new SelectorFilter(\"namespace\", \"main\"),\n-                            new BoundFilter(new BoundDimFilter(\n-                                \"r1.regionName\",\n-                                \"Quebec\",\n-                                \"Quebec\",\n-                                false,\n-                                false,\n-                                null,\n-                                null,\n-                                null\n-                            ))\n-                        )\n-                    )\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Les Argonautes\", \"Quebec\", \"Canada\"}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#fr.wikipedia\"),\n-                new BoundFilter(new BoundDimFilter(\n-                    \"page\",\n-                    \"Les Argonautes\",\n-                    \"Les Argonautes\",\n-                    false,\n-                    false,\n-                    null,\n-                    null,\n-                    null\n-                )),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"CA\"), null, null).toFilter(),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"namespace\", \"main\"),\n-                        new BoundFilter(new BoundDimFilter(\n-                            \"user\",\n-                            \"24.122.168.111\",\n-                            \"24.122.168.111\",\n-                            false,\n-                            false,\n-                            null,\n-                            null,\n-                            null\n-                        ))\n-                    )\n-                )\n-            )\n-        ),\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"rtc.countryName\", \"Canada\"),\n-                new BoundFilter(new BoundDimFilter(\n-                    \"rtc.countryName\",\n-                    \"Canada\",\n-                    \"Canada\",\n-                    false,\n-                    false,\n-                    null,\n-                    null,\n-                    null\n-                )),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"namespace\", \"main\"),\n-                        new BoundFilter(new BoundDimFilter(\n-                            \"r1.regionName\",\n-                            \"Quebec\",\n-                            \"Quebec\",\n-                            false,\n-                            false,\n-                            null,\n-                            null,\n-                            null\n-                        ))\n-                    )\n-                )\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factExpressionsToRegionToCountryLeftFilterOnChannelAndCountryName()\n-  {\n-    JoinableClause factExprToRegon = new JoinableClause(\n-        FACT_TO_REGION_PREFIX,\n-        new IndexedTableJoinable(regionsTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%sregionIsoCode\\\" == reverse(regionIsoCode) && \\\"%scountryIsoCode\\\" == reverse(countryIsoCode)\",\n-                FACT_TO_REGION_PREFIX,\n-                FACT_TO_REGION_PREFIX\n-            ),\n-            FACT_TO_REGION_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factExprToRegon,\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"rtc.countryName\", \"States United\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Old Anatolian Turkish\", \"Ainigriv\", \"States United\"}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-              new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-              new InDimFilter(\"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\", ImmutableSet.of(\"SU\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(\"rtc.countryName\", \"States United\"),\n-        ImmutableList.of()\n-    );\n-    ExpressionVirtualColumn expectedVirtualColumn = new ExpressionVirtualColumn(\n-        \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\",\n-        \"reverse(countryIsoCode)\",\n-        ValueType.STRING,\n-        ExprMacroTable.nil()\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getBaseTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getBaseTableFilter()\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getJoinTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getJoinTableFilter()\n-    );\n-    ExpressionVirtualColumn actualVirtualColumn = (ExpressionVirtualColumn) adapter.getPreviousJoinFilterSplitForTesting()\n-                                                                                   .getPushDownVirtualColumns()\n-                                                                                   .get(0);\n-    compareExpressionVirtualColumns(expectedVirtualColumn, actualVirtualColumn);\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryNotEquiJoinLeftFilterOnChannelAndCountryName()\n-  {\n-    expectedException.expect(IllegalArgumentException.class);\n-    expectedException.expectMessage(\"Cannot build hash-join matcher on non-equi-join condition: \\\"r1.regionIsoCode\\\" == regionIsoCode && reverse(\\\"r1.countryIsoCode\\\") == countryIsoCode\");\n-\n-    JoinableClause factExprToRegon = new JoinableClause(\n-        FACT_TO_REGION_PREFIX,\n-        new IndexedTableJoinable(regionsTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%sregionIsoCode\\\" == regionIsoCode && reverse(\\\"%scountryIsoCode\\\") == countryIsoCode\",\n-                FACT_TO_REGION_PREFIX,\n-                FACT_TO_REGION_PREFIX\n-            ),\n-            FACT_TO_REGION_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factExprToRegon,\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"rtc.countryName\", \"States United\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Old Anatolian Turkish\", \"Ainigriv\", \"States United\"}\n-        )\n-    );\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftUnnormalizedFilter()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new OrFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                    new AndFilter(\n-                        ImmutableList.of(\n-                          new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-                          new SelectorFilter(\"r1.regionName\", \"Virginia\")\n-                        )\n-                    )\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"\uc720\ud76c\uc655 GX\", \"Seoul\", \"Republic of Korea\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"US\"), null, null).toFilter()\n-                    )\n-                ),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new AndFilter(\n-                            ImmutableList.of(\n-                                new InDimFilter(\"regionIsoCode\", ImmutableSet.of(\"VA\"), null, null).toFilter(),\n-                                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"US\"), null, null).toFilter()\n-                            )\n-                        )\n-                    )\n-                )\n-            )\n-        ),\n-        new AndFilter(\n-            ImmutableList.of(\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new SelectorFilter(\"rtc.countryName\", \"United States\")\n-                    )\n-                ),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new SelectorFilter(\"r1.regionName\", \"Virginia\")\n-                    )\n-                )\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factConcatExpressionToCountryLeftFilterOnChannelAndCountryName()\n-  {\n-    JoinableClause factExprToCountry = new JoinableClause(\n-        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%scountryIsoCode\\\" == concat(countryIsoCode, regionIsoCode)\",\n-                FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX\n-            ),\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factExprToCountry\n-        )\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"c1.countryName\", \"Usca\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"President of India\", \"Usca\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"Usca\"},\n-            new Object[]{\"Carlo Curti\", \"Usca\"}\n-        )\n-    );\n-\n-    ExpressionVirtualColumn expectedVirtualColumn = new ExpressionVirtualColumn(\n-        \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\",\n-        \"concat(countryIsoCode, regionIsoCode)\",\n-        ValueType.STRING,\n-        ExprMacroTable.nil()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                new InDimFilter(\"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\", ImmutableSet.of(\"USCA\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(\"c1.countryName\", \"Usca\"),\n-        ImmutableList.of(\n-            expectedVirtualColumn\n-        )\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getBaseTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getBaseTableFilter()\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getJoinTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getJoinTableFilter()\n-    );\n-    ExpressionVirtualColumn actualVirtualColumn = (ExpressionVirtualColumn) adapter.getPreviousJoinFilterSplitForTesting()\n-                                                                                   .getPushDownVirtualColumns()\n-                                                                                   .get(0);\n-    compareExpressionVirtualColumns(expectedVirtualColumn, actualVirtualColumn);\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryRightWithFilterOnChannelAndJoinable()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.RIGHT))\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#de.wikipedia\"),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"Germany\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Diskussion:Sebastian Schulz\", \"DE\", 3L, \"DE\", \"Germany\", 3L}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#de.wikipedia\"),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"DE\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"Germany\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryRightWithFilterOnNullColumns()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.RIGHT))\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", null),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", null),\n-                new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryInnerUsingCountryNumberFilterOnChannelAndCountryName()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnNumber(JoinType.INNER))\n-    );\n-\n-    // In non-SQL-compatible mode, we get an extra row, since the 'null' countryNumber for \"Talk:Oswald Tilghman\"\n-    // is interpreted as 0 (a.k.a. Australia).\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", \"Australia\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryNumber\"\n-        ),\n-        NullHandling.sqlCompatible() ?\n-        ImmutableList.of(\n-            new Object[]{\"Peremptory norm\", \"AU\", \"AU\", \"Australia\", 0L}\n-        ) :\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, \"AU\", \"Australia\", 0L},\n-            new Object[]{\"Peremptory norm\", \"AU\", \"AU\", \"Australia\", 0L}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                new InDimFilter(\"countryNumber\", ImmutableSet.of(\"0\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", \"Australia\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryInnerUsingCountryNumberFilterOnNulls()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnNumber(JoinType.INNER))\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", null),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", null),\n-                new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryFullWithFilterOnChannelAndCountryName()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.FULL))\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#es.wikipedia\"),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"El Salvador\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Wendigo\", \"SV\", 12L, \"SV\", \"El Salvador\", 12L}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#es.wikipedia\"),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"SV\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"El Salvador\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryFullWithFilterOnNulls()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.FULL))\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", null),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of()\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", null),\n-                new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  private JoinableClause factToCountryNameUsingIsoCodeLookup(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-        LookupJoinable.wrap(countryIsoCodeToNameLookup),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%sk\\\" == countryIsoCode\", FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX),\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToCountryNameUsingNumberLookup(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-        LookupJoinable.wrap(countryNumberToNameLookup),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%sk\\\" == countryNumber\", FACT_TO_COUNTRY_ON_NUMBER_PREFIX),\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToCountryOnIsoCode(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%scountryIsoCode\\\" == countryIsoCode\", FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX),\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToCountryOnNumber(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%scountryNumber\\\" == countryNumber\", FACT_TO_COUNTRY_ON_NUMBER_PREFIX),\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToRegion(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_REGION_PREFIX,\n-        new IndexedTableJoinable(regionsTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%sregionIsoCode\\\" == regionIsoCode && \\\"%scountryIsoCode\\\" == countryIsoCode\",\n-                FACT_TO_REGION_PREFIX,\n-                FACT_TO_REGION_PREFIX\n-            ),\n-            FACT_TO_REGION_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause regionToCountry(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        REGION_TO_COUNTRY_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%scountryIsoCode\\\" == \\\"%scountryIsoCode\\\"\",\n-                FACT_TO_REGION_PREFIX,\n-                REGION_TO_COUNTRY_PREFIX\n-            ),\n-            REGION_TO_COUNTRY_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private HashJoinSegmentStorageAdapter makeFactToCountrySegment()\n-  {\n-    return new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.LEFT))\n-    );\n-  }\n-\n-  private void compareExpressionVirtualColumns(\n-      ExpressionVirtualColumn expectedVirtualColumn,\n-      ExpressionVirtualColumn actualVirtualColumn\n-  )\n-  {\n-    Assert.assertEquals(\n-        expectedVirtualColumn.getOutputName(),\n-        actualVirtualColumn.getOutputName()\n-    );\n-    Assert.assertEquals(\n-        expectedVirtualColumn.getOutputType(),\n-        actualVirtualColumn.getOutputType()\n-    );\n-    Assert.assertEquals(\n-        expectedVirtualColumn.getParsedExpression().get().toString(),\n-        actualVirtualColumn.getParsedExpression().get().toString()\n-    );\n-  }\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex 74732f4666..5455fdd43e 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -1312,1164 +1247,4 @@ public class HashJoinSegmentStorageAdapterTest\n         ImmutableList.of()\n     );\n   }\n-\n-  // Filter push down tests\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnChannel()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, null},\n-            new Object[]{\"Peremptory norm\", \"New South Wales\", \"Australia\"},\n-            new Object[]{\"President of India\", \"California\", \"United States\"},\n-            new Object[]{\"Glasgow\", \"Kingston upon Hull\", \"United Kingdom\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"California\", \"United States\"},\n-            new Object[]{\"Sarah Michelle Gellar\", \"Ontario\", \"Canada\"},\n-            new Object[]{\"DirecTV\", \"North Carolina\", \"United States\"},\n-            new Object[]{\"Carlo Curti\", \"California\", \"United States\"},\n-            new Object[]{\"Giusy Ferreri discography\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Roma-Bangkok\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"},\n-            new Object[]{\"Cream Soda\", \"Ainigriv\", \"States United\"},\n-            new Object[][]{new Object[]{\"Orange Soda\", null, null}}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-        null,\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionExprToCountryLeftFilterOnCountryName()\n-  {\n-    JoinableClause regionExprToCountry = new JoinableClause(\n-        REGION_TO_COUNTRY_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"reverse(\\\"%scountryIsoCode\\\") == \\\"%scountryIsoCode\\\"\",\n-                FACT_TO_REGION_PREFIX,\n-                REGION_TO_COUNTRY_PREFIX\n-            ),\n-            REGION_TO_COUNTRY_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionExprToCountry\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Cream Soda\", \"Ainigriv\", \"United States\"}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnChannelAndCountryName()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"rtc.countryName\", \"United States\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"President of India\", \"California\", \"United States\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"California\", \"United States\"},\n-            new Object[]{\"DirecTV\", \"North Carolina\", \"United States\"},\n-            new Object[]{\"Carlo Curti\", \"California\", \"United States\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"US\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnNullColumns()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"countryIsoCode\", null),\n-                    new SelectorFilter(\"countryNumber\", null),\n-                    new SelectorFilter(\"rtc.countryName\", null),\n-                    new SelectorFilter(\"r1.regionName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        NullHandling.sqlCompatible() ?\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, null},\n-            new Object[]{\"Rallicula\", null, null},\n-            new Object[]{\"Apamea abruzzorum\", null, null},\n-            new Object[]{\"Atractus flammigerus\", null, null},\n-            new Object[]{\"Agama mossambica\", null, null}\n-        ) :\n-        ImmutableList.of() // when not running in SQL compatible mode, countryNumber does not have nulls\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"countryIsoCode\", null),\n-                new SelectorFilter(\"countryNumber\", null),\n-                new SelectorFilter(\"rtc.countryName\", null),\n-                new SelectorFilter(\"r1.regionName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnInvalidColumns()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"baseTableInvalidColumn\", \"abcd\"),\n-                    new SelectorFilter(\"rtc.invalidColumn\", \"abcd\"),\n-                    new SelectorFilter(\"r1.invalidColumn\", \"abcd\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new SelectorFilter(\"baseTableInvalidColumn\", \"abcd\"),\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"rtc.invalidColumn\", \"abcd\"),\n-                new SelectorFilter(\"r1.invalidColumn\", \"abcd\")\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterOnChannelVirtualColumn()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"v1\", \"virtual-column-#en.wikipedia\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.create(\n-                ImmutableList.of(\n-                    new ExpressionVirtualColumn(\n-                        \"v1\",\n-                        \"concat('virtual-column-', \\\"channel\\\")\",\n-                        ValueType.STRING,\n-                        TestExprMacroTable.INSTANCE\n-                    )\n-                )\n-            ),\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, null},\n-            new Object[]{\"Peremptory norm\", \"New South Wales\", \"Australia\"},\n-            new Object[]{\"President of India\", \"California\", \"United States\"},\n-            new Object[]{\"Glasgow\", \"Kingston upon Hull\", \"United Kingdom\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"California\", \"United States\"},\n-            new Object[]{\"Sarah Michelle Gellar\", \"Ontario\", \"Canada\"},\n-            new Object[]{\"DirecTV\", \"North Carolina\", \"United States\"},\n-            new Object[]{\"Carlo Curti\", \"California\", \"United States\"},\n-            new Object[]{\"Giusy Ferreri discography\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Roma-Bangkok\", \"Provincia di Varese\", \"Italy\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"},\n-            new Object[]{\"Cream Soda\", \"Ainigriv\", \"States United\"},\n-            new Object[][]{new Object[]{\"Orange Soda\", null, null}}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new SelectorFilter(\"v1\", \"virtual-column-#en.wikipedia\"),\n-        null,\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftFilterNormalizedAlreadyPushDownVariety()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#fr.wikipedia\"),\n-                    new BoundFilter(new BoundDimFilter(\n-                        \"page\",\n-                        \"Les Argonautes\",\n-                        \"Les Argonautes\",\n-                        false,\n-                        false,\n-                        null,\n-                        null,\n-                        null\n-                    )),\n-                    new SelectorFilter(\"rtc.countryName\", \"Canada\"),\n-                    new BoundFilter(new BoundDimFilter(\n-                        \"rtc.countryName\",\n-                        \"Canada\",\n-                        \"Canada\",\n-                        false,\n-                        false,\n-                        null,\n-                        null,\n-                        null\n-                    )),\n-                    new OrFilter(\n-                        ImmutableList.of(\n-                            new SelectorFilter(\"namespace\", \"main\"),\n-                            new BoundFilter(new BoundDimFilter(\n-                                \"user\",\n-                                \"24.122.168.111\",\n-                                \"24.122.168.111\",\n-                                false,\n-                                false,\n-                                null,\n-                                null,\n-                                null\n-                            ))\n-                        )\n-                    ),\n-                    new OrFilter(\n-                        ImmutableList.of(\n-                            new SelectorFilter(\"namespace\", \"main\"),\n-                            new BoundFilter(new BoundDimFilter(\n-                                \"r1.regionName\",\n-                                \"Quebec\",\n-                                \"Quebec\",\n-                                false,\n-                                false,\n-                                null,\n-                                null,\n-                                null\n-                            ))\n-                        )\n-                    )\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Les Argonautes\", \"Quebec\", \"Canada\"}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#fr.wikipedia\"),\n-                new BoundFilter(new BoundDimFilter(\n-                    \"page\",\n-                    \"Les Argonautes\",\n-                    \"Les Argonautes\",\n-                    false,\n-                    false,\n-                    null,\n-                    null,\n-                    null\n-                )),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"CA\"), null, null).toFilter(),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"namespace\", \"main\"),\n-                        new BoundFilter(new BoundDimFilter(\n-                            \"user\",\n-                            \"24.122.168.111\",\n-                            \"24.122.168.111\",\n-                            false,\n-                            false,\n-                            null,\n-                            null,\n-                            null\n-                        ))\n-                    )\n-                )\n-            )\n-        ),\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"rtc.countryName\", \"Canada\"),\n-                new BoundFilter(new BoundDimFilter(\n-                    \"rtc.countryName\",\n-                    \"Canada\",\n-                    \"Canada\",\n-                    false,\n-                    false,\n-                    null,\n-                    null,\n-                    null\n-                )),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"namespace\", \"main\"),\n-                        new BoundFilter(new BoundDimFilter(\n-                            \"r1.regionName\",\n-                            \"Quebec\",\n-                            \"Quebec\",\n-                            false,\n-                            false,\n-                            null,\n-                            null,\n-                            null\n-                        ))\n-                    )\n-                )\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factExpressionsToRegionToCountryLeftFilterOnChannelAndCountryName()\n-  {\n-    JoinableClause factExprToRegon = new JoinableClause(\n-        FACT_TO_REGION_PREFIX,\n-        new IndexedTableJoinable(regionsTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%sregionIsoCode\\\" == reverse(regionIsoCode) && \\\"%scountryIsoCode\\\" == reverse(countryIsoCode)\",\n-                FACT_TO_REGION_PREFIX,\n-                FACT_TO_REGION_PREFIX\n-            ),\n-            FACT_TO_REGION_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factExprToRegon,\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"rtc.countryName\", \"States United\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Old Anatolian Turkish\", \"Ainigriv\", \"States United\"}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-              new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-              new InDimFilter(\"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\", ImmutableSet.of(\"SU\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(\"rtc.countryName\", \"States United\"),\n-        ImmutableList.of()\n-    );\n-    ExpressionVirtualColumn expectedVirtualColumn = new ExpressionVirtualColumn(\n-        \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\",\n-        \"reverse(countryIsoCode)\",\n-        ValueType.STRING,\n-        ExprMacroTable.nil()\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getBaseTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getBaseTableFilter()\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getJoinTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getJoinTableFilter()\n-    );\n-    ExpressionVirtualColumn actualVirtualColumn = (ExpressionVirtualColumn) adapter.getPreviousJoinFilterSplitForTesting()\n-                                                                                   .getPushDownVirtualColumns()\n-                                                                                   .get(0);\n-    compareExpressionVirtualColumns(expectedVirtualColumn, actualVirtualColumn);\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryNotEquiJoinLeftFilterOnChannelAndCountryName()\n-  {\n-    expectedException.expect(IllegalArgumentException.class);\n-    expectedException.expectMessage(\"Cannot build hash-join matcher on non-equi-join condition: \\\"r1.regionIsoCode\\\" == regionIsoCode && reverse(\\\"r1.countryIsoCode\\\") == countryIsoCode\");\n-\n-    JoinableClause factExprToRegon = new JoinableClause(\n-        FACT_TO_REGION_PREFIX,\n-        new IndexedTableJoinable(regionsTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%sregionIsoCode\\\" == regionIsoCode && reverse(\\\"%scountryIsoCode\\\") == countryIsoCode\",\n-                FACT_TO_REGION_PREFIX,\n-                FACT_TO_REGION_PREFIX\n-            ),\n-            FACT_TO_REGION_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factExprToRegon,\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"rtc.countryName\", \"States United\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Old Anatolian Turkish\", \"Ainigriv\", \"States United\"}\n-        )\n-    );\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToRegionToCountryLeftUnnormalizedFilter()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factToRegion(JoinType.LEFT),\n-            regionToCountry(JoinType.LEFT)\n-        )\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new OrFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                    new AndFilter(\n-                        ImmutableList.of(\n-                          new SelectorFilter(\"rtc.countryName\", \"United States\"),\n-                          new SelectorFilter(\"r1.regionName\", \"Virginia\")\n-                        )\n-                    )\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_REGION_PREFIX + \"regionName\",\n-            REGION_TO_COUNTRY_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"\uc720\ud76c\uc655 GX\", \"Seoul\", \"Republic of Korea\"},\n-            new Object[]{\"Old Anatolian Turkish\", \"Virginia\", \"United States\"}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"US\"), null, null).toFilter()\n-                    )\n-                ),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new AndFilter(\n-                            ImmutableList.of(\n-                                new InDimFilter(\"regionIsoCode\", ImmutableSet.of(\"VA\"), null, null).toFilter(),\n-                                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"US\"), null, null).toFilter()\n-                            )\n-                        )\n-                    )\n-                )\n-            )\n-        ),\n-        new AndFilter(\n-            ImmutableList.of(\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new SelectorFilter(\"rtc.countryName\", \"United States\")\n-                    )\n-                ),\n-                new OrFilter(\n-                    ImmutableList.of(\n-                        new SelectorFilter(\"channel\", \"#ko.wikipedia\"),\n-                        new SelectorFilter(\"r1.regionName\", \"Virginia\")\n-                    )\n-                )\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factConcatExpressionToCountryLeftFilterOnChannelAndCountryName()\n-  {\n-    JoinableClause factExprToCountry = new JoinableClause(\n-        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        JoinType.LEFT,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%scountryIsoCode\\\" == concat(countryIsoCode, regionIsoCode)\",\n-                FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX\n-            ),\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(\n-            factExprToCountry\n-        )\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(\"c1.countryName\", \"Usca\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"President of India\", \"Usca\"},\n-            new Object[]{\"Otjiwarongo Airport\", \"Usca\"},\n-            new Object[]{\"Carlo Curti\", \"Usca\"}\n-        )\n-    );\n-\n-    ExpressionVirtualColumn expectedVirtualColumn = new ExpressionVirtualColumn(\n-        \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\",\n-        \"concat(countryIsoCode, regionIsoCode)\",\n-        ValueType.STRING,\n-        ExprMacroTable.nil()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                new InDimFilter(\"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-0\", ImmutableSet.of(\"USCA\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(\"c1.countryName\", \"Usca\"),\n-        ImmutableList.of(\n-            expectedVirtualColumn\n-        )\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getBaseTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getBaseTableFilter()\n-    );\n-    Assert.assertEquals(\n-        expectedFilterSplit.getJoinTableFilter(),\n-        adapter.getPreviousJoinFilterSplitForTesting().getJoinTableFilter()\n-    );\n-    ExpressionVirtualColumn actualVirtualColumn = (ExpressionVirtualColumn) adapter.getPreviousJoinFilterSplitForTesting()\n-                                                                                   .getPushDownVirtualColumns()\n-                                                                                   .get(0);\n-    compareExpressionVirtualColumns(expectedVirtualColumn, actualVirtualColumn);\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryRightWithFilterOnChannelAndJoinable()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.RIGHT))\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#de.wikipedia\"),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"Germany\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Diskussion:Sebastian Schulz\", \"DE\", 3L, \"DE\", \"Germany\", 3L}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#de.wikipedia\"),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"DE\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"Germany\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryRightWithFilterOnNullColumns()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.RIGHT))\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", null),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", null),\n-                new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryInnerUsingCountryNumberFilterOnChannelAndCountryName()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnNumber(JoinType.INNER))\n-    );\n-\n-    // In non-SQL-compatible mode, we get an extra row, since the 'null' countryNumber for \"Talk:Oswald Tilghman\"\n-    // is interpreted as 0 (a.k.a. Australia).\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", \"Australia\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryNumber\"\n-        ),\n-        NullHandling.sqlCompatible() ?\n-        ImmutableList.of(\n-            new Object[]{\"Peremptory norm\", \"AU\", \"AU\", \"Australia\", 0L}\n-        ) :\n-        ImmutableList.of(\n-            new Object[]{\"Talk:Oswald Tilghman\", null, \"AU\", \"Australia\", 0L},\n-            new Object[]{\"Peremptory norm\", \"AU\", \"AU\", \"Australia\", 0L}\n-        )\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#en.wikipedia\"),\n-                new InDimFilter(\"countryNumber\", ImmutableSet.of(\"0\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", \"Australia\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryInnerUsingCountryNumberFilterOnNulls()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnNumber(JoinType.INNER))\n-    );\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", null),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of()\n-    );\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", null),\n-                new SelectorFilter(FACT_TO_COUNTRY_ON_NUMBER_PREFIX + \"countryName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryFullWithFilterOnChannelAndCountryName()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.FULL))\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", \"#es.wikipedia\"),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"El Salvador\")\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of(\n-            new Object[]{\"Wendigo\", \"SV\", 12L, \"SV\", \"El Salvador\", 12L}\n-        )\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", \"#es.wikipedia\"),\n-                new InDimFilter(\"countryIsoCode\", ImmutableSet.of(\"SV\"), null, null).toFilter()\n-            )\n-        ),\n-        new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", \"El Salvador\"),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  @Test\n-  public void test_makeCursorsFilterPushDown_factToCountryFullWithFilterOnNulls()\n-  {\n-    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.FULL))\n-    );\n-\n-    JoinTestHelper.verifyCursors(\n-        adapter.makeCursors(\n-            new AndFilter(\n-                ImmutableList.of(\n-                    new SelectorFilter(\"channel\", null),\n-                    new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-                )\n-            ),\n-            Intervals.ETERNITY,\n-            VirtualColumns.EMPTY,\n-            Granularities.ALL,\n-            false,\n-            null\n-        ),\n-        ImmutableList.of(\n-            \"page\",\n-            \"countryIsoCode\",\n-            \"countryNumber\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n-        ),\n-        ImmutableList.of()\n-    );\n-\n-    JoinFilterAnalyzer.JoinFilterSplit expectedFilterSplit = new JoinFilterAnalyzer.JoinFilterSplit(\n-        null,\n-        new AndFilter(\n-            ImmutableList.of(\n-                new SelectorFilter(\"channel\", null),\n-                new SelectorFilter(FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\", null)\n-            )\n-        ),\n-        ImmutableList.of()\n-    );\n-    Assert.assertEquals(expectedFilterSplit, adapter.getPreviousJoinFilterSplitForTesting());\n-  }\n-\n-  private JoinableClause factToCountryNameUsingIsoCodeLookup(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-        LookupJoinable.wrap(countryIsoCodeToNameLookup),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%sk\\\" == countryIsoCode\", FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX),\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToCountryNameUsingNumberLookup(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-        LookupJoinable.wrap(countryNumberToNameLookup),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%sk\\\" == countryNumber\", FACT_TO_COUNTRY_ON_NUMBER_PREFIX),\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToCountryOnIsoCode(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%scountryIsoCode\\\" == countryIsoCode\", FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX),\n-            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToCountryOnNumber(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\"\\\"%scountryNumber\\\" == countryNumber\", FACT_TO_COUNTRY_ON_NUMBER_PREFIX),\n-            FACT_TO_COUNTRY_ON_NUMBER_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause factToRegion(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        FACT_TO_REGION_PREFIX,\n-        new IndexedTableJoinable(regionsTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%sregionIsoCode\\\" == regionIsoCode && \\\"%scountryIsoCode\\\" == countryIsoCode\",\n-                FACT_TO_REGION_PREFIX,\n-                FACT_TO_REGION_PREFIX\n-            ),\n-            FACT_TO_REGION_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private JoinableClause regionToCountry(final JoinType joinType)\n-  {\n-    return new JoinableClause(\n-        REGION_TO_COUNTRY_PREFIX,\n-        new IndexedTableJoinable(countriesTable),\n-        joinType,\n-        JoinConditionAnalysis.forExpression(\n-            StringUtils.format(\n-                \"\\\"%scountryIsoCode\\\" == \\\"%scountryIsoCode\\\"\",\n-                FACT_TO_REGION_PREFIX,\n-                REGION_TO_COUNTRY_PREFIX\n-            ),\n-            REGION_TO_COUNTRY_PREFIX,\n-            ExprMacroTable.nil()\n-        )\n-    );\n-  }\n-\n-  private HashJoinSegmentStorageAdapter makeFactToCountrySegment()\n-  {\n-    return new HashJoinSegmentStorageAdapter(\n-        factSegment.asStorageAdapter(),\n-        ImmutableList.of(factToCountryOnIsoCode(JoinType.LEFT))\n-    );\n-  }\n-\n-  private void compareExpressionVirtualColumns(\n-      ExpressionVirtualColumn expectedVirtualColumn,\n-      ExpressionVirtualColumn actualVirtualColumn\n-  )\n-  {\n-    Assert.assertEquals(\n-        expectedVirtualColumn.getOutputName(),\n-        actualVirtualColumn.getOutputName()\n-    );\n-    Assert.assertEquals(\n-        expectedVirtualColumn.getOutputType(),\n-        actualVirtualColumn.getOutputType()\n-    );\n-    Assert.assertEquals(\n-        expectedVirtualColumn.getParsedExpression().get().toString(),\n-        actualVirtualColumn.getParsedExpression().get().toString()\n-    );\n-  }\n }\n", "next_change": {"commit": "3082b9289a19e91a32bc874be187730ff47c6428", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex 5455fdd43e..d672a69af7 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -1247,4 +1259,30 @@ public class HashJoinSegmentStorageAdapterTest extends BaseHashJoinSegmentStorag\n         ImmutableList.of()\n     );\n   }\n+\n+  @Test\n+  public void test_makeCursors_factToCountryLeft_filterExcludesAllLeftRows()\n+  {\n+    JoinTestHelper.verifyCursors(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(factToCountryOnIsoCode(JoinType.LEFT))\n+        ).makeCursors(\n+            new SelectorFilter(\"page\", \"this matches nothing\"),\n+            Intervals.ETERNITY,\n+            VirtualColumns.EMPTY,\n+            Granularities.ALL,\n+            false,\n+            null\n+        ),\n+        ImmutableList.of(\n+            \"page\",\n+            \"countryIsoCode\",\n+            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryIsoCode\",\n+            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryName\",\n+            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"countryNumber\"\n+        ),\n+        ImmutableList.of()\n+    );\n+  }\n }\n", "next_change": {"commit": "accd710115efea87120d58f01b08342065d6ae5f", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex d672a69af7..b7e9a58c80 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -1285,4 +2131,43 @@ public class HashJoinSegmentStorageAdapterTest extends BaseHashJoinSegmentStorag\n         ImmutableList.of()\n     );\n   }\n+\n+  @Test\n+  public void test_makeCursors_factToCountryLeft_filterExcludesAllLeftRowsUsingLookup()\n+  {\n+    Filter originalFilter = new SelectorFilter(\"page\", \"this matches nothing\");\n+    List<JoinableClause> joinableClauses = ImmutableList.of(factToCountryNameUsingIsoCodeLookup(JoinType.LEFT));\n+\n+    JoinFilterPreAnalysis preAnalysis = JoinFilterAnalyzer.computeJoinFilterPreAnalysis(\n+        joinableClauses,\n+        VirtualColumns.EMPTY,\n+        originalFilter,\n+        true,\n+        true,\n+        true,\n+        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE_MAX_SIZE\n+    );\n+\n+    JoinTestHelper.verifyCursors(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            joinableClauses,\n+            preAnalysis\n+        ).makeCursors(\n+            originalFilter,\n+            Intervals.ETERNITY,\n+            VirtualColumns.EMPTY,\n+            Granularities.ALL,\n+            false,\n+            null\n+        ),\n+        ImmutableList.of(\n+            \"page\",\n+            \"countryIsoCode\",\n+            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"k\",\n+            FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX + \"v\"\n+        ),\n+        ImmutableList.of()\n+    );\n+  }\n }\n", "next_change": {"commit": "b0167295d7c621bfa9722b7203bc7ca08fc76495", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex b7e9a58c80..c58291301d 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -2170,4 +2170,40 @@ public class HashJoinSegmentStorageAdapterTest extends BaseHashJoinSegmentStorag\n         ImmutableList.of()\n     );\n   }\n+\n+  @Test\n+  public void test_makeCursors_originalFilterDoesNotMatchPreAnalysis_shouldThrowISE()\n+  {\n+    List<JoinableClause> joinableClauses = ImmutableList.of(factToCountryOnIsoCode(JoinType.LEFT));\n+\n+    JoinFilterPreAnalysis preAnalysis = JoinFilterAnalyzer.computeJoinFilterPreAnalysis(\n+        joinableClauses,\n+        VirtualColumns.EMPTY,\n+        null,\n+        true,\n+        true,\n+        true,\n+        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE_MAX_SIZE\n+    );\n+    Filter filter = new SelectorFilter(\"page\", \"this matches nothing\");\n+\n+    try {\n+      new HashJoinSegmentStorageAdapter(\n+          factSegment.asStorageAdapter(),\n+          joinableClauses,\n+          preAnalysis\n+      ).makeCursors(\n+          filter,\n+          Intervals.ETERNITY,\n+          VirtualColumns.EMPTY,\n+          Granularities.ALL,\n+          false,\n+          null\n+      );\n+      Assert.fail();\n+    }\n+    catch (ISE e) {\n+      Assert.assertTrue(e.getMessage().startsWith(\"Filter provided to cursor [\"));\n+    }\n+  }\n }\n", "next_change": {"commit": "37e150c0755c0efba609601b1122cd6bc8a271fb", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex c58291301d..ed6e1782f3 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -2175,35 +2006,25 @@ public class HashJoinSegmentStorageAdapterTest extends BaseHashJoinSegmentStorag\n   public void test_makeCursors_originalFilterDoesNotMatchPreAnalysis_shouldThrowISE()\n   {\n     List<JoinableClause> joinableClauses = ImmutableList.of(factToCountryOnIsoCode(JoinType.LEFT));\n+    Filter filter = new SelectorFilter(\"page\", \"this matches nothing\");\n+    JoinFilterPreAnalysisGroup joinFilterPreAnalysisGroup = makeDefaultConfigPreAnalysisGroup(\n+        filter,\n+        joinableClauses,\n+        VirtualColumns.EMPTY\n+    );\n \n-    JoinFilterPreAnalysis preAnalysis = JoinFilterAnalyzer.computeJoinFilterPreAnalysis(\n+    new HashJoinSegmentStorageAdapter(\n+        factSegment.asStorageAdapter(),\n         joinableClauses,\n+        joinFilterPreAnalysisGroup\n+    ).makeCursors(\n+        filter,\n+        Intervals.ETERNITY,\n         VirtualColumns.EMPTY,\n-        null,\n-        true,\n-        true,\n-        true,\n-        QueryContexts.DEFAULT_ENABLE_JOIN_FILTER_REWRITE_MAX_SIZE\n+        Granularities.ALL,\n+        false,\n+        null\n     );\n-    Filter filter = new SelectorFilter(\"page\", \"this matches nothing\");\n-\n-    try {\n-      new HashJoinSegmentStorageAdapter(\n-          factSegment.asStorageAdapter(),\n-          joinableClauses,\n-          preAnalysis\n-      ).makeCursors(\n-          filter,\n-          Intervals.ETERNITY,\n-          VirtualColumns.EMPTY,\n-          Granularities.ALL,\n-          false,\n-          null\n-      );\n-      Assert.fail();\n-    }\n-    catch (ISE e) {\n-      Assert.assertTrue(e.getMessage().startsWith(\"Filter provided to cursor [\"));\n-    }\n   }\n+\n }\n", "next_change": {"commit": "567e38170500d3649cbfaa28cf7aa6f5275d02e7", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex ed6e1782f3..55469624ac 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -2027,4 +2019,40 @@ public class HashJoinSegmentStorageAdapterTest extends BaseHashJoinSegmentStorag\n     );\n   }\n \n+  @Test\n+  public void test_determineBaseColumnsWithPreAndPostJoinVirtualColumns()\n+  {\n+    List<JoinableClause> joinableClauses = ImmutableList.of(factToCountryOnIsoCode(JoinType.LEFT));\n+    JoinFilterPreAnalysis analysis = makeDefaultConfigPreAnalysis(null, joinableClauses, VirtualColumns.EMPTY);\n+    HashJoinSegmentStorageAdapter adapter = new HashJoinSegmentStorageAdapter(\n+        factSegment.asStorageAdapter(),\n+        joinableClauses,\n+        analysis\n+    );\n+    List<VirtualColumn> expectedPreJoin = ImmutableList.of(\n+        makeExpressionVirtualColumn(\"concat(countryIsoCode,'L')\", \"v0\"),\n+        makeExpressionVirtualColumn(\"concat(countryIsoCode, countryNumber)\", \"v1\"),\n+        makeExpressionVirtualColumn(\"channel_uniques - 1\", \"v2\"),\n+        makeExpressionVirtualColumn(\"channel_uniques - __time\", \"v3\")\n+    );\n+\n+    List<VirtualColumn> expectedPostJoin = ImmutableList.of(\n+        makeExpressionVirtualColumn(\"concat(countryIsoCode, dummyColumn)\", \"v4\"),\n+        makeExpressionVirtualColumn(\"dummyMetric - __time\", \"v5\")\n+    );\n+    List<VirtualColumn> actualPreJoin = new ArrayList<>();\n+    List<VirtualColumn> actualPostJoin = new ArrayList<>();\n+    List<VirtualColumn> allVirtualColumns = new ArrayList<>();\n+    allVirtualColumns.addAll(expectedPreJoin);\n+    allVirtualColumns.addAll(expectedPostJoin);\n+    adapter.determineBaseColumnsWithPreAndPostJoinVirtualColumns(\n+        VirtualColumns.create(allVirtualColumns),\n+        actualPreJoin,\n+        actualPostJoin\n+    );\n+\n+    Assert.assertEquals(expectedPreJoin, actualPreJoin);\n+    Assert.assertEquals(expectedPostJoin, actualPostJoin);\n+  }\n+\n }\n", "next_change": {"commit": "8ba7f6a48c95074a6632b14fa93447487923b18c", "changed_code": [{"header": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\nindex 55469624ac..4ee41a2cef 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java\n", "chunk": "@@ -2055,4 +2266,101 @@ public class HashJoinSegmentStorageAdapterTest extends BaseHashJoinSegmentStorag\n     Assert.assertEquals(expectedPostJoin, actualPostJoin);\n   }\n \n+  @Test\n+  public void test_hasBuiltInFiltersForSingleJoinableClauseWithVariousJoinTypes()\n+  {\n+    Assert.assertTrue(makeFactToCountrySegment(JoinType.INNER).hasBuiltInFilters());\n+    Assert.assertFalse(makeFactToCountrySegment(JoinType.LEFT).hasBuiltInFilters());\n+    Assert.assertFalse(makeFactToCountrySegment(JoinType.RIGHT).hasBuiltInFilters());\n+    Assert.assertFalse(makeFactToCountrySegment(JoinType.FULL).hasBuiltInFilters());\n+    // cross join\n+    Assert.assertFalse(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(\n+                new JoinableClause(\n+                    FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n+                    new IndexedTableJoinable(countriesTable),\n+                    JoinType.INNER,\n+                    JoinConditionAnalysis.forExpression(\n+                        \"'true'\",\n+                        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n+                        ExprMacroTable.nil()\n+                    )\n+                )\n+            ),\n+            null\n+        ).hasBuiltInFilters()\n+    );\n+  }\n+\n+  @Test\n+  public void test_hasBuiltInFiltersForEmptyJoinableClause()\n+  {\n+    Assert.assertFalse(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(),\n+            null\n+        ).hasBuiltInFilters()\n+    );\n+  }\n+\n+  @Test\n+  public void test_hasBuiltInFiltersForMultipleJoinableClausesWithVariousJoinTypes()\n+  {\n+    Assert.assertTrue(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(\n+                factToRegion(JoinType.INNER),\n+                regionToCountry(JoinType.LEFT)\n+            ),\n+            null\n+        ).hasBuiltInFilters()\n+    );\n+\n+    Assert.assertTrue(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(\n+                factToRegion(JoinType.RIGHT),\n+                regionToCountry(JoinType.INNER),\n+                factToCountryOnNumber(JoinType.FULL)\n+            ),\n+            null\n+        ).hasBuiltInFilters()\n+    );\n+\n+    Assert.assertFalse(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(\n+                factToRegion(JoinType.LEFT),\n+                regionToCountry(JoinType.LEFT)\n+            ),\n+            null\n+        ).hasBuiltInFilters()\n+    );\n+\n+    Assert.assertFalse(\n+        new HashJoinSegmentStorageAdapter(\n+            factSegment.asStorageAdapter(),\n+            ImmutableList.of(\n+                factToRegion(JoinType.LEFT),\n+                new JoinableClause(\n+                    FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n+                    new IndexedTableJoinable(countriesTable),\n+                    JoinType.INNER,\n+                    JoinConditionAnalysis.forExpression(\n+                        \"'true'\",\n+                        FACT_TO_COUNTRY_ON_ISO_CODE_PREFIX,\n+                        ExprMacroTable.nil()\n+                    )\n+                )\n+            ),\n+            null\n+        ).hasBuiltInFilters()\n+    );\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "73a0181e34f1e0816011b778bc1d3ecbe9d7ad97", "committedDate": "2020-02-17 10:54:04 -0800", "message": "Fix handling for columns that appear multiple times in join conditions (#9362)"}, {"oid": "3082b9289a19e91a32bc874be187730ff47c6428", "committedDate": "2020-03-11 19:23:05 -0700", "message": "Fix NPE when using IndexedTable and all left rows are filtered out (#9490)"}, {"oid": "ff59d2e78bd3949e46858bc2f9882db9a7d2a186", "committedDate": "2020-03-12 11:06:44 -0700", "message": "Move RowSignature from druid-sql to druid-processing and make use of it. (#9508)"}, {"oid": "b1847364b0816cfc3c2ac376cd888033a06fb93f", "committedDate": "2020-03-16 22:16:14 -0700", "message": "More efficient join filter rewrites (#9516)"}, {"oid": "5249155284fcdcd3cbcb4115ee267f23bc43c2e6", "committedDate": "2020-04-10 18:11:05 -0700", "message": "Fix off-by-one in IndexedTableJoinMatcher.getCardinality. (#9674)"}, {"oid": "0ff926b1a1367be88fb6f5f4baaa74ca849bd8bf", "committedDate": "2020-04-11 01:18:11 -0700", "message": "fix issue with group by limit pushdown for extractionFn, expressions, joins, etc (#9662)"}, {"oid": "e677c62484bf02379ff8cb7855de1e3e43a4b4b1", "committedDate": "2020-04-16 22:12:20 -0700", "message": "document useFilterCNF query context parameter (#9647)"}, {"oid": "accd710115efea87120d58f01b08342065d6ae5f", "committedDate": "2020-05-06 16:10:41 -0700", "message": "Add equivalent test coverage for all RHS join impls (#9831)"}, {"oid": "b0167295d7c621bfa9722b7203bc7ca08fc76495", "committedDate": "2020-05-13 14:23:04 -0700", "message": "Fail incorrectly constructed join queries (#9830)"}, {"oid": "9c40bebc02dfd13e1bd58f2f45fd24424e4530a4", "committedDate": "2020-05-29 15:03:35 -0700", "message": "Refactor JoinFilterAnalyzer - part 2 (#9929)"}, {"oid": "37e150c0755c0efba609601b1122cd6bc8a271fb", "committedDate": "2020-06-18 21:32:29 -0700", "message": "Fix join filter rewrites with nested queries (#10015)"}, {"oid": "5faa897a342096b2ac88587ad62e6e15022b01dd", "committedDate": "2020-06-30 19:14:22 -0700", "message": "Join filter pre-analysis simplifications and sanity checks. (#10104)"}, {"oid": "c72f96a4babdf5055912bb0fb5eb2236cfe0ef23", "committedDate": "2020-08-11 11:07:17 -0700", "message": "fix bug with expressions on sparse string realtime columns without explicit null valued rows (#10248)"}, {"oid": "567e38170500d3649cbfaa28cf7aa6f5275d02e7", "committedDate": "2020-10-12 13:04:55 -0700", "message": "Any virtual column on \"__time\" should be a pre-join virtual column (#10451)"}, {"oid": "1a15987432fab044fc83a99af8ab497d887aeda1", "committedDate": "2021-03-04 10:39:21 -0800", "message": "Supporting filters in the left base table for join datasources (#10697)"}, {"oid": "202c78c8f32bd3ec5e70e021b1494d878f38d678", "committedDate": "2021-04-14 10:49:27 -0700", "message": "Enable rewriting certain inner joins as filters. (#11068)"}, {"oid": "8ba7f6a48c95074a6632b14fa93447487923b18c", "committedDate": "2021-07-31 15:55:49 -0700", "message": "Fix incorrect result of exact topN on an inner join with limit (#11517)"}, {"oid": "6c196a5ea2100b5b5c5e81fe75b30ad5d3a63f83", "committedDate": "2021-11-09 15:18:07 -0800", "message": "Remove StorageAdapter.getColumnTypeName. (#11893)"}, {"oid": "af700bba0c8408d63de7374d77f681bf8fdeb2f7", "committedDate": "2022-08-13 16:26:24 +0530", "message": "Fix hasBuiltInFilters for joins (#12894)"}]}, {"oid": "2150436af7691541d0462c39a9caa5e9a46e5c29", "url": "https://github.com/apache/druid/commit/2150436af7691541d0462c39a9caa5e9a46e5c29", "message": "Address PR comments", "committedDate": "2020-02-05T00:02:32Z", "type": "commit"}, {"oid": "b31fbddcd678b5f9faf705a2def1864072188929", "url": "https://github.com/apache/druid/commit/b31fbddcd678b5f9faf705a2def1864072188929", "message": "More PR comments", "committedDate": "2020-02-05T00:12:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375007275", "body": "It would be great to have a javadoc here describing what kind of analysis this class is trying to do, and why. Something like the javadocs at the top of JoinConditionAnalysis and DataSourceAnalysis.", "bodyText": "It would be great to have a javadoc here describing what kind of analysis this class is trying to do, and why. Something like the javadocs at the top of JoinConditionAnalysis and DataSourceAnalysis.", "bodyHTML": "<p dir=\"auto\">It would be great to have a javadoc here describing what kind of analysis this class is trying to do, and why. Something like the javadocs at the top of JoinConditionAnalysis and DataSourceAnalysis.</p>", "author": "gianm", "createdAt": "2020-02-05T00:55:20Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NTc4MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375665780", "bodyText": "Added javadoc here describing the goal and details about the push down and rewrites", "author": "jon-wei", "createdAt": "2020-02-06T06:54:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA0OTkxNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376049916", "bodyText": "Thanks!", "author": "gianm", "createdAt": "2020-02-06T19:56:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -17,43 +17,55 @@\n  * under the License.\n  */\n \n-package org.apache.druid.segment.join;\n+package org.apache.druid.segment.join.filter;\n \n import com.google.common.collect.ImmutableList;\n-import it.unimi.dsi.fastutil.ints.IntList;\n import org.apache.druid.math.expr.Expr;\n-import org.apache.druid.query.dimension.DimensionSpec;\n import org.apache.druid.query.filter.Filter;\n import org.apache.druid.query.filter.InDimFilter;\n import org.apache.druid.query.filter.ValueMatcher;\n import org.apache.druid.segment.ColumnSelectorFactory;\n-import org.apache.druid.segment.ColumnValueSelector;\n-import org.apache.druid.segment.DimensionSelector;\n-import org.apache.druid.segment.NilColumnValueSelector;\n import org.apache.druid.segment.VirtualColumn;\n-import org.apache.druid.segment.column.ColumnCapabilities;\n import org.apache.druid.segment.column.ValueType;\n import org.apache.druid.segment.filter.AndFilter;\n import org.apache.druid.segment.filter.Filters;\n-import org.apache.druid.segment.filter.InFilter;\n import org.apache.druid.segment.filter.OrFilter;\n import org.apache.druid.segment.filter.SelectorFilter;\n-import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n-import org.apache.druid.segment.join.lookup.LookupJoinable;\n-import org.apache.druid.segment.join.table.IndexedTable;\n-import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.join.Equality;\n+import org.apache.druid.segment.join.HashJoinSegmentStorageAdapter;\n+import org.apache.druid.segment.join.JoinConditionAnalysis;\n+import org.apache.druid.segment.join.JoinableClause;\n import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n \n import javax.annotation.Nullable;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.HashMap;\n-import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n+import java.util.Optional;\n import java.util.Set;\n \n+/**\n+ * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n+ * when we first read from the base table instead of after the join.\n+ *\n+ * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Filter)} method that\n+ * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n+ * portion that should be applied after the join.\n+ *\n+ * The first step of the filter splitting is to convert the fllter into\n+ * https://en.wikipedia.org/wiki/Conjunctive_normal_form (an AND of ORs). This allows us to consider each\n+ * OR clause independently as a candidate for filter push down to the base table.\n+ *\n+ * A filter clause can be pushed down if it meets one of the following conditions:\n+ * - The filter only applies to columns from the base table\n+ * - The filter applies to columns from the join table, and we determine that the filter can be rewritten\n+ *   into a filter on columns from the base table\n+ *\n+ * For the second case, where we rewrite filter clauses, the rewritten clause can be less selective than the original,\n+ * so we preserve the original clause in the post-join filtering phase.\n+ */\n public class JoinFilterAnalyzer\n {\n   private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -17,43 +17,55 @@\n  * under the License.\n  */\n \n-package org.apache.druid.segment.join;\n+package org.apache.druid.segment.join.filter;\n \n import com.google.common.collect.ImmutableList;\n-import it.unimi.dsi.fastutil.ints.IntList;\n import org.apache.druid.math.expr.Expr;\n-import org.apache.druid.query.dimension.DimensionSpec;\n import org.apache.druid.query.filter.Filter;\n import org.apache.druid.query.filter.InDimFilter;\n import org.apache.druid.query.filter.ValueMatcher;\n import org.apache.druid.segment.ColumnSelectorFactory;\n-import org.apache.druid.segment.ColumnValueSelector;\n-import org.apache.druid.segment.DimensionSelector;\n-import org.apache.druid.segment.NilColumnValueSelector;\n import org.apache.druid.segment.VirtualColumn;\n-import org.apache.druid.segment.column.ColumnCapabilities;\n import org.apache.druid.segment.column.ValueType;\n import org.apache.druid.segment.filter.AndFilter;\n import org.apache.druid.segment.filter.Filters;\n-import org.apache.druid.segment.filter.InFilter;\n import org.apache.druid.segment.filter.OrFilter;\n import org.apache.druid.segment.filter.SelectorFilter;\n-import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n-import org.apache.druid.segment.join.lookup.LookupJoinable;\n-import org.apache.druid.segment.join.table.IndexedTable;\n-import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.join.Equality;\n+import org.apache.druid.segment.join.HashJoinSegmentStorageAdapter;\n+import org.apache.druid.segment.join.JoinConditionAnalysis;\n+import org.apache.druid.segment.join.JoinableClause;\n import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n \n import javax.annotation.Nullable;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.HashMap;\n-import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n+import java.util.Optional;\n import java.util.Set;\n \n+/**\n+ * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n+ * when we first read from the base table instead of after the join.\n+ *\n+ * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Filter)} method that\n+ * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n+ * portion that should be applied after the join.\n+ *\n+ * The first step of the filter splitting is to convert the fllter into\n+ * https://en.wikipedia.org/wiki/Conjunctive_normal_form (an AND of ORs). This allows us to consider each\n+ * OR clause independently as a candidate for filter push down to the base table.\n+ *\n+ * A filter clause can be pushed down if it meets one of the following conditions:\n+ * - The filter only applies to columns from the base table\n+ * - The filter applies to columns from the join table, and we determine that the filter can be rewritten\n+ *   into a filter on columns from the base table\n+ *\n+ * For the second case, where we rewrite filter clauses, the rewritten clause can be less selective than the original,\n+ * so we preserve the original clause in the post-join filtering phase.\n+ */\n public class JoinFilterAnalyzer\n {\n   private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzg3Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375007877", "body": "Skimming a bit, it seems like this would work if it was given a `List<JoinableClause>` instead of a `HashJoinSegmentStorageAdapter`. If so, that'd be a good change (it's better for methods like this to take conceptually smaller objects \u2014\u00a0unit testing is easier, and it makes it clearer what the 'real' dependencies are of the computation it is doing).", "bodyText": "Skimming a bit, it seems like this would work if it was given a List<JoinableClause> instead of a HashJoinSegmentStorageAdapter. If so, that'd be a good change (it's better for methods like this to take conceptually smaller objects \u2014\u00a0unit testing is easier, and it makes it clearer what the 'real' dependencies are of the computation it is doing).", "bodyHTML": "<p dir=\"auto\">Skimming a bit, it seems like this would work if it was given a <code>List&lt;JoinableClause&gt;</code> instead of a <code>HashJoinSegmentStorageAdapter</code>. If so, that'd be a good change (it's better for methods like this to take conceptually smaller objects \u2014\u00a0unit testing is easier, and it makes it clearer what the 'real' dependencies are of the computation it is doing).</p>", "author": "gianm", "createdAt": "2020-02-05T00:57:27Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjI3MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666271", "bodyText": "Right now it could be changed to just accept a list of joinable clauses, but in the future I think the filter analysis would likely need to check the column capabilities and other info from the adapter, so I think it should accept the adapter instead", "author": "jon-wei", "createdAt": "2020-02-06T06:56:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzg3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -17,43 +17,55 @@\n  * under the License.\n  */\n \n-package org.apache.druid.segment.join;\n+package org.apache.druid.segment.join.filter;\n \n import com.google.common.collect.ImmutableList;\n-import it.unimi.dsi.fastutil.ints.IntList;\n import org.apache.druid.math.expr.Expr;\n-import org.apache.druid.query.dimension.DimensionSpec;\n import org.apache.druid.query.filter.Filter;\n import org.apache.druid.query.filter.InDimFilter;\n import org.apache.druid.query.filter.ValueMatcher;\n import org.apache.druid.segment.ColumnSelectorFactory;\n-import org.apache.druid.segment.ColumnValueSelector;\n-import org.apache.druid.segment.DimensionSelector;\n-import org.apache.druid.segment.NilColumnValueSelector;\n import org.apache.druid.segment.VirtualColumn;\n-import org.apache.druid.segment.column.ColumnCapabilities;\n import org.apache.druid.segment.column.ValueType;\n import org.apache.druid.segment.filter.AndFilter;\n import org.apache.druid.segment.filter.Filters;\n-import org.apache.druid.segment.filter.InFilter;\n import org.apache.druid.segment.filter.OrFilter;\n import org.apache.druid.segment.filter.SelectorFilter;\n-import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n-import org.apache.druid.segment.join.lookup.LookupJoinable;\n-import org.apache.druid.segment.join.table.IndexedTable;\n-import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.join.Equality;\n+import org.apache.druid.segment.join.HashJoinSegmentStorageAdapter;\n+import org.apache.druid.segment.join.JoinConditionAnalysis;\n+import org.apache.druid.segment.join.JoinableClause;\n import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n \n import javax.annotation.Nullable;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.HashMap;\n-import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n+import java.util.Optional;\n import java.util.Set;\n \n+/**\n+ * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n+ * when we first read from the base table instead of after the join.\n+ *\n+ * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Filter)} method that\n+ * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n+ * portion that should be applied after the join.\n+ *\n+ * The first step of the filter splitting is to convert the fllter into\n+ * https://en.wikipedia.org/wiki/Conjunctive_normal_form (an AND of ORs). This allows us to consider each\n+ * OR clause independently as a candidate for filter push down to the base table.\n+ *\n+ * A filter clause can be pushed down if it meets one of the following conditions:\n+ * - The filter only applies to columns from the base table\n+ * - The filter applies to columns from the join table, and we determine that the filter can be rewritten\n+ *   into a filter on columns from the base table\n+ *\n+ * For the second case, where we rewrite filter clauses, the rewritten clause can be less selective than the original,\n+ * so we preserve the original clause in the post-join filtering phase.\n+ */\n public class JoinFilterAnalyzer\n {\n   private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n", "next_change": null}, {"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -65,7 +77,7 @@ public class JoinFilterAnalyzer\n   )\n   {\n     if (originalFilter == null) {\n-      return new JoinFilterAnalyzer.JoinFilterSplit(\n+      return new JoinFilterSplit(\n           null,\n           null,\n           ImmutableList.of()\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -17,43 +17,55 @@\n  * under the License.\n  */\n \n-package org.apache.druid.segment.join;\n+package org.apache.druid.segment.join.filter;\n \n import com.google.common.collect.ImmutableList;\n-import it.unimi.dsi.fastutil.ints.IntList;\n import org.apache.druid.math.expr.Expr;\n-import org.apache.druid.query.dimension.DimensionSpec;\n import org.apache.druid.query.filter.Filter;\n import org.apache.druid.query.filter.InDimFilter;\n import org.apache.druid.query.filter.ValueMatcher;\n import org.apache.druid.segment.ColumnSelectorFactory;\n-import org.apache.druid.segment.ColumnValueSelector;\n-import org.apache.druid.segment.DimensionSelector;\n-import org.apache.druid.segment.NilColumnValueSelector;\n import org.apache.druid.segment.VirtualColumn;\n-import org.apache.druid.segment.column.ColumnCapabilities;\n import org.apache.druid.segment.column.ValueType;\n import org.apache.druid.segment.filter.AndFilter;\n import org.apache.druid.segment.filter.Filters;\n-import org.apache.druid.segment.filter.InFilter;\n import org.apache.druid.segment.filter.OrFilter;\n import org.apache.druid.segment.filter.SelectorFilter;\n-import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n-import org.apache.druid.segment.join.lookup.LookupJoinable;\n-import org.apache.druid.segment.join.table.IndexedTable;\n-import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.join.Equality;\n+import org.apache.druid.segment.join.HashJoinSegmentStorageAdapter;\n+import org.apache.druid.segment.join.JoinConditionAnalysis;\n+import org.apache.druid.segment.join.JoinableClause;\n import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n \n import javax.annotation.Nullable;\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.HashMap;\n-import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n+import java.util.Optional;\n import java.util.Set;\n \n+/**\n+ * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n+ * when we first read from the base table instead of after the join.\n+ *\n+ * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Filter)} method that\n+ * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n+ * portion that should be applied after the join.\n+ *\n+ * The first step of the filter splitting is to convert the fllter into\n+ * https://en.wikipedia.org/wiki/Conjunctive_normal_form (an AND of ORs). This allows us to consider each\n+ * OR clause independently as a candidate for filter push down to the base table.\n+ *\n+ * A filter clause can be pushed down if it meets one of the following conditions:\n+ * - The filter only applies to columns from the base table\n+ * - The filter applies to columns from the join table, and we determine that the filter can be rewritten\n+ *   into a filter on columns from the base table\n+ *\n+ * For the second case, where we rewrite filter clauses, the rewritten clause can be less selective than the original,\n+ * so we preserve the original clause in the post-join filtering phase.\n+ */\n public class JoinFilterAnalyzer\n {\n   private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n", "next_change": null}, {"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -65,7 +77,7 @@ public class JoinFilterAnalyzer\n   )\n   {\n     if (originalFilter == null) {\n-      return new JoinFilterAnalyzer.JoinFilterSplit(\n+      return new JoinFilterSplit(\n           null,\n           null,\n           ImmutableList.of()\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375009323", "body": "This code assumes that no two clauses have the same prefix, and (maybe also?) that the prefixes don't shadow each other. I don't think anything currently verifies either of those preconditions. It'd be good to add validation somewhere. Maybe right here, or maybe in HashJoinSegment's constructor. Maybe add a `Joinables` function that verifies it and call it wherever might care.", "bodyText": "This code assumes that no two clauses have the same prefix, and (maybe also?) that the prefixes don't shadow each other. I don't think anything currently verifies either of those preconditions. It'd be good to add validation somewhere. Maybe right here, or maybe in HashJoinSegment's constructor. Maybe add a Joinables function that verifies it and call it wherever might care.", "bodyHTML": "<p dir=\"auto\">This code assumes that no two clauses have the same prefix, and (maybe also?) that the prefixes don't shadow each other. I don't think anything currently verifies either of those preconditions. It'd be good to add validation somewhere. Maybe right here, or maybe in HashJoinSegment's constructor. Maybe add a <code>Joinables</code> function that verifies it and call it wherever might care.</p>", "author": "gianm", "createdAt": "2020-02-05T01:02:49Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjUzMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666532", "bodyText": "Hm, that sounds good, but can we address this in a follow-on PR since it's not specific to the filtering code?", "author": "jon-wei", "createdAt": "2020-02-06T06:58:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA1MjA3OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376052078", "bodyText": "I think it is specific to the filtering code, because it's handled consistently elsewhere. (The clauses check in order whether they match and the first one wins.) So this patch is introducing an inconsistency in behavior that didn't used to exist. But I do think it's fine to do in a follow on. Please raise a github issue and add a comment pointing to it.", "author": "gianm", "createdAt": "2020-02-06T20:01:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTA5OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129098", "bodyText": "I opened #9329 and linked it in a comment here", "author": "jon-wei", "createdAt": "2020-02-06T22:58:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw=="}], "type": "inlineReview", "revised_code": {"commit": "dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -75,6 +87,10 @@ public class JoinFilterAnalyzer\n     Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n \n     // build the prefix and equicondition maps\n+    // We should check that the prefixes do not duplicate or shadow each other. This is not currently implemented,\n+    // but this is tracked at https://github.com/apache/druid/issues/9329\n+    // We should also consider the case where one RHS column is joined to multiple columns:\n+    // https://github.com/apache/druid/issues/9328\n     Map<String, Expr> equiconditions = new HashMap<>();\n     Map<String, JoinableClause> prefixes = new HashMap<>();\n     for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -75,6 +87,10 @@ public class JoinFilterAnalyzer\n     Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n \n     // build the prefix and equicondition maps\n+    // We should check that the prefixes do not duplicate or shadow each other. This is not currently implemented,\n+    // but this is tracked at https://github.com/apache/druid/issues/9329\n+    // We should also consider the case where one RHS column is joined to multiple columns:\n+    // https://github.com/apache/druid/issues/9328\n     Map<String, Expr> equiconditions = new HashMap<>();\n     Map<String, JoinableClause> prefixes = new HashMap<>();\n     for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMDcyOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375010728", "body": "Maybe clearer to say that this single clause is expected to be either an OR or a leaf filter.", "bodyText": "Maybe clearer to say that this single clause is expected to be either an OR or a leaf filter.", "bodyHTML": "<p dir=\"auto\">Maybe clearer to say that this single clause is expected to be either an OR or a leaf filter.</p>", "author": "gianm", "createdAt": "2020-02-05T01:07:55Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjU5NA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666594", "bodyText": "Adjusted the wording to the suggested", "author": "jon-wei", "createdAt": "2020-02-06T06:58:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMDcyOA=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +133,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +137,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMjQ4OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375012488", "body": "Would be nice to say why (I presume it's something like: conditions that match NULL are tricky to push down when doing OUTER JOINs, and we'd rather not worry about that right now).", "bodyText": "Would be nice to say why (I presume it's something like: conditions that match NULL are tricky to push down when doing OUTER JOINs, and we'd rather not worry about that right now).", "bodyHTML": "<p dir=\"auto\">Would be nice to say why (I presume it's something like: conditions that match NULL are tricky to push down when doing OUTER JOINs, and we'd rather not worry about that right now).</p>", "author": "gianm", "createdAt": "2020-02-05T01:15:05Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjcwMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666701", "bodyText": "Added a comment about why NULL matching conditions are not handled now", "author": "jon-wei", "createdAt": "2020-02-06T06:58:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMjQ4OA=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -214,10 +158,12 @@ public class JoinFilterAnalyzer\n       Filter filterClause,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n-    // NULL matching conditions are not currently pushed down\n+    // NULL matching conditions are not currently pushed down.\n+    // They require special consideration based on the join type, and for simplicity of the initial implementation\n+    // this is not currently handled.\n     if (filterMatchesNull(filterClause)) {\n       return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n     }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -214,10 +162,12 @@ public class JoinFilterAnalyzer\n       Filter filterClause,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n-    // NULL matching conditions are not currently pushed down\n+    // NULL matching conditions are not currently pushed down.\n+    // They require special consideration based on the join type, and for simplicity of the initial implementation\n+    // this is not currently handled.\n     if (filterMatchesNull(filterClause)) {\n       return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n     }\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzQxNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375013414", "body": "It looks like it's expected that callers will modify this parameter. It'd be good to note that (and any other case where it's expected that parameters will be modified).", "bodyText": "It looks like it's expected that callers will modify this parameter. It'd be good to note that (and any other case where it's expected that parameters will be modified).", "bodyHTML": "<p dir=\"auto\">It looks like it's expected that callers will modify this parameter. It'd be good to note that (and any other case where it's expected that parameters will be modified).</p>", "author": "gianm", "createdAt": "2020-02-05T01:18:30Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Njc4NA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666784", "bodyText": "Added a note about the cache being modified", "author": "jon-wei", "createdAt": "2020-02-06T06:58:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzQxNA=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +133,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +137,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375014730", "body": "Instead of doing an `instanceof`, could you add a method to Joinable that enables this use case? The interface is still really new and we should be evolving it to meet our needs.", "bodyText": "Instead of doing an instanceof, could you add a method to Joinable that enables this use case? The interface is still really new and we should be evolving it to meet our needs.", "bodyHTML": "<p dir=\"auto\">Instead of doing an <code>instanceof</code>, could you add a method to Joinable that enables this use case? The interface is still really new and we should be evolving it to meet our needs.</p>", "author": "gianm", "createdAt": "2020-02-05T01:23:16Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Njg2OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666869", "bodyText": "Added a getCorrelatedColumnValues method on Joinable", "author": "jon-wei", "createdAt": "2020-02-06T06:59:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2MTA0MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376061041", "bodyText": "I just read the javadoc. Could you please clarify (or rename) what \"main column\" means and also where \"correlationColumnName\" is supposed to come from? They're concepts that haven't been defined elsewhere in the class and it's not immediately clear to me what they mean. I'm guessing both columns are from the Joinable itself, and \"main column\" means the one being searched and \"correlation column\" means the one being retrieved.\nCurrently it says:\n\nGiven a key column name and value, return all the values of the column denoted by correlationColumnName that appear in rows where the main column has the provided main column value.\n\nIf my guesses are right then how about:\n\nSearches a column from this Joinable for a particular value, finds rows that match and returns values of a second column for those rows.\nArguments \"searchColumn\", \"searchValue\", \"retrievalColumn\"", "author": "gianm", "createdAt": "2020-02-06T20:20:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTI2MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129261", "bodyText": "Thanks, those are much better names, changed to the suggested description and names", "author": "jon-wei", "createdAt": "2020-02-06T22:58:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -455,62 +402,11 @@ public class JoinFilterAnalyzer\n     String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n     String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n \n-    // would be good to allow non-key column indices on the Joinables for better perf\n-    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n-      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n-      List<String> correlatedValues;\n-      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n-        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n-        }\n-      } else {\n-        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n-        }\n-      }\n-      return correlatedValues;\n-    }\n-\n-    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n-      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n-      IndexedTable indexedTable = indexedTableJoinable.getTable();\n-\n-      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n-      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n-\n-      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n-        return null;\n-      }\n-\n-      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n-        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n-        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n-        IntList rowIndex = index.find(filterValue);\n-        List<String> correlatedValues = new ArrayList<>();\n-        for (int i = 0; i < rowIndex.size(); i++) {\n-          int rowNum = rowIndex.getInt(i);\n-          correlatedValues.add(reader.read(rowNum).toString());\n-        }\n-        return correlatedValues;\n-      } else {\n-        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n-        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n-        Set<String> correlatedValueSet = new HashSet<>();\n-        for (int i = 0; i < indexedTable.numRows(); i++) {\n-          if (filterValue.equals(dimNameReader.read(i).toString())) {\n-            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n-          }\n-        }\n-\n-        return new ArrayList<>(correlatedValueSet);\n-      }\n-    }\n-\n-    return null;\n+    return clauseForFilteredTable.getJoinable().getCorrelatedColumnValues(\n+        filterColumnNoPrefix,\n+        filterValue,\n+        correlatedColumnNoPrefix\n+    );\n   }\n \n   /**\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -455,81 +407,50 @@ public class JoinFilterAnalyzer\n     String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n     String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n \n-    // would be good to allow non-key column indices on the Joinables for better perf\n-    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n-      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n-      List<String> correlatedValues;\n-      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n-        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n-        }\n-      } else {\n-        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n-        }\n-      }\n-      return correlatedValues;\n-    }\n-\n-    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n-      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n-      IndexedTable indexedTable = indexedTableJoinable.getTable();\n-\n-      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n-      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n-\n-      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n-        return null;\n-      }\n-\n-      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n-        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n-        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n-        IntList rowIndex = index.find(filterValue);\n-        List<String> correlatedValues = new ArrayList<>();\n-        for (int i = 0; i < rowIndex.size(); i++) {\n-          int rowNum = rowIndex.getInt(i);\n-          correlatedValues.add(reader.read(rowNum).toString());\n-        }\n-        return correlatedValues;\n-      } else {\n-        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n-        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n-        Set<String> correlatedValueSet = new HashSet<>();\n-        for (int i = 0; i < indexedTable.numRows(); i++) {\n-          if (filterValue.equals(dimNameReader.read(i).toString())) {\n-            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n-          }\n-        }\n-\n-        return new ArrayList<>(correlatedValueSet);\n-      }\n-    }\n-\n-    return null;\n+    return clauseForFilteredTable.getJoinable().getCorrelatedColumnValues(\n+        filterColumnNoPrefix,\n+        filterValue,\n+        correlatedColumnNoPrefix\n+    );\n   }\n \n   /**\n-   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   * For each rhs column that appears in the equiconditions for a table's JoinableClause,\n+   * we try to determine what base table columns are related to the rhs column through the total set of equiconditions.\n+   * We do this by searching backwards through the chain of join equiconditions using the provided equicondition map.\n+   *\n+   * For example, suppose we have 3 tables, A,B,C, joined with the following conditions, where A is the base table:\n+   *   A.joinColumn == B.joinColumn\n+   *   B.joinColum == C.joinColumn\n+   *\n+   * We would determine that C.joinColumn is correlated with A.joinColumn: we first see that\n+   * C.joinColumn is linked to B.joinColumn which in turn is linked to A.joinColumn\n+   *\n+   * Suppose we had the following join conditions instead:\n+   *   f(A.joinColumn) == B.joinColumn\n+   *   B.joinColum == C.joinColumn\n+   * In this case, the JoinFilterColumnCorrelationAnalysis for C.joinColumn would be linked to f(A.joinColumn).\n+   *\n+   * Suppose we had the following join conditions instead:\n+   *   A.joinColumn == B.joinColumn\n+   *   f(B.joinColum) == C.joinColumn\n+   *\n+   * Because we cannot reverse the function f() applied to the second table B in all cases,\n+   * we cannot relate C.joinColumn to A.joinColumn, and we would not generate a correlation for C.joinColumn\n    *\n    * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n    * @param tablePrefix          Prefix for a join table\n    * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n    *\n    * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n    * the tablePrefix\n    */\n-  @Nullable\n-  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n       HashJoinSegmentStorageAdapter adapter,\n       String tablePrefix,\n       JoinableClause clauseForTablePrefix,\n-      Map<String, Expr> equiconditions\n+      Map<String, Expr> equiConditions\n   )\n   {\n     JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjgxMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375016811", "body": "Do people outside this class need to be able to make their own? Could be `private` if not.", "bodyText": "Do people outside this class need to be able to make their own? Could be private if not.", "bodyHTML": "<p dir=\"auto\">Do people outside this class need to be able to make their own? Could be <code>private</code> if not.</p>", "author": "gianm", "createdAt": "2020-02-05T01:31:22Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzA2Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667062", "bodyText": "I moved this into a separate file, the tests need to be able to create expected splits so the new class is public", "author": "jon-wei", "createdAt": "2020-02-06T07:00:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjgxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +133,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +137,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375017083", "body": "This should be `@Nullable` given the annotation in the constructor.\r\n\r\nAlternatively, consider `Optional<Filter>` rather than `@Nullable Filter`.", "bodyText": "This should be @Nullable given the annotation in the constructor.\nAlternatively, consider Optional<Filter> rather than @Nullable Filter.", "bodyHTML": "<p dir=\"auto\">This should be <code>@Nullable</code> given the annotation in the constructor.</p>\n<p dir=\"auto\">Alternatively, consider <code>Optional&lt;Filter&gt;</code> rather than <code>@Nullable Filter</code>.</p>", "author": "gianm", "createdAt": "2020-02-05T01:32:31Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzE2MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667161", "bodyText": "Adjusted this to return Optional<Filter> for the filter getters", "author": "jon-wei", "createdAt": "2020-02-06T07:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2MTI1OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376061258", "bodyText": "Rad.", "author": "gianm", "createdAt": "2020-02-06T20:21:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +133,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +137,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxOTc2Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375019767", "body": "nit: Inconsistent spelling of \"pushdown\" (or \"pushDown\"?) between isCanPushDown, getPushdownFilter.", "bodyText": "nit: Inconsistent spelling of \"pushdown\" (or \"pushDown\"?) between isCanPushDown, getPushdownFilter.", "bodyHTML": "<p dir=\"auto\">nit: Inconsistent spelling of \"pushdown\" (or \"pushDown\"?) between isCanPushDown, getPushdownFilter.</p>", "author": "gianm", "createdAt": "2020-02-05T01:43:06Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzIyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667223", "bodyText": "Made these use pushDown consistently", "author": "jon-wei", "createdAt": "2020-02-06T07:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxOTc2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -110,9 +122,9 @@ public class JoinFilterAnalyzer\n           correlationCache\n       );\n       if (joinFilterAnalysis.isCanPushDown()) {\n-        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n-        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n-          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        leftFilters.add(joinFilterAnalysis.getPushDownFilter().get());\n+        if (!joinFilterAnalysis.getPushDownVirtualColumns().isEmpty()) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushDownVirtualColumns());\n         }\n       }\n       if (joinFilterAnalysis.isRetainAfterJoin()) {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -110,9 +126,9 @@ public class JoinFilterAnalyzer\n           correlationCache\n       );\n       if (joinFilterAnalysis.isCanPushDown()) {\n-        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n-        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n-          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        leftFilters.add(joinFilterAnalysis.getPushDownFilter().get());\n+        if (!joinFilterAnalysis.getPushDownVirtualColumns().isEmpty()) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushDownVirtualColumns());\n         }\n       }\n       if (joinFilterAnalysis.isRetainAfterJoin()) {\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDIwOQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375020209", "body": "It looks like this is the only spot getPushdownVirtualColumns is null-guarded, and in this case, using an empty list instead of null would have the same effect. Maybe nix the nullability and use an empty list instead?", "bodyText": "It looks like this is the only spot getPushdownVirtualColumns is null-guarded, and in this case, using an empty list instead of null would have the same effect. Maybe nix the nullability and use an empty list instead?", "bodyHTML": "<p dir=\"auto\">It looks like this is the only spot getPushdownVirtualColumns is null-guarded, and in this case, using an empty list instead of null would have the same effect. Maybe nix the nullability and use an empty list instead?</p>", "author": "gianm", "createdAt": "2020-02-05T01:44:53Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzMwNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667304", "bodyText": "Adjusted getPushdownVirtualColumns to use an empty list instead", "author": "jon-wei", "createdAt": "2020-02-06T07:01:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDIwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -110,9 +122,9 @@ public class JoinFilterAnalyzer\n           correlationCache\n       );\n       if (joinFilterAnalysis.isCanPushDown()) {\n-        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n-        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n-          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        leftFilters.add(joinFilterAnalysis.getPushDownFilter().get());\n+        if (!joinFilterAnalysis.getPushDownVirtualColumns().isEmpty()) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushDownVirtualColumns());\n         }\n       }\n       if (joinFilterAnalysis.isRetainAfterJoin()) {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -110,9 +126,9 @@ public class JoinFilterAnalyzer\n           correlationCache\n       );\n       if (joinFilterAnalysis.isCanPushDown()) {\n-        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n-        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n-          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        leftFilters.add(joinFilterAnalysis.getPushDownFilter().get());\n+        if (!joinFilterAnalysis.getPushDownVirtualColumns().isEmpty()) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushDownVirtualColumns());\n         }\n       }\n       if (joinFilterAnalysis.isRetainAfterJoin()) {\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDc3Ng==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375020776", "body": "Small suggestion: might be nice to make this a helper method like `Filters.and(List<Filter>)`. This logic is duplicated in QueryableIndexStroageAdapter, so they could both use such a helper.", "bodyText": "Small suggestion: might be nice to make this a helper method like Filters.and(List<Filter>). This logic is duplicated in QueryableIndexStroageAdapter, so they could both use such a helper.", "bodyHTML": "<p dir=\"auto\">Small suggestion: might be nice to make this a helper method like <code>Filters.and(List&lt;Filter&gt;)</code>. This logic is duplicated in QueryableIndexStroageAdapter, so they could both use such a helper.</p>", "author": "gianm", "createdAt": "2020-02-05T01:47:12Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzM5Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667392", "bodyText": "Added a Filters.and method and adjusted this and QueryableIndexStroageAdapter", "author": "jon-wei", "createdAt": "2020-02-06T07:01:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDc3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +133,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -121,91 +137,23 @@ public class JoinFilterAnalyzer\n     }\n \n     return new JoinFilterSplit(\n-        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n-        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        Filters.and(leftFilters),\n+        Filters.and(rightFilters),\n         pushDownVirtualColumns\n     );\n   }\n \n-  /**\n-   * Holds the result of splitting a filter into:\n-   * - a portion that can be pushed down to the base table\n-   * - a portion that will be applied post-join\n-   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n-   */\n-  public static class JoinFilterSplit\n-  {\n-    final Filter baseTableFilter;\n-    final Filter joinTableFilter;\n-    final List<VirtualColumn> pushDownVirtualColumns;\n-\n-    public JoinFilterSplit(\n-        Filter baseTableFilter,\n-        @Nullable Filter joinTableFilter,\n-        List<VirtualColumn> pushDownVirtualColumns\n-    )\n-    {\n-      this.baseTableFilter = baseTableFilter;\n-      this.joinTableFilter = joinTableFilter;\n-      this.pushDownVirtualColumns = pushDownVirtualColumns;\n-    }\n-\n-    public Filter getBaseTableFilter()\n-    {\n-      return baseTableFilter;\n-    }\n \n-    public Filter getJoinTableFilter()\n-    {\n-      return joinTableFilter;\n-    }\n-\n-    public List<VirtualColumn> getPushDownVirtualColumns()\n-    {\n-      return pushDownVirtualColumns;\n-    }\n-\n-    @Override\n-    public String toString()\n-    {\n-      return \"JoinFilterSplit{\" +\n-             \"baseTableFilter=\" + baseTableFilter +\n-             \", joinTableFilter=\" + joinTableFilter +\n-             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n-             '}';\n-    }\n-\n-    @Override\n-    public boolean equals(Object o)\n-    {\n-      if (this == o) {\n-        return true;\n-      }\n-      if (o == null || getClass() != o.getClass()) {\n-        return false;\n-      }\n-      JoinFilterSplit that = (JoinFilterSplit) o;\n-      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n-             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n-             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n-    }\n-\n-    @Override\n-    public int hashCode()\n-    {\n-      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n-    }\n-  }\n \n   /**\n-   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n-   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   * Analyze a filter clause from a filter that is in conjunctive normal form (AND of ORs).\n+   * The clause is expected to be an OR filter or a leaf filter.\n    *\n    * @param adapter          Adapter for the join\n-   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param filterClause     Individual filter clause (an OR filter or a leaf filter) from a filter that is in CNF\n    * @param prefixes         Map of table prefixes\n    * @param equiconditions   Equicondition map\n-   * @param correlationCache Cache of column correlation analyses\n+   * @param correlationCache Cache of column correlation analyses.\n    *\n    * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n    */\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMjI2Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375022267", "body": "Should use `prefixAndClause.getValue().includesColumn(filteringColumn)` \u2014\u00a0it's more semantically intentful and also the logic is slightly different.", "bodyText": "Should use prefixAndClause.getValue().includesColumn(filteringColumn) \u2014\u00a0it's more semantically intentful and also the logic is slightly different.", "bodyHTML": "<p dir=\"auto\">Should use <code>prefixAndClause.getValue().includesColumn(filteringColumn)</code> \u2014\u00a0it's more semantically intentful and also the logic is slightly different.</p>", "author": "gianm", "createdAt": "2020-02-05T01:53:24Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzQyNw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667427", "bodyText": "Changed to the suggested", "author": "jon-wei", "createdAt": "2020-02-06T07:01:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMjI2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -336,13 +282,13 @@ public class JoinFilterAnalyzer\n       SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n-        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n+        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n             prefixAndClause.getKey(),\n             p -> findCorrelatedBaseTableColumns(\n                 baseAdapter,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -336,13 +286,13 @@ public class JoinFilterAnalyzer\n       SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n-        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n+        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n             prefixAndClause.getKey(),\n             p -> findCorrelatedBaseTableColumns(\n                 baseAdapter,\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMzA0MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375023041", "body": "`null` is used for two things here:\r\n\r\n(a) correlationCache hasn't been populated yet\r\n(b) correlationCache has been populated, but findCorrelatedBaseTableColumns returned null\r\n\r\nWould it make sense to have findCorrelatedBaseTableColumns return `Optional<List<JoinFilterColumnCorrelationAnalysis>>` rather than `@Nullable List<JoinFilterColumnCorrelationAnalysis>`?", "bodyText": "null is used for two things here:\n(a) correlationCache hasn't been populated yet\n(b) correlationCache has been populated, but findCorrelatedBaseTableColumns returned null\nWould it make sense to have findCorrelatedBaseTableColumns return Optional<List<JoinFilterColumnCorrelationAnalysis>> rather than @Nullable List<JoinFilterColumnCorrelationAnalysis>?", "bodyHTML": "<p dir=\"auto\"><code>null</code> is used for two things here:</p>\n<p dir=\"auto\">(a) correlationCache hasn't been populated yet<br>\n(b) correlationCache has been populated, but findCorrelatedBaseTableColumns returned null</p>\n<p dir=\"auto\">Would it make sense to have findCorrelatedBaseTableColumns return <code>Optional&lt;List&lt;JoinFilterColumnCorrelationAnalysis&gt;&gt;</code> rather than <code>@Nullable List&lt;JoinFilterColumnCorrelationAnalysis&gt;</code>?</p>", "author": "gianm", "createdAt": "2020-02-05T01:56:41Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzUyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667526", "bodyText": "Hm, good point, I changed the map values to Optional<List<JoinFilterColumnCorrelationAnalysis>>", "author": "jon-wei", "createdAt": "2020-02-06T07:01:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMzA0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -336,13 +282,13 @@ public class JoinFilterAnalyzer\n       SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n-        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n+        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n             prefixAndClause.getKey(),\n             p -> findCorrelatedBaseTableColumns(\n                 baseAdapter,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -336,13 +286,13 @@ public class JoinFilterAnalyzer\n       SelectorFilter selectorFilter,\n       Map<String, JoinableClause> prefixes,\n       Map<String, Expr> equiconditions,\n-      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n   )\n   {\n     String filteringColumn = selectorFilter.getDimension();\n     for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n-        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n+        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n             prefixAndClause.getKey(),\n             p -> findCorrelatedBaseTableColumns(\n                 baseAdapter,\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNDYyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375024626", "body": "This class is pretty jam packed with different concepts and inner classes, maybe it would make sense to put it in its own `org.apache.druid.segment.join.filter` package and split it up into different classes? (Sort of like DataSourceAnalysis and its friend PreJoinableClause in `org.apache.druid.query.planning`, but this one is even more complex)", "bodyText": "This class is pretty jam packed with different concepts and inner classes, maybe it would make sense to put it in its own org.apache.druid.segment.join.filter package and split it up into different classes? (Sort of like DataSourceAnalysis and its friend PreJoinableClause in org.apache.druid.query.planning, but this one is even more complex)", "bodyHTML": "<p dir=\"auto\">This class is pretty jam packed with different concepts and inner classes, maybe it would make sense to put it in its own <code>org.apache.druid.segment.join.filter</code> package and split it up into different classes? (Sort of like DataSourceAnalysis and its friend PreJoinableClause in <code>org.apache.druid.query.planning</code>, but this one is even more complex)</p>", "author": "gianm", "createdAt": "2020-02-05T02:03:20Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;\n+          if (adapter.isBaseColumn(identifier)) {\n+            terminate = true;\n+            correlatedBaseColumns.add(findMappingFor);\n+          }\n+        }\n+      }\n+\n+      if (correlatedBaseColumns.isEmpty() && correlatedBaseExpressions.isEmpty()) {\n+        return null;\n+      }\n+\n+      correlations.add(\n+          new JoinFilterColumnCorrelationAnalysis(\n+              rhsColumn,\n+              correlatedBaseColumns,\n+              correlatedBaseExpressions\n+          )\n+      );\n+    }\n+\n+    return correlations;\n+  }\n+\n+  private static boolean filterMatchesNull(Filter filter)\n+  {\n+    ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n+    return valueMatcher.matches();\n+  }\n+\n+  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzY0Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667642", "bodyText": "I split out the inner classes and JoinFilterAnalyzer into a new package org.apache.druid.segment.join.filter", "author": "jon-wei", "createdAt": "2020-02-06T07:02:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNDYyNg=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -596,148 +489,4 @@ public class JoinFilterAnalyzer\n     ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n-\n-  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory\n-  {\n-    @Override\n-    public DimensionSelector makeDimensionSelector(DimensionSpec dimensionSpec)\n-    {\n-      return DimensionSelector.constant(null);\n-    }\n-\n-    @Override\n-    public ColumnValueSelector<?> makeColumnValueSelector(String columnName)\n-    {\n-      return NilColumnValueSelector.instance();\n-    }\n-\n-    @Override\n-    public ColumnCapabilities getColumnCapabilities(String columnName)\n-    {\n-      return null;\n-    }\n-  }\n-\n-  /**\n-   * Holds information about:\n-   * - whether a filter can be pushed down\n-   * - if it needs to be retained after the join,\n-   * - a reference to the original filter\n-   * - a potentially rewritten filter to be pushed down to the base table\n-   * - a list of virtual columns that need to be created on the base table to support the pushed down filter\n-   */\n-  private static class JoinFilterAnalysis\n-  {\n-    private final boolean canPushDown;\n-    private final boolean retainAfterJoin;\n-    private final Filter originalFilter;\n-    private final Filter pushdownFilter;\n-    private final List<VirtualColumn> pushdownVirtualColumns;\n-\n-    public JoinFilterAnalysis(\n-        boolean canPushDown,\n-        boolean retainAfterJoin,\n-        Filter originalFilter,\n-        @Nullable Filter pushdownFilter,\n-        @Nullable List<VirtualColumn> pushdownVirtualColumns\n-    )\n-    {\n-      this.canPushDown = canPushDown;\n-      this.retainAfterJoin = retainAfterJoin;\n-      this.originalFilter = originalFilter;\n-      this.pushdownFilter = pushdownFilter;\n-      this.pushdownVirtualColumns = pushdownVirtualColumns;\n-    }\n-\n-    public boolean isCanPushDown()\n-    {\n-      return canPushDown;\n-    }\n-\n-    public boolean isRetainAfterJoin()\n-    {\n-      return retainAfterJoin;\n-    }\n-\n-    public Filter getOriginalFilter()\n-    {\n-      return originalFilter;\n-    }\n-\n-    @Nullable\n-    public Filter getPushdownFilter()\n-    {\n-      return pushdownFilter;\n-    }\n-\n-    @Nullable\n-    public List<VirtualColumn> getPushdownVirtualColumns()\n-    {\n-      return pushdownVirtualColumns;\n-    }\n-\n-    /**\n-     * Utility method for generating an analysis that represents: \"Filter cannot be pushed down\"\n-     *\n-     * @param originalFilter The original filter which cannot be pushed down\n-     *\n-     * @return analysis that represents: \"Filter cannot be pushed down\"\n-     */\n-    public static JoinFilterAnalysis createNoPushdownFilterAnalysis(Filter originalFilter)\n-    {\n-      return new JoinFilterAnalysis(\n-          false,\n-          true,\n-          originalFilter,\n-          null,\n-          null\n-      );\n-    }\n-  }\n-\n-  /**\n-   * Represents an analysis of what base table columns, if any, can be correlated with a column that will\n-   * be filtered on.\n-   * <p>\n-   * For example, if we're joining on a base table via the equiconditions (id = j.id AND f(id2) = j.id2),\n-   * then we can correlate j.id with id (base table column) and j.id2 with f(id2) (a base table expression).\n-   */\n-  private static class JoinFilterColumnCorrelationAnalysis\n-  {\n-    private final String joinColumn;\n-    private final List<String> baseColumns;\n-    private final List<Expr> baseExpressions;\n-\n-    public JoinFilterColumnCorrelationAnalysis(\n-        String joinColumn,\n-        List<String> baseColumns,\n-        List<Expr> baseExpressions\n-    )\n-    {\n-      this.joinColumn = joinColumn;\n-      this.baseColumns = baseColumns;\n-      this.baseExpressions = baseExpressions;\n-    }\n-\n-    public String getJoinColumn()\n-    {\n-      return joinColumn;\n-    }\n-\n-    public List<String> getBaseColumns()\n-    {\n-      return baseColumns;\n-    }\n-\n-    public List<Expr> getBaseExpressions()\n-    {\n-      return baseExpressions;\n-    }\n-\n-    public boolean supportsPushDown()\n-    {\n-      return !baseColumns.isEmpty() || !baseExpressions.isEmpty();\n-    }\n-  }\n-\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -596,148 +518,4 @@ public class JoinFilterAnalyzer\n     ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n-\n-  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory\n-  {\n-    @Override\n-    public DimensionSelector makeDimensionSelector(DimensionSpec dimensionSpec)\n-    {\n-      return DimensionSelector.constant(null);\n-    }\n-\n-    @Override\n-    public ColumnValueSelector<?> makeColumnValueSelector(String columnName)\n-    {\n-      return NilColumnValueSelector.instance();\n-    }\n-\n-    @Override\n-    public ColumnCapabilities getColumnCapabilities(String columnName)\n-    {\n-      return null;\n-    }\n-  }\n-\n-  /**\n-   * Holds information about:\n-   * - whether a filter can be pushed down\n-   * - if it needs to be retained after the join,\n-   * - a reference to the original filter\n-   * - a potentially rewritten filter to be pushed down to the base table\n-   * - a list of virtual columns that need to be created on the base table to support the pushed down filter\n-   */\n-  private static class JoinFilterAnalysis\n-  {\n-    private final boolean canPushDown;\n-    private final boolean retainAfterJoin;\n-    private final Filter originalFilter;\n-    private final Filter pushdownFilter;\n-    private final List<VirtualColumn> pushdownVirtualColumns;\n-\n-    public JoinFilterAnalysis(\n-        boolean canPushDown,\n-        boolean retainAfterJoin,\n-        Filter originalFilter,\n-        @Nullable Filter pushdownFilter,\n-        @Nullable List<VirtualColumn> pushdownVirtualColumns\n-    )\n-    {\n-      this.canPushDown = canPushDown;\n-      this.retainAfterJoin = retainAfterJoin;\n-      this.originalFilter = originalFilter;\n-      this.pushdownFilter = pushdownFilter;\n-      this.pushdownVirtualColumns = pushdownVirtualColumns;\n-    }\n-\n-    public boolean isCanPushDown()\n-    {\n-      return canPushDown;\n-    }\n-\n-    public boolean isRetainAfterJoin()\n-    {\n-      return retainAfterJoin;\n-    }\n-\n-    public Filter getOriginalFilter()\n-    {\n-      return originalFilter;\n-    }\n-\n-    @Nullable\n-    public Filter getPushdownFilter()\n-    {\n-      return pushdownFilter;\n-    }\n-\n-    @Nullable\n-    public List<VirtualColumn> getPushdownVirtualColumns()\n-    {\n-      return pushdownVirtualColumns;\n-    }\n-\n-    /**\n-     * Utility method for generating an analysis that represents: \"Filter cannot be pushed down\"\n-     *\n-     * @param originalFilter The original filter which cannot be pushed down\n-     *\n-     * @return analysis that represents: \"Filter cannot be pushed down\"\n-     */\n-    public static JoinFilterAnalysis createNoPushdownFilterAnalysis(Filter originalFilter)\n-    {\n-      return new JoinFilterAnalysis(\n-          false,\n-          true,\n-          originalFilter,\n-          null,\n-          null\n-      );\n-    }\n-  }\n-\n-  /**\n-   * Represents an analysis of what base table columns, if any, can be correlated with a column that will\n-   * be filtered on.\n-   * <p>\n-   * For example, if we're joining on a base table via the equiconditions (id = j.id AND f(id2) = j.id2),\n-   * then we can correlate j.id with id (base table column) and j.id2 with f(id2) (a base table expression).\n-   */\n-  private static class JoinFilterColumnCorrelationAnalysis\n-  {\n-    private final String joinColumn;\n-    private final List<String> baseColumns;\n-    private final List<Expr> baseExpressions;\n-\n-    public JoinFilterColumnCorrelationAnalysis(\n-        String joinColumn,\n-        List<String> baseColumns,\n-        List<Expr> baseExpressions\n-    )\n-    {\n-      this.joinColumn = joinColumn;\n-      this.baseColumns = baseColumns;\n-      this.baseExpressions = baseExpressions;\n-    }\n-\n-    public String getJoinColumn()\n-    {\n-      return joinColumn;\n-    }\n-\n-    public List<String> getBaseColumns()\n-    {\n-      return baseColumns;\n-    }\n-\n-    public List<Expr> getBaseExpressions()\n-    {\n-      return baseExpressions;\n-    }\n-\n-    public boolean supportsPushDown()\n-    {\n-      return !baseColumns.isEmpty() || !baseExpressions.isEmpty();\n-    }\n-  }\n-\n }\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTMyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025326", "body": "equiConditions would match the spelling from JoinConditionAnalysis.", "bodyText": "equiConditions would match the spelling from JoinConditionAnalysis.", "bodyHTML": "<p dir=\"auto\">equiConditions would match the spelling from JoinConditionAnalysis.</p>", "author": "gianm", "createdAt": "2020-02-05T02:06:19Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzY4OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667689", "bodyText": "Adjusted spelling to equiConditions", "author": "jon-wei", "createdAt": "2020-02-06T07:02:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTMyNg=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -519,17 +415,16 @@ public class JoinFilterAnalyzer\n    * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n    * @param tablePrefix          Prefix for a join table\n    * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n    *\n    * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n    * the tablePrefix\n    */\n-  @Nullable\n-  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n       HashJoinSegmentStorageAdapter adapter,\n       String tablePrefix,\n       JoinableClause clauseForTablePrefix,\n-      Map<String, Expr> equiconditions\n+      Map<String, Expr> equiConditions\n   )\n   {\n     JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -455,81 +407,50 @@ public class JoinFilterAnalyzer\n     String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n     String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n \n-    // would be good to allow non-key column indices on the Joinables for better perf\n-    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n-      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n-      List<String> correlatedValues;\n-      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n-        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n-        }\n-      } else {\n-        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n-        }\n-      }\n-      return correlatedValues;\n-    }\n-\n-    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n-      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n-      IndexedTable indexedTable = indexedTableJoinable.getTable();\n-\n-      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n-      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n-\n-      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n-        return null;\n-      }\n-\n-      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n-        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n-        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n-        IntList rowIndex = index.find(filterValue);\n-        List<String> correlatedValues = new ArrayList<>();\n-        for (int i = 0; i < rowIndex.size(); i++) {\n-          int rowNum = rowIndex.getInt(i);\n-          correlatedValues.add(reader.read(rowNum).toString());\n-        }\n-        return correlatedValues;\n-      } else {\n-        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n-        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n-        Set<String> correlatedValueSet = new HashSet<>();\n-        for (int i = 0; i < indexedTable.numRows(); i++) {\n-          if (filterValue.equals(dimNameReader.read(i).toString())) {\n-            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n-          }\n-        }\n-\n-        return new ArrayList<>(correlatedValueSet);\n-      }\n-    }\n-\n-    return null;\n+    return clauseForFilteredTable.getJoinable().getCorrelatedColumnValues(\n+        filterColumnNoPrefix,\n+        filterValue,\n+        correlatedColumnNoPrefix\n+    );\n   }\n \n   /**\n-   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   * For each rhs column that appears in the equiconditions for a table's JoinableClause,\n+   * we try to determine what base table columns are related to the rhs column through the total set of equiconditions.\n+   * We do this by searching backwards through the chain of join equiconditions using the provided equicondition map.\n+   *\n+   * For example, suppose we have 3 tables, A,B,C, joined with the following conditions, where A is the base table:\n+   *   A.joinColumn == B.joinColumn\n+   *   B.joinColum == C.joinColumn\n+   *\n+   * We would determine that C.joinColumn is correlated with A.joinColumn: we first see that\n+   * C.joinColumn is linked to B.joinColumn which in turn is linked to A.joinColumn\n+   *\n+   * Suppose we had the following join conditions instead:\n+   *   f(A.joinColumn) == B.joinColumn\n+   *   B.joinColum == C.joinColumn\n+   * In this case, the JoinFilterColumnCorrelationAnalysis for C.joinColumn would be linked to f(A.joinColumn).\n+   *\n+   * Suppose we had the following join conditions instead:\n+   *   A.joinColumn == B.joinColumn\n+   *   f(B.joinColum) == C.joinColumn\n+   *\n+   * Because we cannot reverse the function f() applied to the second table B in all cases,\n+   * we cannot relate C.joinColumn to A.joinColumn, and we would not generate a correlation for C.joinColumn\n    *\n    * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n    * @param tablePrefix          Prefix for a join table\n    * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n    *\n    * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n    * the tablePrefix\n    */\n-  @Nullable\n-  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n       HashJoinSegmentStorageAdapter adapter,\n       String tablePrefix,\n       JoinableClause clauseForTablePrefix,\n-      Map<String, Expr> equiconditions\n+      Map<String, Expr> equiConditions\n   )\n   {\n     JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTQxOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025418", "body": "Two conditions can refer to the same rhs column. Should this be a Set?", "bodyText": "Two conditions can refer to the same rhs column. Should this be a Set?", "bodyHTML": "<p dir=\"auto\">Two conditions can refer to the same rhs column. Should this be a Set?</p>", "author": "gianm", "createdAt": "2020-02-05T02:06:37Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Nzc1OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667758", "bodyText": "Ah, changed this to Set", "author": "jon-wei", "createdAt": "2020-02-06T07:02:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTQxOA=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -519,17 +415,16 @@ public class JoinFilterAnalyzer\n    * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n    * @param tablePrefix          Prefix for a join table\n    * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n    *\n    * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n    * the tablePrefix\n    */\n-  @Nullable\n-  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n       HashJoinSegmentStorageAdapter adapter,\n       String tablePrefix,\n       JoinableClause clauseForTablePrefix,\n-      Map<String, Expr> equiconditions\n+      Map<String, Expr> equiConditions\n   )\n   {\n     JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -455,81 +407,50 @@ public class JoinFilterAnalyzer\n     String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n     String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n \n-    // would be good to allow non-key column indices on the Joinables for better perf\n-    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n-      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n-      List<String> correlatedValues;\n-      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n-        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n-        }\n-      } else {\n-        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n-          correlatedValues = ImmutableList.of(filterValue);\n-        } else {\n-          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n-        }\n-      }\n-      return correlatedValues;\n-    }\n-\n-    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n-      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n-      IndexedTable indexedTable = indexedTableJoinable.getTable();\n-\n-      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n-      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n-\n-      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n-        return null;\n-      }\n-\n-      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n-        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n-        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n-        IntList rowIndex = index.find(filterValue);\n-        List<String> correlatedValues = new ArrayList<>();\n-        for (int i = 0; i < rowIndex.size(); i++) {\n-          int rowNum = rowIndex.getInt(i);\n-          correlatedValues.add(reader.read(rowNum).toString());\n-        }\n-        return correlatedValues;\n-      } else {\n-        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n-        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n-        Set<String> correlatedValueSet = new HashSet<>();\n-        for (int i = 0; i < indexedTable.numRows(); i++) {\n-          if (filterValue.equals(dimNameReader.read(i).toString())) {\n-            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n-          }\n-        }\n-\n-        return new ArrayList<>(correlatedValueSet);\n-      }\n-    }\n-\n-    return null;\n+    return clauseForFilteredTable.getJoinable().getCorrelatedColumnValues(\n+        filterColumnNoPrefix,\n+        filterValue,\n+        correlatedColumnNoPrefix\n+    );\n   }\n \n   /**\n-   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   * For each rhs column that appears in the equiconditions for a table's JoinableClause,\n+   * we try to determine what base table columns are related to the rhs column through the total set of equiconditions.\n+   * We do this by searching backwards through the chain of join equiconditions using the provided equicondition map.\n+   *\n+   * For example, suppose we have 3 tables, A,B,C, joined with the following conditions, where A is the base table:\n+   *   A.joinColumn == B.joinColumn\n+   *   B.joinColum == C.joinColumn\n+   *\n+   * We would determine that C.joinColumn is correlated with A.joinColumn: we first see that\n+   * C.joinColumn is linked to B.joinColumn which in turn is linked to A.joinColumn\n+   *\n+   * Suppose we had the following join conditions instead:\n+   *   f(A.joinColumn) == B.joinColumn\n+   *   B.joinColum == C.joinColumn\n+   * In this case, the JoinFilterColumnCorrelationAnalysis for C.joinColumn would be linked to f(A.joinColumn).\n+   *\n+   * Suppose we had the following join conditions instead:\n+   *   A.joinColumn == B.joinColumn\n+   *   f(B.joinColum) == C.joinColumn\n+   *\n+   * Because we cannot reverse the function f() applied to the second table B in all cases,\n+   * we cannot relate C.joinColumn to A.joinColumn, and we would not generate a correlation for C.joinColumn\n    *\n    * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n    * @param tablePrefix          Prefix for a join table\n    * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n    *\n    * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n    * the tablePrefix\n    */\n-  @Nullable\n-  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n       HashJoinSegmentStorageAdapter adapter,\n       String tablePrefix,\n       JoinableClause clauseForTablePrefix,\n-      Map<String, Expr> equiconditions\n+      Map<String, Expr> equiConditions\n   )\n   {\n     JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025840", "body": "There could be more than one equi-condition for the same rhs column. It looks like this code disregards that possibility.", "bodyText": "There could be more than one equi-condition for the same rhs column. It looks like this code disregards that possibility.", "bodyHTML": "<p dir=\"auto\">There could be more than one equi-condition for the same rhs column. It looks like this code disregards that possibility.</p>", "author": "gianm", "createdAt": "2020-02-05T02:08:12Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Nzc5NQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667795", "bodyText": "I'm still looking into this comment", "author": "jon-wei", "createdAt": "2020-02-06T07:03:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY4OTkwMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375689903", "bodyText": "I tried a test where I had the following join condition:\n\"r1.regionIsoCode\" == regionIsoCode && \"r1.regionIsoCode\" == countryIsoCode\n\nIn one of the Equality objects in the equiConditions, the right hand column ends up as regionIsoCode_0 with an extra _0 suffix, and the query fails with:\n\"Cannot build hash-join matcher on non-key-based condition: Equality{leftExpr=countryIsoCode, rightColumn='regionIsoCode_0'}\"\n\nI added a new test which shows this (JoinFilterAnalyzerTest.test_filterPushDown_factToRegionTwoColumnsToOneRHSColumnAndFilterOnRHS)\nCan we address this in a follow-on PR?", "author": "jon-wei", "createdAt": "2020-02-06T08:14:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2MTgwNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376061804", "bodyText": "Sure, but please raise a github issue and mention it in a comment.", "author": "gianm", "createdAt": "2020-02-06T20:22:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTYzNw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129637", "bodyText": "I opened #9327 to track the query failure issue and #9328 to track the adjustments needed here", "author": "jon-wei", "createdAt": "2020-02-06T22:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}], "type": "inlineReview", "revised_code": {"commit": "dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -75,6 +87,10 @@ public class JoinFilterAnalyzer\n     Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n \n     // build the prefix and equicondition maps\n+    // We should check that the prefixes do not duplicate or shadow each other. This is not currently implemented,\n+    // but this is tracked at https://github.com/apache/druid/issues/9329\n+    // We should also consider the case where one RHS column is joined to multiple columns:\n+    // https://github.com/apache/druid/issues/9328\n     Map<String, Expr> equiconditions = new HashMap<>();\n     Map<String, JoinableClause> prefixes = new HashMap<>();\n     for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -75,6 +87,10 @@ public class JoinFilterAnalyzer\n     Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n \n     // build the prefix and equicondition maps\n+    // We should check that the prefixes do not duplicate or shadow each other. This is not currently implemented,\n+    // but this is tracked at https://github.com/apache/druid/issues/9329\n+    // We should also consider the case where one RHS column is joined to multiple columns:\n+    // https://github.com/apache/druid/issues/9328\n     Map<String, Expr> equiconditions = new HashMap<>();\n     Map<String, JoinableClause> prefixes = new HashMap<>();\n     for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjE4Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375026182", "body": "small suggestion: `!requiredBindings.stream().allMatch( blah blah blah )` may be more readable", "bodyText": "small suggestion: !requiredBindings.stream().allMatch( blah blah blah ) may be more readable", "bodyHTML": "<p dir=\"auto\">small suggestion: <code>!requiredBindings.stream().allMatch( blah blah blah )</code> may be more readable</p>", "author": "gianm", "createdAt": "2020-02-05T02:09:44Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzgyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667826", "bodyText": "Changed to the suggested stream usage", "author": "jon-wei", "createdAt": "2020-02-06T07:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjE4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -557,10 +452,8 @@ public class JoinFilterAnalyzer\n           // We push down if the function only requires base table columns\n           Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n           Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n-          for (String requiredBinding : requiredBindings) {\n-            if (!adapter.isBaseColumn(requiredBinding)) {\n-              return null;\n-            }\n+          if (!requiredBindings.stream().allMatch(requiredBinding -> adapter.isBaseColumn(requiredBinding))) {\n+            return Optional.empty();\n           }\n \n           terminate = true;\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -541,26 +462,25 @@ public class JoinFilterAnalyzer\n \n     List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n \n+\n     for (String rhsColumn : rhsColumns) {\n       List<String> correlatedBaseColumns = new ArrayList<>();\n       List<Expr> correlatedBaseExpressions = new ArrayList<>();\n       boolean terminate = false;\n-\n       String findMappingFor = rhsColumn;\n       while (!terminate) {\n-        Expr lhs = equiconditions.get(findMappingFor);\n+        Expr lhs = equiConditions.get(findMappingFor);\n         if (lhs == null) {\n           break;\n         }\n+\n         String identifier = lhs.getBindingIfIdentifier();\n         if (identifier == null) {\n           // We push down if the function only requires base table columns\n           Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n           Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n-          for (String requiredBinding : requiredBindings) {\n-            if (!adapter.isBaseColumn(requiredBinding)) {\n-              return null;\n-            }\n+          if (!requiredBindings.stream().allMatch(requiredBinding -> adapter.isBaseColumn(requiredBinding))) {\n+            return Optional.empty();\n           }\n \n           terminate = true;\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375026542", "body": "What case is this meant to handle? I don't understand why we'd need to switch `findMappingFor` from a rhs column to a lhs column.", "bodyText": "What case is this meant to handle? I don't understand why we'd need to switch findMappingFor from a rhs column to a lhs column.", "bodyHTML": "<p dir=\"auto\">What case is this meant to handle? I don't understand why we'd need to switch <code>findMappingFor</code> from a rhs column to a lhs column.</p>", "author": "gianm", "createdAt": "2020-02-05T02:11:33Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2ODk5OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375668999", "bodyText": "This is for cases like the fact->region->country joins in the tests, where the three tables are all joined on countryIsoCode, but the last table is joined to the second table, instead of the base table, and we have a filter on a column from the last table in the chain.\nJoinFilterAnalyzerTest.test_filterPushDown_factToRegionToCountryLeftFilterOnChannelAndCountryName is an example where this is used.", "author": "jon-wei", "createdAt": "2020-02-06T07:08:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2NzQyOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376067428", "bodyText": "Hmm, I see.\nWould you mind adding some comments to findCorrelatedBaseTableColumns explaining the idea behind the logic?", "author": "gianm", "createdAt": "2020-02-06T20:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTg0Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129847", "bodyText": "I added more description and examples to the javadoc for findCorrelatedBaseTableColumns, hopefully it's more clear now", "author": "jon-wei", "createdAt": "2020-02-06T23:00:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -557,10 +452,8 @@ public class JoinFilterAnalyzer\n           // We push down if the function only requires base table columns\n           Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n           Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n-          for (String requiredBinding : requiredBindings) {\n-            if (!adapter.isBaseColumn(requiredBinding)) {\n-              return null;\n-            }\n+          if (!requiredBindings.stream().allMatch(requiredBinding -> adapter.isBaseColumn(requiredBinding))) {\n+            return Optional.empty();\n           }\n \n           terminate = true;\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -541,26 +462,25 @@ public class JoinFilterAnalyzer\n \n     List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n \n+\n     for (String rhsColumn : rhsColumns) {\n       List<String> correlatedBaseColumns = new ArrayList<>();\n       List<Expr> correlatedBaseExpressions = new ArrayList<>();\n       boolean terminate = false;\n-\n       String findMappingFor = rhsColumn;\n       while (!terminate) {\n-        Expr lhs = equiconditions.get(findMappingFor);\n+        Expr lhs = equiConditions.get(findMappingFor);\n         if (lhs == null) {\n           break;\n         }\n+\n         String identifier = lhs.getBindingIfIdentifier();\n         if (identifier == null) {\n           // We push down if the function only requires base table columns\n           Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n           Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n-          for (String requiredBinding : requiredBindings) {\n-            if (!adapter.isBaseColumn(requiredBinding)) {\n-              return null;\n-            }\n+          if (!requiredBindings.stream().allMatch(requiredBinding -> adapter.isBaseColumn(requiredBinding))) {\n+            return Optional.empty();\n           }\n \n           terminate = true;\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375027922", "body": "When would there be more than one base column?", "bodyText": "When would there be more than one base column?", "bodyHTML": "<p dir=\"auto\">When would there be more than one base column?</p>", "author": "gianm", "createdAt": "2020-02-05T02:17:39Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2OTEyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375669123", "bodyText": "Still looking into this comment", "author": "jon-wei", "createdAt": "2020-02-06T07:08:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY5MTkzMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375691932", "bodyText": "My original intent was related to the comment here about handling cases where one RHS column is joined to multiple columns: #9301 (comment)\nIt's not implemented right now in JoinFilterAnalyzer.findCorrelatedBaseTableColumns (and should be), but in that case there would be multiple base columns correlated to the RHS filtering column.\nSince a query of that type doesn't run successfully right now, can we address this in a follow-on PR?", "author": "jon-wei", "createdAt": "2020-02-06T08:19:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA0MTk3MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376041970", "bodyText": "I think doing it in a follow-on is OK. Please just add a comment about the known limitation and create a followup github issue (the comment could just link to the issue).", "author": "gianm", "createdAt": "2020-02-06T19:40:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTk4Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129982", "bodyText": "I opened #9327 to track the query failure issue and #9328 to track the adjustments needed here", "author": "jon-wei", "createdAt": "2020-02-06T23:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -352,28 +298,28 @@ public class JoinFilterAnalyzer\n             )\n         );\n \n-        if (correlations == null) {\n+        if (!correlations.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n         List<Filter> newFilters = new ArrayList<>();\n         List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n           if (correlationAnalysis.supportsPushDown()) {\n-            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n                 selectorFilter.getDimension(),\n                 selectorFilter.getValue(),\n                 correlationAnalysis.getJoinColumn(),\n                 prefixAndClause.getValue()\n             );\n \n-            if (correlatedValues == null) {\n+            if (correlatedValues.isEmpty()) {\n               return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n             }\n \n             for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+              Filter rewrittenFilter = new InDimFilter(\n                   correlatedBaseColumn,\n                   correlatedValues,\n                   null,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -352,28 +302,28 @@ public class JoinFilterAnalyzer\n             )\n         );\n \n-        if (correlations == null) {\n+        if (!correlations.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n         List<Filter> newFilters = new ArrayList<>();\n         List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n           if (correlationAnalysis.supportsPushDown()) {\n-            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n                 selectorFilter.getDimension(),\n                 selectorFilter.getValue(),\n                 correlationAnalysis.getJoinColumn(),\n                 prefixAndClause.getValue()\n             );\n \n-            if (correlatedValues == null) {\n+            if (correlatedValues.isEmpty()) {\n               return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n             }\n \n             for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+              Filter rewrittenFilter = new InDimFilter(\n                   correlatedBaseColumn,\n                   correlatedValues,\n                   null,\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375029851", "body": "This code is nasty for the reason you mentioned in your comment. I don't think it'd be good to leave it like this, since it means any attempt to serialize this virtual column will yield something unusable, potentially leading to latent bugs.\r\n\r\nI'd almost consider _not_ supporting pushdown of filters where the lhs is an expression until we have a way to actually convert parsed expressions to strings.\r\n\r\nAnother option:\r\n\r\n1) Make a single private constructor of ExpressionVirtualColumn that takes a nullable 'expression' and an optional pre-parsed expression.\r\n2) Make a `@JsonCreator` static factory method that Jackson will use.\r\n3) Make another static factory method that accepts a pre-parsed expression, and stores null for the 'expression'.\r\n4) Make `getExpression()` throw an exception if 'expression' is null. This means anyone trying to serialize it will realize what is going on before getting hit by latent bugs.\r\n5) Make sure to note in the javadoc of JoinFilterAnalysis that the virtual columns are not serializable.\r\n\r\nOpen to other ideas.", "bodyText": "This code is nasty for the reason you mentioned in your comment. I don't think it'd be good to leave it like this, since it means any attempt to serialize this virtual column will yield something unusable, potentially leading to latent bugs.\nI'd almost consider not supporting pushdown of filters where the lhs is an expression until we have a way to actually convert parsed expressions to strings.\nAnother option:\n\nMake a single private constructor of ExpressionVirtualColumn that takes a nullable 'expression' and an optional pre-parsed expression.\nMake a @JsonCreator static factory method that Jackson will use.\nMake another static factory method that accepts a pre-parsed expression, and stores null for the 'expression'.\nMake getExpression() throw an exception if 'expression' is null. This means anyone trying to serialize it will realize what is going on before getting hit by latent bugs.\nMake sure to note in the javadoc of JoinFilterAnalysis that the virtual columns are not serializable.\n\nOpen to other ideas.", "bodyHTML": "<p dir=\"auto\">This code is nasty for the reason you mentioned in your comment. I don't think it'd be good to leave it like this, since it means any attempt to serialize this virtual column will yield something unusable, potentially leading to latent bugs.</p>\n<p dir=\"auto\">I'd almost consider <em>not</em> supporting pushdown of filters where the lhs is an expression until we have a way to actually convert parsed expressions to strings.</p>\n<p dir=\"auto\">Another option:</p>\n<ol dir=\"auto\">\n<li>Make a single private constructor of ExpressionVirtualColumn that takes a nullable 'expression' and an optional pre-parsed expression.</li>\n<li>Make a <code>@JsonCreator</code> static factory method that Jackson will use.</li>\n<li>Make another static factory method that accepts a pre-parsed expression, and stores null for the 'expression'.</li>\n<li>Make <code>getExpression()</code> throw an exception if 'expression' is null. This means anyone trying to serialize it will realize what is going on before getting hit by latent bugs.</li>\n<li>Make sure to note in the javadoc of JoinFilterAnalysis that the virtual columns are not serializable.</li>\n</ol>\n<p dir=\"auto\">Open to other ideas.</p>", "author": "gianm", "createdAt": "2020-02-05T02:25:57Z", "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java", "diffHunk": "@@ -62,6 +64,23 @@ public ExpressionVirtualColumn(\n     this.parsedExpression = Suppliers.memoize(() -> Parser.parse(expression, macroTable));\n   }\n \n+  /**\n+   * Constructor for creating an ExpressionVirtualColumn from a pre-parsed expression.\n+   */\n+  public ExpressionVirtualColumn(\n+      String name,\n+      Expr parsedExpression,\n+      ValueType outputType\n+  )\n+  {\n+    this.name = Preconditions.checkNotNull(name, \"name\");\n+    // Unfortunately this string representation can't be reparsed into the same expression, might be useful\n+    // if the expression system supported that\n+    this.expression = parsedExpression.toString();", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2OTgxMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375669811", "bodyText": "I decided to just disable lhs expression push down for now (JoinFilterColumnCorrelationAnalysis.supportsPushDown returns false now if there are lhs expressions), but kept the rest of the code there and added an @Ignore annotation to tests that have lhs expressions (since the \"only\" thing blocking it is the lack of support from the expression system)", "author": "jon-wei", "createdAt": "2020-02-06T07:11:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA0MTEwMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376041101", "bodyText": "I think this is a reasonable course of action. Could you please also raise a followup github issue.", "author": "gianm", "createdAt": "2020-02-06T19:38:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEzMDEzOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376130138", "bodyText": "I opened #9326 to track the expressions enhancement and mentioned it in a comment here", "author": "jon-wei", "createdAt": "2020-02-06T23:01:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": {"commit": "19c4b1664086539a3bb495eb402616cf8b6f2a77", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java b/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java\nindex 4823651529..8ad46d6436 100644\n--- a/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java\n+++ b/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java\n", "chunk": "@@ -77,7 +87,7 @@ public class ExpressionVirtualColumn implements VirtualColumn\n     // Unfortunately this string representation can't be reparsed into the same expression, might be useful\n     // if the expression system supported that\n     this.expression = parsedExpression.toString();\n-    this.outputType = outputType != null ? outputType : ValueType.FLOAT;\n+    this.outputType = outputType;\n     this.parsedExpression = Suppliers.ofInstance(parsedExpression);\n   }\n \n", "next_change": {"commit": "920aa414ca5eab60149239f448891afd01b736ee", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java b/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java\nindex 8ad46d6436..c0de0876c5 100644\n--- a/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java\n+++ b/processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java\n", "chunk": "@@ -89,6 +92,7 @@ public class ExpressionVirtualColumn implements VirtualColumn\n     this.expression = parsedExpression.toString();\n     this.outputType = outputType;\n     this.parsedExpression = Suppliers.ofInstance(parsedExpression);\n+    this.cacheKey = makeCacheKeySupplier();\n   }\n \n   @JsonProperty(\"name\")\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}, {"oid": "77dd5b06ae8fd7c81474cb03c0fc399cdf21646a", "committedDate": "2020-06-04 23:52:37 -0700", "message": "ColumnCapabilities.hasMultipleValues refactor (#9731)"}, {"oid": "ab606610089f7bb9b4b1b68ac488764f394723fd", "committedDate": "2020-08-26 10:53:44 -0700", "message": "refactor internal type system (#9638)"}, {"oid": "19c4b1664086539a3bb495eb402616cf8b6f2a77", "committedDate": "2020-09-23 13:56:38 -0700", "message": "vectorized expressions and expression virtual columns (#10401)"}, {"oid": "753bce324bdf8c7c5b2b602f89c720749bfa6e22", "committedDate": "2020-09-29 13:19:06 -0700", "message": "vectorize constant expressions with optimized selectors (#10440)"}, {"oid": "9ec5c08e2a3c1210fefc78e26fbafe75702c7c2f", "committedDate": "2020-10-03 15:30:34 -0700", "message": "fix array types from escaping into wider query engine (#10460)"}, {"oid": "57ff1f9cdb45370df1467fef03222909700fa768", "committedDate": "2021-04-22 18:30:16 -0700", "message": "expression aggregator (#11104)"}, {"oid": "920aa414ca5eab60149239f448891afd01b736ee", "committedDate": "2021-06-14 17:26:43 -0700", "message": "enrich expression cache key information to support expressions which depend on external state (#11358)"}, {"oid": "17efa6f5569d21fffdbb263d6e12db5982d7529b", "committedDate": "2021-07-06 11:20:49 -0700", "message": "add single input string expression dimension vector selector and better expression planning (#11213)"}, {"oid": "187df58e303c9338e7c2e107d7725b4638404bb1", "committedDate": "2021-10-19 01:47:25 -0700", "message": "better types (#11713)"}, {"oid": "ae71e05fc5d0cec8f7ae78df25ccf4a45cfecfda", "committedDate": "2022-02-07 19:59:30 -0800", "message": "array_concat_agg and array_agg support for array inputs (#12226)"}, {"oid": "82ad92708778de02eb3857cc6aca337663bed871", "committedDate": "2022-08-25 00:48:49 -0700", "message": "tighten up array handling, fix bug with array_slice output type inference (#12914)"}, {"oid": "ffeda72abb40d8e849a95a6ccc1a76a870e45dd0", "committedDate": "2023-02-09 03:16:38 -0800", "message": "fix filtering nested field virtual column when used with non nested column input (#13779)"}, {"oid": "4b1ffbc452831178dccd38456ed9b2cdf2521d13", "committedDate": "2023-03-10 16:42:08 +0530", "message": "Various changes and fixes to UNNEST. (#13892)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAzMDU5Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375030593", "body": "Is there a reason for this cast? Seems like we could let it go in to `newFilters` as an uncast Filter.", "bodyText": "Is there a reason for this cast? Seems like we could let it go in to newFilters as an uncast Filter.", "bodyHTML": "<p dir=\"auto\">Is there a reason for this cast? Seems like we could let it go in to <code>newFilters</code> as an uncast Filter.</p>", "author": "gianm", "createdAt": "2020-02-05T02:29:19Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2OTk5Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375669997", "bodyText": "Hm, it must have been a relic from an earlier version of the code, adjusted as suggested", "author": "jon-wei", "createdAt": "2020-02-06T07:12:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAzMDU5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..4f9e03ea21 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -352,28 +298,28 @@ public class JoinFilterAnalyzer\n             )\n         );\n \n-        if (correlations == null) {\n+        if (!correlations.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n         List<Filter> newFilters = new ArrayList<>();\n         List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n           if (correlationAnalysis.supportsPushDown()) {\n-            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n                 selectorFilter.getDimension(),\n                 selectorFilter.getValue(),\n                 correlationAnalysis.getJoinColumn(),\n                 prefixAndClause.getValue()\n             );\n \n-            if (correlatedValues == null) {\n+            if (correlatedValues.isEmpty()) {\n               return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n             }\n \n             for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+              Filter rewrittenFilter = new InDimFilter(\n                   correlatedBaseColumn,\n                   correlatedValues,\n                   null,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "changed_code": [{"header": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nsimilarity index 54%\nrename from processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\nrename to processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\nindex 2a83d8133f..c5a47c1eae 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java\n", "chunk": "@@ -352,28 +302,28 @@ public class JoinFilterAnalyzer\n             )\n         );\n \n-        if (correlations == null) {\n+        if (!correlations.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n         List<Filter> newFilters = new ArrayList<>();\n         List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n           if (correlationAnalysis.supportsPushDown()) {\n-            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n                 selectorFilter.getDimension(),\n                 selectorFilter.getValue(),\n                 correlationAnalysis.getJoinColumn(),\n                 prefixAndClause.getValue()\n             );\n \n-            if (correlatedValues == null) {\n+            if (correlatedValues.isEmpty()) {\n               return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n             }\n \n             for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+              Filter rewrittenFilter = new InDimFilter(\n                   correlatedBaseColumn,\n                   correlatedValues,\n                   null,\n", "next_change": null}]}, "commits_in_main": [{"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3", "message": "Merge commit", "committedDate": null}]}, {"oid": "0de4d0f4019ae7aeed5180281722fee9b9ef8c27", "url": "https://github.com/apache/druid/commit/0de4d0f4019ae7aeed5180281722fee9b9ef8c27", "message": "Merge remote-tracking branch 'upstream/master' into join_filter_pushdowns2", "committedDate": "2020-02-06T01:39:32Z", "type": "commit"}, {"oid": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "url": "https://github.com/apache/druid/commit/d3e603321d5a8239ddb9addd5396c5c94e8b8893", "message": "Address some PR comments", "committedDate": "2020-02-06T06:42:32Z", "type": "commit"}, {"oid": "194a1ef09a7ac70f26159eff40581a3184a4926d", "url": "https://github.com/apache/druid/commit/194a1ef09a7ac70f26159eff40581a3184a4926d", "message": "Address more PR comments", "committedDate": "2020-02-06T08:22:06Z", "type": "commit"}, {"oid": "dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "url": "https://github.com/apache/druid/commit/dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "message": "Fix TC failures and address PR comments", "committedDate": "2020-02-06T22:56:51Z", "type": "commit"}]}