{"pr_number": 936, "pr_title": "Moved RecordFileParser file system logic to RecordFilePoller", "pr_author": "Nana-EC", "pr_createdAt": "2020-08-07T02:02:21Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/936", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NDI5MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467094290", "body": "This sort can be removed since it's already sorted above.", "bodyText": "This sort can be removed since it's already sorted above.", "bodyHTML": "<p dir=\"auto\">This sort can be removed since it's already sorted above.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T14:57:55Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)\n+                        .collect(Collectors.toList());\n+\n+                if (fullPaths != null && fullPaths.size() != 0) {\n+                    log.trace(\"Processing record files: {}\", fullPaths);\n+                    loadRecordFiles(fullPaths);\n+                } else {\n+                    log.debug(\"No files to parse\");\n+                }\n+            } else {\n+                log.error(\"Input parameter is not a folder: {}\", path);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Error parsing files\", e);\n+        }\n+    }\n+\n+    /**\n+     * read and parse a list of record files\n+     *\n+     * @throws Exception\n+     */\n+    private void loadRecordFiles(List<String> filePaths) {\n+        Collections.sort(filePaths);", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjAyOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676028", "bodyText": "Removed", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NDI5MA=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -89,17 +81,18 @@ public class RecordFilePoller implements FilePoller {\n      *\n      * @throws Exception\n      */\n-    private void loadRecordFiles(List<String> filePaths) {\n-        Collections.sort(filePaths);\n+    private void loadRecordFiles(String[] filePaths) {\n+        Path validPath = parserProperties.getValidPath();\n         for (String filePath : filePaths) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n \n-            File file = new File(filePath);\n+            // get file from full path\n+            File file = validPath.resolve(filePath).toFile();\n \n             try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(filePath, fileInputStream));\n+                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n", "next_change": {"commit": "a56ea83364b2c8e38746a5a5048555dad80741d3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex d5b6bf905..d11a9f4e6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -91,19 +88,16 @@ public class RecordFilePoller implements FilePoller {\n             // get file from full path\n             File file = validPath.resolve(filePath).toFile();\n \n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n+            try {\n+                recordFileParser.parse(StreamFileData.from(file));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n                 } else {\n                     FileUtils.deleteQuietly(file);\n                 }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n             } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                log.error(\"Error parsing file {}\", filePath, e);\n                 return;\n             }\n         }\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d11a9f4e6..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,105 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.domain.StreamFileData;\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedDelayString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try {\n-                recordFileParser.parse(StreamFileData.from(file));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjAwNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467096005", "body": "This can return null. We should return here if so.", "bodyText": "This can return null. We should return here if so.", "bodyHTML": "<p dir=\"auto\">This can return null. We should return here if so.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:00:50Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjA0Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676042", "bodyText": "Added", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjAwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -63,19 +59,15 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                Arrays.sort(files);           // sorted by name (timestamp)\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n+                    return;\n+                }\n \n-                // add directory prefix to get full path\n-                List<String> fullPaths = Arrays.asList(files).stream()\n-                        .map(s -> file + \"/\" + s)\n-                        .collect(Collectors.toList());\n+                Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (fullPaths != null && fullPaths.size() != 0) {\n-                    log.trace(\"Processing record files: {}\", fullPaths);\n-                    loadRecordFiles(fullPaths);\n-                } else {\n-                    log.debug(\"No files to parse\");\n-                }\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n             } else {\n                 log.error(\"Input parameter is not a folder: {}\", path);\n             }\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d5b6bf905..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,111 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.InputStream;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n-            } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjY4NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467096684", "body": "It would be more efficient to not loop over the files twice: once here and once again in `loadRecordFiles()`. Better to just add the valid path inside the loop in loadRecordFiles.", "bodyText": "It would be more efficient to not loop over the files twice: once here and once again in loadRecordFiles(). Better to just add the valid path inside the loop in loadRecordFiles.", "bodyHTML": "<p dir=\"auto\">It would be more efficient to not loop over the files twice: once here and once again in <code>loadRecordFiles()</code>. Better to just add the valid path inside the loop in loadRecordFiles.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:02:00Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjA0Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676046", "bodyText": "Agreed, removed this additional loop.", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjY4NA=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -63,19 +59,15 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                Arrays.sort(files);           // sorted by name (timestamp)\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n+                    return;\n+                }\n \n-                // add directory prefix to get full path\n-                List<String> fullPaths = Arrays.asList(files).stream()\n-                        .map(s -> file + \"/\" + s)\n-                        .collect(Collectors.toList());\n+                Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (fullPaths != null && fullPaths.size() != 0) {\n-                    log.trace(\"Processing record files: {}\", fullPaths);\n-                    loadRecordFiles(fullPaths);\n-                } else {\n-                    log.debug(\"No files to parse\");\n-                }\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n             } else {\n                 log.error(\"Input parameter is not a folder: {}\", path);\n             }\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d5b6bf905..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,111 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.InputStream;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n-            } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5OTY4MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467099681", "body": "Can we change to use `validPath.resolve(s)` here so it's Windows compatible?", "bodyText": "Can we change to use validPath.resolve(s) here so it's Windows compatible?", "bodyHTML": "<p dir=\"auto\">Can we change to use <code>validPath.resolve(s)</code> here so it's Windows compatible?</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:07:22Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjA1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676053", "bodyText": "No need here as this list creation was removed. Added it when creating the File in loadRecordFiles()", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5OTY4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -63,19 +59,15 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                Arrays.sort(files);           // sorted by name (timestamp)\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n+                    return;\n+                }\n \n-                // add directory prefix to get full path\n-                List<String> fullPaths = Arrays.asList(files).stream()\n-                        .map(s -> file + \"/\" + s)\n-                        .collect(Collectors.toList());\n+                Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (fullPaths != null && fullPaths.size() != 0) {\n-                    log.trace(\"Processing record files: {}\", fullPaths);\n-                    loadRecordFiles(fullPaths);\n-                } else {\n-                    log.debug(\"No files to parse\");\n-                }\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n             } else {\n                 log.error(\"Input parameter is not a folder: {}\", path);\n             }\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d5b6bf905..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,111 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.InputStream;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n-            } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEwNzgwMQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467107801", "body": "As order is very important here and this approach does not verify that, we should use `InOrder` mock to verify files are processed in order.", "bodyText": "As order is very important here and this approach does not verify that, we should use InOrder mock to verify files are processed in order.", "bodyHTML": "<p dir=\"auto\">As order is very important here and this approach does not verify that, we should use <code>InOrder</code> mock to verify files are processed in order.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:21:38Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java", "diffHunk": "@@ -0,0 +1,168 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoInteractions;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.List;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.MirrorProperties;\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class RecordFilePollerTest {\n+\n+    @TempDir\n+    Path dataPath;\n+    @Mock\n+    RecordFileParser recordFileParser;\n+    private FileCopier fileCopier;\n+    private RecordFilePoller recordFilePoller;\n+    private RecordParserProperties parserProperties;\n+\n+    private File file1;\n+    private File file2;\n+    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n+    private static final int NUM_TXNS_FILE_1 = 19;\n+    private static final int NUM_TXNS_FILE_2 = 15;\n+    private static RecordFile recordFile1;\n+    private static RecordFile recordFile2;\n+\n+    @BeforeEach\n+    void before() {\n+        var mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataPath);\n+        parserProperties = new RecordParserProperties(mirrorProperties);\n+        parserProperties.setKeepFiles(false);\n+        parserProperties.init();\n+        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n+        StreamType streamType = StreamType.RECORD;\n+        fileCopier = FileCopier\n+                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n+                .filterFiles(\"*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n+        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n+        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n+\n+        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFile1.getFileHash(), 2);\n+    }\n+\n+    @Test\n+    void poll() throws Exception {\n+        // given\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void pollAndKeepFiles() throws Exception {\n+        // given\n+        parserProperties.setKeepFiles(true);\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void noFiles() throws Exception {\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertParsedFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+\n+    // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n+    private void assertParse(String... fileNames) {\n+        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n+        verify(recordFileParser, times(fileNames.length)).parse(captor.capture());", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI0ODY2Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467248666", "bodyText": "Sure, could achieve the same with below, since InOrder will make method less general as you have to have a verify for each occurrence of the method with the expected parameter.\nassertThat(actualArgs)\n                .extracting(StreamFileData::getFilename)\n                .isEqualTo(Arrays.asList(fileNames));", "author": "Nana-EC", "createdAt": "2020-08-07T20:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEwNzgwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 14c7bb619..8a1529abc 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -120,10 +127,49 @@ public class RecordFilePollerTest {\n         recordFilePoller.poll();\n \n         // then\n-        assertParsedFiles();\n         verifyNoInteractions(recordFileParser);\n     }\n \n+    @Test\n+    void pathNotDirectory() throws Exception {\n+        // when\n+        fileCopier.copy();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+\n+    @Test\n+    void fileNotFoundFromRecordFileParser() {\n+        // given\n+        fileCopier.copy();\n+        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n+        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n+        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n+    @Test\n+    void errorFromRecordFileParser() {\n+        // when\n+        fileCopier.copy();\n+        doThrow(ParserException.class).when(recordFileParser).parse(any());\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n     // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n     private void assertParse(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\ndeleted file mode 100644\nindex 8a1529abc..000000000\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ /dev/null\n", "chunk": "@@ -1,214 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import static org.assertj.core.api.Assertions.assertThat;\n-import static org.junit.Assert.assertFalse;\n-import static org.junit.Assert.assertTrue;\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.doReturn;\n-import static org.mockito.Mockito.doThrow;\n-import static org.mockito.Mockito.times;\n-import static org.mockito.Mockito.verify;\n-import static org.mockito.Mockito.verifyNoInteractions;\n-\n-import java.io.File;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import java.util.List;\n-import org.junit.jupiter.api.BeforeEach;\n-import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import org.junit.jupiter.api.io.TempDir;\n-import org.mockito.ArgumentCaptor;\n-import org.mockito.Mock;\n-import org.mockito.Mockito;\n-import org.mockito.junit.jupiter.MockitoExtension;\n-\n-import com.hedera.mirror.importer.FileCopier;\n-import com.hedera.mirror.importer.MirrorProperties;\n-import com.hedera.mirror.importer.domain.RecordFile;\n-import com.hedera.mirror.importer.domain.StreamType;\n-import com.hedera.mirror.importer.exception.ParserException;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-\n-@ExtendWith(MockitoExtension.class)\n-public class RecordFilePollerTest {\n-\n-    @TempDir\n-    Path dataPath;\n-    @Mock\n-    RecordFileParser recordFileParser;\n-    private FileCopier fileCopier;\n-    private RecordFilePoller recordFilePoller;\n-    private RecordParserProperties parserProperties;\n-    private MirrorProperties mirrorProperties;\n-\n-    private File file1;\n-    private File file2;\n-    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n-    private static final int NUM_TXNS_FILE_1 = 19;\n-    private static final int NUM_TXNS_FILE_2 = 15;\n-    private static RecordFile recordFile1;\n-    private static RecordFile recordFile2;\n-\n-    @BeforeEach\n-    void before() {\n-        mirrorProperties = new MirrorProperties();\n-        mirrorProperties.setDataPath(dataPath);\n-        parserProperties = new RecordParserProperties(mirrorProperties);\n-        parserProperties.setKeepFiles(false);\n-        parserProperties.init();\n-        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n-        StreamType streamType = StreamType.RECORD;\n-        fileCopier = FileCopier\n-                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n-                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n-                .filterFiles(\"*.rcd\")\n-                .to(streamType.getPath(), streamType.getValid());\n-        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n-        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n-                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n-                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n-\n-        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n-                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n-                recordFile1.getFileHash(), 2);\n-    }\n-\n-    @Test\n-    void poll() throws Exception {\n-        // given\n-        fileCopier.copy();\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertAllProcessed();\n-    }\n-\n-    @Test\n-    void pollAndKeepFiles() throws Exception {\n-        // given\n-        parserProperties.setKeepFiles(true);\n-        fileCopier.copy();\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertAllProcessed();\n-    }\n-\n-    @Test\n-    void noFiles() throws Exception {\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        verifyNoInteractions(recordFileParser);\n-    }\n-\n-    @Test\n-    void pathNotDirectory() throws Exception {\n-        // when\n-        fileCopier.copy();\n-        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-        verifyNoInteractions(recordFileParser);\n-    }\n-\n-    @Test\n-    void fileNotFoundFromRecordFileParser() {\n-        // given\n-        fileCopier.copy();\n-        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n-        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n-        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-    }\n-\n-    @Test\n-    void errorFromRecordFileParser() {\n-        // when\n-        fileCopier.copy();\n-        doThrow(ParserException.class).when(recordFileParser).parse(any());\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-    }\n-\n-    // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n-    private void assertParse(String... fileNames) {\n-        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n-        verify(recordFileParser, times(fileNames.length)).parse(captor.capture());\n-        List<StreamFileData> actualArgs = captor.getAllValues();\n-        assertThat(actualArgs)\n-                .extracting(StreamFileData::getFilename)\n-                .isEqualTo(Arrays.asList(fileNames));\n-    }\n-\n-    // Asserts that parsed directory contains exactly the files with given fileNames\n-    private void assertParsedFiles(String... fileNames) throws Exception {\n-        assertThat(Files.walk(parserProperties.getParsedPath()))\n-                .filteredOn(p -> !p.toFile().isDirectory())\n-                .hasSize(fileNames.length)\n-                .extracting(Path::getFileName)\n-                .extracting(Path::toString)\n-                .contains(fileNames);\n-    }\n-\n-    // Asserts that valid files are untouched i.e. neither deleted, nor moved\n-    private void assertValidFiles() {\n-        assertTrue(Files.exists(file1.toPath()));\n-        assertTrue(Files.exists(file2.toPath()));\n-    }\n-\n-    private void assertAllProcessed() throws Exception {\n-        // assert no valid files when processing completes successfully\n-        assertFalse(Files.exists(file1.toPath()));\n-        assertFalse(Files.exists(file2.toPath()));\n-\n-        // assert parsed files are moved/deleted.\n-        if (parserProperties.isKeepFiles()) {\n-            assertParsedFiles(file1.getName(), file2.getName());\n-        } else {\n-            assertParsedFiles(); // assert no files in parsed directory\n-        }\n-\n-        // assert mock interactions\n-        assertParse(file1.getPath(), file2.getPath());\n-    }\n-}\n", "next_change": null}]}}, {"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 14c7bb619..8a1529abc 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -131,7 +177,7 @@ public class RecordFilePollerTest {\n         List<StreamFileData> actualArgs = captor.getAllValues();\n         assertThat(actualArgs)\n                 .extracting(StreamFileData::getFilename)\n-                .contains(fileNames);\n+                .isEqualTo(Arrays.asList(fileNames));\n     }\n \n     // Asserts that parsed directory contains exactly the files with given fileNames\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\ndeleted file mode 100644\nindex 8a1529abc..000000000\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ /dev/null\n", "chunk": "@@ -1,214 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import static org.assertj.core.api.Assertions.assertThat;\n-import static org.junit.Assert.assertFalse;\n-import static org.junit.Assert.assertTrue;\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.doReturn;\n-import static org.mockito.Mockito.doThrow;\n-import static org.mockito.Mockito.times;\n-import static org.mockito.Mockito.verify;\n-import static org.mockito.Mockito.verifyNoInteractions;\n-\n-import java.io.File;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import java.util.List;\n-import org.junit.jupiter.api.BeforeEach;\n-import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import org.junit.jupiter.api.io.TempDir;\n-import org.mockito.ArgumentCaptor;\n-import org.mockito.Mock;\n-import org.mockito.Mockito;\n-import org.mockito.junit.jupiter.MockitoExtension;\n-\n-import com.hedera.mirror.importer.FileCopier;\n-import com.hedera.mirror.importer.MirrorProperties;\n-import com.hedera.mirror.importer.domain.RecordFile;\n-import com.hedera.mirror.importer.domain.StreamType;\n-import com.hedera.mirror.importer.exception.ParserException;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-\n-@ExtendWith(MockitoExtension.class)\n-public class RecordFilePollerTest {\n-\n-    @TempDir\n-    Path dataPath;\n-    @Mock\n-    RecordFileParser recordFileParser;\n-    private FileCopier fileCopier;\n-    private RecordFilePoller recordFilePoller;\n-    private RecordParserProperties parserProperties;\n-    private MirrorProperties mirrorProperties;\n-\n-    private File file1;\n-    private File file2;\n-    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n-    private static final int NUM_TXNS_FILE_1 = 19;\n-    private static final int NUM_TXNS_FILE_2 = 15;\n-    private static RecordFile recordFile1;\n-    private static RecordFile recordFile2;\n-\n-    @BeforeEach\n-    void before() {\n-        mirrorProperties = new MirrorProperties();\n-        mirrorProperties.setDataPath(dataPath);\n-        parserProperties = new RecordParserProperties(mirrorProperties);\n-        parserProperties.setKeepFiles(false);\n-        parserProperties.init();\n-        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n-        StreamType streamType = StreamType.RECORD;\n-        fileCopier = FileCopier\n-                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n-                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n-                .filterFiles(\"*.rcd\")\n-                .to(streamType.getPath(), streamType.getValid());\n-        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n-        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n-                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n-                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n-\n-        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n-                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n-                recordFile1.getFileHash(), 2);\n-    }\n-\n-    @Test\n-    void poll() throws Exception {\n-        // given\n-        fileCopier.copy();\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertAllProcessed();\n-    }\n-\n-    @Test\n-    void pollAndKeepFiles() throws Exception {\n-        // given\n-        parserProperties.setKeepFiles(true);\n-        fileCopier.copy();\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertAllProcessed();\n-    }\n-\n-    @Test\n-    void noFiles() throws Exception {\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        verifyNoInteractions(recordFileParser);\n-    }\n-\n-    @Test\n-    void pathNotDirectory() throws Exception {\n-        // when\n-        fileCopier.copy();\n-        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-        verifyNoInteractions(recordFileParser);\n-    }\n-\n-    @Test\n-    void fileNotFoundFromRecordFileParser() {\n-        // given\n-        fileCopier.copy();\n-        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n-        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n-        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-    }\n-\n-    @Test\n-    void errorFromRecordFileParser() {\n-        // when\n-        fileCopier.copy();\n-        doThrow(ParserException.class).when(recordFileParser).parse(any());\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-    }\n-\n-    // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n-    private void assertParse(String... fileNames) {\n-        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n-        verify(recordFileParser, times(fileNames.length)).parse(captor.capture());\n-        List<StreamFileData> actualArgs = captor.getAllValues();\n-        assertThat(actualArgs)\n-                .extracting(StreamFileData::getFilename)\n-                .isEqualTo(Arrays.asList(fileNames));\n-    }\n-\n-    // Asserts that parsed directory contains exactly the files with given fileNames\n-    private void assertParsedFiles(String... fileNames) throws Exception {\n-        assertThat(Files.walk(parserProperties.getParsedPath()))\n-                .filteredOn(p -> !p.toFile().isDirectory())\n-                .hasSize(fileNames.length)\n-                .extracting(Path::getFileName)\n-                .extracting(Path::toString)\n-                .contains(fileNames);\n-    }\n-\n-    // Asserts that valid files are untouched i.e. neither deleted, nor moved\n-    private void assertValidFiles() {\n-        assertTrue(Files.exists(file1.toPath()));\n-        assertTrue(Files.exists(file2.toPath()));\n-    }\n-\n-    private void assertAllProcessed() throws Exception {\n-        // assert no valid files when processing completes successfully\n-        assertFalse(Files.exists(file1.toPath()));\n-        assertFalse(Files.exists(file2.toPath()));\n-\n-        // assert parsed files are moved/deleted.\n-        if (parserProperties.isKeepFiles()) {\n-            assertParsedFiles(file1.getName(), file2.getName());\n-        } else {\n-            assertParsedFiles(); // assert no files in parsed directory\n-        }\n-\n-        // assert mock interactions\n-        assertParse(file1.getPath(), file2.getPath());\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzExMjMzMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467112330", "body": "This exception is already logged in poller, so this log can be removed.", "bodyText": "This exception is already logged in poller, so this log can be removed.", "bodyHTML": "<p dir=\"auto\">This exception is already logged in poller, so this log can be removed.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:29:29Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -165,6 +155,10 @@ public void loadRecordFile(StreamFileData streamFileData) {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (Exception ex) {\n+            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjEwMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676103", "bodyText": "Removed", "author": "Nana-EC", "createdAt": "2020-08-10T03:48:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzExMjMzMA=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..6c0258766 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -150,20 +150,17 @@ public class RecordFileParser implements FileParser {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n         } catch (Exception ex) {\n-            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n-            recordStreamFileListener.onError(); // rollback changes\n+            recordStreamFileListener.onError(); // rollback\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..3a2c97fed 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -165,7 +173,7 @@ public class RecordFileParser implements FileParser {\n         }\n     }\n \n-    private void processRecordItem(RecordItem recordItem) {\n+    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3a2c97fed..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -124,52 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n+            }\n+\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n \n-            recordParserLatencyMetric(recordFile);\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n+\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEyMjI5Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467122296", "body": "This seems to leak details of the parser. I think it makes more sense to catch DuplicateFileException in the parser and ignore it there.", "bodyText": "This seems to leak details of the parser. I think it makes more sense to catch DuplicateFileException in the parser and ignore it there.", "bodyHTML": "<p dir=\"auto\">This seems to leak details of the parser. I think it makes more sense to catch DuplicateFileException in the parser and ignore it there.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:47:30Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)\n+                        .collect(Collectors.toList());\n+\n+                if (fullPaths != null && fullPaths.size() != 0) {\n+                    log.trace(\"Processing record files: {}\", fullPaths);\n+                    loadRecordFiles(fullPaths);\n+                } else {\n+                    log.debug(\"No files to parse\");\n+                }\n+            } else {\n+                log.error(\"Input parameter is not a folder: {}\", path);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Error parsing files\", e);\n+        }\n+    }\n+\n+    /**\n+     * read and parse a list of record files\n+     *\n+     * @throws Exception\n+     */\n+    private void loadRecordFiles(List<String> filePaths) {\n+        Collections.sort(filePaths);\n+        for (String filePath : filePaths) {\n+            if (ShutdownHelper.isStopping()) {\n+                return;\n+            }\n+\n+            File file = new File(filePath);\n+\n+            try (InputStream fileInputStream = new FileInputStream(file)) {\n+                recordFileParser.parse(new StreamFileData(filePath, fileInputStream));\n+\n+                if (parserProperties.isKeepFiles()) {\n+                    Utility.archiveFile(file, parserProperties.getParsedPath());\n+                } else {\n+                    FileUtils.deleteQuietly(file);\n+                }\n+            } catch (FileNotFoundException e) {\n+                log.warn(\"File does not exist {}\", filePath);\n+                return;\n+            } catch (Exception e) {\n+                log.error(\"Error parsing file {}\", filePath, e);\n+                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjE5Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676193", "bodyText": "DuplicateFileException catch log and ignore added to parser", "author": "Nana-EC", "createdAt": "2020-08-10T03:48:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEyMjI5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -110,11 +103,8 @@ public class RecordFilePoller implements FilePoller {\n                 log.warn(\"File does not exist {}\", filePath);\n                 return;\n             } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n-                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other\n-                    // files\n-                    return;\n-                }\n+                log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                return;\n             }\n         }\n     }\n", "next_change": {"commit": "a7d4932eb9ea4621d184f40c095857f456e7a496", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex d5b6bf905..687b8a512 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -103,7 +103,7 @@ public class RecordFilePoller implements FilePoller {\n                 log.warn(\"File does not exist {}\", filePath);\n                 return;\n             } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                log.error(\"Error parsing file {}\", filePath, e);\n                 return;\n             }\n         }\n", "next_change": {"commit": "a56ea83364b2c8e38746a5a5048555dad80741d3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex 687b8a512..d11a9f4e6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -91,17 +88,14 @@ public class RecordFilePoller implements FilePoller {\n             // get file from full path\n             File file = validPath.resolve(filePath).toFile();\n \n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n+            try {\n+                recordFileParser.parse(StreamFileData.from(file));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n                 } else {\n                     FileUtils.deleteQuietly(file);\n                 }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n             } catch (Exception e) {\n                 log.error(\"Error parsing file {}\", filePath, e);\n                 return;\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d11a9f4e6..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,105 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.domain.StreamFileData;\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedDelayString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try {\n-                recordFileParser.parse(StreamFileData.from(file));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzA1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467133053", "body": "There's a problem here. In SqlEntityListener we manually manage the commit and that can cause issues. From `connection.setAutoCommit()`:\r\n```\r\nIf this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\r\n```\r\nAlso, I'm not sure the impact of explicitly calling commit on a connection with an outer transaction in progress. It would be better to remove setAutoCommit and not call commit/rollback manually. This annotation should handle it for us. But please verify with tests.\r\n\r\nI'm not sure about the connection and statements in SqlEntityListener. I'm guessing we still need to manually close those but since they're proxied they won't actually close until the outer transaction completes.", "bodyText": "There's a problem here. In SqlEntityListener we manually manage the commit and that can cause issues. From connection.setAutoCommit():\nIf this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\n\nAlso, I'm not sure the impact of explicitly calling commit on a connection with an outer transaction in progress. It would be better to remove setAutoCommit and not call commit/rollback manually. This annotation should handle it for us. But please verify with tests.\nI'm not sure about the connection and statements in SqlEntityListener. I'm guessing we still need to manually close those but since they're proxied they won't actually close until the outer transaction completes.", "bodyHTML": "<p dir=\"auto\">There's a problem here. In SqlEntityListener we manually manage the commit and that can cause issues. From <code>connection.setAutoCommit()</code>:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"If this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\"><pre><code>If this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\n</code></pre></div>\n<p dir=\"auto\">Also, I'm not sure the impact of explicitly calling commit on a connection with an outer transaction in progress. It would be better to remove setAutoCommit and not call commit/rollback manually. This annotation should handle it for us. But please verify with tests.</p>\n<p dir=\"auto\">I'm not sure about the connection and statements in SqlEntityListener. I'm guessing we still need to manually close those but since they're proxied they won't actually close until the outer transaction completes.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:07:01Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -135,11 +123,13 @@ public RecordFileParser(ApplicationStatusRepository applicationStatusRepository,\n     }\n \n     /**\n-     * Given a service record name, read and parse and return as a list of service record pair\n+     * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    @Override\n+    @Transactional", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjQ5OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676499", "bodyText": "Manual close is good practice, but you're right the outer transaction close will probably handle it.\nI did remove the setAutoCommit", "author": "Nana-EC", "createdAt": "2020-08-10T03:50:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzA1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..6c0258766 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,12 +132,12 @@ public class RecordFileParser implements FileParser {\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n-        recordStreamFileListener.onStart(streamFileData);\n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n+            recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n                     streamFileData.getFilename(), expectedPrevFileHash,\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..3a2c97fed 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -134,6 +140,7 @@ public class RecordFileParser implements FileParser {\n \n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n", "next_change": {"commit": "ee6eef3e60ca0b187642ec53dd9c42aa3bad5f8c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3a2c97fed..8b4278371 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -144,22 +143,26 @@ public class RecordFileParser implements FileParser {\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n+            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    streamFileData.getFilename(),\n                     recordItem -> {\n                         if (processRecordItem(recordItem, dateRangeFilter)) {\n                             counter.incrementAndGet();\n                         }\n                     });\n+            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n+                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            }\n+\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFile);\n+            recordFileDb.setLoadStart(startTime.getEpochSecond());\n+            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFileDb);\n \n-            recordParserLatencyMetric(recordFile);\n+            recordParserLatencyMetric(recordFileDb);\n             success = true;\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 8b4278371..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -123,56 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n-                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n             }\n \n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFileDb.setLoadStart(startTime.getEpochSecond());\n-            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFileDb);\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFile);\n+\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n \n-            recordParserLatencyMetric(recordFileDb);\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..3a2c97fed 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,8 +150,9 @@ public class RecordFileParser implements FileParser {\n                     streamFileData.getFilename(), expectedPrevFileHash,\n                     parserProperties.getMirrorProperties().getVerifyHashAfter(),\n                     recordItem -> {\n-                        counter.incrementAndGet();\n-                        processRecordItem(recordItem);\n+                        if (processRecordItem(recordItem, dateRangeFilter)) {\n+                            counter.incrementAndGet();\n+                        }\n                     });\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n             recordFile.setLoadStart(startTime.getEpochSecond());\n", "next_change": {"commit": "ee6eef3e60ca0b187642ec53dd9c42aa3bad5f8c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3a2c97fed..8b4278371 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -144,22 +143,26 @@ public class RecordFileParser implements FileParser {\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n+            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    streamFileData.getFilename(),\n                     recordItem -> {\n                         if (processRecordItem(recordItem, dateRangeFilter)) {\n                             counter.incrementAndGet();\n                         }\n                     });\n+            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n+                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            }\n+\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFile);\n+            recordFileDb.setLoadStart(startTime.getEpochSecond());\n+            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFileDb);\n \n-            recordParserLatencyMetric(recordFile);\n+            recordParserLatencyMetric(recordFileDb);\n             success = true;\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 8b4278371..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -123,56 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n-                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n             }\n \n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFileDb.setLoadStart(startTime.getEpochSecond());\n-            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFileDb);\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFile);\n+\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n \n-            recordParserLatencyMetric(recordFileDb);\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzkxMQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467133911", "body": "Can remove rollback changes comment, considering previous change.", "bodyText": "Can remove rollback changes comment, considering previous change.", "bodyHTML": "<p dir=\"auto\">Can remove rollback changes comment, considering previous change.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:08:36Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -165,6 +155,10 @@ public void loadRecordFile(StreamFileData streamFileData) {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (Exception ex) {\n+            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n+            recordStreamFileListener.onError(); // rollback changes", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjU2OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676568", "bodyText": "Removed comment", "author": "Nana-EC", "createdAt": "2020-08-10T03:51:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..6c0258766 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -150,20 +150,17 @@ public class RecordFileParser implements FileParser {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n         } catch (Exception ex) {\n-            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n-            recordStreamFileListener.onError(); // rollback changes\n+            recordStreamFileListener.onError(); // rollback\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..3a2c97fed 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -165,7 +173,7 @@ public class RecordFileParser implements FileParser {\n         }\n     }\n \n-    private void processRecordItem(RecordItem recordItem) {\n+    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3a2c97fed..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -124,52 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n+            }\n+\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n \n-            recordParserLatencyMetric(recordFile);\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n+\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNDUxNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467134516", "body": "Unused", "bodyText": "Unused", "bodyHTML": "<p dir=\"auto\">Unused</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:09:40Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -188,47 +166,63 @@ void bypassHashMismatch() throws Exception {\n         // given\n         parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n         when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n-        fileCopier.copy();\n \n         // when\n-        recordFileParser.parse();\n+        recordFileParser.parse(streamFileData1);\n \n         // then\n-        assertAllProcessed();\n+        verify(recordStreamFileListener, never()).onError();\n+        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() throws Exception {\n+    void failureProcessingItemShouldRollback() {\n         // given\n-        fileCopier.copy();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        recordFileParser.parse();\n+        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n+            recordFileParser.parse(streamFileData1);\n+        });\n \n         // then\n-        assertValidFiles();\n+        verify(recordStreamFileListener).onStart(streamFileData1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n         verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n-    void skipFileOnDuplicateFileException() throws Exception {\n+    void skipFileOnDuplicateFileException() {\n         // given\n-        fileCopier.copy();\n-        String fileName = file1.toString();\n-        recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+        recordFileParser.parse(streamFileData1);\n         doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n \n         // when: load same file again\n         // then: throws exception\n         Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+            recordFileParser.parse(streamFileData1);\n         });\n         verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n         verify(recordStreamFileListener, times(2)).onStart(any());\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n+    @Test\n+    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n+        // given\n+        String fileName = file1.toString();", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjYxNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676615", "bodyText": "Removed leftover", "author": "Nana-EC", "createdAt": "2020-08-10T03:51:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNDUxNg=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex ab3f2e8ce..cf76749fa 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -191,38 +190,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n-    @Test\n-    void skipFileOnDuplicateFileException() {\n-        // given\n-        recordFileParser.parse(streamFileData1);\n-        doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n-\n-        // when: load same file again\n-        // then: throws exception\n-        Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n-        verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n-        verify(recordStreamFileListener, times(2)).onStart(any());\n-        verify(recordStreamFileListener, times(1)).onEnd(any());\n-    }\n-\n-    @Test\n-    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n-        // given\n-        String fileName = file1.toString();\n-        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n-\n-        // when\n-        Assertions.assertThrows(ParserSQLException.class, () -> {\n-            recordFileParser.parse(streamFileData2);\n-        });\n-\n-        // then\n-        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);\n-        verify(recordStreamFileListener).onError();\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex cf76749fa..6a6a8b292 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -190,6 +235,60 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n+    @ParameterizedTest(name = \"parse with endDate set to {0}ns after the {1}th transaction\")\n+    @CsvSource(value = {\n+            \"-1, 0\",\n+            \" 0, 0\",\n+            \" 1, 0\",\n+            \"-1, 19\",\n+            \" 0, 19\",\n+            \" 1, 19\"\n+    })\n+    void parseWithEndDate(long nanos, int index) throws Exception {\n+        // given\n+        long end = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        DateRangeFilter filter = new DateRangeFilter(Instant.EPOCH, Instant.ofEpochSecond(0, end));\n+        doReturn(filter)\n+                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n+        fileCopier.copy();\n+        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n+                .thenReturn(recordFile1.getFileHash());\n+\n+        // when\n+        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(streamFileData2);\n+\n+        // then\n+        assertAllProcessed(filter);\n+    }\n+\n+    @ParameterizedTest(name = \"parse with startDate set to {0}ns after the {1}th transaction\")\n+    @CsvSource(value = {\n+            \"-1, 0\",\n+            \" 0, 0\",\n+            \" 1, 0\",\n+            \"-1, 19\",\n+            \" 0, 19\",\n+            \" 1, 19\"\n+    })\n+    void parseWithStartDate(long nanos, int index) throws Exception {\n+        // given\n+        long start = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        DateRangeFilter filter = new DateRangeFilter(Instant.ofEpochSecond(0, start), null);\n+        doReturn(filter)\n+                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n+        fileCopier.copy();\n+        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n+                .thenReturn(recordFile1.getFileHash());\n+\n+        // when\n+        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(streamFileData2);\n+\n+        // then\n+        assertAllProcessed(filter);\n+    }\n+\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 6a6a8b292..c4c4d81bf 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -47,289 +45,220 @@ import org.junit.jupiter.api.extension.ExtendWith;\n import org.junit.jupiter.api.io.TempDir;\n import org.junit.jupiter.params.ParameterizedTest;\n import org.junit.jupiter.params.provider.CsvSource;\n-import org.mockito.ArgumentCaptor;\n import org.mockito.Mock;\n import org.mockito.junit.jupiter.MockitoExtension;\n \n-import com.hedera.mirror.importer.FileCopier;\n import com.hedera.mirror.importer.MirrorProperties;\n import com.hedera.mirror.importer.config.MirrorDateRangePropertiesProcessor;\n+import com.hedera.mirror.importer.config.MirrorDateRangePropertiesProcessor.DateRangeFilter;\n+import com.hedera.mirror.importer.domain.DigestAlgorithm;\n+import com.hedera.mirror.importer.domain.EntityId;\n+import com.hedera.mirror.importer.domain.EntityTypeEnum;\n import com.hedera.mirror.importer.domain.RecordFile;\n-import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.exception.ImporterException;\n import com.hedera.mirror.importer.exception.ParserSQLException;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-import com.hedera.mirror.importer.repository.ApplicationStatusRepository;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+import com.hedera.mirror.importer.util.Utility;\n \n @ExtendWith(MockitoExtension.class)\n-public class RecordFileParserTest {\n+class RecordFileParserTest {\n \n     @TempDir\n-    Path dataPath;\n-    @Mock\n-    private ApplicationStatusRepository applicationStatusRepository;\n+    Path dataDir;\n+\n     @Mock\n     private RecordItemListener recordItemListener;\n-    @Mock\n+\n+    @Mock(lenient = true)\n     private RecordStreamFileListener recordStreamFileListener;\n+\n     @Mock\n     private MirrorDateRangePropertiesProcessor mirrorDateRangePropertiesProcessor;\n \n-    private MirrorProperties mirrorProperties;\n-    private FileCopier fileCopier;\n     private RecordFileParser recordFileParser;\n     private RecordParserProperties parserProperties;\n-\n-    private File file1;\n-    private File file2;\n-    private static final int NUM_TXNS_FILE_1 = 19;\n-    private static final long[] FILE_CONSENSUS_TIMESTAMPS = {\n-            1567188600419072000L,\n-            1567188600762801000L,\n-            1567188600883799000L,\n-            1567188600963103000L,\n-            1567188601371995000L,\n-            1567188601739500000L,\n-            1567188602108299000L,\n-            1567188602118673001L,\n-            1567188602450554001L,\n-            1567188602838615000L,\n-            1567188603175332000L,\n-            1567188603277507000L,\n-            1567188603609988000L,\n-            1567188603706753001L,\n-            1567188604084005000L,\n-            1567188604429968000L,\n-            1567188604524835000L,\n-            1567188604856082001L,\n-            1567188604906443001L,\n-            1567188605249678000L,\n-            1567188605824917000L,\n-            1567188606171654000L,\n-            1567188606181740000L,\n-            1567188606499404000L,\n-            1567188606576024000L,\n-            1567188606932283000L,\n-            1567188607246509000L,\n-            1567188608065015001L,\n-            1567188608413240000L,\n-            1567188608566437000L,\n-            1567188608878373000L,\n-            1567188608972069001L,\n-            1567188609337810002L,\n-            1567188609705382001L\n-    };\n-\n-    private static RecordFile recordFile1;\n-    private static RecordFile recordFile2;\n-    private static StreamFileData streamFileData1;\n-    private static StreamFileData streamFileData2;\n+    private long count = 0;\n \n     @BeforeEach\n-    void before() throws FileNotFoundException {\n-        mirrorProperties = new MirrorProperties();\n-        mirrorProperties.setDataPath(dataPath);\n+    void before() {\n+        MirrorProperties mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataDir);\n         parserProperties = new RecordParserProperties(mirrorProperties);\n-        parserProperties.setKeepFiles(false);\n-        parserProperties.init();\n-        recordFileParser = new RecordFileParser(applicationStatusRepository, parserProperties, new SimpleMeterRegistry(),\n+\n+        recordFileParser = new RecordFileParser(parserProperties, new SimpleMeterRegistry(),\n                 recordItemListener, recordStreamFileListener, mirrorDateRangePropertiesProcessor);\n-        StreamType streamType = StreamType.RECORD;\n-        fileCopier = FileCopier\n-                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n-                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n-                .filterFiles(\"*.rcd\");\n-\n-        fileCopier.copy();\n-        file1 = dataPath.resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n-        file2 = dataPath.resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n-                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n-                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n-\n-        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n-                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n-                recordFile1.getFileHash(), 2);\n-\n-        streamFileData1 = new StreamFileData(file1.toString(), new FileInputStream(file1));\n-        streamFileData2 = new StreamFileData(file2.toString(), new FileInputStream(file2));\n     }\n \n     @Test\n     void parse() throws Exception {\n         // given\n-        parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash(), recordFile2.getFileHash());\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n-\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n         verify(recordStreamFileListener, never()).onError();\n-        assertAllProcessed();\n+        assertFilesArchived();\n+        assertThat(recordFile.getBytes()).isNull();\n     }\n \n     @Test\n-    void invalidFile() throws Exception {\n+    void disabled() throws Exception {\n         // given\n-        FileUtils.writeStringToFile(file1, \"corrupt\", \"UTF-8\");\n-        streamFileData1 = new StreamFileData(file1.toString(), new FileInputStream(file1));\n+        parserProperties.setEnabled(false);\n+        parserProperties.setKeepFiles(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n-        verify(recordStreamFileListener).onError();\n+        verify(recordStreamFileListener, never()).onStart();\n+        assertFilesArchived();\n     }\n \n     @Test\n-    void hashMismatch() {\n+    void persistBytes() throws Exception {\n         // given\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n+        parserProperties.setPersistBytes(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(any());\n-        verify(recordStreamFileListener).onError();\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n+        verify(recordStreamFileListener, never()).onError();\n+        assertThat(recordFile.getBytes()).isNotNull();\n     }\n \n     @Test\n-    void bypassHashMismatch() throws Exception {\n+    void keepFiles() throws Exception {\n         // given\n-        parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n+        parserProperties.setKeepFiles(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(recordFile);\n \n         // then\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n         verify(recordStreamFileListener, never()).onError();\n-        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n+        assertFilesArchived(recordFile.getName());\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() {\n+    void failureShouldRollback() throws Exception {\n         // given\n+        RecordFile recordFile = recordFile();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n+        Assertions.assertThrows(ImporterException.class, () -> {\n+            recordFileParser.parse(recordFile);\n         });\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile);\n         verify(recordStreamFileListener).onError();\n+        assertFilesArchived();\n     }\n \n-    @ParameterizedTest(name = \"parse with endDate set to {0}ns after the {1}th transaction\")\n-    @CsvSource(value = {\n-            \"-1, 0\",\n-            \" 0, 0\",\n-            \" 1, 0\",\n-            \"-1, 19\",\n-            \" 0, 19\",\n-            \" 1, 19\"\n-    })\n-    void parseWithEndDate(long nanos, int index) throws Exception {\n+    @ParameterizedTest(name = \"endDate with offset {0}ns\")\n+    @CsvSource({\"-1\", \"0\", \"1\"})\n+    void endDate(long offset) {\n         // given\n-        long end = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        RecordFile recordFile = recordFile();\n+        long end = recordFile.getConsensusStart() + offset;\n         DateRangeFilter filter = new DateRangeFilter(Instant.EPOCH, Instant.ofEpochSecond(0, end));\n-        doReturn(filter)\n-                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n-        fileCopier.copy();\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash());\n+        doReturn(filter).when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        assertAllProcessed(filter);\n+        verify(recordStreamFileListener).onStart();\n+        if (offset >= 0) {\n+            verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        }\n+        verify(recordStreamFileListener).onEnd(recordFile);\n     }\n \n-    @ParameterizedTest(name = \"parse with startDate set to {0}ns after the {1}th transaction\")\n-    @CsvSource(value = {\n-            \"-1, 0\",\n-            \" 0, 0\",\n-            \" 1, 0\",\n-            \"-1, 19\",\n-            \" 0, 19\",\n-            \" 1, 19\"\n-    })\n-    void parseWithStartDate(long nanos, int index) throws Exception {\n+    @ParameterizedTest(name = \"startDate with offset {0}ns\")\n+    @CsvSource({\"-1\", \"0\", \"1\"})\n+    void startDate(long offset) {\n         // given\n-        long start = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        RecordFile recordFile = recordFile();\n+        long start = recordFile.getConsensusStart() + offset;\n         DateRangeFilter filter = new DateRangeFilter(Instant.ofEpochSecond(0, start), null);\n-        doReturn(filter)\n-                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n-        fileCopier.copy();\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash());\n+        doReturn(filter).when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        assertAllProcessed(filter);\n-    }\n-\n-    // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n-    private void assertOnStart(String... fileNames) {\n-        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n-        verify(recordStreamFileListener, times(fileNames.length)).onStart(captor.capture());\n-        List<StreamFileData> actualArgs = captor.getAllValues();\n-        assertThat(actualArgs)\n-                .extracting(StreamFileData::getFilename)\n-                .contains(fileNames);\n-    }\n-\n-    // Asserts that recordStreamFileListener.onEnd is called exactly with given recordFiles (ignoring load start and end\n-    //times), in given order\n-    private void assertOnEnd(RecordFile... recordFiles) {\n-        ArgumentCaptor<RecordFile> captor = ArgumentCaptor.forClass(RecordFile.class);\n-        verify(recordStreamFileListener, times(recordFiles.length)).onEnd(captor.capture());\n-        List<RecordFile> actualArgs = captor.getAllValues();\n-        for (int i = 0; i < recordFiles.length; i++) {\n-            RecordFile actual = actualArgs.get(i);\n-            RecordFile expected = recordFiles[i];\n-            assertThat(actual).isEqualToIgnoringGivenFields(expected, \"id\", \"loadEnd\", \"loadStart\", \"recordItems\");\n+        verify(recordStreamFileListener).onStart();\n+        if (offset < 0) {\n+            verify(recordItemListener).onItem(recordFile.getItems().get(0));\n         }\n+        verify(recordStreamFileListener).onEnd(recordFile);\n     }\n \n-    private void assertProcessedFile(StreamFileData streamFileData, RecordFile recordFile, int numTransactions) throws Exception {\n-        // assert mock interactions\n-        verify(recordItemListener, times(numTransactions)).onItem(any());\n-        assertOnStart(streamFileData.getFilename());\n-        assertOnEnd(recordFile);\n+    // Asserts that parsed directory contains exactly the files with given fileNames\n+    private void assertFilesArchived(String... fileNames) throws Exception {\n+        if (fileNames == null || fileNames.length == 0) {\n+            assertThat(parserProperties.getParsedPath()).doesNotExist();\n+            return;\n+        }\n+        assertThat(Files.walk(parserProperties.getParsedPath()))\n+                .filteredOn(p -> !p.toFile().isDirectory())\n+                .hasSize(fileNames.length)\n+                .extracting(Path::getFileName)\n+                .extracting(Path::toString)\n+                .contains(fileNames);\n     }\n \n-    private void assertAllProcessed() throws Exception {\n-        assertAllProcessed(null);\n+    private RecordFile recordFile() {\n+        long id = ++count;\n+        Instant instant = Instant.ofEpochSecond(0L, id);\n+        String filename = Utility.getStreamFilenameFromInstant(parserProperties.getStreamType(), instant);\n+        RecordFile recordFile = new RecordFile();\n+        recordFile.setBytes(new byte[] {0, 1, 2});\n+        recordFile.setConsensusEnd(id);\n+        recordFile.setConsensusStart(id);\n+        recordFile.setConsensusEnd(id);\n+        recordFile.setCount(id);\n+        recordFile.setDigestAlgorithm(DigestAlgorithm.SHA384);\n+        recordFile.setFileHash(\"fileHash\" + id);\n+        recordFile.setHash(\"hash\" + id);\n+        recordFile.setLoadEnd(id);\n+        recordFile.setLoadStart(id);\n+        recordFile.setName(filename);\n+        recordFile.setNodeAccountId(EntityId.of(\"0.0.3\", EntityTypeEnum.ACCOUNT));\n+        recordFile.setPreviousHash(\"previousHash\" + (id - 1));\n+        recordFile.setVersion(1);\n+        recordFile.getItems().add(recordItem(id));\n+        return recordFile;\n     }\n \n-    private void assertAllProcessed(DateRangeFilter dateRangeFilter) throws Exception {\n-        // assert mock interactions\n-        int expectedNumTxns = (int)Arrays.stream(FILE_CONSENSUS_TIMESTAMPS)\n-                .filter(ts -> dateRangeFilter == null || dateRangeFilter.filter(ts)).count();\n-\n-        verify(recordItemListener, times(expectedNumTxns)).onItem(any());\n-        assertOnStart(streamFileData1.getFilename(), streamFileData2.getFilename());\n-        assertOnEnd(recordFile1, recordFile2);\n+    private RecordItem recordItem(long timestamp) {\n+        CryptoTransferTransactionBody cryptoTransfer = CryptoTransferTransactionBody.newBuilder().build();\n+        TransactionBody transactionBody = TransactionBody.newBuilder().setCryptoTransfer(cryptoTransfer).build();\n+        SignedTransaction signedTransaction = SignedTransaction.newBuilder()\n+                .setBodyBytes(transactionBody.toByteString())\n+                .setSigMap(SignatureMap.newBuilder().build())\n+                .build();\n+        Transaction transaction = Transaction.newBuilder()\n+                .setSignedTransactionBytes(signedTransaction.toByteString())\n+                .build();\n+        TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n+                .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+                .build();\n+        return new RecordItem(transaction.toByteArray(), transactionRecord.toByteArray());\n     }\n }\n", "next_change": {"commit": "627531943097f9c37ed087518790afbed92d1e65", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex c4c4d81bf..c198feeab 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -259,6 +201,6 @@ class RecordFileParserTest {\n         TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n                 .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n                 .build();\n-        return new RecordItem(transaction.toByteArray(), transactionRecord.toByteArray());\n+        return new RecordItem(transaction, transactionRecord);\n     }\n }\n", "next_change": {"commit": "064e4d6687bccad391f48d60156c651777caabbf", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex c198feeab..6faf94898 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -198,9 +260,31 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n         Transaction transaction = Transaction.newBuilder()\n                 .setSignedTransactionBytes(signedTransaction.toByteString())\n                 .build();\n-        TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n-                .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+        return RecordItem.builder()\n+                .record(transactionRecord)\n+                .transactionBytes(transaction.toByteArray())\n+                .build();\n+    }\n+\n+    private RecordItem ethereumTransaction(ContractFunctionResult contractFunctionResult, long timestamp,\n+            int transactionIdNonce) {\n+        return recordItemBuilder\n+                .ethereumTransaction(true)\n+                .record(builder -> builder.setContractCallResult(contractFunctionResult)\n+                        .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+                        .setTransactionID(TransactionID.newBuilder().setNonce(transactionIdNonce).build())\n+                )\n                 .build();\n-        return new RecordItem(transaction, transactionRecord);\n+    }\n+\n+    private RecordFile getStreamFile(final Flux<RecordItem> items, final long timestamp) {\n+        return domainBuilder\n+                .recordFile()\n+                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] { 0, 1, 2 })\n+                        .consensusEnd(timestamp)\n+                        .consensusStart(timestamp)\n+                        .items(items)\n+                )\n+                .get();\n     }\n }\n", "next_change": {"commit": "29de773a595e26507d772e92061bf63225447db3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 6faf94898..b28ed86e0 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -280,9 +280,10 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n     private RecordFile getStreamFile(final Flux<RecordItem> items, final long timestamp) {\n         return domainBuilder\n                 .recordFile()\n-                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] { 0, 1, 2 })\n+                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] {0, 1, 2})\n                         .consensusEnd(timestamp)\n                         .consensusStart(timestamp)\n+                        .gasUsed(0L)\n                         .items(items)\n                 )\n                 .get();\n", "next_change": {"commit": "79a9fb94bb82b4b46d25651f91314bdae5c0ccb1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex b28ed86e0..118392977 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -281,7 +398,7 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n         return domainBuilder\n                 .recordFile()\n                 .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] {0, 1, 2})\n-                        .consensusEnd(timestamp)\n+                        .consensusEnd(timestamp+1)\n                         .consensusStart(timestamp)\n                         .gasUsed(0L)\n                         .items(items)\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467138046", "body": "I don't think it's possible to truly test database rollback with mocks. Since it's probably tricky to convert this to not use mocks, we can probably create a separate integration test file just for the rollback test.", "bodyText": "I don't think it's possible to truly test database rollback with mocks. Since it's probably tricky to convert this to not use mocks, we can probably create a separate integration test file just for the rollback test.", "bodyHTML": "<p dir=\"auto\">I don't think it's possible to truly test database rollback with mocks. Since it's probably tricky to convert this to not use mocks, we can probably create a separate integration test file just for the rollback test.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:16:28Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -188,47 +166,63 @@ void bypassHashMismatch() throws Exception {\n         // given\n         parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n         when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n-        fileCopier.copy();\n \n         // when\n-        recordFileParser.parse();\n+        recordFileParser.parse(streamFileData1);\n \n         // then\n-        assertAllProcessed();\n+        verify(recordStreamFileListener, never()).onError();\n+        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() throws Exception {\n+    void failureProcessingItemShouldRollback() {\n         // given\n-        fileCopier.copy();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        recordFileParser.parse();\n+        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n+            recordFileParser.parse(streamFileData1);\n+        });\n \n         // then\n-        assertValidFiles();\n+        verify(recordStreamFileListener).onStart(streamFileData1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n         verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n-    void skipFileOnDuplicateFileException() throws Exception {\n+    void skipFileOnDuplicateFileException() {\n         // given\n-        fileCopier.copy();\n-        String fileName = file1.toString();\n-        recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+        recordFileParser.parse(streamFileData1);\n         doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n \n         // when: load same file again\n         // then: throws exception\n         Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+            recordFileParser.parse(streamFileData1);\n         });\n         verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n         verify(recordStreamFileListener, times(2)).onStart(any());\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n+    @Test\n+    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n+        // given\n+        String fileName = file1.toString();\n+        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3Njc1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676751", "bodyText": "Working on integration test.  Parse method makes it a bit tricky to force an error after commit to I'm having to at last mock the applicationStatus Repository call for such a test.", "author": "Nana-EC", "createdAt": "2020-08-10T03:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3MjE5MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468172190", "bodyText": "Proving difficult to get a test that captures this.\nMaybe it's sufficient to rely on @transactional functioning correctly based on our configuration.\nI did update RecordFilePrser to use the spring version so we could get coverage for the RunTimeExceptions which are not caught and therefore don't force a rollback when the base @transactional is used.", "author": "Nana-EC", "createdAt": "2020-08-10T20:38:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTY1MzYzOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r469653639", "bodyText": "Added a rollback test to the RecordFileParserIntegrationTest.\nMore importantly verified against a local running parser that the rollback works for both pgcopy and prepared statement produced inserts", "author": "Nana-EC", "createdAt": "2020-08-13T02:03:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex ab3f2e8ce..cf76749fa 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -191,38 +190,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n-    @Test\n-    void skipFileOnDuplicateFileException() {\n-        // given\n-        recordFileParser.parse(streamFileData1);\n-        doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n-\n-        // when: load same file again\n-        // then: throws exception\n-        Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n-        verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n-        verify(recordStreamFileListener, times(2)).onStart(any());\n-        verify(recordStreamFileListener, times(1)).onEnd(any());\n-    }\n-\n-    @Test\n-    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n-        // given\n-        String fileName = file1.toString();\n-        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n-\n-        // when\n-        Assertions.assertThrows(ParserSQLException.class, () -> {\n-            recordFileParser.parse(streamFileData2);\n-        });\n-\n-        // then\n-        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);\n-        verify(recordStreamFileListener).onError();\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex cf76749fa..6a6a8b292 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -190,6 +235,60 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n+    @ParameterizedTest(name = \"parse with endDate set to {0}ns after the {1}th transaction\")\n+    @CsvSource(value = {\n+            \"-1, 0\",\n+            \" 0, 0\",\n+            \" 1, 0\",\n+            \"-1, 19\",\n+            \" 0, 19\",\n+            \" 1, 19\"\n+    })\n+    void parseWithEndDate(long nanos, int index) throws Exception {\n+        // given\n+        long end = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        DateRangeFilter filter = new DateRangeFilter(Instant.EPOCH, Instant.ofEpochSecond(0, end));\n+        doReturn(filter)\n+                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n+        fileCopier.copy();\n+        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n+                .thenReturn(recordFile1.getFileHash());\n+\n+        // when\n+        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(streamFileData2);\n+\n+        // then\n+        assertAllProcessed(filter);\n+    }\n+\n+    @ParameterizedTest(name = \"parse with startDate set to {0}ns after the {1}th transaction\")\n+    @CsvSource(value = {\n+            \"-1, 0\",\n+            \" 0, 0\",\n+            \" 1, 0\",\n+            \"-1, 19\",\n+            \" 0, 19\",\n+            \" 1, 19\"\n+    })\n+    void parseWithStartDate(long nanos, int index) throws Exception {\n+        // given\n+        long start = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        DateRangeFilter filter = new DateRangeFilter(Instant.ofEpochSecond(0, start), null);\n+        doReturn(filter)\n+                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n+        fileCopier.copy();\n+        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n+                .thenReturn(recordFile1.getFileHash());\n+\n+        // when\n+        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(streamFileData2);\n+\n+        // then\n+        assertAllProcessed(filter);\n+    }\n+\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 6a6a8b292..c4c4d81bf 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -47,289 +45,220 @@ import org.junit.jupiter.api.extension.ExtendWith;\n import org.junit.jupiter.api.io.TempDir;\n import org.junit.jupiter.params.ParameterizedTest;\n import org.junit.jupiter.params.provider.CsvSource;\n-import org.mockito.ArgumentCaptor;\n import org.mockito.Mock;\n import org.mockito.junit.jupiter.MockitoExtension;\n \n-import com.hedera.mirror.importer.FileCopier;\n import com.hedera.mirror.importer.MirrorProperties;\n import com.hedera.mirror.importer.config.MirrorDateRangePropertiesProcessor;\n+import com.hedera.mirror.importer.config.MirrorDateRangePropertiesProcessor.DateRangeFilter;\n+import com.hedera.mirror.importer.domain.DigestAlgorithm;\n+import com.hedera.mirror.importer.domain.EntityId;\n+import com.hedera.mirror.importer.domain.EntityTypeEnum;\n import com.hedera.mirror.importer.domain.RecordFile;\n-import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.exception.ImporterException;\n import com.hedera.mirror.importer.exception.ParserSQLException;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-import com.hedera.mirror.importer.repository.ApplicationStatusRepository;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+import com.hedera.mirror.importer.util.Utility;\n \n @ExtendWith(MockitoExtension.class)\n-public class RecordFileParserTest {\n+class RecordFileParserTest {\n \n     @TempDir\n-    Path dataPath;\n-    @Mock\n-    private ApplicationStatusRepository applicationStatusRepository;\n+    Path dataDir;\n+\n     @Mock\n     private RecordItemListener recordItemListener;\n-    @Mock\n+\n+    @Mock(lenient = true)\n     private RecordStreamFileListener recordStreamFileListener;\n+\n     @Mock\n     private MirrorDateRangePropertiesProcessor mirrorDateRangePropertiesProcessor;\n \n-    private MirrorProperties mirrorProperties;\n-    private FileCopier fileCopier;\n     private RecordFileParser recordFileParser;\n     private RecordParserProperties parserProperties;\n-\n-    private File file1;\n-    private File file2;\n-    private static final int NUM_TXNS_FILE_1 = 19;\n-    private static final long[] FILE_CONSENSUS_TIMESTAMPS = {\n-            1567188600419072000L,\n-            1567188600762801000L,\n-            1567188600883799000L,\n-            1567188600963103000L,\n-            1567188601371995000L,\n-            1567188601739500000L,\n-            1567188602108299000L,\n-            1567188602118673001L,\n-            1567188602450554001L,\n-            1567188602838615000L,\n-            1567188603175332000L,\n-            1567188603277507000L,\n-            1567188603609988000L,\n-            1567188603706753001L,\n-            1567188604084005000L,\n-            1567188604429968000L,\n-            1567188604524835000L,\n-            1567188604856082001L,\n-            1567188604906443001L,\n-            1567188605249678000L,\n-            1567188605824917000L,\n-            1567188606171654000L,\n-            1567188606181740000L,\n-            1567188606499404000L,\n-            1567188606576024000L,\n-            1567188606932283000L,\n-            1567188607246509000L,\n-            1567188608065015001L,\n-            1567188608413240000L,\n-            1567188608566437000L,\n-            1567188608878373000L,\n-            1567188608972069001L,\n-            1567188609337810002L,\n-            1567188609705382001L\n-    };\n-\n-    private static RecordFile recordFile1;\n-    private static RecordFile recordFile2;\n-    private static StreamFileData streamFileData1;\n-    private static StreamFileData streamFileData2;\n+    private long count = 0;\n \n     @BeforeEach\n-    void before() throws FileNotFoundException {\n-        mirrorProperties = new MirrorProperties();\n-        mirrorProperties.setDataPath(dataPath);\n+    void before() {\n+        MirrorProperties mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataDir);\n         parserProperties = new RecordParserProperties(mirrorProperties);\n-        parserProperties.setKeepFiles(false);\n-        parserProperties.init();\n-        recordFileParser = new RecordFileParser(applicationStatusRepository, parserProperties, new SimpleMeterRegistry(),\n+\n+        recordFileParser = new RecordFileParser(parserProperties, new SimpleMeterRegistry(),\n                 recordItemListener, recordStreamFileListener, mirrorDateRangePropertiesProcessor);\n-        StreamType streamType = StreamType.RECORD;\n-        fileCopier = FileCopier\n-                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n-                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n-                .filterFiles(\"*.rcd\");\n-\n-        fileCopier.copy();\n-        file1 = dataPath.resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n-        file2 = dataPath.resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n-                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n-                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n-\n-        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n-                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n-                recordFile1.getFileHash(), 2);\n-\n-        streamFileData1 = new StreamFileData(file1.toString(), new FileInputStream(file1));\n-        streamFileData2 = new StreamFileData(file2.toString(), new FileInputStream(file2));\n     }\n \n     @Test\n     void parse() throws Exception {\n         // given\n-        parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash(), recordFile2.getFileHash());\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n-\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n         verify(recordStreamFileListener, never()).onError();\n-        assertAllProcessed();\n+        assertFilesArchived();\n+        assertThat(recordFile.getBytes()).isNull();\n     }\n \n     @Test\n-    void invalidFile() throws Exception {\n+    void disabled() throws Exception {\n         // given\n-        FileUtils.writeStringToFile(file1, \"corrupt\", \"UTF-8\");\n-        streamFileData1 = new StreamFileData(file1.toString(), new FileInputStream(file1));\n+        parserProperties.setEnabled(false);\n+        parserProperties.setKeepFiles(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n-        verify(recordStreamFileListener).onError();\n+        verify(recordStreamFileListener, never()).onStart();\n+        assertFilesArchived();\n     }\n \n     @Test\n-    void hashMismatch() {\n+    void persistBytes() throws Exception {\n         // given\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n+        parserProperties.setPersistBytes(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(any());\n-        verify(recordStreamFileListener).onError();\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n+        verify(recordStreamFileListener, never()).onError();\n+        assertThat(recordFile.getBytes()).isNotNull();\n     }\n \n     @Test\n-    void bypassHashMismatch() throws Exception {\n+    void keepFiles() throws Exception {\n         // given\n-        parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n+        parserProperties.setKeepFiles(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(recordFile);\n \n         // then\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n         verify(recordStreamFileListener, never()).onError();\n-        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n+        assertFilesArchived(recordFile.getName());\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() {\n+    void failureShouldRollback() throws Exception {\n         // given\n+        RecordFile recordFile = recordFile();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n+        Assertions.assertThrows(ImporterException.class, () -> {\n+            recordFileParser.parse(recordFile);\n         });\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile);\n         verify(recordStreamFileListener).onError();\n+        assertFilesArchived();\n     }\n \n-    @ParameterizedTest(name = \"parse with endDate set to {0}ns after the {1}th transaction\")\n-    @CsvSource(value = {\n-            \"-1, 0\",\n-            \" 0, 0\",\n-            \" 1, 0\",\n-            \"-1, 19\",\n-            \" 0, 19\",\n-            \" 1, 19\"\n-    })\n-    void parseWithEndDate(long nanos, int index) throws Exception {\n+    @ParameterizedTest(name = \"endDate with offset {0}ns\")\n+    @CsvSource({\"-1\", \"0\", \"1\"})\n+    void endDate(long offset) {\n         // given\n-        long end = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        RecordFile recordFile = recordFile();\n+        long end = recordFile.getConsensusStart() + offset;\n         DateRangeFilter filter = new DateRangeFilter(Instant.EPOCH, Instant.ofEpochSecond(0, end));\n-        doReturn(filter)\n-                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n-        fileCopier.copy();\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash());\n+        doReturn(filter).when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        assertAllProcessed(filter);\n+        verify(recordStreamFileListener).onStart();\n+        if (offset >= 0) {\n+            verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        }\n+        verify(recordStreamFileListener).onEnd(recordFile);\n     }\n \n-    @ParameterizedTest(name = \"parse with startDate set to {0}ns after the {1}th transaction\")\n-    @CsvSource(value = {\n-            \"-1, 0\",\n-            \" 0, 0\",\n-            \" 1, 0\",\n-            \"-1, 19\",\n-            \" 0, 19\",\n-            \" 1, 19\"\n-    })\n-    void parseWithStartDate(long nanos, int index) throws Exception {\n+    @ParameterizedTest(name = \"startDate with offset {0}ns\")\n+    @CsvSource({\"-1\", \"0\", \"1\"})\n+    void startDate(long offset) {\n         // given\n-        long start = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        RecordFile recordFile = recordFile();\n+        long start = recordFile.getConsensusStart() + offset;\n         DateRangeFilter filter = new DateRangeFilter(Instant.ofEpochSecond(0, start), null);\n-        doReturn(filter)\n-                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n-        fileCopier.copy();\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash());\n+        doReturn(filter).when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        assertAllProcessed(filter);\n-    }\n-\n-    // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n-    private void assertOnStart(String... fileNames) {\n-        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n-        verify(recordStreamFileListener, times(fileNames.length)).onStart(captor.capture());\n-        List<StreamFileData> actualArgs = captor.getAllValues();\n-        assertThat(actualArgs)\n-                .extracting(StreamFileData::getFilename)\n-                .contains(fileNames);\n-    }\n-\n-    // Asserts that recordStreamFileListener.onEnd is called exactly with given recordFiles (ignoring load start and end\n-    //times), in given order\n-    private void assertOnEnd(RecordFile... recordFiles) {\n-        ArgumentCaptor<RecordFile> captor = ArgumentCaptor.forClass(RecordFile.class);\n-        verify(recordStreamFileListener, times(recordFiles.length)).onEnd(captor.capture());\n-        List<RecordFile> actualArgs = captor.getAllValues();\n-        for (int i = 0; i < recordFiles.length; i++) {\n-            RecordFile actual = actualArgs.get(i);\n-            RecordFile expected = recordFiles[i];\n-            assertThat(actual).isEqualToIgnoringGivenFields(expected, \"id\", \"loadEnd\", \"loadStart\", \"recordItems\");\n+        verify(recordStreamFileListener).onStart();\n+        if (offset < 0) {\n+            verify(recordItemListener).onItem(recordFile.getItems().get(0));\n         }\n+        verify(recordStreamFileListener).onEnd(recordFile);\n     }\n \n-    private void assertProcessedFile(StreamFileData streamFileData, RecordFile recordFile, int numTransactions) throws Exception {\n-        // assert mock interactions\n-        verify(recordItemListener, times(numTransactions)).onItem(any());\n-        assertOnStart(streamFileData.getFilename());\n-        assertOnEnd(recordFile);\n+    // Asserts that parsed directory contains exactly the files with given fileNames\n+    private void assertFilesArchived(String... fileNames) throws Exception {\n+        if (fileNames == null || fileNames.length == 0) {\n+            assertThat(parserProperties.getParsedPath()).doesNotExist();\n+            return;\n+        }\n+        assertThat(Files.walk(parserProperties.getParsedPath()))\n+                .filteredOn(p -> !p.toFile().isDirectory())\n+                .hasSize(fileNames.length)\n+                .extracting(Path::getFileName)\n+                .extracting(Path::toString)\n+                .contains(fileNames);\n     }\n \n-    private void assertAllProcessed() throws Exception {\n-        assertAllProcessed(null);\n+    private RecordFile recordFile() {\n+        long id = ++count;\n+        Instant instant = Instant.ofEpochSecond(0L, id);\n+        String filename = Utility.getStreamFilenameFromInstant(parserProperties.getStreamType(), instant);\n+        RecordFile recordFile = new RecordFile();\n+        recordFile.setBytes(new byte[] {0, 1, 2});\n+        recordFile.setConsensusEnd(id);\n+        recordFile.setConsensusStart(id);\n+        recordFile.setConsensusEnd(id);\n+        recordFile.setCount(id);\n+        recordFile.setDigestAlgorithm(DigestAlgorithm.SHA384);\n+        recordFile.setFileHash(\"fileHash\" + id);\n+        recordFile.setHash(\"hash\" + id);\n+        recordFile.setLoadEnd(id);\n+        recordFile.setLoadStart(id);\n+        recordFile.setName(filename);\n+        recordFile.setNodeAccountId(EntityId.of(\"0.0.3\", EntityTypeEnum.ACCOUNT));\n+        recordFile.setPreviousHash(\"previousHash\" + (id - 1));\n+        recordFile.setVersion(1);\n+        recordFile.getItems().add(recordItem(id));\n+        return recordFile;\n     }\n \n-    private void assertAllProcessed(DateRangeFilter dateRangeFilter) throws Exception {\n-        // assert mock interactions\n-        int expectedNumTxns = (int)Arrays.stream(FILE_CONSENSUS_TIMESTAMPS)\n-                .filter(ts -> dateRangeFilter == null || dateRangeFilter.filter(ts)).count();\n-\n-        verify(recordItemListener, times(expectedNumTxns)).onItem(any());\n-        assertOnStart(streamFileData1.getFilename(), streamFileData2.getFilename());\n-        assertOnEnd(recordFile1, recordFile2);\n+    private RecordItem recordItem(long timestamp) {\n+        CryptoTransferTransactionBody cryptoTransfer = CryptoTransferTransactionBody.newBuilder().build();\n+        TransactionBody transactionBody = TransactionBody.newBuilder().setCryptoTransfer(cryptoTransfer).build();\n+        SignedTransaction signedTransaction = SignedTransaction.newBuilder()\n+                .setBodyBytes(transactionBody.toByteString())\n+                .setSigMap(SignatureMap.newBuilder().build())\n+                .build();\n+        Transaction transaction = Transaction.newBuilder()\n+                .setSignedTransactionBytes(signedTransaction.toByteString())\n+                .build();\n+        TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n+                .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+                .build();\n+        return new RecordItem(transaction.toByteArray(), transactionRecord.toByteArray());\n     }\n }\n", "next_change": {"commit": "627531943097f9c37ed087518790afbed92d1e65", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex c4c4d81bf..c198feeab 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -259,6 +201,6 @@ class RecordFileParserTest {\n         TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n                 .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n                 .build();\n-        return new RecordItem(transaction.toByteArray(), transactionRecord.toByteArray());\n+        return new RecordItem(transaction, transactionRecord);\n     }\n }\n", "next_change": {"commit": "064e4d6687bccad391f48d60156c651777caabbf", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex c198feeab..6faf94898 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -198,9 +260,31 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n         Transaction transaction = Transaction.newBuilder()\n                 .setSignedTransactionBytes(signedTransaction.toByteString())\n                 .build();\n-        TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n-                .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+        return RecordItem.builder()\n+                .record(transactionRecord)\n+                .transactionBytes(transaction.toByteArray())\n+                .build();\n+    }\n+\n+    private RecordItem ethereumTransaction(ContractFunctionResult contractFunctionResult, long timestamp,\n+            int transactionIdNonce) {\n+        return recordItemBuilder\n+                .ethereumTransaction(true)\n+                .record(builder -> builder.setContractCallResult(contractFunctionResult)\n+                        .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+                        .setTransactionID(TransactionID.newBuilder().setNonce(transactionIdNonce).build())\n+                )\n                 .build();\n-        return new RecordItem(transaction, transactionRecord);\n+    }\n+\n+    private RecordFile getStreamFile(final Flux<RecordItem> items, final long timestamp) {\n+        return domainBuilder\n+                .recordFile()\n+                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] { 0, 1, 2 })\n+                        .consensusEnd(timestamp)\n+                        .consensusStart(timestamp)\n+                        .items(items)\n+                )\n+                .get();\n     }\n }\n", "next_change": {"commit": "29de773a595e26507d772e92061bf63225447db3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 6faf94898..b28ed86e0 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -280,9 +280,10 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n     private RecordFile getStreamFile(final Flux<RecordItem> items, final long timestamp) {\n         return domainBuilder\n                 .recordFile()\n-                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] { 0, 1, 2 })\n+                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] {0, 1, 2})\n                         .consensusEnd(timestamp)\n                         .consensusStart(timestamp)\n+                        .gasUsed(0L)\n                         .items(items)\n                 )\n                 .get();\n", "next_change": {"commit": "79a9fb94bb82b4b46d25651f91314bdae5c0ccb1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex b28ed86e0..118392977 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -281,7 +398,7 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n         return domainBuilder\n                 .recordFile()\n                 .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] {0, 1, 2})\n-                        .consensusEnd(timestamp)\n+                        .consensusEnd(timestamp+1)\n                         .consensusStart(timestamp)\n                         .gasUsed(0L)\n                         .items(items)\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA3MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467138071", "body": "There should be nothing processed, right? This test is suspect.", "bodyText": "There should be nothing processed, right? This test is suspect.", "bodyHTML": "<p dir=\"auto\">There should be nothing processed, right? This test is suspect.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:16:30Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -188,47 +166,63 @@ void bypassHashMismatch() throws Exception {\n         // given\n         parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n         when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n-        fileCopier.copy();\n \n         // when\n-        recordFileParser.parse();\n+        recordFileParser.parse(streamFileData1);\n \n         // then\n-        assertAllProcessed();\n+        verify(recordStreamFileListener, never()).onError();\n+        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() throws Exception {\n+    void failureProcessingItemShouldRollback() {\n         // given\n-        fileCopier.copy();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        recordFileParser.parse();\n+        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n+            recordFileParser.parse(streamFileData1);\n+        });\n \n         // then\n-        assertValidFiles();\n+        verify(recordStreamFileListener).onStart(streamFileData1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n         verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n-    void skipFileOnDuplicateFileException() throws Exception {\n+    void skipFileOnDuplicateFileException() {\n         // given\n-        fileCopier.copy();\n-        String fileName = file1.toString();\n-        recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+        recordFileParser.parse(streamFileData1);\n         doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n \n         // when: load same file again\n         // then: throws exception\n         Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+            recordFileParser.parse(streamFileData1);\n         });\n         verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n         verify(recordStreamFileListener, times(2)).onStart(any());\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n+    @Test\n+    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n+        // given\n+        String fileName = file1.toString();\n+        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n+\n+        // when\n+        Assertions.assertThrows(ParserSQLException.class, () -> {\n+            recordFileParser.parse(streamFileData2);\n+        });\n+\n+        // then\n+        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NzU4OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467677589", "bodyText": "Actually in this test everything would have been processed as expected, expect after persistence but before file complete an error occurred.\nTest is removed though", "author": "Nana-EC", "createdAt": "2020-08-10T03:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex ab3f2e8ce..cf76749fa 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -191,38 +190,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n-    @Test\n-    void skipFileOnDuplicateFileException() {\n-        // given\n-        recordFileParser.parse(streamFileData1);\n-        doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n-\n-        // when: load same file again\n-        // then: throws exception\n-        Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n-        verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n-        verify(recordStreamFileListener, times(2)).onStart(any());\n-        verify(recordStreamFileListener, times(1)).onEnd(any());\n-    }\n-\n-    @Test\n-    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n-        // given\n-        String fileName = file1.toString();\n-        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n-\n-        // when\n-        Assertions.assertThrows(ParserSQLException.class, () -> {\n-            recordFileParser.parse(streamFileData2);\n-        });\n-\n-        // then\n-        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);\n-        verify(recordStreamFileListener).onError();\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex cf76749fa..6a6a8b292 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -190,6 +235,60 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n+    @ParameterizedTest(name = \"parse with endDate set to {0}ns after the {1}th transaction\")\n+    @CsvSource(value = {\n+            \"-1, 0\",\n+            \" 0, 0\",\n+            \" 1, 0\",\n+            \"-1, 19\",\n+            \" 0, 19\",\n+            \" 1, 19\"\n+    })\n+    void parseWithEndDate(long nanos, int index) throws Exception {\n+        // given\n+        long end = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        DateRangeFilter filter = new DateRangeFilter(Instant.EPOCH, Instant.ofEpochSecond(0, end));\n+        doReturn(filter)\n+                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n+        fileCopier.copy();\n+        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n+                .thenReturn(recordFile1.getFileHash());\n+\n+        // when\n+        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(streamFileData2);\n+\n+        // then\n+        assertAllProcessed(filter);\n+    }\n+\n+    @ParameterizedTest(name = \"parse with startDate set to {0}ns after the {1}th transaction\")\n+    @CsvSource(value = {\n+            \"-1, 0\",\n+            \" 0, 0\",\n+            \" 1, 0\",\n+            \"-1, 19\",\n+            \" 0, 19\",\n+            \" 1, 19\"\n+    })\n+    void parseWithStartDate(long nanos, int index) throws Exception {\n+        // given\n+        long start = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        DateRangeFilter filter = new DateRangeFilter(Instant.ofEpochSecond(0, start), null);\n+        doReturn(filter)\n+                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n+        fileCopier.copy();\n+        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n+                .thenReturn(recordFile1.getFileHash());\n+\n+        // when\n+        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(streamFileData2);\n+\n+        // then\n+        assertAllProcessed(filter);\n+    }\n+\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 6a6a8b292..c4c4d81bf 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -47,289 +45,220 @@ import org.junit.jupiter.api.extension.ExtendWith;\n import org.junit.jupiter.api.io.TempDir;\n import org.junit.jupiter.params.ParameterizedTest;\n import org.junit.jupiter.params.provider.CsvSource;\n-import org.mockito.ArgumentCaptor;\n import org.mockito.Mock;\n import org.mockito.junit.jupiter.MockitoExtension;\n \n-import com.hedera.mirror.importer.FileCopier;\n import com.hedera.mirror.importer.MirrorProperties;\n import com.hedera.mirror.importer.config.MirrorDateRangePropertiesProcessor;\n+import com.hedera.mirror.importer.config.MirrorDateRangePropertiesProcessor.DateRangeFilter;\n+import com.hedera.mirror.importer.domain.DigestAlgorithm;\n+import com.hedera.mirror.importer.domain.EntityId;\n+import com.hedera.mirror.importer.domain.EntityTypeEnum;\n import com.hedera.mirror.importer.domain.RecordFile;\n-import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.exception.ImporterException;\n import com.hedera.mirror.importer.exception.ParserSQLException;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-import com.hedera.mirror.importer.repository.ApplicationStatusRepository;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+import com.hedera.mirror.importer.util.Utility;\n \n @ExtendWith(MockitoExtension.class)\n-public class RecordFileParserTest {\n+class RecordFileParserTest {\n \n     @TempDir\n-    Path dataPath;\n-    @Mock\n-    private ApplicationStatusRepository applicationStatusRepository;\n+    Path dataDir;\n+\n     @Mock\n     private RecordItemListener recordItemListener;\n-    @Mock\n+\n+    @Mock(lenient = true)\n     private RecordStreamFileListener recordStreamFileListener;\n+\n     @Mock\n     private MirrorDateRangePropertiesProcessor mirrorDateRangePropertiesProcessor;\n \n-    private MirrorProperties mirrorProperties;\n-    private FileCopier fileCopier;\n     private RecordFileParser recordFileParser;\n     private RecordParserProperties parserProperties;\n-\n-    private File file1;\n-    private File file2;\n-    private static final int NUM_TXNS_FILE_1 = 19;\n-    private static final long[] FILE_CONSENSUS_TIMESTAMPS = {\n-            1567188600419072000L,\n-            1567188600762801000L,\n-            1567188600883799000L,\n-            1567188600963103000L,\n-            1567188601371995000L,\n-            1567188601739500000L,\n-            1567188602108299000L,\n-            1567188602118673001L,\n-            1567188602450554001L,\n-            1567188602838615000L,\n-            1567188603175332000L,\n-            1567188603277507000L,\n-            1567188603609988000L,\n-            1567188603706753001L,\n-            1567188604084005000L,\n-            1567188604429968000L,\n-            1567188604524835000L,\n-            1567188604856082001L,\n-            1567188604906443001L,\n-            1567188605249678000L,\n-            1567188605824917000L,\n-            1567188606171654000L,\n-            1567188606181740000L,\n-            1567188606499404000L,\n-            1567188606576024000L,\n-            1567188606932283000L,\n-            1567188607246509000L,\n-            1567188608065015001L,\n-            1567188608413240000L,\n-            1567188608566437000L,\n-            1567188608878373000L,\n-            1567188608972069001L,\n-            1567188609337810002L,\n-            1567188609705382001L\n-    };\n-\n-    private static RecordFile recordFile1;\n-    private static RecordFile recordFile2;\n-    private static StreamFileData streamFileData1;\n-    private static StreamFileData streamFileData2;\n+    private long count = 0;\n \n     @BeforeEach\n-    void before() throws FileNotFoundException {\n-        mirrorProperties = new MirrorProperties();\n-        mirrorProperties.setDataPath(dataPath);\n+    void before() {\n+        MirrorProperties mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataDir);\n         parserProperties = new RecordParserProperties(mirrorProperties);\n-        parserProperties.setKeepFiles(false);\n-        parserProperties.init();\n-        recordFileParser = new RecordFileParser(applicationStatusRepository, parserProperties, new SimpleMeterRegistry(),\n+\n+        recordFileParser = new RecordFileParser(parserProperties, new SimpleMeterRegistry(),\n                 recordItemListener, recordStreamFileListener, mirrorDateRangePropertiesProcessor);\n-        StreamType streamType = StreamType.RECORD;\n-        fileCopier = FileCopier\n-                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n-                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n-                .filterFiles(\"*.rcd\");\n-\n-        fileCopier.copy();\n-        file1 = dataPath.resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n-        file2 = dataPath.resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n-                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n-                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n-\n-        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n-                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n-                recordFile1.getFileHash(), 2);\n-\n-        streamFileData1 = new StreamFileData(file1.toString(), new FileInputStream(file1));\n-        streamFileData2 = new StreamFileData(file2.toString(), new FileInputStream(file2));\n     }\n \n     @Test\n     void parse() throws Exception {\n         // given\n-        parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash(), recordFile2.getFileHash());\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n-\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n         verify(recordStreamFileListener, never()).onError();\n-        assertAllProcessed();\n+        assertFilesArchived();\n+        assertThat(recordFile.getBytes()).isNull();\n     }\n \n     @Test\n-    void invalidFile() throws Exception {\n+    void disabled() throws Exception {\n         // given\n-        FileUtils.writeStringToFile(file1, \"corrupt\", \"UTF-8\");\n-        streamFileData1 = new StreamFileData(file1.toString(), new FileInputStream(file1));\n+        parserProperties.setEnabled(false);\n+        parserProperties.setKeepFiles(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n-        verify(recordStreamFileListener).onError();\n+        verify(recordStreamFileListener, never()).onStart();\n+        assertFilesArchived();\n     }\n \n     @Test\n-    void hashMismatch() {\n+    void persistBytes() throws Exception {\n         // given\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n+        parserProperties.setPersistBytes(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(any());\n-        verify(recordStreamFileListener).onError();\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n+        verify(recordStreamFileListener, never()).onError();\n+        assertThat(recordFile.getBytes()).isNotNull();\n     }\n \n     @Test\n-    void bypassHashMismatch() throws Exception {\n+    void keepFiles() throws Exception {\n         // given\n-        parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n+        parserProperties.setKeepFiles(true);\n+        RecordFile recordFile = recordFile();\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n+        recordFileParser.parse(recordFile);\n \n         // then\n+        verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        verify(recordStreamFileListener).onEnd(recordFile);\n         verify(recordStreamFileListener, never()).onError();\n-        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n+        assertFilesArchived(recordFile.getName());\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() {\n+    void failureShouldRollback() throws Exception {\n         // given\n+        RecordFile recordFile = recordFile();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n+        Assertions.assertThrows(ImporterException.class, () -> {\n+            recordFileParser.parse(recordFile);\n         });\n \n         // then\n-        verify(recordStreamFileListener).onStart(streamFileData1);\n-        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile);\n         verify(recordStreamFileListener).onError();\n+        assertFilesArchived();\n     }\n \n-    @ParameterizedTest(name = \"parse with endDate set to {0}ns after the {1}th transaction\")\n-    @CsvSource(value = {\n-            \"-1, 0\",\n-            \" 0, 0\",\n-            \" 1, 0\",\n-            \"-1, 19\",\n-            \" 0, 19\",\n-            \" 1, 19\"\n-    })\n-    void parseWithEndDate(long nanos, int index) throws Exception {\n+    @ParameterizedTest(name = \"endDate with offset {0}ns\")\n+    @CsvSource({\"-1\", \"0\", \"1\"})\n+    void endDate(long offset) {\n         // given\n-        long end = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        RecordFile recordFile = recordFile();\n+        long end = recordFile.getConsensusStart() + offset;\n         DateRangeFilter filter = new DateRangeFilter(Instant.EPOCH, Instant.ofEpochSecond(0, end));\n-        doReturn(filter)\n-                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n-        fileCopier.copy();\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash());\n+        doReturn(filter).when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        assertAllProcessed(filter);\n+        verify(recordStreamFileListener).onStart();\n+        if (offset >= 0) {\n+            verify(recordItemListener).onItem(recordFile.getItems().get(0));\n+        }\n+        verify(recordStreamFileListener).onEnd(recordFile);\n     }\n \n-    @ParameterizedTest(name = \"parse with startDate set to {0}ns after the {1}th transaction\")\n-    @CsvSource(value = {\n-            \"-1, 0\",\n-            \" 0, 0\",\n-            \" 1, 0\",\n-            \"-1, 19\",\n-            \" 0, 19\",\n-            \" 1, 19\"\n-    })\n-    void parseWithStartDate(long nanos, int index) throws Exception {\n+    @ParameterizedTest(name = \"startDate with offset {0}ns\")\n+    @CsvSource({\"-1\", \"0\", \"1\"})\n+    void startDate(long offset) {\n         // given\n-        long start = FILE_CONSENSUS_TIMESTAMPS[index] + nanos;\n+        RecordFile recordFile = recordFile();\n+        long start = recordFile.getConsensusStart() + offset;\n         DateRangeFilter filter = new DateRangeFilter(Instant.ofEpochSecond(0, start), null);\n-        doReturn(filter)\n-                .when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n-        fileCopier.copy();\n-        when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"\")\n-                .thenReturn(recordFile1.getFileHash());\n+        doReturn(filter).when(mirrorDateRangePropertiesProcessor).getDateRangeFilter(parserProperties.getStreamType());\n \n         // when\n-        recordFileParser.parse(streamFileData1);\n-        recordFileParser.parse(streamFileData2);\n+        recordFileParser.parse(recordFile);\n \n         // then\n-        assertAllProcessed(filter);\n-    }\n-\n-    // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n-    private void assertOnStart(String... fileNames) {\n-        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n-        verify(recordStreamFileListener, times(fileNames.length)).onStart(captor.capture());\n-        List<StreamFileData> actualArgs = captor.getAllValues();\n-        assertThat(actualArgs)\n-                .extracting(StreamFileData::getFilename)\n-                .contains(fileNames);\n-    }\n-\n-    // Asserts that recordStreamFileListener.onEnd is called exactly with given recordFiles (ignoring load start and end\n-    //times), in given order\n-    private void assertOnEnd(RecordFile... recordFiles) {\n-        ArgumentCaptor<RecordFile> captor = ArgumentCaptor.forClass(RecordFile.class);\n-        verify(recordStreamFileListener, times(recordFiles.length)).onEnd(captor.capture());\n-        List<RecordFile> actualArgs = captor.getAllValues();\n-        for (int i = 0; i < recordFiles.length; i++) {\n-            RecordFile actual = actualArgs.get(i);\n-            RecordFile expected = recordFiles[i];\n-            assertThat(actual).isEqualToIgnoringGivenFields(expected, \"id\", \"loadEnd\", \"loadStart\", \"recordItems\");\n+        verify(recordStreamFileListener).onStart();\n+        if (offset < 0) {\n+            verify(recordItemListener).onItem(recordFile.getItems().get(0));\n         }\n+        verify(recordStreamFileListener).onEnd(recordFile);\n     }\n \n-    private void assertProcessedFile(StreamFileData streamFileData, RecordFile recordFile, int numTransactions) throws Exception {\n-        // assert mock interactions\n-        verify(recordItemListener, times(numTransactions)).onItem(any());\n-        assertOnStart(streamFileData.getFilename());\n-        assertOnEnd(recordFile);\n+    // Asserts that parsed directory contains exactly the files with given fileNames\n+    private void assertFilesArchived(String... fileNames) throws Exception {\n+        if (fileNames == null || fileNames.length == 0) {\n+            assertThat(parserProperties.getParsedPath()).doesNotExist();\n+            return;\n+        }\n+        assertThat(Files.walk(parserProperties.getParsedPath()))\n+                .filteredOn(p -> !p.toFile().isDirectory())\n+                .hasSize(fileNames.length)\n+                .extracting(Path::getFileName)\n+                .extracting(Path::toString)\n+                .contains(fileNames);\n     }\n \n-    private void assertAllProcessed() throws Exception {\n-        assertAllProcessed(null);\n+    private RecordFile recordFile() {\n+        long id = ++count;\n+        Instant instant = Instant.ofEpochSecond(0L, id);\n+        String filename = Utility.getStreamFilenameFromInstant(parserProperties.getStreamType(), instant);\n+        RecordFile recordFile = new RecordFile();\n+        recordFile.setBytes(new byte[] {0, 1, 2});\n+        recordFile.setConsensusEnd(id);\n+        recordFile.setConsensusStart(id);\n+        recordFile.setConsensusEnd(id);\n+        recordFile.setCount(id);\n+        recordFile.setDigestAlgorithm(DigestAlgorithm.SHA384);\n+        recordFile.setFileHash(\"fileHash\" + id);\n+        recordFile.setHash(\"hash\" + id);\n+        recordFile.setLoadEnd(id);\n+        recordFile.setLoadStart(id);\n+        recordFile.setName(filename);\n+        recordFile.setNodeAccountId(EntityId.of(\"0.0.3\", EntityTypeEnum.ACCOUNT));\n+        recordFile.setPreviousHash(\"previousHash\" + (id - 1));\n+        recordFile.setVersion(1);\n+        recordFile.getItems().add(recordItem(id));\n+        return recordFile;\n     }\n \n-    private void assertAllProcessed(DateRangeFilter dateRangeFilter) throws Exception {\n-        // assert mock interactions\n-        int expectedNumTxns = (int)Arrays.stream(FILE_CONSENSUS_TIMESTAMPS)\n-                .filter(ts -> dateRangeFilter == null || dateRangeFilter.filter(ts)).count();\n-\n-        verify(recordItemListener, times(expectedNumTxns)).onItem(any());\n-        assertOnStart(streamFileData1.getFilename(), streamFileData2.getFilename());\n-        assertOnEnd(recordFile1, recordFile2);\n+    private RecordItem recordItem(long timestamp) {\n+        CryptoTransferTransactionBody cryptoTransfer = CryptoTransferTransactionBody.newBuilder().build();\n+        TransactionBody transactionBody = TransactionBody.newBuilder().setCryptoTransfer(cryptoTransfer).build();\n+        SignedTransaction signedTransaction = SignedTransaction.newBuilder()\n+                .setBodyBytes(transactionBody.toByteString())\n+                .setSigMap(SignatureMap.newBuilder().build())\n+                .build();\n+        Transaction transaction = Transaction.newBuilder()\n+                .setSignedTransactionBytes(signedTransaction.toByteString())\n+                .build();\n+        TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n+                .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+                .build();\n+        return new RecordItem(transaction.toByteArray(), transactionRecord.toByteArray());\n     }\n }\n", "next_change": {"commit": "627531943097f9c37ed087518790afbed92d1e65", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex c4c4d81bf..c198feeab 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -259,6 +201,6 @@ class RecordFileParserTest {\n         TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n                 .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n                 .build();\n-        return new RecordItem(transaction.toByteArray(), transactionRecord.toByteArray());\n+        return new RecordItem(transaction, transactionRecord);\n     }\n }\n", "next_change": {"commit": "064e4d6687bccad391f48d60156c651777caabbf", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex c198feeab..6faf94898 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -198,9 +260,31 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n         Transaction transaction = Transaction.newBuilder()\n                 .setSignedTransactionBytes(signedTransaction.toByteString())\n                 .build();\n-        TransactionRecord transactionRecord = TransactionRecord.newBuilder()\n-                .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+        return RecordItem.builder()\n+                .record(transactionRecord)\n+                .transactionBytes(transaction.toByteArray())\n+                .build();\n+    }\n+\n+    private RecordItem ethereumTransaction(ContractFunctionResult contractFunctionResult, long timestamp,\n+            int transactionIdNonce) {\n+        return recordItemBuilder\n+                .ethereumTransaction(true)\n+                .record(builder -> builder.setContractCallResult(contractFunctionResult)\n+                        .setConsensusTimestamp(Timestamp.newBuilder().setNanos((int) timestamp))\n+                        .setTransactionID(TransactionID.newBuilder().setNonce(transactionIdNonce).build())\n+                )\n                 .build();\n-        return new RecordItem(transaction, transactionRecord);\n+    }\n+\n+    private RecordFile getStreamFile(final Flux<RecordItem> items, final long timestamp) {\n+        return domainBuilder\n+                .recordFile()\n+                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] { 0, 1, 2 })\n+                        .consensusEnd(timestamp)\n+                        .consensusStart(timestamp)\n+                        .items(items)\n+                )\n+                .get();\n     }\n }\n", "next_change": {"commit": "29de773a595e26507d772e92061bf63225447db3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 6faf94898..b28ed86e0 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -280,9 +280,10 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n     private RecordFile getStreamFile(final Flux<RecordItem> items, final long timestamp) {\n         return domainBuilder\n                 .recordFile()\n-                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] { 0, 1, 2 })\n+                .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] {0, 1, 2})\n                         .consensusEnd(timestamp)\n                         .consensusStart(timestamp)\n+                        .gasUsed(0L)\n                         .items(items)\n                 )\n                 .get();\n", "next_change": {"commit": "79a9fb94bb82b4b46d25651f91314bdae5c0ccb1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex b28ed86e0..118392977 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -281,7 +398,7 @@ class RecordFileParserTest extends AbstractStreamFileParserTest<RecordFileParser\n         return domainBuilder\n                 .recordFile()\n                 .customize(recordFileBuilder -> recordFileBuilder.bytes(new byte[] {0, 1, 2})\n-                        .consensusEnd(timestamp)\n+                        .consensusEnd(timestamp+1)\n                         .consensusStart(timestamp)\n                         .gasUsed(0L)\n                         .items(items)\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODQzNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467138437", "body": "Please add a test for not a directory. Would also be good to check code coverage report and see if any other paths not tested.", "bodyText": "Please add a test for not a directory. Would also be good to check code coverage report and see if any other paths not tested.", "bodyHTML": "<p dir=\"auto\">Please add a test for not a directory. Would also be good to check code coverage report and see if any other paths not tested.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:17:07Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java", "diffHunk": "@@ -0,0 +1,168 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoInteractions;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.List;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.MirrorProperties;\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class RecordFilePollerTest {\n+\n+    @TempDir\n+    Path dataPath;\n+    @Mock\n+    RecordFileParser recordFileParser;\n+    private FileCopier fileCopier;\n+    private RecordFilePoller recordFilePoller;\n+    private RecordParserProperties parserProperties;\n+\n+    private File file1;\n+    private File file2;\n+    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n+    private static final int NUM_TXNS_FILE_1 = 19;\n+    private static final int NUM_TXNS_FILE_2 = 15;\n+    private static RecordFile recordFile1;\n+    private static RecordFile recordFile2;\n+\n+    @BeforeEach\n+    void before() {\n+        var mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataPath);\n+        parserProperties = new RecordParserProperties(mirrorProperties);\n+        parserProperties.setKeepFiles(false);\n+        parserProperties.init();\n+        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n+        StreamType streamType = StreamType.RECORD;\n+        fileCopier = FileCopier\n+                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n+                .filterFiles(\"*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n+        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n+        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n+\n+        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFile1.getFileHash(), 2);\n+    }\n+\n+    @Test\n+    void poll() throws Exception {\n+        // given\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void pollAndKeepFiles() throws Exception {\n+        // given\n+        parserProperties.setKeepFiles(true);\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void noFiles() throws Exception {\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertParsedFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3ODQ3MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467678471", "bodyText": "Added not a directory test. Adding more to increase coverage for Poller.", "author": "Nana-EC", "createdAt": "2020-08-10T04:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODQzNw=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 14c7bb619..8a1529abc 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -120,10 +127,49 @@ public class RecordFilePollerTest {\n         recordFilePoller.poll();\n \n         // then\n-        assertParsedFiles();\n         verifyNoInteractions(recordFileParser);\n     }\n \n+    @Test\n+    void pathNotDirectory() throws Exception {\n+        // when\n+        fileCopier.copy();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+\n+    @Test\n+    void fileNotFoundFromRecordFileParser() {\n+        // given\n+        fileCopier.copy();\n+        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n+        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n+        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n+    @Test\n+    void errorFromRecordFileParser() {\n+        // when\n+        fileCopier.copy();\n+        doThrow(ParserException.class).when(recordFileParser).parse(any());\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n     // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n     private void assertParse(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\ndeleted file mode 100644\nindex 8a1529abc..000000000\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ /dev/null\n", "chunk": "@@ -1,214 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import static org.assertj.core.api.Assertions.assertThat;\n-import static org.junit.Assert.assertFalse;\n-import static org.junit.Assert.assertTrue;\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.doReturn;\n-import static org.mockito.Mockito.doThrow;\n-import static org.mockito.Mockito.times;\n-import static org.mockito.Mockito.verify;\n-import static org.mockito.Mockito.verifyNoInteractions;\n-\n-import java.io.File;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import java.util.List;\n-import org.junit.jupiter.api.BeforeEach;\n-import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import org.junit.jupiter.api.io.TempDir;\n-import org.mockito.ArgumentCaptor;\n-import org.mockito.Mock;\n-import org.mockito.Mockito;\n-import org.mockito.junit.jupiter.MockitoExtension;\n-\n-import com.hedera.mirror.importer.FileCopier;\n-import com.hedera.mirror.importer.MirrorProperties;\n-import com.hedera.mirror.importer.domain.RecordFile;\n-import com.hedera.mirror.importer.domain.StreamType;\n-import com.hedera.mirror.importer.exception.ParserException;\n-import com.hedera.mirror.importer.parser.domain.StreamFileData;\n-\n-@ExtendWith(MockitoExtension.class)\n-public class RecordFilePollerTest {\n-\n-    @TempDir\n-    Path dataPath;\n-    @Mock\n-    RecordFileParser recordFileParser;\n-    private FileCopier fileCopier;\n-    private RecordFilePoller recordFilePoller;\n-    private RecordParserProperties parserProperties;\n-    private MirrorProperties mirrorProperties;\n-\n-    private File file1;\n-    private File file2;\n-    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n-    private static final int NUM_TXNS_FILE_1 = 19;\n-    private static final int NUM_TXNS_FILE_2 = 15;\n-    private static RecordFile recordFile1;\n-    private static RecordFile recordFile2;\n-\n-    @BeforeEach\n-    void before() {\n-        mirrorProperties = new MirrorProperties();\n-        mirrorProperties.setDataPath(dataPath);\n-        parserProperties = new RecordParserProperties(mirrorProperties);\n-        parserProperties.setKeepFiles(false);\n-        parserProperties.init();\n-        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n-        StreamType streamType = StreamType.RECORD;\n-        fileCopier = FileCopier\n-                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n-                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n-                .filterFiles(\"*.rcd\")\n-                .to(streamType.getPath(), streamType.getValid());\n-        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n-        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n-                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n-                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n-\n-        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n-                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n-                recordFile1.getFileHash(), 2);\n-    }\n-\n-    @Test\n-    void poll() throws Exception {\n-        // given\n-        fileCopier.copy();\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertAllProcessed();\n-    }\n-\n-    @Test\n-    void pollAndKeepFiles() throws Exception {\n-        // given\n-        parserProperties.setKeepFiles(true);\n-        fileCopier.copy();\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertAllProcessed();\n-    }\n-\n-    @Test\n-    void noFiles() throws Exception {\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        verifyNoInteractions(recordFileParser);\n-    }\n-\n-    @Test\n-    void pathNotDirectory() throws Exception {\n-        // when\n-        fileCopier.copy();\n-        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-        verifyNoInteractions(recordFileParser);\n-    }\n-\n-    @Test\n-    void fileNotFoundFromRecordFileParser() {\n-        // given\n-        fileCopier.copy();\n-        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n-        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n-        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-    }\n-\n-    @Test\n-    void errorFromRecordFileParser() {\n-        // when\n-        fileCopier.copy();\n-        doThrow(ParserException.class).when(recordFileParser).parse(any());\n-\n-        // when\n-        recordFilePoller.poll();\n-\n-        // then\n-        assertValidFiles();\n-    }\n-\n-    // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n-    private void assertParse(String... fileNames) {\n-        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n-        verify(recordFileParser, times(fileNames.length)).parse(captor.capture());\n-        List<StreamFileData> actualArgs = captor.getAllValues();\n-        assertThat(actualArgs)\n-                .extracting(StreamFileData::getFilename)\n-                .isEqualTo(Arrays.asList(fileNames));\n-    }\n-\n-    // Asserts that parsed directory contains exactly the files with given fileNames\n-    private void assertParsedFiles(String... fileNames) throws Exception {\n-        assertThat(Files.walk(parserProperties.getParsedPath()))\n-                .filteredOn(p -> !p.toFile().isDirectory())\n-                .hasSize(fileNames.length)\n-                .extracting(Path::getFileName)\n-                .extracting(Path::toString)\n-                .contains(fileNames);\n-    }\n-\n-    // Asserts that valid files are untouched i.e. neither deleted, nor moved\n-    private void assertValidFiles() {\n-        assertTrue(Files.exists(file1.toPath()));\n-        assertTrue(Files.exists(file2.toPath()));\n-    }\n-\n-    private void assertAllProcessed() throws Exception {\n-        // assert no valid files when processing completes successfully\n-        assertFalse(Files.exists(file1.toPath()));\n-        assertFalse(Files.exists(file2.toPath()));\n-\n-        // assert parsed files are moved/deleted.\n-        if (parserProperties.isKeepFiles()) {\n-            assertParsedFiles(file1.getName(), file2.getName());\n-        } else {\n-            assertParsedFiles(); // assert no files in parsed directory\n-        }\n-\n-        // assert mock interactions\n-        assertParse(file1.getPath(), file2.getPath());\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIxMzgyNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468213827", "body": "This is missing a return statement. We don't want to continue to the next file if a parsing error on current file.", "bodyText": "This is missing a return statement. We don't want to continue to the next file if a parsing error on current file.", "bodyHTML": "<p dir=\"auto\">This is missing a return statement. We don't want to continue to the next file if a parsing error on current file.</p>", "author": "steven-sheehy", "createdAt": "2020-08-10T22:09:24Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,110 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n+                    return;\n+                }\n+\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n+            } else {\n+                log.error(\"Input parameter is not a folder: {}\", path);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Error parsing files\", e);\n+        }\n+    }\n+\n+    /**\n+     * read and parse a list of record files\n+     *\n+     * @throws Exception\n+     */\n+    private void loadRecordFiles(String[] filePaths) {\n+        Path validPath = parserProperties.getValidPath();\n+        for (String filePath : filePaths) {\n+            if (ShutdownHelper.isStopping()) {\n+                return;\n+            }\n+\n+            // get file from full path\n+            File file = validPath.resolve(filePath).toFile();\n+\n+            try (InputStream fileInputStream = new FileInputStream(file)) {\n+                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n+\n+                if (parserProperties.isKeepFiles()) {\n+                    Utility.archiveFile(file, parserProperties.getParsedPath());\n+                } else {\n+                    FileUtils.deleteQuietly(file);\n+                }\n+            } catch (FileNotFoundException e) {\n+                log.warn(\"File does not exist {}\", filePath);\n+                return;\n+            } catch (Exception e) {\n+                log.error(String.format(\"Error parsing file %s\", filePath), e);", "originalCommit": "d83065ef5dd67f75f00548058af9bd067ab89a0b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex c5b137b70..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -104,6 +104,7 @@ public class RecordFilePoller implements FilePoller {\n                 return;\n             } catch (Exception e) {\n                 log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                return;\n             }\n         }\n     }\n", "next_change": {"commit": "a7d4932eb9ea4621d184f40c095857f456e7a496", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex d5b6bf905..687b8a512 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -103,7 +103,7 @@ public class RecordFilePoller implements FilePoller {\n                 log.warn(\"File does not exist {}\", filePath);\n                 return;\n             } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                log.error(\"Error parsing file {}\", filePath, e);\n                 return;\n             }\n         }\n", "next_change": {"commit": "a56ea83364b2c8e38746a5a5048555dad80741d3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex 687b8a512..d11a9f4e6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -91,17 +88,14 @@ public class RecordFilePoller implements FilePoller {\n             // get file from full path\n             File file = validPath.resolve(filePath).toFile();\n \n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n+            try {\n+                recordFileParser.parse(StreamFileData.from(file));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n                 } else {\n                     FileUtils.deleteQuietly(file);\n                 }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n             } catch (Exception e) {\n                 log.error(\"Error parsing file {}\", filePath, e);\n                 return;\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d11a9f4e6..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,105 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.domain.StreamFileData;\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedDelayString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try {\n-                recordFileParser.parse(StreamFileData.from(file));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjk1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468236951", "body": "Should remove rollbackFor. I don't see a reason to exclude Error.", "bodyText": "Should remove rollbackFor. I don't see a reason to exclude Error.", "bodyHTML": "<p dir=\"auto\">Should remove rollbackFor. I don't see a reason to exclude Error.</p>", "author": "steven-sheehy", "createdAt": "2020-08-10T23:17:20Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -135,11 +124,13 @@ public RecordFileParser(ApplicationStatusRepository applicationStatusRepository,\n     }\n \n     /**\n-     * Given a service record name, read and parse and return as a list of service record pair\n+     * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    @Override\n+    @Transactional(rollbackFor = Exception.class)", "originalCommit": "d83065ef5dd67f75f00548058af9bd067ab89a0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI0MDcwMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468240700", "bodyText": "My understanding was without this RuntimeExceptions wouldn't result in a rollback. But yeah excluding Errors was not an intended impact.", "author": "Nana-EC", "createdAt": "2020-08-10T23:29:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjk1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex c28f4fda8..6c0258766 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -129,16 +128,16 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional(rollbackFor = Exception.class)\n+    @Transactional\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n-        recordStreamFileListener.onStart(streamFileData);\n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n+            recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n                     streamFileData.getFilename(), expectedPrevFileHash,\n", "next_change": {"commit": "6f0719e98140aeeb313b8d1c5fce7c0910ec4ca7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..3a2c97fed 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -134,6 +140,7 @@ public class RecordFileParser implements FileParser {\n \n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n", "next_change": {"commit": "ee6eef3e60ca0b187642ec53dd9c42aa3bad5f8c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3a2c97fed..8b4278371 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -144,22 +143,26 @@ public class RecordFileParser implements FileParser {\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n+            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    streamFileData.getFilename(),\n                     recordItem -> {\n                         if (processRecordItem(recordItem, dateRangeFilter)) {\n                             counter.incrementAndGet();\n                         }\n                     });\n+            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n+                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            }\n+\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFile);\n+            recordFileDb.setLoadStart(startTime.getEpochSecond());\n+            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFileDb);\n \n-            recordParserLatencyMetric(recordFile);\n+            recordParserLatencyMetric(recordFileDb);\n             success = true;\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 8b4278371..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -123,56 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n-                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n             }\n \n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFileDb.setLoadStart(startTime.getEpochSecond());\n-            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFileDb);\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFile);\n+\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n \n-            recordParserLatencyMetric(recordFileDb);\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..3a2c97fed 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,8 +150,9 @@ public class RecordFileParser implements FileParser {\n                     streamFileData.getFilename(), expectedPrevFileHash,\n                     parserProperties.getMirrorProperties().getVerifyHashAfter(),\n                     recordItem -> {\n-                        counter.incrementAndGet();\n-                        processRecordItem(recordItem);\n+                        if (processRecordItem(recordItem, dateRangeFilter)) {\n+                            counter.incrementAndGet();\n+                        }\n                     });\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n             recordFile.setLoadStart(startTime.getEpochSecond());\n", "next_change": {"commit": "ee6eef3e60ca0b187642ec53dd9c42aa3bad5f8c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3a2c97fed..8b4278371 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -144,22 +143,26 @@ public class RecordFileParser implements FileParser {\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n+            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    streamFileData.getFilename(),\n                     recordItem -> {\n                         if (processRecordItem(recordItem, dateRangeFilter)) {\n                             counter.incrementAndGet();\n                         }\n                     });\n+            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n+                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            }\n+\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFile);\n+            recordFileDb.setLoadStart(startTime.getEpochSecond());\n+            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFileDb);\n \n-            recordParserLatencyMetric(recordFile);\n+            recordParserLatencyMetric(recordFileDb);\n             success = true;\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 8b4278371..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -123,56 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n-                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n             }\n \n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFileDb.setLoadStart(startTime.getEpochSecond());\n-            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFileDb);\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFile);\n+\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n \n-            recordParserLatencyMetric(recordFileDb);\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNzY3Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468237677", "body": "I think it's fine to just log this instead of rethrow. Also, because we want to ensure `cleanup()` is always called.", "bodyText": "I think it's fine to just log this instead of rethrow. Also, because we want to ensure cleanup() is always called.", "bodyHTML": "<p dir=\"auto\">I think it's fine to just log this instead of rethrow. Also, because we want to ensure <code>cleanup()</code> is always called.</p>", "author": "steven-sheehy", "createdAt": "2020-08-10T23:19:52Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -198,9 +184,11 @@ private void executeBatch(PreparedStatement ps, String entity) {\n \n     private void closeConnectionAndStatements() {\n         try {\n-            sqlInsertEntityId.close();\n-            sqlNotifyTopicMessage.close();\n-            connection.close();\n+            if (connection != null) {\n+                sqlInsertEntityId.close();\n+                sqlNotifyTopicMessage.close();\n+                connection.close();\n+            }\n         } catch (SQLException e) {\n             throw new ParserSQLException(\"Error closing connection\", e);", "originalCommit": "d83065ef5dd67f75f00548058af9bd067ab89a0b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5166bb8d6..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -182,15 +186,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void closeConnectionAndStatements() {\n+    private void closeQuietly(Statement statement) {\n         try {\n-            if (connection != null) {\n-                sqlInsertEntityId.close();\n-                sqlNotifyTopicMessage.close();\n-                connection.close();\n+            if (statement != null) {\n+                statement.close();\n             }\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(\"Error closing connection\", e);\n+        } catch (Exception e) {\n+            log.warn(\"Error closing statement\", e);\n         }\n     }\n \n", "next_change": {"commit": "9c13a19e8f4506ecdb2519a1e45a45f61dc34f56", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..7268051ae 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -172,32 +155,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n-\n-        DataSourceUtils.releaseConnection(connection, dataSource);\n-    }\n-\n-    private void executeBatch(PreparedStatement ps, String entity) {\n-        try {\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            var executeResult = ps.executeBatch();\n-            log.info(\"Inserted {} {} in {}\", executeResult.length, entity, stopwatch);\n-        } catch (SQLException e) {\n-            throw new ParserException(e);\n-        }\n-    }\n-\n-    private void closeQuietly(Statement statement) {\n-        try {\n-            if (statement != null) {\n-                statement.close();\n-            }\n-        } catch (Exception e) {\n-            log.warn(\"Error closing statement\", e);\n-        }\n     }\n \n     private void executeBatches() {\n+        Connection connection = null;\n+\n         try {\n+            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             transactionPgCopy.copy(transactions, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n", "next_change": {"commit": "53237aa496805c216c66586835cfd53c5d3a5835", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7268051ae..03dc924b1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -170,9 +193,10 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n-            eventPublisher.publishEvent(new EntityBatchEvent(this));\n+            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n", "next_change": {"commit": "37143536977c12b97f8548a52ebd619ab215557c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 03dc924b1..3e7a38a0b 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -196,7 +199,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n", "next_change": {"commit": "8504f4894f725fd11d79dbbb08c53c380fb5b684", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3e7a38a0b..bf7000073 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -197,6 +208,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            scheduleSignaturePgCopy.copy(scheduleSignatures, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "0c3d94b17a2e300b36023ac8cd5ae76e4b1d397d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex bf7000073..c80ee7ff1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -208,7 +197,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n-            scheduleSignaturePgCopy.copy(scheduleSignatures, connection);\n+            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c80ee7ff1..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -189,16 +207,23 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n             connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n-            transactionPgCopy.copy(transactions, connection);\n+\n+            // insert only operations\n+            contractResultPgCopy.copy(contractResults, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n             fileDataPgCopy.copy(fileData, connection);\n-            contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n+            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            topicMessagePgCopy.copy(topicMessages, connection);\n+            transactionPgCopy.copy(transactions, connection);\n             transactionSignaturePgCopy.copy(transactionSignatures, connection);\n-            persistEntities();\n+\n+            // insert operations with conflict management for updates\n+            entityPgCopy.copy(entities.values(), connection);\n+            schedulePgCopy.copy(schedules.values(), connection);\n+            tokenPgCopy.copy(tokens.values(), connection);\n+            tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "50c046b953fc6dd0a4df360f9267ee08489a3535", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..675b494f6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -209,21 +242,28 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n+            assessedCustomFeePgCopy.copy(assessedCustomFees, connection);\n             contractResultPgCopy.copy(contractResults, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n+            customFeePgCopy.copy(customFees, connection);\n             fileDataPgCopy.copy(fileData, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             transactionPgCopy.copy(transactions, connection);\n             transactionSignaturePgCopy.copy(transactionSignatures, connection);\n \n-            // insert operations with conflict management for updates\n+            // insert operations with conflict management\n             entityPgCopy.copy(entities.values(), connection);\n-            schedulePgCopy.copy(schedules.values(), connection);\n             tokenPgCopy.copy(tokens.values(), connection);\n             tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n+            nftPgCopy.copy(nfts.values(), connection); // persist nft after token entity\n+            schedulePgCopy.copy(schedules.values(), connection);\n+\n+            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n+            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n+            nftTransferPgCopy.copy(nftTransfers, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "783b786089e673910c75b3c317aed55928a11113", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 675b494f6..9dd720311 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -264,6 +281,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             nftTransferPgCopy.copy(nftTransfers, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n \n+            // handle the transfers from token dissociate transactions after nft is processed\n+            tokenDissociateTransferPgCopy.copy(tokenDissociateTransfers, connection);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "95b5209ec65eb0489fcce60b78fd3059da3b5f44", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 9dd720311..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -248,41 +196,40 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n     }\n \n     private void executeBatches() {\n-        Connection connection = null;\n-\n         try {\n             // batch save action may run asynchronously, triggering it before other operations can reduce latency\n             eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n \n-            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n-            assessedCustomFeePgCopy.copy(assessedCustomFees, connection);\n-            contractResultPgCopy.copy(contractResults, connection);\n-            cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            customFeePgCopy.copy(customFees, connection);\n-            fileDataPgCopy.copy(fileData, connection);\n-            liveHashPgCopy.copy(liveHashes, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n-            transactionPgCopy.copy(transactions, connection);\n-            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n+            batchPersister.persist(assessedCustomFees);\n+            batchPersister.persist(contractLogs);\n+            batchPersister.persist(contractResults);\n+            batchPersister.persist(cryptoTransfers);\n+            batchPersister.persist(customFees);\n+            batchPersister.persist(fileData);\n+            batchPersister.persist(liveHashes);\n+            batchPersister.persist(topicMessages);\n+            batchPersister.persist(transactions);\n+            batchPersister.persist(transactionSignatures);\n \n             // insert operations with conflict management\n-            entityPgCopy.copy(entities.values(), connection);\n-            tokenPgCopy.copy(tokens.values(), connection);\n+            batchPersister.persist(contracts.values());\n+            batchPersister.persist(entities.values());\n+            batchPersister.persist(tokens.values());\n             // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            tokenAccountPgCopy.copy(tokenAccounts, connection);\n-            nftPgCopy.copy(nfts.values(), connection); // persist nft after token entity\n-            schedulePgCopy.copy(schedules.values(), connection);\n+            batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(nfts.values()); // persist nft after token entity\n+            batchPersister.persist(schedules.values());\n \n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            nftTransferPgCopy.copy(nftTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            batchPersister.persist(nonFeeTransfers);\n+            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferPgCopy.copy(tokenDissociateTransfers, connection);\n+            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n \n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "1165e4ac7db8ee7798847082bd3e2a912393a6c1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..99c140ace 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -215,17 +260,20 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             batchPersister.persist(transactionSignatures);\n \n             // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n+            batchPersister.persist(contracts);\n+            batchPersister.persist(cryptoAllowances);\n             batchPersister.persist(entities.values());\n+            batchPersister.persist(nftAllowances);\n             batchPersister.persist(tokens.values());\n             // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n             batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(tokenAllowances);\n             batchPersister.persist(nfts.values()); // persist nft after token entity\n             batchPersister.persist(schedules.values());\n \n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n             batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(nftTransferState.values());\n             batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n", "next_change": {"commit": "834b5f7f264c67c8dc949449f7e1b4d1bcc279af", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 99c140ace..d28de0c78 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -274,6 +285,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n             batchPersister.persist(nonFeeTransfers);\n             batchPersister.persist(nftTransferState.values());\n+            batchPersister.persist(stakingRewardTransfers);\n             batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d28de0c78..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -248,59 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(contractStateChanges);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(ethereumTransactions);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(nodeStakes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts);\n-            batchPersister.persist(cryptoAllowances);\n-            batchPersister.persist(entities);\n-            batchPersister.persist(nftAllowances);\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts.values());\n-            batchPersister.persist(tokenAllowances);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransferState.values());\n-            batchPersister.persist(stakingRewardTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 9dd720311..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -291,7 +238,6 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n             throw new ParserException(e);\n         } finally {\n             cleanup();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n         }\n     }\n \n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -195,52 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n-            batchPersister.persist(entities.values());\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxMzI2OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472413269", "body": "I believe moving this into SqlEntityListener breaks PubSub as it doesn't update the last processed hash.", "bodyText": "I believe moving this into SqlEntityListener breaks PubSub as it doesn't update the last processed hash.", "bodyHTML": "<p dir=\"auto\">I believe moving this into SqlEntityListener breaks PubSub as it doesn't update the last processed hash.</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T18:57:20Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -160,16 +149,19 @@ public void loadRecordFile(StreamFileData streamFileData) {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2NTQ4NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474165484", "bodyText": "Good point", "author": "Nana-EC", "createdAt": "2020-08-20T17:47:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxMzI2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ2OTEzNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474469135", "bodyText": "I think it's more important for SqlEntityListener to have control of the db writes. So I stuck with this and added the hash update to the pubs flow", "author": "Nana-EC", "createdAt": "2020-08-21T07:29:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxMzI2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex de4662fcd..6c0258766 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -152,8 +153,6 @@ public class RecordFileParser implements FileParser {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n-        } catch (DuplicateFileException ex) {\n-            log.warn(String.format(\"Skipping file %s\", streamFileData.getFilename()), ex);\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n             throw ex;\n", "next_change": {"commit": "ee6eef3e60ca0b187642ec53dd9c42aa3bad5f8c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..8b4278371 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -134,24 +139,30 @@ public class RecordFileParser implements FileParser {\n \n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n+            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    streamFileData.getFilename(),\n                     recordItem -> {\n-                        counter.incrementAndGet();\n-                        processRecordItem(recordItem);\n+                        if (processRecordItem(recordItem, dateRangeFilter)) {\n+                            counter.incrementAndGet();\n+                        }\n                     });\n+            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n+                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            }\n+\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFile);\n+            recordFileDb.setLoadStart(startTime.getEpochSecond());\n+            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFileDb);\n \n-            recordParserLatencyMetric(recordFile);\n+            recordParserLatencyMetric(recordFileDb);\n             success = true;\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 8b4278371..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -123,56 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n-                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n             }\n \n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFileDb.setLoadStart(startTime.getEpochSecond());\n-            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFileDb);\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFile);\n+\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n \n-            recordParserLatencyMetric(recordFileDb);\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxNjk1Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472416956", "body": "nit: Would prefer parameters be named the same as the fields as most of the other fields are.", "bodyText": "nit: Would prefer parameters be named the same as the fields as most of the other fields are.", "bodyHTML": "<p dir=\"auto\">nit: Would prefer parameters be named the same as the fields as most of the other fields are.</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T19:04:26Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -95,13 +105,20 @@\n     private PreparedStatement sqlNotifyTopicMessage;\n     private Connection connection;\n     private long batchCount;\n+    private RecordFile partialRecordFile;\n \n     public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n-                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager) {\n+                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n+                             ApplicationStatusRepository applicationStatusRepository,\n+                             TransactionRepository transactionRepository,\n+                             RecordParserProperties parserProps) {\n         this.dataSource = dataSource;\n+        this.applicationStatusRepository = applicationStatusRepository;\n         this.recordFileRepository = recordFileRepository;\n+        this.transactionRepository = transactionRepository;\n         sqlProperties = properties;\n+        parserProperties = parserProps;", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -101,33 +96,29 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     // used to optimize inserts into t_entities table so node and treasury ids are not tried for every transaction\n     private final Cache entityCache;\n \n-    private PreparedStatement sqlInsertEntityId;\n     private PreparedStatement sqlNotifyTopicMessage;\n     private Connection connection;\n     private long batchCount;\n-    private RecordFile partialRecordFile;\n \n-    public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n+    public SqlEntityListener(SqlProperties sqlProperties, DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n                              @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n                              ApplicationStatusRepository applicationStatusRepository,\n-                             TransactionRepository transactionRepository,\n-                             RecordParserProperties parserProps) {\n+                             EntityRepository entityRepository) {\n         this.dataSource = dataSource;\n         this.applicationStatusRepository = applicationStatusRepository;\n+        this.entityRepository = entityRepository;\n         this.recordFileRepository = recordFileRepository;\n-        this.transactionRepository = transactionRepository;\n-        sqlProperties = properties;\n-        parserProperties = parserProps;\n+        this.sqlProperties = sqlProperties;\n         entityCache = cacheManager.getCache(CacheConfiguration.NEVER_EXPIRE_LARGE);\n \n-        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, properties);\n-        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, properties);\n-        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, properties);\n-        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, properties);\n-        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, properties);\n-        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, properties);\n-        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, properties);\n+        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, sqlProperties);\n+        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, sqlProperties);\n+        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, sqlProperties);\n+        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, sqlProperties);\n+        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, sqlProperties);\n+        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, sqlProperties);\n+        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, sqlProperties);\n \n         transactions = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n", "next_change": {"commit": "53237aa496805c216c66586835cfd53c5d3a5835", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..03dc924b1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -119,6 +127,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, sqlProperties);\n         liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, sqlProperties);\n         topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, sqlProperties);\n+        tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, sqlProperties);\n \n         transactions = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n", "next_change": {"commit": "8504f4894f725fd11d79dbbb08c53c380fb5b684", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 03dc924b1..bf7000073 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -128,6 +136,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, sqlProperties);\n         topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, sqlProperties);\n         tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, sqlProperties);\n+        scheduleSignaturePgCopy = new PgCopy<>(ScheduleSignature.class, meterRegistry, sqlProperties);\n \n         transactions = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n", "next_change": {"commit": "c9a6c983ce422469c0bf0b597ad512f648311d3b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex bf7000073..a644ce2c4 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -128,15 +123,15 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         this.tokenAccountRepository = tokenAccountRepository;\n         this.scheduleRepository = scheduleRepository;\n \n-        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, sqlProperties);\n-        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, sqlProperties);\n-        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, sqlProperties);\n-        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, sqlProperties);\n-        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, sqlProperties);\n-        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, sqlProperties);\n-        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, sqlProperties);\n-        tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, sqlProperties);\n-        scheduleSignaturePgCopy = new PgCopy<>(ScheduleSignature.class, meterRegistry, sqlProperties);\n+        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, recordParserProperties);\n+        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, recordParserProperties);\n+        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, recordParserProperties);\n+        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, recordParserProperties);\n+        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, recordParserProperties);\n+        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, recordParserProperties);\n+        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, recordParserProperties);\n+        tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, recordParserProperties);\n+        scheduleSignaturePgCopy = new PgCopy<>(ScheduleSignature.class, meterRegistry, recordParserProperties);\n \n         transactions = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n", "next_change": {"commit": "0c3d94b17a2e300b36023ac8cd5ae76e4b1d397d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex a644ce2c4..c80ee7ff1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -131,7 +131,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, recordParserProperties);\n         topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, recordParserProperties);\n         tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, recordParserProperties);\n-        scheduleSignaturePgCopy = new PgCopy<>(ScheduleSignature.class, meterRegistry, recordParserProperties);\n+        transactionSignaturePgCopy = new PgCopy<>(TransactionSignature.class, meterRegistry, recordParserProperties);\n \n         transactions = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c80ee7ff1..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -73,76 +73,91 @@ import com.hedera.mirror.importer.repository.TokenRepository;\n public class SqlEntityListener implements EntityListener, RecordStreamFileListener {\n \n     private final DataSource dataSource;\n-    private final EntityRepository entityRepository;\n     private final RecordFileRepository recordFileRepository;\n     private final SqlProperties sqlProperties;\n     private final ApplicationEventPublisher eventPublisher;\n-    private final TokenRepository tokenRepository;\n-    private final TokenAccountRepository tokenAccountRepository;\n-    private final ScheduleRepository scheduleRepository;\n \n     // init schemas, writers, etc once per process\n-    private final PgCopy<Transaction> transactionPgCopy;\n+    private final PgCopy<ContractResult> contractResultPgCopy;\n     private final PgCopy<CryptoTransfer> cryptoTransferPgCopy;\n-    private final PgCopy<NonFeeTransfer> nonFeeTransferPgCopy;\n     private final PgCopy<FileData> fileDataPgCopy;\n-    private final PgCopy<ContractResult> contractResultPgCopy;\n     private final PgCopy<LiveHash> liveHashPgCopy;\n-    private final PgCopy<TopicMessage> topicMessagePgCopy;\n+    private final PgCopy<NonFeeTransfer> nonFeeTransferPgCopy;\n     private final PgCopy<TokenTransfer> tokenTransferPgCopy;\n+    private final PgCopy<TopicMessage> topicMessagePgCopy;\n+    private final PgCopy<Transaction> transactionPgCopy;\n     private final PgCopy<TransactionSignature> transactionSignaturePgCopy;\n \n-    // used to optimize inserts into t_entities table so node and treasury ids are not tried for every transaction\n-    private final Cache entityCache;\n+    private final UpsertPgCopy<Entity> entityPgCopy;\n+    private final UpsertPgCopy<Schedule> schedulePgCopy;\n+    private final UpsertPgCopy<TokenAccount> tokenAccountPgCopy;\n+    private final UpsertPgCopy<Token> tokenPgCopy;\n \n-    private final Collection<Transaction> transactions;\n+    // lists of insert only domains\n+    private final Collection<ContractResult> contractResults;\n     private final Collection<CryptoTransfer> cryptoTransfers;\n-    private final Collection<NonFeeTransfer> nonFeeTransfers;\n     private final Collection<FileData> fileData;\n-    private final Collection<ContractResult> contractResults;\n     private final Collection<LiveHash> liveHashes;\n+    private final Collection<NonFeeTransfer> nonFeeTransfers;\n     private final Collection<TopicMessage> topicMessages;\n-    private final Collection<EntityId> entityIds;\n     private final Collection<TokenTransfer> tokenTransfers;\n+    private final Collection<Transaction> transactions;\n     private final Collection<TransactionSignature> transactionSignatures;\n \n+    // maps of upgradable domains\n+    private final Map<Long, Entity> entities;\n+    private final Map<Long, Schedule> schedules;\n+    private final Map<Long, Token> tokens;\n+    private final Map<TokenAccountId, TokenAccount> tokenAccounts;\n+\n     public SqlEntityListener(RecordParserProperties recordParserProperties, SqlProperties sqlProperties,\n                              DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n-                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n-                             EntityRepository entityRepository, ApplicationEventPublisher eventPublisher,\n-                             TokenRepository tokenRepository, TokenAccountRepository tokenAccountRepository,\n-                             ScheduleRepository scheduleRepository) {\n+                             ApplicationEventPublisher eventPublisher,\n+                             EntityUpsertQueryGenerator entityUpsertQueryGenerator,\n+                             ScheduleUpsertQueryGenerator scheduleUpsertQueryGenerator,\n+                             TokenUpsertQueryGenerator tokenUpsertQueryGenerator,\n+                             TokenAccountUpsertQueryGenerator tokenAccountUpsertQueryGenerator) {\n         this.dataSource = dataSource;\n-        this.entityRepository = entityRepository;\n         this.recordFileRepository = recordFileRepository;\n         this.sqlProperties = sqlProperties;\n-        entityCache = cacheManager.getCache(CacheConfiguration.NEVER_EXPIRE_LARGE);\n         this.eventPublisher = eventPublisher;\n-        this.tokenRepository = tokenRepository;\n-        this.tokenAccountRepository = tokenAccountRepository;\n-        this.scheduleRepository = scheduleRepository;\n \n-        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, recordParserProperties);\n+        // insert only tables\n+        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, recordParserProperties);\n         cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, recordParserProperties);\n-        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, recordParserProperties);\n         fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, recordParserProperties);\n-        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, recordParserProperties);\n         liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, recordParserProperties);\n-        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, recordParserProperties);\n+        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, recordParserProperties);\n         tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, recordParserProperties);\n+        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, recordParserProperties);\n+        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, recordParserProperties);\n         transactionSignaturePgCopy = new PgCopy<>(TransactionSignature.class, meterRegistry, recordParserProperties);\n \n-        transactions = new ArrayList<>();\n+        // updatable tables\n+        entityPgCopy = new UpsertPgCopy<>(Entity.class, meterRegistry, recordParserProperties,\n+                entityUpsertQueryGenerator);\n+        schedulePgCopy = new UpsertPgCopy<>(Schedule.class, meterRegistry, recordParserProperties,\n+                scheduleUpsertQueryGenerator);\n+        tokenAccountPgCopy = new UpsertPgCopy<>(TokenAccount.class, meterRegistry, recordParserProperties,\n+                tokenAccountUpsertQueryGenerator);\n+        tokenPgCopy = new UpsertPgCopy<>(Token.class, meterRegistry, recordParserProperties,\n+                tokenUpsertQueryGenerator);\n+\n+        contractResults = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n-        nonFeeTransfers = new ArrayList<>();\n         fileData = new ArrayList<>();\n-        contractResults = new ArrayList<>();\n         liveHashes = new ArrayList<>();\n-        entityIds = new HashSet<>();\n-        topicMessages = new ArrayList<>();\n+        nonFeeTransfers = new ArrayList<>();\n         tokenTransfers = new ArrayList<>();\n+        topicMessages = new ArrayList<>();\n+        transactions = new ArrayList<>();\n         transactionSignatures = new ArrayList<>();\n+\n+        entities = new HashMap<>();\n+        schedules = new HashMap<>();\n+        tokens = new HashMap<>();\n+        tokenAccounts = new HashMap<>();\n     }\n \n     @Override\n", "next_change": {"commit": "50c046b953fc6dd0a4df360f9267ee08489a3535", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..675b494f6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -155,6 +179,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         transactionSignatures = new ArrayList<>();\n \n         entities = new HashMap<>();\n+        nfts = new HashMap<>();\n         schedules = new HashMap<>();\n         tokens = new HashMap<>();\n         tokenAccounts = new HashMap<>();\n", "next_change": {"commit": "8b87691d796a6f769028945c5ec68c5a4dfcc228", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 675b494f6..cfbf3363e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -182,7 +190,8 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         nfts = new HashMap<>();\n         schedules = new HashMap<>();\n         tokens = new HashMap<>();\n-        tokenAccounts = new HashMap<>();\n+\n+        tokenAccountState = new HashMap<>();\n     }\n \n     @Override\n", "next_change": {"commit": "d250a32e9a3aca0308bd57fe0990c7ba892fa94c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex cfbf3363e..2c02a77f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -59,138 +60,92 @@ import com.hedera.mirror.importer.domain.Transaction;\n import com.hedera.mirror.importer.domain.TransactionSignature;\n import com.hedera.mirror.importer.exception.ImporterException;\n import com.hedera.mirror.importer.exception.ParserException;\n-import com.hedera.mirror.importer.parser.PgCopy;\n-import com.hedera.mirror.importer.parser.UpsertPgCopy;\n-import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+import com.hedera.mirror.importer.parser.batch.BatchPersister;\n import com.hedera.mirror.importer.parser.record.RecordStreamFileListener;\n-import com.hedera.mirror.importer.parser.record.entity.AbstractEntityListener;\n import com.hedera.mirror.importer.parser.record.entity.ConditionOnEntityRecordParser;\n import com.hedera.mirror.importer.parser.record.entity.EntityBatchCleanupEvent;\n import com.hedera.mirror.importer.parser.record.entity.EntityBatchSaveEvent;\n+import com.hedera.mirror.importer.parser.record.entity.EntityListener;\n import com.hedera.mirror.importer.repository.RecordFileRepository;\n-import com.hedera.mirror.importer.repository.upsert.EntityUpsertQueryGenerator;\n-import com.hedera.mirror.importer.repository.upsert.NftUpsertQueryGenerator;\n-import com.hedera.mirror.importer.repository.upsert.ScheduleUpsertQueryGenerator;\n-import com.hedera.mirror.importer.repository.upsert.TokenAccountUpsertQueryGenerator;\n-import com.hedera.mirror.importer.repository.upsert.TokenUpsertQueryGenerator;\n \n @Log4j2\n @Named\n @Order(0)\n @ConditionOnEntityRecordParser\n-public class SqlEntityListener extends AbstractEntityListener implements RecordStreamFileListener {\n+public class SqlEntityListener implements EntityListener, RecordStreamFileListener {\n \n-    private final DataSource dataSource;\n+    private final BatchPersister batchPersister;\n+    private final ApplicationEventPublisher eventPublisher;\n     private final RecordFileRepository recordFileRepository;\n     private final SqlProperties sqlProperties;\n-    private final ApplicationEventPublisher eventPublisher;\n-\n-    // init schemas, writers, etc once per process\n-    private final PgCopy<AssessedCustomFee> assessedCustomFeePgCopy;\n-    private final PgCopy<ContractResult> contractResultPgCopy;\n-    private final PgCopy<CryptoTransfer> cryptoTransferPgCopy;\n-    private final PgCopy<CustomFee> customFeePgCopy;\n-    private final PgCopy<FileData> fileDataPgCopy;\n-    private final PgCopy<LiveHash> liveHashPgCopy;\n-    private final PgCopy<NftTransfer> nftTransferPgCopy;\n-    private final PgCopy<NonFeeTransfer> nonFeeTransferPgCopy;\n-    private final PgCopy<TokenTransfer> tokenTransferPgCopy;\n-    private final PgCopy<TopicMessage> topicMessagePgCopy;\n-    private final PgCopy<Transaction> transactionPgCopy;\n-    private final PgCopy<TransactionSignature> transactionSignaturePgCopy;\n-\n-    private final UpsertPgCopy<Entity> entityPgCopy;\n-    private final UpsertPgCopy<Nft> nftPgCopy;\n-    private final UpsertPgCopy<Schedule> schedulePgCopy;\n-    private final UpsertPgCopy<TokenAccount> tokenAccountPgCopy;\n-    private final UpsertPgCopy<Token> tokenPgCopy;\n+    private final BatchPersister tokenDissociateTransferBatchPersister;\n \n     // lists of insert only domains\n     private final Collection<AssessedCustomFee> assessedCustomFees;\n+    private final Collection<Contract> contracts;\n+    private final Collection<ContractLog> contractLogs;\n     private final Collection<ContractResult> contractResults;\n     private final Collection<CryptoTransfer> cryptoTransfers;\n     private final Collection<CustomFee> customFees;\n+    private final Collection<Entity> entities;\n     private final Collection<FileData> fileData;\n     private final Collection<LiveHash> liveHashes;\n     private final Collection<NftTransfer> nftTransfers;\n     private final Collection<NonFeeTransfer> nonFeeTransfers;\n     private final Collection<TokenAccount> tokenAccounts;\n+    private final Collection<TokenTransfer> tokenDissociateTransfers;\n     private final Collection<TokenTransfer> tokenTransfers;\n     private final Collection<TopicMessage> topicMessages;\n     private final Collection<Transaction> transactions;\n     private final Collection<TransactionSignature> transactionSignatures;\n \n     // maps of upgradable domains\n-    private final Map<Long, Entity> entities;\n+    private final Map<Long, Contract> contractState;\n+    private final Map<Long, Entity> entityState;\n     private final Map<Long, Schedule> schedules;\n     private final Map<Long, Token> tokens;\n     private final Map<NftId, Nft> nfts;\n \n     // tracks the state of <token, account> relationships in a batch, the initial state before the batch is in db.\n     // for each <token, account> update, merge the state and the update, save the merged state to the batch.\n-    // during upsert pgcopy, the merged state at time T is again merged with the initial state before the batch to\n+    // during batch upsert, the merged state at time T is again merged with the initial state before the batch to\n     // get the full state at time T\n     private final Map<TokenAccountKey, TokenAccount> tokenAccountState;\n \n-    public SqlEntityListener(RecordParserProperties recordParserProperties, SqlProperties sqlProperties,\n-                             DataSource dataSource,\n-                             RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n+    public SqlEntityListener(BatchPersister batchPersister,\n                              ApplicationEventPublisher eventPublisher,\n-                             EntityUpsertQueryGenerator entityUpsertQueryGenerator,\n-                             ScheduleUpsertQueryGenerator scheduleUpsertQueryGenerator,\n-                             TokenUpsertQueryGenerator tokenUpsertQueryGenerator,\n-                             TokenAccountUpsertQueryGenerator tokenAccountUpsertQueryGenerator,\n-                             NftUpsertQueryGenerator nftUpsertQueryGenerator) {\n-        this.dataSource = dataSource;\n+                             RecordFileRepository recordFileRepository,\n+                             SqlProperties sqlProperties,\n+                             @Qualifier(TOKEN_DISSOCIATE_BATCH_PERSISTER) BatchPersister tokenDissociateTransferBatchPersister) {\n+        this.batchPersister = batchPersister;\n+        this.eventPublisher = eventPublisher;\n         this.recordFileRepository = recordFileRepository;\n         this.sqlProperties = sqlProperties;\n-        this.eventPublisher = eventPublisher;\n-\n-        // insert only tables\n-        assessedCustomFeePgCopy = new PgCopy<>(AssessedCustomFee.class, meterRegistry, recordParserProperties);\n-        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, recordParserProperties);\n-        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, recordParserProperties);\n-        customFeePgCopy = new PgCopy<>(CustomFee.class, meterRegistry, recordParserProperties);\n-        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, recordParserProperties);\n-        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, recordParserProperties);\n-        nftTransferPgCopy = new PgCopy<>(NftTransfer.class, meterRegistry, recordParserProperties);\n-        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, recordParserProperties);\n-        tokenTransferPgCopy = new PgCopy<>(TokenTransfer.class, meterRegistry, recordParserProperties);\n-        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, recordParserProperties);\n-        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, recordParserProperties);\n-        transactionSignaturePgCopy = new PgCopy<>(TransactionSignature.class, meterRegistry, recordParserProperties);\n-\n-        // updatable tables\n-        entityPgCopy = new UpsertPgCopy<>(Entity.class, meterRegistry, recordParserProperties,\n-                entityUpsertQueryGenerator);\n-        nftPgCopy = new UpsertPgCopy<>(Nft.class, meterRegistry, recordParserProperties,\n-                nftUpsertQueryGenerator);\n-        schedulePgCopy = new UpsertPgCopy<>(Schedule.class, meterRegistry, recordParserProperties,\n-                scheduleUpsertQueryGenerator);\n-        tokenAccountPgCopy = new UpsertPgCopy<>(TokenAccount.class, meterRegistry, recordParserProperties,\n-                tokenAccountUpsertQueryGenerator);\n-        tokenPgCopy = new UpsertPgCopy<>(Token.class, meterRegistry, recordParserProperties,\n-                tokenUpsertQueryGenerator);\n+        this.tokenDissociateTransferBatchPersister = tokenDissociateTransferBatchPersister;\n \n         assessedCustomFees = new ArrayList<>();\n+        contracts = new ArrayList<>();\n+        contractLogs = new ArrayList<>();\n         contractResults = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n         customFees = new ArrayList<>();\n+        entities = new ArrayList<>();\n         fileData = new ArrayList<>();\n         liveHashes = new ArrayList<>();\n         nftTransfers = new ArrayList<>();\n         nonFeeTransfers = new ArrayList<>();\n+        tokenDissociateTransfers = new ArrayList<>();\n         tokenTransfers = new ArrayList<>();\n         tokenAccounts = new ArrayList<>();\n         topicMessages = new ArrayList<>();\n         transactions = new ArrayList<>();\n         transactionSignatures = new ArrayList<>();\n \n-        entities = new HashMap<>();\n+        contractState = new HashMap<>();\n+        entityState = new HashMap<>();\n         nfts = new HashMap<>();\n         schedules = new HashMap<>();\n         tokens = new HashMap<>();\n-\n         tokenAccountState = new HashMap<>();\n     }\n \n", "next_change": {"commit": "65b7f5080f7746a638793b600e0ce50fd106b33c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 2c02a77f0..90f63e8ac 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -127,26 +142,33 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         contracts = new ArrayList<>();\n         contractLogs = new ArrayList<>();\n         contractResults = new ArrayList<>();\n+        contractStateChanges = new ArrayList<>();\n+        cryptoAllowances = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n         customFees = new ArrayList<>();\n         entities = new ArrayList<>();\n         fileData = new ArrayList<>();\n         liveHashes = new ArrayList<>();\n+        nftAllowances = new ArrayList<>();\n         nftTransfers = new ArrayList<>();\n         nonFeeTransfers = new ArrayList<>();\n+        tokenAccounts = new ArrayList<>();\n+        tokenAllowances = new ArrayList<>();\n         tokenDissociateTransfers = new ArrayList<>();\n         tokenTransfers = new ArrayList<>();\n-        tokenAccounts = new ArrayList<>();\n         topicMessages = new ArrayList<>();\n         transactions = new ArrayList<>();\n         transactionSignatures = new ArrayList<>();\n \n         contractState = new HashMap<>();\n+        cryptoAllowanceState = new HashMap<>();\n         entityState = new HashMap<>();\n         nfts = new HashMap<>();\n+        nftAllowanceState = new HashMap<>();\n         schedules = new HashMap<>();\n         tokens = new HashMap<>();\n         tokenAccountState = new HashMap<>();\n+        tokenAllowanceState = new HashMap<>();\n     }\n \n     @Override\n", "next_change": {"commit": "1165e4ac7db8ee7798847082bd3e2a912393a6c1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 90f63e8ac..99c140ace 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -162,9 +168,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n         contractState = new HashMap<>();\n         cryptoAllowanceState = new HashMap<>();\n-        entityState = new HashMap<>();\n         nfts = new HashMap<>();\n         nftAllowanceState = new HashMap<>();\n+        nftTransferState = new HashMap<>();\n         schedules = new HashMap<>();\n         tokens = new HashMap<>();\n         tokenAccountState = new HashMap<>();\n", "next_change": {"commit": "834b5f7f264c67c8dc949449f7e1b4d1bcc279af", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 99c140ace..d28de0c78 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -168,6 +174,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n         contractState = new HashMap<>();\n         cryptoAllowanceState = new HashMap<>();\n+        entityState = new HashMap<>();\n         nfts = new HashMap<>();\n         nftAllowanceState = new HashMap<>();\n         nftTransferState = new HashMap<>();\n", "next_change": {"commit": "f369a6652c704d28f65d28f74414cd8b8c65b6f9", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d28de0c78..4f1ce5250 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -172,7 +186,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         transactions = new ArrayList<>();\n         transactionSignatures = new ArrayList<>();\n \n-        contractState = new HashMap<>();\n         cryptoAllowanceState = new HashMap<>();\n         entityState = new HashMap<>();\n         nfts = new HashMap<>();\n", "next_change": {"commit": "3671e9f20841bcdae20ba68bc859e1d0502076e7", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 4f1ce5250..c2223831c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -184,6 +190,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         tokenTransfers = new ArrayList<>();\n         topicMessages = new ArrayList<>();\n         transactions = new ArrayList<>();\n+        transactionHashes = new ArrayList<>();\n         transactionSignatures = new ArrayList<>();\n \n         cryptoAllowanceState = new HashMap<>();\n", "next_change": {"commit": "c10f28794e89ed9dc5824a72628f6ca6ddc3c0aa", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c2223831c..65169d9af 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -193,6 +193,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         transactionHashes = new ArrayList<>();\n         transactionSignatures = new ArrayList<>();\n \n+        contractStates = new HashMap<>();\n         cryptoAllowanceState = new HashMap<>();\n         entityState = new HashMap<>();\n         nfts = new HashMap<>();\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQyNTk0OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472425949", "body": "Turns out `record_file.name` has a unique constraint so this can't happen. Remove", "bodyText": "Turns out record_file.name has a unique constraint so this can't happen. Remove", "bodyHTML": "<p dir=\"auto\">Turns out <code>record_file.name</code> has a unique constraint so this can't happen. Remove</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T19:20:42Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -160,16 +149,19 @@ public void loadRecordFile(StreamFileData streamFileData) {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (DuplicateFileException ex) {", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE3MDc4Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474170783", "bodyText": "Removed", "author": "Nana-EC", "createdAt": "2020-08-20T17:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQyNTk0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex de4662fcd..6c0258766 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -152,8 +153,6 @@ public class RecordFileParser implements FileParser {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n-        } catch (DuplicateFileException ex) {\n-            log.warn(String.format(\"Skipping file %s\", streamFileData.getFilename()), ex);\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n             throw ex;\n", "next_change": {"commit": "ee6eef3e60ca0b187642ec53dd9c42aa3bad5f8c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 6c0258766..8b4278371 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -134,24 +139,30 @@ public class RecordFileParser implements FileParser {\n \n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n-            recordStreamFileListener.onStart(streamFileData);\n+            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    streamFileData.getFilename(),\n                     recordItem -> {\n-                        counter.incrementAndGet();\n-                        processRecordItem(recordItem);\n+                        if (processRecordItem(recordItem, dateRangeFilter)) {\n+                            counter.incrementAndGet();\n+                        }\n                     });\n+            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n+                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            }\n+\n             log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFile.setLoadStart(startTime.getEpochSecond());\n-            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFile);\n+            recordFileDb.setLoadStart(startTime.getEpochSecond());\n+            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFileDb);\n \n-            recordParserLatencyMetric(recordFile);\n+            recordParserLatencyMetric(recordFileDb);\n             success = true;\n         } catch (Exception ex) {\n             recordStreamFileListener.onError(); // rollback\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 8b4278371..47f1d25f0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -123,56 +117,68 @@ public class RecordFileParser implements FileParser {\n \n         latencyMetrics = latencyMetricsBuilder.build();\n         sizeMetrics = sizeMetricsBuilder.build();\n-        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN);\n-        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN);\n+        unknownLatencyMetric = latencyMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n+        unknownSizeMetric = sizeMetrics.get(TransactionTypeEnum.UNKNOWN.getProtoId());\n     }\n \n     /**\n      * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n-     * @param streamFileData containing information about file to be processed\n+     * @param recordFile containing information about file to be processed\n      */\n     @Override\n+    @Retryable(backoff = @Backoff(\n+            delayExpression = \"#{@recordParserProperties.getRetry().getMinBackoff().toMillis()}\",\n+            maxDelayExpression = \"#{@recordParserProperties.getRetry().getMaxBackoff().toMillis()}\",\n+            multiplierExpression = \"#{@recordParserProperties.getRetry().getMultiplier()}\"),\n+            maxAttemptsExpression = \"#{@recordParserProperties.getRetry().getMaxAttempts()}\")\n+    @ServiceActivator(inputChannel = CHANNEL_RECORD,\n+            poller = @Poller(fixedDelay = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    )\n     @Transactional\n-    public void parse(StreamFileData streamFileData) {\n-        Instant startTime = Instant.now();\n+    public void parse(RecordFile recordFile) {\n+        if (!parserProperties.isEnabled()) {\n+            return;\n+        }\n \n-        String expectedPrevFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor.getDateRangeFilter(parserProperties.getStreamType());\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        DateRangeFilter dateRangeFilter = mirrorDateRangePropertiesProcessor\n+                .getDateRangeFilter(parserProperties.getStreamType());\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n+\n         try {\n-            RecordFile recordFileDb = recordStreamFileListener.onStart(streamFileData);\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            RecordFile recordFile = Utility.parseRecordFile(\n-                    streamFileData.getFilename(),\n-                    recordItem -> {\n-                        if (processRecordItem(recordItem, dateRangeFilter)) {\n-                            counter.incrementAndGet();\n-                        }\n-                    });\n-            if (!Utility.verifyHashChain(recordFile.getPreviousHash(), expectedPrevFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(), recordFile.getName())) {\n-                throw new HashMismatchException(recordFile.getName(), expectedPrevFileHash, recordFile.getPreviousHash());\n+            recordStreamFileListener.onStart();\n+            recordFile.getItems().forEach(recordItem -> {\n+                if (processRecordItem(recordItem, dateRangeFilter)) {\n+                    counter.incrementAndGet();\n+                }\n+            });\n+\n+            byte[] bytes = recordFile.getBytes();\n+            if (!parserProperties.isPersistBytes()) {\n+                recordFile.setBytes(null);\n             }\n \n-            log.info(\"Time to parse record file: {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n-            recordFileDb.setLoadStart(startTime.getEpochSecond());\n-            recordFileDb.setLoadEnd(Instant.now().getEpochSecond());\n-            recordStreamFileListener.onEnd(recordFileDb);\n+            Instant loadEnd = Instant.now();\n+            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordStreamFileListener.onEnd(recordFile);\n+\n+            if (parserProperties.isKeepFiles()) {\n+                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n+            }\n \n-            recordParserLatencyMetric(recordFileDb);\n+            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n+            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n             success = true;\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n-            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n-            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n-            parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n+                    counter, recordFile.getName(), stopwatch, success);\n+            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 47f1d25f0..bad2d7e0e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,30 +124,11 @@ public class RecordFileParser implements StreamFileParser<RecordFile> {\n                 }\n             });\n \n-            byte[] bytes = recordFile.getBytes();\n-            if (!parserProperties.isPersistBytes()) {\n-                recordFile.setBytes(null);\n-            }\n-\n-            Instant loadEnd = Instant.now();\n-            recordFile.setLoadEnd(loadEnd.getEpochSecond());\n+            recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-\n-            if (parserProperties.isKeepFiles()) {\n-                Utility.archiveFile(recordFile.getName(), bytes, parserProperties.getParsedPath());\n-            }\n-\n-            Instant consensusEnd = Instant.ofEpochSecond(0L, recordFile.getConsensusEnd());\n-            parseLatencyMetric.record(Duration.between(consensusEnd, loadEnd));\n-            success = true;\n         } catch (Exception ex) {\n-            log.error(\"Error parsing file {}\", recordFile.getName(), ex);\n             recordStreamFileListener.onError();\n             throw ex;\n-        } finally {\n-            log.info(\"Finished parsing {} transactions from record file {} in {}. Success: {}\",\n-                    counter, recordFile.getName(), stopwatch, success);\n-            parseDurationMetrics.get(success).record(stopwatch.elapsed());\n         }\n     }\n \n", "next_change": {"commit": "101725efa15598881d4b8b694dab8480909ace3c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bad2d7e0e..4b68e099e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -132,7 +133,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         }\n     }\n \n-    private boolean processRecordItem(RecordItem recordItem, DateRangeFilter dateRangeFilter) {\n+    private void logItem(RecordItem recordItem) {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n", "next_change": {"commit": "b36fe94a4dfdd1a49fd7be684e419bcc90d0cf5c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 4b68e099e..bf12ab06e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -139,7 +145,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n                     Utility.printProtoMessage(recordItem.getRecord()));\n         } else if (log.isDebugEnabled()) {\n-            log.debug(\"Storing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n+            log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n     }\n \n", "next_change": {"commit": "2fedd6166240a93829916d2fcaa414223f36aafe", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -143,7 +153,7 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         if (log.isTraceEnabled()) {\n             log.trace(\"Transaction = {}, Record = {}\",\n                     Utility.printProtoMessage(recordItem.getTransaction()),\n-                    Utility.printProtoMessage(recordItem.getRecord()));\n+                    Utility.printProtoMessage(recordItem.getTransactionRecord()));\n         } else if (log.isDebugEnabled()) {\n             log.debug(\"Parsing transaction with consensus timestamp {}\", recordItem.getConsensusTimestamp());\n         }\n", "next_change": null}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex bf12ab06e..3370916fd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -153,8 +163,31 @@ public class RecordFileParser extends AbstractStreamFileParser<RecordFile> {\n         sizeMetrics.getOrDefault(recordItem.getTransactionType(), unknownSizeMetric)\n                 .record(recordItem.getTransactionBytes().length);\n \n-        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getRecord().getConsensusTimestamp());\n+        Instant consensusTimestamp = Utility.convertToInstant(recordItem.getTransactionRecord().getConsensusTimestamp());\n         latencyMetrics.getOrDefault(recordItem.getTransactionType(), unknownLatencyMetric)\n                 .record(Duration.between(consensusTimestamp, Instant.now()));\n     }\n+\n+    // Correct v5 block numbers once we receive a v6 block with a canonical number\n+    private void updateIndex(RecordFile recordFile) {\n+        var lastInMemory = last.get();\n+        var lastRecordFile = lastInMemory;\n+        var recordFileRepository = (RecordFileRepository) streamFileRepository;\n+\n+        if (lastRecordFile == null) {\n+            lastRecordFile = recordFileRepository.findLatest().orElse(null);\n+        }\n+\n+        if (lastRecordFile != null && lastRecordFile.getVersion() < VERSION && recordFile.getVersion() >= VERSION) {\n+            long offset = recordFile.getIndex() - lastRecordFile.getIndex() - 1;\n+\n+            if (offset != 0) {\n+                var stopwatch = Stopwatch.createStarted();\n+                int count = recordFileRepository.updateIndex(offset);\n+                log.info(\"Updated {} blocks with offset {} in {}\", count, offset, stopwatch);\n+            }\n+        }\n+\n+        last.compareAndSet(lastInMemory, recordFile);\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDU0Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472510546", "body": "name is unique so this repository method can only ever return one entry. Should be adjusted to return single optional and handle method be adjusted.", "bodyText": "name is unique so this repository method can only ever return one entry. Should be adjusted to return single optional and handle method be adjusted.", "bodyHTML": "<p dir=\"auto\">name is unique so this repository method can only ever return one entry. Should be adjusted to return single optional and handle method be adjusted.</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T21:43:59Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -120,14 +137,18 @@ public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n         liveHashes = new ArrayList<>();\n         entityIds = new HashSet<>();\n         topicMessages = new ArrayList<>();\n+        partialRecordFile = null;\n     }\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n         String fileName = FilenameUtils.getName(streamFileData.getFilename());\n \n-        if (recordFileRepository.findByName(fileName).size() > 0) {\n-            throw new DuplicateFileException(\"File already exists in the database: \" + fileName);\n+        List<RecordFile> matchingRecords = recordFileRepository.findByName(fileName);", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2NjkzNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474166935", "bodyText": "Handle method removed :)", "author": "Nana-EC", "createdAt": "2020-08-20T17:50:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDU0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -137,30 +128,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         liveHashes = new ArrayList<>();\n         entityIds = new HashSet<>();\n         topicMessages = new ArrayList<>();\n-        partialRecordFile = null;\n     }\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n-        String fileName = FilenameUtils.getName(streamFileData.getFilename());\n-\n-        List<RecordFile> matchingRecords = recordFileRepository.findByName(fileName);\n-        partialRecordFile = null;\n-        if (matchingRecords.size() > 0) {\n-            partialRecordFile = matchingRecords.get(0); // cache to avoid jpa exception\n-            handleDuplicateOrPartiallyProcessedRecordFile(partialRecordFile);\n-        }\n-\n         try {\n             cleanup();\n-            connection = dataSource.getConnection();\n-            connection.setAutoCommit(false);\n-            connection.setClientInfo(\"ApplicationName\", getClass().getSimpleName());\n-\n-            sqlInsertEntityId = connection.prepareStatement(\"INSERT INTO t_entities \" +\n-                    \"(id, entity_shard, entity_realm, entity_num, fk_entity_type_id) \" +\n-                    \"VALUES (?, ?, ?, ?, ?) \" +\n-                    \"ON CONFLICT DO NOTHING\");\n+            connection = DataSourceUtils.getConnection(dataSource);\n \n             sqlNotifyTopicMessage = connection.prepareStatement(\"select pg_notify('topic_message', ?)\");\n         } catch (SQLException e) {\n", "next_change": {"commit": "9c13a19e8f4506ecdb2519a1e45a45f61dc34f56", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..7268051ae 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -131,28 +124,21 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     @Override\n-    public void onStart(StreamFileData streamFileData) {\n-        try {\n-            cleanup();\n-            connection = DataSourceUtils.getConnection(dataSource);\n+    public boolean isEnabled() {\n+        return sqlProperties.isEnabled();\n+    }\n \n-            sqlNotifyTopicMessage = connection.prepareStatement(\"select pg_notify('topic_message', ?)\");\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(\"Error setting up connection to database\", e);\n-        }\n+    @Override\n+    public void onStart(StreamFileData streamFileData) {\n+        cleanup();\n     }\n \n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n-\n-        try {\n-            recordFileRepository.save(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-        } finally {\n-            cleanup();\n-        }\n+        recordFileRepository.save(recordFile);\n+        applicationStatusRepository.updateStatusValue(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n     }\n \n     @Override\n", "next_change": {"commit": "819a776dc0db274add954aa0be3f5f2f5da9cea5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7268051ae..cde6637b9 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -138,7 +159,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatches();\n         recordFileRepository.save(recordFile);\n         applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getCurrentHash());\n     }\n \n     @Override\n", "next_change": {"commit": "36243ea348fa9eababed6c651acd79c4c89856bf", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex cde6637b9..732777e2d 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -159,7 +169,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatches();\n         recordFileRepository.save(recordFile);\n         applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getCurrentHash());\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getHash());\n     }\n \n     @Override\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 732777e2d..d535e5fbf 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -156,20 +148,14 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     @Override\n-    public RecordFile onStart(StreamFileData streamFileData) {\n-        String fileName = FilenameUtils.getName(streamFileData.getFilename());\n-        RecordFile recordFile = recordFileRepository.findByName(fileName)\n-                .orElseThrow(() -> new MissingFileException(\"File not found in the database: \" + fileName));\n+    public void onStart() {\n         cleanup();\n-        return recordFile;\n     }\n \n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n         recordFileRepository.save(recordFile);\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getHash());\n     }\n \n     @Override\n", "next_change": {"commit": "6e531c54b1c52932324da85786f173e9d98dcabc", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d535e5fbf..b59f638ce 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -164,17 +183,24 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     private void cleanup() {\n-        contractResults.clear();\n-        cryptoTransfers.clear();\n-        entityIds.clear();\n-        fileData.clear();\n-        liveHashes.clear();\n-        nonFeeTransfers.clear();\n-        topicMessages.clear();\n-        transactions.clear();\n-        tokenTransfers.clear();\n-        scheduleSignatures.clear();\n-        eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n+        try {\n+            contractResults.clear();\n+            cryptoTransfers.clear();\n+            entities.clear();\n+            fileData.clear();\n+            liveHashes.clear();\n+            nonFeeTransfers.clear();\n+            schedules.clear();\n+            topicMessages.clear();\n+            transactions.clear();\n+            tokenAccounts.clear();\n+            tokens.clear();\n+            tokenTransfers.clear();\n+            transactionSignatures.clear();\n+            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n+        } catch (BeanCreationNotAllowedException e) {\n+            // This error can occur during shutdown\n+        }\n     }\n \n     private void executeBatches() {\n", "next_change": {"commit": "95b5209ec65eb0489fcce60b78fd3059da3b5f44", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex b59f638ce..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -204,31 +196,41 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     private void executeBatches() {\n-        Connection connection = null;\n-\n         try {\n             // batch save action may run asynchronously, triggering it before other operations can reduce latency\n             eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n \n-            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n-            contractResultPgCopy.copy(contractResults, connection);\n-            cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            fileDataPgCopy.copy(fileData, connection);\n-            liveHashPgCopy.copy(liveHashes, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n-            transactionPgCopy.copy(transactions, connection);\n-            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n-\n-            // insert operations with conflict management for updates\n-            entityPgCopy.copy(entities.values(), connection);\n-            schedulePgCopy.copy(schedules.values(), connection);\n-            tokenPgCopy.copy(tokens.values(), connection);\n-            tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n+            batchPersister.persist(assessedCustomFees);\n+            batchPersister.persist(contractLogs);\n+            batchPersister.persist(contractResults);\n+            batchPersister.persist(cryptoTransfers);\n+            batchPersister.persist(customFees);\n+            batchPersister.persist(fileData);\n+            batchPersister.persist(liveHashes);\n+            batchPersister.persist(topicMessages);\n+            batchPersister.persist(transactions);\n+            batchPersister.persist(transactionSignatures);\n+\n+            // insert operations with conflict management\n+            batchPersister.persist(contracts.values());\n+            batchPersister.persist(entities.values());\n+            batchPersister.persist(tokens.values());\n+            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n+            batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(nfts.values()); // persist nft after token entity\n+            batchPersister.persist(schedules.values());\n+\n+            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n+            batchPersister.persist(nonFeeTransfers);\n+            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(tokenTransfers);\n+\n+            // handle the transfers from token dissociate transactions after nft is processed\n+            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -195,52 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n-            batchPersister.persist(entities.values());\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEwMDAyMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r473100020", "body": "Filesystem is case sensitive so comparison should be as well.", "bodyText": "Filesystem is case sensitive so comparison should be as well.", "bodyHTML": "<p dir=\"auto\">Filesystem is case sensitive so comparison should be as well.</p>", "author": "steven-sheehy", "createdAt": "2020-08-19T15:04:41Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -314,6 +339,65 @@ private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n+    /**\n+     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n+     * java sql operations. Check whether the given file was partially processed and matches the last record file\n+     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n+     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n+     * handle case where transaction data was rolled bach but not record_file entry\n+     *\n+     * @param recordFile record file object that was partially processed file\n+     */\n+    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n+        // handle faulty transaction management between spring repositories and manual java sql operations\n+        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n+                \"database: \" + recordFile.getName());\n+        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n+        String lastRecordFileHash =\n+                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+\n+        // check if latest record file is a match processed file by comparing name and hash\n+        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2NzM5MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474167391", "bodyText": "No longer applicable.", "author": "Nana-EC", "createdAt": "2020-08-20T17:51:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEwMDAyMA=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -331,75 +286,15 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     private void persistEntities() {\n-        executeBatch(sqlInsertEntityId, \"entities\");\n-        entityIds.forEach(entityId -> entityCache.put(entityId.getId(), null));\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        entityIds.forEach(entityId -> {\n+            entityRepository.insertEntityId(entityId);\n+            entityCache.put(entityId, null);\n+        });\n+        log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n     }\n \n     private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n-\n-    /**\n-     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n-     * java sql operations. Check whether the given file was partially processed and matches the last record file\n-     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n-     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n-     * handle case where transaction data was rolled bach but not record_file entry\n-     *\n-     * @param recordFile record file object that was partially processed file\n-     */\n-    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n-        // handle faulty transaction management between spring repositories and manual java sql operations\n-        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n-                \"database: \" + recordFile.getName());\n-        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n-        String lastRecordFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-\n-        // check if latest record file is a match processed file by comparing name and hash\n-        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n-                !Utility.verifyHashChain(\n-                        latestRecordFile.getFileHash(),\n-                        lastRecordFileHash,\n-                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                        recordFile.getName())) {\n-\n-            // check if this file is next in line of hash chain\n-            // Assumes application status updates after record_file update which is current process\n-            if (Utility.verifyHashChain(\n-                    latestRecordFile.getPreviousHash(),\n-                    lastRecordFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordFile.getName())) {\n-                // application_status outdated\n-                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n-                applicationStatusRepository.updateStatusValue(\n-                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n-                throw duplicateFileException;\n-            } else {\n-                // very unlikely edge case\n-                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n-                        .getName());\n-                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n-                        .getFileHash());\n-            }\n-        } else {\n-            // check if transactions are already present\n-            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n-                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n-                throw duplicateFileException;\n-            }\n-        }\n-\n-        // allow file processing but update to previous hash\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n-        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n-                recordFile.getName());\n-    }\n-\n-    enum F_ENTITY_ID {\n-        ZERO, // column indices start at 1, this creates the necessary offset\n-        ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n-    }\n }\n", "next_change": {"commit": "9c13a19e8f4506ecdb2519a1e45a45f61dc34f56", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..7268051ae 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -293,8 +239,4 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         });\n         log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n     }\n-\n-    private void notifyTopicMessages() {\n-        executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n-    }\n }\n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7268051ae..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -231,12 +284,131 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         liveHashes.add(liveHash);\n     }\n \n-    private void persistEntities() {\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n-        entityIds.forEach(entityId -> {\n-            entityRepository.insertEntityId(entityId);\n-            entityCache.put(entityId, null);\n-        });\n-        log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n+    @Override\n+    public void onToken(Token token) throws ImporterException {\n+        // tokens could experience multiple updates in a single record file, handle updates in memory for this case\n+        tokens.merge(token.getTokenId().getTokenId().getId(), token, this::mergeToken);\n+    }\n+\n+    @Override\n+    public void onTokenAccount(TokenAccount tokenAccount) throws ImporterException {\n+        // tokenAccounts may experience multiple updates in a single record file, handle updates in memory for this case\n+        tokenAccounts.merge(tokenAccount.getId(), tokenAccount, this::mergeTokenAccount);\n+    }\n+\n+    @Override\n+    public void onTokenTransfer(TokenTransfer tokenTransfer) throws ImporterException {\n+        tokenTransfers.add(tokenTransfer);\n+    }\n+\n+    @Override\n+    public void onSchedule(Schedule schedule) throws ImporterException {\n+        // schedules could experience multiple updates in a single record file, handle updates in memory for this case\n+        schedules.merge(schedule.getScheduleId().getId(), schedule, this::mergeSchedule);\n+    }\n+\n+    @Override\n+    public void onTransactionSignature(TransactionSignature transactionSignature) throws ImporterException {\n+        transactionSignatures.add(transactionSignature);\n+    }\n+\n+    private Entity mergeEntity(Entity cachedEntity, Entity newEntity) {\n+        if (newEntity.getAutoRenewAccountId() != null) {\n+            cachedEntity.setAutoRenewAccountId(newEntity.getAutoRenewAccountId());\n+        }\n+\n+        if (newEntity.getAutoRenewPeriod() != null) {\n+            cachedEntity.setAutoRenewPeriod(newEntity.getAutoRenewPeriod());\n+        }\n+\n+        if (newEntity.getDeleted() != null) {\n+            cachedEntity.setDeleted(newEntity.getDeleted());\n+        }\n+\n+        if (newEntity.getExpirationTimestamp() != null) {\n+            cachedEntity.setExpirationTimestamp(newEntity.getExpirationTimestamp());\n+        }\n+\n+        if (newEntity.getKey() != null) {\n+            cachedEntity.setKey(newEntity.getKey());\n+            cachedEntity.setPublicKey(newEntity.getPublicKey());\n+        }\n+\n+        if (newEntity.getMemo() != null) {\n+            cachedEntity.setMemo(newEntity.getMemo());\n+        }\n+\n+        if (newEntity.getModifiedTimestamp() != null) {\n+            cachedEntity.setModifiedTimestamp(newEntity.getModifiedTimestamp());\n+        }\n+\n+        if (newEntity.getProxyAccountId() != null) {\n+            cachedEntity.setProxyAccountId(newEntity.getProxyAccountId());\n+        }\n+\n+        if (newEntity.getSubmitKey() != null) {\n+            cachedEntity.setSubmitKey(newEntity.getSubmitKey());\n+        }\n+\n+        return cachedEntity;\n+    }\n+\n+    private Token mergeToken(Token cachedToken, Token newToken) {\n+        if (newToken.getFreezeKey() != null) {\n+            cachedToken.setFreezeKey(newToken.getFreezeKey());\n+        }\n+\n+        if (newToken.getKycKey() != null) {\n+            cachedToken.setKycKey(newToken.getKycKey());\n+        }\n+\n+        if (newToken.getName() != null) {\n+            cachedToken.setName(newToken.getName());\n+        }\n+\n+        if (newToken.getSymbol() != null) {\n+            cachedToken.setSymbol(newToken.getSymbol());\n+        }\n+\n+        if (newToken.getTotalSupply() != null) {\n+            cachedToken.setTotalSupply(newToken.getTotalSupply());\n+        }\n+\n+        if (newToken.getTreasuryAccountId() != null) {\n+            cachedToken.setTreasuryAccountId(newToken.getTreasuryAccountId());\n+        }\n+\n+        if (newToken.getSupplyKey() != null) {\n+            cachedToken.setSupplyKey(newToken.getSupplyKey());\n+        }\n+\n+        if (newToken.getWipeKey() != null) {\n+            cachedToken.setWipeKey(newToken.getWipeKey());\n+        }\n+\n+        cachedToken.setModifiedTimestamp(newToken.getModifiedTimestamp());\n+        return cachedToken;\n+    }\n+\n+    private TokenAccount mergeTokenAccount(TokenAccount cachedTokenAccount, TokenAccount newTokenAccount) {\n+        if (newTokenAccount.getAssociated() != null) {\n+            cachedTokenAccount.setAssociated(newTokenAccount.getAssociated());\n+        }\n+\n+        if (newTokenAccount.getFreezeStatus() != null) {\n+            cachedTokenAccount.setFreezeStatus(newTokenAccount.getFreezeStatus());\n+        }\n+\n+        if (newTokenAccount.getKycStatus() != null) {\n+            cachedTokenAccount.setKycStatus(newTokenAccount.getKycStatus());\n+        }\n+\n+        cachedTokenAccount.setModifiedTimestamp(newTokenAccount.getModifiedTimestamp());\n+        return cachedTokenAccount;\n+    }\n+\n+    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n+        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n+        return cachedSchedule;\n     }\n }\n", "next_change": {"commit": "643f0c788bf111205c08f13d5fd38c8e3ffc6e12", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..5e26ce111 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -406,9 +461,4 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cachedTokenAccount.setModifiedTimestamp(newTokenAccount.getModifiedTimestamp());\n         return cachedTokenAccount;\n     }\n-\n-    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n-        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n-        return cachedSchedule;\n-    }\n }\n", "next_change": {"commit": "f12c4518fb054eda37fcb89741938bd80c6faf43", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5e26ce111..134ba9c9c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -361,104 +371,4 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onTransactionSignature(TransactionSignature transactionSignature) throws ImporterException {\n         transactionSignatures.add(transactionSignature);\n     }\n-\n-    private Entity mergeEntity(Entity cachedEntity, Entity newEntity) {\n-        if (newEntity.getAutoRenewAccountId() != null) {\n-            cachedEntity.setAutoRenewAccountId(newEntity.getAutoRenewAccountId());\n-        }\n-\n-        if (newEntity.getAutoRenewPeriod() != null) {\n-            cachedEntity.setAutoRenewPeriod(newEntity.getAutoRenewPeriod());\n-        }\n-\n-        if (newEntity.getDeleted() != null) {\n-            cachedEntity.setDeleted(newEntity.getDeleted());\n-        }\n-\n-        if (newEntity.getExpirationTimestamp() != null) {\n-            cachedEntity.setExpirationTimestamp(newEntity.getExpirationTimestamp());\n-        }\n-\n-        if (newEntity.getKey() != null) {\n-            cachedEntity.setKey(newEntity.getKey());\n-            cachedEntity.setPublicKey(newEntity.getPublicKey());\n-        }\n-\n-        if (newEntity.getMemo() != null) {\n-            cachedEntity.setMemo(newEntity.getMemo());\n-        }\n-\n-        if (newEntity.getModifiedTimestamp() != null) {\n-            cachedEntity.setModifiedTimestamp(newEntity.getModifiedTimestamp());\n-        }\n-\n-        if (newEntity.getProxyAccountId() != null) {\n-            cachedEntity.setProxyAccountId(newEntity.getProxyAccountId());\n-        }\n-\n-        if (newEntity.getSubmitKey() != null) {\n-            cachedEntity.setSubmitKey(newEntity.getSubmitKey());\n-        }\n-\n-        return cachedEntity;\n-    }\n-\n-    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n-        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n-        return cachedSchedule;\n-    }\n-\n-    private Token mergeToken(Token cachedToken, Token newToken) {\n-        if (newToken.getFreezeKey() != null) {\n-            cachedToken.setFreezeKey(newToken.getFreezeKey());\n-        }\n-\n-        if (newToken.getKycKey() != null) {\n-            cachedToken.setKycKey(newToken.getKycKey());\n-        }\n-\n-        if (newToken.getName() != null) {\n-            cachedToken.setName(newToken.getName());\n-        }\n-\n-        if (newToken.getSymbol() != null) {\n-            cachedToken.setSymbol(newToken.getSymbol());\n-        }\n-\n-        if (newToken.getTotalSupply() != null) {\n-            cachedToken.setTotalSupply(newToken.getTotalSupply());\n-        }\n-\n-        if (newToken.getTreasuryAccountId() != null) {\n-            cachedToken.setTreasuryAccountId(newToken.getTreasuryAccountId());\n-        }\n-\n-        if (newToken.getSupplyKey() != null) {\n-            cachedToken.setSupplyKey(newToken.getSupplyKey());\n-        }\n-\n-        if (newToken.getWipeKey() != null) {\n-            cachedToken.setWipeKey(newToken.getWipeKey());\n-        }\n-\n-        cachedToken.setModifiedTimestamp(newToken.getModifiedTimestamp());\n-        return cachedToken;\n-    }\n-\n-    private TokenAccount mergeTokenAccount(TokenAccount cachedTokenAccount, TokenAccount newTokenAccount) {\n-        if (newTokenAccount.getAssociated() != null) {\n-            cachedTokenAccount.setAssociated(newTokenAccount.getAssociated());\n-        }\n-\n-        if (newTokenAccount.getFreezeStatus() != null) {\n-            cachedTokenAccount.setFreezeStatus(newTokenAccount.getFreezeStatus());\n-        }\n-\n-        if (newTokenAccount.getKycStatus() != null) {\n-            cachedTokenAccount.setKycStatus(newTokenAccount.getKycStatus());\n-        }\n-\n-        cachedTokenAccount.setModifiedTimestamp(newTokenAccount.getModifiedTimestamp());\n-        return cachedTokenAccount;\n-    }\n }\n", "next_change": {"commit": "85cf2c002ce7575420b3e95865d5d01eb8608297", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 134ba9c9c..7aa8e4dd5 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -371,4 +397,160 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n     public void onTransactionSignature(TransactionSignature transactionSignature) throws ImporterException {\n         transactionSignatures.add(transactionSignature);\n     }\n+\n+    private Entity mergeEntity(Entity cachedEntity, Entity newEntity) {\n+        if (newEntity.getAutoRenewAccountId() != null) {\n+            cachedEntity.setAutoRenewAccountId(newEntity.getAutoRenewAccountId());\n+        }\n+\n+        if (newEntity.getAutoRenewPeriod() != null) {\n+            cachedEntity.setAutoRenewPeriod(newEntity.getAutoRenewPeriod());\n+        }\n+\n+        if (newEntity.getCreatedTimestamp() != null) {\n+            // it's possible when processing transactions, an entity is populated with the minimum amount of info and\n+            // gets inserted to the cache before a later fully populated entity object of the same id. So set the\n+            // created timestamp if the new entity object has it set.\n+            cachedEntity.setCreatedTimestamp(newEntity.getCreatedTimestamp());\n+        }\n+\n+        if (newEntity.getDeleted() != null) {\n+            cachedEntity.setDeleted(newEntity.getDeleted());\n+        }\n+\n+        if (newEntity.getExpirationTimestamp() != null) {\n+            cachedEntity.setExpirationTimestamp(newEntity.getExpirationTimestamp());\n+        }\n+\n+        if (newEntity.getKey() != null) {\n+            cachedEntity.setKey(newEntity.getKey());\n+            cachedEntity.setPublicKey(newEntity.getPublicKey());\n+        }\n+\n+        if (newEntity.getMemo() != null) {\n+            cachedEntity.setMemo(newEntity.getMemo());\n+        }\n+\n+        if (newEntity.getProxyAccountId() != null) {\n+            cachedEntity.setProxyAccountId(newEntity.getProxyAccountId());\n+        }\n+\n+        if (newEntity.getSubmitKey() != null) {\n+            cachedEntity.setSubmitKey(newEntity.getSubmitKey());\n+        }\n+\n+        if (newEntity.getTimestampRange() != null && (cachedEntity.getTimestampRange() == null ||\n+                newEntity.getModifiedTimestamp() >= cachedEntity.getModifiedTimestamp())) {\n+            cachedEntity.setTimestampRange(newEntity.getTimestampRange());\n+        }\n+\n+        return cachedEntity;\n+    }\n+\n+    private Nft mergeNft(Nft cachedNft, Nft newNft) {\n+        if (cachedNft.getCreatedTimestamp() == null && newNft.getCreatedTimestamp() != null) {\n+            cachedNft.setCreatedTimestamp(newNft.getCreatedTimestamp());\n+        }\n+\n+        if (newNft.getAccountId() != null) { // only domains generated by NftTransfers should set account\n+            cachedNft.setAccountId(newNft.getAccountId());\n+        }\n+\n+        if (newNft.getDeleted() != null) {\n+            cachedNft.setDeleted(newNft.getDeleted());\n+        }\n+\n+        if (newNft.getMetadata() != null) {\n+            cachedNft.setMetadata(newNft.getMetadata());\n+        }\n+\n+        cachedNft.setModifiedTimestamp(newNft.getModifiedTimestamp());\n+        return cachedNft;\n+    }\n+\n+    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n+        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n+        return cachedSchedule;\n+    }\n+\n+    private Token mergeToken(Token cachedToken, Token newToken) {\n+        if (newToken.getFreezeKey() != null) {\n+            cachedToken.setFreezeKey(newToken.getFreezeKey());\n+        }\n+\n+        if (newToken.getKycKey() != null) {\n+            cachedToken.setKycKey(newToken.getKycKey());\n+        }\n+\n+        if (newToken.getName() != null) {\n+            cachedToken.setName(newToken.getName());\n+        }\n+\n+        if (newToken.getPauseKey() != null) {\n+            cachedToken.setPauseKey(newToken.getPauseKey());\n+        }\n+\n+        if (newToken.getPauseStatus() != null) {\n+            cachedToken.setPauseStatus(newToken.getPauseStatus());\n+        }\n+\n+        if (newToken.getSupplyKey() != null) {\n+            cachedToken.setSupplyKey(newToken.getSupplyKey());\n+        }\n+\n+        if (newToken.getSymbol() != null) {\n+            cachedToken.setSymbol(newToken.getSymbol());\n+        }\n+\n+        if (newToken.getTotalSupply() != null) {\n+            Long newTotalSupply = newToken.getTotalSupply();\n+            if (cachedToken.getTotalSupply() != null && newTotalSupply < 0) {\n+                // if the cached token has total supply set, and the new total supply is negative because it's an update\n+                // from the token transfer of a token dissociate of a deleted token, aggregate the change\n+                cachedToken.setTotalSupply(cachedToken.getTotalSupply() + newTotalSupply);\n+            } else {\n+                // if the cached token doesn't have total supply or the new total supply is non-negative, set it to the\n+                // new token's total supply. Later step should apply the change on the current total supply in db if\n+                // the value is negative.\n+                cachedToken.setTotalSupply(newToken.getTotalSupply());\n+            }\n+        }\n+\n+        if (newToken.getTreasuryAccountId() != null) {\n+            cachedToken.setTreasuryAccountId(newToken.getTreasuryAccountId());\n+        }\n+\n+        if (newToken.getWipeKey() != null) {\n+            cachedToken.setWipeKey(newToken.getWipeKey());\n+        }\n+\n+        cachedToken.setModifiedTimestamp(newToken.getModifiedTimestamp());\n+        return cachedToken;\n+    }\n+\n+    private TokenAccount mergeTokenAccount(TokenAccount lastTokenAccount, TokenAccount newTokenAccount) {\n+        if (newTokenAccount.getCreatedTimestamp() != null) {\n+            return newTokenAccount;\n+        }\n+\n+        // newTokenAccount is a partial update. It must have its id (tokenId, accountId, modifiedTimestamp) set.\n+        // copy the lifespan immutable fields createdTimestamp and automaticAssociation from the last snapshot.\n+        // copy other fields from the last snapshot if not set in newTokenAccount\n+        newTokenAccount.setCreatedTimestamp(lastTokenAccount.getCreatedTimestamp());\n+        newTokenAccount.setAutomaticAssociation(lastTokenAccount.getAutomaticAssociation());\n+\n+        if (newTokenAccount.getAssociated() == null) {\n+            newTokenAccount.setAssociated(lastTokenAccount.getAssociated());\n+        }\n+\n+        if (newTokenAccount.getFreezeStatus() == null) {\n+            newTokenAccount.setFreezeStatus(lastTokenAccount.getFreezeStatus());\n+        }\n+\n+        if (newTokenAccount.getKycStatus() == null) {\n+            newTokenAccount.setKycStatus(lastTokenAccount.getKycStatus());\n+        }\n+\n+        return newTokenAccount;\n+    }\n }\n", "next_change": {"commit": "65b7f5080f7746a638793b600e0ce50fd106b33c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7aa8e4dd5..90f63e8ac 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -553,4 +601,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n         return newTokenAccount;\n     }\n+\n+    private TokenAllowance mergeTokenAllowance(TokenAllowance previous, TokenAllowance current) {\n+        previous.setTimestampUpper(current.getTimestampLower());\n+        return current;\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEwMzMzMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r473103332", "body": "I don't see any point to this method. It only recovers from the scenario when record file saves but application status does not. This scenario can be easily handled by putting a `@Transactional` on `onEnd()` to ensure they're committed together. There shouldn't be any problem with that approach since they're both repositories.", "bodyText": "I don't see any point to this method. It only recovers from the scenario when record file saves but application status does not. This scenario can be easily handled by putting a @Transactional on onEnd() to ensure they're committed together. There shouldn't be any problem with that approach since they're both repositories.", "bodyHTML": "<p dir=\"auto\">I don't see any point to this method. It only recovers from the scenario when record file saves but application status does not. This scenario can be easily handled by putting a <code>@Transactional</code> on <code>onEnd()</code> to ensure they're committed together. There shouldn't be any problem with that approach since they're both repositories.</p>", "author": "steven-sheehy", "createdAt": "2020-08-19T15:09:18Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -314,6 +339,65 @@ private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n+    /**\n+     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n+     * java sql operations. Check whether the given file was partially processed and matches the last record file\n+     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n+     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n+     * handle case where transaction data was rolled bach but not record_file entry\n+     *\n+     * @param recordFile record file object that was partially processed file\n+     */\n+    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -331,75 +286,15 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     private void persistEntities() {\n-        executeBatch(sqlInsertEntityId, \"entities\");\n-        entityIds.forEach(entityId -> entityCache.put(entityId.getId(), null));\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        entityIds.forEach(entityId -> {\n+            entityRepository.insertEntityId(entityId);\n+            entityCache.put(entityId, null);\n+        });\n+        log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n     }\n \n     private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n-\n-    /**\n-     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n-     * java sql operations. Check whether the given file was partially processed and matches the last record file\n-     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n-     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n-     * handle case where transaction data was rolled bach but not record_file entry\n-     *\n-     * @param recordFile record file object that was partially processed file\n-     */\n-    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n-        // handle faulty transaction management between spring repositories and manual java sql operations\n-        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n-                \"database: \" + recordFile.getName());\n-        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n-        String lastRecordFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-\n-        // check if latest record file is a match processed file by comparing name and hash\n-        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n-                !Utility.verifyHashChain(\n-                        latestRecordFile.getFileHash(),\n-                        lastRecordFileHash,\n-                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                        recordFile.getName())) {\n-\n-            // check if this file is next in line of hash chain\n-            // Assumes application status updates after record_file update which is current process\n-            if (Utility.verifyHashChain(\n-                    latestRecordFile.getPreviousHash(),\n-                    lastRecordFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordFile.getName())) {\n-                // application_status outdated\n-                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n-                applicationStatusRepository.updateStatusValue(\n-                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n-                throw duplicateFileException;\n-            } else {\n-                // very unlikely edge case\n-                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n-                        .getName());\n-                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n-                        .getFileHash());\n-            }\n-        } else {\n-            // check if transactions are already present\n-            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n-                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n-                throw duplicateFileException;\n-            }\n-        }\n-\n-        // allow file processing but update to previous hash\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n-        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n-                recordFile.getName());\n-    }\n-\n-    enum F_ENTITY_ID {\n-        ZERO, // column indices start at 1, this creates the necessary offset\n-        ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n-    }\n }\n", "next_change": {"commit": "9c13a19e8f4506ecdb2519a1e45a45f61dc34f56", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..7268051ae 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -293,8 +239,4 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         });\n         log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n     }\n-\n-    private void notifyTopicMessages() {\n-        executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n-    }\n }\n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7268051ae..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -231,12 +284,131 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         liveHashes.add(liveHash);\n     }\n \n-    private void persistEntities() {\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n-        entityIds.forEach(entityId -> {\n-            entityRepository.insertEntityId(entityId);\n-            entityCache.put(entityId, null);\n-        });\n-        log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n+    @Override\n+    public void onToken(Token token) throws ImporterException {\n+        // tokens could experience multiple updates in a single record file, handle updates in memory for this case\n+        tokens.merge(token.getTokenId().getTokenId().getId(), token, this::mergeToken);\n+    }\n+\n+    @Override\n+    public void onTokenAccount(TokenAccount tokenAccount) throws ImporterException {\n+        // tokenAccounts may experience multiple updates in a single record file, handle updates in memory for this case\n+        tokenAccounts.merge(tokenAccount.getId(), tokenAccount, this::mergeTokenAccount);\n+    }\n+\n+    @Override\n+    public void onTokenTransfer(TokenTransfer tokenTransfer) throws ImporterException {\n+        tokenTransfers.add(tokenTransfer);\n+    }\n+\n+    @Override\n+    public void onSchedule(Schedule schedule) throws ImporterException {\n+        // schedules could experience multiple updates in a single record file, handle updates in memory for this case\n+        schedules.merge(schedule.getScheduleId().getId(), schedule, this::mergeSchedule);\n+    }\n+\n+    @Override\n+    public void onTransactionSignature(TransactionSignature transactionSignature) throws ImporterException {\n+        transactionSignatures.add(transactionSignature);\n+    }\n+\n+    private Entity mergeEntity(Entity cachedEntity, Entity newEntity) {\n+        if (newEntity.getAutoRenewAccountId() != null) {\n+            cachedEntity.setAutoRenewAccountId(newEntity.getAutoRenewAccountId());\n+        }\n+\n+        if (newEntity.getAutoRenewPeriod() != null) {\n+            cachedEntity.setAutoRenewPeriod(newEntity.getAutoRenewPeriod());\n+        }\n+\n+        if (newEntity.getDeleted() != null) {\n+            cachedEntity.setDeleted(newEntity.getDeleted());\n+        }\n+\n+        if (newEntity.getExpirationTimestamp() != null) {\n+            cachedEntity.setExpirationTimestamp(newEntity.getExpirationTimestamp());\n+        }\n+\n+        if (newEntity.getKey() != null) {\n+            cachedEntity.setKey(newEntity.getKey());\n+            cachedEntity.setPublicKey(newEntity.getPublicKey());\n+        }\n+\n+        if (newEntity.getMemo() != null) {\n+            cachedEntity.setMemo(newEntity.getMemo());\n+        }\n+\n+        if (newEntity.getModifiedTimestamp() != null) {\n+            cachedEntity.setModifiedTimestamp(newEntity.getModifiedTimestamp());\n+        }\n+\n+        if (newEntity.getProxyAccountId() != null) {\n+            cachedEntity.setProxyAccountId(newEntity.getProxyAccountId());\n+        }\n+\n+        if (newEntity.getSubmitKey() != null) {\n+            cachedEntity.setSubmitKey(newEntity.getSubmitKey());\n+        }\n+\n+        return cachedEntity;\n+    }\n+\n+    private Token mergeToken(Token cachedToken, Token newToken) {\n+        if (newToken.getFreezeKey() != null) {\n+            cachedToken.setFreezeKey(newToken.getFreezeKey());\n+        }\n+\n+        if (newToken.getKycKey() != null) {\n+            cachedToken.setKycKey(newToken.getKycKey());\n+        }\n+\n+        if (newToken.getName() != null) {\n+            cachedToken.setName(newToken.getName());\n+        }\n+\n+        if (newToken.getSymbol() != null) {\n+            cachedToken.setSymbol(newToken.getSymbol());\n+        }\n+\n+        if (newToken.getTotalSupply() != null) {\n+            cachedToken.setTotalSupply(newToken.getTotalSupply());\n+        }\n+\n+        if (newToken.getTreasuryAccountId() != null) {\n+            cachedToken.setTreasuryAccountId(newToken.getTreasuryAccountId());\n+        }\n+\n+        if (newToken.getSupplyKey() != null) {\n+            cachedToken.setSupplyKey(newToken.getSupplyKey());\n+        }\n+\n+        if (newToken.getWipeKey() != null) {\n+            cachedToken.setWipeKey(newToken.getWipeKey());\n+        }\n+\n+        cachedToken.setModifiedTimestamp(newToken.getModifiedTimestamp());\n+        return cachedToken;\n+    }\n+\n+    private TokenAccount mergeTokenAccount(TokenAccount cachedTokenAccount, TokenAccount newTokenAccount) {\n+        if (newTokenAccount.getAssociated() != null) {\n+            cachedTokenAccount.setAssociated(newTokenAccount.getAssociated());\n+        }\n+\n+        if (newTokenAccount.getFreezeStatus() != null) {\n+            cachedTokenAccount.setFreezeStatus(newTokenAccount.getFreezeStatus());\n+        }\n+\n+        if (newTokenAccount.getKycStatus() != null) {\n+            cachedTokenAccount.setKycStatus(newTokenAccount.getKycStatus());\n+        }\n+\n+        cachedTokenAccount.setModifiedTimestamp(newTokenAccount.getModifiedTimestamp());\n+        return cachedTokenAccount;\n+    }\n+\n+    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n+        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n+        return cachedSchedule;\n     }\n }\n", "next_change": {"commit": "643f0c788bf111205c08f13d5fd38c8e3ffc6e12", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..5e26ce111 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -406,9 +461,4 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cachedTokenAccount.setModifiedTimestamp(newTokenAccount.getModifiedTimestamp());\n         return cachedTokenAccount;\n     }\n-\n-    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n-        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n-        return cachedSchedule;\n-    }\n }\n", "next_change": {"commit": "f12c4518fb054eda37fcb89741938bd80c6faf43", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5e26ce111..134ba9c9c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -361,104 +371,4 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onTransactionSignature(TransactionSignature transactionSignature) throws ImporterException {\n         transactionSignatures.add(transactionSignature);\n     }\n-\n-    private Entity mergeEntity(Entity cachedEntity, Entity newEntity) {\n-        if (newEntity.getAutoRenewAccountId() != null) {\n-            cachedEntity.setAutoRenewAccountId(newEntity.getAutoRenewAccountId());\n-        }\n-\n-        if (newEntity.getAutoRenewPeriod() != null) {\n-            cachedEntity.setAutoRenewPeriod(newEntity.getAutoRenewPeriod());\n-        }\n-\n-        if (newEntity.getDeleted() != null) {\n-            cachedEntity.setDeleted(newEntity.getDeleted());\n-        }\n-\n-        if (newEntity.getExpirationTimestamp() != null) {\n-            cachedEntity.setExpirationTimestamp(newEntity.getExpirationTimestamp());\n-        }\n-\n-        if (newEntity.getKey() != null) {\n-            cachedEntity.setKey(newEntity.getKey());\n-            cachedEntity.setPublicKey(newEntity.getPublicKey());\n-        }\n-\n-        if (newEntity.getMemo() != null) {\n-            cachedEntity.setMemo(newEntity.getMemo());\n-        }\n-\n-        if (newEntity.getModifiedTimestamp() != null) {\n-            cachedEntity.setModifiedTimestamp(newEntity.getModifiedTimestamp());\n-        }\n-\n-        if (newEntity.getProxyAccountId() != null) {\n-            cachedEntity.setProxyAccountId(newEntity.getProxyAccountId());\n-        }\n-\n-        if (newEntity.getSubmitKey() != null) {\n-            cachedEntity.setSubmitKey(newEntity.getSubmitKey());\n-        }\n-\n-        return cachedEntity;\n-    }\n-\n-    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n-        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n-        return cachedSchedule;\n-    }\n-\n-    private Token mergeToken(Token cachedToken, Token newToken) {\n-        if (newToken.getFreezeKey() != null) {\n-            cachedToken.setFreezeKey(newToken.getFreezeKey());\n-        }\n-\n-        if (newToken.getKycKey() != null) {\n-            cachedToken.setKycKey(newToken.getKycKey());\n-        }\n-\n-        if (newToken.getName() != null) {\n-            cachedToken.setName(newToken.getName());\n-        }\n-\n-        if (newToken.getSymbol() != null) {\n-            cachedToken.setSymbol(newToken.getSymbol());\n-        }\n-\n-        if (newToken.getTotalSupply() != null) {\n-            cachedToken.setTotalSupply(newToken.getTotalSupply());\n-        }\n-\n-        if (newToken.getTreasuryAccountId() != null) {\n-            cachedToken.setTreasuryAccountId(newToken.getTreasuryAccountId());\n-        }\n-\n-        if (newToken.getSupplyKey() != null) {\n-            cachedToken.setSupplyKey(newToken.getSupplyKey());\n-        }\n-\n-        if (newToken.getWipeKey() != null) {\n-            cachedToken.setWipeKey(newToken.getWipeKey());\n-        }\n-\n-        cachedToken.setModifiedTimestamp(newToken.getModifiedTimestamp());\n-        return cachedToken;\n-    }\n-\n-    private TokenAccount mergeTokenAccount(TokenAccount cachedTokenAccount, TokenAccount newTokenAccount) {\n-        if (newTokenAccount.getAssociated() != null) {\n-            cachedTokenAccount.setAssociated(newTokenAccount.getAssociated());\n-        }\n-\n-        if (newTokenAccount.getFreezeStatus() != null) {\n-            cachedTokenAccount.setFreezeStatus(newTokenAccount.getFreezeStatus());\n-        }\n-\n-        if (newTokenAccount.getKycStatus() != null) {\n-            cachedTokenAccount.setKycStatus(newTokenAccount.getKycStatus());\n-        }\n-\n-        cachedTokenAccount.setModifiedTimestamp(newTokenAccount.getModifiedTimestamp());\n-        return cachedTokenAccount;\n-    }\n }\n", "next_change": {"commit": "85cf2c002ce7575420b3e95865d5d01eb8608297", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 134ba9c9c..7aa8e4dd5 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -371,4 +397,160 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n     public void onTransactionSignature(TransactionSignature transactionSignature) throws ImporterException {\n         transactionSignatures.add(transactionSignature);\n     }\n+\n+    private Entity mergeEntity(Entity cachedEntity, Entity newEntity) {\n+        if (newEntity.getAutoRenewAccountId() != null) {\n+            cachedEntity.setAutoRenewAccountId(newEntity.getAutoRenewAccountId());\n+        }\n+\n+        if (newEntity.getAutoRenewPeriod() != null) {\n+            cachedEntity.setAutoRenewPeriod(newEntity.getAutoRenewPeriod());\n+        }\n+\n+        if (newEntity.getCreatedTimestamp() != null) {\n+            // it's possible when processing transactions, an entity is populated with the minimum amount of info and\n+            // gets inserted to the cache before a later fully populated entity object of the same id. So set the\n+            // created timestamp if the new entity object has it set.\n+            cachedEntity.setCreatedTimestamp(newEntity.getCreatedTimestamp());\n+        }\n+\n+        if (newEntity.getDeleted() != null) {\n+            cachedEntity.setDeleted(newEntity.getDeleted());\n+        }\n+\n+        if (newEntity.getExpirationTimestamp() != null) {\n+            cachedEntity.setExpirationTimestamp(newEntity.getExpirationTimestamp());\n+        }\n+\n+        if (newEntity.getKey() != null) {\n+            cachedEntity.setKey(newEntity.getKey());\n+            cachedEntity.setPublicKey(newEntity.getPublicKey());\n+        }\n+\n+        if (newEntity.getMemo() != null) {\n+            cachedEntity.setMemo(newEntity.getMemo());\n+        }\n+\n+        if (newEntity.getProxyAccountId() != null) {\n+            cachedEntity.setProxyAccountId(newEntity.getProxyAccountId());\n+        }\n+\n+        if (newEntity.getSubmitKey() != null) {\n+            cachedEntity.setSubmitKey(newEntity.getSubmitKey());\n+        }\n+\n+        if (newEntity.getTimestampRange() != null && (cachedEntity.getTimestampRange() == null ||\n+                newEntity.getModifiedTimestamp() >= cachedEntity.getModifiedTimestamp())) {\n+            cachedEntity.setTimestampRange(newEntity.getTimestampRange());\n+        }\n+\n+        return cachedEntity;\n+    }\n+\n+    private Nft mergeNft(Nft cachedNft, Nft newNft) {\n+        if (cachedNft.getCreatedTimestamp() == null && newNft.getCreatedTimestamp() != null) {\n+            cachedNft.setCreatedTimestamp(newNft.getCreatedTimestamp());\n+        }\n+\n+        if (newNft.getAccountId() != null) { // only domains generated by NftTransfers should set account\n+            cachedNft.setAccountId(newNft.getAccountId());\n+        }\n+\n+        if (newNft.getDeleted() != null) {\n+            cachedNft.setDeleted(newNft.getDeleted());\n+        }\n+\n+        if (newNft.getMetadata() != null) {\n+            cachedNft.setMetadata(newNft.getMetadata());\n+        }\n+\n+        cachedNft.setModifiedTimestamp(newNft.getModifiedTimestamp());\n+        return cachedNft;\n+    }\n+\n+    private Schedule mergeSchedule(Schedule cachedSchedule, Schedule schedule) {\n+        cachedSchedule.setExecutedTimestamp(schedule.getExecutedTimestamp());\n+        return cachedSchedule;\n+    }\n+\n+    private Token mergeToken(Token cachedToken, Token newToken) {\n+        if (newToken.getFreezeKey() != null) {\n+            cachedToken.setFreezeKey(newToken.getFreezeKey());\n+        }\n+\n+        if (newToken.getKycKey() != null) {\n+            cachedToken.setKycKey(newToken.getKycKey());\n+        }\n+\n+        if (newToken.getName() != null) {\n+            cachedToken.setName(newToken.getName());\n+        }\n+\n+        if (newToken.getPauseKey() != null) {\n+            cachedToken.setPauseKey(newToken.getPauseKey());\n+        }\n+\n+        if (newToken.getPauseStatus() != null) {\n+            cachedToken.setPauseStatus(newToken.getPauseStatus());\n+        }\n+\n+        if (newToken.getSupplyKey() != null) {\n+            cachedToken.setSupplyKey(newToken.getSupplyKey());\n+        }\n+\n+        if (newToken.getSymbol() != null) {\n+            cachedToken.setSymbol(newToken.getSymbol());\n+        }\n+\n+        if (newToken.getTotalSupply() != null) {\n+            Long newTotalSupply = newToken.getTotalSupply();\n+            if (cachedToken.getTotalSupply() != null && newTotalSupply < 0) {\n+                // if the cached token has total supply set, and the new total supply is negative because it's an update\n+                // from the token transfer of a token dissociate of a deleted token, aggregate the change\n+                cachedToken.setTotalSupply(cachedToken.getTotalSupply() + newTotalSupply);\n+            } else {\n+                // if the cached token doesn't have total supply or the new total supply is non-negative, set it to the\n+                // new token's total supply. Later step should apply the change on the current total supply in db if\n+                // the value is negative.\n+                cachedToken.setTotalSupply(newToken.getTotalSupply());\n+            }\n+        }\n+\n+        if (newToken.getTreasuryAccountId() != null) {\n+            cachedToken.setTreasuryAccountId(newToken.getTreasuryAccountId());\n+        }\n+\n+        if (newToken.getWipeKey() != null) {\n+            cachedToken.setWipeKey(newToken.getWipeKey());\n+        }\n+\n+        cachedToken.setModifiedTimestamp(newToken.getModifiedTimestamp());\n+        return cachedToken;\n+    }\n+\n+    private TokenAccount mergeTokenAccount(TokenAccount lastTokenAccount, TokenAccount newTokenAccount) {\n+        if (newTokenAccount.getCreatedTimestamp() != null) {\n+            return newTokenAccount;\n+        }\n+\n+        // newTokenAccount is a partial update. It must have its id (tokenId, accountId, modifiedTimestamp) set.\n+        // copy the lifespan immutable fields createdTimestamp and automaticAssociation from the last snapshot.\n+        // copy other fields from the last snapshot if not set in newTokenAccount\n+        newTokenAccount.setCreatedTimestamp(lastTokenAccount.getCreatedTimestamp());\n+        newTokenAccount.setAutomaticAssociation(lastTokenAccount.getAutomaticAssociation());\n+\n+        if (newTokenAccount.getAssociated() == null) {\n+            newTokenAccount.setAssociated(lastTokenAccount.getAssociated());\n+        }\n+\n+        if (newTokenAccount.getFreezeStatus() == null) {\n+            newTokenAccount.setFreezeStatus(lastTokenAccount.getFreezeStatus());\n+        }\n+\n+        if (newTokenAccount.getKycStatus() == null) {\n+            newTokenAccount.setKycStatus(lastTokenAccount.getKycStatus());\n+        }\n+\n+        return newTokenAccount;\n+    }\n }\n", "next_change": {"commit": "65b7f5080f7746a638793b600e0ce50fd106b33c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7aa8e4dd5..90f63e8ac 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -553,4 +601,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n         return newTokenAccount;\n     }\n+\n+    private TokenAllowance mergeTokenAllowance(TokenAllowance previous, TokenAllowance current) {\n+        previous.setTimestampUpper(current.getTimestampLower());\n+        return current;\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"oid": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "message": "Moved RecordFileParser file system logic to RecordFilePoller\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:32Z", "type": "commit"}, {"oid": "3b23462bdfa1fc2dd0371e85e5153ad447f8a828", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3b23462bdfa1fc2dd0371e85e5153ad447f8a828", "message": "Removed transactional from SqlEntityListener.OnEnd\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:32Z", "type": "commit"}, {"oid": "2ba305984f72c15a7c9551fbc3c82369f518b883", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2ba305984f72c15a7c9551fbc3c82369f518b883", "message": "Addressed feedback if poller and parser\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "1f345762e97fe2b4a66de19759ceb96eacc11885", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/1f345762e97fe2b4a66de19759ceb96eacc11885", "message": "Cleaned up a bit\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "message": "Added poller tests\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "message": "Addressed additional feedback\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "message": "Reverted to autocommit false, fixed rollback test\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "message": "Add logic to handle and recover from transaction management issues\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "06cadc07aaf127073e2d82d093dc4605b1db342a", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/06cadc07aaf127073e2d82d093dc4605b1db342a", "message": "Increased hikari max pool size andrenamed some tests\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2b2939cc5c9779e6d415c9d1e674f37356378ab8", "message": "Use @Transactional\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "message": "Add release connection, convert entity persistence to use repositories and fixed tests\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "cab3a93ee3e294ad55a39b4f1501658c574f035d", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/cab3a93ee3e294ad55a39b4f1501658c574f035d", "message": "Moved RecordFileParser file system logic to RecordFilePoller\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:16:13Z", "type": "commit"}, {"oid": "b4cc3eb744b66c38142331083132933c04c42c6e", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/b4cc3eb744b66c38142331083132933c04c42c6e", "message": "Removed transactional from SqlEntityListener.OnEnd\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:16:14Z", "type": "commit"}, {"oid": "e969c08a4d361fcc7d24aa828f08a0033611ed2b", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e969c08a4d361fcc7d24aa828f08a0033611ed2b", "message": "Addressed feedback if poller and parser\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:21:28Z", "type": "commit"}, {"oid": "a43a5910249d6663de2bd74846727eb02670ff0e", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/a43a5910249d6663de2bd74846727eb02670ff0e", "message": "Cleaned up a bit\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:22:13Z", "type": "commit"}, {"oid": "a396e69ac30e7a9aa88358fde0acce5ba73e25f2", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/a396e69ac30e7a9aa88358fde0acce5ba73e25f2", "message": "Addressed additional feedback\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:22:30Z", "type": "commit"}, {"oid": "674faa4bcf2cccf21461e998fc75b46eea872ee9", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/674faa4bcf2cccf21461e998fc75b46eea872ee9", "message": "Reverted to autocommit false, fixed rollback test\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:23:37Z", "type": "commit"}, {"oid": "ee307fc75600692c03bbb6379b6e6d8ec296ad41", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/ee307fc75600692c03bbb6379b6e6d8ec296ad41", "message": "Add logic to handle and recover from transaction management issues\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:25:08Z", "type": "commit"}, {"oid": "18c528c8a2e88b244409a5792d3151d2858da0d5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/18c528c8a2e88b244409a5792d3151d2858da0d5", "message": "Use @Transactional\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-08-21T07:27:06Z", "type": "commit"}, {"oid": "18c528c8a2e88b244409a5792d3151d2858da0d5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/18c528c8a2e88b244409a5792d3151d2858da0d5", "message": "Use @Transactional\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-08-21T07:27:06Z", "type": "forcePushed"}, {"oid": "8f6e32df0462a0038977243d94254f453359b232", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/8f6e32df0462a0038977243d94254f453359b232", "message": "Removed duplicate file check from RecordParser and reverted back to HashSet for entityIds in SqlENtityListener\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T15:35:16Z", "type": "commit"}, {"oid": "93ad6221c56a7010f711163484f0bd61c42f4054", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/93ad6221c56a7010f711163484f0bd61c42f4054", "message": "Removed extra cache manager storage\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T15:38:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474829832", "body": "This is not quite correct. If we inserted `0.0.2` during a previous file then get a rollback error next file it would be unnecessarily removed even though it exists in db. Please wrap `entityCache` with `transactionAwareCacheDecorator` instead.\r\n\r\nOr remove `entityCache` and `entityIds` and put `@Cacheable(cacheManager = CacheConfiguration.NEVER_EXPIRE_LARGE)` on `entityRepository.insertEntityId()`.", "bodyText": "This is not quite correct. If we inserted 0.0.2 during a previous file then get a rollback error next file it would be unnecessarily removed even though it exists in db. Please wrap entityCache with transactionAwareCacheDecorator instead.\nOr remove entityCache and entityIds and put @Cacheable(cacheManager = CacheConfiguration.NEVER_EXPIRE_LARGE) on entityRepository.insertEntityId().", "bodyHTML": "<p dir=\"auto\">This is not quite correct. If we inserted <code>0.0.2</code> during a previous file then get a rollback error next file it would be unnecessarily removed even though it exists in db. Please wrap <code>entityCache</code> with <code>transactionAwareCacheDecorator</code> instead.</p>\n<p dir=\"auto\">Or remove <code>entityCache</code> and <code>entityIds</code> and put <code>@Cacheable(cacheManager = CacheConfiguration.NEVER_EXPIRE_LARGE)</code> on <code>entityRepository.insertEntityId()</code>.</p>", "author": "steven-sheehy", "createdAt": "2020-08-21T17:24:47Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -151,39 +146,43 @@ public void onStart(StreamFileData streamFileData) {\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n+        boolean releaseConnection = false;\n         try {\n-            connection.commit();\n             recordFileRepository.save(recordFile);\n-            closeConnectionAndStatements();\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(e);\n+            applicationStatusRepository.updateStatusValue(\n+                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n+            releaseConnection = true;\n+        } finally {\n+            cleanup(false, releaseConnection);\n         }\n     }\n \n     @Override\n     public void onError() {\n-        try {\n-            if (connection != null) {\n-                connection.rollback();\n-                closeConnectionAndStatements();\n-            }\n-        } catch (SQLException e) {\n-            log.error(\"Exception while rolling transaction back\", e);\n-        } finally {\n-            cleanup();\n-        }\n+        cleanup(true, true);\n     }\n \n-    private void cleanup() {\n+    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n+        if (isRollBackCleanup) {\n+            // evict entities from cache from this round of batches as they were rolled back\n+            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));", "originalCommit": "93ad6221c56a7010f711163484f0bd61c42f4054", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5OTQ1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474999451", "bodyText": "True, Applying the cache on successful cases of entityRepository.insertEntityId encapsulates the desired outcome", "author": "Nana-EC", "createdAt": "2020-08-21T22:42:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE0NDg2Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475144867", "bodyText": "Ended up going with transactionAwareCacheDecorator as @Cacheable on repository on wasn't rolling back.", "author": "Nana-EC", "createdAt": "2020-08-22T22:31:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE1NzY0NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475157645", "bodyText": "You missed my comment above that you need to Please also wrap all CacheManagers in a TransactionAwareCacheManagerProxy so they are transaction aware via annotations. This needs to be done regardless of approach here. I'm not sure if a TransactionAwareCacheManagerProxy also needs a transactionAwareCacheDecorator when used without annotations. Probably not.", "author": "steven-sheehy", "createdAt": "2020-08-23T01:44:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcyMjU0OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475722549", "bodyText": "Good call, missed this.\nAdopted the TransactionAwareCacheManagerProxy and yeah with that the transactionAwareCacheDecorator is not needed", "author": "Nana-EC", "createdAt": "2020-08-24T16:01:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3a44e9282..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -146,43 +146,34 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n-        boolean releaseConnection = false;\n         try {\n             recordFileRepository.save(recordFile);\n             applicationStatusRepository.updateStatusValue(\n                     ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-            releaseConnection = true;\n         } finally {\n-            cleanup(false, releaseConnection);\n+            cleanup();\n         }\n     }\n \n     @Override\n     public void onError() {\n-        cleanup(true, true);\n+        cleanup();\n     }\n \n-    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n-        if (isRollBackCleanup) {\n-            // evict entities from cache from this round of batches as they were rolled back\n-            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n-        }\n-\n+    private void cleanup() {\n         closeQuietly(sqlNotifyTopicMessage);\n         sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n+        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n \n-        if (releaseConnection) {\n-            entityIds.clear();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n-        }\n+        DataSourceUtils.releaseConnection(connection, dataSource);\n     }\n \n     private void executeBatch(PreparedStatement ps, String entity) {\n", "next_change": {"commit": "9c13a19e8f4506ecdb2519a1e45a45f61dc34f56", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..7268051ae 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -172,32 +155,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n-\n-        DataSourceUtils.releaseConnection(connection, dataSource);\n-    }\n-\n-    private void executeBatch(PreparedStatement ps, String entity) {\n-        try {\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            var executeResult = ps.executeBatch();\n-            log.info(\"Inserted {} {} in {}\", executeResult.length, entity, stopwatch);\n-        } catch (SQLException e) {\n-            throw new ParserException(e);\n-        }\n-    }\n-\n-    private void closeQuietly(Statement statement) {\n-        try {\n-            if (statement != null) {\n-                statement.close();\n-            }\n-        } catch (Exception e) {\n-            log.warn(\"Error closing statement\", e);\n-        }\n     }\n \n     private void executeBatches() {\n+        Connection connection = null;\n+\n         try {\n+            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             transactionPgCopy.copy(transactions, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n", "next_change": {"commit": "53237aa496805c216c66586835cfd53c5d3a5835", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7268051ae..03dc924b1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -170,9 +193,10 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n-            eventPublisher.publishEvent(new EntityBatchEvent(this));\n+            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n", "next_change": {"commit": "37143536977c12b97f8548a52ebd619ab215557c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 03dc924b1..3e7a38a0b 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -196,7 +199,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n", "next_change": {"commit": "8504f4894f725fd11d79dbbb08c53c380fb5b684", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3e7a38a0b..bf7000073 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -197,6 +208,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            scheduleSignaturePgCopy.copy(scheduleSignatures, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "0c3d94b17a2e300b36023ac8cd5ae76e4b1d397d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex bf7000073..c80ee7ff1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -208,7 +197,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n-            scheduleSignaturePgCopy.copy(scheduleSignatures, connection);\n+            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c80ee7ff1..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -189,16 +207,23 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n             connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n-            transactionPgCopy.copy(transactions, connection);\n+\n+            // insert only operations\n+            contractResultPgCopy.copy(contractResults, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n             fileDataPgCopy.copy(fileData, connection);\n-            contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n+            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            topicMessagePgCopy.copy(topicMessages, connection);\n+            transactionPgCopy.copy(transactions, connection);\n             transactionSignaturePgCopy.copy(transactionSignatures, connection);\n-            persistEntities();\n+\n+            // insert operations with conflict management for updates\n+            entityPgCopy.copy(entities.values(), connection);\n+            schedulePgCopy.copy(schedules.values(), connection);\n+            tokenPgCopy.copy(tokens.values(), connection);\n+            tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "50c046b953fc6dd0a4df360f9267ee08489a3535", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..675b494f6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -209,21 +242,28 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n+            assessedCustomFeePgCopy.copy(assessedCustomFees, connection);\n             contractResultPgCopy.copy(contractResults, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n+            customFeePgCopy.copy(customFees, connection);\n             fileDataPgCopy.copy(fileData, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             transactionPgCopy.copy(transactions, connection);\n             transactionSignaturePgCopy.copy(transactionSignatures, connection);\n \n-            // insert operations with conflict management for updates\n+            // insert operations with conflict management\n             entityPgCopy.copy(entities.values(), connection);\n-            schedulePgCopy.copy(schedules.values(), connection);\n             tokenPgCopy.copy(tokens.values(), connection);\n             tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n+            nftPgCopy.copy(nfts.values(), connection); // persist nft after token entity\n+            schedulePgCopy.copy(schedules.values(), connection);\n+\n+            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n+            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n+            nftTransferPgCopy.copy(nftTransfers, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "783b786089e673910c75b3c317aed55928a11113", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 675b494f6..9dd720311 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -264,6 +281,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             nftTransferPgCopy.copy(nftTransfers, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n \n+            // handle the transfers from token dissociate transactions after nft is processed\n+            tokenDissociateTransferPgCopy.copy(tokenDissociateTransfers, connection);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "95b5209ec65eb0489fcce60b78fd3059da3b5f44", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 9dd720311..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -248,41 +196,40 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n     }\n \n     private void executeBatches() {\n-        Connection connection = null;\n-\n         try {\n             // batch save action may run asynchronously, triggering it before other operations can reduce latency\n             eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n \n-            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n-            assessedCustomFeePgCopy.copy(assessedCustomFees, connection);\n-            contractResultPgCopy.copy(contractResults, connection);\n-            cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            customFeePgCopy.copy(customFees, connection);\n-            fileDataPgCopy.copy(fileData, connection);\n-            liveHashPgCopy.copy(liveHashes, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n-            transactionPgCopy.copy(transactions, connection);\n-            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n+            batchPersister.persist(assessedCustomFees);\n+            batchPersister.persist(contractLogs);\n+            batchPersister.persist(contractResults);\n+            batchPersister.persist(cryptoTransfers);\n+            batchPersister.persist(customFees);\n+            batchPersister.persist(fileData);\n+            batchPersister.persist(liveHashes);\n+            batchPersister.persist(topicMessages);\n+            batchPersister.persist(transactions);\n+            batchPersister.persist(transactionSignatures);\n \n             // insert operations with conflict management\n-            entityPgCopy.copy(entities.values(), connection);\n-            tokenPgCopy.copy(tokens.values(), connection);\n+            batchPersister.persist(contracts.values());\n+            batchPersister.persist(entities.values());\n+            batchPersister.persist(tokens.values());\n             // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            tokenAccountPgCopy.copy(tokenAccounts, connection);\n-            nftPgCopy.copy(nfts.values(), connection); // persist nft after token entity\n-            schedulePgCopy.copy(schedules.values(), connection);\n+            batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(nfts.values()); // persist nft after token entity\n+            batchPersister.persist(schedules.values());\n \n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            nftTransferPgCopy.copy(nftTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            batchPersister.persist(nonFeeTransfers);\n+            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferPgCopy.copy(tokenDissociateTransfers, connection);\n+            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n \n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "1165e4ac7db8ee7798847082bd3e2a912393a6c1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..99c140ace 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -215,17 +260,20 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             batchPersister.persist(transactionSignatures);\n \n             // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n+            batchPersister.persist(contracts);\n+            batchPersister.persist(cryptoAllowances);\n             batchPersister.persist(entities.values());\n+            batchPersister.persist(nftAllowances);\n             batchPersister.persist(tokens.values());\n             // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n             batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(tokenAllowances);\n             batchPersister.persist(nfts.values()); // persist nft after token entity\n             batchPersister.persist(schedules.values());\n \n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n             batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(nftTransferState.values());\n             batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n", "next_change": {"commit": "834b5f7f264c67c8dc949449f7e1b4d1bcc279af", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 99c140ace..d28de0c78 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -274,6 +285,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n             batchPersister.persist(nonFeeTransfers);\n             batchPersister.persist(nftTransferState.values());\n+            batchPersister.persist(stakingRewardTransfers);\n             batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d28de0c78..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -248,59 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(contractStateChanges);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(ethereumTransactions);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(nodeStakes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts);\n-            batchPersister.persist(cryptoAllowances);\n-            batchPersister.persist(entities);\n-            batchPersister.persist(nftAllowances);\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts.values());\n-            batchPersister.persist(tokenAllowances);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransferState.values());\n-            batchPersister.persist(stakingRewardTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 9dd720311..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -291,7 +238,6 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n             throw new ParserException(e);\n         } finally {\n             cleanup();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n         }\n     }\n \n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -195,52 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n-            batchPersister.persist(entities.values());\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNTIzNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474835237", "body": "I think we should always clear entityIds and release connection. The connection doesn't really get released, it just gets a reference decremented since it's wrapped in an outer connection.", "bodyText": "I think we should always clear entityIds and release connection. The connection doesn't really get released, it just gets a reference decremented since it's wrapped in an outer connection.", "bodyHTML": "<p dir=\"auto\">I think we should always clear entityIds and release connection. The connection doesn't really get released, it just gets a reference decremented since it's wrapped in an outer connection.</p>", "author": "steven-sheehy", "createdAt": "2020-08-21T17:36:02Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -151,39 +146,43 @@ public void onStart(StreamFileData streamFileData) {\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n+        boolean releaseConnection = false;\n         try {\n-            connection.commit();\n             recordFileRepository.save(recordFile);\n-            closeConnectionAndStatements();\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(e);\n+            applicationStatusRepository.updateStatusValue(\n+                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n+            releaseConnection = true;\n+        } finally {\n+            cleanup(false, releaseConnection);\n         }\n     }\n \n     @Override\n     public void onError() {\n-        try {\n-            if (connection != null) {\n-                connection.rollback();\n-                closeConnectionAndStatements();\n-            }\n-        } catch (SQLException e) {\n-            log.error(\"Exception while rolling transaction back\", e);\n-        } finally {\n-            cleanup();\n-        }\n+        cleanup(true, true);\n     }\n \n-    private void cleanup() {\n+    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n+        if (isRollBackCleanup) {\n+            // evict entities from cache from this round of batches as they were rolled back\n+            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n+        }\n+\n+        closeQuietly(sqlNotifyTopicMessage);\n+        sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n-        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n+\n+        if (releaseConnection) {\n+            entityIds.clear();\n+            DataSourceUtils.releaseConnection(connection, dataSource);", "originalCommit": "93ad6221c56a7010f711163484f0bd61c42f4054", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NjcxOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474996718", "bodyText": "Holding onto entities till end of file allowed for the right entityIds to be evicted from cache.\nWith the other approach you suggested I can revert this.\nThe release connection to decrement the reference seems to be necessary otherwise the connections stay open and the pool gets filled up with active connections.", "author": "Nana-EC", "createdAt": "2020-08-21T22:31:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNTIzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NzMyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474997326", "bodyText": "Right, I didn't suggest to remove releaseConnection but to always releaseConnection.", "author": "steven-sheehy", "createdAt": "2020-08-21T22:34:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNTIzNw=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3a44e9282..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -146,43 +146,34 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n-        boolean releaseConnection = false;\n         try {\n             recordFileRepository.save(recordFile);\n             applicationStatusRepository.updateStatusValue(\n                     ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-            releaseConnection = true;\n         } finally {\n-            cleanup(false, releaseConnection);\n+            cleanup();\n         }\n     }\n \n     @Override\n     public void onError() {\n-        cleanup(true, true);\n+        cleanup();\n     }\n \n-    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n-        if (isRollBackCleanup) {\n-            // evict entities from cache from this round of batches as they were rolled back\n-            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n-        }\n-\n+    private void cleanup() {\n         closeQuietly(sqlNotifyTopicMessage);\n         sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n+        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n \n-        if (releaseConnection) {\n-            entityIds.clear();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n-        }\n+        DataSourceUtils.releaseConnection(connection, dataSource);\n     }\n \n     private void executeBatch(PreparedStatement ps, String entity) {\n", "next_change": {"commit": "9c13a19e8f4506ecdb2519a1e45a45f61dc34f56", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..7268051ae 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -172,32 +155,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n-\n-        DataSourceUtils.releaseConnection(connection, dataSource);\n-    }\n-\n-    private void executeBatch(PreparedStatement ps, String entity) {\n-        try {\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-            var executeResult = ps.executeBatch();\n-            log.info(\"Inserted {} {} in {}\", executeResult.length, entity, stopwatch);\n-        } catch (SQLException e) {\n-            throw new ParserException(e);\n-        }\n-    }\n-\n-    private void closeQuietly(Statement statement) {\n-        try {\n-            if (statement != null) {\n-                statement.close();\n-            }\n-        } catch (Exception e) {\n-            log.warn(\"Error closing statement\", e);\n-        }\n     }\n \n     private void executeBatches() {\n+        Connection connection = null;\n+\n         try {\n+            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             transactionPgCopy.copy(transactions, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n", "next_change": {"commit": "53237aa496805c216c66586835cfd53c5d3a5835", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7268051ae..03dc924b1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -170,9 +193,10 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n-            eventPublisher.publishEvent(new EntityBatchEvent(this));\n+            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n", "next_change": {"commit": "37143536977c12b97f8548a52ebd619ab215557c", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 03dc924b1..3e7a38a0b 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -196,7 +199,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n", "next_change": {"commit": "8504f4894f725fd11d79dbbb08c53c380fb5b684", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3e7a38a0b..bf7000073 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -197,6 +208,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            scheduleSignaturePgCopy.copy(scheduleSignatures, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "0c3d94b17a2e300b36023ac8cd5ae76e4b1d397d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex bf7000073..c80ee7ff1 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -208,7 +197,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n-            scheduleSignaturePgCopy.copy(scheduleSignatures, connection);\n+            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n             persistEntities();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c80ee7ff1..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -189,16 +207,23 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n             connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n-            transactionPgCopy.copy(transactions, connection);\n+\n+            // insert only operations\n+            contractResultPgCopy.copy(contractResults, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n             fileDataPgCopy.copy(fileData, connection);\n-            contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n+            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            topicMessagePgCopy.copy(topicMessages, connection);\n+            transactionPgCopy.copy(transactions, connection);\n             transactionSignaturePgCopy.copy(transactionSignatures, connection);\n-            persistEntities();\n+\n+            // insert operations with conflict management for updates\n+            entityPgCopy.copy(entities.values(), connection);\n+            schedulePgCopy.copy(schedules.values(), connection);\n+            tokenPgCopy.copy(tokens.values(), connection);\n+            tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "50c046b953fc6dd0a4df360f9267ee08489a3535", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..675b494f6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -209,21 +242,28 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n+            assessedCustomFeePgCopy.copy(assessedCustomFees, connection);\n             contractResultPgCopy.copy(contractResults, connection);\n             cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n+            customFeePgCopy.copy(customFees, connection);\n             fileDataPgCopy.copy(fileData, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n             transactionPgCopy.copy(transactions, connection);\n             transactionSignaturePgCopy.copy(transactionSignatures, connection);\n \n-            // insert operations with conflict management for updates\n+            // insert operations with conflict management\n             entityPgCopy.copy(entities.values(), connection);\n-            schedulePgCopy.copy(schedules.values(), connection);\n             tokenPgCopy.copy(tokens.values(), connection);\n             tokenAccountPgCopy.copy(tokenAccounts.values(), connection);\n+            nftPgCopy.copy(nfts.values(), connection); // persist nft after token entity\n+            schedulePgCopy.copy(schedules.values(), connection);\n+\n+            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n+            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n+            nftTransferPgCopy.copy(nftTransfers, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "783b786089e673910c75b3c317aed55928a11113", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 675b494f6..9dd720311 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -264,6 +281,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             nftTransferPgCopy.copy(nftTransfers, connection);\n             tokenTransferPgCopy.copy(tokenTransfers, connection);\n \n+            // handle the transfers from token dissociate transactions after nft is processed\n+            tokenDissociateTransferPgCopy.copy(tokenDissociateTransfers, connection);\n+\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n             throw e;\n", "next_change": {"commit": "95b5209ec65eb0489fcce60b78fd3059da3b5f44", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 9dd720311..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -248,41 +196,40 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n     }\n \n     private void executeBatches() {\n-        Connection connection = null;\n-\n         try {\n             // batch save action may run asynchronously, triggering it before other operations can reduce latency\n             eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n \n-            connection = DataSourceUtils.getConnection(dataSource);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n \n             // insert only operations\n-            assessedCustomFeePgCopy.copy(assessedCustomFees, connection);\n-            contractResultPgCopy.copy(contractResults, connection);\n-            cryptoTransferPgCopy.copy(cryptoTransfers, connection);\n-            customFeePgCopy.copy(customFees, connection);\n-            fileDataPgCopy.copy(fileData, connection);\n-            liveHashPgCopy.copy(liveHashes, connection);\n-            topicMessagePgCopy.copy(topicMessages, connection);\n-            transactionPgCopy.copy(transactions, connection);\n-            transactionSignaturePgCopy.copy(transactionSignatures, connection);\n+            batchPersister.persist(assessedCustomFees);\n+            batchPersister.persist(contractLogs);\n+            batchPersister.persist(contractResults);\n+            batchPersister.persist(cryptoTransfers);\n+            batchPersister.persist(customFees);\n+            batchPersister.persist(fileData);\n+            batchPersister.persist(liveHashes);\n+            batchPersister.persist(topicMessages);\n+            batchPersister.persist(transactions);\n+            batchPersister.persist(transactionSignatures);\n \n             // insert operations with conflict management\n-            entityPgCopy.copy(entities.values(), connection);\n-            tokenPgCopy.copy(tokens.values(), connection);\n+            batchPersister.persist(contracts.values());\n+            batchPersister.persist(entities.values());\n+            batchPersister.persist(tokens.values());\n             // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            tokenAccountPgCopy.copy(tokenAccounts, connection);\n-            nftPgCopy.copy(nfts.values(), connection); // persist nft after token entity\n-            schedulePgCopy.copy(schedules.values(), connection);\n+            batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(nfts.values()); // persist nft after token entity\n+            batchPersister.persist(schedules.values());\n \n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            nonFeeTransferPgCopy.copy(nonFeeTransfers, connection);\n-            nftTransferPgCopy.copy(nftTransfers, connection);\n-            tokenTransferPgCopy.copy(tokenTransfers, connection);\n+            batchPersister.persist(nonFeeTransfers);\n+            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferPgCopy.copy(tokenDissociateTransfers, connection);\n+            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n \n             log.info(\"Completed batch inserts in {}\", stopwatch);\n         } catch (ParserException e) {\n", "next_change": {"commit": "1165e4ac7db8ee7798847082bd3e2a912393a6c1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..99c140ace 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -215,17 +260,20 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             batchPersister.persist(transactionSignatures);\n \n             // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n+            batchPersister.persist(contracts);\n+            batchPersister.persist(cryptoAllowances);\n             batchPersister.persist(entities.values());\n+            batchPersister.persist(nftAllowances);\n             batchPersister.persist(tokens.values());\n             // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n             batchPersister.persist(tokenAccounts);\n+            batchPersister.persist(tokenAllowances);\n             batchPersister.persist(nfts.values()); // persist nft after token entity\n             batchPersister.persist(schedules.values());\n \n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n             batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n+            batchPersister.persist(nftTransferState.values());\n             batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n", "next_change": {"commit": "834b5f7f264c67c8dc949449f7e1b4d1bcc279af", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 99c140ace..d28de0c78 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -274,6 +285,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             // transfers operations should be last to ensure insert logic completeness, entities should already exist\n             batchPersister.persist(nonFeeTransfers);\n             batchPersister.persist(nftTransferState.values());\n+            batchPersister.persist(stakingRewardTransfers);\n             batchPersister.persist(tokenTransfers);\n \n             // handle the transfers from token dissociate transactions after nft is processed\n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d28de0c78..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -248,59 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(contractStateChanges);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(ethereumTransactions);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(nodeStakes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts);\n-            batchPersister.persist(cryptoAllowances);\n-            batchPersister.persist(entities);\n-            batchPersister.persist(nftAllowances);\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts.values());\n-            batchPersister.persist(tokenAllowances);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransferState.values());\n-            batchPersister.persist(stakingRewardTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 9dd720311..c087991cb 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -291,7 +238,6 @@ public class SqlEntityListener extends AbstractEntityListener implements RecordS\n             throw new ParserException(e);\n         } finally {\n             cleanup();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n         }\n     }\n \n", "next_change": {"commit": "f900b42b75a667ce666771c77988712187d9c9a5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex c087991cb..aa6c9a54e 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -195,52 +325,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void executeBatches() {\n-        try {\n-            // batch save action may run asynchronously, triggering it before other operations can reduce latency\n-            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n-\n-            Stopwatch stopwatch = Stopwatch.createStarted();\n-\n-            // insert only operations\n-            batchPersister.persist(assessedCustomFees);\n-            batchPersister.persist(contractLogs);\n-            batchPersister.persist(contractResults);\n-            batchPersister.persist(cryptoTransfers);\n-            batchPersister.persist(customFees);\n-            batchPersister.persist(fileData);\n-            batchPersister.persist(liveHashes);\n-            batchPersister.persist(topicMessages);\n-            batchPersister.persist(transactions);\n-            batchPersister.persist(transactionSignatures);\n-\n-            // insert operations with conflict management\n-            batchPersister.persist(contracts.values());\n-            batchPersister.persist(entities.values());\n-            batchPersister.persist(tokens.values());\n-            // ingest tokenAccounts after tokens since some fields of token accounts depends on the associated token\n-            batchPersister.persist(tokenAccounts);\n-            batchPersister.persist(nfts.values()); // persist nft after token entity\n-            batchPersister.persist(schedules.values());\n-\n-            // transfers operations should be last to ensure insert logic completeness, entities should already exist\n-            batchPersister.persist(nonFeeTransfers);\n-            batchPersister.persist(nftTransfers);\n-            batchPersister.persist(tokenTransfers);\n-\n-            // handle the transfers from token dissociate transactions after nft is processed\n-            tokenDissociateTransferBatchPersister.persist(tokenDissociateTransfers);\n-\n-            log.info(\"Completed batch inserts in {}\", stopwatch);\n-        } catch (ParserException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new ParserException(e);\n-        } finally {\n-            cleanup();\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": {"commit": "c28a5dd4db3a89f2f9c3e9a604f75596f36b9421", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex aa6c9a54e..55abcbb22 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -282,49 +228,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cleanup();\n     }\n \n-    private void cleanup() {\n-        try {\n-            assessedCustomFees.clear();\n-            contracts.clear();\n-            contractActions.clear();\n-            contractLogs.clear();\n-            contractResults.clear();\n-            contractStateChanges.clear();\n-            cryptoAllowances.clear();\n-            cryptoAllowanceState.clear();\n-            cryptoTransfers.clear();\n-            customFees.clear();\n-            entities.clear();\n-            entityState.clear();\n-            ethereumTransactions.clear();\n-            fileData.clear();\n-            liveHashes.clear();\n-            networkStakes.clear();\n-            nfts.clear();\n-            nftAllowances.clear();\n-            nftAllowanceState.clear();\n-            nftTransferState.clear();\n-            nodeStakes.clear();\n-            nonFeeTransfers.clear();\n-            prngs.clear();\n-            schedules.clear();\n-            stakingRewardTransfers.clear();\n-            topicMessages.clear();\n-            tokenAccounts.clear();\n-            tokenAccountState.clear();\n-            tokenAllowances.clear();\n-            tokenAllowanceState.clear();\n-            tokens.clear();\n-            tokenDissociateTransfers.clear();\n-            tokenTransfers.clear();\n-            transactions.clear();\n-            transactionSignatures.clear();\n-            eventPublisher.publishEvent(new EntityBatchCleanupEvent(this));\n-        } catch (BeanCreationNotAllowedException e) {\n-            // This error can occur during shutdown\n-        }\n-    }\n-\n     @Override\n     public void onAssessedCustomFee(AssessedCustomFee assessedCustomFee) throws ImporterException {\n         assessedCustomFees.add(assessedCustomFee);\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474952150", "body": "This breaks encapsulation of `SqlEntityListener` since now it relies on `EntityRecordItemListener` to populate the same cache for this to work. So if `SqlEntityListener` is used outside of this scope, say from a test, it would not be functionally correct. \r\n\r\nBetter option would be to add a `@CachePut` to `entityRepository.save()` that updates the entity id cache. You can use `@Caching` to group.", "bodyText": "This breaks encapsulation of SqlEntityListener since now it relies on EntityRecordItemListener to populate the same cache for this to work. So if SqlEntityListener is used outside of this scope, say from a test, it would not be functionally correct.\nBetter option would be to add a @CachePut to entityRepository.save() that updates the entity id cache. You can use @Caching to group.", "bodyHTML": "<p dir=\"auto\">This breaks encapsulation of <code>SqlEntityListener</code> since now it relies on <code>EntityRecordItemListener</code> to populate the same cache for this to work. So if <code>SqlEntityListener</code> is used outside of this scope, say from a test, it would not be functionally correct.</p>\n<p dir=\"auto\">Better option would be to add a <code>@CachePut</code> to <code>entityRepository.save()</code> that updates the entity id cache. You can use <code>@Caching</code> to group.</p>", "author": "steven-sheehy", "createdAt": "2020-08-21T20:42:09Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -241,22 +240,7 @@ public void onTransaction(Transaction transaction) throws ImporterException {\n \n     @Override\n     public void onEntityId(EntityId entityId) throws ImporterException {\n-        // add entities not found in cache to list of entities to be persisted\n-        if (entityCache.get(entityId.getId()) != null) {\n-            return;\n-        }\n-\n-        try {\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ID.ordinal(), entityId.getId());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ENTITY_SHARD.ordinal(), entityId.getShardNum());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ENTITY_REALM.ordinal(), entityId.getRealmNum());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ENTITY_NUM.ordinal(), entityId.getEntityNum());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.TYPE.ordinal(), entityId.getType());\n-            sqlInsertEntityId.addBatch();\n-            entityIds.add(entityId);\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(e);\n-        }\n+        entityIds.add(entityId);", "originalCommit": "93ad6221c56a7010f711163484f0bd61c42f4054", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NzM0MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474997341", "bodyText": "Fair point.", "author": "Nana-EC", "createdAt": "2020-08-21T22:34:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE0NDkwMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475144903", "bodyText": "Put cache management in SqlEntityListener using the recommended transactionAwareCacheDecorator .", "author": "Nana-EC", "createdAt": "2020-08-22T22:31:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5OTIxOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475699219", "bodyText": "Do we want to cache entityRepository.save() as mentioned above?", "author": "steven-sheehy", "createdAt": "2020-08-24T15:27:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA=="}], "type": "inlineReview", "revised_code": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3a44e9282..af3119a1c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -240,6 +231,11 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     @Override\n     public void onEntityId(EntityId entityId) throws ImporterException {\n+        // only insert entities not found in cache\n+        if (entityCache.get(entityId.getId()) != null) {\n+            return;\n+        }\n+\n         entityIds.add(entityId);\n     }\n \n", "next_change": {"commit": "85f30d0aaca6ead3949a722027cb8af2453dc8d4", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex af3119a1c..b27019518 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -206,33 +193,32 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             contractResultPgCopy.copy(contractResults, connection);\n             liveHashPgCopy.copy(liveHashes, connection);\n             topicMessagePgCopy.copy(topicMessages, connection);\n+            tokenTransferPgCopy.copy(tokenTransfers, connection);\n             persistEntities();\n-            notifyTopicMessages();\n             log.info(\"Completed batch inserts in {}\", stopwatch);\n+            eventPublisher.publishEvent(new EntityBatchSaveEvent(this));\n         } catch (ParserException e) {\n             throw e;\n         } catch (Exception e) {\n             throw new ParserException(e);\n         } finally {\n             cleanup();\n+            DataSourceUtils.releaseConnection(connection, dataSource);\n         }\n     }\n \n     @Override\n     public void onTransaction(Transaction transaction) throws ImporterException {\n         transactions.add(transaction);\n-        if (batchCount == sqlProperties.getBatchSize() - 1) {\n-            // execute any remaining batches\n+        if (transactions.size() == sqlProperties.getBatchSize()) {\n             executeBatches();\n-        } else {\n-            batchCount += 1;\n         }\n     }\n \n     @Override\n     public void onEntityId(EntityId entityId) throws ImporterException {\n         // only insert entities not found in cache\n-        if (entityCache.get(entityId.getId()) != null) {\n+        if (entityId == null || entityCache.get(entityId.getId()) != null) {\n             return;\n         }\n \n", "next_change": {"commit": "6b28db4e42bab934de5e53308528e57ee95cfe39", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex b27019518..7b542abaf 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -218,7 +218,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     @Override\n     public void onEntityId(EntityId entityId) throws ImporterException {\n         // only insert entities not found in cache\n-        if (entityId == null || entityCache.get(entityId.getId()) != null) {\n+        if (EntityId.isEmpty(entityId) || entityCache.get(entityId.getId()) != null) {\n             return;\n         }\n \n", "next_change": {"commit": "419ed6e2bc0c8cd92e15e502be61b19c2a0a0fe3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 7b542abaf..265cd1cf0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -216,13 +244,14 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     @Override\n-    public void onEntityId(EntityId entityId) throws ImporterException {\n-        // only insert entities not found in cache\n-        if (EntityId.isEmpty(entityId) || entityCache.get(entityId.getId()) != null) {\n+    public void onEntity(Entity entity) throws ImporterException {\n+        EntityId entityId = entity.toEntityId();\n+        // handle empty id case\n+        if (EntityId.isEmpty(entityId)) {\n             return;\n         }\n \n-        entityIds.add(entityId);\n+        entities.merge(entity.getId(), entity, this::mergeEntity);\n     }\n \n     @Override\n", "next_change": {"commit": "59f084044fdc5b121cd0fe7a00ee93d4970cadf8", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 265cd1cf0..e8a83d192 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -259,6 +276,16 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         cryptoTransfers.add(cryptoTransfer);\n     }\n \n+    @Override\n+    public void onNft(Nft nft) throws ImporterException {\n+        nftRepository.save(nft);\n+    }\n+\n+    @Override\n+    public void onNftTransfer(NftTransfer nftTransfer) throws ImporterException {\n+        nftTransfers.add(nftTransfer);\n+    }\n+\n     @Override\n     public void onNonFeeTransfer(NonFeeTransfer nonFeeTransfer) throws ImporterException {\n         nonFeeTransfers.add(nonFeeTransfer);\n", "next_change": {"commit": "643f0c788bf111205c08f13d5fd38c8e3ffc6e12", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e8a83d192..5e26ce111 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -292,23 +322,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     @Override\n-    public void onTopicMessage(TopicMessage topicMessage) throws ImporterException {\n-        topicMessages.add(topicMessage);\n-    }\n-\n-    @Override\n-    public void onContractResult(ContractResult contractResult) throws ImporterException {\n-        contractResults.add(contractResult);\n-    }\n-\n-    @Override\n-    public void onFileData(FileData fd) {\n-        fileData.add(fd);\n-    }\n-\n-    @Override\n-    public void onLiveHash(LiveHash liveHash) throws ImporterException {\n-        liveHashes.add(liveHash);\n+    public void onSchedule(Schedule schedule) throws ImporterException {\n+        // schedules could experience multiple updates in a single record file, handle updates in memory for this case\n+        schedules.merge(schedule.getScheduleId().getId(), schedule, this::mergeSchedule);\n     }\n \n     @Override\n", "next_change": {"commit": "e9aa74225a3ef625d0f103a131837c230d065591", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5e26ce111..3309cfd99 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -324,7 +334,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     @Override\n     public void onSchedule(Schedule schedule) throws ImporterException {\n         // schedules could experience multiple updates in a single record file, handle updates in memory for this case\n-        schedules.merge(schedule.getScheduleId().getId(), schedule, this::mergeSchedule);\n+        schedules.merge(schedule.getScheduleId(), schedule, this::mergeSchedule);\n     }\n \n     @Override\n", "next_change": {"commit": "834b5f7f264c67c8dc949449f7e1b4d1bcc279af", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3309cfd99..d28de0c78 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -337,6 +410,11 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         schedules.merge(schedule.getScheduleId(), schedule, this::mergeSchedule);\n     }\n \n+    @Override\n+    public void onStakingRewardTransfer(StakingRewardTransfer stakingRewardTransfer) {\n+        stakingRewardTransfers.add(stakingRewardTransfer);\n+    }\n+\n     @Override\n     public void onToken(Token token) throws ImporterException {\n         // tokens could experience multiple updates in a single record file, handle updates in memory for this case\n", "next_change": {"commit": "3e6d82c559d21a89cee1bf8c61e6fab77092a8f1", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d28de0c78..eaaa425ef 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -423,14 +365,10 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     @Override\n     public void onTokenAccount(TokenAccount tokenAccount) throws ImporterException {\n-        if (tokenAccounts.containsKey(tokenAccount.getId())) {\n-            log.warn(\"Skipping duplicate token account association: {}\", tokenAccount);\n-            return;\n+        var merged = tokenAccountState.merge(tokenAccount.getId(), tokenAccount, this::mergeTokenAccount);\n+        if (merged == tokenAccount) {\n+            tokenAccounts.add(merged);\n         }\n-\n-        var key = new TokenAccountKey(tokenAccount.getId().getTokenId(), tokenAccount.getId().getAccountId());\n-        TokenAccount merged = tokenAccountState.merge(key, tokenAccount, this::mergeTokenAccount);\n-        tokenAccounts.put(merged.getId(), merged);\n     }\n \n     @Override\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"oid": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3eedeade2e3496808da55fc270a1dc5619a4a4f5", "message": "Moved cache management back to SqlEntityListener and utilized TransactionAwareCacheDecorator to account for rollbacks\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-22T22:33:50Z", "type": "commit"}, {"oid": "30af6fa95cf88d42cf2393bb8e73576501308910", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/30af6fa95cf88d42cf2393bb8e73576501308910", "message": "Removed unused recordfilerepository method\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-22T22:39:32Z", "type": "commit"}, {"oid": "f77fdb95bbb25fc658f21b1d5919af8a8c7049c1", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/f77fdb95bbb25fc658f21b1d5919af8a8c7049c1", "message": "Wrapped cachemanagers in TransactionAwareCacheManagerProxy\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-24T16:01:11Z", "type": "commit"}]}