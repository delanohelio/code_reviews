{"pr_number": 12612, "pr_title": "REVERT (CDAP-16784) Removing Kryo as default", "pr_author": "MEseifan", "pr_createdAt": "2020-08-10T18:07:20Z", "pr_url": "https://github.com/cdapio/cdap/pull/12612", "merge_commit": "d1ed7f2c9e1e68492856a145f0854ff265bc8465", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA4ODUyMQ==", "url": "https://github.com/cdapio/cdap/pull/12612#discussion_r468088521", "body": "this shouldn't come back, it's being set lower now (line 127)", "bodyText": "this shouldn't come back, it's being set lower now (line 127)", "bodyHTML": "<p dir=\"auto\">this shouldn't come back, it's being set lower now (line 127)</p>", "author": "albertshau", "createdAt": "2020-08-10T18:12:56Z", "path": "cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java", "diffHunk": "@@ -100,9 +100,9 @@ public void initialize() throws Exception {\n     sparkConf.set(\"spark.streaming.backpressure.enabled\", \"true\");\n     sparkConf.set(\"spark.spark.streaming.blockInterval\", String.valueOf(spec.getBatchIntervalMillis() / 5));\n     sparkConf.set(\"spark.maxRemoteBlockSizeFetchToMem\", String.valueOf(Integer.MAX_VALUE - 512));\n-\n-    //Setting Kryo as default serializer\n-    sparkConf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\");\n+    for (Map.Entry<String, String> property : spec.getProperties().entrySet()) {", "originalCommit": "1025f12797f0ff4c8bce90ac7b3899e816bae839", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA4OTk1MQ==", "url": "https://github.com/cdapio/cdap/pull/12612#discussion_r468089951", "bodyText": "done", "author": "MEseifan", "createdAt": "2020-08-10T18:15:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA4ODUyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e073de9df71529b001e8d99ed10aa357b365616", "changed_code": [{"header": "diff --git a/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java b/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java\nindex e6783b465a6..34a906744a9 100644\n--- a/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java\n+++ b/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java\n", "chunk": "@@ -100,9 +100,6 @@ public class DataStreamsSparkLauncher extends AbstractSpark {\n     sparkConf.set(\"spark.streaming.backpressure.enabled\", \"true\");\n     sparkConf.set(\"spark.spark.streaming.blockInterval\", String.valueOf(spec.getBatchIntervalMillis() / 5));\n     sparkConf.set(\"spark.maxRemoteBlockSizeFetchToMem\", String.valueOf(Integer.MAX_VALUE - 512));\n-    for (Map.Entry<String, String> property : spec.getProperties().entrySet()) {\n-      sparkConf.set(property.getKey(), property.getValue());\n-    }\n \n     // spark... makes you set this to at least the number of receivers (streaming sources)\n     // because it holds one thread per receiver, or one core in distributed mode.\n", "next_change": null}]}, "revised_code_in_main": {"commit": "d1ed7f2c9e1e68492856a145f0854ff265bc8465", "changed_code": [{"header": "diff --git a/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java b/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java\nindex e6783b465a6..34a906744a9 100644\n--- a/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java\n+++ b/cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/DataStreamsSparkLauncher.java\n", "chunk": "@@ -100,9 +100,6 @@ public class DataStreamsSparkLauncher extends AbstractSpark {\n     sparkConf.set(\"spark.streaming.backpressure.enabled\", \"true\");\n     sparkConf.set(\"spark.spark.streaming.blockInterval\", String.valueOf(spec.getBatchIntervalMillis() / 5));\n     sparkConf.set(\"spark.maxRemoteBlockSizeFetchToMem\", String.valueOf(Integer.MAX_VALUE - 512));\n-    for (Map.Entry<String, String> property : spec.getProperties().entrySet()) {\n-      sparkConf.set(property.getKey(), property.getValue());\n-    }\n \n     // spark... makes you set this to at least the number of receivers (streaming sources)\n     // because it holds one thread per receiver, or one core in distributed mode.\n", "next_change": null}]}, "commits_in_main": [{"oid": "d1ed7f2c9e1e68492856a145f0854ff265bc8465", "message": "Merge commit", "committedDate": null}, {"oid": "3a7e5d11e12d819ee055a33ffb8c428e1feaa863", "committedDate": "2021-04-12 13:52:08 -0700", "message": "[CDAP-17693] Introduce spark 3 for tests, drop spark 1, create spark 3 runtime for cdap sandbox and standalone"}]}, {"oid": "6e073de9df71529b001e8d99ed10aa357b365616", "url": "https://github.com/cdapio/cdap/commit/6e073de9df71529b001e8d99ed10aa357b365616", "message": "Revert CDAP-16784, removing Kryo as default", "committedDate": "2020-08-10T18:16:30Z", "type": "commit"}, {"oid": "6e073de9df71529b001e8d99ed10aa357b365616", "url": "https://github.com/cdapio/cdap/commit/6e073de9df71529b001e8d99ed10aa357b365616", "message": "Revert CDAP-16784, removing Kryo as default", "committedDate": "2020-08-10T18:16:30Z", "type": "forcePushed"}]}