{"pr_number": 3370, "pr_title": "Introduce backward analysis to dataflow framework.", "pr_author": "xingweitian", "pr_createdAt": "2020-06-13T05:41:11Z", "pr_url": "https://github.com/typetools/checker-framework/pull/3370", "merge_commit": "e8bbd7fa9795def75001875908771ea91100b353", "timeline": [{"oid": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "url": "https://github.com/typetools/checker-framework/commit/737e03ef9e90ec686ea1233f2302c64d37c284aa", "message": "Refactor dataflow framework. Introduce backward analysis.\n\nCo-authored-by: Charles Chen <Charleszhuochen@gmail.com>", "committedDate": "2020-06-13T03:44:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNDc5Ng==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441134796", "body": "is `node` in this line referring to the input `node` or to nodes generally? The given text isn't clear.", "bodyText": "is node in this line referring to the input node or to nodes generally? The given text isn't clear.", "bodyHTML": "<p dir=\"auto\">is <code>node</code> in this line referring to the input <code>node</code> or to nodes generally? The given text isn't clear.</p>", "author": "kelloggm", "createdAt": "2020-06-16T20:52:14Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": {"commit": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -70,7 +71,7 @@ public interface Analysis<\n      * @param before the boolean value to indicate which store to return (if it is true, return the\n      *     store immediately before {@code node}; otherwise, the store after {@code node} is\n      *     returned)\n-     * @param transferInput the transfer input of the block of this node\n+     * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n      * @return the store before or after {@code node} (depends on the value of {@code before}) after\n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -68,9 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return (if it is true, return the\n-     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n-     *     returned)\n+     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n+     *     or the store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..0e141dfeb 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,8 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n+     * @param preOrPost which store to return: the store immediately before {@code node} or the\n+     *     store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 0e141dfeb..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost which store to return: the store immediately before {@code node} or the\n-     *     store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +80,7 @@ public interface Analysis<\n     S runAnalysisFor(\n             Node node,\n             boolean before,\n-            TransferInput<V, S> transferInput,\n+            TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n \n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "dbb8241f3a4a1bf3a0423c643004358d47c0683e", "committedDate": "2020-07-20 16:43:08 -0400", "message": "Move `getValue(Tree)` to Analysis interface. (#3420)"}, {"oid": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "committedDate": "2020-09-10 15:32:25 -0700", "message": "Rename some occurrences of `transferInput` to `blockTransferInput`"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "committedDate": "2020-12-22 10:08:40 -0800", "message": "Infer method contracts"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNDk3Ng==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441134976", "body": "create->creates\r\nstore->stores", "bodyText": "create->creates\nstore->stores", "bodyHTML": "<p dir=\"auto\">create-&gt;creates<br>\nstore-&gt;stores</p>", "author": "kelloggm", "createdAt": "2020-06-16T20:52:36Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n+     * is not in {@code analysisCaches}, this method create new cache and store it in {@code", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": {"commit": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -70,7 +71,7 @@ public interface Analysis<\n      * @param before the boolean value to indicate which store to return (if it is true, return the\n      *     store immediately before {@code node}; otherwise, the store after {@code node} is\n      *     returned)\n-     * @param transferInput the transfer input of the block of this node\n+     * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n      * @return the store before or after {@code node} (depends on the value of {@code before}) after\n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -68,9 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return (if it is true, return the\n-     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n-     *     returned)\n+     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n+     *     or the store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..0e141dfeb 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,8 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n+     * @param preOrPost which store to return: the store immediately before {@code node} or the\n+     *     store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 0e141dfeb..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost which store to return: the store immediately before {@code node} or the\n-     *     store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +80,7 @@ public interface Analysis<\n     S runAnalysisFor(\n             Node node,\n             boolean before,\n-            TransferInput<V, S> transferInput,\n+            TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n \n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "dbb8241f3a4a1bf3a0423c643004358d47c0683e", "committedDate": "2020-07-20 16:43:08 -0400", "message": "Move `getValue(Tree)` to Analysis interface. (#3420)"}, {"oid": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "committedDate": "2020-09-10 15:32:25 -0700", "message": "Rename some occurrences of `transferInput` to `blockTransferInput`"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "committedDate": "2020-12-22 10:08:40 -0800", "message": "Infer method contracts"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNTc2MA==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441135760", "body": "This comment about `before` isn't very helpful. The text earlier about which store is returned depending on this value is much more informative, and I suggest you move that information here.", "bodyText": "This comment about before isn't very helpful. The text earlier about which store is returned depending on this value is much more informative, and I suggest you move that information here.", "bodyHTML": "<p dir=\"auto\">This comment about <code>before</code> isn't very helpful. The text earlier about which store is returned depending on this value is much more informative, and I suggest you move that information here.</p>", "author": "kelloggm", "createdAt": "2020-06-16T20:54:08Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n+     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n+     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n      *\n-     * @param cfg the control flow graph to use\n-     */\n-    @EnsuresNonNull(\"this.cfg\")\n-    protected void init(ControlFlowGraph cfg) {\n-        thenStores.clear();\n-        elseStores.clear();\n-        if (blockCount != null) {\n-            blockCount.clear();\n-        }\n-        inputs.clear();\n-        storesAtReturnStatements.clear();\n-        nodeValues.clear();\n-        finalLocalValues.clear();\n-\n-        this.cfg = cfg;\n-        worklist.process(cfg);\n-        worklist.add(cfg.getEntryBlock());\n-\n-        List<LocalVariableNode> parameters = null;\n-        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n-        if (underlyingAST.getKind() == Kind.METHOD) {\n-            MethodTree tree = ((CFGMethod) underlyingAST).getMethod();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : tree.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-        } else if (underlyingAST.getKind() == Kind.LAMBDA) {\n-            LambdaExpressionTree lambda = ((CFGLambda) underlyingAST).getLambdaTree();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : lambda.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-\n-        } else {\n-            // nothing to do\n-        }\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        S initialStore = transferFunction.initialStore(underlyingAST, parameters);\n-        Block entry = cfg.getEntryBlock();\n-        thenStores.put(entry, initialStore);\n-        elseStores.put(entry, initialStore);\n-        inputs.put(entry, new TransferInput<>(null, this, initialStore));\n-    }\n-\n-    /**\n-     * Add a basic block to the worklist. If {@code b} is already present, the method does nothing.\n+     * @param node the node to analyze\n+     * @param before the boolean value to indicate which store to return", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzODI2Mg==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441138262", "bodyText": "I would also consider changing before to an enum, so that callsites say Store.BEFORE and Store.AFTER rather than just true and false. Distinguishing between true and false at callsites makes them harder to read.", "author": "kelloggm", "createdAt": "2020-06-16T20:58:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNTc2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTgyOTUwMw==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441829503", "bodyText": "I would also consider changing before to an enum, so that callsites say Store.BEFORE and Store.AFTER rather than just true and false. Distinguishing between true and false at callsites makes them harder to read.\n\nThis is a separate change, not related to the change of this pull request (introducing backward analysis). I will open an issue for future reference.", "author": "xingweitian", "createdAt": "2020-06-17T20:56:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNTc2MA=="}], "type": "inlineReview", "revised_code": {"commit": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": {"commit": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -70,7 +71,7 @@ public interface Analysis<\n      * @param before the boolean value to indicate which store to return (if it is true, return the\n      *     store immediately before {@code node}; otherwise, the store after {@code node} is\n      *     returned)\n-     * @param transferInput the transfer input of the block of this node\n+     * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n      * @return the store before or after {@code node} (depends on the value of {@code before}) after\n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -68,9 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return (if it is true, return the\n-     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n-     *     returned)\n+     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n+     *     or the store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..0e141dfeb 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,8 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n+     * @param preOrPost which store to return: the store immediately before {@code node} or the\n+     *     store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 0e141dfeb..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost which store to return: the store immediately before {@code node} or the\n-     *     store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +80,7 @@ public interface Analysis<\n     S runAnalysisFor(\n             Node node,\n             boolean before,\n-            TransferInput<V, S> transferInput,\n+            TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n \n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "dbb8241f3a4a1bf3a0423c643004358d47c0683e", "committedDate": "2020-07-20 16:43:08 -0400", "message": "Move `getValue(Tree)` to Analysis interface. (#3420)"}, {"oid": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "committedDate": "2020-09-10 15:32:25 -0700", "message": "Rename some occurrences of `transferInput` to `blockTransferInput`"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "committedDate": "2020-12-22 10:08:40 -0800", "message": "Infer method contracts"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNjA2OQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441136069", "body": "The value of `before` also decides which store is returned, so this comment is ambiguous.", "bodyText": "The value of before also decides which store is returned, so this comment is ambiguous.", "bodyHTML": "<p dir=\"auto\">The value of <code>before</code> also decides which store is returned, so this comment is ambiguous.</p>", "author": "kelloggm", "createdAt": "2020-06-16T20:54:44Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n+     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n+     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n      *\n-     * @param cfg the control flow graph to use\n-     */\n-    @EnsuresNonNull(\"this.cfg\")\n-    protected void init(ControlFlowGraph cfg) {\n-        thenStores.clear();\n-        elseStores.clear();\n-        if (blockCount != null) {\n-            blockCount.clear();\n-        }\n-        inputs.clear();\n-        storesAtReturnStatements.clear();\n-        nodeValues.clear();\n-        finalLocalValues.clear();\n-\n-        this.cfg = cfg;\n-        worklist.process(cfg);\n-        worklist.add(cfg.getEntryBlock());\n-\n-        List<LocalVariableNode> parameters = null;\n-        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n-        if (underlyingAST.getKind() == Kind.METHOD) {\n-            MethodTree tree = ((CFGMethod) underlyingAST).getMethod();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : tree.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-        } else if (underlyingAST.getKind() == Kind.LAMBDA) {\n-            LambdaExpressionTree lambda = ((CFGLambda) underlyingAST).getLambdaTree();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : lambda.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-\n-        } else {\n-            // nothing to do\n-        }\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        S initialStore = transferFunction.initialStore(underlyingAST, parameters);\n-        Block entry = cfg.getEntryBlock();\n-        thenStores.put(entry, initialStore);\n-        elseStores.put(entry, initialStore);\n-        inputs.put(entry, new TransferInput<>(null, this, initialStore));\n-    }\n-\n-    /**\n-     * Add a basic block to the worklist. If {@code b} is already present, the method does nothing.\n+     * @param node the node to analyze\n+     * @param before the boolean value to indicate which store to return\n+     * @param transferInput the transfer input of the block of this node\n+     * @param nodeValues abstract values of nodes\n+     * @param analysisCaches caches of analysis results\n+     * @return the store at the location of node after running the analysis", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 2f1adfcfb..476c61a75 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -59,18 +59,22 @@ public interface Analysis<\n     /**\n      * Runs the analysis again within the block of {@code node} and returns the store at the\n      * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n-     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n-     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n-     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n+     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n+     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n+     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n+     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n+     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n+     * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return\n+     * @param before the boolean value to indicate which store to return (if it is true, return the\n+     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n+     *     returned)\n      * @param transferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n-     * @return the store at the location of node after running the analysis\n+     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+     *     running the analysis\n      */\n     S runAnalysisFor(\n             Node node,\n", "next_change": {"commit": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -70,7 +71,7 @@ public interface Analysis<\n      * @param before the boolean value to indicate which store to return (if it is true, return the\n      *     store immediately before {@code node}; otherwise, the store after {@code node} is\n      *     returned)\n-     * @param transferInput the transfer input of the block of this node\n+     * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n      * @return the store before or after {@code node} (depends on the value of {@code before}) after\n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -68,9 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return (if it is true, return the\n-     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n-     *     returned)\n+     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n+     *     or the store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..0e141dfeb 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,8 +79,8 @@ public interface Analysis<\n      * the nodes.\n      *\n      * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n+     * @param preOrPost which store to return: the store immediately before {@code node} or the\n+     *     store after {@code node}\n      * @param blockTransferInput the transfer input of the block of this node\n      * @param nodeValues abstract values of nodes\n      * @param analysisCaches caches of analysis results\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 0e141dfeb..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost which store to return: the store immediately before {@code node} or the\n-     *     store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 476c61a75..ed45f121e 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +80,7 @@ public interface Analysis<\n     S runAnalysisFor(\n             Node node,\n             boolean before,\n-            TransferInput<V, S> transferInput,\n+            TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n \n", "next_change": {"commit": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex ed45f121e..87e39538f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -79,7 +89,7 @@ public interface Analysis<\n      */\n     S runAnalysisFor(\n             Node node,\n-            boolean before,\n+            Analysis.BeforeOrAfter preOrPost,\n             TransferInput<V, S> blockTransferInput,\n             IdentityHashMap<Node, V> nodeValues,\n             Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\nindex 87e39538f..92b5e9e8b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java\n", "chunk": "@@ -19,137 +19,135 @@ import org.checkerframework.dataflow.cfg.node.Node;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public interface Analysis<\n-        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n-\n-    /** The direction of an analysis instance. */\n-    enum Direction {\n-        /** The forward direction. */\n-        FORWARD,\n-        /** The backward direction. */\n-        BACKWARD\n-    }\n-\n-    /**\n-     * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n-     * given node.\n-     */\n-    public static enum BeforeOrAfter {\n-        /** Return the pre-store. */\n-        BEFORE,\n-        /** Return the post-store. */\n-        AFTER\n-    }\n-\n-    /**\n-     * Get the direction of this analysis.\n-     *\n-     * @return the direction of this analysis\n-     */\n-    Direction getDirection();\n-\n-    /**\n-     * Is the analysis currently running?\n-     *\n-     * @return true if the analysis is running currently, else false\n-     */\n-    boolean isRunning();\n-\n-    /**\n-     * Perform the actual analysis.\n-     *\n-     * @param cfg the control flow graph\n-     */\n-    void performAnalysis(ControlFlowGraph cfg);\n-\n-    /**\n-     * Perform the actual analysis on one block.\n-     *\n-     * @param b the block to analyze\n-     */\n-    void performAnalysisBlock(Block b);\n-\n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param node the node to analyze\n-     * @param preOrPost indicates which store to return: the store immediately before {@code node}\n-     *     or the store after {@code node}\n-     * @param blockTransferInput the transfer input of the block of this node\n-     * @param nodeValues abstract values of nodes\n-     * @param analysisCaches caches of analysis results\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    S runAnalysisFor(\n-            Node node,\n-            Analysis.BeforeOrAfter preOrPost,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n-\n-    /**\n-     * The result of running the analysis. This is only available once the analysis finished\n-     * running.\n-     *\n-     * @return the result of running the analysis\n-     */\n-    AnalysisResult<V, S> getResult();\n-\n-    /**\n-     * Get the transfer function of this analysis.\n-     *\n-     * @return the transfer function of this analysis\n-     */\n-    @Nullable T getTransferFunction();\n-\n-    /**\n-     * Get the transfer input of a given {@link Block} b.\n-     *\n-     * @param b a given Block\n-     * @return the transfer input of this Block\n-     */\n-    @Nullable TransferInput<V, S> getInput(Block b);\n-\n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n n a node\n-     * @return the abstract value for node {@code n}, or {@code null} if no information is available\n-     */\n-    @Nullable V getValue(Node n);\n-\n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    @Nullable V getValue(Tree t);\n-\n-    /**\n-     * Returns the regular exit store, or {@code null}, if there is no such store (because the\n-     * method cannot exit through the regular exit block).\n-     *\n-     * @return the regular exit store, or {@code null}, if there is no such store (because the\n-     *     method cannot exit through the regular exit block)\n-     */\n-    @Nullable S getRegularExitStore();\n-\n-    /**\n-     * Returns the exceptional exit store.\n-     *\n-     * @return the exceptional exit store\n-     */\n-    @Nullable S getExceptionalExitStore();\n+    V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n+\n+  /** The direction of an analysis instance. */\n+  enum Direction {\n+    /** The forward direction. */\n+    FORWARD,\n+    /** The backward direction. */\n+    BACKWARD\n+  }\n+\n+  /**\n+   * In calls to {@code Analysis#runAnalysisFor}, whether to return the store before or after the\n+   * given node.\n+   */\n+  public static enum BeforeOrAfter {\n+    /** Return the pre-store. */\n+    BEFORE,\n+    /** Return the post-store. */\n+    AFTER\n+  }\n+\n+  /**\n+   * Get the direction of this analysis.\n+   *\n+   * @return the direction of this analysis\n+   */\n+  Direction getDirection();\n+\n+  /**\n+   * Is the analysis currently running?\n+   *\n+   * @return true if the analysis is running currently, else false\n+   */\n+  boolean isRunning();\n+\n+  /**\n+   * Perform the actual analysis.\n+   *\n+   * @param cfg the control flow graph\n+   */\n+  void performAnalysis(ControlFlowGraph cfg);\n+\n+  /**\n+   * Perform the actual analysis on one block.\n+   *\n+   * @param b the block to analyze\n+   */\n+  void performAnalysisBlock(Block b);\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param blockTransferInput the transfer input of the block of this node\n+   * @param nodeValues abstract values of nodes\n+   * @param analysisCaches caches of analysis results\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches);\n+\n+  /**\n+   * The result of running the analysis. This is only available once the analysis finished running.\n+   *\n+   * @return the result of running the analysis\n+   */\n+  AnalysisResult<V, S> getResult();\n+\n+  /**\n+   * Get the transfer function of this analysis.\n+   *\n+   * @return the transfer function of this analysis\n+   */\n+  @Nullable T getTransferFunction();\n+\n+  /**\n+   * Get the transfer input of a given {@link Block} b.\n+   *\n+   * @param b a given Block\n+   * @return the transfer input of this Block\n+   */\n+  @Nullable TransferInput<V, S> getInput(Block b);\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n n a node\n+   * @return the abstract value for node {@code n}, or {@code null} if no information is available\n+   */\n+  @Nullable V getValue(Node n);\n+\n+  /**\n+   * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t the given tree\n+   * @return the abstract value for the given tree\n+   */\n+  @Nullable V getValue(Tree t);\n+\n+  /**\n+   * Returns the regular exit store, or {@code null}, if there is no such store (because the method\n+   * cannot exit through the regular exit block).\n+   *\n+   * @return the regular exit store, or {@code null}, if there is no such store (because the method\n+   *     cannot exit through the regular exit block)\n+   */\n+  @Nullable S getRegularExitStore();\n+\n+  /**\n+   * Returns the exceptional exit store.\n+   *\n+   * @return the exceptional exit store\n+   */\n+  @Nullable S getExceptionalExitStore();\n }\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "dbb8241f3a4a1bf3a0423c643004358d47c0683e", "committedDate": "2020-07-20 16:43:08 -0400", "message": "Move `getValue(Tree)` to Analysis interface. (#3420)"}, {"oid": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "committedDate": "2020-09-10 15:32:25 -0700", "message": "Rename some occurrences of `transferInput` to `blockTransferInput`"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "committedDate": "2020-12-22 10:08:40 -0800", "message": "Infer method contracts"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNjk1Ng==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441136956", "body": "I'm not sure what `\"waiting for being merged\"` means here. I think it can be replaced with `\"another treeLookup that will be merged into {@code treeLookup}\"`", "bodyText": "I'm not sure what \"waiting for being merged\" means here. I think it can be replaced with \"another treeLookup that will be merged into {@code treeLookup}\"", "bodyHTML": "<p dir=\"auto\">I'm not sure what <code>\"waiting for being merged\"</code> means here. I think it can be replaced with <code>\"another treeLookup that will be merged into {@code treeLookup}\"</code></p>", "author": "kelloggm", "createdAt": "2020-06-16T20:56:22Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java", "diffHunk": "@@ -127,7 +129,12 @@ public void combine(AnalysisResult<V, S> other) {\n         finalLocalValues.putAll(other.finalLocalValues);\n     }\n \n-    // Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n+    /**\n+     * Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n+     *\n+     * @param treeLookup a map from abstract syntax trees to sets of nodes\n+     * @param otherTreeLookup another treeLookup waiting for being merged into {@code treeLookup}", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\nindex 6d7dc7cad..ff0ec7d4a 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\n", "chunk": "@@ -133,7 +133,7 @@ public class AnalysisResult<V extends AbstractValue<V>, S extends Store<S>> {\n      * Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n      *\n      * @param treeLookup a map from abstract syntax trees to sets of nodes\n-     * @param otherTreeLookup another treeLookup waiting for being merged into {@code treeLookup}\n+     * @param otherTreeLookup another treeLookup that will be merged into {@code treeLookup}\n      */\n     private static void mergeTreeLookup(\n             IdentityHashMap<Tree, Set<Node>> treeLookup,\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\nindex 6d7dc7cad..e80977679 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\n", "chunk": "@@ -133,7 +132,7 @@ public class AnalysisResult<V extends AbstractValue<V>, S extends Store<S>> {\n      * Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n      *\n      * @param treeLookup a map from abstract syntax trees to sets of nodes\n-     * @param otherTreeLookup another treeLookup waiting for being merged into {@code treeLookup}\n+     * @param otherTreeLookup another treeLookup that will be merged into {@code treeLookup}\n      */\n     private static void mergeTreeLookup(\n             IdentityHashMap<Tree, Set<Node>> treeLookup,\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\nindex e80977679..2d9692833 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java\n", "chunk": "@@ -24,423 +27,476 @@ import org.checkerframework.javacutil.BugInCF;\n  * @param <V> type of the abstract value that is tracked\n  * @param <S> the store type used in the analysis\n  */\n-public class AnalysisResult<V extends AbstractValue<V>, S extends Store<S>> {\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from AST {@link Tree}s to sets of {@link Node}s. */\n-    protected final IdentityHashMap<Tree, Set<Node>> treeLookup;\n-\n-    /** Map from AST {@link UnaryTree}s to corresponding {@link AssignmentNode}s. */\n-    protected final IdentityHashMap<UnaryTree, AssignmentNode> unaryAssignNodeLookup;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    protected final HashMap<Element, V> finalLocalValues;\n-\n-    /** The stores before every method call. */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> stores;\n-\n-    /**\n-     * Caches of the analysis results for each input for the block of the node and each node.\n-     *\n-     * @see #runAnalysisFor(Node, boolean, TransferInput, IdentityHashMap, Map)\n-     */\n-    protected final Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>>\n-            analysisCaches;\n-\n-    /**\n-     * Initialize with given mappings.\n-     *\n-     * @param nodeValues {@link #nodeValues}\n-     * @param stores {@link #stores}\n-     * @param treeLookup {@link #treeLookup}\n-     * @param unaryAssignNodeLookup {@link #unaryAssignNodeLookup}\n-     * @param finalLocalValues {@link #finalLocalValues}\n-     * @param analysisCaches {@link #analysisCaches}\n-     */\n-    protected AnalysisResult(\n-            Map<Node, V> nodeValues,\n-            IdentityHashMap<Block, TransferInput<V, S>> stores,\n-            IdentityHashMap<Tree, Set<Node>> treeLookup,\n-            IdentityHashMap<UnaryTree, AssignmentNode> unaryAssignNodeLookup,\n-            HashMap<Element, V> finalLocalValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n-        this.nodeValues = new IdentityHashMap<>(nodeValues);\n-        this.treeLookup = new IdentityHashMap<>(treeLookup);\n-        this.unaryAssignNodeLookup = new IdentityHashMap<>(unaryAssignNodeLookup);\n-        // TODO: why are stores and finalLocalValues captured?\n-        this.stores = stores;\n-        this.finalLocalValues = finalLocalValues;\n-        this.analysisCaches = analysisCaches;\n-    }\n+public class AnalysisResult<V extends AbstractValue<V>, S extends Store<S>> implements UniqueId {\n \n-    /**\n-     * Initialize with given mappings and empty cache.\n-     *\n-     * @param nodeValues {@link #nodeValues}\n-     * @param stores {@link #stores}\n-     * @param treeLookup {@link #treeLookup}\n-     * @param unaryAssignNodeLookup {@link #unaryAssignNodeLookup}\n-     * @param finalLocalValues {@link #finalLocalValues}\n-     */\n-    public AnalysisResult(\n-            Map<Node, V> nodeValues,\n-            IdentityHashMap<Block, TransferInput<V, S>> stores,\n-            IdentityHashMap<Tree, Set<Node>> treeLookup,\n-            IdentityHashMap<UnaryTree, AssignmentNode> unaryAssignNodeLookup,\n-            HashMap<Element, V> finalLocalValues) {\n-        this(\n-                nodeValues,\n-                stores,\n-                treeLookup,\n-                unaryAssignNodeLookup,\n-                finalLocalValues,\n-                new IdentityHashMap<>());\n-    }\n+  /** Abstract values of nodes. */\n+  protected final IdentityHashMap<Node, V> nodeValues;\n \n-    /**\n-     * Initialize empty result with specified cache.\n-     *\n-     * @param analysisCaches {@link #analysisCaches}\n-     */\n-    public AnalysisResult(\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n-        this(\n-                new IdentityHashMap<>(),\n-                new IdentityHashMap<>(),\n-                new IdentityHashMap<>(),\n-                new IdentityHashMap<>(),\n-                new HashMap<>(),\n-                analysisCaches);\n-    }\n+  /**\n+   * Map from AST {@link Tree}s to sets of {@link Node}s.\n+   *\n+   * <p>Some of those Nodes might not be keys in {@link #nodeValues}. One reason is that the Node is\n+   * unreachable in the control flow graph, so dataflow never gave it a value.\n+   */\n+  protected final IdentityHashMap<Tree, Set<Node>> treeLookup;\n \n-    /**\n-     * Combine with another analysis result.\n-     *\n-     * @param other an analysis result to combine with this\n-     */\n-    public void combine(AnalysisResult<V, S> other) {\n-        nodeValues.putAll(other.nodeValues);\n-        mergeTreeLookup(treeLookup, other.treeLookup);\n-        unaryAssignNodeLookup.putAll(other.unaryAssignNodeLookup);\n-        stores.putAll(other.stores);\n-        finalLocalValues.putAll(other.finalLocalValues);\n-    }\n+  /** Map from AST {@link UnaryTree}s to corresponding {@link AssignmentNode}s. */\n+  protected final IdentityHashMap<UnaryTree, AssignmentNode> unaryAssignNodeLookup;\n \n-    /**\n-     * Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n-     *\n-     * @param treeLookup a map from abstract syntax trees to sets of nodes\n-     * @param otherTreeLookup another treeLookup that will be merged into {@code treeLookup}\n-     */\n-    private static void mergeTreeLookup(\n-            IdentityHashMap<Tree, Set<Node>> treeLookup,\n-            IdentityHashMap<Tree, Set<Node>> otherTreeLookup) {\n-        for (Map.Entry<Tree, Set<Node>> entry : otherTreeLookup.entrySet()) {\n-            Set<Node> hit = treeLookup.get(entry.getKey());\n-            if (hit == null) {\n-                treeLookup.put(entry.getKey(), entry.getValue());\n-            } else {\n-                hit.addAll(entry.getValue());\n-            }\n-        }\n-    }\n+  /** Map from (effectively final) local variable elements to their abstract value. */\n+  protected final HashMap<Element, V> finalLocalValues;\n \n-    /**\n-     * Returns the value of effectively final local variables.\n-     *\n-     * @return the value of effectively final local variables\n-     */\n-    public HashMap<Element, V> getFinalLocalValues() {\n-        return finalLocalValues;\n-    }\n+  /** The stores before every method call. */\n+  protected final IdentityHashMap<Block, TransferInput<V, S>> stores;\n \n-    /**\n-     * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param n a node\n-     * @return the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n-     *     available\n-     */\n-    public @Nullable V getValue(Node n) {\n-        return nodeValues.get(n);\n-    }\n+  /**\n+   * Caches of the analysis results for each input for the block of the node and each node.\n+   *\n+   * @see #runAnalysisFor(Node, Analysis.BeforeOrAfter, TransferInput, IdentityHashMap, Map)\n+   */\n+  protected final Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>>\n+      analysisCaches;\n \n-    /**\n-     * Returns the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t a tree\n-     * @return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     *     available\n-     */\n-    public @Nullable V getValue(Tree t) {\n-        Set<Node> nodes = treeLookup.get(t);\n-\n-        if (nodes == null) {\n-            return null;\n-        }\n-        V merged = null;\n-        for (Node aNode : nodes) {\n-            V a = getValue(aNode);\n-            if (merged == null) {\n-                merged = a;\n-            } else if (a != null) {\n-                merged = merged.leastUpperBound(a);\n-            }\n-        }\n-        return merged;\n-    }\n+  /** The unique ID for the next-created object. */\n+  static final AtomicLong nextUid = new AtomicLong(0);\n+  /** The unique ID of this object. */\n+  final transient long uid = nextUid.getAndIncrement();\n+\n+  @Override\n+  public long getUid(@UnknownInitialization AnalysisResult<V, S> this) {\n+    return uid;\n+  }\n+\n+  /**\n+   * Initialize with given mappings.\n+   *\n+   * @param nodeValues {@link #nodeValues}\n+   * @param stores {@link #stores}\n+   * @param treeLookup {@link #treeLookup}\n+   * @param unaryAssignNodeLookup {@link #unaryAssignNodeLookup}\n+   * @param finalLocalValues {@link #finalLocalValues}\n+   * @param analysisCaches {@link #analysisCaches}\n+   */\n+  protected AnalysisResult(\n+      IdentityHashMap<Node, V> nodeValues,\n+      IdentityHashMap<Block, TransferInput<V, S>> stores,\n+      IdentityHashMap<Tree, Set<Node>> treeLookup,\n+      IdentityHashMap<UnaryTree, AssignmentNode> unaryAssignNodeLookup,\n+      HashMap<Element, V> finalLocalValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+    this.nodeValues = new IdentityHashMap<>(nodeValues);\n+    this.treeLookup = new IdentityHashMap<>(treeLookup);\n+    this.unaryAssignNodeLookup = new IdentityHashMap<>(unaryAssignNodeLookup);\n+    // TODO: why are stores and finalLocalValues captured?\n+    this.stores = stores;\n+    this.finalLocalValues = finalLocalValues;\n+    this.analysisCaches = analysisCaches;\n+  }\n+\n+  /**\n+   * Initialize with given mappings and empty cache.\n+   *\n+   * @param nodeValues {@link #nodeValues}\n+   * @param stores {@link #stores}\n+   * @param treeLookup {@link #treeLookup}\n+   * @param unaryAssignNodeLookup {@link #unaryAssignNodeLookup}\n+   * @param finalLocalValues {@link #finalLocalValues}\n+   */\n+  public AnalysisResult(\n+      IdentityHashMap<Node, V> nodeValues,\n+      IdentityHashMap<Block, TransferInput<V, S>> stores,\n+      IdentityHashMap<Tree, Set<Node>> treeLookup,\n+      IdentityHashMap<UnaryTree, AssignmentNode> unaryAssignNodeLookup,\n+      HashMap<Element, V> finalLocalValues) {\n+    this(\n+        nodeValues,\n+        stores,\n+        treeLookup,\n+        unaryAssignNodeLookup,\n+        finalLocalValues,\n+        new IdentityHashMap<>());\n+  }\n+\n+  /**\n+   * Initialize empty result with specified cache.\n+   *\n+   * @param analysisCaches {@link #analysisCaches}\n+   */\n+  public AnalysisResult(\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+    this(\n+        new IdentityHashMap<>(),\n+        new IdentityHashMap<>(),\n+        new IdentityHashMap<>(),\n+        new IdentityHashMap<>(),\n+        new HashMap<>(),\n+        analysisCaches);\n+  }\n \n-    /**\n-     * Returns the {@code Node}s corresponding to a particular {@code Tree}. Multiple {@code Node}s\n-     * can correspond to a single {@code Tree} because of several reasons:\n-     *\n-     * <ol>\n-     *   <li>In a lambda expression such as {@code () -> 5} the {@code 5} is both an {@code\n-     *       IntegerLiteralNode} and a {@code LambdaResultExpressionNode}.\n-     *   <li>Narrowing and widening primitive conversions can result in {@code\n-     *       NarrowingConversionNode} and {@code WideningConversionNode}.\n-     *   <li>Automatic String conversion can result in a {@code StringConversionNode}.\n-     *   <li>Trees for {@code finally} blocks are cloned to achieve a precise CFG. Any {@code Tree}\n-     *       within a finally block can have multiple corresponding {@code Node}s attached to them.\n-     * </ol>\n-     *\n-     * Callers of this method should always iterate through the returned set, possibly ignoring all\n-     * {@code Node}s they are not interested in.\n-     *\n-     * @param tree a tree\n-     * @return the set of {@link Node}s for a given {@link Tree}\n-     */\n-    public @Nullable Set<Node> getNodesForTree(Tree tree) {\n-        return treeLookup.get(tree);\n+  /**\n+   * Combine with another analysis result.\n+   *\n+   * @param other an analysis result to combine with this\n+   */\n+  public void combine(AnalysisResult<V, S> other) {\n+    nodeValues.putAll(other.nodeValues);\n+    mergeTreeLookup(treeLookup, other.treeLookup);\n+    unaryAssignNodeLookup.putAll(other.unaryAssignNodeLookup);\n+    stores.putAll(other.stores);\n+    finalLocalValues.putAll(other.finalLocalValues);\n+  }\n+\n+  /**\n+   * Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n+   *\n+   * @param treeLookup a map from abstract syntax trees to sets of nodes\n+   * @param otherTreeLookup another treeLookup that will be merged into {@code treeLookup}\n+   */\n+  private static void mergeTreeLookup(\n+      IdentityHashMap<Tree, Set<Node>> treeLookup,\n+      IdentityHashMap<Tree, Set<Node>> otherTreeLookup) {\n+    for (Map.Entry<Tree, Set<Node>> entry : otherTreeLookup.entrySet()) {\n+      Set<Node> hit = treeLookup.get(entry.getKey());\n+      if (hit == null) {\n+        treeLookup.put(entry.getKey(), entry.getValue());\n+      } else {\n+        hit.addAll(entry.getValue());\n+      }\n     }\n+  }\n \n-    /**\n-     * Returns the corresponding {@link AssignmentNode} for a given {@link UnaryTree}.\n-     *\n-     * @param tree a unary tree\n-     * @return the corresponding assignment node\n-     */\n-    public AssignmentNode getAssignForUnaryTree(UnaryTree tree) {\n-        if (!unaryAssignNodeLookup.containsKey(tree)) {\n-            throw new BugInCF(tree + \" is not in unaryAssignNodeLookup\");\n-        }\n-        return unaryAssignNodeLookup.get(tree);\n+  /**\n+   * Returns the value of effectively final local variables.\n+   *\n+   * @return the value of effectively final local variables\n+   */\n+  public HashMap<Element, V> getFinalLocalValues() {\n+    return finalLocalValues;\n+  }\n+\n+  /**\n+   * Returns the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param n a node\n+   * @return the abstract value for {@link Node} {@code n}, or {@code null} if no information is\n+   *     available\n+   */\n+  public @Nullable V getValue(Node n) {\n+    return nodeValues.get(n);\n+  }\n+\n+  /**\n+   * Returns the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   * available. Note that if the analysis has not finished yet, this value might not represent the\n+   * final value for this node.\n+   *\n+   * @param t a tree\n+   * @return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n+   *     available\n+   */\n+  public @Nullable V getValue(Tree t) {\n+    Set<Node> nodes = treeLookup.get(t);\n+\n+    if (nodes == null) {\n+      return null;\n     }\n+    V merged = null;\n+    for (Node aNode : nodes) {\n+      V a = getValue(aNode);\n+      if (merged == null) {\n+        merged = a;\n+      } else if (a != null) {\n+        merged = merged.leastUpperBound(a);\n+      }\n+    }\n+    return merged;\n+  }\n \n-    /**\n-     * Returns the store immediately before a given {@link Tree}.\n-     *\n-     * @param tree a tree\n-     * @return the store immediately before a given {@link Tree}\n-     */\n-    public @Nullable S getStoreBefore(Tree tree) {\n-        Set<Node> nodes = getNodesForTree(tree);\n-        if (nodes == null) {\n-            return null;\n-        }\n-        S merged = null;\n-        for (Node node : nodes) {\n-            S s = getStoreBefore(node);\n-            if (merged == null) {\n-                merged = s;\n-            } else if (s != null) {\n-                merged = merged.leastUpperBound(s);\n-            }\n-        }\n-        return merged;\n+  /**\n+   * Returns the {@code Node}s corresponding to a particular {@code Tree}. Multiple {@code Node}s\n+   * can correspond to a single {@code Tree} because of several reasons:\n+   *\n+   * <ol>\n+   *   <li>In a lambda expression such as {@code () -> 5} the {@code 5} is both an {@code\n+   *       IntegerLiteralNode} and a {@code LambdaResultExpressionNode}.\n+   *   <li>Widening and narrowing primitive conversions can result in {@code WideningConversionNode}\n+   *       and {@code NarrowingConversionNode}.\n+   *   <li>Automatic String conversion can result in a {@code StringConversionNode}.\n+   *   <li>Trees for {@code finally} blocks are cloned to achieve a precise CFG. Any {@code Tree}\n+   *       within a finally block can have multiple corresponding {@code Node}s attached to them.\n+   * </ol>\n+   *\n+   * Callers of this method should always iterate through the returned set, possibly ignoring all\n+   * {@code Node}s they are not interested in.\n+   *\n+   * @param tree a tree\n+   * @return the set of {@link Node}s for a given {@link Tree}\n+   */\n+  public @Nullable Set<Node> getNodesForTree(Tree tree) {\n+    return treeLookup.get(tree);\n+  }\n+\n+  /**\n+   * Returns the corresponding {@link AssignmentNode} for a given {@link UnaryTree}.\n+   *\n+   * @param tree a unary tree\n+   * @return the corresponding assignment node\n+   */\n+  public AssignmentNode getAssignForUnaryTree(UnaryTree tree) {\n+    if (!unaryAssignNodeLookup.containsKey(tree)) {\n+      throw new BugInCF(tree + \" is not in unaryAssignNodeLookup\");\n     }\n+    return unaryAssignNodeLookup.get(tree);\n+  }\n \n-    /**\n-     * Returns the store immediately before a given {@link Node}.\n-     *\n-     * @param node a node\n-     * @return the store immediately before a given {@link Node}\n-     */\n-    public @Nullable S getStoreBefore(Node node) {\n-        return runAnalysisFor(node, true);\n+  /**\n+   * Returns the store immediately before a given {@link Tree}.\n+   *\n+   * @param tree a tree\n+   * @return the store immediately before a given {@link Tree}\n+   */\n+  public @Nullable S getStoreBefore(Tree tree) {\n+    Set<Node> nodes = getNodesForTree(tree);\n+    if (nodes == null) {\n+      return null;\n+    }\n+    S merged = null;\n+    for (Node node : nodes) {\n+      S s = getStoreBefore(node);\n+      if (merged == null) {\n+        merged = s;\n+      } else if (s != null) {\n+        merged = merged.leastUpperBound(s);\n+      }\n     }\n+    return merged;\n+  }\n \n-    /**\n-     * Returns the regular store immediately before a given {@link Block}.\n-     *\n-     * @param block a block\n-     * @return the store right before the given block\n-     */\n-    public S getStoreBefore(Block block) {\n-        TransferInput<V, S> transferInput = stores.get(block);\n-        assert transferInput != null\n-                : \"@AssumeAssertion(nullness): transferInput should be non-null\";\n-        Analysis<V, S, ?> analysis = transferInput.analysis;\n-        switch (analysis.getDirection()) {\n-            case FORWARD:\n-                return transferInput.getRegularStore();\n-            case BACKWARD:\n-                Node firstNode;\n-                switch (block.getType()) {\n-                    case REGULAR_BLOCK:\n-                        firstNode = ((RegularBlock) block).getContents().get(0);\n-                        break;\n-                    case EXCEPTION_BLOCK:\n-                        firstNode = ((ExceptionBlock) block).getNode();\n-                        break;\n-                    default:\n-                        firstNode = null;\n-                }\n-                if (firstNode == null) {\n-                    // This block doesn't contains any node, return the store in the transfer input\n-                    return transferInput.getRegularStore();\n-                }\n-                return analysis.runAnalysisFor(\n-                        firstNode, true, transferInput, nodeValues, analysisCaches);\n-            default:\n-                throw new BugInCF(\"Unknown direction: \" + analysis.getDirection());\n+  /**\n+   * Returns the store immediately before a given {@link Node}.\n+   *\n+   * @param node a node\n+   * @return the store immediately before a given {@link Node}\n+   */\n+  public @Nullable S getStoreBefore(Node node) {\n+    return runAnalysisFor(node, Analysis.BeforeOrAfter.BEFORE);\n+  }\n+\n+  /**\n+   * Returns the regular store immediately before a given {@link Block}.\n+   *\n+   * @param block a block\n+   * @return the store right before the given block\n+   */\n+  public S getStoreBefore(Block block) {\n+    TransferInput<V, S> transferInput = stores.get(block);\n+    assert transferInput != null : \"@AssumeAssertion(nullness): transferInput should be non-null\";\n+    Analysis<V, S, ?> analysis = transferInput.analysis;\n+    switch (analysis.getDirection()) {\n+      case FORWARD:\n+        return transferInput.getRegularStore();\n+      case BACKWARD:\n+        Node firstNode;\n+        switch (block.getType()) {\n+          case REGULAR_BLOCK:\n+            firstNode = block.getNodes().get(0);\n+            break;\n+          case EXCEPTION_BLOCK:\n+            firstNode = ((ExceptionBlock) block).getNode();\n+            break;\n+          default:\n+            firstNode = null;\n+        }\n+        if (firstNode == null) {\n+          // This block doesn't contains any node, return the store in the transfer input\n+          return transferInput.getRegularStore();\n         }\n+        return analysis.runAnalysisFor(\n+            firstNode, Analysis.BeforeOrAfter.BEFORE, transferInput, nodeValues, analysisCaches);\n+      default:\n+        throw new BugInCF(\"Unknown direction: \" + analysis.getDirection());\n     }\n+  }\n \n-    /**\n-     * Returns the regular store immediately after a given block.\n-     *\n-     * @param block a block\n-     * @return the store after the given block\n-     */\n-    public S getStoreAfter(Block block) {\n-        TransferInput<V, S> transferInput = stores.get(block);\n-        assert transferInput != null\n-                : \"@AssumeAssertion(nullness): transferInput should be non-null\";\n-        Analysis<V, S, ?> analysis = transferInput.analysis;\n-        switch (analysis.getDirection()) {\n-            case FORWARD:\n-                Node lastNode = getLastNode(block);\n-                if (lastNode == null) {\n-                    // This block doesn't contains any node, return the store in the transfer input\n-                    return transferInput.getRegularStore();\n-                }\n-                return analysis.runAnalysisFor(\n-                        lastNode, false, transferInput, nodeValues, analysisCaches);\n-            case BACKWARD:\n-                return transferInput.getRegularStore();\n-            default:\n-                throw new BugInCF(\"Unknown direction: \" + analysis.getDirection());\n+  /**\n+   * Returns the regular store immediately after a given block.\n+   *\n+   * @param block a block\n+   * @return the store after the given block\n+   */\n+  public S getStoreAfter(Block block) {\n+    TransferInput<V, S> transferInput = stores.get(block);\n+    assert transferInput != null : \"@AssumeAssertion(nullness): transferInput should be non-null\";\n+    Analysis<V, S, ?> analysis = transferInput.analysis;\n+    switch (analysis.getDirection()) {\n+      case FORWARD:\n+        Node lastNode = block.getLastNode();\n+        if (lastNode == null) {\n+          // This block doesn't contain any node, return the store in the transfer input\n+          return transferInput.getRegularStore();\n         }\n+        return analysis.runAnalysisFor(\n+            lastNode, Analysis.BeforeOrAfter.AFTER, transferInput, nodeValues, analysisCaches);\n+      case BACKWARD:\n+        return transferInput.getRegularStore();\n+      default:\n+        throw new BugInCF(\"Unknown direction: \" + analysis.getDirection());\n     }\n+  }\n \n-    /**\n-     * Returns the last node of the given block, or {@code null} if none.\n-     *\n-     * @param block the block\n-     * @return the last node of this block or {@code null}\n-     */\n-    protected @Nullable Node getLastNode(Block block) {\n-        switch (block.getType()) {\n-            case REGULAR_BLOCK:\n-                List<Node> blockContents = ((RegularBlock) block).getContents();\n-                return blockContents.get(blockContents.size() - 1);\n-            case CONDITIONAL_BLOCK:\n-            case SPECIAL_BLOCK:\n-                return null;\n-            case EXCEPTION_BLOCK:\n-                return ((ExceptionBlock) block).getNode();\n-            default:\n-                throw new BugInCF(\"Unrecognized block type: \" + block.getType());\n-        }\n+  /**\n+   * Returns the store immediately after a given {@link Tree}.\n+   *\n+   * @param tree a tree\n+   * @return the store immediately after a given {@link Tree}\n+   */\n+  public @Nullable S getStoreAfter(Tree tree) {\n+    Set<Node> nodes = getNodesForTree(tree);\n+    if (nodes == null) {\n+      return null;\n     }\n+    S merged = null;\n+    for (Node node : nodes) {\n+      S s = getStoreAfter(node);\n+      if (merged == null) {\n+        merged = s;\n+      } else if (s != null) {\n+        merged = merged.leastUpperBound(s);\n+      }\n+    }\n+    return merged;\n+  }\n \n-    /**\n-     * Returns the store immediately after a given {@link Tree}.\n-     *\n-     * @param tree a tree\n-     * @return the store immediately after a given {@link Tree}\n-     */\n-    public @Nullable S getStoreAfter(Tree tree) {\n-        Set<Node> nodes = getNodesForTree(tree);\n-        if (nodes == null) {\n-            return null;\n-        }\n-        S merged = null;\n-        for (Node node : nodes) {\n-            S s = getStoreAfter(node);\n-            if (merged == null) {\n-                merged = s;\n-            } else if (s != null) {\n-                merged = merged.leastUpperBound(s);\n-            }\n-        }\n-        return merged;\n+  /**\n+   * Returns the store immediately after a given {@link Node}.\n+   *\n+   * @param node a node\n+   * @return the store immediately after a given {@link Node}\n+   */\n+  public @Nullable S getStoreAfter(Node node) {\n+    return runAnalysisFor(node, Analysis.BeforeOrAfter.AFTER);\n+  }\n+\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+   *\n+   * <p>If the given {@link Node} cannot be reached (in the control flow graph), then {@code null}\n+   * is returned.\n+   *\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  protected @Nullable S runAnalysisFor(Node node, Analysis.BeforeOrAfter preOrPost) {\n+    Block block = node.getBlock();\n+    assert block != null : \"@AssumeAssertion(nullness): invariant\";\n+    TransferInput<V, S> transferInput = stores.get(block);\n+    if (transferInput == null) {\n+      return null;\n     }\n+    return runAnalysisFor(node, preOrPost, transferInput, nodeValues, analysisCaches);\n+  }\n \n-    /**\n-     * Returns the store immediately after a given {@link Node}.\n-     *\n-     * @param node a node\n-     * @return the store immediately after a given {@link Node}\n-     */\n-    public @Nullable S getStoreAfter(Node node) {\n-        return runAnalysisFor(node, false);\n+  /**\n+   * Runs the analysis again within the block of {@code node} and returns the store at the location\n+   * of {@code node}. If {@code before} is true, then the store immediately before the {@link Node}\n+   * {@code node} is returned. Otherwise, the store immediately after {@code node} is returned. If\n+   * {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a map\n+   * of a block of node to the cached analysis result. If the cache for {@code transferInput} is not\n+   * in {@code analysisCaches}, this method creates new cache and stores it in {@code\n+   * analysisCaches}. The cache is a map of nodes to the analysis results of the nodes.\n+   *\n+   * @param <V> the abstract value type to be tracked by the analysis\n+   * @param <S> the store type used in the analysis\n+   * @param node the node to analyze\n+   * @param preOrPost which store to return: the store immediately before {@code node} or the store\n+   *     after {@code node}\n+   * @param transferInput a transfer input\n+   * @param nodeValues {@link #nodeValues}\n+   * @param analysisCaches {@link #analysisCaches}\n+   * @return the store before or after {@code node} (depends on the value of {@code before}) after\n+   *     running the analysis\n+   */\n+  public static <V extends AbstractValue<V>, S extends Store<S>> S runAnalysisFor(\n+      Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> transferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+    if (transferInput.analysis == null) {\n+      throw new BugInCF(\"Analysis in transferInput cannot be null.\");\n     }\n+    return transferInput.analysis.runAnalysisFor(\n+        node, preOrPost, transferInput, nodeValues, analysisCaches);\n+  }\n \n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n-     *\n-     * <p>If the given {@link Node} cannot be reached (in the control flow graph), then {@code null}\n-     * is returned.\n-     *\n-     * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return (if it is true, return the\n-     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n-     *     returned)\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    protected @Nullable S runAnalysisFor(Node node, boolean before) {\n-        Block block = node.getBlock();\n-        assert block != null : \"@AssumeAssertion(nullness): invariant\";\n-        TransferInput<V, S> transferInput = stores.get(block);\n-        if (transferInput == null) {\n-            return null;\n-        }\n-        return runAnalysisFor(node, before, transferInput, nodeValues, analysisCaches);\n+  /**\n+   * Returns a verbose string representation of this, useful for debugging.\n+   *\n+   * @return a string representation of this\n+   */\n+  public String toStringDebug() {\n+    StringJoiner result =\n+        new StringJoiner(\n+            String.format(\"%n  \"), String.format(\"AnalysisResult{%n  \"), String.format(\"%n}\"));\n+    result.add(\"nodeValues = \" + nodeValuesToString(nodeValues));\n+    result.add(\"treeLookup = \" + treeLookupToString(treeLookup));\n+    result.add(\"unaryAssignNodeLookup = \" + unaryAssignNodeLookup);\n+    result.add(\"finalLocalValues = \" + finalLocalValues);\n+    result.add(\"stores = \" + stores);\n+    result.add(\"analysisCaches = \" + analysisCaches);\n+    return result.toString();\n+  }\n+\n+  /**\n+   * Returns a verbose string representation, useful for debugging. The map has the same type as the\n+   * {@code nodeValues} field.\n+   *\n+   * @param <V> the type of values in the map\n+   * @param nodeValues a map to format\n+   * @return a printed representation of the given map\n+   */\n+  public static <V> String nodeValuesToString(Map<Node, V> nodeValues) {\n+    if (nodeValues.isEmpty()) {\n+      return \"{}\";\n+    }\n+    StringJoiner result = new StringJoiner(String.format(\"%n    \"));\n+    result.add(\"{\");\n+    for (Map.Entry<Node, V> entry : nodeValues.entrySet()) {\n+      Node key = entry.getKey();\n+      result.add(String.format(\"%s => %s\", key.toStringDebug(), entry.getValue()));\n     }\n+    result.add(\"}\");\n+    return result.toString();\n+  }\n \n-    /**\n-     * Runs the analysis again within the block of {@code node} and returns the store at the\n-     * location of {@code node}. If {@code before} is true, then the store immediately before the\n-     * {@link Node} {@code node} is returned. Otherwise, the store immediately after {@code node} is\n-     * returned. If {@code analysisCaches} is not null, this method uses a cache. {@code\n-     * analysisCaches} is a map of a block of node to the cached analysis result. If the cache for\n-     * {@code transferInput} is not in {@code analysisCaches}, this method creates new cache and\n-     * stores it in {@code analysisCaches}. The cache is a map of nodes to the analysis results of\n-     * the nodes.\n-     *\n-     * @param <V> the abstract value type to be tracked by the analysis\n-     * @param <S> the store type used in the analysis\n-     * @param node the node to analyze\n-     * @param before the boolean value to indicate which store to return (if it is true, return the\n-     *     store immediately before {@code node}; otherwise, the store after {@code node} is\n-     *     returned)\n-     * @param transferInput a transfer input\n-     * @param nodeValues {@link #nodeValues}\n-     * @param analysisCaches {@link #analysisCaches}\n-     * @return the store before or after {@code node} (depends on the value of {@code before}) after\n-     *     running the analysis\n-     */\n-    public static <V extends AbstractValue<V>, S extends Store<S>> S runAnalysisFor(\n-            Node node,\n-            boolean before,\n-            TransferInput<V, S> transferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n-        if (transferInput.analysis == null) {\n-            throw new BugInCF(\"Analysis in transferInput cannot be null.\");\n-        }\n-        return transferInput.analysis.runAnalysisFor(\n-                node, before, transferInput, nodeValues, analysisCaches);\n+  /**\n+   * Returns a verbose string representation of a map, useful for debugging. The map has the same\n+   * type as the {@code treeLookup} field.\n+   *\n+   * @param treeLookup a map to format\n+   * @return a printed representation of the given map\n+   */\n+  public static String treeLookupToString(Map<Tree, Set<Node>> treeLookup) {\n+    if (treeLookup.isEmpty()) {\n+      return \"{}\";\n+    }\n+    StringJoiner result = new StringJoiner(String.format(\"%n    \"));\n+    result.add(\"{\");\n+    for (Map.Entry<Tree, Set<Node>> entry : treeLookup.entrySet()) {\n+      Tree key = entry.getKey();\n+      result.add(\n+          TreeUtils.toStringTruncated(key, 65)\n+              + \" => \"\n+              + Node.nodeCollectionToString(entry.getValue()));\n     }\n+    result.add(\"}\");\n+    return result.toString();\n+  }\n }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "a74139468e65c8810ae61a9bac1f22b93795b421", "committedDate": "2020-08-05 12:21:17 -0700", "message": "Routines to format AnalysisResult objects for debugging/logging"}, {"oid": "08afd3f6aebcfc80f7dde7ecbe53957109cb8ec3", "committedDate": "2020-08-05 12:25:03 -0700", "message": "Add Block.getNodes() method"}, {"oid": "8241215e63dc6042450662f1306084f51be892e5", "committedDate": "2020-08-12 13:27:16 -0700", "message": "Improve ControlFlowGraph documentation"}, {"oid": "2136db1e1f89490521cf026dbac4f3059883aaa5", "committedDate": "2020-08-13 14:51:17 -0700", "message": "Improve formatting"}, {"oid": "8796989896010c855eceee69fe83c4ab5f2f1634", "committedDate": "2020-09-09 04:58:36 -0700", "message": "Add unique ID to some printed representations"}, {"oid": "a1fc0e5dc3ad29bd41dd7e6ba46567fba2100bf9", "committedDate": "2020-10-01 19:40:54 -0700", "message": "Mention widening before narrowing, consistent with the JLS"}, {"oid": "4c29a5461413b2381a41fe1d4af32e3f9b159478", "committedDate": "2020-10-13 09:23:58 -0700", "message": "Use plume-util version 1.1.7"}, {"oid": "4baef83b796779491cbbedf5bc4cf94dc5f7121a", "committedDate": "2020-10-24 14:13:04 -0700", "message": "Make unique IDs per-class rather than global"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "fa9b37a1ba6331cfb02ebcfe00ee077f02c38d0c", "committedDate": "2020-11-23 15:35:50 -0800", "message": "Fix Javadoc. (#3925)"}, {"oid": "cc4f07af3359e3508ba91eb967feb271810f52b6", "committedDate": "2020-11-30 08:37:23 -0800", "message": "Javadoc fixes"}, {"oid": "f3c9ecc242b879a3949a9e3163545be4eb23d86c", "committedDate": "2020-12-22 10:08:40 -0800", "message": "Infer method contracts"}, {"oid": "d58933e444dc6fd95c7ee8172cffda9ea7a06702", "committedDate": "2021-01-15 11:01:01 -0800", "message": "Use Error Prone version 2.5.1"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}, {"oid": "36d046806c766aff0e1cb8e974acccb546cf73a1", "committedDate": "2022-03-11 22:33:27 +0000", "message": "Clean up/simplify increment/decrement code"}, {"oid": "e91d91cee3eae7fdbc45c622153e1907630472ae", "committedDate": "2022-06-24 10:57:36 -0700", "message": "Improve diagnostic"}, {"oid": "88e7cedeea4273ef5ef74e1577263bb953cf323f", "committedDate": "2022-06-28 23:01:52 +0000", "message": "Copy maps lazily in `AnalysisResult`"}, {"oid": "f1ace3aef2e0db7c71c7a088c47bec8494636fd5", "committedDate": "2022-07-14 22:05:12 +0000", "message": "Add more map copying to AnalysisResult"}, {"oid": "b55b1eda178bd4d585f522988612cb0dcc9c76e5", "committedDate": "2022-09-12 08:12:23 -0700", "message": "Use more specific types (#5296)"}, {"oid": "05b21daca8bcc8dd37215e2c05389827e475c491", "committedDate": "2023-01-07 18:57:11 -0800", "message": "Use plume-util 1.6.3"}, {"oid": "287675ec1715bbf4f9e8cafb8b1d4d15c384f328", "committedDate": "2023-01-18 12:42:23 -0800", "message": "Format more files (#5533)"}, {"oid": "7c41450007413c58b90dea9457b2f99c6411f7b0", "committedDate": "2023-02-12 12:13:33 -0800", "message": "Add modifiers"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE0MTcyNw==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441141727", "body": "Why does the forward analysis contain widening support, but the backwards analysis does not? I know that there is no need for a widening operator in the liveness analysis, but to be generally useful I would expect that there will be times when a widening operator is needed - otherwise a dataflow problem might not terminate. The backwards analysis is not immune to this (as far as I can tell); it must re-add blocks to the worklist just as the forward analysis does. Am I missing something, or is widening support in the backwards analysis future work?", "bodyText": "Why does the forward analysis contain widening support, but the backwards analysis does not? I know that there is no need for a widening operator in the liveness analysis, but to be generally useful I would expect that there will be times when a widening operator is needed - otherwise a dataflow problem might not terminate. The backwards analysis is not immune to this (as far as I can tell); it must re-add blocks to the worklist just as the forward analysis does. Am I missing something, or is widening support in the backwards analysis future work?", "bodyHTML": "<p dir=\"auto\">Why does the forward analysis contain widening support, but the backwards analysis does not? I know that there is no need for a widening operator in the liveness analysis, but to be generally useful I would expect that there will be times when a widening operator is needed - otherwise a dataflow problem might not terminate. The backwards analysis is not immune to this (as far as I can tell); it must re-add blocks to the worklist just as the forward analysis does. Am I missing something, or is widening support in the backwards analysis future work?</p>", "author": "kelloggm", "createdAt": "2020-06-16T21:05:52Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java", "diffHunk": "@@ -0,0 +1,585 @@\n+package org.checkerframework.dataflow.analysis;\n+\n+import com.sun.source.tree.LambdaExpressionTree;\n+import com.sun.source.tree.MethodTree;\n+import com.sun.source.tree.VariableTree;\n+import java.util.ArrayList;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import javax.lang.model.type.TypeMirror;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n+import org.checkerframework.dataflow.cfg.block.Block;\n+import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n+import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n+import org.checkerframework.dataflow.cfg.block.RegularBlock;\n+import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n+import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n+import org.checkerframework.dataflow.cfg.node.Node;\n+import org.checkerframework.dataflow.cfg.node.ReturnNode;\n+import org.checkerframework.javacutil.BugInCF;\n+import org.checkerframework.javacutil.Pair;\n+\n+/**\n+ * An implementation of a forward analysis to solve a org.checkerframework.dataflow problem given a\n+ * control flow graph and a forward transfer function.\n+ *\n+ * @param <V> the abstract value type to be tracked by the analysis\n+ * @param <S> the store type used in the analysis\n+ * @param <T> the transfer function type that is used to approximate runtime behavior\n+ */\n+public class ForwardAnalysisImpl<\n+                V extends AbstractValue<V>,\n+                S extends Store<S>,\n+                T extends ForwardTransferFunction<V, S>>\n+        extends AbstractAnalysis<V, S, T> implements ForwardAnalysis<V, S, T> {\n+\n+    /**\n+     * Number of times each block has been analyzed since the last time widening was applied. Null\n+     * if maxCountBeforeWidening is -1, which implies widening isn't used for this analysis.\n+     */\n+    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n+\n+    /**\n+     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n+     * be used.\n+     */\n+    protected final int maxCountBeforeWidening;\n+\n+    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n+    protected final IdentityHashMap<Block, S> thenStores;\n+\n+    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n+    protected final IdentityHashMap<Block, S> elseStores;\n+\n+    /** The stores after every return statement. */\n+    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n+\n+    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n+    /**\n+     * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n+     * control flow graph. The transfer function is set by the subclass, e.g., {@code\n+     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n+     *\n+     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     */\n+    public ForwardAnalysisImpl(int maxCountBeforeWidening) {", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null, "revised_code_in_main": {"commit": "6a71e35c12c223c94867d7369dbc18e7098f1f02", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java\nindex b547813dc..64437797f 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java\n", "chunk": "@@ -64,8 +66,8 @@ public class ForwardAnalysisImpl<\n     // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n     /**\n      * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n-     * control flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n+     * control flow graph. When using this constructor, the transfer function is set later by the\n+     * subclass, e.g., {@code org.checkerframework.framework.flow.CFAbstractAnalysis}.\n      *\n      * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n      */\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java\nindex 64437797f..f0e4dce7b 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java\n", "chunk": "@@ -37,566 +37,533 @@ import org.checkerframework.javacutil.Pair;\n  * @param <T> the transfer function type that is used to approximate runtime behavior\n  */\n public class ForwardAnalysisImpl<\n-                V extends AbstractValue<V>,\n-                S extends Store<S>,\n-                T extends ForwardTransferFunction<V, S>>\n-        extends AbstractAnalysis<V, S, T> implements ForwardAnalysis<V, S, T> {\n+        V extends AbstractValue<V>, S extends Store<S>, T extends ForwardTransferFunction<V, S>>\n+    extends AbstractAnalysis<V, S, T> implements ForwardAnalysis<V, S, T> {\n \n-    /**\n-     * Number of times each block has been analyzed since the last time widening was applied. Null\n-     * if maxCountBeforeWidening is -1, which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n+  /**\n+   * Number of times each block has been analyzed since the last time widening was applied. Null if\n+   * maxCountBeforeWidening is -1, which implies widening isn't used for this analysis.\n+   */\n+  protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n \n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n+  /**\n+   * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't be\n+   * used.\n+   */\n+  protected final int maxCountBeforeWidening;\n \n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n+  /** Then stores before every basic block (assumed to be 'no information' if not present). */\n+  protected final IdentityHashMap<Block, S> thenStores;\n \n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n+  /** Else stores before every basic block (assumed to be 'no information' if not present). */\n+  protected final IdentityHashMap<Block, S> elseStores;\n \n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n+  /** The stores after every return statement. */\n+  protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n \n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n-     * control flow graph. When using this constructor, the transfer function is set later by the\n-     * subclass, e.g., {@code org.checkerframework.framework.flow.CFAbstractAnalysis}.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public ForwardAnalysisImpl(int maxCountBeforeWidening) {\n-        super(Direction.FORWARD);\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n+  // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n+  /**\n+   * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n+   * control flow graph. When using this constructor, the transfer function is set later by the\n+   * subclass, e.g., {@code org.checkerframework.framework.flow.CFAbstractAnalysis}.\n+   *\n+   * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+   */\n+  public ForwardAnalysisImpl(int maxCountBeforeWidening) {\n+    super(Direction.FORWARD);\n+    this.maxCountBeforeWidening = maxCountBeforeWidening;\n+    this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n+    this.thenStores = new IdentityHashMap<>();\n+    this.elseStores = new IdentityHashMap<>();\n+    this.storesAtReturnStatements = new IdentityHashMap<>();\n+  }\n+\n+  /**\n+   * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n+   * control flow graph given a transfer function.\n+   *\n+   * @param transfer the transfer function\n+   */\n+  public ForwardAnalysisImpl(@Nullable T transfer) {\n+    this(-1);\n+    this.transferFunction = transfer;\n+  }\n+\n+  @Override\n+  public void performAnalysis(ControlFlowGraph cfg) {\n+    if (isRunning) {\n+      throw new BugInCF(\n+          \"ForwardAnalysisImpl::performAnalysis() shouldn't be called when the analysis is\"\n+              + \" running.\");\n     }\n+    isRunning = true;\n \n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n-     * control flow graph given a transfer function.\n-     *\n-     * @param transfer the transfer function\n-     */\n-    public ForwardAnalysisImpl(@Nullable T transfer) {\n-        this(-1);\n-        this.transferFunction = transfer;\n+    try {\n+      init(cfg);\n+      while (!worklist.isEmpty()) {\n+        Block b = worklist.poll();\n+        performAnalysisBlock(b);\n+      }\n+    } finally {\n+      assert isRunning;\n+      // In case performAnalysisBlock crashed, reset isRunning to false.\n+      isRunning = false;\n     }\n+  }\n \n-    @Override\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        if (isRunning) {\n-            throw new BugInCF(\n-                    \"ForwardAnalysisImpl::performAnalysis() shouldn't be called when the analysis is running.\");\n+  @Override\n+  public void performAnalysisBlock(Block b) {\n+    switch (b.getType()) {\n+      case REGULAR_BLOCK:\n+        {\n+          RegularBlock rb = (RegularBlock) b;\n+          // Apply transfer function to contents\n+          TransferInput<V, S> inputBefore = getInputBefore(rb);\n+          assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n+          currentInput = inputBefore.copy();\n+          Node lastNode = null;\n+          boolean addToWorklistAgain = false;\n+          for (Node n : rb.getNodes()) {\n+            assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+            TransferResult<V, S> transferResult = callTransferFunction(n, currentInput);\n+            addToWorklistAgain |= updateNodeValues(n, transferResult);\n+            currentInput = new TransferInput<>(n, this, transferResult);\n+            lastNode = n;\n+          }\n+          assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+          // Loop will run at least once, making transferResult non-null\n+          // Propagate store to successors\n+          Block succ = rb.getSuccessor();\n+          assert succ != null\n+              : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor\"\n+                  + \" unexpected\";\n+          propagateStoresTo(succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n+          break;\n         }\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n+      case EXCEPTION_BLOCK:\n+        {\n+          ExceptionBlock eb = (ExceptionBlock) b;\n+          // Apply transfer function to content\n+          TransferInput<V, S> inputBefore = getInputBefore(eb);\n+          assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n+          currentInput = inputBefore.copy();\n+          Node node = eb.getNode();\n+          TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n+          boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n+          // Propagate store to successor\n+          Block succ = eb.getSuccessor();\n+          if (succ != null) {\n+            currentInput = new TransferInput<>(node, this, transferResult);\n+            propagateStoresTo(succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n+          }\n+          // Propagate store to exceptional successors\n+          for (Map.Entry<TypeMirror, Set<Block>> e : eb.getExceptionalSuccessors().entrySet()) {\n+            TypeMirror cause = e.getKey();\n+            S exceptionalStore = transferResult.getExceptionalStore(cause);\n+            if (exceptionalStore != null) {\n+              for (Block exceptionSucc : e.getValue()) {\n+                addStoreBefore(\n+                    exceptionSucc, node, exceptionalStore, Store.Kind.BOTH, addToWorklistAgain);\n+              }\n+            } else {\n+              for (Block exceptionSucc : e.getValue()) {\n+                addStoreBefore(\n+                    exceptionSucc,\n+                    node,\n+                    inputBefore.copy().getRegularStore(),\n+                    Store.Kind.BOTH,\n+                    addToWorklistAgain);\n+              }\n             }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n+          }\n+          break;\n         }\n-    }\n-\n-    @Override\n-    public void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-                    // Apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getNodes()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        TransferResult<V, S> transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // Loop will run at least once, making transferResult non-null\n-                    // Propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-                    // Apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-                    // Propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-                    // Propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-                    // Get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-                    // Propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-            case SPECIAL_BLOCK:\n-                {\n-                    // Special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-            default:\n-                throw new BugInCF(\"Unexpected block type: \" + b.getType());\n+      case CONDITIONAL_BLOCK:\n+        {\n+          ConditionalBlock cb = (ConditionalBlock) b;\n+          // Get store before\n+          TransferInput<V, S> inputBefore = getInputBefore(cb);\n+          assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n+          TransferInput<V, S> input = inputBefore.copy();\n+          // Propagate store to successor\n+          Block thenSucc = cb.getThenSuccessor();\n+          Block elseSucc = cb.getElseSuccessor();\n+          propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n+          propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n+          break;\n+        }\n+      case SPECIAL_BLOCK:\n+        {\n+          // Special basic blocks are empty and cannot throw exceptions,\n+          // thus there is no need to perform any analysis.\n+          SpecialBlock sb = (SpecialBlock) b;\n+          Block succ = sb.getSuccessor();\n+          if (succ != null) {\n+            TransferInput<V, S> input = getInputBefore(b);\n+            assert input != null : \"@AssumeAssertion(nullness): invariant\";\n+            propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n+          }\n+          break;\n         }\n+      default:\n+        throw new BugInCF(\"Unexpected block type: \" + b.getType());\n     }\n+  }\n \n-    @Override\n-    public @Nullable TransferInput<V, S> getInput(Block b) {\n-        return getInputBefore(b);\n-    }\n+  @Override\n+  public @Nullable TransferInput<V, S> getInput(Block b) {\n+    return getInputBefore(b);\n+  }\n \n-    @Override\n-    @SuppressWarnings(\"nullness:contracts.precondition.override.invalid\") // implementation field\n-    @RequiresNonNull(\"cfg\")\n-    public List<Pair<ReturnNode, @Nullable TransferResult<V, S>>> getReturnStatementStores() {\n-        List<Pair<ReturnNode, @Nullable TransferResult<V, S>>> result = new ArrayList<>();\n-        for (ReturnNode returnNode : cfg.getReturnNodes()) {\n-            TransferResult<V, S> store = storesAtReturnStatements.get(returnNode);\n-            result.add(Pair.of(returnNode, store));\n-        }\n-        return result;\n-    }\n+  @Override\n+  @SuppressWarnings(\"nullness:contracts.precondition.override.invalid\") // implementation field\n+  @RequiresNonNull(\"cfg\")\n+  public List<Pair<ReturnNode, @Nullable TransferResult<V, S>>> getReturnStatementStores() {\n+    return SystemUtil.<ReturnNode, Pair<ReturnNode, @Nullable TransferResult<V, S>>>mapList(\n+        returnNode -> Pair.of(returnNode, storesAtReturnStatements.get(returnNode)),\n+        cfg.getReturnNodes());\n+  }\n \n-    @Override\n-    public S runAnalysisFor(\n-            @FindDistinct Node node,\n-            boolean before,\n-            TransferInput<V, S> blockTransferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n-        Block block = node.getBlock();\n-        assert block != null : \"@AssumeAssertion(nullness): invariant\";\n-        Node oldCurrentNode = currentNode;\n+  @Override\n+  public S runAnalysisFor(\n+      @FindDistinct Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+    Block block = node.getBlock();\n+    assert block != null : \"@AssumeAssertion(nullness): invariant\";\n+    Node oldCurrentNode = currentNode;\n \n-        // Prepare cache\n-        IdentityHashMap<Node, TransferResult<V, S>> cache;\n-        if (analysisCaches != null) {\n-            cache = analysisCaches.get(blockTransferInput);\n-            if (cache == null) {\n-                cache = new IdentityHashMap<>();\n-                analysisCaches.put(blockTransferInput, cache);\n-            }\n-        } else {\n-            cache = null;\n-        }\n+    // Prepare cache\n+    IdentityHashMap<Node, TransferResult<V, S>> cache;\n+    if (analysisCaches != null) {\n+      cache = analysisCaches.get(blockTransferInput);\n+      if (cache == null) {\n+        cache = new IdentityHashMap<>();\n+        analysisCaches.put(blockTransferInput, cache);\n+      }\n+    } else {\n+      cache = null;\n+    }\n \n-        if (isRunning) {\n-            assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-            return currentInput.getRegularStore();\n-        }\n-        setNodeValues(nodeValues);\n-        isRunning = true;\n-        try {\n-            switch (block.getType()) {\n-                case REGULAR_BLOCK:\n-                    {\n-                        RegularBlock rb = (RegularBlock) block;\n-                        // Apply transfer function to contents until we found the node we are\n-                        // looking for.\n-                        TransferInput<V, S> store = blockTransferInput;\n-                        TransferResult<V, S> transferResult;\n-                        for (Node n : rb.getNodes()) {\n-                            setCurrentNode(n);\n-                            if (n == node && before) {\n-                                return store.getRegularStore();\n-                            }\n-                            if (cache != null && cache.containsKey(n)) {\n-                                transferResult = cache.get(n);\n-                            } else {\n-                                // Copy the store to avoid changing other blocks' transfer inputs in\n-                                // {@link #inputs}\n-                                transferResult = callTransferFunction(n, store.copy());\n-                                if (cache != null) {\n-                                    cache.put(n, transferResult);\n-                                }\n-                            }\n-                            if (n == node) {\n-                                return transferResult.getRegularStore();\n-                            }\n-                            store = new TransferInput<>(n, this, transferResult);\n-                        }\n-                        throw new BugInCF(\"node %s is not in node.getBlock()=%s\", node, block);\n-                    }\n-                case EXCEPTION_BLOCK:\n-                    {\n-                        ExceptionBlock eb = (ExceptionBlock) block;\n-                        // Apply the transfer function to content\n-                        if (eb.getNode() != node) {\n-                            throw new BugInCF(\n-                                    \"Node should be equal to eb.getNode(). But get: node: \"\n-                                            + node\n-                                            + \"\\teb.getNode(): \"\n-                                            + eb.getNode());\n-                        }\n-                        if (before) {\n-                            return blockTransferInput.getRegularStore();\n-                        }\n-                        setCurrentNode(node);\n-                        // Copy the store to avoid changing other blocks' transfer inputs in {@link\n-                        // #inputs}\n-                        TransferResult<V, S> transferResult =\n-                                callTransferFunction(node, blockTransferInput.copy());\n-                        return transferResult.getRegularStore();\n-                    }\n-                default:\n-                    // Only regular blocks and exceptional blocks can hold nodes.\n-                    throw new BugInCF(\"Unexpected block type: \" + block.getType());\n+    if (isRunning) {\n+      assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+      return currentInput.getRegularStore();\n+    }\n+    setNodeValues(nodeValues);\n+    isRunning = true;\n+    try {\n+      switch (block.getType()) {\n+        case REGULAR_BLOCK:\n+          {\n+            RegularBlock rb = (RegularBlock) block;\n+            // Apply transfer function to contents until we found the node we are\n+            // looking for.\n+            TransferInput<V, S> store = blockTransferInput;\n+            TransferResult<V, S> transferResult;\n+            for (Node n : rb.getNodes()) {\n+              setCurrentNode(n);\n+              if (n == node && preOrPost == Analysis.BeforeOrAfter.BEFORE) {\n+                return store.getRegularStore();\n+              }\n+              if (cache != null && cache.containsKey(n)) {\n+                transferResult = cache.get(n);\n+              } else {\n+                // Copy the store to avoid changing other blocks' transfer inputs in\n+                // {@link #inputs}\n+                transferResult = callTransferFunction(n, store.copy());\n+                if (cache != null) {\n+                  cache.put(n, transferResult);\n+                }\n+              }\n+              if (n == node) {\n+                return transferResult.getRegularStore();\n+              }\n+              store = new TransferInput<>(n, this, transferResult);\n             }\n-        } finally {\n-            setCurrentNode(oldCurrentNode);\n-            isRunning = false;\n-        }\n+            throw new BugInCF(\"node %s is not in node.getBlock()=%s\", node, block);\n+          }\n+        case EXCEPTION_BLOCK:\n+          {\n+            ExceptionBlock eb = (ExceptionBlock) block;\n+            // Apply the transfer function to content\n+            if (eb.getNode() != node) {\n+              throw new BugInCF(\n+                  \"Node should be equal to eb.getNode(). But get: node: \"\n+                      + node\n+                      + \"\\teb.getNode(): \"\n+                      + eb.getNode());\n+            }\n+            if (preOrPost == Analysis.BeforeOrAfter.BEFORE) {\n+              return blockTransferInput.getRegularStore();\n+            }\n+            setCurrentNode(node);\n+            // Copy the store to avoid changing other blocks' transfer inputs in {@link\n+            // #inputs}\n+            TransferResult<V, S> transferResult;\n+            if (cache != null && cache.containsKey(node)) {\n+              transferResult = cache.get(node);\n+            } else {\n+              // Copy the store to avoid changing other blocks' transfer inputs in\n+              // {@link #inputs}\n+              transferResult = callTransferFunction(node, blockTransferInput.copy());\n+              if (cache != null) {\n+                cache.put(node, transferResult);\n+              }\n+            }\n+            return transferResult.getRegularStore();\n+          }\n+        default:\n+          // Only regular blocks and exceptional blocks can hold nodes.\n+          throw new BugInCF(\"Unexpected block type: \" + block.getType());\n+      }\n+    } finally {\n+      setCurrentNode(oldCurrentNode);\n+      isRunning = false;\n     }\n+  }\n \n-    @Override\n-    protected void initFields(ControlFlowGraph cfg) {\n-        thenStores.clear();\n-        elseStores.clear();\n-        if (blockCount != null) {\n-            blockCount.clear();\n-        }\n-        storesAtReturnStatements.clear();\n-        super.initFields(cfg);\n+  @Override\n+  protected void initFields(ControlFlowGraph cfg) {\n+    thenStores.clear();\n+    elseStores.clear();\n+    if (blockCount != null) {\n+      blockCount.clear();\n     }\n+    storesAtReturnStatements.clear();\n+    super.initFields(cfg);\n+  }\n \n-    @Override\n-    @RequiresNonNull(\"cfg\")\n-    protected void initInitialInputs() {\n-        worklist.process(cfg);\n-        Block entry = cfg.getEntryBlock();\n-        worklist.add(entry);\n-        List<LocalVariableNode> parameters = null;\n-        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n-        if (underlyingAST.getKind() == Kind.METHOD) {\n-            MethodTree tree = ((CFGMethod) underlyingAST).getMethod();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : tree.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it belongs to\n-            }\n-        } else if (underlyingAST.getKind() == Kind.LAMBDA) {\n-            LambdaExpressionTree lambda = ((CFGLambda) underlyingAST).getLambdaTree();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : lambda.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it belongs to\n-            }\n-        }\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        S initialStore = transferFunction.initialStore(underlyingAST, parameters);\n-        thenStores.put(entry, initialStore);\n-        elseStores.put(entry, initialStore);\n-        inputs.put(entry, new TransferInput<>(null, this, initialStore));\n+  @Override\n+  @RequiresNonNull(\"cfg\")\n+  protected void initInitialInputs() {\n+    worklist.process(cfg);\n+    Block entry = cfg.getEntryBlock();\n+    worklist.add(entry);\n+    UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n+    List<LocalVariableNode> parameters = getParameters(underlyingAST);\n+    assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n+    S initialStore = transferFunction.initialStore(underlyingAST, parameters);\n+    thenStores.put(entry, initialStore);\n+    elseStores.put(entry, initialStore);\n+    inputs.put(entry, new TransferInput<>(null, this, initialStore));\n+  }\n+\n+  /**\n+   * Returns the formal parameters for a method.\n+   *\n+   * @param underlyingAST the AST for the method\n+   * @return the formal parameters for the method\n+   */\n+  @SideEffectFree\n+  private List<LocalVariableNode> getParameters(UnderlyingAST underlyingAST) {\n+    switch (underlyingAST.getKind()) {\n+      case METHOD:\n+        MethodTree tree = ((CFGMethod) underlyingAST).getMethod();\n+        // TODO: document that LocalVariableNode has no block that it belongs to\n+        return SystemUtil.mapList(LocalVariableNode::new, tree.getParameters());\n+      case LAMBDA:\n+        LambdaExpressionTree lambda = ((CFGLambda) underlyingAST).getLambdaTree();\n+        // TODO: document that LocalVariableNode has no block that it belongs to\n+        return SystemUtil.mapList(LocalVariableNode::new, lambda.getParameters());\n+      default:\n+        return Collections.emptyList();\n     }\n+  }\n \n-    @Override\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> input) {\n-        TransferResult<V, S> transferResult = super.callTransferFunction(node, input);\n+  @Override\n+  protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> input) {\n+    TransferResult<V, S> transferResult = super.callTransferFunction(node, input);\n \n-        if (node instanceof ReturnNode) {\n-            // Save a copy of the store to later check if some property holds at a given return\n-            // statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        return transferResult;\n+    if (node instanceof ReturnNode) {\n+      // Save a copy of the store to later check if some property holds at a given return\n+      // statement\n+      storesAtReturnStatements.put((ReturnNode) node, transferResult);\n     }\n+    return transferResult;\n+  }\n \n-    @Override\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-            case BOTH_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getRegularStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case BOTH_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getRegularStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n+  @Override\n+  protected void propagateStoresTo(\n+      Block succ,\n+      @Nullable Node node,\n+      TransferInput<V, S> currentInput,\n+      Store.FlowRule flowRule,\n+      boolean addToWorklistAgain) {\n+    switch (flowRule) {\n+      case EACH_TO_EACH:\n+        if (currentInput.containsTwoStores()) {\n+          addStoreBefore(\n+              succ, node, currentInput.getThenStore(), Store.Kind.THEN, addToWorklistAgain);\n+          addStoreBefore(\n+              succ, node, currentInput.getElseStore(), Store.Kind.ELSE, addToWorklistAgain);\n+        } else {\n+          addStoreBefore(\n+              succ, node, currentInput.getRegularStore(), Store.Kind.BOTH, addToWorklistAgain);\n         }\n+        break;\n+      case THEN_TO_BOTH:\n+        addStoreBefore(\n+            succ, node, currentInput.getThenStore(), Store.Kind.BOTH, addToWorklistAgain);\n+        break;\n+      case ELSE_TO_BOTH:\n+        addStoreBefore(\n+            succ, node, currentInput.getElseStore(), Store.Kind.BOTH, addToWorklistAgain);\n+        break;\n+      case THEN_TO_THEN:\n+        addStoreBefore(\n+            succ, node, currentInput.getThenStore(), Store.Kind.THEN, addToWorklistAgain);\n+        break;\n+      case ELSE_TO_ELSE:\n+        addStoreBefore(\n+            succ, node, currentInput.getElseStore(), Store.Kind.ELSE, addToWorklistAgain);\n+        break;\n+      case BOTH_TO_THEN:\n+        addStoreBefore(\n+            succ, node, currentInput.getRegularStore(), Store.Kind.THEN, addToWorklistAgain);\n+        break;\n+      case BOTH_TO_ELSE:\n+        addStoreBefore(\n+            succ, node, currentInput.getRegularStore(), Store.Kind.ELSE, addToWorklistAgain);\n+        break;\n     }\n+  }\n \n-    /**\n-     * Add a store before the basic block {@code b} by merging with the existing stores for that\n-     * location.\n-     *\n-     * @param b a basic block\n-     * @param node the node of the basic block {@code b}\n-     * @param s the store being added\n-     * @param kind the kind of store {@code s}\n-     * @param addBlockToWorklist whether the basic block {@code b} should be added back to {@code\n-     *     Worklist}\n-     */\n-    protected void addStoreBefore(\n-            Block b, @Nullable Node node, S s, Store.Kind kind, boolean addBlockToWorklist) {\n-        S thenStore = getStoreBefore(b, Store.Kind.THEN);\n-        S elseStore = getStoreBefore(b, Store.Kind.ELSE);\n-        boolean shouldWiden = false;\n-        if (blockCount != null) {\n-            Integer count = blockCount.get(b);\n-            if (count == null) {\n-                count = 0;\n-            }\n-            shouldWiden = count >= maxCountBeforeWidening;\n-            if (shouldWiden) {\n-                blockCount.put(b, 0);\n-            } else {\n-                blockCount.put(b, count + 1);\n+  /**\n+   * Add a store before the basic block {@code b} by merging with the existing stores for that\n+   * location.\n+   *\n+   * @param b a basic block\n+   * @param node the node of the basic block {@code b}\n+   * @param s the store being added\n+   * @param kind the kind of store {@code s}\n+   * @param addBlockToWorklist whether the basic block {@code b} should be added back to {@code\n+   *     Worklist}\n+   */\n+  protected void addStoreBefore(\n+      Block b, @Nullable Node node, S s, Store.Kind kind, boolean addBlockToWorklist) {\n+    S thenStore = getStoreBefore(b, Store.Kind.THEN);\n+    S elseStore = getStoreBefore(b, Store.Kind.ELSE);\n+    boolean shouldWiden = false;\n+    if (blockCount != null) {\n+      Integer count = blockCount.get(b);\n+      if (count == null) {\n+        count = 0;\n+      }\n+      shouldWiden = count >= maxCountBeforeWidening;\n+      if (shouldWiden) {\n+        blockCount.put(b, 0);\n+      } else {\n+        blockCount.put(b, count + 1);\n+      }\n+    }\n+    switch (kind) {\n+      case THEN:\n+        {\n+          // Update the then store\n+          S newThenStore = mergeStores(s, thenStore, shouldWiden);\n+          if (!newThenStore.equals(thenStore)) {\n+            thenStores.put(b, newThenStore);\n+            if (elseStore != null) {\n+              inputs.put(b, new TransferInput<>(node, this, newThenStore, elseStore));\n+              addBlockToWorklist = true;\n             }\n+          }\n+          break;\n         }\n-        switch (kind) {\n-            case THEN:\n-                {\n-                    // Update the then store\n-                    S newThenStore = mergeStores(s, thenStore, shouldWiden);\n-                    if (!newThenStore.equals(thenStore)) {\n-                        thenStores.put(b, newThenStore);\n-                        if (elseStore != null) {\n-                            inputs.put(b, new TransferInput<>(node, this, newThenStore, elseStore));\n-                            addBlockToWorklist = true;\n-                        }\n-                    }\n-                    break;\n-                }\n-            case ELSE:\n-                {\n-                    // Update the else store\n-                    S newElseStore = mergeStores(s, elseStore, shouldWiden);\n-                    if (!newElseStore.equals(elseStore)) {\n-                        elseStores.put(b, newElseStore);\n-                        if (thenStore != null) {\n-                            inputs.put(b, new TransferInput<>(node, this, thenStore, newElseStore));\n-                            addBlockToWorklist = true;\n-                        }\n-                    }\n-                    break;\n-                }\n-            case BOTH:\n-                @SuppressWarnings(\"interning:not.interned\")\n-                boolean sameStore = (thenStore == elseStore);\n-                if (sameStore) {\n-                    // Currently there is only one regular store\n-                    S newStore = mergeStores(s, thenStore, shouldWiden);\n-                    if (!newStore.equals(thenStore)) {\n-                        thenStores.put(b, newStore);\n-                        elseStores.put(b, newStore);\n-                        inputs.put(b, new TransferInput<>(node, this, newStore));\n-                        addBlockToWorklist = true;\n-                    }\n-                } else {\n-                    boolean storeChanged = false;\n-                    S newThenStore = mergeStores(s, thenStore, shouldWiden);\n-                    if (!newThenStore.equals(thenStore)) {\n-                        thenStores.put(b, newThenStore);\n-                        storeChanged = true;\n-                    }\n-                    S newElseStore = mergeStores(s, elseStore, shouldWiden);\n-                    if (!newElseStore.equals(elseStore)) {\n-                        elseStores.put(b, newElseStore);\n-                        storeChanged = true;\n-                    }\n-                    if (storeChanged) {\n-                        inputs.put(b, new TransferInput<>(node, this, newThenStore, newElseStore));\n-                        addBlockToWorklist = true;\n-                    }\n-                }\n-        }\n-        if (addBlockToWorklist) {\n-            addToWorklist(b);\n+      case ELSE:\n+        {\n+          // Update the else store\n+          S newElseStore = mergeStores(s, elseStore, shouldWiden);\n+          if (!newElseStore.equals(elseStore)) {\n+            elseStores.put(b, newElseStore);\n+            if (thenStore != null) {\n+              inputs.put(b, new TransferInput<>(node, this, thenStore, newElseStore));\n+              addBlockToWorklist = true;\n+            }\n+          }\n+          break;\n         }\n-    }\n-\n-    /**\n-     * Merge two stores, possibly widening the result.\n-     *\n-     * @param newStore the new Store\n-     * @param previousStore the previous Store\n-     * @param shouldWiden should widen or not\n-     * @return the merged Store\n-     */\n-    private S mergeStores(S newStore, @Nullable S previousStore, boolean shouldWiden) {\n-        if (previousStore == null) {\n-            return newStore;\n-        } else if (shouldWiden) {\n-            return newStore.widenedUpperBound(previousStore);\n+      case BOTH:\n+        @SuppressWarnings(\"interning:not.interned\")\n+        boolean sameStore = (thenStore == elseStore);\n+        if (sameStore) {\n+          // Currently there is only one regular store\n+          S newStore = mergeStores(s, thenStore, shouldWiden);\n+          if (!newStore.equals(thenStore)) {\n+            thenStores.put(b, newStore);\n+            elseStores.put(b, newStore);\n+            inputs.put(b, new TransferInput<>(node, this, newStore));\n+            addBlockToWorklist = true;\n+          }\n         } else {\n-            return newStore.leastUpperBound(previousStore);\n+          boolean storeChanged = false;\n+          S newThenStore = mergeStores(s, thenStore, shouldWiden);\n+          if (!newThenStore.equals(thenStore)) {\n+            thenStores.put(b, newThenStore);\n+            storeChanged = true;\n+          }\n+          S newElseStore = mergeStores(s, elseStore, shouldWiden);\n+          if (!newElseStore.equals(elseStore)) {\n+            elseStores.put(b, newElseStore);\n+            storeChanged = true;\n+          }\n+          if (storeChanged) {\n+            inputs.put(b, new TransferInput<>(node, this, newThenStore, newElseStore));\n+            addBlockToWorklist = true;\n+          }\n         }\n     }\n+    if (addBlockToWorklist) {\n+      addToWorklist(b);\n+    }\n+  }\n \n-    /**\n-     * Return the store corresponding to the location right before the basic block {@code b}.\n-     *\n-     * @param b a block\n-     * @param kind the kind of store which will be returned\n-     * @return the store corresponding to the location right before the basic block {@code b}\n-     */\n-    protected @Nullable S getStoreBefore(Block b, Store.Kind kind) {\n-        switch (kind) {\n-            case THEN:\n-                return readFromStore(thenStores, b);\n-            case ELSE:\n-                return readFromStore(elseStores, b);\n-            default:\n-                throw new BugInCF(\"Unexpected Store.Kind: \" + kind);\n-        }\n+  /**\n+   * Merge two stores, possibly widening the result.\n+   *\n+   * @param newStore the new Store\n+   * @param previousStore the previous Store\n+   * @param shouldWiden should widen or not\n+   * @return the merged Store\n+   */\n+  private S mergeStores(S newStore, @Nullable S previousStore, boolean shouldWiden) {\n+    if (previousStore == null) {\n+      return newStore;\n+    } else if (shouldWiden) {\n+      return newStore.widenedUpperBound(previousStore);\n+    } else {\n+      return newStore.leastUpperBound(previousStore);\n     }\n+  }\n \n-    /**\n-     * Returns the transfer input corresponding to the location right before the basic block {@code\n-     * b}.\n-     *\n-     * @param b a block\n-     * @return the transfer input corresponding to the location right before the basic block {@code\n-     *     b}\n-     */\n-    protected @Nullable TransferInput<V, S> getInputBefore(Block b) {\n-        return inputs.get(b);\n+  /**\n+   * Return the store corresponding to the location right before the basic block {@code b}.\n+   *\n+   * @param b a block\n+   * @param kind the kind of store which will be returned\n+   * @return the store corresponding to the location right before the basic block {@code b}\n+   */\n+  protected @Nullable S getStoreBefore(Block b, Store.Kind kind) {\n+    switch (kind) {\n+      case THEN:\n+        return readFromStore(thenStores, b);\n+      case ELSE:\n+        return readFromStore(elseStores, b);\n+      default:\n+        throw new BugInCF(\"Unexpected Store.Kind: \" + kind);\n     }\n+  }\n+\n+  /**\n+   * Returns the transfer input corresponding to the location right before the basic block {@code\n+   * b}.\n+   *\n+   * @param b a block\n+   * @return the transfer input corresponding to the location right before the basic block {@code b}\n+   */\n+  protected @Nullable TransferInput<V, S> getInputBefore(Block b) {\n+    return inputs.get(b);\n+  }\n }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "2ec4fd34f7f674b9f77ca120c2fffc2fa624e3bc", "committedDate": "2020-07-07 17:54:14 -0700", "message": "Run Interning Checker on the Checker Framework codebase"}, {"oid": "2f8bfe0f894b387ec0de01205f74ebef410a9733", "committedDate": "2020-07-09 09:50:17 -0700", "message": "Use -ArequirePrefixInWarningSuppressions when type-checking CF source code"}, {"oid": "bc9a1203c90869ceee5b02c7b12071732794ac47", "committedDate": "2020-07-23 13:52:31 -0700", "message": "Correct the logic of dataflow framework. (#3414)"}, {"oid": "08afd3f6aebcfc80f7dde7ecbe53957109cb8ec3", "committedDate": "2020-08-05 12:25:03 -0700", "message": "Add Block.getNodes() method"}, {"oid": "b6eb465341c2d66504a11c13cc636e7775e408c9", "committedDate": "2020-09-10 10:11:22 -0700", "message": "Propagate conditional stores through ?: conditional expressions (#3646)"}, {"oid": "a3e76038b117589dc0dfdb7a8c3d5b2be35efb5d", "committedDate": "2020-09-10 15:32:14 -0700", "message": "Improve messages in exceptions"}, {"oid": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "committedDate": "2020-09-10 15:32:25 -0700", "message": "Rename some occurrences of `transferInput` to `blockTransferInput`"}, {"oid": "6a71e35c12c223c94867d7369dbc18e7098f1f02", "committedDate": "2020-10-13 13:55:46 -0700", "message": "Dataflow documentation tweaks"}, {"oid": "1a0712f39d12806a78b324ed17d281fc7a7d468b", "committedDate": "2020-10-29 12:52:07 -0700", "message": "Enrich treatment of `@PolyNull`; fixes #3614"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "12fb7e65015015bbba541bf0cfee6270d4d25913", "committedDate": "2021-02-18 14:44:27 -0800", "message": "Add caching for exception block case in ForwardAnalysisImpl (#4296)"}, {"oid": "f501266c6a78ddfe264586ec6ae6fece6133b8a6", "committedDate": "2021-03-12 16:47:05 -0800", "message": "Use `mapList()`"}, {"oid": "ad3de66d242bf9f9319ffce0ad94b690cc0213d1", "committedDate": "2021-03-19 10:03:48 -0700", "message": "Size collection creation to the collection's final size (#4431)"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}, {"oid": "bf0dad71fe749a393149f697f4217a331cdffebc", "committedDate": "2021-03-28 20:14:26 -0700", "message": "Use plume-util version 1.5.1"}, {"oid": "764713248ea994e55cfa45f723dcda6a22881eeb", "committedDate": "2021-04-01 08:39:55 -0700", "message": "Reflow comments"}, {"oid": "b5390de432453992c61cfe137f1407d35d305e48", "committedDate": "2021-04-09 12:47:37 -0700", "message": "Use the Map.computeIfAbsent method (#4553)"}, {"oid": "5c04d6836d8e65daf79667de6539e0d5c055fbbb", "committedDate": "2021-04-30 10:50:51 -0700", "message": "Use shorter suppression message keys"}, {"oid": "2d64c76f5ff2f278c5976017cd05851e5687c74b", "committedDate": "2021-08-12 12:24:57 -0700", "message": "Ignore control flow due to NullPointerExceptions in Called Methods Checker"}, {"oid": "287675ec1715bbf4f9e8cafb8b1d4d15c384f328", "committedDate": "2023-01-18 12:42:23 -0800", "message": "Format more files (#5533)"}]}, {"oid": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "url": "https://github.com/typetools/checker-framework/commit/066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "message": "Resolve comments.\nReduce the differences between forward and backward analysis implementation.", "committedDate": "2020-06-17T20:34:26Z", "type": "commit"}, {"oid": "720123f017c5e0c47688c5fae5c05ab01677eb8c", "url": "https://github.com/typetools/checker-framework/commit/720123f017c5e0c47688c5fae5c05ab01677eb8c", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-17T20:34:35Z", "type": "commit"}, {"oid": "0d8664d081e7cdfede1f38ffd18a93091d1c9ff9", "url": "https://github.com/typetools/checker-framework/commit/0d8664d081e7cdfede1f38ffd18a93091d1c9ff9", "message": "Remove unused import.", "committedDate": "2020-06-17T20:37:27Z", "type": "commit"}, {"oid": "741e968c009f94182ff6738a9f47b930b0a1967f", "url": "https://github.com/typetools/checker-framework/commit/741e968c009f94182ff6738a9f47b930b0a1967f", "message": "Add a TODO comment for widening support for backward analysis.\nTweaks the javadoc.", "committedDate": "2020-06-17T21:40:54Z", "type": "commit"}, {"oid": "9880400eb6f4354105fea809e8254a071a0120a2", "url": "https://github.com/typetools/checker-framework/commit/9880400eb6f4354105fea809e8254a071a0120a2", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-21T01:33:52Z", "type": "commit"}, {"oid": "247c6d8dae718be3332e623306f323a483815c13", "url": "https://github.com/typetools/checker-framework/commit/247c6d8dae718be3332e623306f323a483815c13", "message": "Pull latest code from typetools.", "committedDate": "2020-06-25T03:45:21Z", "type": "commit"}, {"oid": "ef29c77cfb9ae52d669e60eaf0c076c2e4e91fdb", "url": "https://github.com/typetools/checker-framework/commit/ef29c77cfb9ae52d669e60eaf0c076c2e4e91fdb", "message": "Tweaks.", "committedDate": "2020-06-26T17:05:53Z", "type": "commit"}, {"oid": "0c2faaf3647ef05cfd2b70fff2785cc152fa5819", "url": "https://github.com/typetools/checker-framework/commit/0c2faaf3647ef05cfd2b70fff2785cc152fa5819", "message": "Revert \"Tweaks.\"\n\nThis reverts commit ef29c77c", "committedDate": "2020-06-26T17:10:01Z", "type": "commit"}, {"oid": "d996fd0760d700aa6b962c1c3188cfa22df75b14", "url": "https://github.com/typetools/checker-framework/commit/d996fd0760d700aa6b962c1c3188cfa22df75b14", "message": "Merge branch 'master' into typetools-backward-analysis", "committedDate": "2020-06-26T22:19:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446440383", "body": "I don't fully understand this comment. I think it means that `store` should not be side-effected, because it is a copy of a store used elsewhere. If that's correct, can you change the documentation to say it directly.\r\n\r\nAlso, I find `store` to be a misleading name, because I would expect it to be a `Store`, but it is a `TransferInput`. Should we change the name?", "bodyText": "I don't fully understand this comment. I think it means that store should not be side-effected, because it is a copy of a store used elsewhere. If that's correct, can you change the documentation to say it directly.\nAlso, I find store to be a misleading name, because I would expect it to be a Store, but it is a TransferInput. Should we change the name?", "bodyHTML": "<p dir=\"auto\">I don't fully understand this comment. I think it means that <code>store</code> should not be side-effected, because it is a copy of a store used elsewhere. If that's correct, can you change the documentation to say it directly.</p>\n<p dir=\"auto\">Also, I find <code>store</code> to be a misleading name, because I would expect it to be a <code>Store</code>, but it is a <code>TransferInput</code>. Should we change the name?</p>", "author": "kelloggm", "createdAt": "2020-06-26T22:41:19Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java", "diffHunk": "@@ -307,7 +307,9 @@ public Direction getDirection() {\n     }\n \n     /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Call the transfer function for node {@code node}, and set that node as current node first. Be\n+     * careful that {@code store} may be shared between nodes in a block. Passing a copied store to\n+     * avoid the accident changing.", "originalCommit": "d996fd0760d700aa6b962c1c3188cfa22df75b14", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ1NDg4OQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446454889", "bodyText": "What I intend to say here is that we should remember to pass a copied store when calling this method, otherwise the node's transfer input may be changed in the future. Here is an example: https://github.com/typetools/checker-framework/pull/3370/files#diff-9f052b8cabea4817c69534ba908adc75R349. The node in the next iteration maybe change the transfer input of the previous node. Could you please give me some advice?\nstore does not mean Store here, one parameter's name of this method is store. I can make it clear in Javadoc.", "author": "xingweitian", "createdAt": "2020-06-26T23:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ2NDYxMQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446464611", "bodyText": "store does not mean Store here, one parameter's name of this method is store. I can make it clear in Javadoc.\n\nMartin suggested that you rename the formal parameter.  It is better to give the variable a meaningful name, rather than retain a bad name and add documentation to explain how it is bad.", "author": "mernst", "createdAt": "2020-06-27T00:59:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ2NzQ2NQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446467465", "bodyText": "Most of the code in AbstractAnalysis is what previously was in Analysis.\nhttps://github.com/typetools/checker-framework/blob/master/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java#L427\nInstead of just locally renaming this parameter, we can perform a clean-up later and make sure there are no TransferInput parameters with name store and that also the arguments have appropriate names.", "author": "wmdietl", "createdAt": "2020-06-27T01:26:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "01a49af69fafd5eebe41b4df64cf8ce48e6f7375", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\nindex 707db80c3..1e5de8630 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n", "chunk": "@@ -307,24 +312,24 @@ public abstract class AbstractAnalysis<\n     }\n \n     /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first. Be\n-     * careful that {@code store} may be shared between nodes in a block. Passing a copied store to\n-     * avoid the accident changing.\n+     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * This method requires a copied {@code transferInput} so that the method can modify it safely.\n      *\n      * @param node the given node\n-     * @param store the transfer input\n+     * @param transferInput the transfer input\n      * @return the output of the transfer function\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n+    protected TransferResult<V, S> callTransferFunction(\n+            Node node, TransferInput<V, S> transferInput) {\n         assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n         if (node.isLValue()) {\n             // TODO: should the default behavior return a regular transfer result, a conditional\n             //  transfer result (depending on store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n+            return new RegularTransferResult<>(null, transferInput.getRegularStore());\n         }\n-        store.node = node;\n+        transferInput.node = node;\n         currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n+        TransferResult<V, S> transferResult = node.accept(transferFunction, transferInput);\n         currentNode = null;\n         if (node instanceof AssignmentNode) {\n             // store the flow-refined value effectively for final local variables\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\nindex 707db80c3..36ee3346a 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n", "chunk": "@@ -307,24 +312,24 @@ public abstract class AbstractAnalysis<\n     }\n \n     /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first. Be\n-     * careful that {@code store} may be shared between nodes in a block. Passing a copied store to\n-     * avoid the accident changing.\n+     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * This method requires a {@code transferInput} that the method can modify.\n      *\n      * @param node the given node\n-     * @param store the transfer input\n+     * @param transferInput the transfer input\n      * @return the output of the transfer function\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n+    protected TransferResult<V, S> callTransferFunction(\n+            Node node, TransferInput<V, S> transferInput) {\n         assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n         if (node.isLValue()) {\n             // TODO: should the default behavior return a regular transfer result, a conditional\n             //  transfer result (depending on store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n+            return new RegularTransferResult<>(null, transferInput.getRegularStore());\n         }\n-        store.node = node;\n+        transferInput.node = node;\n         currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n+        TransferResult<V, S> transferResult = node.accept(transferFunction, transferInput);\n         currentNode = null;\n         if (node instanceof AssignmentNode) {\n             // store the flow-refined value effectively for final local variables\n", "next_change": {"commit": "2ec4fd34f7f674b9f77ca120c2fffc2fa624e3bc", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\nindex 36ee3346a..2117ef9e7 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n", "chunk": "@@ -328,9 +339,10 @@ public abstract class AbstractAnalysis<\n             return new RegularTransferResult<>(null, transferInput.getRegularStore());\n         }\n         transferInput.node = node;\n-        currentNode = node;\n+        setCurrentNode(node);\n+        @SuppressWarnings(\"nullness\") // CF bug: \"INFERENCE FAILED\"\n         TransferResult<V, S> transferResult = node.accept(transferFunction, transferInput);\n-        currentNode = null;\n+        setCurrentNode(null);\n         if (node instanceof AssignmentNode) {\n             // store the flow-refined value effectively for final local variables\n             AssignmentNode assignment = (AssignmentNode) node;\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\nindex 2117ef9e7..d94be332a 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java\n", "chunk": "@@ -36,512 +37,506 @@ import org.checkerframework.javacutil.ElementUtils;\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n public abstract class AbstractAnalysis<\n-                V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>>\n-        implements Analysis<V, S, T> {\n-\n-    /** The direction of this analysis. */\n-    protected final Direction direction;\n-\n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    //  can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /**\n-     * The transfer inputs of every basic block (assumed to be 'no information' if not present,\n-     * inputs before blocks in forward analysis, after blocks in backward analysis).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    protected final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning ==&gt; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @InternedDistinct @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @InternedDistinct @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /**\n-     * Returns the tree that is currently being looked at. The transfer function can set this tree\n-     * to make sure that calls to {@code getValue} will not return information for this given tree.\n-     *\n-     * @return the tree that is currently being looked at\n-     */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n+        V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>>\n+    implements Analysis<V, S, T> {\n+\n+  /** The direction of this analysis. */\n+  protected final Direction direction;\n+\n+  /** Is the analysis currently running? */\n+  protected boolean isRunning = false;\n+\n+  /** The transfer function for regular nodes. */\n+  // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n+  //  can't be created until the Analysis is initialized.\n+  protected @Nullable T transferFunction;\n+\n+  /** The current control flow graph to perform the analysis on. */\n+  protected @MonotonicNonNull ControlFlowGraph cfg;\n+\n+  /**\n+   * The transfer inputs of every basic block (assumed to be 'no information' if not present, inputs\n+   * before blocks in forward analysis, after blocks in backward analysis).\n+   */\n+  protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n+\n+  /** The worklist used for the fix-point iteration. */\n+  protected final Worklist worklist;\n+\n+  /** Abstract values of nodes. */\n+  protected final IdentityHashMap<Node, V> nodeValues;\n+\n+  /** Map from (effectively final) local variable elements to their abstract value. */\n+  protected final HashMap<Element, V> finalLocalValues;\n+\n+  /**\n+   * The node that is currently handled in the analysis (if it is running). The following invariant\n+   * holds:\n+   *\n+   * <pre>\n+   *   !isRunning &rArr; (currentNode == null)\n+   * </pre>\n+   */\n+  // currentNode == null when isRunning is true.\n+  // See https://github.com/typetools/checker-framework/issues/4115\n+  protected @InternedDistinct @Nullable Node currentNode;\n+\n+  /**\n+   * The tree that is currently being looked at. The transfer function can set this tree to make\n+   * sure that calls to {@code getValue} will not return information for this given tree.\n+   */\n+  protected @InternedDistinct @Nullable Tree currentTree;\n+\n+  /** The current transfer input when the analysis is running. */\n+  protected @Nullable TransferInput<V, S> currentInput;\n+\n+  /**\n+   * Returns the tree that is currently being looked at. The transfer function can set this tree to\n+   * make sure that calls to {@code getValue} will not return information for this given tree.\n+   *\n+   * @return the tree that is currently being looked at\n+   */\n+  public @Nullable Tree getCurrentTree() {\n+    return currentTree;\n+  }\n+\n+  /**\n+   * Set the tree that is currently being looked at.\n+   *\n+   * @param currentTree the tree that should be currently looked at\n+   */\n+  public void setCurrentTree(@FindDistinct Tree currentTree) {\n+    this.currentTree = currentTree;\n+  }\n+\n+  /**\n+   * Set the node that is currently being looked at.\n+   *\n+   * @param currentNode the node that should be currently looked at\n+   */\n+  protected void setCurrentNode(@FindDistinct @Nullable Node currentNode) {\n+    this.currentNode = currentNode;\n+  }\n+\n+  /**\n+   * Implementation of common features for {@link BackwardAnalysisImpl} and {@link\n+   * ForwardAnalysisImpl}.\n+   *\n+   * @param direction direction of the analysis\n+   */\n+  protected AbstractAnalysis(Direction direction) {\n+    this.direction = direction;\n+    this.inputs = new IdentityHashMap<>();\n+    this.worklist = new Worklist(this.direction);\n+    this.nodeValues = new IdentityHashMap<>();\n+    this.finalLocalValues = new HashMap<>();\n+  }\n+\n+  /** Initialize the transfer inputs of every basic block before performing the analysis. */\n+  @RequiresNonNull(\"cfg\")\n+  protected abstract void initInitialInputs();\n+\n+  /**\n+   * Propagate the stores in {@code currentInput} to the next block in the direction of analysis,\n+   * according to the {@code flowRule}.\n+   *\n+   * @param nextBlock the target block to propagate the stores to\n+   * @param node the node of the target block\n+   * @param currentInput the current transfer input\n+   * @param flowRule the flow rule being used\n+   * @param addToWorklistAgain whether the block should be added to {@link #worklist} again\n+   */\n+  protected abstract void propagateStoresTo(\n+      Block nextBlock,\n+      Node node,\n+      TransferInput<V, S> currentInput,\n+      Store.FlowRule flowRule,\n+      boolean addToWorklistAgain);\n+\n+  @Override\n+  public boolean isRunning() {\n+    return isRunning;\n+  }\n+\n+  @Override\n+  public Direction getDirection() {\n+    return this.direction;\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"nullness:contracts.precondition.override.invalid\") // implementation field\n+  @RequiresNonNull(\"cfg\")\n+  public AnalysisResult<V, S> getResult() {\n+    if (isRunning) {\n+      throw new BugInCF(\n+          \"AbstractAnalysis::getResult() shouldn't be called when the analysis is running.\");\n     }\n-\n-    /**\n-     * Set the tree that is currently being looked at.\n-     *\n-     * @param currentTree the tree that should be currently looked at\n-     */\n-    public void setCurrentTree(@FindDistinct Tree currentTree) {\n-        this.currentTree = currentTree;\n+    return new AnalysisResult<>(\n+        nodeValues, inputs, cfg.getTreeLookup(), cfg.getUnaryAssignNodeLookup(), finalLocalValues);\n+  }\n+\n+  @Override\n+  public @Nullable T getTransferFunction() {\n+    return transferFunction;\n+  }\n+\n+  @Override\n+  public @Nullable V getValue(Node n) {\n+    if (isRunning) {\n+      // we don't have a org.checkerframework.dataflow fact about the current node yet\n+      if (currentNode == null\n+          || currentNode == n\n+          || (currentTree != null && currentTree == n.getTree())) {\n+        return null;\n+      }\n+      // check that 'n' is a subnode of 'node'. Check immediate operands\n+      // first for efficiency.\n+      assert !n.isLValue() : \"Did not expect an lvalue, but got \" + n;\n+      if (currentNode == n\n+          || (!currentNode.getOperands().contains(n)\n+              && !currentNode.getTransitiveOperands().contains(n))) {\n+        return null;\n+      }\n+      // fall through when the current node is not 'n', and 'n' is not a subnode.\n     }\n-\n-    /**\n-     * Set the node that is currently being looked at.\n-     *\n-     * @param currentNode the node that should be currently looked at\n-     */\n-    protected void setCurrentNode(@FindDistinct @Nullable Node currentNode) {\n-        this.currentNode = currentNode;\n+    return nodeValues.get(n);\n+  }\n+\n+  /**\n+   * Returns all current node values.\n+   *\n+   * @return {@link #nodeValues}\n+   */\n+  public IdentityHashMap<Node, V> getNodeValues() {\n+    return nodeValues;\n+  }\n+\n+  /**\n+   * Set all current node values to the given map.\n+   *\n+   * @param in the current node values\n+   */\n+  /*package-private*/ void setNodeValues(IdentityHashMap<Node, V> in) {\n+    assert !isRunning;\n+    nodeValues.clear();\n+    nodeValues.putAll(in);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"nullness:contracts.precondition.override.invalid\") // implementation field\n+  @RequiresNonNull(\"cfg\")\n+  public @Nullable S getRegularExitStore() {\n+    SpecialBlock regularExitBlock = cfg.getRegularExitBlock();\n+    if (inputs.containsKey(regularExitBlock)) {\n+      return inputs.get(regularExitBlock).getRegularStore();\n+    } else {\n+      return null;\n     }\n-\n-    /**\n-     * Implementation of common features for {@link BackwardAnalysisImpl} and {@link\n-     * ForwardAnalysisImpl}.\n-     *\n-     * @param direction direction of the analysis\n-     */\n-    protected AbstractAnalysis(Direction direction) {\n-        this.direction = direction;\n-        this.inputs = new IdentityHashMap<>();\n-        this.worklist = new Worklist(this.direction);\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"nullness:contracts.precondition.override.invalid\") // implementation field\n+  @RequiresNonNull(\"cfg\")\n+  public @Nullable S getExceptionalExitStore() {\n+    SpecialBlock exceptionalExitBlock = cfg.getExceptionalExitBlock();\n+    if (inputs.containsKey(exceptionalExitBlock)) {\n+      S exceptionalExitStore = inputs.get(exceptionalExitBlock).getRegularStore();\n+      return exceptionalExitStore;\n+    } else {\n+      return null;\n     }\n-\n-    /** Initialize the transfer inputs of every basic block before performing the analysis. */\n-    @RequiresNonNull(\"cfg\")\n-    protected abstract void initInitialInputs();\n-\n-    /**\n-     * Propagate the stores in {@code currentInput} to the next block in the direction of analysis,\n-     * according to the {@code flowRule}.\n-     *\n-     * @param nextBlock the target block to propagate the stores to\n-     * @param node the node of the target block\n-     * @param currentInput the current transfer input\n-     * @param flowRule the flow rule being used\n-     * @param addToWorklistAgain whether the block should be added to {@link #worklist} again\n-     */\n-    protected abstract void propagateStoresTo(\n-            Block nextBlock,\n-            Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain);\n-\n-    @Override\n-    public boolean isRunning() {\n-        return isRunning;\n+  }\n+\n+  /**\n+   * Get the set of {@link Node}s for a given {@link Tree}. Returns null for trees that don't\n+   * produce a value.\n+   *\n+   * @param t the given tree\n+   * @return the set of corresponding nodes to the given tree\n+   */\n+  public @Nullable Set<Node> getNodesForTree(Tree t) {\n+    if (cfg == null) {\n+      return null;\n     }\n-\n-    @Override\n-    public Direction getDirection() {\n-        return this.direction;\n+    return cfg.getNodesCorrespondingToTree(t);\n+  }\n+\n+  @Override\n+  public @Nullable V getValue(Tree t) {\n+    // we don't have a org.checkerframework.dataflow fact about the current node yet\n+    if (t == currentTree) {\n+      return null;\n     }\n-\n-    @Override\n-    @SuppressWarnings(\"contracts.precondition.override.invalid\") // implementation field\n-    @RequiresNonNull(\"cfg\")\n-    public AnalysisResult<V, S> getResult() {\n-        if (isRunning) {\n-            throw new BugInCF(\n-                    \"AbstractAnalysis::getResult() shouldn't be called when the analysis is running.\");\n-        }\n-        return new AnalysisResult<>(\n-                nodeValues,\n-                inputs,\n-                cfg.getTreeLookup(),\n-                cfg.getUnaryAssignNodeLookup(),\n-                finalLocalValues);\n+    Set<Node> nodesCorrespondingToTree = getNodesForTree(t);\n+    if (nodesCorrespondingToTree == null) {\n+      return null;\n     }\n-\n-    @Override\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n+    V merged = null;\n+    for (Node aNode : nodesCorrespondingToTree) {\n+      if (aNode.isLValue()) {\n+        return null;\n+      }\n+      V v = getValue(aNode);\n+      if (merged == null) {\n+        merged = v;\n+      } else if (v != null) {\n+        merged = merged.leastUpperBound(v);\n+      }\n     }\n-\n-    @Override\n-    public @Nullable V getValue(Node n) {\n-        if (isRunning) {\n-            // we don't have a org.checkerframework.dataflow fact about the current node yet\n-            if (currentNode == null\n-                    || currentNode == n\n-                    || (currentTree != null && currentTree == n.getTree())) {\n-                return null;\n-            }\n-            // check that 'n' is a subnode of 'node'. Check immediate operands\n-            // first for efficiency.\n-            assert !n.isLValue() : \"Did not expect an lvalue, but got \" + n;\n-            if (currentNode == n\n-                    || (!currentNode.getOperands().contains(n)\n-                            && !currentNode.getTransitiveOperands().contains(n))) {\n-                return null;\n-            }\n-            // fall through when the current node is not 'n', and 'n' is not a subnode.\n-        }\n-        return nodeValues.get(n);\n+    return merged;\n+  }\n+\n+  /**\n+   * Get the {@link MethodTree} of the current CFG if the argument {@link Tree} maps to a {@link\n+   * Node} in the CFG or {@code null} otherwise.\n+   *\n+   * @param t the given tree\n+   * @return the contained method tree of the given tree\n+   */\n+  public @Nullable MethodTree getContainingMethod(Tree t) {\n+    if (cfg == null) {\n+      return null;\n     }\n-\n-    /**\n-     * Returns all current node values.\n-     *\n-     * @return {@link #nodeValues}\n-     */\n-    public IdentityHashMap<Node, V> getNodeValues() {\n-        return nodeValues;\n+    return cfg.getContainingMethod(t);\n+  }\n+\n+  /**\n+   * Get the {@link ClassTree} of the current CFG if the argument {@link Tree} maps to a {@link\n+   * Node} in the CFG or {@code null} otherwise.\n+   *\n+   * @param t the given tree\n+   * @return the contained class tree of the given tree\n+   */\n+  public @Nullable ClassTree getContainingClass(Tree t) {\n+    if (cfg == null) {\n+      return null;\n     }\n-\n-    /**\n-     * Set all current node values to the given map.\n-     *\n-     * @param in the current node values\n-     */\n-    /*package-private*/ void setNodeValues(IdentityHashMap<Node, V> in) {\n-        assert !isRunning;\n-        nodeValues.clear();\n-        nodeValues.putAll(in);\n+    return cfg.getContainingClass(t);\n+  }\n+\n+  /**\n+   * Call the transfer function for node {@code node}, and set that node as current node first. This\n+   * method requires a {@code transferInput} that the method can modify.\n+   *\n+   * @param node the given node\n+   * @param transferInput the transfer input\n+   * @return the output of the transfer function\n+   */\n+  protected TransferResult<V, S> callTransferFunction(\n+      Node node, TransferInput<V, S> transferInput) {\n+    assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n+    if (node.isLValue()) {\n+      // TODO: should the default behavior return a regular transfer result, a conditional\n+      //  transfer result (depending on store.containsTwoStores()), or is the following\n+      //  correct?\n+      return new RegularTransferResult<>(null, transferInput.getRegularStore());\n     }\n-\n-    @Override\n-    @SuppressWarnings(\"contracts.precondition.override.invalid\") // implementation field\n-    @RequiresNonNull(\"cfg\")\n-    public @Nullable S getRegularExitStore() {\n-        SpecialBlock regularExitBlock = cfg.getRegularExitBlock();\n-        if (inputs.containsKey(regularExitBlock)) {\n-            return inputs.get(regularExitBlock).getRegularStore();\n-        } else {\n-            return null;\n+    transferInput.node = node;\n+    setCurrentNode(node);\n+    @SuppressWarnings(\"nullness\") // CF bug: \"INFERENCE FAILED\"\n+    TransferResult<V, S> transferResult = node.accept(transferFunction, transferInput);\n+    setCurrentNode(null);\n+    if (node instanceof AssignmentNode) {\n+      // store the flow-refined value effectively for final local variables\n+      AssignmentNode assignment = (AssignmentNode) node;\n+      Node lhst = assignment.getTarget();\n+      if (lhst instanceof LocalVariableNode) {\n+        LocalVariableNode lhs = (LocalVariableNode) lhst;\n+        Element elem = lhs.getElement();\n+        if (ElementUtils.isEffectivelyFinal(elem)) {\n+          V resval = transferResult.getResultValue();\n+          if (resval != null) {\n+            finalLocalValues.put(elem, resval);\n+          }\n         }\n+      }\n     }\n-\n-    @Override\n-    @SuppressWarnings(\"contracts.precondition.override.invalid\") // implementation field\n-    @RequiresNonNull(\"cfg\")\n-    public @Nullable S getExceptionalExitStore() {\n-        SpecialBlock exceptionalExitBlock = cfg.getExceptionalExitBlock();\n-        if (inputs.containsKey(exceptionalExitBlock)) {\n-            S exceptionalExitStore = inputs.get(exceptionalExitBlock).getRegularStore();\n-            return exceptionalExitStore;\n-        } else {\n-            return null;\n-        }\n+    return transferResult;\n+  }\n+\n+  /**\n+   * Initialize the analysis with a new control flow graph.\n+   *\n+   * @param cfg the control flow graph to use\n+   */\n+  protected final void init(ControlFlowGraph cfg) {\n+    initFields(cfg);\n+    initInitialInputs();\n+  }\n+\n+  /**\n+   * Initialize fields of this object based on a given control flow graph. Sub-class may override\n+   * this method to initialize customized fields.\n+   *\n+   * @param cfg a given control flow graph\n+   */\n+  @EnsuresNonNull(\"this.cfg\")\n+  protected void initFields(ControlFlowGraph cfg) {\n+    inputs.clear();\n+    nodeValues.clear();\n+    finalLocalValues.clear();\n+    this.cfg = cfg;\n+  }\n+\n+  /**\n+   * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns true\n+   * if the node's value changed, or a store was updated.\n+   *\n+   * @param node the node to update\n+   * @param transferResult the transfer result being updated\n+   * @return true if the node's value changed, or a store was updated\n+   */\n+  protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n+    V newVal = transferResult.getResultValue();\n+    boolean nodeValueChanged = false;\n+    if (newVal != null) {\n+      V oldVal = nodeValues.get(node);\n+      nodeValues.put(node, newVal);\n+      nodeValueChanged = !Objects.equals(oldVal, newVal);\n     }\n-\n-    /**\n-     * Get the set of {@link Node}s for a given {@link Tree}. Returns null for trees that don't\n-     * produce a value.\n-     *\n-     * @param t the given tree\n-     * @return the set of corresponding nodes to the given tree\n-     */\n-    public @Nullable Set<Node> getNodesForTree(Tree t) {\n-        if (cfg == null) {\n-            return null;\n-        }\n-        return cfg.getNodesCorrespondingToTree(t);\n+    return nodeValueChanged || transferResult.storeChanged();\n+  }\n+\n+  /**\n+   * Read the store for a particular basic block from a map of stores (or {@code null} if none\n+   * exists yet).\n+   *\n+   * @param stores a map of stores\n+   * @param b the target block\n+   * @param <S> method return type should be a subtype of {@link Store}\n+   * @return the store for the target block\n+   */\n+  protected static <S> @Nullable S readFromStore(Map<Block, S> stores, Block b) {\n+    return stores.get(b);\n+  }\n+\n+  /**\n+   * Add a basic block to {@link #worklist}. If {@code b} is already present, the method does\n+   * nothing.\n+   *\n+   * @param b the block to add to {@link #worklist}\n+   */\n+  protected void addToWorklist(Block b) {\n+    // TODO: use a more efficient way to check if b is already present\n+    if (!worklist.contains(b)) {\n+      worklist.add(b);\n     }\n+  }\n \n-    /**\n-     * Return the abstract value for {@link Tree} {@code t}, or {@code null} if no information is\n-     * available. Note that if the analysis has not finished yet, this value might not represent the\n-     * final value for this node.\n-     *\n-     * @param t the given tree\n-     * @return the abstract value for the given tree\n-     */\n-    public @Nullable V getValue(Tree t) {\n-        // we don't have a org.checkerframework.dataflow fact about the current node yet\n-        if (t == currentTree) {\n-            return null;\n-        }\n-        Set<Node> nodesCorrespondingToTree = getNodesForTree(t);\n-        if (nodesCorrespondingToTree == null) {\n-            return null;\n-        }\n-        V merged = null;\n-        for (Node aNode : nodesCorrespondingToTree) {\n-            if (aNode.isLValue()) {\n-                return null;\n-            }\n-            V v = getValue(aNode);\n-            if (merged == null) {\n-                merged = v;\n-            } else if (v != null) {\n-                merged = merged.leastUpperBound(v);\n-            }\n-        }\n-        return merged;\n-    }\n+  /**\n+   * A worklist is a priority queue of blocks in which the order is given by depth-first ordering to\n+   * place non-loop predecessors ahead of successors.\n+   */\n+  protected static class Worklist {\n+\n+    /** Map all blocks in the CFG to their depth-first order. */\n+    protected final IdentityHashMap<Block, Integer> depthFirstOrder;\n \n     /**\n-     * Get the {@link MethodTree} of the current CFG if the argument {@link Tree} maps to a {@link\n-     * Node} in the CFG or {@code null} otherwise.\n-     *\n-     * @param t the given tree\n-     * @return the contained method tree of the given tree\n+     * Comparators to allow priority queue to order blocks by their depth-first order, using by\n+     * forward analysis.\n      */\n-    public @Nullable MethodTree getContainingMethod(Tree t) {\n-        if (cfg == null) {\n-            return null;\n-        }\n-        return cfg.getContainingMethod(t);\n+    public class ForwardDFOComparator implements Comparator<Block> {\n+      @SuppressWarnings(\"nullness:unboxing.of.nullable\")\n+      @Override\n+      public int compare(Block b1, Block b2) {\n+        return depthFirstOrder.get(b1) - depthFirstOrder.get(b2);\n+      }\n     }\n \n     /**\n-     * Get the {@link ClassTree} of the current CFG if the argument {@link Tree} maps to a {@link\n-     * Node} in the CFG or {@code null} otherwise.\n-     *\n-     * @param t the given tree\n-     * @return the contained class tree of the given tree\n+     * Comparators to allow priority queue to order blocks by their depth-first order, using by\n+     * backward analysis.\n      */\n-    public @Nullable ClassTree getContainingClass(Tree t) {\n-        if (cfg == null) {\n-            return null;\n-        }\n-        return cfg.getContainingClass(t);\n+    public class BackwardDFOComparator implements Comparator<Block> {\n+      @SuppressWarnings(\"nullness:unboxing.of.nullable\")\n+      @Override\n+      public int compare(Block b1, Block b2) {\n+        return depthFirstOrder.get(b2) - depthFirstOrder.get(b1);\n+      }\n     }\n \n+    /** The backing priority queue. */\n+    protected final PriorityQueue<Block> queue;\n+\n     /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n-     * This method requires a {@code transferInput} that the method can modify.\n+     * Create a Worklist.\n      *\n-     * @param node the given node\n-     * @param transferInput the transfer input\n-     * @return the output of the transfer function\n+     * @param direction the direction (forward or backward)\n      */\n-    protected TransferResult<V, S> callTransferFunction(\n-            Node node, TransferInput<V, S> transferInput) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior return a regular transfer result, a conditional\n-            //  transfer result (depending on store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, transferInput.getRegularStore());\n-        }\n-        transferInput.node = node;\n-        setCurrentNode(node);\n-        @SuppressWarnings(\"nullness\") // CF bug: \"INFERENCE FAILED\"\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, transferInput);\n-        setCurrentNode(null);\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value effectively for final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n+    public Worklist(Direction direction) {\n+      depthFirstOrder = new IdentityHashMap<>();\n+\n+      if (direction == Direction.FORWARD) {\n+        queue = new PriorityQueue<>(new ForwardDFOComparator());\n+      } else if (direction == Direction.BACKWARD) {\n+        queue = new PriorityQueue<>(new BackwardDFOComparator());\n+      } else {\n+        throw new BugInCF(\"Unexpected Direction meet: \" + direction.name());\n+      }\n     }\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Process the control flow graph, add the blocks to {@link #depthFirstOrder}.\n      *\n-     * @param cfg the control flow graph to use\n+     * @param cfg the control flow graph to process\n      */\n-    protected final void init(ControlFlowGraph cfg) {\n-        initFields(cfg);\n-        initInitialInputs();\n+    public void process(ControlFlowGraph cfg) {\n+      depthFirstOrder.clear();\n+      int count = 1;\n+      for (Block b : cfg.getDepthFirstOrderedBlocks()) {\n+        depthFirstOrder.put(b, count++);\n+      }\n+\n+      queue.clear();\n     }\n \n     /**\n-     * Initialize class fields based on a given control flow graph. Sub-class may override this\n-     * method to initialize customized fields.\n+     * See {@link PriorityQueue#isEmpty}.\n      *\n-     * @param cfg a given control flow graph\n+     * @see PriorityQueue#isEmpty\n+     * @return true if {@link #queue} is empty else false\n      */\n-    @EnsuresNonNull(\"this.cfg\")\n-    protected void initFields(ControlFlowGraph cfg) {\n-        inputs.clear();\n-        nodeValues.clear();\n-        finalLocalValues.clear();\n-        this.cfg = cfg;\n+    @Pure\n+    @EnsuresNonNullIf(result = false, expression = \"poll()\")\n+    @SuppressWarnings(\"nullness:contracts.conditional.postcondition.not.satisfied\") // forwarded\n+    public boolean isEmpty() {\n+      return queue.isEmpty();\n     }\n \n     /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n+     * Check if {@link #queue} contains the block which is passed as the argument.\n      *\n-     * @param node the node to update\n-     * @param transferResult the transfer result being updated\n-     * @return true if the node's value changed, or a store was updated\n+     * @param block the given block to check\n+     * @return true if {@link #queue} contains the given block\n      */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-        return nodeValueChanged || transferResult.storeChanged();\n+    public boolean contains(Block block) {\n+      return queue.contains(block);\n     }\n \n     /**\n-     * Read the store for a particular basic block from a map of stores (or {@code null} if none\n-     * exists yet).\n+     * Add the given block to {@link #queue}.\n      *\n-     * @param stores a map of stores\n-     * @param b the target block\n-     * @param <S> method return type should be a subtype of {@link Store}\n-     * @return the store for the target block\n+     * @param block the block to add to {@link #queue}\n      */\n-    protected static <S> @Nullable S readFromStore(Map<Block, S> stores, Block b) {\n-        return stores.get(b);\n+    public void add(Block block) {\n+      queue.add(block);\n     }\n \n     /**\n-     * Add a basic block to {@link #worklist}. If {@code b} is already present, the method does\n-     * nothing.\n+     * See {@link PriorityQueue#poll}.\n      *\n-     * @param b the block to add to {@link #worklist}\n+     * @see PriorityQueue#poll\n+     * @return the head of {@link #queue}\n      */\n-    protected void addToWorklist(Block b) {\n-        // TODO: use a more efficient way to check if b is already present\n-        if (!worklist.contains(b)) {\n-            worklist.add(b);\n-        }\n+    @Pure\n+    public @Nullable Block poll() {\n+      return queue.poll();\n     }\n \n-    /**\n-     * A worklist is a priority queue of blocks in which the order is given by depth-first ordering\n-     * to place non-loop predecessors ahead of successors.\n-     */\n-    protected static class Worklist {\n-\n-        /** Map all blocks in the CFG to their depth-first order. */\n-        protected final IdentityHashMap<Block, Integer> depthFirstOrder;\n-\n-        /**\n-         * Comparators to allow priority queue to order blocks by their depth-first order, using by\n-         * forward analysis.\n-         */\n-        public class ForwardDFOComparator implements Comparator<Block> {\n-            @SuppressWarnings(\"unboxing.of.nullable\")\n-            @Override\n-            public int compare(Block b1, Block b2) {\n-                return depthFirstOrder.get(b1) - depthFirstOrder.get(b2);\n-            }\n-        }\n-\n-        /**\n-         * Comparators to allow priority queue to order blocks by their depth-first order, using by\n-         * backward analysis.\n-         */\n-        public class BackwardDFOComparator implements Comparator<Block> {\n-            @SuppressWarnings(\"unboxing.of.nullable\")\n-            @Override\n-            public int compare(Block b1, Block b2) {\n-                return depthFirstOrder.get(b2) - depthFirstOrder.get(b1);\n-            }\n-        }\n-\n-        /** The backing priority queue. */\n-        protected final PriorityQueue<Block> queue;\n-\n-        /**\n-         * Create a Worklist.\n-         *\n-         * @param direction the direction (forward or backward)\n-         */\n-        public Worklist(Direction direction) {\n-            depthFirstOrder = new IdentityHashMap<>();\n-\n-            if (direction == Direction.FORWARD) {\n-                queue = new PriorityQueue<>(11, new ForwardDFOComparator());\n-            } else if (direction == Direction.BACKWARD) {\n-                queue = new PriorityQueue<>(11, new BackwardDFOComparator());\n-            } else {\n-                throw new BugInCF(\"Unexpected Direction meet: \" + direction.name());\n-            }\n-        }\n-\n-        /**\n-         * Process the control flow graph, add the blocks to {@link #depthFirstOrder}.\n-         *\n-         * @param cfg the control flow graph to process\n-         */\n-        public void process(ControlFlowGraph cfg) {\n-            depthFirstOrder.clear();\n-            int count = 1;\n-            for (Block b : cfg.getDepthFirstOrderedBlocks()) {\n-                depthFirstOrder.put(b, count++);\n-            }\n-\n-            queue.clear();\n-        }\n-\n-        /**\n-         * See {@link PriorityQueue#isEmpty}.\n-         *\n-         * @see PriorityQueue#isEmpty\n-         * @return true if {@link #queue} is empty else false\n-         */\n-        @EnsuresNonNullIf(result = false, expression = \"poll()\")\n-        @SuppressWarnings(\"nullness:contracts.conditional.postcondition.not.satisfied\") // forwarded\n-        public boolean isEmpty() {\n-            return queue.isEmpty();\n-        }\n-\n-        /**\n-         * Check if {@link #queue} contains the block which is passed as the argument.\n-         *\n-         * @param block the given block to check\n-         * @return true if {@link #queue} contains the given block\n-         */\n-        public boolean contains(Block block) {\n-            return queue.contains(block);\n-        }\n-\n-        /**\n-         * Add the given block to {@link #queue}.\n-         *\n-         * @param block the block to add to {@link #queue}\n-         */\n-        public void add(Block block) {\n-            queue.add(block);\n-        }\n-\n-        /**\n-         * See {@link PriorityQueue#poll}.\n-         *\n-         * @see PriorityQueue#poll\n-         * @return the head of {@link #queue}\n-         */\n-        public @Nullable Block poll() {\n-            return queue.poll();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"Worklist(\" + queue + \")\";\n-        }\n+    @Override\n+    public String toString() {\n+      return \"Worklist(\" + queue + \")\";\n     }\n+  }\n }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "2ec4fd34f7f674b9f77ca120c2fffc2fa624e3bc", "committedDate": "2020-07-07 17:54:14 -0700", "message": "Run Interning Checker on the Checker Framework codebase"}, {"oid": "2f8bfe0f894b387ec0de01205f74ebef410a9733", "committedDate": "2020-07-09 09:50:17 -0700", "message": "Use -ArequirePrefixInWarningSuppressions when type-checking CF source code"}, {"oid": "dbb8241f3a4a1bf3a0423c643004358d47c0683e", "committedDate": "2020-07-20 16:43:08 -0400", "message": "Move `getValue(Tree)` to Analysis interface. (#3420)"}, {"oid": "5c8336e2b9a8b2eaced5448a305a91c3aac54920", "committedDate": "2020-09-06 16:18:53 -0700", "message": "Fix typo"}, {"oid": "b039a4757b3140ff43c99c68afb672f034685873", "committedDate": "2020-11-23 08:54:27 -0800", "message": "Improve Javadoc style"}, {"oid": "2e0d837070a380337d2981f43a1a67b0b9c20262", "committedDate": "2020-11-30 09:19:40 -0800", "message": "Documentation improvements (#3937)"}, {"oid": "ab9136c0eca1aab83ce1335dc47a033d0f50f917", "committedDate": "2020-12-18 08:51:23 -0800", "message": "Revert workaround for #765"}, {"oid": "f34b1b8812b4e58d73cfb6e3d81938ab92e67e55", "committedDate": "2021-01-12 08:57:13 -0800", "message": "Remove assertion. (#4133)"}, {"oid": "0c7078c066be7839c95ec460bbb232311ec59f42", "committedDate": "2021-02-14 12:23:40 -0800", "message": "Add purity annotations"}, {"oid": "ad3de66d242bf9f9319ffce0ad94b690cc0213d1", "committedDate": "2021-03-19 10:03:48 -0700", "message": "Size collection creation to the collection's final size (#4431)"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}, {"oid": "b79ec907b80b4ae6d217d2805260772f755ffbad", "committedDate": "2021-03-31 20:38:03 -0700", "message": "Reflow comments"}, {"oid": "b5390de432453992c61cfe137f1407d35d305e48", "committedDate": "2021-04-09 12:47:37 -0700", "message": "Use the Map.computeIfAbsent method (#4553)"}, {"oid": "c676eb8980a0f38ad95b6fc9628f08ee465fdb4d", "committedDate": "2021-04-15 14:36:14 -0700", "message": "Set map capacity, to avoid allocating extra memory"}, {"oid": "5c04d6836d8e65daf79667de6539e0d5c055fbbb", "committedDate": "2021-04-30 10:50:51 -0700", "message": "Use shorter suppression message keys"}, {"oid": "2d64c76f5ff2f278c5976017cd05851e5687c74b", "committedDate": "2021-08-12 12:24:57 -0700", "message": "Ignore control flow due to NullPointerExceptions in Called Methods Checker"}, {"oid": "4619dce4be5921c2d93a281d0d72898b87a97285", "committedDate": "2022-03-08 09:42:33 -0800", "message": "Correct when to use the \"pre-conversion\" node's value"}, {"oid": "36d046806c766aff0e1cb8e974acccb546cf73a1", "committedDate": "2022-03-11 22:33:27 +0000", "message": "Clean up/simplify increment/decrement code"}, {"oid": "b55b1eda178bd4d585f522988612cb0dcc9c76e5", "committedDate": "2022-09-12 08:12:23 -0700", "message": "Use more specific types (#5296)"}, {"oid": "3534c5de0e161bbb9fd3bc358fa566a78b4fc2df", "committedDate": "2022-12-20 08:35:27 -0800", "message": "Use uniform formatting for \"package-private\" (#5457)"}, {"oid": "287675ec1715bbf4f9e8cafb8b1d4d15c384f328", "committedDate": "2023-01-18 12:42:23 -0800", "message": "Format more files (#5533)"}, {"oid": "1c7485f54c9ca29137502a76e4e34a1e341705d4", "committedDate": "2023-02-11 18:17:11 +0000", "message": "Remove redundant test, adjust comment (#5648)"}, {"oid": "7c41450007413c58b90dea9457b2f99c6411f7b0", "committedDate": "2023-02-12 12:13:33 -0800", "message": "Add modifiers"}, {"oid": "d72529890af588b6b1f42b17c1d1d9e62b05f450", "committedDate": "2023-02-28 17:24:33 -0800", "message": "Make whitespace around `/*package-private*/` consistent"}]}, {"oid": "78454288079939bbb75eb938d578a6e3572bf3d1", "url": "https://github.com/typetools/checker-framework/commit/78454288079939bbb75eb938d578a6e3572bf3d1", "message": "Add getLastNode() back.", "committedDate": "2020-06-27T04:20:35Z", "type": "commit"}, {"oid": "f7298ee2715c2da7fcb3d510ee89878eedb30146", "url": "https://github.com/typetools/checker-framework/commit/f7298ee2715c2da7fcb3d510ee89878eedb30146", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-27T04:20:53Z", "type": "commit"}, {"oid": "c7290abc9cc7704ff2cf34c8034753f972c9f5ff", "url": "https://github.com/typetools/checker-framework/commit/c7290abc9cc7704ff2cf34c8034753f972c9f5ff", "message": "Use preconditions instead of asserts.", "committedDate": "2020-06-29T12:35:47Z", "type": "commit"}, {"oid": "3c7229253b54ebd86292433f273624c05f6f71b5", "url": "https://github.com/typetools/checker-framework/commit/3c7229253b54ebd86292433f273624c05f6f71b5", "message": "Simplify changelog.", "committedDate": "2020-06-29T12:39:06Z", "type": "commit"}, {"oid": "e01fec3e3fe530a67434640331750f1d23fd158d", "url": "https://github.com/typetools/checker-framework/commit/e01fec3e3fe530a67434640331750f1d23fd158d", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-29T17:21:19Z", "type": "commit"}, {"oid": "01a49af69fafd5eebe41b4df64cf8ce48e6f7375", "url": "https://github.com/typetools/checker-framework/commit/01a49af69fafd5eebe41b4df64cf8ce48e6f7375", "message": "Resolve comments.", "committedDate": "2020-06-29T17:26:42Z", "type": "commit"}, {"oid": "d411396f4c40aab75beb6d3dbad4e74ddc103c5c", "url": "https://github.com/typetools/checker-framework/commit/d411396f4c40aab75beb6d3dbad4e74ddc103c5c", "message": "Tweaks.", "committedDate": "2020-06-29T18:21:17Z", "type": "commit"}, {"oid": "3d10dff362872a7111fb5f751f9216b5f9d6d8aa", "url": "https://github.com/typetools/checker-framework/commit/3d10dff362872a7111fb5f751f9216b5f9d6d8aa", "message": "Merge remote-tracking branch 'origin/master' into typetools-backward-analysis", "committedDate": "2020-06-30T15:38:38Z", "type": "commit"}, {"oid": "cbebd6c7d27f1ebe7d10a365df08895e0b25a32d", "url": "https://github.com/typetools/checker-framework/commit/cbebd6c7d27f1ebe7d10a365df08895e0b25a32d", "message": "Use block instead of bb as parameter name.", "committedDate": "2020-06-30T15:54:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc5MTI1OQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r447791259", "body": "Can this be removed?", "bodyText": "Can this be removed?", "bodyHTML": "<p dir=\"auto\">Can this be removed?</p>", "author": "smillst", "createdAt": "2020-06-30T15:51:42Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java", "diffHunk": "@@ -0,0 +1,392 @@\n+package org.checkerframework.dataflow.analysis;\n+\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Map;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n+import org.checkerframework.dataflow.analysis.Store.FlowRule;\n+import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST;\n+import org.checkerframework.dataflow.cfg.block.Block;\n+import org.checkerframework.dataflow.cfg.block.BlockImpl;\n+import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n+import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n+import org.checkerframework.dataflow.cfg.block.RegularBlock;\n+import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n+import org.checkerframework.dataflow.cfg.block.SpecialBlock.SpecialBlockType;\n+import org.checkerframework.dataflow.cfg.node.Node;\n+import org.checkerframework.dataflow.cfg.node.ReturnNode;\n+import org.checkerframework.javacutil.BugInCF;\n+\n+/**\n+ * An implementation of a backward analysis to solve a org.checkerframework.dataflow problem given a\n+ * control flow graph and a backward transfer function.\n+ *\n+ * @param <V> the abstract value type to be tracked by the analysis\n+ * @param <S> the store type used in the analysis\n+ * @param <T> the transfer function type that is used to approximate runtime behavior\n+ */\n+public class BackwardAnalysisImpl<\n+                V extends AbstractValue<V>,\n+                S extends Store<S>,\n+                T extends BackwardTransferFunction<V, S>>\n+        extends AbstractAnalysis<V, S, T> implements BackwardAnalysis<V, S, T> {\n+\n+    // TODO: Add widening support like what the forward analysis does.\n+\n+    /** Out stores after every basic block (assumed to be 'no information' if not present). */\n+    protected final IdentityHashMap<Block, S> outStores;\n+\n+    /**\n+     * Exception store of an exception block, propagated by exceptional successors of its exception\n+     * block, and merged with the normal {@link TransferResult}.\n+     */\n+    protected final IdentityHashMap<ExceptionBlock, S> exceptionStores;\n+\n+    /** The store right before the entry block. */\n+    protected @Nullable S storeAtEntry;\n+\n+    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n+    /**\n+     * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n+     * control flow graph. The transfer function is set by the subclass, e.g., {@code\n+     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n+     */\n+    public BackwardAnalysisImpl() {\n+        super(Direction.BACKWARD);\n+        this.outStores = new IdentityHashMap<>();\n+        this.exceptionStores = new IdentityHashMap<>();\n+        this.storeAtEntry = null;\n+    }\n+\n+    /**\n+     * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n+     * control flow graph given a transfer function.\n+     *\n+     * @param transfer the transfer function\n+     */\n+    public BackwardAnalysisImpl(@Nullable T transfer) {\n+        this();\n+        this.transferFunction = transfer;\n+    }\n+\n+    @Override\n+    public void performAnalysis(ControlFlowGraph cfg) {\n+        if (isRunning) {\n+            throw new BugInCF(\n+                    \"performAnalysis() shouldn't be called when the analysis is running.\");\n+        }\n+        isRunning = true;\n+        try {\n+            init(cfg);\n+            while (!worklist.isEmpty()) {\n+                Block b = worklist.poll();\n+                performAnalysisBlock(b);\n+            }\n+        } finally {\n+            assert isRunning;\n+            // In case performAnalysisBlock crashed, reset isRunning to false.\n+            isRunning = false;\n+        }\n+    }\n+\n+    @Override\n+    public void performAnalysisBlock(Block b) {\n+        switch (b.getType()) {\n+            case REGULAR_BLOCK:\n+                {\n+                    RegularBlock rb = (RegularBlock) b;\n+                    TransferInput<V, S> inputAfter = getInput(rb);\n+                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+                    currentInput = inputAfter.copy();\n+                    Node firstNode = null;\n+                    boolean addToWorklistAgain = false;\n+                    List<Node> nodeList = rb.getContents();\n+                    ListIterator<Node> reverseIter = nodeList.listIterator(nodeList.size());\n+                    while (reverseIter.hasPrevious()) {\n+                        Node node = reverseIter.previous();\n+                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+                        TransferResult<V, S> transferResult =\n+                                callTransferFunction(node, currentInput);\n+                        addToWorklistAgain |= updateNodeValues(node, transferResult);\n+                        currentInput = new TransferInput<>(node, this, transferResult);\n+                        firstNode = node;\n+                    }\n+                    // Propagate store to predecessors\n+                    for (BlockImpl pred : rb.getPredecessors()) {\n+                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+                        propagateStoresTo(\n+                                pred,\n+                                firstNode,\n+                                currentInput,\n+                                FlowRule.EACH_TO_EACH,\n+                                addToWorklistAgain);\n+                    }\n+                    break;\n+                }\n+            case EXCEPTION_BLOCK:\n+                {\n+                    ExceptionBlock eb = (ExceptionBlock) b;\n+                    TransferInput<V, S> inputAfter = getInput(eb);\n+                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+                    currentInput = inputAfter.copy();\n+                    Node node = eb.getNode();\n+                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n+                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n+                    // Merge transferResult with exceptionStore if there exists one\n+                    S exceptionStore = exceptionStores.get(eb);\n+                    S mergedStore =\n+                            exceptionStore != null\n+                                    ? transferResult\n+                                            .getRegularStore()\n+                                            .leastUpperBound(exceptionStore)\n+                                    : transferResult.getRegularStore();\n+                    for (BlockImpl pred : eb.getPredecessors()) {\n+                        addStoreAfter(pred, node, mergedStore, addToWorklistAgain);\n+                    }\n+                    break;\n+                }\n+            case CONDITIONAL_BLOCK:\n+                {\n+                    ConditionalBlock cb = (ConditionalBlock) b;\n+                    TransferInput<V, S> inputAfter = getInput(cb);\n+                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+                    TransferInput<V, S> input = inputAfter.copy();\n+                    for (BlockImpl pred : cb.getPredecessors()) {\n+                        propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n+                    }\n+                    break;\n+                }\n+            case SPECIAL_BLOCK:\n+                {\n+                    // Special basic blocks are empty and cannot throw exceptions,\n+                    // thus there is no need to perform any analysis.\n+                    SpecialBlock sb = (SpecialBlock) b;\n+                    final SpecialBlockType sType = sb.getSpecialType();\n+                    if (sType == SpecialBlockType.ENTRY) {\n+                        // storage the store at entry\n+                        storeAtEntry = outStores.get(sb);\n+                    } else {\n+                        assert sType == SpecialBlockType.EXIT\n+                                || sType == SpecialBlockType.EXCEPTIONAL_EXIT;\n+                        TransferInput<V, S> input = getInput(sb);\n+                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n+                        for (BlockImpl pred : sb.getPredecessors()) {\n+                            propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n+                        }\n+                    }\n+                    break;\n+                }\n+            default:\n+                throw new BugInCF(\"Unexpected block type: \" + b.getType());\n+        }\n+    }\n+\n+    @Override\n+    public @Nullable TransferInput<V, S> getInput(Block b) {\n+        return inputs.get(b);\n+    }\n+\n+    @Override\n+    public @Nullable S getEntryStore() {\n+        return storeAtEntry;\n+    }\n+\n+    @Override\n+    protected void initFields(ControlFlowGraph cfg) {\n+        super.initFields(cfg);\n+        outStores.clear();\n+        exceptionStores.clear();\n+        // storeAtEntry is null before analysis begin\n+        storeAtEntry = null;\n+    }\n+\n+    @Override\n+    @RequiresNonNull(\"cfg\")\n+    protected void initInitialInputs() {\n+        worklist.process(cfg);\n+        SpecialBlock regularExitBlock = cfg.getRegularExitBlock();\n+        SpecialBlock exceptionExitBlock = cfg.getExceptionalExitBlock();\n+        if (worklist.depthFirstOrder.get(regularExitBlock) == null\n+                && worklist.depthFirstOrder.get(exceptionExitBlock) == null) {\n+            throw new BugInCF(\n+                    \"regularExitBlock and exceptionExitBlock should never both be null at the same time.\");\n+        }\n+        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n+        List<ReturnNode> returnNodes = cfg.getReturnNodes();\n+        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n+        S normalInitialStore = transferFunction.initialNormalExitStore(underlyingAST, returnNodes);\n+        S exceptionalInitialStore = transferFunction.initialExceptionalExitStore(underlyingAST);\n+        // If regularExitBlock or exceptionExitBlock is reachable in the control flow graph, then\n+        // initialize it as a start point of the analysis.\n+        if (worklist.depthFirstOrder.get(regularExitBlock) != null) {\n+            worklist.add(regularExitBlock);\n+            inputs.put(regularExitBlock, new TransferInput<>(null, this, normalInitialStore));\n+            outStores.put(regularExitBlock, normalInitialStore);\n+        }\n+        if (worklist.depthFirstOrder.get(exceptionExitBlock) != null) {\n+            worklist.add(exceptionExitBlock);\n+            inputs.put(\n+                    exceptionExitBlock, new TransferInput<>(null, this, exceptionalInitialStore));\n+            outStores.put(exceptionExitBlock, exceptionalInitialStore);\n+        }\n+        if (worklist.isEmpty()) {\n+            throw new BugInCF(\"The worklist needs at least one exit block as starting point.\");\n+        }\n+        if (inputs.isEmpty() || outStores.isEmpty()) {\n+            throw new BugInCF(\"At least one input and one output store are required.\");\n+        }\n+    }\n+\n+    @Override\n+    protected void propagateStoresTo(\n+            Block pred,\n+            @Nullable Node node,\n+            TransferInput<V, S> currentInput,\n+            FlowRule flowRule,\n+            boolean addToWorklistAgain) {\n+        if (flowRule != FlowRule.EACH_TO_EACH) {\n+            throw new BugInCF(\n+                    \"Backward analysis always propagates EACH to EACH, because there is no control flow.\");\n+        }\n+\n+        addStoreAfter(pred, node, currentInput.getRegularStore(), addToWorklistAgain);\n+    }\n+\n+    /**\n+     * Add a store after the basic block {@code pred} by merging with the existing stores for that\n+     * location.\n+     *\n+     * @param pred the basic block\n+     * @param node the node of the basic block {@code b}\n+     * @param s the store being added\n+     * @param addBlockToWorklist whether the basic block {@code b} should be added back to {@code\n+     *     Worklist}\n+     */\n+    protected void addStoreAfter(Block pred, @Nullable Node node, S s, boolean addBlockToWorklist) {\n+        // If the block pred is an exception block, decide whether the block of passing node is an\n+        // exceptional successor of the block pred\n+        if (pred instanceof ExceptionBlock\n+                && ((ExceptionBlock) pred).getSuccessor() != null\n+                && node != null) {\n+            @Nullable Block succBlock = ((ExceptionBlock) pred).getSuccessor();\n+            @Nullable Block block = node.getBlock();\n+            if (succBlock != null && block != null && succBlock.getId() == block.getId()) {\n+                // If the block of passing node is an exceptional successor of Block pred, propagate\n+                // store to the exceptionStores. Currently it doesn't track the label of an\n+                // exceptional edge from exception block to its exceptional successors in backward\n+                // direction. Instead, all exception stores of exceptional successors of an\n+                // exception block will merge to one exception store at the exception block\n+                ExceptionBlock ebPred = (ExceptionBlock) pred;\n+                S exceptionStore = exceptionStores.get(ebPred);\n+                S newExceptionStore =\n+                        (exceptionStore != null) ? exceptionStore.leastUpperBound(s) : s;\n+                if (!newExceptionStore.equals(exceptionStore)) {\n+                    exceptionStores.put(ebPred, newExceptionStore);\n+                    addBlockToWorklist = true;\n+                }\n+            }\n+        } else {\n+            S predOutStore = getStoreAfter(pred);\n+            S newPredOutStore = (predOutStore != null) ? predOutStore.leastUpperBound(s) : s;\n+            if (!newPredOutStore.equals(predOutStore)) {\n+                outStores.put(pred, newPredOutStore);\n+                inputs.put(pred, new TransferInput<>(node, this, newPredOutStore));\n+                addBlockToWorklist = true;\n+            }\n+        }\n+        if (addBlockToWorklist) {\n+            addToWorklist(pred);\n+        }\n+    }\n+\n+    /**\n+     * Returns the store corresponding to the location right after the basic block {@code b}.\n+     *\n+     * @param b the given block\n+     * @return the store right after the given block\n+     */\n+    protected @Nullable S getStoreAfter(Block b) {\n+        return readFromStore(outStores, b);\n+    }\n+\n+    @Override\n+    public S runAnalysisFor(\n+            Node node,\n+            boolean before,\n+            TransferInput<V, S> transferInput,\n+            IdentityHashMap<Node, V> nodeValues,\n+            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+        Block block = node.getBlock();\n+        assert block != null : \"@AssumeAssertion(nullness): invariant\";\n+        Node oldCurrentNode = currentNode;\n+        // TODO: Understand why the Store of passing node is analysis.currentInput.getRegularStore()", "originalCommit": "d411396f4c40aab75beb6d3dbad4e74ddc103c5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzgwNjQ0MA==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r447806440", "bodyText": "Yes, thanks a lot! I have removed it.", "author": "xingweitian", "createdAt": "2020-06-30T16:13:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc5MTI1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "f549ff7f77e296cf6c0aca2a3582916b5fb15776", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\nindex 9aac0e323..888b0a801 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\n", "chunk": "@@ -322,8 +322,6 @@ public class BackwardAnalysisImpl<\n         Block block = node.getBlock();\n         assert block != null : \"@AssumeAssertion(nullness): invariant\";\n         Node oldCurrentNode = currentNode;\n-        // TODO: Understand why the Store of passing node is analysis.currentInput.getRegularStore()\n-        // when the analysis is running\n         if (isRunning) {\n             assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n             return currentInput.getRegularStore();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "e8bbd7fa9795def75001875908771ea91100b353", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\nindex 9aac0e323..888b0a801 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\n", "chunk": "@@ -322,8 +322,6 @@ public class BackwardAnalysisImpl<\n         Block block = node.getBlock();\n         assert block != null : \"@AssumeAssertion(nullness): invariant\";\n         Node oldCurrentNode = currentNode;\n-        // TODO: Understand why the Store of passing node is analysis.currentInput.getRegularStore()\n-        // when the analysis is running\n         if (isRunning) {\n             assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n             return currentInput.getRegularStore();\n", "next_change": {"commit": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "changed_code": [{"header": "diff --git a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\nindex 888b0a801..062e61387 100644\n--- a/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\n+++ b/dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java\n", "chunk": "@@ -29,362 +29,350 @@ import org.checkerframework.javacutil.BugInCF;\n  * @param <T> the transfer function type that is used to approximate runtime behavior\n  */\n public class BackwardAnalysisImpl<\n-                V extends AbstractValue<V>,\n-                S extends Store<S>,\n-                T extends BackwardTransferFunction<V, S>>\n-        extends AbstractAnalysis<V, S, T> implements BackwardAnalysis<V, S, T> {\n+        V extends AbstractValue<V>, S extends Store<S>, T extends BackwardTransferFunction<V, S>>\n+    extends AbstractAnalysis<V, S, T> implements BackwardAnalysis<V, S, T> {\n \n-    // TODO: Add widening support like what the forward analysis does.\n+  // TODO: Add widening support like what the forward analysis does.\n \n-    /** Out stores after every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> outStores;\n+  /** Out stores after every basic block (assumed to be 'no information' if not present). */\n+  protected final IdentityHashMap<Block, S> outStores;\n \n-    /**\n-     * Exception store of an exception block, propagated by exceptional successors of its exception\n-     * block, and merged with the normal {@link TransferResult}.\n-     */\n-    protected final IdentityHashMap<ExceptionBlock, S> exceptionStores;\n+  /**\n+   * Exception store of an exception block, propagated by exceptional successors of its exception\n+   * block, and merged with the normal {@link TransferResult}.\n+   */\n+  protected final IdentityHashMap<ExceptionBlock, S> exceptionStores;\n \n-    /** The store right before the entry block. */\n-    protected @Nullable S storeAtEntry;\n+  /** The store right before the entry block. */\n+  protected @Nullable S storeAtEntry;\n \n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n-     * control flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public BackwardAnalysisImpl() {\n-        super(Direction.BACKWARD);\n-        this.outStores = new IdentityHashMap<>();\n-        this.exceptionStores = new IdentityHashMap<>();\n-        this.storeAtEntry = null;\n-    }\n+  // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n+  /**\n+   * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n+   * control flow graph. When using this constructor, the transfer function is set later by the\n+   * subclass, e.g., {@code org.checkerframework.framework.flow.CFAbstractAnalysis}.\n+   */\n+  public BackwardAnalysisImpl() {\n+    super(Direction.BACKWARD);\n+    this.outStores = new IdentityHashMap<>();\n+    this.exceptionStores = new IdentityHashMap<>();\n+    this.storeAtEntry = null;\n+  }\n+\n+  /**\n+   * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n+   * control flow graph given a transfer function.\n+   *\n+   * @param transfer the transfer function\n+   */\n+  public BackwardAnalysisImpl(@Nullable T transfer) {\n+    this();\n+    this.transferFunction = transfer;\n+  }\n \n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n-     * control flow graph given a transfer function.\n-     *\n-     * @param transfer the transfer function\n-     */\n-    public BackwardAnalysisImpl(@Nullable T transfer) {\n-        this();\n-        this.transferFunction = transfer;\n+  @Override\n+  public void performAnalysis(ControlFlowGraph cfg) {\n+    if (isRunning) {\n+      throw new BugInCF(\"performAnalysis() shouldn't be called when the analysis is running.\");\n     }\n+    isRunning = true;\n+    try {\n+      init(cfg);\n+      while (!worklist.isEmpty()) {\n+        Block b = worklist.poll();\n+        performAnalysisBlock(b);\n+      }\n+    } finally {\n+      assert isRunning;\n+      // In case performAnalysisBlock crashed, reset isRunning to false.\n+      isRunning = false;\n+    }\n+  }\n \n-    @Override\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        if (isRunning) {\n-            throw new BugInCF(\n-                    \"performAnalysis() shouldn't be called when the analysis is running.\");\n+  @Override\n+  public void performAnalysisBlock(Block b) {\n+    switch (b.getType()) {\n+      case REGULAR_BLOCK:\n+        {\n+          RegularBlock rb = (RegularBlock) b;\n+          TransferInput<V, S> inputAfter = getInput(rb);\n+          assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+          currentInput = inputAfter.copy();\n+          Node firstNode = null;\n+          boolean addToWorklistAgain = false;\n+          List<Node> nodeList = rb.getNodes();\n+          ListIterator<Node> reverseIter = nodeList.listIterator(nodeList.size());\n+          while (reverseIter.hasPrevious()) {\n+            Node node = reverseIter.previous();\n+            assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+            TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n+            addToWorklistAgain |= updateNodeValues(node, transferResult);\n+            currentInput = new TransferInput<>(node, this, transferResult);\n+            firstNode = node;\n+          }\n+          // Propagate store to predecessors\n+          for (Block pred : rb.getPredecessors()) {\n+            assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+            propagateStoresTo(\n+                pred, firstNode, currentInput, FlowRule.EACH_TO_EACH, addToWorklistAgain);\n+          }\n+          break;\n+        }\n+      case EXCEPTION_BLOCK:\n+        {\n+          ExceptionBlock eb = (ExceptionBlock) b;\n+          TransferInput<V, S> inputAfter = getInput(eb);\n+          assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+          currentInput = inputAfter.copy();\n+          Node node = eb.getNode();\n+          TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n+          boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n+          // Merge transferResult with exceptionStore if there exists one\n+          S exceptionStore = exceptionStores.get(eb);\n+          S mergedStore =\n+              exceptionStore != null\n+                  ? transferResult.getRegularStore().leastUpperBound(exceptionStore)\n+                  : transferResult.getRegularStore();\n+          for (Block pred : eb.getPredecessors()) {\n+            addStoreAfter(pred, node, mergedStore, addToWorklistAgain);\n+          }\n+          break;\n         }\n-        isRunning = true;\n-        try {\n-            init(cfg);\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n+      case CONDITIONAL_BLOCK:\n+        {\n+          ConditionalBlock cb = (ConditionalBlock) b;\n+          TransferInput<V, S> inputAfter = getInput(cb);\n+          assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+          TransferInput<V, S> input = inputAfter.copy();\n+          for (Block pred : cb.getPredecessors()) {\n+            propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n+          }\n+          break;\n+        }\n+      case SPECIAL_BLOCK:\n+        {\n+          // Special basic blocks are empty and cannot throw exceptions,\n+          // thus there is no need to perform any analysis.\n+          SpecialBlock sb = (SpecialBlock) b;\n+          final SpecialBlockType sType = sb.getSpecialType();\n+          if (sType == SpecialBlockType.ENTRY) {\n+            // storage the store at entry\n+            storeAtEntry = outStores.get(sb);\n+          } else {\n+            assert sType == SpecialBlockType.EXIT || sType == SpecialBlockType.EXCEPTIONAL_EXIT;\n+            TransferInput<V, S> input = getInput(sb);\n+            assert input != null : \"@AssumeAssertion(nullness): invariant\";\n+            for (Block pred : sb.getPredecessors()) {\n+              propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n             }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n+          }\n+          break;\n         }\n+      default:\n+        throw new BugInCF(\"Unexpected block type: \" + b.getType());\n     }\n+  }\n \n-    @Override\n-    public void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-                    TransferInput<V, S> inputAfter = getInput(rb);\n-                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputAfter.copy();\n-                    Node firstNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    List<Node> nodeList = rb.getContents();\n-                    ListIterator<Node> reverseIter = nodeList.listIterator(nodeList.size());\n-                    while (reverseIter.hasPrevious()) {\n-                        Node node = reverseIter.previous();\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        TransferResult<V, S> transferResult =\n-                                callTransferFunction(node, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(node, transferResult);\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        firstNode = node;\n-                    }\n-                    // Propagate store to predecessors\n-                    for (BlockImpl pred : rb.getPredecessors()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(\n-                                pred,\n-                                firstNode,\n-                                currentInput,\n-                                FlowRule.EACH_TO_EACH,\n-                                addToWorklistAgain);\n-                    }\n-                    break;\n-                }\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-                    TransferInput<V, S> inputAfter = getInput(eb);\n-                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputAfter.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-                    // Merge transferResult with exceptionStore if there exists one\n-                    S exceptionStore = exceptionStores.get(eb);\n-                    S mergedStore =\n-                            exceptionStore != null\n-                                    ? transferResult\n-                                            .getRegularStore()\n-                                            .leastUpperBound(exceptionStore)\n-                                    : transferResult.getRegularStore();\n-                    for (BlockImpl pred : eb.getPredecessors()) {\n-                        addStoreAfter(pred, node, mergedStore, addToWorklistAgain);\n-                    }\n-                    break;\n-                }\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-                    TransferInput<V, S> inputAfter = getInput(cb);\n-                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputAfter.copy();\n-                    for (BlockImpl pred : cb.getPredecessors()) {\n-                        propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n-                    }\n-                    break;\n-                }\n-            case SPECIAL_BLOCK:\n-                {\n-                    // Special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    final SpecialBlockType sType = sb.getSpecialType();\n-                    if (sType == SpecialBlockType.ENTRY) {\n-                        // storage the store at entry\n-                        storeAtEntry = outStores.get(sb);\n-                    } else {\n-                        assert sType == SpecialBlockType.EXIT\n-                                || sType == SpecialBlockType.EXCEPTIONAL_EXIT;\n-                        TransferInput<V, S> input = getInput(sb);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        for (BlockImpl pred : sb.getPredecessors()) {\n-                            propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n-                        }\n-                    }\n-                    break;\n-                }\n-            default:\n-                throw new BugInCF(\"Unexpected block type: \" + b.getType());\n-        }\n-    }\n+  @Override\n+  public @Nullable TransferInput<V, S> getInput(Block b) {\n+    return inputs.get(b);\n+  }\n \n-    @Override\n-    public @Nullable TransferInput<V, S> getInput(Block b) {\n-        return inputs.get(b);\n-    }\n+  @Override\n+  public @Nullable S getEntryStore() {\n+    return storeAtEntry;\n+  }\n \n-    @Override\n-    public @Nullable S getEntryStore() {\n-        return storeAtEntry;\n+  @Override\n+  protected void initFields(ControlFlowGraph cfg) {\n+    super.initFields(cfg);\n+    outStores.clear();\n+    exceptionStores.clear();\n+    // storeAtEntry is null before analysis begin\n+    storeAtEntry = null;\n+  }\n+\n+  @Override\n+  @RequiresNonNull(\"cfg\")\n+  protected void initInitialInputs() {\n+    worklist.process(cfg);\n+    SpecialBlock regularExitBlock = cfg.getRegularExitBlock();\n+    SpecialBlock exceptionExitBlock = cfg.getExceptionalExitBlock();\n+    if (worklist.depthFirstOrder.get(regularExitBlock) == null\n+        && worklist.depthFirstOrder.get(exceptionExitBlock) == null) {\n+      throw new BugInCF(\n+          \"regularExitBlock and exceptionExitBlock should never both be null at the same time.\");\n+    }\n+    UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n+    List<ReturnNode> returnNodes = cfg.getReturnNodes();\n+    assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n+    S normalInitialStore = transferFunction.initialNormalExitStore(underlyingAST, returnNodes);\n+    S exceptionalInitialStore = transferFunction.initialExceptionalExitStore(underlyingAST);\n+    // If regularExitBlock or exceptionExitBlock is reachable in the control flow graph, then\n+    // initialize it as a start point of the analysis.\n+    if (worklist.depthFirstOrder.get(regularExitBlock) != null) {\n+      worklist.add(regularExitBlock);\n+      inputs.put(regularExitBlock, new TransferInput<>(null, this, normalInitialStore));\n+      outStores.put(regularExitBlock, normalInitialStore);\n     }\n+    if (worklist.depthFirstOrder.get(exceptionExitBlock) != null) {\n+      worklist.add(exceptionExitBlock);\n+      inputs.put(exceptionExitBlock, new TransferInput<>(null, this, exceptionalInitialStore));\n+      outStores.put(exceptionExitBlock, exceptionalInitialStore);\n+    }\n+    if (worklist.isEmpty()) {\n+      throw new BugInCF(\"The worklist needs at least one exit block as starting point.\");\n+    }\n+    if (inputs.isEmpty() || outStores.isEmpty()) {\n+      throw new BugInCF(\"At least one input and one output store are required.\");\n+    }\n+  }\n \n-    @Override\n-    protected void initFields(ControlFlowGraph cfg) {\n-        super.initFields(cfg);\n-        outStores.clear();\n-        exceptionStores.clear();\n-        // storeAtEntry is null before analysis begin\n-        storeAtEntry = null;\n+  @Override\n+  protected void propagateStoresTo(\n+      Block pred,\n+      @Nullable Node node,\n+      TransferInput<V, S> currentInput,\n+      FlowRule flowRule,\n+      boolean addToWorklistAgain) {\n+    if (flowRule != FlowRule.EACH_TO_EACH) {\n+      throw new BugInCF(\n+          \"Backward analysis always propagates EACH to EACH, because there is no control flow.\");\n     }\n \n-    @Override\n-    @RequiresNonNull(\"cfg\")\n-    protected void initInitialInputs() {\n-        worklist.process(cfg);\n-        SpecialBlock regularExitBlock = cfg.getRegularExitBlock();\n-        SpecialBlock exceptionExitBlock = cfg.getExceptionalExitBlock();\n-        if (worklist.depthFirstOrder.get(regularExitBlock) == null\n-                && worklist.depthFirstOrder.get(exceptionExitBlock) == null) {\n-            throw new BugInCF(\n-                    \"regularExitBlock and exceptionExitBlock should never both be null at the same time.\");\n-        }\n-        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n-        List<ReturnNode> returnNodes = cfg.getReturnNodes();\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        S normalInitialStore = transferFunction.initialNormalExitStore(underlyingAST, returnNodes);\n-        S exceptionalInitialStore = transferFunction.initialExceptionalExitStore(underlyingAST);\n-        // If regularExitBlock or exceptionExitBlock is reachable in the control flow graph, then\n-        // initialize it as a start point of the analysis.\n-        if (worklist.depthFirstOrder.get(regularExitBlock) != null) {\n-            worklist.add(regularExitBlock);\n-            inputs.put(regularExitBlock, new TransferInput<>(null, this, normalInitialStore));\n-            outStores.put(regularExitBlock, normalInitialStore);\n-        }\n-        if (worklist.depthFirstOrder.get(exceptionExitBlock) != null) {\n-            worklist.add(exceptionExitBlock);\n-            inputs.put(\n-                    exceptionExitBlock, new TransferInput<>(null, this, exceptionalInitialStore));\n-            outStores.put(exceptionExitBlock, exceptionalInitialStore);\n-        }\n-        if (worklist.isEmpty()) {\n-            throw new BugInCF(\"The worklist needs at least one exit block as starting point.\");\n-        }\n-        if (inputs.isEmpty() || outStores.isEmpty()) {\n-            throw new BugInCF(\"At least one input and one output store are required.\");\n+    addStoreAfter(pred, node, currentInput.getRegularStore(), addToWorklistAgain);\n+  }\n+\n+  /**\n+   * Add a store after the basic block {@code pred} by merging with the existing stores for that\n+   * location.\n+   *\n+   * @param pred the basic block\n+   * @param node the node of the basic block {@code b}\n+   * @param s the store being added\n+   * @param addBlockToWorklist whether the basic block {@code b} should be added back to {@code\n+   *     Worklist}\n+   */\n+  protected void addStoreAfter(Block pred, @Nullable Node node, S s, boolean addBlockToWorklist) {\n+    // If the block pred is an exception block, decide whether the block of passing node is an\n+    // exceptional successor of the block pred\n+    if (pred instanceof ExceptionBlock\n+        && ((ExceptionBlock) pred).getSuccessor() != null\n+        && node != null) {\n+      @Nullable Block succBlock = ((ExceptionBlock) pred).getSuccessor();\n+      @Nullable Block block = node.getBlock();\n+      if (succBlock != null && block != null && succBlock.getUid() == block.getUid()) {\n+        // If the block of passing node is an exceptional successor of Block pred, propagate\n+        // store to the exceptionStores. Currently it doesn't track the label of an\n+        // exceptional edge from exception block to its exceptional successors in backward\n+        // direction. Instead, all exception stores of exceptional successors of an\n+        // exception block will merge to one exception store at the exception block\n+        ExceptionBlock ebPred = (ExceptionBlock) pred;\n+        S exceptionStore = exceptionStores.get(ebPred);\n+        S newExceptionStore = (exceptionStore != null) ? exceptionStore.leastUpperBound(s) : s;\n+        if (!newExceptionStore.equals(exceptionStore)) {\n+          exceptionStores.put(ebPred, newExceptionStore);\n+          inputs.put(ebPred, new TransferInput<V, S>(node, this, newExceptionStore));\n+          addBlockToWorklist = true;\n         }\n+      }\n+    } else {\n+      S predOutStore = getStoreAfter(pred);\n+      S newPredOutStore = (predOutStore != null) ? predOutStore.leastUpperBound(s) : s;\n+      if (!newPredOutStore.equals(predOutStore)) {\n+        outStores.put(pred, newPredOutStore);\n+        inputs.put(pred, new TransferInput<>(node, this, newPredOutStore));\n+        addBlockToWorklist = true;\n+      }\n     }\n+    if (addBlockToWorklist) {\n+      addToWorklist(pred);\n+    }\n+  }\n \n-    @Override\n-    protected void propagateStoresTo(\n-            Block pred,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        if (flowRule != FlowRule.EACH_TO_EACH) {\n-            throw new BugInCF(\n-                    \"Backward analysis always propagates EACH to EACH, because there is no control flow.\");\n-        }\n+  /**\n+   * Returns the store corresponding to the location right after the basic block {@code b}.\n+   *\n+   * @param b the given block\n+   * @return the store right after the given block\n+   */\n+  protected @Nullable S getStoreAfter(Block b) {\n+    return readFromStore(outStores, b);\n+  }\n \n-        addStoreAfter(pred, node, currentInput.getRegularStore(), addToWorklistAgain);\n+  @Override\n+  public S runAnalysisFor(\n+      @FindDistinct Node node,\n+      Analysis.BeforeOrAfter preOrPost,\n+      TransferInput<V, S> blockTransferInput,\n+      IdentityHashMap<Node, V> nodeValues,\n+      Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+    Block block = node.getBlock();\n+    assert block != null : \"@AssumeAssertion(nullness): invariant\";\n+    Node oldCurrentNode = currentNode;\n+    if (isRunning) {\n+      assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+      return currentInput.getRegularStore();\n     }\n-\n-    /**\n-     * Add a store after the basic block {@code pred} by merging with the existing stores for that\n-     * location.\n-     *\n-     * @param pred the basic block\n-     * @param node the node of the basic block {@code b}\n-     * @param s the store being added\n-     * @param addBlockToWorklist whether the basic block {@code b} should be added back to {@code\n-     *     Worklist}\n-     */\n-    protected void addStoreAfter(Block pred, @Nullable Node node, S s, boolean addBlockToWorklist) {\n-        // If the block pred is an exception block, decide whether the block of passing node is an\n-        // exceptional successor of the block pred\n-        if (pred instanceof ExceptionBlock\n-                && ((ExceptionBlock) pred).getSuccessor() != null\n-                && node != null) {\n-            @Nullable Block succBlock = ((ExceptionBlock) pred).getSuccessor();\n-            @Nullable Block block = node.getBlock();\n-            if (succBlock != null && block != null && succBlock.getId() == block.getId()) {\n-                // If the block of passing node is an exceptional successor of Block pred, propagate\n-                // store to the exceptionStores. Currently it doesn't track the label of an\n-                // exceptional edge from exception block to its exceptional successors in backward\n-                // direction. Instead, all exception stores of exceptional successors of an\n-                // exception block will merge to one exception store at the exception block\n-                ExceptionBlock ebPred = (ExceptionBlock) pred;\n-                S exceptionStore = exceptionStores.get(ebPred);\n-                S newExceptionStore =\n-                        (exceptionStore != null) ? exceptionStore.leastUpperBound(s) : s;\n-                if (!newExceptionStore.equals(exceptionStore)) {\n-                    exceptionStores.put(ebPred, newExceptionStore);\n-                    addBlockToWorklist = true;\n-                }\n+    isRunning = true;\n+    try {\n+      switch (block.getType()) {\n+        case REGULAR_BLOCK:\n+          {\n+            RegularBlock rBlock = (RegularBlock) block;\n+            // Apply transfer function to contents until we found the node we are\n+            // looking for.\n+            TransferInput<V, S> store = blockTransferInput;\n+            List<Node> nodeList = rBlock.getNodes();\n+            ListIterator<Node> reverseIter = nodeList.listIterator(nodeList.size());\n+            while (reverseIter.hasPrevious()) {\n+              Node n = reverseIter.previous();\n+              setCurrentNode(n);\n+              if (n == node && preOrPost == Analysis.BeforeOrAfter.AFTER) {\n+                return store.getRegularStore();\n+              }\n+              // Copy the store to avoid changing other blocks' transfer inputs in\n+              // {@link #inputs}\n+              TransferResult<V, S> transferResult = callTransferFunction(n, store.copy());\n+              if (n == node) {\n+                return transferResult.getRegularStore();\n+              }\n+              store = new TransferInput<>(n, this, transferResult);\n             }\n-        } else {\n-            S predOutStore = getStoreAfter(pred);\n-            S newPredOutStore = (predOutStore != null) ? predOutStore.leastUpperBound(s) : s;\n-            if (!newPredOutStore.equals(predOutStore)) {\n-                outStores.put(pred, newPredOutStore);\n-                inputs.put(pred, new TransferInput<>(node, this, newPredOutStore));\n-                addBlockToWorklist = true;\n+            throw new BugInCF(\"node %s is not in node.getBlock()=%s\", node, block);\n+          }\n+        case EXCEPTION_BLOCK:\n+          {\n+            ExceptionBlock eb = (ExceptionBlock) block;\n+            if (eb.getNode() != node) {\n+              throw new BugInCF(\n+                  \"Node should be equal to eb.getNode(). But get: node: \"\n+                      + node\n+                      + \"\\teb.getNode(): \"\n+                      + eb.getNode());\n             }\n-        }\n-        if (addBlockToWorklist) {\n-            addToWorklist(pred);\n-        }\n-    }\n-\n-    /**\n-     * Returns the store corresponding to the location right after the basic block {@code b}.\n-     *\n-     * @param b the given block\n-     * @return the store right after the given block\n-     */\n-    protected @Nullable S getStoreAfter(Block b) {\n-        return readFromStore(outStores, b);\n-    }\n-\n-    @Override\n-    public S runAnalysisFor(\n-            Node node,\n-            boolean before,\n-            TransferInput<V, S> transferInput,\n-            IdentityHashMap<Node, V> nodeValues,\n-            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n-        Block block = node.getBlock();\n-        assert block != null : \"@AssumeAssertion(nullness): invariant\";\n-        Node oldCurrentNode = currentNode;\n-        if (isRunning) {\n-            assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-            return currentInput.getRegularStore();\n-        }\n-        isRunning = true;\n-        try {\n-            switch (block.getType()) {\n-                case REGULAR_BLOCK:\n-                    {\n-                        RegularBlock rBlock = (RegularBlock) block;\n-                        // Apply transfer function to contents until we found the node we are\n-                        // looking for.\n-                        TransferInput<V, S> store = transferInput;\n-                        List<Node> nodeList = rBlock.getContents();\n-                        ListIterator<Node> reverseIter = nodeList.listIterator(nodeList.size());\n-                        while (reverseIter.hasPrevious()) {\n-                            Node n = reverseIter.previous();\n-                            currentNode = n;\n-                            if (n == node && !before) {\n-                                return store.getRegularStore();\n-                            }\n-                            // Copy the store to preserve to change the state in {@link #inputs}\n-                            TransferResult<V, S> transferResult =\n-                                    callTransferFunction(n, store.copy());\n-                            if (n == node) {\n-                                return transferResult.getRegularStore();\n-                            }\n-                            store = new TransferInput<>(n, this, transferResult);\n-                        }\n-                        // This point should never be reached. If the block of 'node' is\n-                        // 'block', then 'node' must be part of the contents of 'block'.\n-                        throw new BugInCF(\"This point should never be reached.\");\n-                    }\n-                case EXCEPTION_BLOCK:\n-                    {\n-                        ExceptionBlock eb = (ExceptionBlock) block;\n-                        if (eb.getNode() != node) {\n-                            throw new BugInCF(\n-                                    \"Node should be equal to eb.getNode(). But get: node: \"\n-                                            + node\n-                                            + \"\\teb.getNode(): \"\n-                                            + eb.getNode());\n-                        }\n-                        if (!before) {\n-                            return transferInput.getRegularStore();\n-                        }\n-                        currentNode = node;\n-                        TransferResult<V, S> transferResult =\n-                                callTransferFunction(node, transferInput);\n-                        // Merge transfer result with the exception store of this exceptional block\n-                        S exceptionStore = exceptionStores.get(eb);\n-                        return exceptionStore == null\n-                                ? transferResult.getRegularStore()\n-                                : transferResult.getRegularStore().leastUpperBound(exceptionStore);\n-                    }\n-                default:\n-                    // Only regular blocks and exceptional blocks can hold nodes.\n-                    throw new BugInCF(\"Unexpected block type: \" + block.getType());\n+            if (preOrPost == Analysis.BeforeOrAfter.AFTER) {\n+              return blockTransferInput.getRegularStore();\n             }\n+            setCurrentNode(node);\n+            // Copy the store to avoid changing other blocks' transfer inputs in {@link\n+            // #inputs}\n+            TransferResult<V, S> transferResult =\n+                callTransferFunction(node, blockTransferInput.copy());\n+            // Merge transfer result with the exception store of this exceptional block\n+            S exceptionStore = exceptionStores.get(eb);\n+            return exceptionStore == null\n+                ? transferResult.getRegularStore()\n+                : transferResult.getRegularStore().leastUpperBound(exceptionStore);\n+          }\n+        default:\n+          // Only regular blocks and exceptional blocks can hold nodes.\n+          throw new BugInCF(\"Unexpected block type: \" + block.getType());\n+      }\n \n-        } finally {\n-            currentNode = oldCurrentNode;\n-            isRunning = false;\n-        }\n+    } finally {\n+      setCurrentNode(oldCurrentNode);\n+      isRunning = false;\n     }\n+  }\n }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "e8bbd7fa9795def75001875908771ea91100b353", "message": "Merge commit", "committedDate": null}, {"oid": "2ec4fd34f7f674b9f77ca120c2fffc2fa624e3bc", "committedDate": "2020-07-07 17:54:14 -0700", "message": "Run Interning Checker on the Checker Framework codebase"}, {"oid": "bc9a1203c90869ceee5b02c7b12071732794ac47", "committedDate": "2020-07-23 13:52:31 -0700", "message": "Correct the logic of dataflow framework. (#3414)"}, {"oid": "b7f353d05983e3367235af0539e19f92c1b48f4b", "committedDate": "2020-07-30 21:58:19 -0700", "message": "Interface should not reference implementation subclasses"}, {"oid": "08afd3f6aebcfc80f7dde7ecbe53957109cb8ec3", "committedDate": "2020-08-05 12:25:03 -0700", "message": "Add Block.getNodes() method"}, {"oid": "a3e76038b117589dc0dfdb7a8c3d5b2be35efb5d", "committedDate": "2020-09-10 15:32:14 -0700", "message": "Improve messages in exceptions"}, {"oid": "95dd27f7e2bd94266ee8f7e6058083be7e6ec07a", "committedDate": "2020-09-10 15:32:25 -0700", "message": "Rename some occurrences of `transferInput` to `blockTransferInput`"}, {"oid": "6a71e35c12c223c94867d7369dbc18e7098f1f02", "committedDate": "2020-10-13 13:55:46 -0700", "message": "Dataflow documentation tweaks"}, {"oid": "139c4df9a4a18f122e458c4276ac914a82ff3776", "committedDate": "2020-10-19 00:16:18 -0700", "message": "Make Block extend UniqueId"}, {"oid": "f90c3d1038925d820c3d99d2fa0ac1c65fca07da", "committedDate": "2020-11-23 09:06:39 -0800", "message": "Change boolean to enum for readability; fixes #3390"}, {"oid": "94173a4b03022ccb6651b5f6471fb81e1bcdf18c", "committedDate": "2021-03-26 13:57:23 -0700", "message": "Use google-java-format version 1.9"}, {"oid": "764713248ea994e55cfa45f723dcda6a22881eeb", "committedDate": "2021-04-01 08:39:55 -0700", "message": "Reflow comments"}, {"oid": "c676eb8980a0f38ad95b6fc9628f08ee465fdb4d", "committedDate": "2021-04-15 14:36:14 -0700", "message": "Set map capacity, to avoid allocating extra memory"}, {"oid": "c5886a97da58e633be28b310f70a6d0815b06621", "committedDate": "2021-08-05 08:36:23 -0700", "message": "Correct handling of exception edges in backward analysis"}, {"oid": "2d64c76f5ff2f278c5976017cd05851e5687c74b", "committedDate": "2021-08-12 12:24:57 -0700", "message": "Ignore control flow due to NullPointerExceptions in Called Methods Checker"}, {"oid": "287675ec1715bbf4f9e8cafb8b1d4d15c384f328", "committedDate": "2023-01-18 12:42:23 -0800", "message": "Format more files (#5533)"}, {"oid": "8c31b8036e369c726d7ea7adae992f1e049e8880", "committedDate": "2023-01-23 08:22:25 -0800", "message": "Iterate over map entries rather than looking up keys (#5557)"}]}, {"oid": "77f50dfe960804603bdad6da8ea256f3a0c3da64", "url": "https://github.com/typetools/checker-framework/commit/77f50dfe960804603bdad6da8ea256f3a0c3da64", "message": "Merge pull request #13 from smillst/typetools-backward-analysis\n\nUse block instead of bb as parameter name.", "committedDate": "2020-06-30T16:01:51Z", "type": "commit"}, {"oid": "f549ff7f77e296cf6c0aca2a3582916b5fb15776", "url": "https://github.com/typetools/checker-framework/commit/f549ff7f77e296cf6c0aca2a3582916b5fb15776", "message": "Resolve comment.", "committedDate": "2020-06-30T16:10:16Z", "type": "commit"}, {"oid": "5ab4d76c269424673723e7dee8f143a118416961", "url": "https://github.com/typetools/checker-framework/commit/5ab4d76c269424673723e7dee8f143a118416961", "message": "Merge remote-tracking branch 'origin/typetools-backward-analysis' into typetools-backward-analysis", "committedDate": "2020-06-30T16:12:06Z", "type": "commit"}]}