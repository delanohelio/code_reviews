{"pr_number": 7414, "pr_title": "Iqss/6497 semantic api", "pr_author": "qqmyers", "pr_createdAt": "2020-11-16T20:54:52Z", "pr_url": "https://github.com/IQSS/dataverse/pull/7414", "merge_commit": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU0MzIyOA==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r662543228", "body": "Jenkins is showing an error (400, BAD REQUEST) instead of a 200 here: https://jenkins.dataverse.org/blue/organizations/jenkins/IQSS-Dataverse-Develop-PR/detail/PR-7414/64/tests ", "bodyText": "Jenkins is showing an error (400, BAD REQUEST) instead of a 200 here: https://jenkins.dataverse.org/blue/organizations/jenkins/IQSS-Dataverse-Develop-PR/detail/PR-7414/64/tests", "bodyHTML": "<p dir=\"auto\">Jenkins is showing an error (400, BAD REQUEST) instead of a 200 here: <a href=\"https://jenkins.dataverse.org/blue/organizations/jenkins/IQSS-Dataverse-Develop-PR/detail/PR-7414/64/tests\" rel=\"nofollow\">https://jenkins.dataverse.org/blue/organizations/jenkins/IQSS-Dataverse-Develop-PR/detail/PR-7414/64/tests</a></p>", "author": "pdurbin", "createdAt": "2021-07-01T19:32:29Z", "path": "src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java", "diffHunk": "@@ -2164,4 +2157,111 @@ public void testRestrictFileExportDdi() throws IOException {\n                 .body(\"message\", equalTo(\"You do not have permission to download this file.\"));\n     }\n \n+    @Test\n+    public void testSemanticMetadataAPIs() {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        // Create a dataset using native api\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n+\n+        // Get the metadata with the semantic api\n+        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+        // Compare the metadata with an expected value - the metadatablock entries\n+        // should be the same but there will be additional fields with values related to\n+        // the dataset's creation (e.g. new id)\n+        String jsonLDString = getData(response.getBody().asString());\n+        JsonObject jo = null;\n+        try {\n+            jo = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        } catch (NoSuchMethodError e) {\n+            logger.info(ExceptionUtils.getStackTrace(e));\n+        }\n+        \n+\n+        String expectedJsonLD = UtilIT.getDatasetJson(\"scripts/search/tests/data/dataset-finch1.jsonld\");\n+        jo = Json.createObjectBuilder(jo).remove(\"@id\").remove(\"http://schema.org/dateModified\").build();\n+        String jsonLD = jo.toString();\n+\n+        // ToDo: Are the static pars as expected\n+        JSONAssert.assertEquals(expectedJsonLD, jsonLD, false);\n+        // Now change the title\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken,\n+                \"{\\\"Title\\\": \\\"New Title\\\", \\\"@context\\\":{\\\"Title\\\": \\\"http://purl.org/dc/terms/title\\\"}}\", true);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        // Check that the semantic api returns the new title\n+        jsonLDString = getData(response.getBody().asString());\n+        JsonObject jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertEquals(\"New Title\", jsonLDObject.getString(\"http://purl.org/dc/terms/title\"));\n+\n+        // Add an additional description (which is multi-valued and compound)\n+        // Also add new terms of use (single value so would fail with replace false if a\n+        // value existed)\n+        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\", \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"} \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n+        response.then().assertThat().statusCode(OK.getStatusCode());", "originalCommit": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzEyNTA0NA==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r663125044", "bodyText": "Some typos in the json-ld -should be fixed", "author": "qqmyers", "createdAt": "2021-07-02T16:22:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU0MzIyOA=="}], "type": "inlineReview", "revised_code": {"commit": "e159003877928889aa5f3293b4ae64b99dfbf8d2", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 7074c55d64..e8f1e71e25 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2210,7 +2210,7 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         // Add an additional description (which is multi-valued and compound)\n         // Also add new terms of use (single value so would fail with replace false if a\n         // value existed)\n-        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\", \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"} \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n+        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\"}, \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\", \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n         response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n         response.then().assertThat().statusCode(OK.getStatusCode());\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 7074c55d64..e8f1e71e25 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2210,7 +2210,7 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         // Add an additional description (which is multi-valued and compound)\n         // Also add new terms of use (single value so would fail with replace false if a\n         // value existed)\n-        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\", \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"} \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n+        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\"}, \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\", \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n         response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n         response.then().assertThat().statusCode(OK.getStatusCode());\n \n", "next_change": {"commit": "1e7fcd17d7b102bd141e94b262ee6a53b60d2f56", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex e8f1e71e25..04d7c77d4f 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2157,111 +2164,4 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .body(\"message\", equalTo(\"You do not have permission to download this file.\"));\n     }\n \n-    @Test\n-    public void testSemanticMetadataAPIs() {\n-        Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-\n-        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n-        createDataverseResponse.prettyPrint();\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n-\n-        // Create a dataset using native api\n-        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        createDatasetResponse.prettyPrint();\n-        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n-\n-        // Get the metadata with the semantic api\n-        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-        // Compare the metadata with an expected value - the metadatablock entries\n-        // should be the same but there will be additional fields with values related to\n-        // the dataset's creation (e.g. new id)\n-        String jsonLDString = getData(response.getBody().asString());\n-        JsonObject jo = null;\n-        try {\n-            jo = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        } catch (NoSuchMethodError e) {\n-            logger.info(ExceptionUtils.getStackTrace(e));\n-        }\n-        \n-\n-        String expectedJsonLD = UtilIT.getDatasetJson(\"scripts/search/tests/data/dataset-finch1.jsonld\");\n-        jo = Json.createObjectBuilder(jo).remove(\"@id\").remove(\"http://schema.org/dateModified\").build();\n-        String jsonLD = jo.toString();\n-\n-        // ToDo: Are the static pars as expected\n-        JSONAssert.assertEquals(expectedJsonLD, jsonLD, false);\n-        // Now change the title\n-        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken,\n-                \"{\\\"Title\\\": \\\"New Title\\\", \\\"@context\\\":{\\\"Title\\\": \\\"http://purl.org/dc/terms/title\\\"}}\", true);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        // Check that the semantic api returns the new title\n-        jsonLDString = getData(response.getBody().asString());\n-        JsonObject jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        assertEquals(\"New Title\", jsonLDObject.getString(\"http://purl.org/dc/terms/title\"));\n-\n-        // Add an additional description (which is multi-valued and compound)\n-        // Also add new terms of use (single value so would fail with replace false if a\n-        // value existed)\n-        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\"}, \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\", \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n-        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        // Look for a second description\n-        jsonLDString = getData(response.getBody().asString());\n-        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        assertEquals(\"New description\",\n-                ((JsonObject) jsonLDObject.getJsonArray(\"https://dataverse.org/schema/citation/Description\").get(1))\n-                        .getString(\"https://dataverse.org/schema/citation/dsDescription#Text\"));\n-\n-        // Can't add terms of use with replace=false and a value already set (single\n-        // valued field)\n-        String badTerms = \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"Bad terms\\\"}}\";\n-        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, badTerms, false);\n-        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n-\n-        // Delete the terms of use\n-        response = UtilIT.deleteDatasetJsonLDMetadata(datasetId, apiToken,\n-                \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"}\");\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        // Verify that they're gone\n-        jsonLDString = getData(response.getBody().asString());\n-        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        assertTrue(!jsonLDObject.containsKey(\"https://dataverse.org/schema/core#termsOfUse\"));\n-\n-        // Cleanup - delete dataset, dataverse, user...\n-        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n-        deleteDatasetResponse.prettyPrint();\n-        assertEquals(200, deleteDatasetResponse.getStatusCode());\n-\n-        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n-        deleteDataverseResponse.prettyPrint();\n-        assertEquals(200, deleteDataverseResponse.getStatusCode());\n-\n-        Response deleteUserResponse = UtilIT.deleteUser(username);\n-        deleteUserResponse.prettyPrint();\n-        assertEquals(200, deleteUserResponse.getStatusCode());\n-\n-    }\n-\n-    private String getData(String body) {\n-        try (StringReader rdr = new StringReader(body)) {\n-            return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n-        }\n-    }\n-\n }\n", "next_change": {"commit": "da9c9e9e24556fafa6bc81d78cddd29b0632094e", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 04d7c77d4f..5943650e80 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2163,5 +2165,157 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .statusCode(BAD_REQUEST.getStatusCode())\n                 .body(\"message\", equalTo(\"You do not have permission to download this file.\"));\n     }\n+    \n+\n+    @Test\n+    public void testSemanticMetadataAPIs() {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        \n+        //Create a dataset using native api\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n+\n+        //Get the metadata with the semantic api\n+        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        //Compare the metadata with an expected value - the metadatablock entries should be the same but there will be additional fields with values related to the dataset's creation (e.g. new id)\n+        String jsonLDString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+        String jsonLD = JSONLDUtil.decontextualizeJsonLD(jsonLDString).toString();\n+\n+        String expectedJsonLD = UtilIT.getDatasetJson(\"scripts/search/tests/data/dataset-finch1.jsonld\");\n+\n+        //ToDo: Are the static pars as expected\n+        assertEquals(expectedJsonLD, jsonLD);\n \n+        //Now change the title\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken,\n+                \"{\\\"Title\\\": \\\"New Title\\\", \\\"@context\\\":{\\\"Title\\\": \\\"http://purl.org/dc/terms/title\\\"}}\", true);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        //Check that the semantic api returns the new title\n+        jsonLDString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+        JsonObject jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertEquals(\"New Title\", jsonLDObject.getString(\"http://purl.org/dc/terms/title\"));\n+\n+        //Add an additional description (which is multi-valued and compound)\n+        //Also add new terms of use (single value so would fail with replace false if a value existed)\n+        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\", \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"} \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        //Look for a second description\n+        jsonLDString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertEquals(\"New description\",\n+                ((JsonObject) jsonLDObject.getJsonArray(\"https://dataverse.org/schema/citation/Description\").get(1))\n+                        .getString(\"https://dataverse.org/schema/citation/dsDescription#Text\"));\n+\n+        //Can't add terms of use with replace=false and a value already set (single valued field)\n+        String badTerms = \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"Bad terms\\\"}}\";\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, badTerms, false);\n+        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+\n+        \n+        //Delete the terms of use\n+        response = UtilIT.deleteDatasetJsonLDMetadata(datasetId, apiToken,\n+                \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"}\");\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        //Verify that they're gone\n+        jsonLDString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertTrue(!jsonLDObject.containsKey(\"https://dataverse.org/schema/core#termsOfUse\"));\n+\n+        //Cleanup - delete dataset, dataverse, user...\n+        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n+        deleteDatasetResponse.prettyPrint();\n+        assertEquals(200, deleteDatasetResponse.getStatusCode());\n+\n+        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n+        deleteDataverseResponse.prettyPrint();\n+        assertEquals(200, deleteDataverseResponse.getStatusCode());\n+\n+        Response deleteUserResponse = UtilIT.deleteUser(username);\n+        deleteUserResponse.prettyPrint();\n+        assertEquals(200, deleteUserResponse.getStatusCode());\n+\n+    }\n+    @Test\n+    public void testReCreateDataset() {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+        assertEquals(200, makeSuperUser.getStatusCode());\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        //Create a dataset using native API\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n+\n+        //Get the semantic metadata\n+        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        String expectedJsonLD = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+\n+        //Delete the dataset via native API\n+        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n+        deleteDatasetResponse.prettyPrint();\n+        assertEquals(200, deleteDatasetResponse.getStatusCode());\n+\n+        //Now use the migrate API to recreate the dataset\n+        response = UtilIT.recreateDatasetJsonLD(datasetId, apiToken, dataverseAlias, expectedJsonLD);\n+        response.then().assertThat().statusCode(CREATED.getStatusCode());\n+        //Id will change but everything else should be as before (DOI and create date)\n+        datasetId = JsonPath.from(response.getBody().asString()).getInt(\"data/id\");\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+        String jsonLDString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+        JsonObject jsonLD = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        \n+\n+        //ToDo: Assert that the semantic api response is the same except for the id\n+        assertEquals(expectedJsonLD, jsonLD.toString());\n+\n+        //Cleanup by deleting things\n+        deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n+        deleteDatasetResponse.prettyPrint();\n+        assertEquals(200, deleteDatasetResponse.getStatusCode());\n+\n+        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n+        deleteDataverseResponse.prettyPrint();\n+        assertEquals(200, deleteDataverseResponse.getStatusCode());\n+\n+        Response deleteUserResponse = UtilIT.deleteUser(username);\n+        deleteUserResponse.prettyPrint();\n+        assertEquals(200, deleteUserResponse.getStatusCode());\n+    }\n }\n", "next_change": {"commit": "4cd26692ad13fdb788b29ed603993e5a027199d4", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 5943650e80..e725864e85 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2318,4 +2341,10 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         deleteUserResponse.prettyPrint();\n         assertEquals(200, deleteUserResponse.getStatusCode());\n     }\n+    \n+    private String getData(String body) {\n+        try (StringReader rdr = new StringReader(body)) {\n+            return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n+        }\n+    }\n }\n", "next_change": {"commit": "5f53e158462feb04c1c53bf4d17aed214733bc48", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex e725864e85..f00bcd5911 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2341,7 +2326,7 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         deleteUserResponse.prettyPrint();\n         assertEquals(200, deleteUserResponse.getStatusCode());\n     }\n-    \n+\n     private String getData(String body) {\n         try (StringReader rdr = new StringReader(body)) {\n             return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n", "next_change": {"commit": "1a348f5f3660916a538a9d4f3fc1ed062fac83ab", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex f00bcd5911..956cce5eec 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2156,180 +2163,5 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .statusCode(BAD_REQUEST.getStatusCode())\n                 .body(\"message\", equalTo(\"You do not have permission to download this file.\"));\n     }\n-    \n-\n-    @Test\n-    public void testSemanticMetadataAPIs() {\n-        Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-\n-        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n-        createDataverseResponse.prettyPrint();\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n-\n-        // Create a dataset using native api\n-        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        createDatasetResponse.prettyPrint();\n-        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n-\n-        // Get the metadata with the semantic api\n-        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-        // Compare the metadata with an expected value - the metadatablock entries\n-        // should be the same but there will be additional fields with values related to\n-        // the dataset's creation (e.g. new id)\n-        String jsonLDString = getData(response.getBody().asString());\n-        JsonObject jo = null;\n-        try {\n-            jo = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        } catch (NoSuchMethodError e) {\n-            logger.info(ExceptionUtils.getStackTrace(e));\n-        }\n-        \n-\n-        String expectedJsonLD = UtilIT.getDatasetJson(\"scripts/search/tests/data/dataset-finch1.jsonld\");\n-        jo = Json.createObjectBuilder(jo).remove(\"@id\").remove(\"http://schema.org/dateModified\").build();\n-        String jsonLD = jo.toString();\n-\n-        // ToDo: Are the static pars as expected\n-        JSONAssert.assertEquals(expectedJsonLD, jsonLD, false);\n-        // Now change the title\n-        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken,\n-                \"{\\\"Title\\\": \\\"New Title\\\", \\\"@context\\\":{\\\"Title\\\": \\\"http://purl.org/dc/terms/title\\\"}}\", true);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        // Check that the semantic api returns the new title\n-        jsonLDString = getData(response.getBody().asString());\n-        JsonObject jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        assertEquals(\"New Title\", jsonLDObject.getString(\"http://purl.org/dc/terms/title\"));\n-\n-        // Add an additional description (which is multi-valued and compound)\n-        // Also add new terms of use (single value so would fail with replace false if a\n-        // value existed)\n-        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\", \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"} \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n-        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        // Look for a second description\n-        jsonLDString = getData(response.getBody().asString());\n-        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        assertEquals(\"New description\",\n-                ((JsonObject) jsonLDObject.getJsonArray(\"https://dataverse.org/schema/citation/Description\").get(1))\n-                        .getString(\"https://dataverse.org/schema/citation/dsDescription#Text\"));\n-\n-        // Can't add terms of use with replace=false and a value already set (single\n-        // valued field)\n-        String badTerms = \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"Bad terms\\\"}}\";\n-        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, badTerms, false);\n-        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n-\n-        // Delete the terms of use\n-        response = UtilIT.deleteDatasetJsonLDMetadata(datasetId, apiToken,\n-                \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"}\");\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        // Verify that they're gone\n-        jsonLDString = getData(response.getBody().asString());\n-        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-        assertTrue(!jsonLDObject.containsKey(\"https://dataverse.org/schema/core#termsOfUse\"));\n-\n-        // Cleanup - delete dataset, dataverse, user...\n-        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n-        deleteDatasetResponse.prettyPrint();\n-        assertEquals(200, deleteDatasetResponse.getStatusCode());\n-\n-        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n-        deleteDataverseResponse.prettyPrint();\n-        assertEquals(200, deleteDataverseResponse.getStatusCode());\n-\n-        Response deleteUserResponse = UtilIT.deleteUser(username);\n-        deleteUserResponse.prettyPrint();\n-        assertEquals(200, deleteUserResponse.getStatusCode());\n-\n-    }\n \n-    @Test\n-    public void testReCreateDataset() {\n-\n-        Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-        Response makeSuperUser = UtilIT.makeSuperUser(username);\n-        assertEquals(200, makeSuperUser.getStatusCode());\n-\n-        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n-        createDataverseResponse.prettyPrint();\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n-\n-        // Create a dataset using native API\n-        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        createDatasetResponse.prettyPrint();\n-        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n-\n-        // Get the semantic metadata\n-        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        String expectedString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n-\n-        // Delete the dataset via native API\n-        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n-        deleteDatasetResponse.prettyPrint();\n-        assertEquals(200, deleteDatasetResponse.getStatusCode());\n-\n-        // Now use the migrate API to recreate the dataset\n-        // Now use the migrate API to recreate the dataset\n-        response = UtilIT.recreateDatasetJsonLD(apiToken, dataverseAlias, expectedString);\n-        String body = response.getBody().asString();\n-        response.then().assertThat().statusCode(CREATED.getStatusCode());\n-\n-        try (StringReader rdr = new StringReader(body)) {\n-            datasetId = Json.createReader(rdr).readObject().getJsonObject(\"data\").getInt(\"id\");\n-        }\n-        // Get the jsonLD metadata for what we recreated\n-        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n-\n-        String jsonLDString = getData(response.getBody().asString());\n-        JsonObject jsonLD = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n-\n-        JsonObject expectedJsonLD = JSONLDUtil.decontextualizeJsonLD(expectedString);\n-        expectedJsonLD = Json.createObjectBuilder(expectedJsonLD).remove(\"@id\").remove(\"http://schema.org/dateModified\")\n-                .build();\n-        // ToDo: Assert that the semantic api response is the same (everything in the\n-        // expected version is in the new one - deleting the @id and dateModified means\n-        // those won't be compared (with last param = false)\n-        JSONAssert.assertEquals(expectedJsonLD.toString(), jsonLD.toString(), false);\n-\n-        // Now cleanup\n-        deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n-        deleteDatasetResponse.prettyPrint();\n-        assertEquals(200, deleteDatasetResponse.getStatusCode());\n-\n-        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n-        deleteDataverseResponse.prettyPrint();\n-        assertEquals(200, deleteDataverseResponse.getStatusCode());\n-\n-        Response deleteUserResponse = UtilIT.deleteUser(username);\n-        deleteUserResponse.prettyPrint();\n-        assertEquals(200, deleteUserResponse.getStatusCode());\n-    }\n-\n-    private String getData(String body) {\n-        try (StringReader rdr = new StringReader(body)) {\n-            return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n-        }\n-    }\n }\n", "next_change": {"commit": "5557145719487de8ad148f3f742871cf5adb7644", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 956cce5eec..7698bc8b2b 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2164,4 +2168,111 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .body(\"message\", equalTo(\"You do not have permission to download this file.\"));\n     }\n \n+    @Test\n+    public void testSemanticMetadataAPIs() {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        // Create a dataset using native api\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n+\n+        // Get the metadata with the semantic api\n+        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+        // Compare the metadata with an expected value - the metadatablock entries\n+        // should be the same but there will be additional fields with values related to\n+        // the dataset's creation (e.g. new id)\n+        String jsonLDString = getData(response.getBody().asString());\n+        JsonObject jo = null;\n+        try {\n+            jo = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        } catch (NoSuchMethodError e) {\n+            logger.info(ExceptionUtils.getStackTrace(e));\n+        }\n+        \n+\n+        String expectedJsonLD = UtilIT.getDatasetJson(\"scripts/search/tests/data/dataset-finch1.jsonld\");\n+        jo = Json.createObjectBuilder(jo).remove(\"@id\").remove(\"http://schema.org/dateModified\").build();\n+        String jsonLD = jo.toString();\n+\n+        // ToDo: Are the static pars as expected\n+        JSONAssert.assertEquals(expectedJsonLD, jsonLD, false);\n+        // Now change the title\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken,\n+                \"{\\\"Title\\\": \\\"New Title\\\", \\\"@context\\\":{\\\"Title\\\": \\\"http://purl.org/dc/terms/title\\\"}}\", true);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        // Check that the semantic api returns the new title\n+        jsonLDString = getData(response.getBody().asString());\n+        JsonObject jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertEquals(\"New Title\", jsonLDObject.getString(\"http://purl.org/dc/terms/title\"));\n+\n+        // Add an additional description (which is multi-valued and compound)\n+        // Also add new terms of use (single value so would fail with replace false if a\n+        // value existed)\n+        String newDescription = \"{\\\"citation:Description\\\": {\\\"dsDescription:Text\\\": \\\"New description\\\"}, \\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\", \\\"@context\\\":{\\\"citation\\\": \\\"https://dataverse.org/schema/citation/\\\",\\\"dsDescription\\\": \\\"https://dataverse.org/schema/citation/dsDescription#\\\"}}\";\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, newDescription, false);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        // Look for a second description\n+        jsonLDString = getData(response.getBody().asString());\n+        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertEquals(\"New description\",\n+                ((JsonObject) jsonLDObject.getJsonArray(\"https://dataverse.org/schema/citation/Description\").get(1))\n+                        .getString(\"https://dataverse.org/schema/citation/dsDescription#Text\"));\n+\n+        // Can't add terms of use with replace=false and a value already set (single\n+        // valued field)\n+        String badTerms = \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"Bad terms\\\"}}\";\n+        response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken, badTerms, false);\n+        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+\n+        // Delete the terms of use\n+        response = UtilIT.deleteDatasetJsonLDMetadata(datasetId, apiToken,\n+                \"{\\\"https://dataverse.org/schema/core#termsOfUse\\\": \\\"New terms\\\"}\");\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        // Verify that they're gone\n+        jsonLDString = getData(response.getBody().asString());\n+        jsonLDObject = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+        assertTrue(!jsonLDObject.containsKey(\"https://dataverse.org/schema/core#termsOfUse\"));\n+\n+        // Cleanup - delete dataset, dataverse, user...\n+        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n+        deleteDatasetResponse.prettyPrint();\n+        assertEquals(200, deleteDatasetResponse.getStatusCode());\n+\n+        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n+        deleteDataverseResponse.prettyPrint();\n+        assertEquals(200, deleteDataverseResponse.getStatusCode());\n+\n+        Response deleteUserResponse = UtilIT.deleteUser(username);\n+        deleteUserResponse.prettyPrint();\n+        assertEquals(200, deleteUserResponse.getStatusCode());\n+\n+    }\n+\n+    private String getData(String body) {\n+        try (StringReader rdr = new StringReader(body)) {\n+            return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n+        }\n+    }\n+\n }\n", "next_change": {"commit": "30d131cfbd8fd99d8eda764e0ec6b82a61c1e354", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 7698bc8b2b..246eb0b250 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2269,10 +2269,77 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n \n     }\n \n+    @Test\n+    public void testReCreateDataset() {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+        assertEquals(200, makeSuperUser.getStatusCode());\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        // Create a dataset using native API\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n+\n+        // Get the semantic metadata\n+        Response response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        String expectedString = JsonPath.from(response.getBody().asString()).getString(\"data\");\n+\n+        // Delete the dataset via native API\n+        Response deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n+        deleteDatasetResponse.prettyPrint();\n+        assertEquals(200, deleteDatasetResponse.getStatusCode());\n+\n+        // Now use the migrate API to recreate the dataset\n+        // Now use the migrate API to recreate the dataset\n+        response = UtilIT.recreateDatasetJsonLD(apiToken, dataverseAlias, expectedString);\n+        String body = response.getBody().asString();\n+        response.then().assertThat().statusCode(CREATED.getStatusCode());\n+\n+        try (StringReader rdr = new StringReader(body)) {\n+            datasetId = Json.createReader(rdr).readObject().getJsonObject(\"data\").getInt(\"id\");\n+        }\n+        // Get the jsonLD metadata for what we recreated\n+        response = UtilIT.getDatasetJsonLDMetadata(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        String jsonLDString = getData(response.getBody().asString());\n+        JsonObject jsonLD = JSONLDUtil.decontextualizeJsonLD(jsonLDString);\n+\n+        JsonObject expectedJsonLD = JSONLDUtil.decontextualizeJsonLD(expectedString);\n+        expectedJsonLD = Json.createObjectBuilder(expectedJsonLD).remove(\"@id\").remove(\"http://schema.org/dateModified\")\n+                .build();\n+        // ToDo: Assert that the semantic api response is the same (everything in the\n+        // expected version is in the new one - deleting the @id and dateModified means\n+        // those won't be compared (with last param = false)\n+        JSONAssert.assertEquals(expectedJsonLD.toString(), jsonLD.toString(), false);\n+\n+        // Now cleanup\n+        deleteDatasetResponse = UtilIT.deleteDatasetViaNativeApi(datasetId, apiToken);\n+        deleteDatasetResponse.prettyPrint();\n+        assertEquals(200, deleteDatasetResponse.getStatusCode());\n+\n+        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n+        deleteDataverseResponse.prettyPrint();\n+        assertEquals(200, deleteDataverseResponse.getStatusCode());\n+\n+        Response deleteUserResponse = UtilIT.deleteUser(username);\n+        deleteUserResponse.prettyPrint();\n+        assertEquals(200, deleteUserResponse.getStatusCode());\n+    }\n+\n     private String getData(String body) {\n         try (StringReader rdr = new StringReader(body)) {\n             return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n         }\n     }\n-\n }\n", "next_change": {"commit": "38b8baa6c3b0f5d3878037c506d6f055380385a0", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 246eb0b250..948e4213df 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2337,6 +2371,59 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         assertEquals(200, deleteUserResponse.getStatusCode());\n     }\n \n+    @Test\n+    public void testCurationLabelAPIs() {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        SystemConfig systemConfig = Mockito.mock(SystemConfig.class);\n+        Map<String, String[]> labelSets = new HashMap<String, String[]>();\n+        labelSets.put(\"StandardProcess\", new String[] { \"Author contacted\", \"Privacy Review\", \"Awaiting paper publication\", \"Final Approval\"});\n+        labelSets.put(\"AlternateProcess\", new String[] {\"State 1\",\"State 2\",\"State 3\"});\n+        Mockito.when(systemConfig.getCurationLabels()).thenReturn(labelSets);\n+\n+        //Set curation label set on dataverse\n+        //Valid option, bad user\n+        Response setDataverseCurationLabelSetResponse = UtilIT.setDataverseCurationLabelSet(dataverseAlias, apiToken, \"AlternateProcess\");\n+        setDataverseCurationLabelSetResponse.then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n+        \n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+        assertEquals(200, makeSuperUser.getStatusCode());\n+\n+        //Non-existent option\n+        setDataverseCurationLabelSetResponse = UtilIT.setDataverseCurationLabelSet(dataverseAlias, apiToken, \"OddProcess\");\n+        setDataverseCurationLabelSetResponse.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        //Valid option, bad user\n+        setDataverseCurationLabelSetResponse = UtilIT.setDataverseCurationLabelSet(dataverseAlias, apiToken, \"AlternateProcess\");\n+        setDataverseCurationLabelSetResponse.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        \n+        // Create a dataset using native api\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDatasetResponse);\n+        // Get the curation label set in use\n+        Response response = UtilIT.getDatasetCurationLabelSet(datasetId, apiToken);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+        //Verify that the set name is what was set on the dataverse\n+        String labelSetName = getData(response.getBody().asString());\n+        assertEquals(\"AlternateProcess\", labelSetName);\n+        \n+        // Now set a label\n+        //Option from the wrong set\n+        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n+        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        // Valid option\n+        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+    }\n+\n     private String getData(String body) {\n         try (StringReader rdr = new StringReader(body)) {\n             return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n", "next_change": {"commit": "00878562c26d8f4efa17e05a1c050b82108a916e", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 948e4213df..60a231d770 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2417,11 +2417,11 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n         // Now set a label\n         //Option from the wrong set\n-        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n-        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        Response response2 = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n+        response2.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n         // Valid option\n-        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n+        Response response3 = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n+        response3.then().assertThat().statusCode(OK.getStatusCode());\n     }\n \n     private String getData(String body) {\n", "next_change": {"commit": "1a4e4f9808e003d9032b17018f20200e71a6fb57", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 60a231d770..be5efbdcbb 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2417,11 +2418,11 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n         // Now set a label\n         //Option from the wrong set\n-        Response response2 = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n-        response2.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n+        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n         // Valid option\n-        Response response3 = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n-        response3.then().assertThat().statusCode(OK.getStatusCode());\n+        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n     }\n \n     private String getData(String body) {\n", "next_change": {"commit": "c0d06a5d344b0d572d30bfbc2a22db155d3e25bd", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex be5efbdcbb..c08a71eea6 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2414,15 +2413,16 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         response.then().assertThat().statusCode(OK.getStatusCode());\n         //Verify that the set name is what was set on the dataverse\n         String labelSetName = getData(response.getBody().asString());\n-        assertEquals(\"AlternateProcess\", labelSetName);\n+        // full should be {\"message\":\"AlternateProcess\"}\n+        assertTrue(labelSetName.contains(\"AlternateProcess\"));\n         \n         // Now set a label\n         //Option from the wrong set\n-        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n-        response.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        Response response2 = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"Author contacted\");\n+        response2.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n         // Valid option\n-        response = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n-        response.then().assertThat().statusCode(OK.getStatusCode());\n+        Response response3 = UtilIT.setDatasetCurationLabel(datasetId, apiToken, \"State 1\");\n+        response3.then().assertThat().statusCode(OK.getStatusCode());\n     }\n \n     private String getData(String body) {\n", "next_change": null}]}}, {"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 60a231d770..be5efbdcbb 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2429,4 +2430,67 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n             return Json.createReader(rdr).readObject().getJsonObject(\"data\").toString();\n         }\n     }\n+\n+    @Test\n+    public void testFilesUnchangedAfterDatasetMetadataUpdate() throws IOException {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        createUser.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n+\n+        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n+        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n+\n+        JsonObjectBuilder json1 = Json.createObjectBuilder()\n+                .add(\"description\", \"A script to reproduce results.\")\n+                .add(\"directoryLabel\", \"code\");\n+\n+        Response uploadReadme1 = UtilIT.uploadFileViaNative(datasetId.toString(), pathtoScript.toString(), json1.build(), apiToken);\n+        uploadReadme1.prettyPrint();\n+        uploadReadme1.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.files[0].label\", equalTo(\"run.sh\"))\n+                .body(\"data.files[0].directoryLabel\", equalTo(\"code\"));\n+\n+        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonBeforeUpdate.prettyPrint();\n+        getDatasetJsonBeforeUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"run.sh\"))\n+                .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n+        \n+        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n+        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n+        updateTitle.prettyPrint();\n+        updateTitle.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonAfterUpdate.prettyPrint();\n+        getDatasetJsonAfterUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"run.sh\"))\n+                .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n+        \n+    }\n+    \n }\n", "next_change": {"commit": "96389dfe022e554394eda8107838c82799066cc3", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex be5efbdcbb..985d0c38f2 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2493,4 +2584,78 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n+    @Test\n+    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        createUser.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        \n+        \n+        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n+\n+        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n+        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n+\n+        JsonObjectBuilder json1 = Json.createObjectBuilder()\n+                .add(\"description\", \"A script to reproduce results.\")\n+                .add(\"directoryLabel\", \"code\");\n+\n+        Response uploadReadme1 = UtilIT.uploadFileViaNative(datasetId.toString(), pathtoScript.toString(), json1.build(), apiToken);\n+        uploadReadme1.prettyPrint();\n+        uploadReadme1.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.files[0].label\", equalTo(\"run.sh\"))\n+                .body(\"data.files[0].directoryLabel\", equalTo(\"code\"));\n+\n+        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonBeforeUpdate.prettyPrint();\n+        getDatasetJsonBeforeUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"run.sh\"))\n+                .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n+        \n+        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n+        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n+        updateTitle.prettyPrint();\n+        updateTitle.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+        // shouldn't be able to update current unless you're a super user\n+\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n+        \n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+                \n+        //should work after making super user\n+        \n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        \n+        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonAfterUpdate.prettyPrint();\n+        getDatasetJsonAfterUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"run.sh\"))\n+                .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n+        \n+    }\n+    \n }\n", "next_change": {"commit": "74c5a0316f52568546b61be95498bf0fa7bfb611", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 985d0c38f2..a64740fe3f 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2584,78 +2587,4 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n-    @Test\n-    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n-        Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        createUser.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        \n-        \n-        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n-        createDataverse.prettyPrint();\n-        createDataverse.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n-\n-        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        createDataset.prettyPrint();\n-        createDataset.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n-        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n-\n-        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n-        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n-\n-        JsonObjectBuilder json1 = Json.createObjectBuilder()\n-                .add(\"description\", \"A script to reproduce results.\")\n-                .add(\"directoryLabel\", \"code\");\n-\n-        Response uploadReadme1 = UtilIT.uploadFileViaNative(datasetId.toString(), pathtoScript.toString(), json1.build(), apiToken);\n-        uploadReadme1.prettyPrint();\n-        uploadReadme1.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.files[0].label\", equalTo(\"run.sh\"))\n-                .body(\"data.files[0].directoryLabel\", equalTo(\"code\"));\n-\n-        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-\n-        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n-        getDatasetJsonBeforeUpdate.prettyPrint();\n-        getDatasetJsonBeforeUpdate.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.latestVersion.files[0].label\", equalTo(\"run.sh\"))\n-                .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n-        \n-        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n-        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n-        updateTitle.prettyPrint();\n-        updateTitle.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        \n-        // shouldn't be able to update current unless you're a super user\n-\n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n-        \n-        Response makeSuperUser = UtilIT.makeSuperUser(username);\n-                \n-        //should work after making super user\n-        \n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-        \n-        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n-        getDatasetJsonAfterUpdate.prettyPrint();\n-        getDatasetJsonAfterUpdate.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.latestVersion.files[0].label\", equalTo(\"run.sh\"))\n-                .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n-        \n-    }\n-    \n }\n", "next_change": {"commit": "57813947aa310c8d85d03ec45abf926b3c230d5f", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex a64740fe3f..96354c37cc 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2587,4 +2584,69 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n+    /**\n+     * In this test we are restricting a file and testing that terms of accees\n+     * or request access is required\n+     *\n+     * Export at the dataset level is always the public version.\n+     *\n+     */\n+    @Test\n+    public void testRestrictFileTermsOfUseAndAccess() throws IOException {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String authorUsername = UtilIT.getUsernameFromResponse(createUser);\n+        String authorApiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverse = UtilIT.createRandomDataverse(authorApiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, authorApiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDataset);\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+\n+        Path pathToFile = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"data.csv\");\n+        String contentOfCsv = \"\"\n+                + \"name,pounds,species\\n\"\n+                + \"Marshall,40,dog\\n\"\n+                + \"Tiger,17,cat\\n\"\n+                + \"Panther,21,cat\\n\";\n+        java.nio.file.Files.write(pathToFile, contentOfCsv.getBytes());\n+\n+        Response uploadFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFile.toString(), authorApiToken);\n+        uploadFile.prettyPrint();\n+        uploadFile.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.files[0].label\", equalTo(\"data.csv\"));\n+\n+        String fileId = JsonPath.from(uploadFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+\n+        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFile, UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", authorApiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+\n+        Response restrictFile = UtilIT.restrictFile(fileId, true, authorApiToken);\n+        restrictFile.prettyPrint();\n+        restrictFile.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response publishDataverse = UtilIT.publishDataverseViaNativeApi(dataverseAlias, authorApiToken);\n+        publishDataverse.then().assertThat().statusCode(OK.getStatusCode());\n+        Response publishDataset = UtilIT.publishDatasetViaNativeApi(datasetPid, \"major\", authorApiToken);\n+        publishDataset.then().assertThat().statusCode(OK.getStatusCode());\n+        \n+        \n+        //not allowed to remove request access if there are retricted files\n+        \n+        Response disallowRequestAccess = UtilIT.allowAccessRequests(datasetPid, false, authorApiToken);\n+        disallowRequestAccess.prettyPrint();\n+        disallowRequestAccess.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        \n+    }\n+    \n }\n", "next_change": {"commit": "e504bfcc134083699d252bc8d33eadb41625209d", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 96354c37cc..b794069fba 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2583,70 +2583,47 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n         \n     }\n-    \n-    /**\n-     * In this test we are restricting a file and testing that terms of accees\n-     * or request access is required\n-     *\n-     * Export at the dataset level is always the public version.\n-     *\n-     */\n+\n     @Test\n-    public void testRestrictFileTermsOfUseAndAccess() throws IOException {\n+    public void testAddFileToDatasetTabIngest() throws IOException, InterruptedException {\n \n         Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        String authorUsername = UtilIT.getUsernameFromResponse(createUser);\n-        String authorApiToken = UtilIT.getApiTokenFromResponse(createUser);\n-\n-        Response createDataverse = UtilIT.createRandomDataverse(authorApiToken);\n-        createDataverse.prettyPrint();\n-        createDataverse.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n-\n-        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, authorApiToken);\n-        createDataset.prettyPrint();\n-        createDataset.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDataset);\n-        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n-\n-        Path pathToFile = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"data.csv\");\n-        String contentOfCsv = \"\"\n-                + \"name,pounds,species\\n\"\n-                + \"Marshall,40,dog\\n\"\n-                + \"Tiger,17,cat\\n\"\n-                + \"Panther,21,cat\\n\";\n-        java.nio.file.Files.write(pathToFile, contentOfCsv.getBytes());\n+        assertEquals(200, createUser.getStatusCode());\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n \n-        Response uploadFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFile.toString(), authorApiToken);\n-        uploadFile.prettyPrint();\n-        uploadFile.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.files[0].label\", equalTo(\"data.csv\"));\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        assertEquals(201, createDataverseResponse.getStatusCode());\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n \n-        String fileId = JsonPath.from(uploadFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        assertEquals(201, createDatasetResponse.getStatusCode());\n+        Integer datasetIdInt = JsonPath.from(createDatasetResponse.body().asString()).getInt(\"data.id\");\n+\n+        String pathToFile = \"src/test/resources/sav/dct.sav\";\n+        String jsonAsString = \"{\\\"description\\\":\\\"My description.\\\",\\\"directoryLabel\\\":\\\"data/subdir1\\\",\\\"categories\\\":[\\\"Data\\\"], \\\"restrict\\\":\\\"false\\\"}\";\n+        Response r = UtilIT.uploadFileViaNative(datasetIdInt.toString(), pathToFile, jsonAsString, apiToken, true);\n+        logger.info(r.prettyPrint());\n+        assertEquals(200, r.getStatusCode());\n+\n+        Thread.sleep(500);\n+        pathToFile = \"src/test/resources/sav/frequency-test.sav\";\n+        Response rTabIngest = UtilIT.uploadFileViaNative(datasetIdInt.toString(), pathToFile, jsonAsString, apiToken, false);\n+        logger.info(rTabIngest.prettyPrint());\n+        assertEquals(200, rTabIngest.getStatusCode());\n+\n+        //cleanup\n+        Thread.sleep(500);\n+        Response destroyDatasetResponse = UtilIT.destroyDataset(datasetIdInt, apiToken);\n+        assertEquals(200, destroyDatasetResponse.getStatusCode());\n \n-        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFile, UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", authorApiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n+        assertEquals(200, deleteDataverseResponse.getStatusCode());\n \n-        Response restrictFile = UtilIT.restrictFile(fileId, true, authorApiToken);\n-        restrictFile.prettyPrint();\n-        restrictFile.then().assertThat().statusCode(OK.getStatusCode());\n+        Response deleteUserResponse = UtilIT.deleteUser(username);\n+        assertEquals(200, deleteUserResponse.getStatusCode());\n \n-        Response publishDataverse = UtilIT.publishDataverseViaNativeApi(dataverseAlias, authorApiToken);\n-        publishDataverse.then().assertThat().statusCode(OK.getStatusCode());\n-        Response publishDataset = UtilIT.publishDatasetViaNativeApi(datasetPid, \"major\", authorApiToken);\n-        publishDataset.then().assertThat().statusCode(OK.getStatusCode());\n-        \n-        \n-        //not allowed to remove request access if there are retricted files\n-        \n-        Response disallowRequestAccess = UtilIT.allowAccessRequests(datasetPid, false, authorApiToken);\n-        disallowRequestAccess.prettyPrint();\n-        disallowRequestAccess.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n-        \n     }\n+\n     \n }\n", "next_change": {"commit": "2163fdc29edf57cb62005071c11cbe249c233a41", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex b794069fba..bedc486657 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2584,46 +2584,6 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n \n-    @Test\n-    public void testAddFileToDatasetTabIngest() throws IOException, InterruptedException {\n-\n-        Response createUser = UtilIT.createRandomUser();\n-        assertEquals(200, createUser.getStatusCode());\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-\n-        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n-        assertEquals(201, createDataverseResponse.getStatusCode());\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n-\n-        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        assertEquals(201, createDatasetResponse.getStatusCode());\n-        Integer datasetIdInt = JsonPath.from(createDatasetResponse.body().asString()).getInt(\"data.id\");\n-\n-        String pathToFile = \"src/test/resources/sav/dct.sav\";\n-        String jsonAsString = \"{\\\"description\\\":\\\"My description.\\\",\\\"directoryLabel\\\":\\\"data/subdir1\\\",\\\"categories\\\":[\\\"Data\\\"], \\\"restrict\\\":\\\"false\\\"}\";\n-        Response r = UtilIT.uploadFileViaNative(datasetIdInt.toString(), pathToFile, jsonAsString, apiToken, true);\n-        logger.info(r.prettyPrint());\n-        assertEquals(200, r.getStatusCode());\n-\n-        Thread.sleep(500);\n-        pathToFile = \"src/test/resources/sav/frequency-test.sav\";\n-        Response rTabIngest = UtilIT.uploadFileViaNative(datasetIdInt.toString(), pathToFile, jsonAsString, apiToken, false);\n-        logger.info(rTabIngest.prettyPrint());\n-        assertEquals(200, rTabIngest.getStatusCode());\n-\n-        //cleanup\n-        Thread.sleep(500);\n-        Response destroyDatasetResponse = UtilIT.destroyDataset(datasetIdInt, apiToken);\n-        assertEquals(200, destroyDatasetResponse.getStatusCode());\n-\n-        Response deleteDataverseResponse = UtilIT.deleteDataverse(dataverseAlias, apiToken);\n-        assertEquals(200, deleteDataverseResponse.getStatusCode());\n-\n-        Response deleteUserResponse = UtilIT.deleteUser(username);\n-        assertEquals(200, deleteUserResponse.getStatusCode());\n-\n-    }\n \n     \n }\n", "next_change": {"commit": "e7a232b0d7db8fab0c597aa28ef3a5b7bd9da394", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex bedc486657..0e1ae91eef 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2583,7 +2593,151 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n         \n     }\n+    \n+    @Test\n+    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        createUser.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        \n+        \n+        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n+\n+        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n+        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n+\n+        JsonObjectBuilder json1 = Json.createObjectBuilder()\n+                .add(\"description\", \"A script to reproduce results.\")\n+                .add(\"directoryLabel\", \"code\");\n+\n+        \n+        \n+\n+        String pathToFileThatGoesThroughIngest = \"src/test/resources/sav/dct.sav\";\n+        Response uploadIngestableFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFileThatGoesThroughIngest, apiToken);\n+        uploadIngestableFile.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        uploadIngestableFile.prettyPrint();\n+\n+        String origFileId = JsonPath.from(uploadIngestableFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+\n+        System.out.println(\"Orig file id \" + origFileId);\n+\n+        logger.fine(\"Orig file id: \" + origFileId);\n+        assertNotNull(origFileId);\n+        assertNotEquals(\"\",origFileId);\n+\n+        // Give file time to ingest\n+        \n+        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFileThatGoesThroughIngest , UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", apiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+        \n+        Response origXml = UtilIT.getFileMetadata(origFileId, null, apiToken);\n+        assertEquals(200, origXml.getStatusCode());\n \n \n+        String stringOrigXml = origXml.getBody().prettyPrint();\n+\n+        InputStream variableData = origXml.body().asInputStream();\n+\n+        Map<Long, VariableMetadata> mapVarToVarMet = new HashMap<Long, VariableMetadata>();\n+        Map<Long,VarGroup> varGroupMap = new HashMap<Long, VarGroup>();\n+        try {\n+            XMLInputFactory factory = XMLInputFactory.newInstance();\n+            XMLStreamReader xmlr = factory.createXMLStreamReader(variableData);\n+            VariableMetadataDDIParser vmdp = new VariableMetadataDDIParser();\n+\n+            vmdp.processDataDscr(xmlr, mapVarToVarMet, varGroupMap);\n+\n+        } catch (XMLStreamException e) {\n+            logger.warning(e.getMessage());\n+            assertEquals(0,1);\n+        }\n+\n+\n+        //Test here\n+        String updatedContent = \"\";\n+        try {\n+            updatedContent = new String(Files.readAllBytes(Paths.get(\"src/test/resources/xml/dct.xml\")));\n+        } catch (IOException e) {\n+            logger.warning(e.getMessage());\n+            assertEquals(0,1);\n+        }\n+        Long replV1168 = 0L;\n+        Long replV1169 = 0L;\n+        Long replV1170 = 0L;\n+        int numberVariables = 0;\n+        for (VariableMetadata var : mapVarToVarMet.values()) {\n+            if (var.getLabel().equals(\"gender\")) {\n+                replV1170 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            } else if (var.getLabel().equals(\"weight\")) {\n+                replV1168 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            } else if (var.getLabel().equals(\"age_rollup\")) {\n+                replV1169 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            }\n+        }\n+        assertEquals(3, numberVariables);\n+\n+        updatedContent = updatedContent.replaceAll(\"v1168\", \"v\" + replV1168 );\n+        updatedContent = updatedContent.replaceAll(\"v1169\", \"v\" + replV1169 );\n+        updatedContent = updatedContent.replaceAll(\"v1170\", \"v\" + replV1170 );\n+\n+        //edit draft vesrsion\n+        Response editDDIResponse = UtilIT.editDDI(updatedContent, origFileId, apiToken);\n+\n+        editDDIResponse.prettyPrint();\n+        assertEquals(200, editDDIResponse.getStatusCode());\n+\n+\n+\n+        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonBeforeUpdate.prettyPrint();\n+        getDatasetJsonBeforeUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"dct.tab\"));\n+        \n+        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n+        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n+        updateTitle.prettyPrint();\n+        updateTitle.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+        // shouldn't be able to update current unless you're a super user\n+\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n+        \n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+                \n+        //should work after making super user\n+        \n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        \n+        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonAfterUpdate.prettyPrint();\n+        getDatasetJsonAfterUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+    }\n     \n }\n", "next_change": {"commit": "b6376dacedb9bc20440cc776c3b8791cdc68ef37", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 0e1ae91eef..a6b5bb7c6a 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2594,150 +2584,4 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n-    @Test\n-    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n-        Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        createUser.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        \n-        \n-        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n-        createDataverse.prettyPrint();\n-        createDataverse.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n-\n-        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        createDataset.prettyPrint();\n-        createDataset.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n-        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n-\n-        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n-        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n-\n-        JsonObjectBuilder json1 = Json.createObjectBuilder()\n-                .add(\"description\", \"A script to reproduce results.\")\n-                .add(\"directoryLabel\", \"code\");\n-\n-        \n-        \n-\n-        String pathToFileThatGoesThroughIngest = \"src/test/resources/sav/dct.sav\";\n-        Response uploadIngestableFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFileThatGoesThroughIngest, apiToken);\n-        uploadIngestableFile.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        uploadIngestableFile.prettyPrint();\n-\n-        String origFileId = JsonPath.from(uploadIngestableFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n-\n-        System.out.println(\"Orig file id \" + origFileId);\n-\n-        logger.fine(\"Orig file id: \" + origFileId);\n-        assertNotNull(origFileId);\n-        assertNotEquals(\"\",origFileId);\n-\n-        // Give file time to ingest\n-        \n-        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFileThatGoesThroughIngest , UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", apiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n-        \n-        Response origXml = UtilIT.getFileMetadata(origFileId, null, apiToken);\n-        assertEquals(200, origXml.getStatusCode());\n-\n-\n-        String stringOrigXml = origXml.getBody().prettyPrint();\n-\n-        InputStream variableData = origXml.body().asInputStream();\n-\n-        Map<Long, VariableMetadata> mapVarToVarMet = new HashMap<Long, VariableMetadata>();\n-        Map<Long,VarGroup> varGroupMap = new HashMap<Long, VarGroup>();\n-        try {\n-            XMLInputFactory factory = XMLInputFactory.newInstance();\n-            XMLStreamReader xmlr = factory.createXMLStreamReader(variableData);\n-            VariableMetadataDDIParser vmdp = new VariableMetadataDDIParser();\n-\n-            vmdp.processDataDscr(xmlr, mapVarToVarMet, varGroupMap);\n-\n-        } catch (XMLStreamException e) {\n-            logger.warning(e.getMessage());\n-            assertEquals(0,1);\n-        }\n-\n-\n-        //Test here\n-        String updatedContent = \"\";\n-        try {\n-            updatedContent = new String(Files.readAllBytes(Paths.get(\"src/test/resources/xml/dct.xml\")));\n-        } catch (IOException e) {\n-            logger.warning(e.getMessage());\n-            assertEquals(0,1);\n-        }\n-        Long replV1168 = 0L;\n-        Long replV1169 = 0L;\n-        Long replV1170 = 0L;\n-        int numberVariables = 0;\n-        for (VariableMetadata var : mapVarToVarMet.values()) {\n-            if (var.getLabel().equals(\"gender\")) {\n-                replV1170 = var.getDataVariable().getId();\n-                numberVariables = numberVariables +1;\n-            } else if (var.getLabel().equals(\"weight\")) {\n-                replV1168 = var.getDataVariable().getId();\n-                numberVariables = numberVariables +1;\n-            } else if (var.getLabel().equals(\"age_rollup\")) {\n-                replV1169 = var.getDataVariable().getId();\n-                numberVariables = numberVariables +1;\n-            }\n-        }\n-        assertEquals(3, numberVariables);\n-\n-        updatedContent = updatedContent.replaceAll(\"v1168\", \"v\" + replV1168 );\n-        updatedContent = updatedContent.replaceAll(\"v1169\", \"v\" + replV1169 );\n-        updatedContent = updatedContent.replaceAll(\"v1170\", \"v\" + replV1170 );\n-\n-        //edit draft vesrsion\n-        Response editDDIResponse = UtilIT.editDDI(updatedContent, origFileId, apiToken);\n-\n-        editDDIResponse.prettyPrint();\n-        assertEquals(200, editDDIResponse.getStatusCode());\n-\n-\n-\n-        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-\n-        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n-        getDatasetJsonBeforeUpdate.prettyPrint();\n-        getDatasetJsonBeforeUpdate.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.latestVersion.files[0].label\", equalTo(\"dct.tab\"));\n-        \n-        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n-        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n-        updateTitle.prettyPrint();\n-        updateTitle.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        \n-        // shouldn't be able to update current unless you're a super user\n-\n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n-        \n-        Response makeSuperUser = UtilIT.makeSuperUser(username);\n-                \n-        //should work after making super user\n-        \n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-        \n-        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n-        getDatasetJsonAfterUpdate.prettyPrint();\n-        getDatasetJsonAfterUpdate.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        \n-    }\n-    \n }\n", "next_change": {"commit": "28f7c6ea067f1e5697bf1dd80bb5b8021bc962c9", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex a6b5bb7c6a..611985acb1 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2584,4 +2587,69 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n+    /**\n+     * In this test we are restricting a file and testing that terms of accees\n+     * or request access is required\n+     *\n+     * Export at the dataset level is always the public version.\n+     *\n+     */\n+    @Test\n+    public void testRestrictFileTermsOfUseAndAccess() throws IOException {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String authorUsername = UtilIT.getUsernameFromResponse(createUser);\n+        String authorApiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverse = UtilIT.createRandomDataverse(authorApiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, authorApiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDataset);\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+\n+        Path pathToFile = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"data.csv\");\n+        String contentOfCsv = \"\"\n+                + \"name,pounds,species\\n\"\n+                + \"Marshall,40,dog\\n\"\n+                + \"Tiger,17,cat\\n\"\n+                + \"Panther,21,cat\\n\";\n+        java.nio.file.Files.write(pathToFile, contentOfCsv.getBytes());\n+\n+        Response uploadFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFile.toString(), authorApiToken);\n+        uploadFile.prettyPrint();\n+        uploadFile.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.files[0].label\", equalTo(\"data.csv\"));\n+\n+        String fileId = JsonPath.from(uploadFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+\n+        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFile, UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", authorApiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+\n+        Response restrictFile = UtilIT.restrictFile(fileId, true, authorApiToken);\n+        restrictFile.prettyPrint();\n+        restrictFile.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response publishDataverse = UtilIT.publishDataverseViaNativeApi(dataverseAlias, authorApiToken);\n+        publishDataverse.then().assertThat().statusCode(OK.getStatusCode());\n+        Response publishDataset = UtilIT.publishDatasetViaNativeApi(datasetPid, \"major\", authorApiToken);\n+        publishDataset.then().assertThat().statusCode(OK.getStatusCode());\n+        \n+        \n+        //not allowed to remove request access if there are retricted files\n+        \n+        Response disallowRequestAccess = UtilIT.allowAccessRequests(datasetPid, false, authorApiToken);\n+        disallowRequestAccess.prettyPrint();\n+        disallowRequestAccess.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        \n+    }\n+    \n }\n", "next_change": {"commit": "05a06eb764b20c88f816fec9fd119da808cfb9b9", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 611985acb1..df88b24ab6 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2587,68 +2597,149 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n-    /**\n-     * In this test we are restricting a file and testing that terms of accees\n-     * or request access is required\n-     *\n-     * Export at the dataset level is always the public version.\n-     *\n-     */\n     @Test\n-    public void testRestrictFileTermsOfUseAndAccess() throws IOException {\n-\n+    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n         Response createUser = UtilIT.createRandomUser();\n         createUser.prettyPrint();\n-        String authorUsername = UtilIT.getUsernameFromResponse(createUser);\n-        String authorApiToken = UtilIT.getApiTokenFromResponse(createUser);\n-\n-        Response createDataverse = UtilIT.createRandomDataverse(authorApiToken);\n+        createUser.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        \n+        \n+        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n         createDataverse.prettyPrint();\n         createDataverse.then().assertThat()\n                 .statusCode(CREATED.getStatusCode());\n+\n         String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n \n-        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, authorApiToken);\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n         createDataset.prettyPrint();\n         createDataset.then().assertThat()\n                 .statusCode(CREATED.getStatusCode());\n \n-        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDataset);\n         String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n \n-        Path pathToFile = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"data.csv\");\n-        String contentOfCsv = \"\"\n-                + \"name,pounds,species\\n\"\n-                + \"Marshall,40,dog\\n\"\n-                + \"Tiger,17,cat\\n\"\n-                + \"Panther,21,cat\\n\";\n-        java.nio.file.Files.write(pathToFile, contentOfCsv.getBytes());\n+        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n+        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n \n-        Response uploadFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFile.toString(), authorApiToken);\n-        uploadFile.prettyPrint();\n-        uploadFile.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.files[0].label\", equalTo(\"data.csv\"));\n+        JsonObjectBuilder json1 = Json.createObjectBuilder()\n+                .add(\"description\", \"A script to reproduce results.\")\n+                .add(\"directoryLabel\", \"code\");\n \n-        String fileId = JsonPath.from(uploadFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+        \n+        \n \n-        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFile, UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", authorApiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+        String pathToFileThatGoesThroughIngest = \"src/test/resources/sav/dct.sav\";\n+        Response uploadIngestableFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFileThatGoesThroughIngest, apiToken);\n+        uploadIngestableFile.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        uploadIngestableFile.prettyPrint();\n \n-        Response restrictFile = UtilIT.restrictFile(fileId, true, authorApiToken);\n-        restrictFile.prettyPrint();\n-        restrictFile.then().assertThat().statusCode(OK.getStatusCode());\n+        String origFileId = JsonPath.from(uploadIngestableFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n \n-        Response publishDataverse = UtilIT.publishDataverseViaNativeApi(dataverseAlias, authorApiToken);\n-        publishDataverse.then().assertThat().statusCode(OK.getStatusCode());\n-        Response publishDataset = UtilIT.publishDatasetViaNativeApi(datasetPid, \"major\", authorApiToken);\n-        publishDataset.then().assertThat().statusCode(OK.getStatusCode());\n+        System.out.println(\"Orig file id \" + origFileId);\n+\n+        logger.fine(\"Orig file id: \" + origFileId);\n+        assertNotNull(origFileId);\n+        assertNotEquals(\"\",origFileId);\n+\n+        // Give file time to ingest\n         \n+        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFileThatGoesThroughIngest , UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", apiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n         \n-        //not allowed to remove request access if there are retricted files\n+        Response origXml = UtilIT.getFileMetadata(origFileId, null, apiToken);\n+        assertEquals(200, origXml.getStatusCode());\n+\n+\n+        String stringOrigXml = origXml.getBody().prettyPrint();\n+\n+        InputStream variableData = origXml.body().asInputStream();\n+\n+        Map<Long, VariableMetadata> mapVarToVarMet = new HashMap<Long, VariableMetadata>();\n+        Map<Long,VarGroup> varGroupMap = new HashMap<Long, VarGroup>();\n+        try {\n+            XMLInputFactory factory = XMLInputFactory.newInstance();\n+            XMLStreamReader xmlr = factory.createXMLStreamReader(variableData);\n+            VariableMetadataDDIParser vmdp = new VariableMetadataDDIParser();\n+\n+            vmdp.processDataDscr(xmlr, mapVarToVarMet, varGroupMap);\n+\n+        } catch (XMLStreamException e) {\n+            logger.warning(e.getMessage());\n+            assertEquals(0,1);\n+        }\n+\n+\n+        //Test here\n+        String updatedContent = \"\";\n+        try {\n+            updatedContent = new String(Files.readAllBytes(Paths.get(\"src/test/resources/xml/dct.xml\")));\n+        } catch (IOException e) {\n+            logger.warning(e.getMessage());\n+            assertEquals(0,1);\n+        }\n+        Long replV1168 = 0L;\n+        Long replV1169 = 0L;\n+        Long replV1170 = 0L;\n+        int numberVariables = 0;\n+        for (VariableMetadata var : mapVarToVarMet.values()) {\n+            if (var.getLabel().equals(\"gender\")) {\n+                replV1170 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            } else if (var.getLabel().equals(\"weight\")) {\n+                replV1168 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            } else if (var.getLabel().equals(\"age_rollup\")) {\n+                replV1169 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            }\n+        }\n+        assertEquals(3, numberVariables);\n+\n+        updatedContent = updatedContent.replaceAll(\"v1168\", \"v\" + replV1168 );\n+        updatedContent = updatedContent.replaceAll(\"v1169\", \"v\" + replV1169 );\n+        updatedContent = updatedContent.replaceAll(\"v1170\", \"v\" + replV1170 );\n+\n+        //edit draft vesrsion\n+        Response editDDIResponse = UtilIT.editDDI(updatedContent, origFileId, apiToken);\n+\n+        editDDIResponse.prettyPrint();\n+        assertEquals(200, editDDIResponse.getStatusCode());\n+\n+\n+\n+        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonBeforeUpdate.prettyPrint();\n+        getDatasetJsonBeforeUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"dct.tab\"));\n+        \n+        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n+        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n+        updateTitle.prettyPrint();\n+        updateTitle.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+        // shouldn't be able to update current unless you're a super user\n+\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n+        \n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+                \n+        //should work after making super user\n+        \n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n         \n-        Response disallowRequestAccess = UtilIT.allowAccessRequests(datasetPid, false, authorApiToken);\n-        disallowRequestAccess.prettyPrint();\n-        disallowRequestAccess.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonAfterUpdate.prettyPrint();\n+        getDatasetJsonAfterUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n         \n     }\n     \n", "next_change": {"commit": "9094b94828e5737d93e8425bca3a9675b23cfb24", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex df88b24ab6..33cf2927ce 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2596,151 +2586,7 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n                 .body(\"data.latestVersion.files[0].directoryLabel\", equalTo(\"code\"));\n         \n     }\n-    \n-    @Test\n-    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n-        Response createUser = UtilIT.createRandomUser();\n-        createUser.prettyPrint();\n-        createUser.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n-        String username = UtilIT.getUsernameFromResponse(createUser);\n-        \n-        \n-        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n-        createDataverse.prettyPrint();\n-        createDataverse.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n-\n-        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n-        createDataset.prettyPrint();\n-        createDataset.then().assertThat()\n-                .statusCode(CREATED.getStatusCode());\n-\n-        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n-        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n-\n-        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n-        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n-\n-        JsonObjectBuilder json1 = Json.createObjectBuilder()\n-                .add(\"description\", \"A script to reproduce results.\")\n-                .add(\"directoryLabel\", \"code\");\n-\n-        \n-        \n-\n-        String pathToFileThatGoesThroughIngest = \"src/test/resources/sav/dct.sav\";\n-        Response uploadIngestableFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFileThatGoesThroughIngest, apiToken);\n-        uploadIngestableFile.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        uploadIngestableFile.prettyPrint();\n-\n-        String origFileId = JsonPath.from(uploadIngestableFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n-\n-        System.out.println(\"Orig file id \" + origFileId);\n-\n-        logger.fine(\"Orig file id: \" + origFileId);\n-        assertNotNull(origFileId);\n-        assertNotEquals(\"\",origFileId);\n-\n-        // Give file time to ingest\n-        \n-        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFileThatGoesThroughIngest , UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", apiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n-        \n-        Response origXml = UtilIT.getFileMetadata(origFileId, null, apiToken);\n-        assertEquals(200, origXml.getStatusCode());\n \n \n-        String stringOrigXml = origXml.getBody().prettyPrint();\n-\n-        InputStream variableData = origXml.body().asInputStream();\n-\n-        Map<Long, VariableMetadata> mapVarToVarMet = new HashMap<Long, VariableMetadata>();\n-        Map<Long,VarGroup> varGroupMap = new HashMap<Long, VarGroup>();\n-        try {\n-            XMLInputFactory factory = XMLInputFactory.newInstance();\n-            XMLStreamReader xmlr = factory.createXMLStreamReader(variableData);\n-            VariableMetadataDDIParser vmdp = new VariableMetadataDDIParser();\n-\n-            vmdp.processDataDscr(xmlr, mapVarToVarMet, varGroupMap);\n-\n-        } catch (XMLStreamException e) {\n-            logger.warning(e.getMessage());\n-            assertEquals(0,1);\n-        }\n-\n-\n-        //Test here\n-        String updatedContent = \"\";\n-        try {\n-            updatedContent = new String(Files.readAllBytes(Paths.get(\"src/test/resources/xml/dct.xml\")));\n-        } catch (IOException e) {\n-            logger.warning(e.getMessage());\n-            assertEquals(0,1);\n-        }\n-        Long replV1168 = 0L;\n-        Long replV1169 = 0L;\n-        Long replV1170 = 0L;\n-        int numberVariables = 0;\n-        for (VariableMetadata var : mapVarToVarMet.values()) {\n-            if (var.getLabel().equals(\"gender\")) {\n-                replV1170 = var.getDataVariable().getId();\n-                numberVariables = numberVariables +1;\n-            } else if (var.getLabel().equals(\"weight\")) {\n-                replV1168 = var.getDataVariable().getId();\n-                numberVariables = numberVariables +1;\n-            } else if (var.getLabel().equals(\"age_rollup\")) {\n-                replV1169 = var.getDataVariable().getId();\n-                numberVariables = numberVariables +1;\n-            }\n-        }\n-        assertEquals(3, numberVariables);\n-\n-        updatedContent = updatedContent.replaceAll(\"v1168\", \"v\" + replV1168 );\n-        updatedContent = updatedContent.replaceAll(\"v1169\", \"v\" + replV1169 );\n-        updatedContent = updatedContent.replaceAll(\"v1170\", \"v\" + replV1170 );\n-\n-        //edit draft vesrsion\n-        Response editDDIResponse = UtilIT.editDDI(updatedContent, origFileId, apiToken);\n-\n-        editDDIResponse.prettyPrint();\n-        assertEquals(200, editDDIResponse.getStatusCode());\n-\n-\n-\n-        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-\n-        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n-        getDatasetJsonBeforeUpdate.prettyPrint();\n-        getDatasetJsonBeforeUpdate.then().assertThat()\n-                .statusCode(OK.getStatusCode())\n-                .body(\"data.latestVersion.files[0].label\", equalTo(\"dct.tab\"));\n-        \n-        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n-        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n-        updateTitle.prettyPrint();\n-        updateTitle.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        \n-        // shouldn't be able to update current unless you're a super user\n-\n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n-        \n-        Response makeSuperUser = UtilIT.makeSuperUser(username);\n-                \n-        //should work after making super user\n-        \n-        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n-        \n-        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n-        getDatasetJsonAfterUpdate.prettyPrint();\n-        getDatasetJsonAfterUpdate.then().assertThat()\n-                .statusCode(OK.getStatusCode());\n-        \n-    }\n     \n }\n", "next_change": {"commit": "95beeaa1f0764b36aa0348cb675b8836a7aac6a2", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 33cf2927ce..81ad3aba4a 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2589,4 +2599,150 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n \n \n     \n+    @Test\n+    public void testCuratePublishedDatasetVersionCommand() throws IOException {\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        createUser.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        \n+        \n+        Response createDataverse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+        Integer datasetId = JsonPath.from(createDataset.asString()).getInt(\"data.id\");\n+\n+        Path pathtoScript = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"run.sh\");\n+        java.nio.file.Files.write(pathtoScript, \"#!/bin/bash\\necho hello\".getBytes());\n+\n+        JsonObjectBuilder json1 = Json.createObjectBuilder()\n+                .add(\"description\", \"A script to reproduce results.\")\n+                .add(\"directoryLabel\", \"code\");\n+\n+        \n+        \n+\n+        String pathToFileThatGoesThroughIngest = \"src/test/resources/sav/dct.sav\";\n+        Response uploadIngestableFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFileThatGoesThroughIngest, apiToken);\n+        uploadIngestableFile.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        uploadIngestableFile.prettyPrint();\n+\n+        String origFileId = JsonPath.from(uploadIngestableFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+\n+        System.out.println(\"Orig file id \" + origFileId);\n+\n+        logger.fine(\"Orig file id: \" + origFileId);\n+        assertNotNull(origFileId);\n+        assertNotEquals(\"\",origFileId);\n+\n+        // Give file time to ingest\n+        \n+        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFileThatGoesThroughIngest , UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", apiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+        \n+        Response origXml = UtilIT.getFileMetadata(origFileId, null, apiToken);\n+        assertEquals(200, origXml.getStatusCode());\n+\n+\n+        String stringOrigXml = origXml.getBody().prettyPrint();\n+\n+        InputStream variableData = origXml.body().asInputStream();\n+\n+        Map<Long, VariableMetadata> mapVarToVarMet = new HashMap<Long, VariableMetadata>();\n+        Map<Long,VarGroup> varGroupMap = new HashMap<Long, VarGroup>();\n+        try {\n+            XMLInputFactory factory = XMLInputFactory.newInstance();\n+            XMLStreamReader xmlr = factory.createXMLStreamReader(variableData);\n+            VariableMetadataDDIParser vmdp = new VariableMetadataDDIParser();\n+\n+            vmdp.processDataDscr(xmlr, mapVarToVarMet, varGroupMap);\n+\n+        } catch (XMLStreamException e) {\n+            logger.warning(e.getMessage());\n+            assertEquals(0,1);\n+        }\n+\n+\n+        //Test here\n+        String updatedContent = \"\";\n+        try {\n+            updatedContent = new String(Files.readAllBytes(Paths.get(\"src/test/resources/xml/dct.xml\")));\n+        } catch (IOException e) {\n+            logger.warning(e.getMessage());\n+            assertEquals(0,1);\n+        }\n+        Long replV1168 = 0L;\n+        Long replV1169 = 0L;\n+        Long replV1170 = 0L;\n+        int numberVariables = 0;\n+        for (VariableMetadata var : mapVarToVarMet.values()) {\n+            if (var.getLabel().equals(\"gender\")) {\n+                replV1170 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            } else if (var.getLabel().equals(\"weight\")) {\n+                replV1168 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            } else if (var.getLabel().equals(\"age_rollup\")) {\n+                replV1169 = var.getDataVariable().getId();\n+                numberVariables = numberVariables +1;\n+            }\n+        }\n+        assertEquals(3, numberVariables);\n+\n+        updatedContent = updatedContent.replaceAll(\"v1168\", \"v\" + replV1168 );\n+        updatedContent = updatedContent.replaceAll(\"v1169\", \"v\" + replV1169 );\n+        updatedContent = updatedContent.replaceAll(\"v1170\", \"v\" + replV1170 );\n+\n+        //edit draft vesrsion\n+        Response editDDIResponse = UtilIT.editDDI(updatedContent, origFileId, apiToken);\n+\n+        editDDIResponse.prettyPrint();\n+        assertEquals(200, editDDIResponse.getStatusCode());\n+\n+\n+\n+        UtilIT.publishDataverseViaNativeApi(dataverseAlias, apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"major\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response getDatasetJsonBeforeUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonBeforeUpdate.prettyPrint();\n+        getDatasetJsonBeforeUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.latestVersion.files[0].label\", equalTo(\"dct.tab\"));\n+        \n+        String pathToJsonFile = \"doc/sphinx-guides/source/_static/api/dataset-update-metadata.json\";\n+        Response updateTitle = UtilIT.updateDatasetMetadataViaNative(datasetPid, pathToJsonFile, apiToken);\n+        updateTitle.prettyPrint();\n+        updateTitle.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+        // shouldn't be able to update current unless you're a super user\n+\n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(FORBIDDEN.getStatusCode());\n+        \n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+                \n+        //should work after making super user\n+        \n+        UtilIT.publishDatasetViaNativeApi(datasetId, \"updatecurrent\", apiToken).then().assertThat().statusCode(OK.getStatusCode());\n+        \n+        Response getDatasetJsonAfterUpdate = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonAfterUpdate.prettyPrint();\n+        getDatasetJsonAfterUpdate.then().assertThat()\n+                .statusCode(OK.getStatusCode());\n+        \n+    }\n+    \n }\n", "next_change": {"commit": "2b3c8b7e67892815dbb3ee761640fba368a7fec8", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 81ad3aba4a..0349b70daa 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2745,4 +2745,69 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         \n     }\n     \n+    /**\n+     * In this test we are restricting a file and testing that terms of accees\n+     * or request access is required\n+     *\n+     * Export at the dataset level is always the public version.\n+     *\n+     */\n+    @Test\n+    public void testRestrictFileTermsOfUseAndAccess() throws IOException {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        String authorUsername = UtilIT.getUsernameFromResponse(createUser);\n+        String authorApiToken = UtilIT.getApiTokenFromResponse(createUser);\n+\n+        Response createDataverse = UtilIT.createRandomDataverse(authorApiToken);\n+        createDataverse.prettyPrint();\n+        createDataverse.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverse);\n+\n+        Response createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, authorApiToken);\n+        createDataset.prettyPrint();\n+        createDataset.then().assertThat()\n+                .statusCode(CREATED.getStatusCode());\n+\n+        Integer datasetId = UtilIT.getDatasetIdFromResponse(createDataset);\n+        String datasetPid = JsonPath.from(createDataset.asString()).getString(\"data.persistentId\");\n+\n+        Path pathToFile = Paths.get(java.nio.file.Files.createTempDirectory(null) + File.separator + \"data.csv\");\n+        String contentOfCsv = \"\"\n+                + \"name,pounds,species\\n\"\n+                + \"Marshall,40,dog\\n\"\n+                + \"Tiger,17,cat\\n\"\n+                + \"Panther,21,cat\\n\";\n+        java.nio.file.Files.write(pathToFile, contentOfCsv.getBytes());\n+\n+        Response uploadFile = UtilIT.uploadFileViaNative(datasetId.toString(), pathToFile.toString(), authorApiToken);\n+        uploadFile.prettyPrint();\n+        uploadFile.then().assertThat()\n+                .statusCode(OK.getStatusCode())\n+                .body(\"data.files[0].label\", equalTo(\"data.csv\"));\n+\n+        String fileId = JsonPath.from(uploadFile.body().asString()).getString(\"data.files[0].dataFile.id\");\n+\n+        assertTrue(\"Failed test if Ingest Lock exceeds max duration \" + pathToFile, UtilIT.sleepForLock(datasetId.longValue(), \"Ingest\", authorApiToken, UtilIT.MAXIMUM_INGEST_LOCK_DURATION));\n+\n+        Response restrictFile = UtilIT.restrictFile(fileId, true, authorApiToken);\n+        restrictFile.prettyPrint();\n+        restrictFile.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        Response publishDataverse = UtilIT.publishDataverseViaNativeApi(dataverseAlias, authorApiToken);\n+        publishDataverse.then().assertThat().statusCode(OK.getStatusCode());\n+        Response publishDataset = UtilIT.publishDatasetViaNativeApi(datasetPid, \"major\", authorApiToken);\n+        publishDataset.then().assertThat().statusCode(OK.getStatusCode());\n+        \n+        \n+        //not allowed to remove request access if there are retricted files\n+        \n+        Response disallowRequestAccess = UtilIT.allowAccessRequests(datasetPid, false, authorApiToken);\n+        disallowRequestAccess.prettyPrint();\n+        disallowRequestAccess.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n+        \n+    }\n+    \n }\n", "next_change": {"commit": "9223e7df02f9f829a0e333247971e57706803aa7", "changed_code": [{"header": "diff --git a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\nindex 0349b70daa..77a7a49996 100644\n--- a/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n+++ b/src/test/java/edu/harvard/iq/dataverse/api/DatasetsIT.java\n", "chunk": "@@ -2809,5 +2811,101 @@ createDataset = UtilIT.createRandomDatasetViaNativeApi(dataverse1Alias, apiToken\n         disallowRequestAccess.then().assertThat().statusCode(BAD_REQUEST.getStatusCode());\n         \n     }\n-    \n+\n+    /**\n+     * In this test we do CRUD of archivalStatus (Note this and other archiving\n+     * related tests are part of\n+     * https://github.com/harvard-lts/hdc-integration-tests)\n+     *\n+     * This test requires the root dataverse to be published to pass.\n+     */\n+    @Test\n+    public void testArchivalStatusAPI() throws IOException {\n+\n+        Response createUser = UtilIT.createRandomUser();\n+        createUser.prettyPrint();\n+        assertEquals(200, createUser.getStatusCode());\n+        String username = UtilIT.getUsernameFromResponse(createUser);\n+        String apiToken = UtilIT.getApiTokenFromResponse(createUser);\n+        Response makeSuperUser = UtilIT.makeSuperUser(username);\n+        assertEquals(200, makeSuperUser.getStatusCode());\n+\n+        Response createNoAccessUser = UtilIT.createRandomUser();\n+        createNoAccessUser.prettyPrint();\n+        String apiTokenNoAccess = UtilIT.getApiTokenFromResponse(createNoAccessUser);\n+\n+        Response createDataverseResponse = UtilIT.createRandomDataverse(apiToken);\n+        createDataverseResponse.prettyPrint();\n+        String dataverseAlias = UtilIT.getAliasFromResponse(createDataverseResponse);\n+\n+        Response createDatasetResponse = UtilIT.createRandomDatasetViaNativeApi(dataverseAlias, apiToken);\n+        createDatasetResponse.prettyPrint();\n+        Integer datasetId = JsonPath.from(createDatasetResponse.body().asString()).getInt(\"data.id\");\n+\n+        Response getDatasetJsonBeforePublishing = UtilIT.nativeGet(datasetId, apiToken);\n+        getDatasetJsonBeforePublishing.prettyPrint();\n+        String protocol = JsonPath.from(getDatasetJsonBeforePublishing.getBody().asString()).getString(\"data.protocol\");\n+        String authority = JsonPath.from(getDatasetJsonBeforePublishing.getBody().asString())\n+                .getString(\"data.authority\");\n+        String identifier = JsonPath.from(getDatasetJsonBeforePublishing.getBody().asString())\n+                .getString(\"data.identifier\");\n+        String datasetPersistentId = protocol + \":\" + authority + \"/\" + identifier;\n+\n+        Response publishDataverse = UtilIT.publishDataverseViaSword(dataverseAlias, apiToken);\n+        assertEquals(200, publishDataverse.getStatusCode());\n+\n+        logger.info(\"Attempting to publish a major version\");\n+        // Return random sleep 9/13/2019\n+        // Without it we've seen some DB deadlocks\n+        // 3 second sleep, to allow the indexing to finish:\n+\n+        try {\n+            Thread.sleep(3000l);\n+        } catch (InterruptedException iex) {\n+        }\n+\n+        Response publishDataset = UtilIT.publishDatasetViaNativeApi(datasetPersistentId, \"major\", apiToken);\n+        assertEquals(200, publishDataset.getStatusCode());\n+\n+        // Now change the title\n+        Response response = UtilIT.updateDatasetJsonLDMetadata(datasetId, apiToken,\n+                \"{\\\"title\\\": \\\"New Title\\\", \\\"@context\\\":{\\\"title\\\": \\\"http://purl.org/dc/terms/title\\\"}}\", true);\n+        response.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        int status = Status.CONFLICT.getStatusCode();\n+        while (status == Status.CONFLICT.getStatusCode()) {\n+\n+            Response publishV2 = UtilIT.publishDatasetViaNativeApi(datasetPersistentId, \"major\", apiToken);\n+            status = response.thenReturn().statusCode();\n+        }\n+        assertEquals(OK.getStatusCode(), status);\n+\n+        if (!UtilIT.sleepForReindex(datasetPersistentId, apiToken, 3000)) {\n+            logger.info(\"Still indexing after 3 seconds\");\n+        }\n+\n+        //Verify the status is empty\n+        Response nullStatus = UtilIT.getDatasetVersionArchivalStatus(datasetId, \"1.0\", apiToken);\n+        nullStatus.then().assertThat().statusCode(NO_CONTENT.getStatusCode());\n+\n+        //Set it\n+        Response setStatus = UtilIT.setDatasetVersionArchivalStatus(datasetId, \"1.0\", apiToken, \"pending\",\n+                \"almost there\");\n+        setStatus.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        //Get it\n+        Response getStatus = UtilIT.getDatasetVersionArchivalStatus(datasetId, \"1.0\", apiToken);\n+        getStatus.then().assertThat().body(\"data.status\", equalTo(\"pending\")).body(\"data.message\",\n+                equalTo(\"almost there\"));\n+\n+        //Delete it\n+        Response deleteStatus = UtilIT.deleteDatasetVersionArchivalStatus(datasetId, \"1.0\", apiToken);\n+        deleteStatus.then().assertThat().statusCode(OK.getStatusCode());\n+\n+        //Make sure it's gone\n+        Response nullStatus2 = UtilIT.getDatasetVersionArchivalStatus(datasetId, \"1.0\", apiToken);\n+        nullStatus2.then().assertThat().statusCode(NO_CONTENT.getStatusCode());\n+\n+    }\n+\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "message": "Merge commit", "committedDate": null}, {"oid": "1e7fcd17d7b102bd141e94b262ee6a53b60d2f56", "committedDate": "2021-03-24 09:01:23 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "60f474dec0f631735b9705cb5c0d7a714d5f57de", "committedDate": "2021-06-03 12:19:09 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "da9c9e9e24556fafa6bc81d78cddd29b0632094e", "committedDate": "2021-06-25 12:34:43 -0400", "message": "initial test commit"}, {"oid": "4cd26692ad13fdb788b29ed603993e5a027199d4", "committedDate": "2021-06-29 13:45:46 -0400", "message": "update tests, incr. titanium"}, {"oid": "5f53e158462feb04c1c53bf4d17aed214733bc48", "committedDate": "2021-06-29 17:30:19 -0400", "message": "finish tests"}, {"oid": "d857009b3ea3d3b01488390a6edd2b5ebcf76eee", "committedDate": "2021-07-02 12:21:23 -0400", "message": "fix test"}, {"oid": "048975efbbc743bc602fa8ae9085ced04ffd6a85", "committedDate": "2021-07-02 14:18:33 -0400", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "1a348f5f3660916a538a9d4f3fc1ed062fac83ab", "committedDate": "2021-07-21 10:26:10 +0200", "message": "Non-integer identifiers using stored procedure"}, {"oid": "6a7066e4027fce6ac66ddd77c917390407580aad", "committedDate": "2021-07-21 10:31:33 +0200", "message": "Added a comment to the storedProcGenerated test\u00a0"}, {"oid": "5557145719487de8ad148f3f742871cf5adb7644", "committedDate": "2021-07-21 17:07:49 -0400", "message": "Merge pull request #7976 from claudiodsf/string_identifiers"}, {"oid": "30d131cfbd8fd99d8eda764e0ec6b82a61c1e354", "committedDate": "2021-07-22 15:10:31 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "52fbc935b2e0f6f0ab0c3e0f961b3735cf169cb5", "committedDate": "2021-07-23 12:56:31 -0400", "message": "lost test update"}, {"oid": "60e72093081d9dc12bbe1d0b6c41d7fabeb72785", "committedDate": "2021-09-03 12:06:50 -0400", "message": "#6752 add validator to test for empty DS"}, {"oid": "a70f479ca4f7683c52bb6b831f91a635e67939b3", "committedDate": "2021-09-08 15:07:27 -0400", "message": "#6752 fix prepare dataset validation"}, {"oid": "38b8baa6c3b0f5d3878037c506d6f055380385a0", "committedDate": "2021-09-29 15:28:46 -0400", "message": "addressing review feedback"}, {"oid": "a79ce03e58b5110b28f7b4981b50568e01499177", "committedDate": "2021-10-04 12:50:30 -0400", "message": "Fix PUT curationSetLabel and test"}, {"oid": "00878562c26d8f4efa17e05a1c050b82108a916e", "committedDate": "2021-10-14 10:33:56 -0400", "message": "avoid reusing the Response variable"}, {"oid": "b55c5f48dda572190287218738294f5cb9852e57", "committedDate": "2021-10-14 12:32:06 -0400", "message": "fix test - set setting directly"}, {"oid": "36e43eb64826243a3f1dff16a508f52a8b35b0f5", "committedDate": "2021-10-14 14:05:57 -0400", "message": "also fix Get test"}, {"oid": "1a4e4f9808e003d9032b17018f20200e71a6fb57", "committedDate": "2021-10-14 15:00:44 -0400", "message": "add directoryLabel test for pull request #8142"}, {"oid": "c0d06a5d344b0d572d30bfbc2a22db155d3e25bd", "committedDate": "2021-10-15 14:14:57 -0400", "message": "Merge pull request #8142 from janvanmansum/DIR_LABEL_COPY"}, {"oid": "ef636435efe8c6737597da1e8dbce89f36b5d6e8", "committedDate": "2022-02-18 20:51:07 -0500", "message": "Expanding the locks API to list locks installation-wide, across all datasets. (IQSS/dataverse.harvard.edu#135)"}, {"oid": "36e077fa49e7483b895f21e26b727c18d0887f35", "committedDate": "2022-02-21 16:21:24 -0500", "message": "Add debug info to test"}, {"oid": "2163721e13034ec3598b34291852ca9d9d722ba4", "committedDate": "2022-02-21 18:53:48 -0500", "message": "explicitly print"}, {"oid": "96389dfe022e554394eda8107838c82799066cc3", "committedDate": "2022-03-03 16:42:13 -0500", "message": "#8400 add integration test for curation publish"}, {"oid": "74c5a0316f52568546b61be95498bf0fa7bfb611", "committedDate": "2022-03-07 13:39:43 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/8337-handle_metadatalanguage_in_import/migrate"}, {"oid": "57813947aa310c8d85d03ec45abf926b3c230d5f", "committedDate": "2022-03-09 10:53:42 -0500", "message": "#8191 add integration test for req/toa validation"}, {"oid": "e504bfcc134083699d252bc8d33eadb41625209d", "committedDate": "2022-03-23 17:11:58 -0400", "message": "tab ingest skip option"}, {"oid": "d0c70e7b9e78ab250088f488465d7b8081ead008", "committedDate": "2022-03-24 13:20:53 -0400", "message": "small fixes"}, {"oid": "eea514e8f943960c164635cfc7252544bd0f3bf4", "committedDate": "2022-03-28 15:36:40 -0400", "message": "Remove hardcoded sleep"}, {"oid": "2163fdc29edf57cb62005071c11cbe249c233a41", "committedDate": "2022-03-29 16:13:54 -0400", "message": "test and doc"}, {"oid": "e7a232b0d7db8fab0c597aa28ef3a5b7bd9da394", "committedDate": "2022-03-31 10:46:10 -0400", "message": "#8400 fix variable metadata copy"}, {"oid": "b6376dacedb9bc20440cc776c3b8791cdc68ef37", "committedDate": "2022-04-09 14:37:17 -0400", "message": "update guides examples, tests, cleanup metadatablock discussion"}, {"oid": "28f7c6ea067f1e5697bf1dd80bb5b8021bc962c9", "committedDate": "2022-04-12 10:03:57 -0400", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "05a06eb764b20c88f816fec9fd119da808cfb9b9", "committedDate": "2022-04-12 10:14:17 -0400", "message": "Merge branch 'develop' into 8400-publish-bug"}, {"oid": "9094b94828e5737d93e8425bca3a9675b23cfb24", "committedDate": "2022-04-12 10:41:53 -0400", "message": "Merge pull request #8532 from lubitchv/8525-injest-optional-skip"}, {"oid": "95beeaa1f0764b36aa0348cb675b8836a7aac6a2", "committedDate": "2022-04-12 11:57:02 -0400", "message": "Merge pull request #8562 from IQSS/8400-publish-bug"}, {"oid": "2b3c8b7e67892815dbb3ee761640fba368a7fec8", "committedDate": "2022-04-12 12:15:06 -0400", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "a4712d80a028738092590019344149a4094f4c16", "committedDate": "2022-05-13 13:24:55 -0400", "message": "Merge pull request #8592 from GlobalDataverseCommunityConsortium/IQSS/8533_update_internal_semantic_mappings"}, {"oid": "9223e7df02f9f829a0e333247971e57706803aa7", "committedDate": "2022-07-15 17:21:48 -0400", "message": "updates per review"}, {"oid": "f5396d85f92f8b497038cda9ca33886f26468911", "committedDate": "2022-07-15 18:38:05 -0400", "message": "swap native update"}, {"oid": "467cf7c0cd189f929ab050ca7441be0251b82a86", "committedDate": "2022-08-09 11:04:52 -0400", "message": "#8859 add test for restricting files while toa out of compliance"}, {"oid": "b79bec251b674224106b62850cbfce8ec6158fa6", "committedDate": "2022-09-08 13:22:12 -0400", "message": "#8859 have restrict file api return conflict if out of compliance"}, {"oid": "eeaefecf68d2b46180ff7bbdc82a534076ca9e83", "committedDate": "2022-09-09 15:04:42 -0400", "message": "add API test for new testExport method near similar method #8720 #5771"}, {"oid": "de9f68b1de761bcda4e7cf10e3b4ae1664b48306", "committedDate": "2022-09-14 11:12:31 -0400", "message": "#8859 add test framework"}, {"oid": "9f23b6aa042cd2e703b5022e3c022edcdd86ff78", "committedDate": "2022-09-21 11:14:14 -0400", "message": "#8859 update api message prior to command; update tests"}, {"oid": "bd47b8e7f459e9f3abb141c5837297466c7ac1ec", "committedDate": "2022-09-21 15:46:16 -0400", "message": "support database IDs too (as well as PIDs) #8720"}, {"oid": "ccfa579c698fccde31c187933a70ca1488be54ea", "committedDate": "2022-09-27 13:07:45 +0200", "message": "Merge branch 'develop' of github.com:IQSS/dataverse into 8720-allow-metadata-reExport-in-smaller-batches"}, {"oid": "85a3306e6ab3d20aa206a9669926cbc462b5a76c", "committedDate": "2022-10-05 16:56:14 -0400", "message": "update test to use seconds"}, {"oid": "c80a06f38b679641d80a05b5215106006da52667", "committedDate": "2022-10-28 18:07:07 -0400", "message": "fix for cvv and editMetadata replace=true, and test"}, {"oid": "5993be8a5adecd41bf138e35ceda212cac522f92", "committedDate": "2022-10-28 18:15:35 -0400", "message": "check math exists before update"}, {"oid": "120adc18a8b02d4fcf18c4dd9ef557f529de1ae9", "committedDate": "2022-12-07 17:38:06 -0500", "message": "Merge pull request #9107 from GlobalDataverseCommunityConsortium/GDCC/9106-fix_editMetadata_api_when_replace_is_true"}, {"oid": "94082ebbe33c718c9a045d624bc5bd39f7a61f2b", "committedDate": "2023-02-03 11:42:33 +0000", "message": "Added: minor refactoring and IT test fixes"}, {"oid": "2f64428f0c9dd34b7b8da97d7ab44b9bdde4c1cf", "committedDate": "2023-02-03 14:17:50 +0000", "message": "Fixed: DatasetsIT.testPrivateUrl wrong status code when bad API token provided"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU2NjY5Ng==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r662566696", "body": "I'm happy to see someone updating this old API. \ud83d\ude04 ", "bodyText": "I'm happy to see someone updating this old API. \ud83d\ude04", "bodyHTML": "<p dir=\"auto\">I'm happy to see someone updating this old API. <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>", "author": "pdurbin", "createdAt": "2021-07-01T20:19:39Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/DatasetFieldServiceApi.java", "diffHunk": "@@ -168,7 +169,8 @@ public Response getByName(@PathParam(\"name\") String name) {\n                     .add(\"parentAllowsMultiples\", parentAllowsMultiplesDisplay)\n                     .add(\"solrFieldSearchable\", solrFieldSearchable)\n                     .add(\"solrFieldFacetable\", solrFieldFacetable)\n-                    .add(\"isRequired\", isRequired));\n+                    .add(\"isRequired\", isRequired)\n+                    .add(\"uri\", uri));", "originalCommit": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NjcyOA==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r663166728", "bodyText": "This is mostly a separate thing. Slava pointed out that this API didn't include the URI for a term (which was added with the OAI-ORE/Bag work from QDR). Since this was a one line change related to semantics, I added it here but the rest of the changes do not depend on this API having the extra field.", "author": "qqmyers", "createdAt": "2021-07-02T17:45:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU2NjY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDgwMzQ1Ng==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r664803456", "bodyText": "Cool. Why not.", "author": "pdurbin", "createdAt": "2021-07-06T18:54:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU2NjY5Ng=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "message": "Merge commit", "committedDate": null}, {"oid": "d66e9a0d7bee31760712b32ee655a7015c8d0ff3", "committedDate": "2021-09-16 15:12:54 -0400", "message": "#6752 consolidate cv exception string building"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NDE4Mg==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r662574182", "body": "This should be deleted or set to fine.", "bodyText": "This should be deleted or set to fine.", "bodyHTML": "<p dir=\"auto\">This should be deleted or set to fine.</p>", "author": "pdurbin", "createdAt": "2021-07-01T20:31:23Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Datasets.java", "diffHunk": "@@ -651,6 +651,96 @@ public Response updateDraftVersion( String jsonBody, @PathParam(\"id\") String id,\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");", "originalCommit": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Nzc0Ng==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r663167746", "bodyText": "removed", "author": "qqmyers", "createdAt": "2021-07-02T17:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NDE4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "1d54c68fe4b515e56fee490a302cd8464d278d2d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 608d9554f6..645b3cc835 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -714,14 +714,12 @@ public class Datasets extends AbstractApiBean {\n     @Path(\"{id}/metadata/delete\")\n     @Consumes(\"application/ld+json, application/json-ld\")\n     public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n         try {\n             Dataset ds = findDatasetOrDie(id);\n             DataverseRequest req = createDataverseRequest(findUserOrDie());\n             DatasetVersion dsv = ds.getEditVersion();\n             boolean updateDraft = ds.getLatestVersion().isDraft();\n             dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n             DatasetVersion managedVersion;\n             if (updateDraft) {\n                 Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n", "next_change": null}]}, "revised_code_in_main": {"commit": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 608d9554f6..645b3cc835 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -714,14 +714,12 @@ public class Datasets extends AbstractApiBean {\n     @Path(\"{id}/metadata/delete\")\n     @Consumes(\"application/ld+json, application/json-ld\")\n     public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n         try {\n             Dataset ds = findDatasetOrDie(id);\n             DataverseRequest req = createDataverseRequest(findUserOrDie());\n             DatasetVersion dsv = ds.getEditVersion();\n             boolean updateDraft = ds.getLatestVersion().isDraft();\n             dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n             DatasetVersion managedVersion;\n             if (updateDraft) {\n                 Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n", "next_change": {"commit": "00d53ee4d43fd49a81faa1f31b9b0c6a1cad8b46", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 645b3cc835..7fd3b1ab63 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -651,94 +609,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "b45336c95ecbcee28b88a5b334c2180c86eb63fc", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 7fd3b1ab63..20874f7065 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -610,6 +611,38 @@ public class Datasets extends AbstractApiBean {\n         }\n     }\n     \n+\t@PUT\n+\t@Path(\"{id}/versions/{versionId}/metadata\")\n+\t@Consumes(\"application/json-ld\")\n+\tpublic Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id,\n+\t\t\t@PathParam(\"versionId\") String versionId, @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+\t\tif (!\":draft\".equals(versionId)) {\n+\t\t\treturn error(Response.Status.BAD_REQUEST, \"Only the :draft version can be updated\");\n+\t\t}\n+\t\ttry {\n+\t\t\tDataset ds = findDatasetOrDie(id);\n+\t\t\tDataverseRequest req = createDataverseRequest(findUserOrDie());\n+\t\t\tDatasetVersion dsv = ds.getEditVersion();\n+\t\t\tboolean updateDraft = ds.getLatestVersion().isDraft();\n+\t\t\tdsv = JSONLDUtil.updateDatasetVersionFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms);\n+\t\t\t\n+\t\t\tDatasetVersion managedVersion;\n+\t\t\tif (updateDraft) {\n+\t\t\t\tDataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+\t\t\t\tmanagedVersion = managedDataset.getEditVersion();\n+\t\t\t} else {\n+\t\t\t\tmanagedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+\t\t\t}\n+\t\t\tString info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+\t\t\treturn ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+\t\t} catch (WrappedResponse ex) {\n+\t\t\treturn ex.getResponse();\n+\n+\t\t}\n+\t}\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "6d537ce15b5989abb1bacd85a48ae17b447cd1cd", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 20874f7065..a376e663e9 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -639,7 +641,9 @@ public class Datasets extends AbstractApiBean {\n \n \t\t} catch (WrappedResponse ex) {\n \t\t\treturn ex.getResponse();\n-\n+\t\t} catch (JsonParsingException jpe) {\n+\t\t    logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n \t\t}\n \t}\n     \n", "next_change": {"commit": "24cfcfa08257d9245b2d6f033c679e59c4424316", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a376e663e9..8b9118741b 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -640,9 +696,11 @@ public class Datasets extends AbstractApiBean {\n \t\t\treturn ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n \t\t} catch (WrappedResponse ex) {\n+\t\t    ex.printStackTrace();\n \t\t\treturn ex.getResponse();\n \t\t} catch (JsonParsingException jpe) {\n \t\t    logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+\t\t    jpe.printStackTrace();\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n \t\t}\n \t}\n", "next_change": {"commit": "38a1d38f37f8ef0d9d75db51a5b6707f58fb8227", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8b9118741b..1db28d5dcc 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -614,96 +615,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-\t@PUT\n-\t@Path(\"{id}/metadata/delete\")\n-\t@Consumes(\"application/json-ld\")\n-\tpublic Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-\t\ttry {\n-\t\t\tDataset ds = findDatasetOrDie(id);\n-\t\t\tDataverseRequest req = createDataverseRequest(findUserOrDie());\n-\t\t\tDatasetVersion dsv = ds.getEditVersion();\n-\t\t\tboolean updateDraft = ds.getLatestVersion().isDraft();\n-\t\t\tdsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-\t\t\tlogger.info(\"Updating ver\");\n-\t\t\tDatasetVersion managedVersion;\n-\t\t\tif (updateDraft) {\n-\t\t\t\tDataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-\t\t\t\tmanagedVersion = managedDataset.getEditVersion();\n-\t\t\t} else {\n-\t\t\t\tmanagedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-\t\t\t}\n-\t\t\tString info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-\t\t\treturn ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-\t\t} catch (WrappedResponse ex) {\n-\t\t    ex.printStackTrace();\n-\t\t\treturn ex.getResponse();\n-\t\t} catch (JsonParsingException jpe) {\n-\t\t    logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-\t\t    jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-\t\t}\n-\t}\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "5305e759e7e20774e3a435936a3ea2009bf1d058", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 1db28d5dcc..9eb82996de 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -615,6 +647,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "2fa243abe63c60b07a714070acd4a62d5c8d6e96", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9eb82996de..c2854b33e2 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -636,108 +644,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "99a1ecff4a08f72f8f01c4eb171424795009c8c5", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex c2854b33e2..8836eb62e4 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,18 +652,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n-\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n         } catch (WrappedResponse ex) {\n             return ex.getResponse();\n-\n+            \n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "3a3235451900dacd9dbf48ea33ed445f128214a1", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8836eb62e4..777627437d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,6 +651,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "6cd23a1b327f84fd649a0b802322532df92d345a", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 777627437d..afeb10e304 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -651,96 +663,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "1e7fcd17d7b102bd141e94b262ee6a53b60d2f56", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex afeb10e304..c2cb940901 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,6 +655,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "491fe42c07944db5fc4686a4699ffb1399ca9051", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex c2cb940901..be46a5fab3 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -655,96 +663,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "4b5ad664ac18165dc032ab7faeee240cf6002aa2", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex be46a5fab3..9457397345 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,6 +655,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "bc5edf0ad09ecf627cb936a5de50e19be4df34ba", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9457397345..b328877e14 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,108 +653,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c3b12195db2c5132f11672295e777f411eda4759", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex b328877e14..459de504c1 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -653,18 +644,108 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+            \n+        }\n+    }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n \n         } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n             return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "e68003191dbd06e8f34b9d52d559bee1ee081a30", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 459de504c1..a63a86a258 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,108 +653,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "58a2317d9fb696999fc7439bbcea18d05bc2728e", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a63a86a258..a6ae292dc5 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -653,18 +647,108 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+            \n+        }\n+    }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n \n         } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n             return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "e72c4e50fca0ceb2332d6057c4c05808b1d215dc", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a6ae292dc5..6183032124 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -658,96 +648,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "12e2e6eb1de0e2223c895b1a7fbfb6b29b3d5f14", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 6183032124..ca6425fc73 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -637,18 +644,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+\n         } catch (WrappedResponse ex) {\n             return ex.getResponse();\n-            \n+\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "878ef6fff6a27510b39cffb058b26afca31301c3", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ca6425fc73..1586576697 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,18 +637,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n-\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n         } catch (WrappedResponse ex) {\n             return ex.getResponse();\n-\n+            \n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "fb2b52cf66f7cb51b5b0cee0cd298657fdd0638d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 1586576697..51728242d3 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -648,6 +653,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "ad48ad711049f99d17b3494fab3d923016bfc799", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 51728242d3..f56674cb35 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -642,108 +644,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "faa944efd1a0644085555d5eae18bfad1a823e4d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex f56674cb35..daad72b2df 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,18 +651,108 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+            \n+        }\n+    }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n \n         } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n             return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "6fa5e904755345a8f3ae8ccea00f47d83265c726", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex daad72b2df..e0e6dd2fcb 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -662,96 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "f702a6188c89567592f593f96e9c7277bc0955fd", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex e0e6dd2fcb..8d56742b9f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +663,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "4fa484bfe8cc99a5330cd4291a6b86feeca333ca", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8d56742b9f..eacc00a456 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,96 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "60f474dec0f631735b9705cb5c0d7a714d5f57de", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex eacc00a456..3ecd785257 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +663,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "b12f881bb7408eb4eefb0f432ad30d6ca3638160", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 3ecd785257..226b409207 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,96 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "ff2419b9d62095405ddc5f67e40f37fcd7b19a4c", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 226b409207..0a86d8b67f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +663,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "2c494d85b5f2906cfbd5a3727a9a358635b47815", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 0a86d8b67f..4a1c96ea8e 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,94 +617,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "e1c1bfe58e64ea0ed54cbb03ad89bab209314aef", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 4a1c96ea8e..549647df69 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -617,6 +664,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "599504ab9a81d6766932bbdc9be69de131a09f27", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 549647df69..bef945554c 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -664,94 +619,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "a1f9f3ebe80dd6a20b60d1d19bb9acbd0a84713b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex bef945554c..b63b115a08 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -619,6 +620,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "fd21968e515394812d8a7f034d46203f44537740", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex b63b115a08..27fbf8661f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -620,94 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "19f3eac7cfd7837b45f6d22f8d8d53215354c1ad", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 27fbf8661f..b32908a303 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +659,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+\n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+\n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+\n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "6cc86e020135c1916d26be8ecef37bbf14f4f7c6", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex b32908a303..9ea7e4b27f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -747,7 +747,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c833eb98362792296239444bdb0510be10135a38", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9ea7e4b27f..348323b49d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -747,7 +752,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "21ff777277a49e45a8ececbd797d7f2272e7780d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 348323b49d..75e81efdba 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -752,7 +767,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "60d7d0dff8f6f0063f94f44bf79080867e3ec0ae", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 75e81efdba..ddb3cf489d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -767,7 +752,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "925a1c3f3d2538a365edc8f8c23735355615e08b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ddb3cf489d..9f86649718 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -752,7 +747,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "eade0066585b3511ccb9adbc1cea1d1f4d8caf37", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9f86649718..c2f820fbf8 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -747,7 +755,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "56fd065a1675449925d0426558aa007bf0a299e7", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex c2f820fbf8..a9b7317167 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -755,7 +766,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "8f8531a23b5156f0093e32272ed683c692e27f7f", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a9b7317167..2da116f5f6 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -766,7 +760,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "fae74755535964a4f8d87f46a14f454cf8d544a5", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 2da116f5f6..fb585a4ba9 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -760,7 +761,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c72c57ac2b225b614824d4a5ffc4bed467d73a8b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex fb585a4ba9..ee4c5ffa12 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -761,7 +760,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "d2c61b343fcdfbcba5590b18b89f0ed976ee147a", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ee4c5ffa12..948b91ca66 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -760,7 +769,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "ec1313056ada36b4d66da2938c1273c6b8d5e72b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 948b91ca66..8473be7065 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -769,7 +729,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "f994923879e5eb5b9404c8c9eb3d77e613eea0fd", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8473be7065..ce5caf20db 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -729,7 +762,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "8026778c742f6d6be71a6161907fe62eca061415", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ce5caf20db..cd9c57c41a 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -762,7 +731,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c10530ce764d5c67267958970dd6d9196e9a37ef", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex cd9c57c41a..02fdaf1543 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -731,7 +737,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "16d03003488998ae5e64cb80f0a94e8bb5cf6961", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 02fdaf1543..93f4875390 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -737,7 +729,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "8f596531cf0e1ec6583e89a5d96ccff38dbe46a4", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 93f4875390..7520c53117 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -729,7 +733,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "cf57f1427a43c89c6729be92b207a14111327307", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 7520c53117..ffe9b2bb69 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -735,10 +766,11 @@ public class Datasets extends AbstractApiBean {\n     }\n \n     @PUT\n+    @AuthRequired\n     @Path(\"{id}/deleteMetadata\")\n-    public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n+    public Response deleteVersionMetadata(@Context ContainerRequestContext crc, String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n \n-        DataverseRequest req = createDataverseRequest(findUserOrDie());\n+        DataverseRequest req = createDataverseRequest(getRequestUser(crc));\n \n         return processDatasetFieldDataDelete(jsonBody, id, req);\n     }\n", "next_change": {"commit": "e895445f46467f4997c3a90ee3df3f8e47c1071b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ffe9b2bb69..9869f947e4 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -766,11 +760,10 @@ public class Datasets extends AbstractApiBean {\n     }\n \n     @PUT\n-    @AuthRequired\n     @Path(\"{id}/deleteMetadata\")\n-    public Response deleteVersionMetadata(@Context ContainerRequestContext crc, String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n+    public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n \n-        DataverseRequest req = createDataverseRequest(getRequestUser(crc));\n+        DataverseRequest req = createDataverseRequest(findUserOrDie());\n \n         return processDatasetFieldDataDelete(jsonBody, id, req);\n     }\n", "next_change": {"commit": "de6beffa71c36fc10017de6f7f615089eddf7f19", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9869f947e4..83990619dd 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -760,10 +782,11 @@ public class Datasets extends AbstractApiBean {\n     }\n \n     @PUT\n+    @AuthRequired\n     @Path(\"{id}/deleteMetadata\")\n-    public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n+    public Response deleteVersionMetadata(@Context ContainerRequestContext crc, String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n \n-        DataverseRequest req = createDataverseRequest(findUserOrDie());\n+        DataverseRequest req = createDataverseRequest(getRequestUser(crc));\n \n         return processDatasetFieldDataDelete(jsonBody, id, req);\n     }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "message": "Merge commit", "committedDate": null}, {"oid": "00d53ee4d43fd49a81faa1f31b9b0c6a1cad8b46", "committedDate": "2020-10-14 12:39:49 -0400", "message": "adjust incoming identifier for HttpOverlay drivers"}, {"oid": "239d5a8de208b6bf4bb2c809264d2069526e33ff", "committedDate": "2020-10-14 14:03:44 -0400", "message": "debug logging"}, {"oid": "e86c2d0fca0693614c3e8d90adf89dfd5f1dd1da", "committedDate": "2020-10-14 15:27:51 -0400", "message": "more logging"}, {"oid": "0062c681c124c40a016e775b8da6acb9646a9c43", "committedDate": "2020-10-14 15:59:00 -0400", "message": "fix storageidentifier parsing/updating"}, {"oid": "b45336c95ecbcee28b88a5b334c2180c86eb63fc", "committedDate": "2020-12-01 16:58:49 -0500", "message": "add replace param"}, {"oid": "6d537ce15b5989abb1bacd85a48ae17b447cd1cd", "committedDate": "2020-12-22 13:37:42 -0500", "message": "fix error handling"}, {"oid": "2a83a701cd1721647316d9cbb149f3c42573c628", "committedDate": "2020-12-22 13:38:53 -0500", "message": "specify default"}, {"oid": "782d5ecfcedc0460b0ed619288651795775ddaf6", "committedDate": "2020-12-22 13:39:18 -0500", "message": "add migrating switch"}, {"oid": "63362d9f87df415198d8c11aa9367580df7bd796", "committedDate": "2020-12-22 13:59:39 -0500", "message": "GET/DELETE endpoints"}, {"oid": "5050e9390ff8fe4679ffb58a3f3bb89106b7f8d0", "committedDate": "2020-12-22 14:00:31 -0500", "message": "put is always for :draft version"}, {"oid": "24cfcfa08257d9245b2d6f033c679e59c4424316", "committedDate": "2020-12-22 14:15:21 -0500", "message": "multiple updates/fixes, added logging"}, {"oid": "e6366e4e29166365265ac947287d187c51f848cd", "committedDate": "2021-01-08 09:55:52 -0500", "message": "add note"}, {"oid": "cb20416b881c9b3a6e2ba06c5f6f7055ac370737", "committedDate": "2021-01-29 11:15:41 -0500", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "d885d633a96a649b296ada1b5fd3a0a18cf932a6", "committedDate": "2021-02-09 15:16:36 -0500", "message": "cleanup"}, {"oid": "8851fe322cbc6db5b0ad3bade0c3bdaf21acbcee", "committedDate": "2021-02-09 16:31:35 -0500", "message": "comments/cleanup"}, {"oid": "38a1d38f37f8ef0d9d75db51a5b6707f58fb8227", "committedDate": "2021-02-10 16:04:53 -0500", "message": "globusAPI initial commit"}, {"oid": "66a4ca056cf16450ed5bf788aa9b726928efb6ec", "committedDate": "2021-02-11 15:23:55 -0500", "message": "debug 1"}, {"oid": "b9689b3f53053896dff8170cac8d5afdbdcce3d9", "committedDate": "2021-02-16 08:56:08 -0500", "message": "Resolved Globus API for multiple files input (dv version 5.3 )"}, {"oid": "f8b7c3e2a630595a2d553e542c32b89b171bb24b", "committedDate": "2021-02-16 09:08:56 -0500", "message": "Removed unwanted statements"}, {"oid": "d6480aa7cc4f09fa73619af2cc08719b9a84b687", "committedDate": "2021-02-16 09:25:30 -0500", "message": "mimeType is calculated only from file extension"}, {"oid": "c10989dc062661bcf0db00f758a4a0ffa275991e", "committedDate": "2021-02-18 09:13:41 -0500", "message": "Merge remote-tracking branch 'Remote/develop' into develop-globus-phase2.1"}, {"oid": "9b14433f161d7fbf65f8d46e840b79cb571a5751", "committedDate": "2021-02-23 12:48:54 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "5305e759e7e20774e3a435936a3ea2009bf1d058", "committedDate": "2021-02-23 13:12:48 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "2fa243abe63c60b07a714070acd4a62d5c8d6e96", "committedDate": "2021-03-16 10:16:31 -0400", "message": "Globus API upgrade"}, {"oid": "99a1ecff4a08f72f8f01c4eb171424795009c8c5", "committedDate": "2021-03-16 10:39:39 -0400", "message": "merge with develop iqss"}, {"oid": "282063ebb7b6615b71d2d4fa5f7ec34b510fe521", "committedDate": "2021-03-16 16:44:08 -0400", "message": "corrected few variables"}, {"oid": "a5413c85073967798ba099f45fff5f865fc5f19d", "committedDate": "2021-03-18 13:28:58 -0400", "message": "hardcoded httpRequestUrl"}, {"oid": "f1433266987581e9ac3fc684b646a3923bd9288b", "committedDate": "2021-03-19 15:12:57 -0400", "message": "- tweak datasetlock, - skip checksum validation using dataset category"}, {"oid": "3a3235451900dacd9dbf48ea33ed445f128214a1", "committedDate": "2021-03-22 08:58:01 -0400", "message": "method dropped in merge"}, {"oid": "9ca076833a8b9cda803700e9af7812b1a88257e9", "committedDate": "2021-03-24 08:44:46 -0400", "message": "make sure release user is set"}, {"oid": "6cd23a1b327f84fd649a0b802322532df92d345a", "committedDate": "2021-03-24 08:55:04 -0400", "message": "- tweak datasetlock, - skip checksum validation using dataset category"}, {"oid": "1e7fcd17d7b102bd141e94b262ee6a53b60d2f56", "committedDate": "2021-03-24 09:01:23 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "491fe42c07944db5fc4686a4699ffb1399ca9051", "committedDate": "2021-03-29 10:50:33 -0400", "message": "- delete globus permission"}, {"oid": "4b5ad664ac18165dc032ab7faeee240cf6002aa2", "committedDate": "2021-03-30 11:04:13 -0400", "message": "Assign a version if not set"}, {"oid": "a17c4bb05aa66eb375279174355bcbb79a1ad5ed", "committedDate": "2021-03-30 11:08:58 -0400", "message": "Don't call archiver directly"}, {"oid": "bc5edf0ad09ecf627cb936a5de50e19be4df34ba", "committedDate": "2021-03-30 17:38:42 -0400", "message": "- added GLOBUSUPLOADSUCCESS notification type and user notification messages - added deleteRule api -"}, {"oid": "c3b12195db2c5132f11672295e777f411eda4759", "committedDate": "2021-03-31 09:19:03 -0400", "message": "add @POST per Chris Muller"}, {"oid": "e68003191dbd06e8f34b9d52d559bee1ee081a30", "committedDate": "2021-03-31 09:44:27 -0400", "message": "Merge remote-tracking branch 'Remote/develop' into develop-globus-phase2.1"}, {"oid": "14352024df292342d644af182543e6bcb3d0690d", "committedDate": "2021-03-31 11:11:05 -0400", "message": "corrected error"}, {"oid": "c3ff22927bf27e7716b9cd5f43fb0640752303ba", "committedDate": "2021-04-01 11:40:15 -0400", "message": " api to delete globus rule and added notification"}, {"oid": "58a2317d9fb696999fc7439bbcea18d05bc2728e", "committedDate": "2021-04-01 17:27:14 -0400", "message": "handle mutliple versions, setting pub/release dates correctly"}, {"oid": "b441a15d394b0935155b3b20c8484dd44e19df0f", "committedDate": "2021-04-07 17:41:49 -0400", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "e72c4e50fca0ceb2332d6057c4c05808b1d215dc", "committedDate": "2021-04-07 17:46:25 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "12e2e6eb1de0e2223c895b1a7fbfb6b29b3d5f14", "committedDate": "2021-04-08 11:29:14 -0400", "message": "correction to verify ruleID existence, added ChecksumDatasetSizeLimit and ChecksumFileSizeLimit settings"}, {"oid": "878ef6fff6a27510b39cffb058b26afca31301c3", "committedDate": "2021-04-14 12:09:46 +0200", "message": "Merged back develop"}, {"oid": "fb2b52cf66f7cb51b5b0cee0cd298657fdd0638d", "committedDate": "2021-04-14 13:00:11 -0400", "message": "don't used deprecated Long constructor"}, {"oid": "e584d6fa0b10ad5eb1bd275abe445b554470693c", "committedDate": "2021-04-14 19:22:37 -0400", "message": "add pre-pub wf to migrate"}, {"oid": "ad48ad711049f99d17b3494fab3d923016bfc799", "committedDate": "2021-04-19 16:58:39 -0400", "message": "cleanup : removed redundant code from Phase 1"}, {"oid": "a4531f54ab2565c8015493a3bcaa1043bed6137f", "committedDate": "2021-04-20 16:55:47 -0400", "message": "update"}, {"oid": "faa944efd1a0644085555d5eae18bfad1a823e4d", "committedDate": "2021-04-26 14:49:20 -0400", "message": "mirror responses from publish command - accepted(w /wf) or ok"}, {"oid": "6fa5e904755345a8f3ae8ccea00f47d83265c726", "committedDate": "2021-05-20 11:30:51 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "f702a6188c89567592f593f96e9c7277bc0955fd", "committedDate": "2021-05-20 13:06:04 -0400", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "4fa484bfe8cc99a5330cd4291a6b86feeca333ca", "committedDate": "2021-05-25 16:29:08 -0400", "message": "api /addFiles"}, {"oid": "83b21f01362eac9b2954b3c61d02a7f4689e3f73", "committedDate": "2021-05-26 15:10:25 +0200", "message": "DD-420 multi license UI (#73)"}, {"oid": "71f6be2178ab1c236cd5f229253bb277212e08bb", "committedDate": "2021-05-26 15:23:00 +0200", "message": "Merged back develop"}, {"oid": "399e2ad1569c8ee9bb55ef17457ade2cf1e22aa3", "committedDate": "2021-05-26 17:39:05 -0400", "message": "handling exception"}, {"oid": "c0eba6d375fbff567d81e4fcfa077eeec3f5a3ec", "committedDate": "2021-05-28 14:12:36 -0400", "message": "handling exception"}, {"oid": "a24392c349afb503d1c02ec6c57c82f29d75baaf", "committedDate": "2021-05-28 14:14:15 -0400", "message": "Revert \"handling exception\""}, {"oid": "db6944774fdbdf0de4eebb9d6c0675586bc8e3c7", "committedDate": "2021-05-28 14:49:14 -0400", "message": "Refactored /addFiles"}, {"oid": "debc952527925ed540e1ffff97b0b97eb53fe436", "committedDate": "2021-05-28 15:12:15 -0400", "message": "Merge branch 'IQSS:develop' into 7900-api-toadd-multipleFiles"}, {"oid": "7dbd78d546c5e53b8312d67326276d20f49535be", "committedDate": "2021-06-03 15:21:57 +0200", "message": "Merge branch 'develop' into multi-license"}, {"oid": "60f474dec0f631735b9705cb5c0d7a714d5f57de", "committedDate": "2021-06-03 12:19:09 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "b12f881bb7408eb4eefb0f432ad30d6ca3638160", "committedDate": "2021-06-15 13:11:58 +0200", "message": "Merge pull request #88 from PaulBoon/embargo"}, {"oid": "c9750a0cb53dd216eb088481c3fa7de92495f799", "committedDate": "2021-06-23 13:00:33 -0400", "message": "initial external status label impl"}, {"oid": "19dcce1c4fda90b8f9454451ff8c9750cdf85676", "committedDate": "2021-06-23 13:06:22 -0400", "message": "typos, update errors, change regexp"}, {"oid": "044cbbc8b64033790d988b67b5e72901d3376519", "committedDate": "2021-06-23 13:06:56 -0400", "message": "allow delete, clear upon publication"}, {"oid": "ff2419b9d62095405ddc5f67e40f37fcd7b19a4c", "committedDate": "2021-06-25 12:34:30 -0400", "message": "support application/ld+json(new) application/json-ld (old/non-standard)"}, {"oid": "2c494d85b5f2906cfbd5a3727a9a358635b47815", "committedDate": "2021-06-26 21:37:25 +0200", "message": "DD-461 Implement Embargo API (#89)"}, {"oid": "249722848cd6d536e14a312e5ae8b447c8192918", "committedDate": "2021-06-30 14:42:51 +0200", "message": "Merged back develop"}, {"oid": "e1c1bfe58e64ea0ed54cbb03ad89bab209314aef", "committedDate": "2021-06-30 11:59:50 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "599504ab9a81d6766932bbdc9be69de131a09f27", "committedDate": "2021-06-30 14:15:43 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "e5d375ae87a14c0eac71c6208298334b6fdd8de7", "committedDate": "2021-07-02 09:09:34 -0400", "message": "further updates"}, {"oid": "5ca182e2830cda4ba8428907994bb1fbab37191f", "committedDate": "2021-07-06 10:49:41 -0400", "message": "Note todos"}, {"oid": "20e4360aa4ec612f5f8673fca06dfd9ab2e3f208", "committedDate": "2021-07-08 13:24:32 +0200", "message": "DD-526 create url for custom terms (#99)"}, {"oid": "792d479066a24a8623d6f1b3c4ba244deb3cb2b6", "committedDate": "2021-07-08 16:47:49 -0400", "message": "Merge remote-tracking branch 'SP/develop' into 7900-api-toadd-multipleFiles"}, {"oid": "a1f9f3ebe80dd6a20b60d1d19bb9acbd0a84713b", "committedDate": "2021-07-14 12:23:53 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "fd21968e515394812d8a7f034d46203f44537740", "committedDate": "2021-07-14 19:07:05 +0200", "message": "DD-526 create url for custom terms (#103)"}, {"oid": "19f3eac7cfd7837b45f6d22f8d8d53215354c1ad", "committedDate": "2021-07-14 20:27:51 +0200", "message": "Merge back develop (#105)"}, {"oid": "8c4d651709f53c1a79c8c570df2f05ff117a8bfa", "committedDate": "2021-07-14 17:02:09 -0400", "message": "Merge pull request #7901 from scholarsportal/7900-api-toadd-multipleFiles"}, {"oid": "30d131cfbd8fd99d8eda764e0ec6b82a61c1e354", "committedDate": "2021-07-22 15:10:31 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "a7a8f80da2d7a0252b4099f3e0834db1d6cd17fc", "committedDate": "2021-07-22 15:34:52 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into QDR/6886-external_status_labels"}, {"oid": "ac82d6f42e2232b9965e4d7df97be79db45b93b8", "committedDate": "2021-07-23 13:12:15 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "6cc86e020135c1916d26be8ecef37bbf14f4f7c6", "committedDate": "2021-07-24 11:02:47 +0200", "message": "Resolved merge conflicts"}, {"oid": "c833eb98362792296239444bdb0510be10135a38", "committedDate": "2021-07-27 15:23:28 -0400", "message": "handle version 1.0 info already set"}, {"oid": "d549f72af2ba398bbe28729b6762e5f6f6468e60", "committedDate": "2021-07-27 15:47:32 -0400", "message": "enable DOI updates"}, {"oid": "93481bd2039e7bd551752dd975c768490f29be52", "committedDate": "2021-07-27 16:10:37 -0400", "message": "cut/pasted to the wrong place"}, {"oid": "259e26d748e50f62a32f7b232978954e9b219fd4", "committedDate": "2021-07-28 12:26:28 -0400", "message": "add flag required to also update PID at provider during migrate"}, {"oid": "a7a9f8b66a30153d2f03b149fa24eb24de36ab18", "committedDate": "2021-07-28 13:19:29 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "1e6f9847149bfb4bb8b7e7f5d2d794f915f01b21", "committedDate": "2021-07-28 13:24:46 -0400", "message": "merge issue - dropped import"}, {"oid": "46b10e3f688f3d0b70233092c62a528d5cf8aa7e", "committedDate": "2021-07-29 09:10:48 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into QDR/6886-external_status_labels"}, {"oid": "7e884d76cb25171e41299b314df6769336e42de1", "committedDate": "2021-08-04 17:52:38 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "64b8b906694dc4992e4e9291dc44bb4b7f83dd25", "committedDate": "2021-08-04 18:09:42 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into QDR/6886-external_status_labels"}, {"oid": "257349a31531fc87a7f1aee0dbbae10ab945c937", "committedDate": "2021-08-04 18:16:02 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "effe3bf95c1f2b46c2047ce8c1b162be4b14f4b6", "committedDate": "2021-08-19 16:45:19 -0400", "message": "add a curation status report api call"}, {"oid": "21ff777277a49e45a8ececbd797d7f2272e7780d", "committedDate": "2021-08-24 15:26:18 -0400", "message": "Merge remote-tracking branch 'SP/develop' into develop-globus-phase2.1"}, {"oid": "60d7d0dff8f6f0063f94f44bf79080867e3ec0ae", "committedDate": "2021-09-07 17:04:17 -0400", "message": "refactor to support support addFiles api from #7901"}, {"oid": "925a1c3f3d2538a365edc8f8c23735355615e08b", "committedDate": "2021-09-10 17:22:50 +0200", "message": "DD-573 Implement set license in semantic api (#113)"}, {"oid": "b001bf137f9440251a739369dde27b7c258ad472", "committedDate": "2021-09-10 17:39:39 +0200", "message": "Merged back develop"}, {"oid": "eade0066585b3511ccb9adbc1cea1d1f4d8caf37", "committedDate": "2021-09-21 12:50:19 -0400", "message": "add apis and docs"}, {"oid": "10996d679b08c8933d5c20d25a9ff9ae7b30788d", "committedDate": "2021-09-21 13:08:08 -0400", "message": "cleanup"}, {"oid": "d266bb31169f22576620002b716c6c918191faaa", "committedDate": "2021-09-21 14:27:23 -0400", "message": "make role reporting generic"}, {"oid": "56fd065a1675449925d0426558aa007bf0a299e7", "committedDate": "2021-09-21 14:37:57 -0400", "message": "style fixes"}, {"oid": "8f8531a23b5156f0093e32272ed683c692e27f7f", "committedDate": "2021-09-27 16:32:36 -0400", "message": "Revert \"style fixes\""}, {"oid": "20cf55d5d7603145ddc40caf6b9d0631ccdefd6a", "committedDate": "2021-09-27 16:42:33 -0400", "message": "cleanup"}, {"oid": "38b8baa6c3b0f5d3878037c506d6f055380385a0", "committedDate": "2021-09-29 15:28:46 -0400", "message": "addressing review feedback"}, {"oid": "a79ce03e58b5110b28f7b4981b50568e01499177", "committedDate": "2021-10-04 12:50:30 -0400", "message": "Fix PUT curationSetLabel and test"}, {"oid": "fae74755535964a4f8d87f46a14f454cf8d544a5", "committedDate": "2021-10-06 17:36:13 +0200", "message": "implemented change requests"}, {"oid": "c72c57ac2b225b614824d4a5ffc4bed467d73a8b", "committedDate": "2021-10-06 17:16:20 -0400", "message": "merge needed for put/delete"}, {"oid": "cc8e14604636b856e514bc80cc22002d8322b35f", "committedDate": "2021-10-07 13:47:45 -0400", "message": "don't need to be super to get allowed curation labels in set"}, {"oid": "0b617f64ce3a90acc5565be92a2f533aa0bdb305", "committedDate": "2021-10-07 13:56:05 -0400", "message": "add permission check"}, {"oid": "10e8bc457d7a03e87a3ed047473dd1f42f2b9044", "committedDate": "2021-10-07 14:13:06 -0400", "message": "fix concatenation"}, {"oid": "0b681218a4fde3fc59a9d3874ccf4ea15f8a9ec5", "committedDate": "2021-10-07 14:14:57 -0400", "message": "fix null for no label"}, {"oid": "392a88f9d88738605990a2cfaccf1809d2bc3ae8", "committedDate": "2021-10-13 11:42:19 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "c719a880e8b6300acdd4c7a993df75e2350bd69e", "committedDate": "2021-10-13 11:45:01 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "b7c622637c7e9f1e3736f420f831032b8c7f2ca8", "committedDate": "2021-10-19 09:18:59 -0400", "message": "update api"}, {"oid": "1d635a71e077566b348617f4b69bccfa0dc819af", "committedDate": "2021-10-19 10:41:05 -0400", "message": "fix unset - check perm on dataset not its owner"}, {"oid": "5b97725c6a3523298e4463eb55aa9dd8dc3a48e7", "committedDate": "2021-10-19 12:19:06 -0400", "message": "old logic - only check released and ! superuser"}, {"oid": "980839bb8d308bd0561b46acb7b3a64d95a86a09", "committedDate": "2021-10-21 08:30:07 -0400", "message": "avoid NPE in embargo tracking"}, {"oid": "d2c61b343fcdfbcba5590b18b89f0ed976ee147a", "committedDate": "2021-10-22 16:30:54 +0200", "message": "Merged back develop"}, {"oid": "ec1313056ada36b4d66da2938c1273c6b8d5e72b", "committedDate": "2021-10-25 18:01:42 -0400", "message": "changing action logging to include userIdentifier"}, {"oid": "4808c302691ac6b828cdf54189e131a7f86eeb72", "committedDate": "2021-10-25 18:38:19 -0400", "message": "handle null, update user id used, change actiontype for create/delete"}, {"oid": "f994923879e5eb5b9404c8c9eb3d77e613eea0fd", "committedDate": "2021-11-09 09:03:54 +0100", "message": "Merged back develop"}, {"oid": "8026778c742f6d6be71a6161907fe62eca061415", "committedDate": "2021-12-15 15:37:37 -0500", "message": "#8191 fix tests and update query"}, {"oid": "c10530ce764d5c67267958970dd6d9196e9a37ef", "committedDate": "2022-01-10 16:52:38 -0500", "message": "refactor to add license package"}, {"oid": "b6d170ba3dddf92f3b191cf92a8d391fe802c9ab", "committedDate": "2022-01-10 16:58:56 -0500", "message": "fix/simplify refactor"}, {"oid": "663bde9c9059c3d964d1e52fc5a577b45383ac1c", "committedDate": "2022-01-11 13:31:20 -0500", "message": "braces for if, reformat method"}, {"oid": "16d03003488998ae5e64cb80f0a94e8bb5cf6961", "committedDate": "2022-01-24 15:14:41 -0500", "message": "prevents the file upload api from defaulting to \"text/plain\" for the mime type, when no Content-Type: header is found in the incoming data part. (#8344)"}, {"oid": "76bfee2b0930ed58f13e6d11b17af95e1f0c51ca", "committedDate": "2022-01-25 17:45:28 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "8f596531cf0e1ec6583e89a5d96ccff38dbe46a4", "committedDate": "2022-02-02 13:44:09 -0500", "message": "Merge branch 'develop' into 8344-file-upload-default-mime"}, {"oid": "bbc7e32e411db172f7096d347419b5b05bcfdc76", "committedDate": "2022-02-02 14:01:40 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "70ea695d41f7cc579dbfe814918d207b4ee980a2", "committedDate": "2022-02-03 10:31:17 -0500", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "e3bdb52c99f2ce584e739dcfed9747b77e0dea07", "committedDate": "2022-02-03 12:35:45 -0500", "message": "Merge branch 'develop' into develop-globus-phase2.1"}, {"oid": "963d2990892db55cf24027c9134feb9f97d4ccae", "committedDate": "2022-02-03 13:13:05 -0500", "message": "Merge remote-tracking branch 'origin/develop' into develop-globus-phase2.1"}, {"oid": "a7ec3bf2a34196ca18bd265fee3f6960b0ac45d3", "committedDate": "2022-02-03 13:23:21 -0500", "message": "Merge branch 'develop' into develop-globus-phase2.1"}, {"oid": "5feb2c178c55aaaf4af6bc0bdc5e5bb519e822d7", "committedDate": "2022-02-03 16:11:12 -0500", "message": "- removed old method"}, {"oid": "acb2ec32f5dd54f764d11fc0c8201dd327d4bac1", "committedDate": "2022-02-16 10:46:42 -0500", "message": "Basic framework for a lock-listing API. Work in progress, lots to figure out/finalize. (IQSS/dataverse.harvard.edu#135)"}, {"oid": "ef636435efe8c6737597da1e8dbce89f36b5d6e8", "committedDate": "2022-02-18 20:51:07 -0500", "message": "Expanding the locks API to list locks installation-wide, across all datasets. (IQSS/dataverse.harvard.edu#135)"}, {"oid": "0905ad38ea61a00179af4d2022fbe365e3375ab8", "committedDate": "2022-02-23 14:51:19 -0500", "message": "minor/cosmetic. IQSS/dataverse.harvard.edu#135"}, {"oid": "29e0dc4595c5cf872f8a314148ef1963d94990f1", "committedDate": "2022-02-24 14:24:03 -0500", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "8698f786181d6a941adaecc261c95418427c3e08", "committedDate": "2022-03-03 11:12:44 -0500", "message": "Merge branch 'develop' into 8344-file-upload-default-mime"}, {"oid": "6a1333dbdd07d30bc6833b1bedee7c0faad4434e", "committedDate": "2022-03-08 22:35:08 -0500", "message": "replace another Strings.join"}, {"oid": "e8be11588f76659cb9b2eba829bcfb61d81b7ca4", "committedDate": "2022-03-09 09:31:17 -0500", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "b78075c0ffd6f449f3984e94e6e6ae50687d5441", "committedDate": "2022-03-15 17:11:29 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "cc763f8fccc0acfe3d55ae24cbe75e2bd9c8fffa", "committedDate": "2022-03-21 15:37:48 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "51b743e0cc54018f5911440e8f4653ec1814a140", "committedDate": "2022-04-12 13:27:53 -0400", "message": "protect against null TermsOfUseAndAccess"}, {"oid": "231a15f78d20016dfa0f2f798d4fb55de20163a6", "committedDate": "2022-04-12 14:48:50 -0400", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "4504e001b02a30ed599f03a7f8aff635c3bbd633", "committedDate": "2022-04-14 09:18:36 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "5a823ab64163627d3b6e6814eee9f59bfd79efa5", "committedDate": "2022-04-14 13:06:46 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "b846a9670fd25294ecc80c02c4331c88430c00da", "committedDate": "2022-04-26 12:56:52 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "adca68b7255e7c082030542c3430479737411062", "committedDate": "2022-04-27 11:25:35 -0400", "message": "Merge branch 'IQSS/7324_TRSA-HTTP-store' into GDCC/DC-1"}, {"oid": "c5246d28e972c897f1318707b8ba4100d2e2cd28", "committedDate": "2022-04-29 09:25:17 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "7b68d57295853c0dca32cfc0f7fa51bb4be0f6e1", "committedDate": "2022-04-29 09:27:33 -0400", "message": "Refactor to RemoteOverlay, use constants for store types/sep"}, {"oid": "6f1f543063f916ffa3eeda2354286a99499cc0a6", "committedDate": "2022-04-29 17:57:06 -0400", "message": "Merge branch 'IQSS/7324_TRSA-HTTP-store' into GDCC/DC-1"}, {"oid": "de627912c50400cd8f2c412c1e453b70d67a22b0", "committedDate": "2022-05-13 14:51:53 -0400", "message": "Archival status success/pending/failure/null support"}, {"oid": "dcd5034b59f1d2a9e40f4139053e2353be2c6fde", "committedDate": "2022-05-26 15:51:14 -0400", "message": "single-version semantics for archiving"}, {"oid": "cdaa28b4104c285d905441a9c97a9f6a53ff8446", "committedDate": "2022-06-24 10:06:04 -0400", "message": "move globus calls to globus bean, doc Lock issue, cleaunup"}, {"oid": "9223e7df02f9f829a0e333247971e57706803aa7", "committedDate": "2022-07-15 17:21:48 -0400", "message": "updates per review"}, {"oid": "7362e1c82086bed520007d2bc13eb59695e0115f", "committedDate": "2022-07-19 16:49:39 -0400", "message": "lower logging #8605"}, {"oid": "778e78021ba65bf47eb0c81d2e6f38e00dfa9c5b", "committedDate": "2022-07-20 13:11:00 -0400", "message": "Merge branch 'GDCC/8605-add-archival-status' into GDCC/8746-single-version-semantics_for_archiving"}, {"oid": "c74f9b68cb719abe669be63024b3419fc9678d9e", "committedDate": "2022-07-20 13:19:26 -0400", "message": "handle name and dataset/version changes from 8696 review"}, {"oid": "9aa7dd07d756e746373711ea26d9ee4106f730bb", "committedDate": "2022-07-21 19:52:29 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "c1fa462f5f43a6a668a4e7f62ee3a70fd05fb342", "committedDate": "2022-07-25 14:22:50 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "4441795e461b67a433fb205b1a17f143ad8866e3", "committedDate": "2022-07-25 14:47:21 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "ff8eec0f1d4ec44f8ef83d66562f6105ce532656", "committedDate": "2022-07-28 17:19:51 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "abd392319709024396e3f0a546b7239e7ae66953", "committedDate": "2022-07-29 13:06:01 -0400", "message": "updates for archival status (missed/lost)"}, {"oid": "bcad012f43d0be25dc8cf50ee76dbe06b68b23b9", "committedDate": "2022-08-02 15:51:44 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "97644428369109cb9693b8b04327d516c7668779", "committedDate": "2022-08-03 14:00:19 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC1"}, {"oid": "c6e362cabdb62f126d66955056ac7fad7c45bbe9", "committedDate": "2022-08-05 16:28:46 -0400", "message": "per reviewDog"}, {"oid": "ea6ee80a681549fe800b026bde7c091a1dd51e79", "committedDate": "2022-08-08 16:07:03 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "504ca17bdbb459614236ec893ddeead73a2357d1", "committedDate": "2022-08-09 14:25:45 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "0fd56cf2be9ff2e5a1331605fb038f2488cc461c", "committedDate": "2022-08-09 14:34:42 -0400", "message": "minor error meg and comment changes"}, {"oid": "80bd84d5560354534be164d5825a9b7225af1034", "committedDate": "2022-08-12 10:51:44 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "3558a0bb33a5fa5d4c819515f579ff7f2b0d8b9e", "committedDate": "2022-08-12 17:59:08 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "7f990dc776e0b6723eeb5afbf10359129c19a560", "committedDate": "2022-08-16 14:27:00 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "643b9242ff8f658c88192858f6c41ac480b0272c", "committedDate": "2022-08-17 10:11:27 -0400", "message": "add checking w.r.t. dataset storage driver/base driver"}, {"oid": "ff2f137d6f6da08026241fcbd21e5923d08ada1b", "committedDate": "2022-08-17 12:36:57 -0400", "message": "Merge branch 'IQSS/7324_TRSA-HTTP-store' into GDCC/DC-1"}, {"oid": "3ada97f7e511d721cb330ab78e3bd47fcab18747", "committedDate": "2022-08-18 17:56:53 -0400", "message": "strip any html from archival status"}, {"oid": "9fa0561e52ed726287f8dcded98486b109623ca4", "committedDate": "2022-08-29 14:53:22 -0400", "message": "#8859 add conflict response status"}, {"oid": "45dfdfa3520cb47af3defc7644c912f3067800f0", "committedDate": "2022-08-31 14:32:47 -0400", "message": "#8859 add comments; clean up test"}, {"oid": "0909f7e0c89d4c13335f6c637575363f6b9ae790", "committedDate": "2022-09-02 10:46:15 -0400", "message": "return 400 for bad JSON"}, {"oid": "25ae68ca4cf0c7789c6aa3083e1bb06e32cbda11", "committedDate": "2022-09-06 10:59:14 -0400", "message": "Merge branch 'develop' into 8859-update-api-error-msg"}, {"oid": "04869dbb4f249724a89f3553c4f044fab29e8668", "committedDate": "2022-09-07 16:16:08 -0400", "message": "typos (test Jenkins) #8859"}, {"oid": "37a9c50779d689cc94da14b3c00ec6161751d27f", "committedDate": "2022-09-08 16:14:36 -0400", "message": "#8859 check for valid terms prior to embargo"}, {"oid": "5e79f049fc6635ff5b3ae1a214e58b4bb4e33f4e", "committedDate": "2022-09-14 13:51:18 -0400", "message": "Merge branch 'develop' into GDCC/DC-1 #8891"}, {"oid": "4e0e884615d9076e30e65b55d0c8a1b381e7bb99", "committedDate": "2022-09-19 15:34:03 -0400", "message": "#8859 resolve conflict"}, {"oid": "9f23b6aa042cd2e703b5022e3c022edcdd86ff78", "committedDate": "2022-09-21 11:14:14 -0400", "message": "#8859 update api message prior to command; update tests"}, {"oid": "a413a13f3a04c2dca2e2c39d80791f1cf47a939a", "committedDate": "2022-09-27 12:52:06 -0400", "message": "add tool callback methods for dataset and datafile"}, {"oid": "e06ec36b2a4a78e8c64e42858542faaccf62841b", "committedDate": "2022-09-30 10:04:55 -0400", "message": "Add /replaceFiles call"}, {"oid": "b59f4835074518fc8374e4f86b4a8f36dc3ccb58", "committedDate": "2022-10-06 11:40:51 +0200", "message": "dataset files cleanup"}, {"oid": "c80a06f38b679641d80a05b5215106006da52667", "committedDate": "2022-10-28 18:07:07 -0400", "message": "fix for cvv and editMetadata replace=true, and test"}, {"oid": "9ba760d67456cfebc369d7f7d83e2d2dc7f3c505", "committedDate": "2022-11-04 18:23:16 +0100", "message": "replaced listAllFiles and deleteFile with cleanUp in the StorageIO interface"}, {"oid": "00170695b920c2f5accdeb1cdcb367b6c892ab1b", "committedDate": "2022-11-04 18:34:28 +0100", "message": "better filter for files to delete"}, {"oid": "f0ac872828d3a48cf74e74052ae1b3767afb264a", "committedDate": "2022-11-07 13:59:16 +0100", "message": "updated filter: exlude export files"}, {"oid": "bcaeb9fd58f38fdcd8cc1587e763a80c17b55048", "committedDate": "2022-11-07 14:05:35 +0100", "message": "bugfix in filter"}, {"oid": "503b9a36ca409e4bf89659cc877b62415d4ef33a", "committedDate": "2022-11-07 14:06:35 +0100", "message": "added dryrun query parameter"}, {"oid": "4b0d36596835333bf5c528e3659b8a5bbef5ed60", "committedDate": "2022-11-07 14:10:25 -0500", "message": "rename getEditVersion to getOrCreateEditVersion #8930"}, {"oid": "559e5c5aa7acc885064001fb6c93871bb2df3296", "committedDate": "2022-11-10 13:48:51 -0500", "message": "Merge branch 'develop' into 7715-signed-urls-for-external-tools #7715"}, {"oid": "fbf7190f193fb5d65dc6c100d7bb6c2d62dd1b0e", "committedDate": "2022-11-23 09:45:40 -0500", "message": "Improved error handling per QA"}, {"oid": "398fd4819f74241a0db3a458b74515f7688aacce", "committedDate": "2022-11-28 14:00:57 -0500", "message": "Improve error handling"}, {"oid": "120adc18a8b02d4fcf18c4dd9ef557f529de1ae9", "committedDate": "2022-12-07 17:38:06 -0500", "message": "Merge pull request #9107 from GlobalDataverseCommunityConsortium/GDCC/9106-fix_editMetadata_api_when_replace_is_true"}, {"oid": "233926e4cff9bd24d2af90e86391b77b147b42b9", "committedDate": "2022-12-13 12:48:18 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/9005-replaceFiles_api_call"}, {"oid": "f7e9b1baddb71ca0bab16380446fd0b6113d73f1", "committedDate": "2023-01-23 10:19:39 +0100", "message": "Merge branch 'develop' of https://github.com/IQSS/dataverse into dataset_files_cleanup"}, {"oid": "aab0f2ab4ef87fdd46f70e0c5de1870ccccd55b0", "committedDate": "2023-01-23 10:27:03 +0100", "message": "simplified for loop: loop directly on DataFiles of dataset, not over each version separately"}, {"oid": "d4d69b70ede07d5ab04deb5004157dd1522ed413", "committedDate": "2023-01-23 10:59:33 +0000", "message": "Refactor: deleteDataset endpoint uses AuthFilter instead of findUserOrDie"}, {"oid": "a5b27c2e2fa78aa9cb5d37742d131cf81765964c", "committedDate": "2023-01-23 11:14:13 +0000", "message": "Refactor: new AbstractApiBean method for retrieving user from ContainerRequestContext"}, {"oid": "360b73819df4028a9fbcd1bc914ab90720f334da", "committedDate": "2023-01-23 12:35:49 +0100", "message": "clean up files made safer"}, {"oid": "cf57f1427a43c89c6729be92b207a14111327307", "committedDate": "2023-01-23 11:42:14 +0000", "message": "Refactor: all Datasets API findUserOrDie calls replaced by AuthFilter"}, {"oid": "17653b3f35d6db3245e7059c000293c19f20307a", "committedDate": "2023-01-23 11:51:46 +0000", "message": "Fixed: missing AuthFilter setup for Datasets getVersionJsonLDMetadata endpoint call"}, {"oid": "219beedec339e204952906a88e608c25f832a372", "committedDate": "2023-01-24 13:45:20 +0000", "message": "Refactor: from findAuthenticatedUserOrDie to AuthFilter"}, {"oid": "e895445f46467f4997c3a90ee3df3f8e47c1071b", "committedDate": "2023-01-25 12:41:10 +0100", "message": "removed split limit when splitting the storage identifier"}, {"oid": "222b56a15e146429def111cfd766219d04d529d5", "committedDate": "2023-01-25 12:43:51 +0100", "message": "legacy files generate only a warning now, no error is returned"}, {"oid": "de6beffa71c36fc10017de6f7f615089eddf7f19", "committedDate": "2023-01-26 11:20:24 +0000", "message": "Refactor: new response method within AbstractApiBean for handling user requests by handling filter-comming user instead of findUserOrDie method"}, {"oid": "b00deeab20830d991e196f0d53f069c7aed826f7", "committedDate": "2023-01-27 10:54:47 +0000", "message": "Refactor: using ApiConstants in all places for common API statuses"}, {"oid": "353aad9d77674ebe647a531c3d04c8f676eefe99", "committedDate": "2023-01-30 10:50:16 +0100", "message": "Merge branch 'develop' into 9293-filter-api-auth"}, {"oid": "08cefe392fb8c03ed9407a4d4b5b5828fa03e560", "committedDate": "2023-01-31 11:18:32 +0100", "message": "Refactor: using new filter-based auth on missing dataset endpoint"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NDMyNw==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r662574327", "body": "Same. Delete or set to fine.", "bodyText": "Same. Delete or set to fine.", "bodyHTML": "<p dir=\"auto\">Same. Delete or set to fine.</p>", "author": "pdurbin", "createdAt": "2021-07-01T20:31:41Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Datasets.java", "diffHunk": "@@ -651,6 +651,96 @@ public Response updateDraftVersion( String jsonBody, @PathParam(\"id\") String id,\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");", "originalCommit": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzY2NA==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r663167664", "bodyText": "removed", "author": "qqmyers", "createdAt": "2021-07-02T17:46:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NDMyNw=="}], "type": "inlineReview", "revised_code": {"commit": "1d54c68fe4b515e56fee490a302cd8464d278d2d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 608d9554f6..645b3cc835 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -714,14 +714,12 @@ public class Datasets extends AbstractApiBean {\n     @Path(\"{id}/metadata/delete\")\n     @Consumes(\"application/ld+json, application/json-ld\")\n     public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n         try {\n             Dataset ds = findDatasetOrDie(id);\n             DataverseRequest req = createDataverseRequest(findUserOrDie());\n             DatasetVersion dsv = ds.getEditVersion();\n             boolean updateDraft = ds.getLatestVersion().isDraft();\n             dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n             DatasetVersion managedVersion;\n             if (updateDraft) {\n                 Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n", "next_change": null}]}, "revised_code_in_main": {"commit": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 608d9554f6..645b3cc835 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -714,14 +714,12 @@ public class Datasets extends AbstractApiBean {\n     @Path(\"{id}/metadata/delete\")\n     @Consumes(\"application/ld+json, application/json-ld\")\n     public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n         try {\n             Dataset ds = findDatasetOrDie(id);\n             DataverseRequest req = createDataverseRequest(findUserOrDie());\n             DatasetVersion dsv = ds.getEditVersion();\n             boolean updateDraft = ds.getLatestVersion().isDraft();\n             dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n             DatasetVersion managedVersion;\n             if (updateDraft) {\n                 Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n", "next_change": {"commit": "00d53ee4d43fd49a81faa1f31b9b0c6a1cad8b46", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 645b3cc835..7fd3b1ab63 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -651,94 +609,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "b45336c95ecbcee28b88a5b334c2180c86eb63fc", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 7fd3b1ab63..20874f7065 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -610,6 +611,38 @@ public class Datasets extends AbstractApiBean {\n         }\n     }\n     \n+\t@PUT\n+\t@Path(\"{id}/versions/{versionId}/metadata\")\n+\t@Consumes(\"application/json-ld\")\n+\tpublic Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id,\n+\t\t\t@PathParam(\"versionId\") String versionId, @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+\t\tif (!\":draft\".equals(versionId)) {\n+\t\t\treturn error(Response.Status.BAD_REQUEST, \"Only the :draft version can be updated\");\n+\t\t}\n+\t\ttry {\n+\t\t\tDataset ds = findDatasetOrDie(id);\n+\t\t\tDataverseRequest req = createDataverseRequest(findUserOrDie());\n+\t\t\tDatasetVersion dsv = ds.getEditVersion();\n+\t\t\tboolean updateDraft = ds.getLatestVersion().isDraft();\n+\t\t\tdsv = JSONLDUtil.updateDatasetVersionFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms);\n+\t\t\t\n+\t\t\tDatasetVersion managedVersion;\n+\t\t\tif (updateDraft) {\n+\t\t\t\tDataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+\t\t\t\tmanagedVersion = managedDataset.getEditVersion();\n+\t\t\t} else {\n+\t\t\t\tmanagedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+\t\t\t}\n+\t\t\tString info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+\t\t\treturn ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+\t\t} catch (WrappedResponse ex) {\n+\t\t\treturn ex.getResponse();\n+\n+\t\t}\n+\t}\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "6d537ce15b5989abb1bacd85a48ae17b447cd1cd", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 20874f7065..a376e663e9 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -639,7 +641,9 @@ public class Datasets extends AbstractApiBean {\n \n \t\t} catch (WrappedResponse ex) {\n \t\t\treturn ex.getResponse();\n-\n+\t\t} catch (JsonParsingException jpe) {\n+\t\t    logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n \t\t}\n \t}\n     \n", "next_change": {"commit": "24cfcfa08257d9245b2d6f033c679e59c4424316", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a376e663e9..8b9118741b 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -640,9 +696,11 @@ public class Datasets extends AbstractApiBean {\n \t\t\treturn ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n \t\t} catch (WrappedResponse ex) {\n+\t\t    ex.printStackTrace();\n \t\t\treturn ex.getResponse();\n \t\t} catch (JsonParsingException jpe) {\n \t\t    logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+\t\t    jpe.printStackTrace();\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n \t\t}\n \t}\n", "next_change": {"commit": "38a1d38f37f8ef0d9d75db51a5b6707f58fb8227", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8b9118741b..1db28d5dcc 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -614,96 +615,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-\t@PUT\n-\t@Path(\"{id}/metadata/delete\")\n-\t@Consumes(\"application/json-ld\")\n-\tpublic Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-\t\ttry {\n-\t\t\tDataset ds = findDatasetOrDie(id);\n-\t\t\tDataverseRequest req = createDataverseRequest(findUserOrDie());\n-\t\t\tDatasetVersion dsv = ds.getEditVersion();\n-\t\t\tboolean updateDraft = ds.getLatestVersion().isDraft();\n-\t\t\tdsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-\t\t\tlogger.info(\"Updating ver\");\n-\t\t\tDatasetVersion managedVersion;\n-\t\t\tif (updateDraft) {\n-\t\t\t\tDataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-\t\t\t\tmanagedVersion = managedDataset.getEditVersion();\n-\t\t\t} else {\n-\t\t\t\tmanagedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-\t\t\t}\n-\t\t\tString info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-\t\t\treturn ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-\t\t} catch (WrappedResponse ex) {\n-\t\t    ex.printStackTrace();\n-\t\t\treturn ex.getResponse();\n-\t\t} catch (JsonParsingException jpe) {\n-\t\t    logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-\t\t    jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-\t\t}\n-\t}\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "5305e759e7e20774e3a435936a3ea2009bf1d058", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 1db28d5dcc..9eb82996de 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -615,6 +647,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "2fa243abe63c60b07a714070acd4a62d5c8d6e96", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9eb82996de..c2854b33e2 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -636,108 +644,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "99a1ecff4a08f72f8f01c4eb171424795009c8c5", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex c2854b33e2..8836eb62e4 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,18 +652,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n-\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n         } catch (WrappedResponse ex) {\n             return ex.getResponse();\n-\n+            \n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "3a3235451900dacd9dbf48ea33ed445f128214a1", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8836eb62e4..777627437d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,6 +651,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "6cd23a1b327f84fd649a0b802322532df92d345a", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 777627437d..afeb10e304 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -651,96 +663,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "1e7fcd17d7b102bd141e94b262ee6a53b60d2f56", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex afeb10e304..c2cb940901 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,6 +655,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "491fe42c07944db5fc4686a4699ffb1399ca9051", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex c2cb940901..be46a5fab3 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -655,96 +663,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "4b5ad664ac18165dc032ab7faeee240cf6002aa2", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex be46a5fab3..9457397345 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,6 +655,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "bc5edf0ad09ecf627cb936a5de50e19be4df34ba", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9457397345..b328877e14 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,108 +653,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c3b12195db2c5132f11672295e777f411eda4759", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex b328877e14..459de504c1 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -653,18 +644,108 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+            \n+        }\n+    }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n \n         } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n             return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "e68003191dbd06e8f34b9d52d559bee1ee081a30", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 459de504c1..a63a86a258 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,108 +653,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "58a2317d9fb696999fc7439bbcea18d05bc2728e", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a63a86a258..a6ae292dc5 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -653,18 +647,108 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+            \n+        }\n+    }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n \n         } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n             return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "e72c4e50fca0ceb2332d6057c4c05808b1d215dc", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a6ae292dc5..6183032124 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -658,96 +648,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "12e2e6eb1de0e2223c895b1a7fbfb6b29b3d5f14", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 6183032124..ca6425fc73 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -637,18 +644,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+\n         } catch (WrappedResponse ex) {\n             return ex.getResponse();\n-            \n+\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "878ef6fff6a27510b39cffb058b26afca31301c3", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ca6425fc73..1586576697 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,18 +637,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n-\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n         } catch (WrappedResponse ex) {\n             return ex.getResponse();\n-\n+            \n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "fb2b52cf66f7cb51b5b0cee0cd298657fdd0638d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 1586576697..51728242d3 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -648,6 +653,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "ad48ad711049f99d17b3494fab3d923016bfc799", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 51728242d3..f56674cb35 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -642,108 +644,18 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok( json(managedVersion) );\n-                    \n+            return ok(json(managedVersion));\n+\n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n-            \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-            \n-        }\n-    }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n+            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n \n         } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n             return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "faa944efd1a0644085555d5eae18bfad1a823e4d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex f56674cb35..daad72b2df 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -644,18 +651,108 @@ public class Datasets extends AbstractApiBean {\n //            DatasetVersion managedVersion = execCommand( updateDraft\n //                                                             ? new UpdateDatasetVersionCommand(req, incomingVersion)\n //                                                             : new CreateDatasetVersionCommand(req, ds, incomingVersion));\n-            return ok(json(managedVersion));\n-\n+            return ok( json(managedVersion) );\n+                    \n         } catch (JsonParseException ex) {\n             logger.log(Level.SEVERE, \"Semantic error parsing dataset version Json: \" + ex.getMessage(), ex);\n-            return error(Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage());\n+            return error( Response.Status.BAD_REQUEST, \"Error parsing dataset version: \" + ex.getMessage() );\n+            \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+            \n+        }\n+    }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n \n         } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n             return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n \n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "6fa5e904755345a8f3ae8ccea00f47d83265c726", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex daad72b2df..e0e6dd2fcb 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -662,96 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "f702a6188c89567592f593f96e9c7277bc0955fd", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex e0e6dd2fcb..8d56742b9f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +663,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "4fa484bfe8cc99a5330cd4291a6b86feeca333ca", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8d56742b9f..eacc00a456 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,96 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "60f474dec0f631735b9705cb5c0d7a714d5f57de", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex eacc00a456..3ecd785257 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +663,96 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        logger.info(\"In delteMetadata\");\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            logger.info(\"Updating ver\");\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "b12f881bb7408eb4eefb0f432ad30d6ca3638160", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 3ecd785257..226b409207 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,96 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        logger.info(\"In delteMetadata\");\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            logger.info(\"Updating ver\");\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "ff2419b9d62095405ddc5f67e40f37fcd7b19a4c", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 226b409207..0a86d8b67f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +663,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "2c494d85b5f2906cfbd5a3727a9a358635b47815", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 0a86d8b67f..4a1c96ea8e 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -663,94 +617,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "e1c1bfe58e64ea0ed54cbb03ad89bab209314aef", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 4a1c96ea8e..549647df69 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -617,6 +664,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "599504ab9a81d6766932bbdc9be69de131a09f27", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 549647df69..bef945554c 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -664,94 +619,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "a1f9f3ebe80dd6a20b60d1d19bb9acbd0a84713b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex bef945554c..b63b115a08 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -619,6 +620,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+  \n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+            \n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+            \n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+    \n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "fd21968e515394812d8a7f034d46203f44537740", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex b63b115a08..27fbf8661f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -620,94 +649,6 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n-  \n-    @GET\n-    @Path(\"{id}/versions/{versionId}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        try {\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n-            OREMap ore = new OREMap(dsv,\n-                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n-            return ok(ore.getOREMapBuilder(true));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (Exception jpe) {\n-            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n-            jpe.printStackTrace();\n-            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n-        }\n-    }\n-\n-    @GET\n-    @Path(\"{id}/metadata\")\n-    @Produces(\"application/ld+json, application/json-ld\")\n-    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n-        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n-    }\n-            \n-    @PUT\n-    @Path(\"{id}/metadata\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n-\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n-            \n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n-    \n-    @PUT\n-    @Path(\"{id}/metadata/delete\")\n-    @Consumes(\"application/ld+json, application/json-ld\")\n-    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n-        try {\n-            Dataset ds = findDatasetOrDie(id);\n-            DataverseRequest req = createDataverseRequest(findUserOrDie());\n-            DatasetVersion dsv = ds.getEditVersion();\n-            boolean updateDraft = ds.getLatestVersion().isDraft();\n-            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n-            DatasetVersion managedVersion;\n-            if (updateDraft) {\n-                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n-                managedVersion = managedDataset.getEditVersion();\n-            } else {\n-                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n-            }\n-            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n-            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n-\n-        } catch (WrappedResponse ex) {\n-            ex.printStackTrace();\n-            return ex.getResponse();\n-        } catch (JsonParsingException jpe) {\n-            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n-            jpe.printStackTrace();\n-            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n-        }\n-    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "19f3eac7cfd7837b45f6d22f8d8d53215354c1ad", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 27fbf8661f..b32908a303 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -649,6 +659,94 @@ public class Datasets extends AbstractApiBean {\n             \n         }\n     }\n+\n+    @GET\n+    @Path(\"{id}/versions/{versionId}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @PathParam(\"versionId\") String versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        try {\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = getDatasetVersionOrDie(req, versionId, findDatasetOrDie(id), uriInfo, headers);\n+            OREMap ore = new OREMap(dsv,\n+                    settingsService.isTrueForKey(SettingsServiceBean.Key.ExcludeEmailFromExport, false));\n+            return ok(ore.getOREMapBuilder(true));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (Exception jpe) {\n+            logger.log(Level.SEVERE, \"Error getting jsonld metadata for dsv: \", jpe.getLocalizedMessage());\n+            jpe.printStackTrace();\n+            return error(Response.Status.INTERNAL_SERVER_ERROR, jpe.getLocalizedMessage());\n+        }\n+    }\n+\n+    @GET\n+    @Path(\"{id}/metadata\")\n+    @Produces(\"application/ld+json, application/json-ld\")\n+    public Response getVersionJsonLDMetadata(@PathParam(\"id\") String id, @Context UriInfo uriInfo, @Context HttpHeaders headers) {\n+        return getVersionJsonLDMetadata(id, \":draft\", uriInfo, headers);\n+    }\n+\n+    @PUT\n+    @Path(\"{id}/metadata\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response updateVersionMetadata(String jsonLDBody, @PathParam(\"id\") String id, @DefaultValue(\"false\") @QueryParam(\"replace\") boolean replaceTerms) {\n+\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.updateDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc, !replaceTerms, false);\n+\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n+\n+    @PUT\n+    @Path(\"{id}/metadata/delete\")\n+    @Consumes(\"application/ld+json, application/json-ld\")\n+    public Response deleteMetadata(String jsonLDBody, @PathParam(\"id\") String id) {\n+        try {\n+            Dataset ds = findDatasetOrDie(id);\n+            DataverseRequest req = createDataverseRequest(findUserOrDie());\n+            DatasetVersion dsv = ds.getEditVersion();\n+            boolean updateDraft = ds.getLatestVersion().isDraft();\n+            dsv = JSONLDUtil.deleteDatasetVersionMDFromJsonLD(dsv, jsonLDBody, metadataBlockService, datasetFieldSvc);\n+            DatasetVersion managedVersion;\n+            if (updateDraft) {\n+                Dataset managedDataset = execCommand(new UpdateDatasetVersionCommand(ds, req));\n+                managedVersion = managedDataset.getEditVersion();\n+            } else {\n+                managedVersion = execCommand(new CreateDatasetVersionCommand(req, ds, dsv));\n+            }\n+            String info = updateDraft ? \"Version Updated\" : \"Version Created\";\n+            return ok(Json.createObjectBuilder().add(info, managedVersion.getVersionDate()));\n+\n+        } catch (WrappedResponse ex) {\n+            ex.printStackTrace();\n+            return ex.getResponse();\n+        } catch (JsonParsingException jpe) {\n+            logger.log(Level.SEVERE, \"Error parsing dataset json. Json: {0}\", jsonLDBody);\n+            jpe.printStackTrace();\n+            return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n+        }\n+    }\n     \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n", "next_change": {"commit": "6cc86e020135c1916d26be8ecef37bbf14f4f7c6", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex b32908a303..9ea7e4b27f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -747,7 +747,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c833eb98362792296239444bdb0510be10135a38", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9ea7e4b27f..348323b49d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -747,7 +752,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "21ff777277a49e45a8ececbd797d7f2272e7780d", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 348323b49d..75e81efdba 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -752,7 +767,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "60d7d0dff8f6f0063f94f44bf79080867e3ec0ae", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 75e81efdba..ddb3cf489d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -767,7 +752,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "925a1c3f3d2538a365edc8f8c23735355615e08b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ddb3cf489d..9f86649718 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -752,7 +747,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "eade0066585b3511ccb9adbc1cea1d1f4d8caf37", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9f86649718..c2f820fbf8 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -747,7 +755,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "56fd065a1675449925d0426558aa007bf0a299e7", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex c2f820fbf8..a9b7317167 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -755,7 +766,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "8f8531a23b5156f0093e32272ed683c692e27f7f", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex a9b7317167..2da116f5f6 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -766,7 +760,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "fae74755535964a4f8d87f46a14f454cf8d544a5", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 2da116f5f6..fb585a4ba9 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -760,7 +761,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c72c57ac2b225b614824d4a5ffc4bed467d73a8b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex fb585a4ba9..ee4c5ffa12 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -761,7 +760,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "d2c61b343fcdfbcba5590b18b89f0ed976ee147a", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ee4c5ffa12..948b91ca66 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -760,7 +769,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "ec1313056ada36b4d66da2938c1273c6b8d5e72b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 948b91ca66..8473be7065 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -769,7 +729,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "f994923879e5eb5b9404c8c9eb3d77e613eea0fd", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 8473be7065..ce5caf20db 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -729,7 +762,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "8026778c742f6d6be71a6161907fe62eca061415", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ce5caf20db..cd9c57c41a 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -762,7 +731,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "c10530ce764d5c67267958970dd6d9196e9a37ef", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex cd9c57c41a..02fdaf1543 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -731,7 +737,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "16d03003488998ae5e64cb80f0a94e8bb5cf6961", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 02fdaf1543..93f4875390 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -737,7 +729,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-\n+    \n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "8f596531cf0e1ec6583e89a5d96ccff38dbe46a4", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 93f4875390..7520c53117 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -729,7 +733,7 @@ public class Datasets extends AbstractApiBean {\n             return error(Status.BAD_REQUEST, \"Error parsing Json: \" + jpe.getMessage());\n         }\n     }\n-    \n+\n     @PUT\n     @Path(\"{id}/deleteMetadata\")\n     public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n", "next_change": {"commit": "cf57f1427a43c89c6729be92b207a14111327307", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 7520c53117..ffe9b2bb69 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -735,10 +766,11 @@ public class Datasets extends AbstractApiBean {\n     }\n \n     @PUT\n+    @AuthRequired\n     @Path(\"{id}/deleteMetadata\")\n-    public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n+    public Response deleteVersionMetadata(@Context ContainerRequestContext crc, String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n \n-        DataverseRequest req = createDataverseRequest(findUserOrDie());\n+        DataverseRequest req = createDataverseRequest(getRequestUser(crc));\n \n         return processDatasetFieldDataDelete(jsonBody, id, req);\n     }\n", "next_change": {"commit": "e895445f46467f4997c3a90ee3df3f8e47c1071b", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex ffe9b2bb69..9869f947e4 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -766,11 +760,10 @@ public class Datasets extends AbstractApiBean {\n     }\n \n     @PUT\n-    @AuthRequired\n     @Path(\"{id}/deleteMetadata\")\n-    public Response deleteVersionMetadata(@Context ContainerRequestContext crc, String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n+    public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n \n-        DataverseRequest req = createDataverseRequest(getRequestUser(crc));\n+        DataverseRequest req = createDataverseRequest(findUserOrDie());\n \n         return processDatasetFieldDataDelete(jsonBody, id, req);\n     }\n", "next_change": {"commit": "de6beffa71c36fc10017de6f7f615089eddf7f19", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\nindex 9869f947e4..83990619dd 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/api/Datasets.java\n", "chunk": "@@ -760,10 +782,11 @@ public class Datasets extends AbstractApiBean {\n     }\n \n     @PUT\n+    @AuthRequired\n     @Path(\"{id}/deleteMetadata\")\n-    public Response deleteVersionMetadata(String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n+    public Response deleteVersionMetadata(@Context ContainerRequestContext crc, String jsonBody, @PathParam(\"id\") String id) throws WrappedResponse {\n \n-        DataverseRequest req = createDataverseRequest(findUserOrDie());\n+        DataverseRequest req = createDataverseRequest(getRequestUser(crc));\n \n         return processDatasetFieldDataDelete(jsonBody, id, req);\n     }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "message": "Merge commit", "committedDate": null}, {"oid": "00d53ee4d43fd49a81faa1f31b9b0c6a1cad8b46", "committedDate": "2020-10-14 12:39:49 -0400", "message": "adjust incoming identifier for HttpOverlay drivers"}, {"oid": "239d5a8de208b6bf4bb2c809264d2069526e33ff", "committedDate": "2020-10-14 14:03:44 -0400", "message": "debug logging"}, {"oid": "e86c2d0fca0693614c3e8d90adf89dfd5f1dd1da", "committedDate": "2020-10-14 15:27:51 -0400", "message": "more logging"}, {"oid": "0062c681c124c40a016e775b8da6acb9646a9c43", "committedDate": "2020-10-14 15:59:00 -0400", "message": "fix storageidentifier parsing/updating"}, {"oid": "b45336c95ecbcee28b88a5b334c2180c86eb63fc", "committedDate": "2020-12-01 16:58:49 -0500", "message": "add replace param"}, {"oid": "6d537ce15b5989abb1bacd85a48ae17b447cd1cd", "committedDate": "2020-12-22 13:37:42 -0500", "message": "fix error handling"}, {"oid": "2a83a701cd1721647316d9cbb149f3c42573c628", "committedDate": "2020-12-22 13:38:53 -0500", "message": "specify default"}, {"oid": "782d5ecfcedc0460b0ed619288651795775ddaf6", "committedDate": "2020-12-22 13:39:18 -0500", "message": "add migrating switch"}, {"oid": "63362d9f87df415198d8c11aa9367580df7bd796", "committedDate": "2020-12-22 13:59:39 -0500", "message": "GET/DELETE endpoints"}, {"oid": "5050e9390ff8fe4679ffb58a3f3bb89106b7f8d0", "committedDate": "2020-12-22 14:00:31 -0500", "message": "put is always for :draft version"}, {"oid": "24cfcfa08257d9245b2d6f033c679e59c4424316", "committedDate": "2020-12-22 14:15:21 -0500", "message": "multiple updates/fixes, added logging"}, {"oid": "e6366e4e29166365265ac947287d187c51f848cd", "committedDate": "2021-01-08 09:55:52 -0500", "message": "add note"}, {"oid": "cb20416b881c9b3a6e2ba06c5f6f7055ac370737", "committedDate": "2021-01-29 11:15:41 -0500", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "d885d633a96a649b296ada1b5fd3a0a18cf932a6", "committedDate": "2021-02-09 15:16:36 -0500", "message": "cleanup"}, {"oid": "8851fe322cbc6db5b0ad3bade0c3bdaf21acbcee", "committedDate": "2021-02-09 16:31:35 -0500", "message": "comments/cleanup"}, {"oid": "38a1d38f37f8ef0d9d75db51a5b6707f58fb8227", "committedDate": "2021-02-10 16:04:53 -0500", "message": "globusAPI initial commit"}, {"oid": "66a4ca056cf16450ed5bf788aa9b726928efb6ec", "committedDate": "2021-02-11 15:23:55 -0500", "message": "debug 1"}, {"oid": "b9689b3f53053896dff8170cac8d5afdbdcce3d9", "committedDate": "2021-02-16 08:56:08 -0500", "message": "Resolved Globus API for multiple files input (dv version 5.3 )"}, {"oid": "f8b7c3e2a630595a2d553e542c32b89b171bb24b", "committedDate": "2021-02-16 09:08:56 -0500", "message": "Removed unwanted statements"}, {"oid": "d6480aa7cc4f09fa73619af2cc08719b9a84b687", "committedDate": "2021-02-16 09:25:30 -0500", "message": "mimeType is calculated only from file extension"}, {"oid": "c10989dc062661bcf0db00f758a4a0ffa275991e", "committedDate": "2021-02-18 09:13:41 -0500", "message": "Merge remote-tracking branch 'Remote/develop' into develop-globus-phase2.1"}, {"oid": "9b14433f161d7fbf65f8d46e840b79cb571a5751", "committedDate": "2021-02-23 12:48:54 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "5305e759e7e20774e3a435936a3ea2009bf1d058", "committedDate": "2021-02-23 13:12:48 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "2fa243abe63c60b07a714070acd4a62d5c8d6e96", "committedDate": "2021-03-16 10:16:31 -0400", "message": "Globus API upgrade"}, {"oid": "99a1ecff4a08f72f8f01c4eb171424795009c8c5", "committedDate": "2021-03-16 10:39:39 -0400", "message": "merge with develop iqss"}, {"oid": "282063ebb7b6615b71d2d4fa5f7ec34b510fe521", "committedDate": "2021-03-16 16:44:08 -0400", "message": "corrected few variables"}, {"oid": "a5413c85073967798ba099f45fff5f865fc5f19d", "committedDate": "2021-03-18 13:28:58 -0400", "message": "hardcoded httpRequestUrl"}, {"oid": "f1433266987581e9ac3fc684b646a3923bd9288b", "committedDate": "2021-03-19 15:12:57 -0400", "message": "- tweak datasetlock, - skip checksum validation using dataset category"}, {"oid": "3a3235451900dacd9dbf48ea33ed445f128214a1", "committedDate": "2021-03-22 08:58:01 -0400", "message": "method dropped in merge"}, {"oid": "9ca076833a8b9cda803700e9af7812b1a88257e9", "committedDate": "2021-03-24 08:44:46 -0400", "message": "make sure release user is set"}, {"oid": "6cd23a1b327f84fd649a0b802322532df92d345a", "committedDate": "2021-03-24 08:55:04 -0400", "message": "- tweak datasetlock, - skip checksum validation using dataset category"}, {"oid": "1e7fcd17d7b102bd141e94b262ee6a53b60d2f56", "committedDate": "2021-03-24 09:01:23 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "491fe42c07944db5fc4686a4699ffb1399ca9051", "committedDate": "2021-03-29 10:50:33 -0400", "message": "- delete globus permission"}, {"oid": "4b5ad664ac18165dc032ab7faeee240cf6002aa2", "committedDate": "2021-03-30 11:04:13 -0400", "message": "Assign a version if not set"}, {"oid": "a17c4bb05aa66eb375279174355bcbb79a1ad5ed", "committedDate": "2021-03-30 11:08:58 -0400", "message": "Don't call archiver directly"}, {"oid": "bc5edf0ad09ecf627cb936a5de50e19be4df34ba", "committedDate": "2021-03-30 17:38:42 -0400", "message": "- added GLOBUSUPLOADSUCCESS notification type and user notification messages - added deleteRule api -"}, {"oid": "c3b12195db2c5132f11672295e777f411eda4759", "committedDate": "2021-03-31 09:19:03 -0400", "message": "add @POST per Chris Muller"}, {"oid": "e68003191dbd06e8f34b9d52d559bee1ee081a30", "committedDate": "2021-03-31 09:44:27 -0400", "message": "Merge remote-tracking branch 'Remote/develop' into develop-globus-phase2.1"}, {"oid": "14352024df292342d644af182543e6bcb3d0690d", "committedDate": "2021-03-31 11:11:05 -0400", "message": "corrected error"}, {"oid": "c3ff22927bf27e7716b9cd5f43fb0640752303ba", "committedDate": "2021-04-01 11:40:15 -0400", "message": " api to delete globus rule and added notification"}, {"oid": "58a2317d9fb696999fc7439bbcea18d05bc2728e", "committedDate": "2021-04-01 17:27:14 -0400", "message": "handle mutliple versions, setting pub/release dates correctly"}, {"oid": "b441a15d394b0935155b3b20c8484dd44e19df0f", "committedDate": "2021-04-07 17:41:49 -0400", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "e72c4e50fca0ceb2332d6057c4c05808b1d215dc", "committedDate": "2021-04-07 17:46:25 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "12e2e6eb1de0e2223c895b1a7fbfb6b29b3d5f14", "committedDate": "2021-04-08 11:29:14 -0400", "message": "correction to verify ruleID existence, added ChecksumDatasetSizeLimit and ChecksumFileSizeLimit settings"}, {"oid": "878ef6fff6a27510b39cffb058b26afca31301c3", "committedDate": "2021-04-14 12:09:46 +0200", "message": "Merged back develop"}, {"oid": "fb2b52cf66f7cb51b5b0cee0cd298657fdd0638d", "committedDate": "2021-04-14 13:00:11 -0400", "message": "don't used deprecated Long constructor"}, {"oid": "e584d6fa0b10ad5eb1bd275abe445b554470693c", "committedDate": "2021-04-14 19:22:37 -0400", "message": "add pre-pub wf to migrate"}, {"oid": "ad48ad711049f99d17b3494fab3d923016bfc799", "committedDate": "2021-04-19 16:58:39 -0400", "message": "cleanup : removed redundant code from Phase 1"}, {"oid": "a4531f54ab2565c8015493a3bcaa1043bed6137f", "committedDate": "2021-04-20 16:55:47 -0400", "message": "update"}, {"oid": "faa944efd1a0644085555d5eae18bfad1a823e4d", "committedDate": "2021-04-26 14:49:20 -0400", "message": "mirror responses from publish command - accepted(w /wf) or ok"}, {"oid": "6fa5e904755345a8f3ae8ccea00f47d83265c726", "committedDate": "2021-05-20 11:30:51 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "f702a6188c89567592f593f96e9c7277bc0955fd", "committedDate": "2021-05-20 13:06:04 -0400", "message": "Merge branch 'IQSS/6497-semantic_api' into IQSS/6497-migrate_dataset_api"}, {"oid": "4fa484bfe8cc99a5330cd4291a6b86feeca333ca", "committedDate": "2021-05-25 16:29:08 -0400", "message": "api /addFiles"}, {"oid": "83b21f01362eac9b2954b3c61d02a7f4689e3f73", "committedDate": "2021-05-26 15:10:25 +0200", "message": "DD-420 multi license UI (#73)"}, {"oid": "71f6be2178ab1c236cd5f229253bb277212e08bb", "committedDate": "2021-05-26 15:23:00 +0200", "message": "Merged back develop"}, {"oid": "399e2ad1569c8ee9bb55ef17457ade2cf1e22aa3", "committedDate": "2021-05-26 17:39:05 -0400", "message": "handling exception"}, {"oid": "c0eba6d375fbff567d81e4fcfa077eeec3f5a3ec", "committedDate": "2021-05-28 14:12:36 -0400", "message": "handling exception"}, {"oid": "a24392c349afb503d1c02ec6c57c82f29d75baaf", "committedDate": "2021-05-28 14:14:15 -0400", "message": "Revert \"handling exception\""}, {"oid": "db6944774fdbdf0de4eebb9d6c0675586bc8e3c7", "committedDate": "2021-05-28 14:49:14 -0400", "message": "Refactored /addFiles"}, {"oid": "debc952527925ed540e1ffff97b0b97eb53fe436", "committedDate": "2021-05-28 15:12:15 -0400", "message": "Merge branch 'IQSS:develop' into 7900-api-toadd-multipleFiles"}, {"oid": "7dbd78d546c5e53b8312d67326276d20f49535be", "committedDate": "2021-06-03 15:21:57 +0200", "message": "Merge branch 'develop' into multi-license"}, {"oid": "60f474dec0f631735b9705cb5c0d7a714d5f57de", "committedDate": "2021-06-03 12:19:09 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "b12f881bb7408eb4eefb0f432ad30d6ca3638160", "committedDate": "2021-06-15 13:11:58 +0200", "message": "Merge pull request #88 from PaulBoon/embargo"}, {"oid": "c9750a0cb53dd216eb088481c3fa7de92495f799", "committedDate": "2021-06-23 13:00:33 -0400", "message": "initial external status label impl"}, {"oid": "19dcce1c4fda90b8f9454451ff8c9750cdf85676", "committedDate": "2021-06-23 13:06:22 -0400", "message": "typos, update errors, change regexp"}, {"oid": "044cbbc8b64033790d988b67b5e72901d3376519", "committedDate": "2021-06-23 13:06:56 -0400", "message": "allow delete, clear upon publication"}, {"oid": "ff2419b9d62095405ddc5f67e40f37fcd7b19a4c", "committedDate": "2021-06-25 12:34:30 -0400", "message": "support application/ld+json(new) application/json-ld (old/non-standard)"}, {"oid": "2c494d85b5f2906cfbd5a3727a9a358635b47815", "committedDate": "2021-06-26 21:37:25 +0200", "message": "DD-461 Implement Embargo API (#89)"}, {"oid": "249722848cd6d536e14a312e5ae8b447c8192918", "committedDate": "2021-06-30 14:42:51 +0200", "message": "Merged back develop"}, {"oid": "e1c1bfe58e64ea0ed54cbb03ad89bab209314aef", "committedDate": "2021-06-30 11:59:50 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "599504ab9a81d6766932bbdc9be69de131a09f27", "committedDate": "2021-06-30 14:15:43 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "e5d375ae87a14c0eac71c6208298334b6fdd8de7", "committedDate": "2021-07-02 09:09:34 -0400", "message": "further updates"}, {"oid": "5ca182e2830cda4ba8428907994bb1fbab37191f", "committedDate": "2021-07-06 10:49:41 -0400", "message": "Note todos"}, {"oid": "20e4360aa4ec612f5f8673fca06dfd9ab2e3f208", "committedDate": "2021-07-08 13:24:32 +0200", "message": "DD-526 create url for custom terms (#99)"}, {"oid": "792d479066a24a8623d6f1b3c4ba244deb3cb2b6", "committedDate": "2021-07-08 16:47:49 -0400", "message": "Merge remote-tracking branch 'SP/develop' into 7900-api-toadd-multipleFiles"}, {"oid": "a1f9f3ebe80dd6a20b60d1d19bb9acbd0a84713b", "committedDate": "2021-07-14 12:23:53 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "fd21968e515394812d8a7f034d46203f44537740", "committedDate": "2021-07-14 19:07:05 +0200", "message": "DD-526 create url for custom terms (#103)"}, {"oid": "19f3eac7cfd7837b45f6d22f8d8d53215354c1ad", "committedDate": "2021-07-14 20:27:51 +0200", "message": "Merge back develop (#105)"}, {"oid": "8c4d651709f53c1a79c8c570df2f05ff117a8bfa", "committedDate": "2021-07-14 17:02:09 -0400", "message": "Merge pull request #7901 from scholarsportal/7900-api-toadd-multipleFiles"}, {"oid": "30d131cfbd8fd99d8eda764e0ec6b82a61c1e354", "committedDate": "2021-07-22 15:10:31 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-migrate_dataset_api"}, {"oid": "a7a8f80da2d7a0252b4099f3e0834db1d6cd17fc", "committedDate": "2021-07-22 15:34:52 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into QDR/6886-external_status_labels"}, {"oid": "ac82d6f42e2232b9965e4d7df97be79db45b93b8", "committedDate": "2021-07-23 13:12:15 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "6cc86e020135c1916d26be8ecef37bbf14f4f7c6", "committedDate": "2021-07-24 11:02:47 +0200", "message": "Resolved merge conflicts"}, {"oid": "c833eb98362792296239444bdb0510be10135a38", "committedDate": "2021-07-27 15:23:28 -0400", "message": "handle version 1.0 info already set"}, {"oid": "d549f72af2ba398bbe28729b6762e5f6f6468e60", "committedDate": "2021-07-27 15:47:32 -0400", "message": "enable DOI updates"}, {"oid": "93481bd2039e7bd551752dd975c768490f29be52", "committedDate": "2021-07-27 16:10:37 -0400", "message": "cut/pasted to the wrong place"}, {"oid": "259e26d748e50f62a32f7b232978954e9b219fd4", "committedDate": "2021-07-28 12:26:28 -0400", "message": "add flag required to also update PID at provider during migrate"}, {"oid": "a7a9f8b66a30153d2f03b149fa24eb24de36ab18", "committedDate": "2021-07-28 13:19:29 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "1e6f9847149bfb4bb8b7e7f5d2d794f915f01b21", "committedDate": "2021-07-28 13:24:46 -0400", "message": "merge issue - dropped import"}, {"oid": "46b10e3f688f3d0b70233092c62a528d5cf8aa7e", "committedDate": "2021-07-29 09:10:48 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into QDR/6886-external_status_labels"}, {"oid": "7e884d76cb25171e41299b314df6769336e42de1", "committedDate": "2021-08-04 17:52:38 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "64b8b906694dc4992e4e9291dc44bb4b7f83dd25", "committedDate": "2021-08-04 18:09:42 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into QDR/6886-external_status_labels"}, {"oid": "257349a31531fc87a7f1aee0dbbae10ab945c937", "committedDate": "2021-08-04 18:16:02 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "effe3bf95c1f2b46c2047ce8c1b162be4b14f4b6", "committedDate": "2021-08-19 16:45:19 -0400", "message": "add a curation status report api call"}, {"oid": "21ff777277a49e45a8ececbd797d7f2272e7780d", "committedDate": "2021-08-24 15:26:18 -0400", "message": "Merge remote-tracking branch 'SP/develop' into develop-globus-phase2.1"}, {"oid": "60d7d0dff8f6f0063f94f44bf79080867e3ec0ae", "committedDate": "2021-09-07 17:04:17 -0400", "message": "refactor to support support addFiles api from #7901"}, {"oid": "925a1c3f3d2538a365edc8f8c23735355615e08b", "committedDate": "2021-09-10 17:22:50 +0200", "message": "DD-573 Implement set license in semantic api (#113)"}, {"oid": "b001bf137f9440251a739369dde27b7c258ad472", "committedDate": "2021-09-10 17:39:39 +0200", "message": "Merged back develop"}, {"oid": "eade0066585b3511ccb9adbc1cea1d1f4d8caf37", "committedDate": "2021-09-21 12:50:19 -0400", "message": "add apis and docs"}, {"oid": "10996d679b08c8933d5c20d25a9ff9ae7b30788d", "committedDate": "2021-09-21 13:08:08 -0400", "message": "cleanup"}, {"oid": "d266bb31169f22576620002b716c6c918191faaa", "committedDate": "2021-09-21 14:27:23 -0400", "message": "make role reporting generic"}, {"oid": "56fd065a1675449925d0426558aa007bf0a299e7", "committedDate": "2021-09-21 14:37:57 -0400", "message": "style fixes"}, {"oid": "8f8531a23b5156f0093e32272ed683c692e27f7f", "committedDate": "2021-09-27 16:32:36 -0400", "message": "Revert \"style fixes\""}, {"oid": "20cf55d5d7603145ddc40caf6b9d0631ccdefd6a", "committedDate": "2021-09-27 16:42:33 -0400", "message": "cleanup"}, {"oid": "38b8baa6c3b0f5d3878037c506d6f055380385a0", "committedDate": "2021-09-29 15:28:46 -0400", "message": "addressing review feedback"}, {"oid": "a79ce03e58b5110b28f7b4981b50568e01499177", "committedDate": "2021-10-04 12:50:30 -0400", "message": "Fix PUT curationSetLabel and test"}, {"oid": "fae74755535964a4f8d87f46a14f454cf8d544a5", "committedDate": "2021-10-06 17:36:13 +0200", "message": "implemented change requests"}, {"oid": "c72c57ac2b225b614824d4a5ffc4bed467d73a8b", "committedDate": "2021-10-06 17:16:20 -0400", "message": "merge needed for put/delete"}, {"oid": "cc8e14604636b856e514bc80cc22002d8322b35f", "committedDate": "2021-10-07 13:47:45 -0400", "message": "don't need to be super to get allowed curation labels in set"}, {"oid": "0b617f64ce3a90acc5565be92a2f533aa0bdb305", "committedDate": "2021-10-07 13:56:05 -0400", "message": "add permission check"}, {"oid": "10e8bc457d7a03e87a3ed047473dd1f42f2b9044", "committedDate": "2021-10-07 14:13:06 -0400", "message": "fix concatenation"}, {"oid": "0b681218a4fde3fc59a9d3874ccf4ea15f8a9ec5", "committedDate": "2021-10-07 14:14:57 -0400", "message": "fix null for no label"}, {"oid": "392a88f9d88738605990a2cfaccf1809d2bc3ae8", "committedDate": "2021-10-13 11:42:19 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into DANS/embargo"}, {"oid": "c719a880e8b6300acdd4c7a993df75e2350bd69e", "committedDate": "2021-10-13 11:45:01 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "b7c622637c7e9f1e3736f420f831032b8c7f2ca8", "committedDate": "2021-10-19 09:18:59 -0400", "message": "update api"}, {"oid": "1d635a71e077566b348617f4b69bccfa0dc819af", "committedDate": "2021-10-19 10:41:05 -0400", "message": "fix unset - check perm on dataset not its owner"}, {"oid": "5b97725c6a3523298e4463eb55aa9dd8dc3a48e7", "committedDate": "2021-10-19 12:19:06 -0400", "message": "old logic - only check released and ! superuser"}, {"oid": "980839bb8d308bd0561b46acb7b3a64d95a86a09", "committedDate": "2021-10-21 08:30:07 -0400", "message": "avoid NPE in embargo tracking"}, {"oid": "d2c61b343fcdfbcba5590b18b89f0ed976ee147a", "committedDate": "2021-10-22 16:30:54 +0200", "message": "Merged back develop"}, {"oid": "ec1313056ada36b4d66da2938c1273c6b8d5e72b", "committedDate": "2021-10-25 18:01:42 -0400", "message": "changing action logging to include userIdentifier"}, {"oid": "4808c302691ac6b828cdf54189e131a7f86eeb72", "committedDate": "2021-10-25 18:38:19 -0400", "message": "handle null, update user id used, change actiontype for create/delete"}, {"oid": "f994923879e5eb5b9404c8c9eb3d77e613eea0fd", "committedDate": "2021-11-09 09:03:54 +0100", "message": "Merged back develop"}, {"oid": "8026778c742f6d6be71a6161907fe62eca061415", "committedDate": "2021-12-15 15:37:37 -0500", "message": "#8191 fix tests and update query"}, {"oid": "c10530ce764d5c67267958970dd6d9196e9a37ef", "committedDate": "2022-01-10 16:52:38 -0500", "message": "refactor to add license package"}, {"oid": "b6d170ba3dddf92f3b191cf92a8d391fe802c9ab", "committedDate": "2022-01-10 16:58:56 -0500", "message": "fix/simplify refactor"}, {"oid": "663bde9c9059c3d964d1e52fc5a577b45383ac1c", "committedDate": "2022-01-11 13:31:20 -0500", "message": "braces for if, reformat method"}, {"oid": "16d03003488998ae5e64cb80f0a94e8bb5cf6961", "committedDate": "2022-01-24 15:14:41 -0500", "message": "prevents the file upload api from defaulting to \"text/plain\" for the mime type, when no Content-Type: header is found in the incoming data part. (#8344)"}, {"oid": "76bfee2b0930ed58f13e6d11b17af95e1f0c51ca", "committedDate": "2022-01-25 17:45:28 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "8f596531cf0e1ec6583e89a5d96ccff38dbe46a4", "committedDate": "2022-02-02 13:44:09 -0500", "message": "Merge branch 'develop' into 8344-file-upload-default-mime"}, {"oid": "bbc7e32e411db172f7096d347419b5b05bcfdc76", "committedDate": "2022-02-02 14:01:40 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "70ea695d41f7cc579dbfe814918d207b4ee980a2", "committedDate": "2022-02-03 10:31:17 -0500", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "e3bdb52c99f2ce584e739dcfed9747b77e0dea07", "committedDate": "2022-02-03 12:35:45 -0500", "message": "Merge branch 'develop' into develop-globus-phase2.1"}, {"oid": "963d2990892db55cf24027c9134feb9f97d4ccae", "committedDate": "2022-02-03 13:13:05 -0500", "message": "Merge remote-tracking branch 'origin/develop' into develop-globus-phase2.1"}, {"oid": "a7ec3bf2a34196ca18bd265fee3f6960b0ac45d3", "committedDate": "2022-02-03 13:23:21 -0500", "message": "Merge branch 'develop' into develop-globus-phase2.1"}, {"oid": "5feb2c178c55aaaf4af6bc0bdc5e5bb519e822d7", "committedDate": "2022-02-03 16:11:12 -0500", "message": "- removed old method"}, {"oid": "acb2ec32f5dd54f764d11fc0c8201dd327d4bac1", "committedDate": "2022-02-16 10:46:42 -0500", "message": "Basic framework for a lock-listing API. Work in progress, lots to figure out/finalize. (IQSS/dataverse.harvard.edu#135)"}, {"oid": "ef636435efe8c6737597da1e8dbce89f36b5d6e8", "committedDate": "2022-02-18 20:51:07 -0500", "message": "Expanding the locks API to list locks installation-wide, across all datasets. (IQSS/dataverse.harvard.edu#135)"}, {"oid": "0905ad38ea61a00179af4d2022fbe365e3375ab8", "committedDate": "2022-02-23 14:51:19 -0500", "message": "minor/cosmetic. IQSS/dataverse.harvard.edu#135"}, {"oid": "29e0dc4595c5cf872f8a314148ef1963d94990f1", "committedDate": "2022-02-24 14:24:03 -0500", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "8698f786181d6a941adaecc261c95418427c3e08", "committedDate": "2022-03-03 11:12:44 -0500", "message": "Merge branch 'develop' into 8344-file-upload-default-mime"}, {"oid": "6a1333dbdd07d30bc6833b1bedee7c0faad4434e", "committedDate": "2022-03-08 22:35:08 -0500", "message": "replace another Strings.join"}, {"oid": "e8be11588f76659cb9b2eba829bcfb61d81b7ca4", "committedDate": "2022-03-09 09:31:17 -0500", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "b78075c0ffd6f449f3984e94e6e6ae50687d5441", "committedDate": "2022-03-15 17:11:29 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "cc763f8fccc0acfe3d55ae24cbe75e2bd9c8fffa", "committedDate": "2022-03-21 15:37:48 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "51b743e0cc54018f5911440e8f4653ec1814a140", "committedDate": "2022-04-12 13:27:53 -0400", "message": "protect against null TermsOfUseAndAccess"}, {"oid": "231a15f78d20016dfa0f2f798d4fb55de20163a6", "committedDate": "2022-04-12 14:48:50 -0400", "message": "Merge branch 'develop' into 8191-require-TOA-or-req-access"}, {"oid": "4504e001b02a30ed599f03a7f8aff635c3bbd633", "committedDate": "2022-04-14 09:18:36 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "5a823ab64163627d3b6e6814eee9f59bfd79efa5", "committedDate": "2022-04-14 13:06:46 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "b846a9670fd25294ecc80c02c4331c88430c00da", "committedDate": "2022-04-26 12:56:52 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "adca68b7255e7c082030542c3430479737411062", "committedDate": "2022-04-27 11:25:35 -0400", "message": "Merge branch 'IQSS/7324_TRSA-HTTP-store' into GDCC/DC-1"}, {"oid": "c5246d28e972c897f1318707b8ba4100d2e2cd28", "committedDate": "2022-04-29 09:25:17 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "7b68d57295853c0dca32cfc0f7fa51bb4be0f6e1", "committedDate": "2022-04-29 09:27:33 -0400", "message": "Refactor to RemoteOverlay, use constants for store types/sep"}, {"oid": "6f1f543063f916ffa3eeda2354286a99499cc0a6", "committedDate": "2022-04-29 17:57:06 -0400", "message": "Merge branch 'IQSS/7324_TRSA-HTTP-store' into GDCC/DC-1"}, {"oid": "de627912c50400cd8f2c412c1e453b70d67a22b0", "committedDate": "2022-05-13 14:51:53 -0400", "message": "Archival status success/pending/failure/null support"}, {"oid": "dcd5034b59f1d2a9e40f4139053e2353be2c6fde", "committedDate": "2022-05-26 15:51:14 -0400", "message": "single-version semantics for archiving"}, {"oid": "cdaa28b4104c285d905441a9c97a9f6a53ff8446", "committedDate": "2022-06-24 10:06:04 -0400", "message": "move globus calls to globus bean, doc Lock issue, cleaunup"}, {"oid": "9223e7df02f9f829a0e333247971e57706803aa7", "committedDate": "2022-07-15 17:21:48 -0400", "message": "updates per review"}, {"oid": "7362e1c82086bed520007d2bc13eb59695e0115f", "committedDate": "2022-07-19 16:49:39 -0400", "message": "lower logging #8605"}, {"oid": "778e78021ba65bf47eb0c81d2e6f38e00dfa9c5b", "committedDate": "2022-07-20 13:11:00 -0400", "message": "Merge branch 'GDCC/8605-add-archival-status' into GDCC/8746-single-version-semantics_for_archiving"}, {"oid": "c74f9b68cb719abe669be63024b3419fc9678d9e", "committedDate": "2022-07-20 13:19:26 -0400", "message": "handle name and dataset/version changes from 8696 review"}, {"oid": "9aa7dd07d756e746373711ea26d9ee4106f730bb", "committedDate": "2022-07-21 19:52:29 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "c1fa462f5f43a6a668a4e7f62ee3a70fd05fb342", "committedDate": "2022-07-25 14:22:50 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "4441795e461b67a433fb205b1a17f143ad8866e3", "committedDate": "2022-07-25 14:47:21 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "ff8eec0f1d4ec44f8ef83d66562f6105ce532656", "committedDate": "2022-07-28 17:19:51 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "abd392319709024396e3f0a546b7239e7ae66953", "committedDate": "2022-07-29 13:06:01 -0400", "message": "updates for archival status (missed/lost)"}, {"oid": "bcad012f43d0be25dc8cf50ee76dbe06b68b23b9", "committedDate": "2022-08-02 15:51:44 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "97644428369109cb9693b8b04327d516c7668779", "committedDate": "2022-08-03 14:00:19 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC1"}, {"oid": "c6e362cabdb62f126d66955056ac7fad7c45bbe9", "committedDate": "2022-08-05 16:28:46 -0400", "message": "per reviewDog"}, {"oid": "ea6ee80a681549fe800b026bde7c091a1dd51e79", "committedDate": "2022-08-08 16:07:03 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "504ca17bdbb459614236ec893ddeead73a2357d1", "committedDate": "2022-08-09 14:25:45 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "0fd56cf2be9ff2e5a1331605fb038f2488cc461c", "committedDate": "2022-08-09 14:34:42 -0400", "message": "minor error meg and comment changes"}, {"oid": "80bd84d5560354534be164d5825a9b7225af1034", "committedDate": "2022-08-12 10:51:44 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-3B"}, {"oid": "3558a0bb33a5fa5d4c819515f579ff7f2b0d8b9e", "committedDate": "2022-08-12 17:59:08 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/DC-1"}, {"oid": "7f990dc776e0b6723eeb5afbf10359129c19a560", "committedDate": "2022-08-16 14:27:00 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/7324_TRSA-HTTP-store"}, {"oid": "643b9242ff8f658c88192858f6c41ac480b0272c", "committedDate": "2022-08-17 10:11:27 -0400", "message": "add checking w.r.t. dataset storage driver/base driver"}, {"oid": "ff2f137d6f6da08026241fcbd21e5923d08ada1b", "committedDate": "2022-08-17 12:36:57 -0400", "message": "Merge branch 'IQSS/7324_TRSA-HTTP-store' into GDCC/DC-1"}, {"oid": "3ada97f7e511d721cb330ab78e3bd47fcab18747", "committedDate": "2022-08-18 17:56:53 -0400", "message": "strip any html from archival status"}, {"oid": "9fa0561e52ed726287f8dcded98486b109623ca4", "committedDate": "2022-08-29 14:53:22 -0400", "message": "#8859 add conflict response status"}, {"oid": "45dfdfa3520cb47af3defc7644c912f3067800f0", "committedDate": "2022-08-31 14:32:47 -0400", "message": "#8859 add comments; clean up test"}, {"oid": "0909f7e0c89d4c13335f6c637575363f6b9ae790", "committedDate": "2022-09-02 10:46:15 -0400", "message": "return 400 for bad JSON"}, {"oid": "25ae68ca4cf0c7789c6aa3083e1bb06e32cbda11", "committedDate": "2022-09-06 10:59:14 -0400", "message": "Merge branch 'develop' into 8859-update-api-error-msg"}, {"oid": "04869dbb4f249724a89f3553c4f044fab29e8668", "committedDate": "2022-09-07 16:16:08 -0400", "message": "typos (test Jenkins) #8859"}, {"oid": "37a9c50779d689cc94da14b3c00ec6161751d27f", "committedDate": "2022-09-08 16:14:36 -0400", "message": "#8859 check for valid terms prior to embargo"}, {"oid": "5e79f049fc6635ff5b3ae1a214e58b4bb4e33f4e", "committedDate": "2022-09-14 13:51:18 -0400", "message": "Merge branch 'develop' into GDCC/DC-1 #8891"}, {"oid": "4e0e884615d9076e30e65b55d0c8a1b381e7bb99", "committedDate": "2022-09-19 15:34:03 -0400", "message": "#8859 resolve conflict"}, {"oid": "9f23b6aa042cd2e703b5022e3c022edcdd86ff78", "committedDate": "2022-09-21 11:14:14 -0400", "message": "#8859 update api message prior to command; update tests"}, {"oid": "a413a13f3a04c2dca2e2c39d80791f1cf47a939a", "committedDate": "2022-09-27 12:52:06 -0400", "message": "add tool callback methods for dataset and datafile"}, {"oid": "e06ec36b2a4a78e8c64e42858542faaccf62841b", "committedDate": "2022-09-30 10:04:55 -0400", "message": "Add /replaceFiles call"}, {"oid": "b59f4835074518fc8374e4f86b4a8f36dc3ccb58", "committedDate": "2022-10-06 11:40:51 +0200", "message": "dataset files cleanup"}, {"oid": "c80a06f38b679641d80a05b5215106006da52667", "committedDate": "2022-10-28 18:07:07 -0400", "message": "fix for cvv and editMetadata replace=true, and test"}, {"oid": "9ba760d67456cfebc369d7f7d83e2d2dc7f3c505", "committedDate": "2022-11-04 18:23:16 +0100", "message": "replaced listAllFiles and deleteFile with cleanUp in the StorageIO interface"}, {"oid": "00170695b920c2f5accdeb1cdcb367b6c892ab1b", "committedDate": "2022-11-04 18:34:28 +0100", "message": "better filter for files to delete"}, {"oid": "f0ac872828d3a48cf74e74052ae1b3767afb264a", "committedDate": "2022-11-07 13:59:16 +0100", "message": "updated filter: exlude export files"}, {"oid": "bcaeb9fd58f38fdcd8cc1587e763a80c17b55048", "committedDate": "2022-11-07 14:05:35 +0100", "message": "bugfix in filter"}, {"oid": "503b9a36ca409e4bf89659cc877b62415d4ef33a", "committedDate": "2022-11-07 14:06:35 +0100", "message": "added dryrun query parameter"}, {"oid": "4b0d36596835333bf5c528e3659b8a5bbef5ed60", "committedDate": "2022-11-07 14:10:25 -0500", "message": "rename getEditVersion to getOrCreateEditVersion #8930"}, {"oid": "559e5c5aa7acc885064001fb6c93871bb2df3296", "committedDate": "2022-11-10 13:48:51 -0500", "message": "Merge branch 'develop' into 7715-signed-urls-for-external-tools #7715"}, {"oid": "fbf7190f193fb5d65dc6c100d7bb6c2d62dd1b0e", "committedDate": "2022-11-23 09:45:40 -0500", "message": "Improved error handling per QA"}, {"oid": "398fd4819f74241a0db3a458b74515f7688aacce", "committedDate": "2022-11-28 14:00:57 -0500", "message": "Improve error handling"}, {"oid": "120adc18a8b02d4fcf18c4dd9ef557f529de1ae9", "committedDate": "2022-12-07 17:38:06 -0500", "message": "Merge pull request #9107 from GlobalDataverseCommunityConsortium/GDCC/9106-fix_editMetadata_api_when_replace_is_true"}, {"oid": "233926e4cff9bd24d2af90e86391b77b147b42b9", "committedDate": "2022-12-13 12:48:18 -0500", "message": "Merge remote-tracking branch 'IQSS/develop' into GDCC/9005-replaceFiles_api_call"}, {"oid": "f7e9b1baddb71ca0bab16380446fd0b6113d73f1", "committedDate": "2023-01-23 10:19:39 +0100", "message": "Merge branch 'develop' of https://github.com/IQSS/dataverse into dataset_files_cleanup"}, {"oid": "aab0f2ab4ef87fdd46f70e0c5de1870ccccd55b0", "committedDate": "2023-01-23 10:27:03 +0100", "message": "simplified for loop: loop directly on DataFiles of dataset, not over each version separately"}, {"oid": "d4d69b70ede07d5ab04deb5004157dd1522ed413", "committedDate": "2023-01-23 10:59:33 +0000", "message": "Refactor: deleteDataset endpoint uses AuthFilter instead of findUserOrDie"}, {"oid": "a5b27c2e2fa78aa9cb5d37742d131cf81765964c", "committedDate": "2023-01-23 11:14:13 +0000", "message": "Refactor: new AbstractApiBean method for retrieving user from ContainerRequestContext"}, {"oid": "360b73819df4028a9fbcd1bc914ab90720f334da", "committedDate": "2023-01-23 12:35:49 +0100", "message": "clean up files made safer"}, {"oid": "cf57f1427a43c89c6729be92b207a14111327307", "committedDate": "2023-01-23 11:42:14 +0000", "message": "Refactor: all Datasets API findUserOrDie calls replaced by AuthFilter"}, {"oid": "17653b3f35d6db3245e7059c000293c19f20307a", "committedDate": "2023-01-23 11:51:46 +0000", "message": "Fixed: missing AuthFilter setup for Datasets getVersionJsonLDMetadata endpoint call"}, {"oid": "219beedec339e204952906a88e608c25f832a372", "committedDate": "2023-01-24 13:45:20 +0000", "message": "Refactor: from findAuthenticatedUserOrDie to AuthFilter"}, {"oid": "e895445f46467f4997c3a90ee3df3f8e47c1071b", "committedDate": "2023-01-25 12:41:10 +0100", "message": "removed split limit when splitting the storage identifier"}, {"oid": "222b56a15e146429def111cfd766219d04d529d5", "committedDate": "2023-01-25 12:43:51 +0100", "message": "legacy files generate only a warning now, no error is returned"}, {"oid": "de6beffa71c36fc10017de6f7f615089eddf7f19", "committedDate": "2023-01-26 11:20:24 +0000", "message": "Refactor: new response method within AbstractApiBean for handling user requests by handling filter-comming user instead of findUserOrDie method"}, {"oid": "b00deeab20830d991e196f0d53f069c7aed826f7", "committedDate": "2023-01-27 10:54:47 +0000", "message": "Refactor: using ApiConstants in all places for common API statuses"}, {"oid": "353aad9d77674ebe647a531c3d04c8f676eefe99", "committedDate": "2023-01-30 10:50:16 +0100", "message": "Merge branch 'develop' into 9293-filter-api-auth"}, {"oid": "08cefe392fb8c03ed9407a4d4b5b5828fa03e560", "committedDate": "2023-01-31 11:18:32 +0100", "message": "Refactor: using new filter-based auth on missing dataset endpoint"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NjU1Ng==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r662576556", "body": "Should this be getAsString?", "bodyText": "Should this be getAsString?", "bodyHTML": "<p dir=\"auto\">Should this be getAsString?</p>", "author": "pdurbin", "createdAt": "2021-07-01T20:36:00Z", "path": "src/main/java/edu/harvard/iq/dataverse/util/bagit/BagGenerator.java", "diffHunk": "@@ -816,7 +824,7 @@ private String generateInfoFile() {\n         } else {\r\n             info.append(\r\n                     // FixMe - handle description having subfields better\r\n-                    WordUtils.wrap(getSingleValue(aggregation.getAsJsonObject(descriptionTerm.getLabel()),\r\n+                    WordUtils.wrap(getSingleValue(aggregation.get(descriptionTerm.getLabel()),\r", "originalCommit": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2OTc1Mw==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r663169753", "bodyText": "Description is a multi-valued field so this could be a JsonObject or JsonArray. The added logic here handles both cases. Nominally this is also separable from the API itself - just caught in testing along the way. Could be moved to a separate PR.", "author": "qqmyers", "createdAt": "2021-07-02T17:51:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NjU1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDgwNDUwOA==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r664804508", "bodyText": "Oh, I see the added logic now. Thanks.", "author": "pdurbin", "createdAt": "2021-07-06T18:56:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU3NjU1Ng=="}], "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "message": "Merge commit", "committedDate": null}, {"oid": "175649e3d1cfd79a3fb92e9230127a66d1b56f03", "committedDate": "2021-08-19 11:51:01 -0400", "message": "use file paths, minor cleanup"}, {"oid": "ac0101e9650504d631de21125a3d2134dbd60e23", "committedDate": "2021-08-19 11:54:43 -0400", "message": "swap deprecated import"}, {"oid": "634c6f7c2d4f7a4963de91847640e065f9b71216", "committedDate": "2021-08-19 12:18:46 -0400", "message": "improve logging"}, {"oid": "30877d783c445543d9341a472c9e1b8f48b440cf", "committedDate": "2022-03-31 13:03:31 -0400", "message": "Use try with resources to close connections for non-200 status"}, {"oid": "eebee9629e98ac595ce1cb5b551e9ce808b0b8ca", "committedDate": "2022-03-31 13:50:18 -0400", "message": "add STANDARD cookie spec"}, {"oid": "3c90bbeebbdab42a9f03bbac45e9ce725cc5f6e8", "committedDate": "2022-03-31 14:51:30 -0400", "message": "modify zero-file behaviour to include empty manifest"}, {"oid": "7fc6ba434ae37db04a4d53f60ec99d2daa0c1e73", "committedDate": "2022-03-31 18:34:05 -0400", "message": "Clearer logging"}, {"oid": "ab8325b298d6fb74f1db3ff404a098aed9517dd6", "committedDate": "2022-04-04 15:54:40 -0400", "message": "add method to change thread pool size"}, {"oid": "8f9e7ebc5a420d17f3308d9cd7e9884f9919500b", "committedDate": "2022-04-05 14:11:22 -0400", "message": "don't close response in 200 case"}, {"oid": "e4470bf23d7b48e492eb9e61ea6bf43548a5a6a9", "committedDate": "2022-04-09 18:04:39 -0400", "message": "remove unused import"}, {"oid": "48dd0e909d00661e81c2aadd5583a21f315bf105", "committedDate": "2022-04-09 18:24:36 -0400", "message": "remove all but thread code, add Google/Local archivers"}, {"oid": "954e7eed982bd61a291970c4934bf781a568c33a", "committedDate": "2022-06-03 12:26:38 -0400", "message": "restore bagger improvements"}, {"oid": "e484a105f2070150260991cc273f903d31002020", "committedDate": "2022-06-03 13:17:29 -0400", "message": "get non-URL form of PID (now that OREMap uses the URL)"}, {"oid": "8cc6e711e73c6c1fd20c36ebb889658a7ccbd9ab", "committedDate": "2022-06-03 13:42:09 -0400", "message": "Fix parsing - convert url to local pid form"}, {"oid": "b3292fafbe5d73af85ab25023a810137ddf77b49", "committedDate": "2022-07-15 11:15:33 -0400", "message": "Do ToDo per review"}, {"oid": "9abaf88b0ed25513f9f534fa64cf186eb491306a", "committedDate": "2022-07-21 19:34:48 -0400", "message": "Merge remote-tracking branch 'IQSS/develop' into TDL/7493-improve_BagGnerator_failure_handling"}, {"oid": "e594b8155db9e7b9fbb61e3ea1500389a3e94f76", "committedDate": "2022-09-29 12:32:34 -0400", "message": "refactor to add parsing per PidProvider"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU4MDIzNQ==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r662580235", "body": "Ah, it seems like maybe all installations do need the new .tsv file. If so, it should be added to the script that adds them all during installation.", "bodyText": "Ah, it seems like maybe all installations do need the new .tsv file. If so, it should be added to the script that adds them all during installation.", "bodyHTML": "<p dir=\"auto\">Ah, it seems like maybe all installations do need the new .tsv file. If so, it should be added to the script that adds them all during installation.</p>", "author": "pdurbin", "createdAt": "2021-07-01T20:43:07Z", "path": "src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java", "diffHunk": "@@ -48,6 +45,8 @@\n     public static JsonLDTerm totalSize = JsonLDTerm.DVCore(\"totalSize\");\r\n     public static JsonLDTerm fileCount = JsonLDTerm.DVCore(\"fileCount\");\r\n     public static JsonLDTerm maxFileSize = JsonLDTerm.DVCore(\"maxFileSize\");\r\n+    \r\n+    public static JsonLDTerm metadataOnOrig = JsonLDTerm.DVCore(\"metadataOnOrig\");\r", "originalCommit": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE3MDI1Ng==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r663170256", "bodyText": "As noted above, this is optional/not needed by default. If we decide to remove the functionality, this line would also go.", "author": "qqmyers", "createdAt": "2021-07-02T17:52:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU4MDIzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NjQ0NDkyMg==", "url": "https://github.com/IQSS/dataverse/pull/7414#discussion_r666444922", "bodyText": "Removed in a5a745d.", "author": "pdurbin", "createdAt": "2021-07-08T18:57:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MjU4MDIzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "a5a745d157036972194ddd790d3320c140219e6e", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java b/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java\nindex 18e865b2f4..20aeceda7d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java\n", "chunk": "@@ -45,8 +45,6 @@ public class JsonLDTerm {\n     public static JsonLDTerm totalSize = JsonLDTerm.DVCore(\"totalSize\");\n     public static JsonLDTerm fileCount = JsonLDTerm.DVCore(\"fileCount\");\n     public static JsonLDTerm maxFileSize = JsonLDTerm.DVCore(\"maxFileSize\");\n-    \n-    public static JsonLDTerm metadataOnOrig = JsonLDTerm.DVCore(\"metadataOnOrig\");\n \n     public JsonLDTerm(JsonLDNamespace namespace, String term) {\n         this.namespace = namespace;\n", "next_change": null}]}, "revised_code_in_main": {"commit": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "changed_code": [{"header": "diff --git a/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java b/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java\nindex 18e865b2f4..20aeceda7d 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/util/json/JsonLDTerm.java\n", "chunk": "@@ -45,8 +45,6 @@ public class JsonLDTerm {\n     public static JsonLDTerm totalSize = JsonLDTerm.DVCore(\"totalSize\");\n     public static JsonLDTerm fileCount = JsonLDTerm.DVCore(\"fileCount\");\n     public static JsonLDTerm maxFileSize = JsonLDTerm.DVCore(\"maxFileSize\");\n-    \n-    public static JsonLDTerm metadataOnOrig = JsonLDTerm.DVCore(\"metadataOnOrig\");\n \n     public JsonLDTerm(JsonLDNamespace namespace, String term) {\n         this.namespace = namespace;\n", "next_change": null}]}, "commits_in_main": [{"oid": "15e7b7c5420eb37f268623cf6ddcf35ef7dedef7", "message": "Merge commit", "committedDate": null}, {"oid": "47c570ca764a1a7d39b9d61943018ba63462af43", "committedDate": "2022-08-06 13:19:12 -0400", "message": "use original name/mimetype/size if ingested"}]}, {"oid": "e159003877928889aa5f3293b4ae64b99dfbf8d2", "url": "https://github.com/IQSS/dataverse/commit/e159003877928889aa5f3293b4ae64b99dfbf8d2", "message": "fix test", "committedDate": "2021-07-02T16:20:55Z", "type": "commit"}, {"oid": "cf8b2b52f4f795c9717cef2702e53be377651a92", "url": "https://github.com/IQSS/dataverse/commit/cf8b2b52f4f795c9717cef2702e53be377651a92", "message": "Update doc/release-notes/6497-semantic-api.md\n\nCo-authored-by: Philip Durbin <philipdurbin@gmail.com>", "committedDate": "2021-07-02T16:24:48Z", "type": "commit"}, {"oid": "d5ff95563970fb5aac3622bea613fcae70a1d86c", "url": "https://github.com/IQSS/dataverse/commit/d5ff95563970fb5aac3622bea613fcae70a1d86c", "message": "Update doc/sphinx-guides/source/developers/dataset-semantic-metadata-api.rst\n\nCo-authored-by: Philip Durbin <philipdurbin@gmail.com>", "committedDate": "2021-07-02T16:30:10Z", "type": "commit"}, {"oid": "61627d161911424e3d586e2f4ffea498c02f7a80", "url": "https://github.com/IQSS/dataverse/commit/61627d161911424e3d586e2f4ffea498c02f7a80", "message": "add create example, remove solr schema copies file", "committedDate": "2021-07-02T17:23:48Z", "type": "commit"}, {"oid": "1d54c68fe4b515e56fee490a302cd8464d278d2d", "url": "https://github.com/IQSS/dataverse/commit/1d54c68fe4b515e56fee490a302cd8464d278d2d", "message": "removed debug logging", "committedDate": "2021-07-02T17:55:19Z", "type": "commit"}, {"oid": "bc821808c71334ecb180deff1bbc8e467a77db8b", "url": "https://github.com/IQSS/dataverse/commit/bc821808c71334ecb180deff1bbc8e467a77db8b", "message": "Merge branch 'IQSS/6497-semantic_api' of https://github.com/GlobalDataverseCommunityConsortium/dataverse.git into IQSS/6497-semantic_api", "committedDate": "2021-07-02T18:06:16Z", "type": "commit"}, {"oid": "4c1d31a59aa4b0be7de74a95efc8d1c08f693a36", "url": "https://github.com/IQSS/dataverse/commit/4c1d31a59aa4b0be7de74a95efc8d1c08f693a36", "message": "missing header", "committedDate": "2021-07-02T18:20:29Z", "type": "commit"}, {"oid": "a5a745d157036972194ddd790d3320c140219e6e", "url": "https://github.com/IQSS/dataverse/commit/a5a745d157036972194ddd790d3320c140219e6e", "message": "remove metadataOnOrig per review", "committedDate": "2021-07-08T16:32:14Z", "type": "commit"}, {"oid": "bd37e3023489aa903393fee0f4283ee166a80900", "url": "https://github.com/IQSS/dataverse/commit/bd37e3023489aa903393fee0f4283ee166a80900", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2021-07-08T16:32:33Z", "type": "commit"}, {"oid": "0138ebb8a8909ed4943c00c2345278258992d2cf", "url": "https://github.com/IQSS/dataverse/commit/0138ebb8a8909ed4943c00c2345278258992d2cf", "message": "add missing create method (in migrate PR)", "committedDate": "2021-07-13T16:54:35Z", "type": "commit"}, {"oid": "13a7841b3e08e84460fbdf1a8a0405adc53bb4a4", "url": "https://github.com/IQSS/dataverse/commit/13a7841b3e08e84460fbdf1a8a0405adc53bb4a4", "message": "No \"@id\" npe fix", "committedDate": "2021-07-13T18:41:24Z", "type": "commit"}, {"oid": "86a08e3362e84de51226f26cae258b52dab107af", "url": "https://github.com/IQSS/dataverse/commit/86a08e3362e84de51226f26cae258b52dab107af", "message": "avoid npe in logging", "committedDate": "2021-07-13T18:52:21Z", "type": "commit"}, {"oid": "0c64c68dff6be42299f1d0d27a9da3431167632b", "url": "https://github.com/IQSS/dataverse/commit/0c64c68dff6be42299f1d0d27a9da3431167632b", "message": "only require \"@id\" when migrating", "committedDate": "2021-07-13T19:39:11Z", "type": "commit"}, {"oid": "8e9f2f72223453f85dd81ff425c959582a127b9e", "url": "https://github.com/IQSS/dataverse/commit/8e9f2f72223453f85dd81ff425c959582a127b9e", "message": "fix logging in create case", "committedDate": "2021-07-13T20:36:15Z", "type": "commit"}, {"oid": "4d7097170d7e1399f751846e3dd6de07c853fc2f", "url": "https://github.com/IQSS/dataverse/commit/4d7097170d7e1399f751846e3dd6de07c853fc2f", "message": "initial semantic API endpoint", "committedDate": "2020-03-23T17:37:31Z", "type": "commit"}, {"oid": "b2befca1c389f2d170cde88083e434d923e84147", "url": "https://github.com/IQSS/dataverse/commit/b2befca1c389f2d170cde88083e434d923e84147", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497", "committedDate": "2020-03-23T17:50:08Z", "type": "commit"}, {"oid": "fb6421bbd1573f2eb012f1ab49f4e9daed704372", "url": "https://github.com/IQSS/dataverse/commit/fb6421bbd1573f2eb012f1ab49f4e9daed704372", "message": "merge new fields with existing ones", "committedDate": "2020-03-24T20:29:29Z", "type": "commit"}, {"oid": "8bc3df6a800e53530b41887de3b2f46ff449a876", "url": "https://github.com/IQSS/dataverse/commit/8bc3df6a800e53530b41887de3b2f46ff449a876", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497", "committedDate": "2020-03-27T14:27:50Z", "type": "commit"}, {"oid": "5b828aa78acf217858fd4de645151213613afe48", "url": "https://github.com/IQSS/dataverse/commit/5b828aa78acf217858fd4de645151213613afe48", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497", "committedDate": "2020-04-17T18:28:04Z", "type": "commit"}, {"oid": "f472b6c17f6419380447d8fde1095f0598318086", "url": "https://github.com/IQSS/dataverse/commit/f472b6c17f6419380447d8fde1095f0598318086", "message": "differences from IQSS/develop that break compilation", "committedDate": "2020-04-17T18:31:00Z", "type": "commit"}, {"oid": "bab11f0927cb0660baddb5b49fd1bd40bed4b645", "url": "https://github.com/IQSS/dataverse/commit/bab11f0927cb0660baddb5b49fd1bd40bed4b645", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tsrc/main/java/edu/harvard/iq/dataverse/api/Datasets.java", "committedDate": "2020-08-31T16:26:42Z", "type": "commit"}, {"oid": "d30586709792d3383d77d380521549022a3f729b", "url": "https://github.com/IQSS/dataverse/commit/d30586709792d3383d77d380521549022a3f729b", "message": "Add jsonld lib to compact to local context", "committedDate": "2020-09-08T20:01:50Z", "type": "commit"}, {"oid": "98d978e45faa9e436eff53559174e6a7f2dd52e3", "url": "https://github.com/IQSS/dataverse/commit/98d978e45faa9e436eff53559174e6a7f2dd52e3", "message": "use expand/compact, refactor, add :startmigration endpoint", "committedDate": "2020-09-11T19:37:24Z", "type": "commit"}, {"oid": "244370246eba5e3e02681a478a59b2373ce21f17", "url": "https://github.com/IQSS/dataverse/commit/244370246eba5e3e02681a478a59b2373ce21f17", "message": "try fix for parse error", "committedDate": "2020-09-16T20:53:57Z", "type": "commit"}, {"oid": "d44264321edc00e2744a20b6b16bd199b3dda6ba", "url": "https://github.com/IQSS/dataverse/commit/d44264321edc00e2744a20b6b16bd199b3dda6ba", "message": "log value", "committedDate": "2020-09-16T20:55:01Z", "type": "commit"}, {"oid": "fdeac97e24b9740ca7ea95759e20d6aece254f4b", "url": "https://github.com/IQSS/dataverse/commit/fdeac97e24b9740ca7ea95759e20d6aece254f4b", "message": "return dataset", "committedDate": "2020-09-16T21:30:39Z", "type": "commit"}, {"oid": "554e62091b8b31d79b3c65882311b6dbe3db69a8", "url": "https://github.com/IQSS/dataverse/commit/554e62091b8b31d79b3c65882311b6dbe3db69a8", "message": "manage versionState, add debug output", "committedDate": "2020-09-17T14:04:16Z", "type": "commit"}, {"oid": "bee7731fe34153ba1f89dc00b6e474d9c5b33a01", "url": "https://github.com/IQSS/dataverse/commit/bee7731fe34153ba1f89dc00b6e474d9c5b33a01", "message": "move debug ore generation after configuring dataset", "committedDate": "2020-09-17T14:25:44Z", "type": "commit"}, {"oid": "f4cecd3f39992c895a73bbdf5bd2396518b0ce2c", "url": "https://github.com/IQSS/dataverse/commit/f4cecd3f39992c895a73bbdf5bd2396518b0ce2c", "message": "set versionstate, simplify, move terms init outside loop", "committedDate": "2020-09-17T16:16:56Z", "type": "commit"}, {"oid": "a4189de0f3332ec75216c57374562a50cc4f5944", "url": "https://github.com/IQSS/dataverse/commit/a4189de0f3332ec75216c57374562a50cc4f5944", "message": "parse version number", "committedDate": "2020-09-17T17:30:32Z", "type": "commit"}, {"oid": "e0de1dba2dc6f1959c03580acdbffa465332f40a", "url": "https://github.com/IQSS/dataverse/commit/e0de1dba2dc6f1959c03580acdbffa465332f40a", "message": "fix toStrings", "committedDate": "2020-09-17T17:51:48Z", "type": "commit"}, {"oid": "928a88e1df05300b45d7d03e0bb0f5dda73cd642", "url": "https://github.com/IQSS/dataverse/commit/928a88e1df05300b45d7d03e0bb0f5dda73cd642", "message": "debug null pointer in DataverseFieldTypeInputLevel", "committedDate": "2020-09-17T20:13:12Z", "type": "commit"}, {"oid": "b78aed1886d4f9f52e418731e1119826f1b08c77", "url": "https://github.com/IQSS/dataverse/commit/b78aed1886d4f9f52e418731e1119826f1b08c77", "message": "add support for fields with their own formal URI", "committedDate": "2020-09-17T22:06:12Z", "type": "commit"}, {"oid": "3a47630f339d9eada23cbb12f65cd382b2c7f2d1", "url": "https://github.com/IQSS/dataverse/commit/3a47630f339d9eada23cbb12f65cd382b2c7f2d1", "message": "allow non-published to support debugging and future use", "committedDate": "2020-09-17T22:06:32Z", "type": "commit"}, {"oid": "3f8534bd690c28b1203a1979130183c573dfff2f", "url": "https://github.com/IQSS/dataverse/commit/3f8534bd690c28b1203a1979130183c573dfff2f", "message": "refactor, use expanded version directly", "committedDate": "2020-09-18T15:18:21Z", "type": "commit"}, {"oid": "64af0e8384ecb94dcf337bc8a2b66fe83c216c30", "url": "https://github.com/IQSS/dataverse/commit/64af0e8384ecb94dcf337bc8a2b66fe83c216c30", "message": "add modification time", "committedDate": "2020-09-18T15:28:17Z", "type": "commit"}, {"oid": "04ee08ae2a47edf72a760bfebbea8312d61be5e2", "url": "https://github.com/IQSS/dataverse/commit/04ee08ae2a47edf72a760bfebbea8312d61be5e2", "message": "expanded has array with 1 val - handle it", "committedDate": "2020-09-18T16:08:41Z", "type": "commit"}, {"oid": "c7c257382fefac53bd7374f258f9dd5a4792f5a9", "url": "https://github.com/IQSS/dataverse/commit/c7c257382fefac53bd7374f258f9dd5a4792f5a9", "message": "log compound values to start", "committedDate": "2020-09-18T16:13:10Z", "type": "commit"}, {"oid": "fc77f924b113936a4c438ca4f889f1164af16540", "url": "https://github.com/IQSS/dataverse/commit/fc77f924b113936a4c438ca4f889f1164af16540", "message": "compact with no context for decontextualize", "committedDate": "2020-09-18T17:54:30Z", "type": "commit"}, {"oid": "e2876449654628b4ef51907909eb0ceda77d0093", "url": "https://github.com/IQSS/dataverse/commit/e2876449654628b4ef51907909eb0ceda77d0093", "message": "handle appending and compound fields", "committedDate": "2020-09-18T21:49:16Z", "type": "commit"}, {"oid": "8596ac80ef206f9141cfc9815c0e98ccf718b327", "url": "https://github.com/IQSS/dataverse/commit/8596ac80ef206f9141cfc9815c0e98ccf718b327", "message": "sort compound field children by display order", "committedDate": "2020-09-20T14:57:53Z", "type": "commit"}, {"oid": "ffbc05ad7422cbf5080c0f576986dd494946d935", "url": "https://github.com/IQSS/dataverse/commit/ffbc05ad7422cbf5080c0f576986dd494946d935", "message": "parse date/time correctly", "committedDate": "2020-09-22T16:15:03Z", "type": "commit"}, {"oid": "0226b0d3c6cb15f3b7700eb1c259db90a9c75fa4", "url": "https://github.com/IQSS/dataverse/commit/0226b0d3c6cb15f3b7700eb1c259db90a9c75fa4", "message": "Revert \"sort compound field children by display order\"\n\nThis reverts commit 8596ac80ef206f9141cfc9815c0e98ccf718b327.", "committedDate": "2020-09-22T19:41:53Z", "type": "commit"}, {"oid": "fad62f44203210117b968ba84e4c6428aaa2fdd8", "url": "https://github.com/IQSS/dataverse/commit/fad62f44203210117b968ba84e4c6428aaa2fdd8", "message": "typo", "committedDate": "2020-09-22T19:47:29Z", "type": "commit"}, {"oid": "c6b19a9da2d4c54367021db830309cac445ad335", "url": "https://github.com/IQSS/dataverse/commit/c6b19a9da2d4c54367021db830309cac445ad335", "message": "now use Uri instead of label when matching terms", "committedDate": "2020-09-22T20:10:46Z", "type": "commit"}, {"oid": "a014fc43aa41a58c856eca3c185d55959f097585", "url": "https://github.com/IQSS/dataverse/commit/a014fc43aa41a58c856eca3c185d55959f097585", "message": "set dsfield of dsfvalue", "committedDate": "2020-09-22T21:22:22Z", "type": "commit"}, {"oid": "5bb5e68e3e4ceb90054d1bd085ac4c4909854813", "url": "https://github.com/IQSS/dataverse/commit/5bb5e68e3e4ceb90054d1bd085ac4c4909854813", "message": "additional debug, always set display order", "committedDate": "2020-09-23T13:21:01Z", "type": "commit"}, {"oid": "6a47fad40f9afcc3f98ef9acfe2bceb119ff4ffe", "url": "https://github.com/IQSS/dataverse/commit/6a47fad40f9afcc3f98ef9acfe2bceb119ff4ffe", "message": "generate URIs for child types to match current ore maps", "committedDate": "2020-09-23T14:10:13Z", "type": "commit"}, {"oid": "f34da09948bd726ea92c525d861ee6ec8b3d0fb4", "url": "https://github.com/IQSS/dataverse/commit/f34da09948bd726ea92c525d861ee6ec8b3d0fb4", "message": "allow oremap to work w/o modified date for debug", "committedDate": "2020-09-23T14:12:51Z", "type": "commit"}, {"oid": "6b8bbc77a75bfb37e97acd6b4d1b057bc2f0ae88", "url": "https://github.com/IQSS/dataverse/commit/6b8bbc77a75bfb37e97acd6b4d1b057bc2f0ae88", "message": "null check on date itself", "committedDate": "2020-09-23T14:49:57Z", "type": "commit"}, {"oid": "8af09380bd21fe112e95af6a213f7f39eaf21970", "url": "https://github.com/IQSS/dataverse/commit/8af09380bd21fe112e95af6a213f7f39eaf21970", "message": "fix compound value iteration\n\ndon't replace existing value - always add a new value, but, if not\nappending, clear the list of values to start", "committedDate": "2020-09-23T15:01:19Z", "type": "commit"}, {"oid": "79048442a4b3421769c3d6c4c913d212ec1c6133", "url": "https://github.com/IQSS/dataverse/commit/79048442a4b3421769c3d6c4c913d212ec1c6133", "message": "fix ttype map for terms with no uri - use title not name\n\nas is done currently in generating the ORE map", "committedDate": "2020-09-23T15:12:31Z", "type": "commit"}, {"oid": "e4ceee3d7dc91d2f913cfc713502656faa459c1d", "url": "https://github.com/IQSS/dataverse/commit/e4ceee3d7dc91d2f913cfc713502656faa459c1d", "message": "handle date format variations, including DV internal ones\n\nsee note in Dataverses - using Date() versus Timestamp() causes a\ndifference in precision and, perhaps surprisingly, a difference in the\nresponse from version.getLastUpdateTime().toString() in creating the\nOREmap.", "committedDate": "2020-09-23T20:27:00Z", "type": "commit"}, {"oid": "f176387c627a06dc89f67f4b266da56e4d7cb979", "url": "https://github.com/IQSS/dataverse/commit/f176387c627a06dc89f67f4b266da56e4d7cb979", "message": "and the format in current published bags", "committedDate": "2020-09-23T21:09:28Z", "type": "commit"}, {"oid": "2724d9ebb8c543ab26eb1991d8eeeae33d13f025", "url": "https://github.com/IQSS/dataverse/commit/2724d9ebb8c543ab26eb1991d8eeeae33d13f025", "message": "initial endpoint to release a migrated dataset", "committedDate": "2020-09-24T13:55:26Z", "type": "commit"}, {"oid": "7d5006d93941a6a5f89d08ed235b10d28dfc8c80", "url": "https://github.com/IQSS/dataverse/commit/7d5006d93941a6a5f89d08ed235b10d28dfc8c80", "message": "create metadataOnOrig field", "committedDate": "2020-09-24T16:40:08Z", "type": "commit"}, {"oid": "925070b4bbc856127dadc238d163d3fbe563ebba", "url": "https://github.com/IQSS/dataverse/commit/925070b4bbc856127dadc238d163d3fbe563ebba", "message": "add metadataOnOrig to solr", "committedDate": "2020-09-24T17:43:27Z", "type": "commit"}, {"oid": "005db9753c633562987a0fe5f863d1c03a99bb6d", "url": "https://github.com/IQSS/dataverse/commit/005db9753c633562987a0fe5f863d1c03a99bb6d", "message": "use Finalize Publication command\n\nCurate is for cases with an existing published version and migrated\ndatasets only have 1 version\n\nAlso - don't want to go through Publish command since it creates new\nversion numbers, etc.", "committedDate": "2020-09-24T20:04:12Z", "type": "commit"}, {"oid": "f336cfda5bcd6ad591b22b987508abaa7e370a34", "url": "https://github.com/IQSS/dataverse/commit/f336cfda5bcd6ad591b22b987508abaa7e370a34", "message": "add debug, allow more details in 400 responses", "committedDate": "2020-09-24T21:05:50Z", "type": "commit"}, {"oid": "0de70dd4f8a81fcaa74af63090436e6fbb46a85b", "url": "https://github.com/IQSS/dataverse/commit/0de70dd4f8a81fcaa74af63090436e6fbb46a85b", "message": "fix date-time issue", "committedDate": "2020-09-24T22:03:22Z", "type": "commit"}, {"oid": "395bb71ee512fc3e969ebd48a0e2b0f631617d80", "url": "https://github.com/IQSS/dataverse/commit/395bb71ee512fc3e969ebd48a0e2b0f631617d80", "message": "typos", "committedDate": "2020-09-25T13:26:39Z", "type": "commit"}, {"oid": "61c0349061e54548d877cd37403d0aeebf1d19f7", "url": "https://github.com/IQSS/dataverse/commit/61c0349061e54548d877cd37403d0aeebf1d19f7", "message": "create transfer bag type with orig files\n\nhandle no checksums on orig files", "committedDate": "2020-09-25T17:00:54Z", "type": "commit"}, {"oid": "1753257836e34ccb0017a0b8a3b58f39d4aaa18d", "url": "https://github.com/IQSS/dataverse/commit/1753257836e34ccb0017a0b8a3b58f39d4aaa18d", "message": "missing tab", "committedDate": "2020-09-30T20:39:04Z", "type": "commit"}, {"oid": "e642c65c3490c1bfd22058c9a3321a6f115426fc", "url": "https://github.com/IQSS/dataverse/commit/e642c65c3490c1bfd22058c9a3321a6f115426fc", "message": "add type param", "committedDate": "2020-09-30T21:20:20Z", "type": "commit"}, {"oid": "df66f224d0e9fe4446f946f3a8af9ee8e258cf92", "url": "https://github.com/IQSS/dataverse/commit/df66f224d0e9fe4446f946f3a8af9ee8e258cf92", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tsrc/main/java/edu/harvard/iq/dataverse/api/Datasets.java", "committedDate": "2020-10-06T15:25:02Z", "type": "commit"}, {"oid": "3445daac3136cfc5b9d87daafb8ac139f5a80ed6", "url": "https://github.com/IQSS/dataverse/commit/3445daac3136cfc5b9d87daafb8ac139f5a80ed6", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2020-11-16T16:43:15Z", "type": "commit"}, {"oid": "2e1d914cc7e344b31f3b4169e9d799f3a5340b84", "url": "https://github.com/IQSS/dataverse/commit/2e1d914cc7e344b31f3b4169e9d799f3a5340b84", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2020-11-16T19:19:27Z", "type": "commit"}, {"oid": "9ad779a2d0c7b74b5c4957d93bc1e2f3f7dab23f", "url": "https://github.com/IQSS/dataverse/commit/9ad779a2d0c7b74b5c4957d93bc1e2f3f7dab23f", "message": "add semantic metadata api call only", "committedDate": "2020-11-16T19:55:12Z", "type": "commit"}, {"oid": "8abd55e9e6a0031e60cf701790aaced3e2a4cbd0", "url": "https://github.com/IQSS/dataverse/commit/8abd55e9e6a0031e60cf701790aaced3e2a4cbd0", "message": "remove OREMap parameter", "committedDate": "2020-12-01T17:43:56Z", "type": "commit"}, {"oid": "1a35ed24a1c2721f66bec1c91ad17a38571abc43", "url": "https://github.com/IQSS/dataverse/commit/1a35ed24a1c2721f66bec1c91ad17a38571abc43", "message": "fix error handling\n\nFWIW: We have an error handler for the\nedu.harvard.iq.dataverse.util.json.JsonParseException class but not for\njavax.json.stream.JsonParsingException which was getting caught by the\nThrowable handler and returned as a 500 error with json message {}", "committedDate": "2020-12-01T20:34:07Z", "type": "commit"}, {"oid": "7b1512e71ecb7c0482f41e62a5b5b7a3eb459259", "url": "https://github.com/IQSS/dataverse/commit/7b1512e71ecb7c0482f41e62a5b5b7a3eb459259", "message": "append to current terms", "committedDate": "2020-12-01T21:29:36Z", "type": "commit"}, {"oid": "e5b54dfc6739c06bccb447103633d4dcd1f930f5", "url": "https://github.com/IQSS/dataverse/commit/e5b54dfc6739c06bccb447103633d4dcd1f930f5", "message": "add replace param", "committedDate": "2020-12-01T22:01:24Z", "type": "commit"}, {"oid": "578790f0b2558721f98defab8b384681246856f3", "url": "https://github.com/IQSS/dataverse/commit/578790f0b2558721f98defab8b384681246856f3", "message": "handle append on terms - fix cut/paste errors", "committedDate": "2020-12-02T15:34:22Z", "type": "commit"}, {"oid": "acee4df8ce31d9d910766560caa459b2c15374a2", "url": "https://github.com/IQSS/dataverse/commit/acee4df8ce31d9d910766560caa459b2c15374a2", "message": "fix logic", "committedDate": "2020-12-02T16:58:50Z", "type": "commit"}, {"oid": "9185126fb88970b1b3e3a448070745f232261a11", "url": "https://github.com/IQSS/dataverse/commit/9185126fb88970b1b3e3a448070745f232261a11", "message": "specify default", "committedDate": "2020-12-02T16:59:09Z", "type": "commit"}, {"oid": "e8698dc41095d03442ebb156d5b4de03c3cec1ca", "url": "https://github.com/IQSS/dataverse/commit/e8698dc41095d03442ebb156d5b4de03c3cec1ca", "message": "make replace still append for multiple val fields", "committedDate": "2020-12-02T17:21:56Z", "type": "commit"}, {"oid": "901efe863fb13d31dfdd8751373657f469090e2b", "url": "https://github.com/IQSS/dataverse/commit/901efe863fb13d31dfdd8751373657f469090e2b", "message": "add migrating switch", "committedDate": "2020-12-02T19:38:17Z", "type": "commit"}, {"oid": "34a28a37180c3c1a698ad359c88ff945a5ed0f53", "url": "https://github.com/IQSS/dataverse/commit/34a28a37180c3c1a698ad359c88ff945a5ed0f53", "message": "expose uri in datasetField api", "committedDate": "2020-12-03T18:13:28Z", "type": "commit"}, {"oid": "1b98b2c959b2f8ad92c020e2ffb05efc5a645551", "url": "https://github.com/IQSS/dataverse/commit/1b98b2c959b2f8ad92c020e2ffb05efc5a645551", "message": "track defined namespaces\n\nand avoid having contexts with specific entries for terms that are in a\nnamespace already", "committedDate": "2020-12-03T19:27:14Z", "type": "commit"}, {"oid": "55a8b303b124b1d9982c1aba620c443a499628c0", "url": "https://github.com/IQSS/dataverse/commit/55a8b303b124b1d9982c1aba620c443a499628c0", "message": "define equals, avoid duplicates in list", "committedDate": "2020-12-03T20:22:37Z", "type": "commit"}, {"oid": "966394ad33ded6939f9d606d0ca4682cb32f25a8", "url": "https://github.com/IQSS/dataverse/commit/966394ad33ded6939f9d606d0ca4682cb32f25a8", "message": "replace string with const", "committedDate": "2020-12-04T20:27:43Z", "type": "commit"}, {"oid": "b83f7b2f134ce87e5cf2b1d7af8182b756f1faf0", "url": "https://github.com/IQSS/dataverse/commit/b83f7b2f134ce87e5cf2b1d7af8182b756f1faf0", "message": "constant for CC0_URI", "committedDate": "2020-12-04T20:28:14Z", "type": "commit"}, {"oid": "1e08f102e617fcfcdeea7482d03e5aeae8270c11", "url": "https://github.com/IQSS/dataverse/commit/1e08f102e617fcfcdeea7482d03e5aeae8270c11", "message": "GET/DELETE endpoints", "committedDate": "2020-12-04T20:28:32Z", "type": "commit"}, {"oid": "780630f3a953c736a7a6278db98e64c04371c5f9", "url": "https://github.com/IQSS/dataverse/commit/780630f3a953c736a7a6278db98e64c04371c5f9", "message": "7130-handle missing contact name", "committedDate": "2020-12-08T17:58:16Z", "type": "commit"}, {"oid": "cc7e69cf143a62df201d8a1fe30ae0ab017b7328", "url": "https://github.com/IQSS/dataverse/commit/cc7e69cf143a62df201d8a1fe30ae0ab017b7328", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2020-12-08T18:01:11Z", "type": "commit"}, {"oid": "e0ea36ea18d121229ed10620f4030f27017d1775", "url": "https://github.com/IQSS/dataverse/commit/e0ea36ea18d121229ed10620f4030f27017d1775", "message": "Fix multiple description logic for info file", "committedDate": "2020-12-11T18:16:08Z", "type": "commit"}, {"oid": "6d0c6153f2215815b6d9be201e66fe191ed447e0", "url": "https://github.com/IQSS/dataverse/commit/6d0c6153f2215815b6d9be201e66fe191ed447e0", "message": "put is always for :draft version", "committedDate": "2020-12-11T18:44:51Z", "type": "commit"}, {"oid": "51f8f78cbf6c30a142c481587d1bb93ed1f797a1", "url": "https://github.com/IQSS/dataverse/commit/51f8f78cbf6c30a142c481587d1bb93ed1f797a1", "message": "don't cast to String[]", "committedDate": "2020-12-11T20:17:22Z", "type": "commit"}, {"oid": "353644a0e0bf560839841ba29bb3911ae0c03e70", "url": "https://github.com/IQSS/dataverse/commit/353644a0e0bf560839841ba29bb3911ae0c03e70", "message": "add more logging", "committedDate": "2020-12-11T20:17:52Z", "type": "commit"}, {"oid": "2382fef9211623ba35f56c0f59accfb06c4bafa0", "url": "https://github.com/IQSS/dataverse/commit/2382fef9211623ba35f56c0f59accfb06c4bafa0", "message": "handle unpublished versions", "committedDate": "2020-12-11T20:34:10Z", "type": "commit"}, {"oid": "243769aee31fe5c49ca93a1f168aa8ac083d493d", "url": "https://github.com/IQSS/dataverse/commit/243769aee31fe5c49ca93a1f168aa8ac083d493d", "message": "add method that can return JsonObjectBuilder\n\nwhich can be used with existing AbstractApiBean.ok()", "committedDate": "2020-12-11T22:27:05Z", "type": "commit"}, {"oid": "9bfa7c3d2f6c492b361fccd13f0bbc109d325353", "url": "https://github.com/IQSS/dataverse/commit/9bfa7c3d2f6c492b361fccd13f0bbc109d325353", "message": "log details on failure", "committedDate": "2020-12-11T22:27:24Z", "type": "commit"}, {"oid": "60f8a99676e1b9e2c35e7f624fc4f3da58d6675d", "url": "https://github.com/IQSS/dataverse/commit/60f8a99676e1b9e2c35e7f624fc4f3da58d6675d", "message": "multiple updates/fixes, added logging", "committedDate": "2020-12-11T22:27:55Z", "type": "commit"}, {"oid": "464832a4c47e9234f62e92d04a960333d68a7e1e", "url": "https://github.com/IQSS/dataverse/commit/464832a4c47e9234f62e92d04a960333d68a7e1e", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2020-12-22T19:17:51Z", "type": "commit"}, {"oid": "e93114940d5ed79cbfa138fcf5262b90d36b83ef", "url": "https://github.com/IQSS/dataverse/commit/e93114940d5ed79cbfa138fcf5262b90d36b83ef", "message": "fix terms retrieval", "committedDate": "2020-12-22T20:02:12Z", "type": "commit"}, {"oid": "2b8189afc433e5e4d0367d7391fe707fead036fa", "url": "https://github.com/IQSS/dataverse/commit/2b8189afc433e5e4d0367d7391fe707fead036fa", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2021-01-08T14:56:23Z", "type": "commit"}, {"oid": "e8f737c7ce334643b75139770248780611de54bf", "url": "https://github.com/IQSS/dataverse/commit/e8f737c7ce334643b75139770248780611de54bf", "message": "date test fixes for locale", "committedDate": "2021-01-13T22:29:12Z", "type": "commit"}, {"oid": "1c93260df74dee477162dc24318412974dad8329", "url": "https://github.com/IQSS/dataverse/commit/1c93260df74dee477162dc24318412974dad8329", "message": "Java 11 update and test fixes inc. for different exception mesg", "committedDate": "2021-01-13T22:29:49Z", "type": "commit"}, {"oid": "a85c1d68b3873ef00a96ecc5681d301d77190760", "url": "https://github.com/IQSS/dataverse/commit/a85c1d68b3873ef00a96ecc5681d301d77190760", "message": "update pom for v11 and running tests under 11", "committedDate": "2021-01-14T18:36:03Z", "type": "commit"}, {"oid": "1476a613cb2eb455e7045712d61cc4dcfd02e473", "url": "https://github.com/IQSS/dataverse/commit/1476a613cb2eb455e7045712d61cc4dcfd02e473", "message": "Merge branch 'iqssdevelop' into IQSS/6497-semantic_api\n\nConflicts:\n\tpom.xml", "committedDate": "2021-01-14T18:53:37Z", "type": "commit"}, {"oid": "a52353b8461d4d191f7e92561b3771411e895ff3", "url": "https://github.com/IQSS/dataverse/commit/a52353b8461d4d191f7e92561b3771411e895ff3", "message": "fix for edu.harvard.iq.dataverse.api.AdminIT test fail in Java 11\n\nThe DV code tested in testLoadMetadataBlock_ErrorHandling assumed it\ncould parse the message of an ArrayOutOfBounds exception as an it to\ndetermine the column that fails. This message is now a String. Rather\nthan parse it (and fail if it changes), I modified the code so that the\nlength of the values array is visible in the catch and can be sent\ndirectly (the first out of bounds index is if/when the index is\nvalues.length).", "committedDate": "2021-01-14T20:36:48Z", "type": "commit"}, {"oid": "6f405abadb1bfe54eda29225624b975ff298e4a8", "url": "https://github.com/IQSS/dataverse/commit/6f405abadb1bfe54eda29225624b975ff298e4a8", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tpom.xml\n\tsrc/main/java/edu/harvard/iq/dataverse/api/DatasetFieldServiceApi.java\n\tsrc/test/java/edu/harvard/iq/dataverse/dataaccess/StorageIOTest.java", "committedDate": "2021-01-29T16:07:44Z", "type": "commit"}, {"oid": "e866ae0f9bf89df5afca790d6c0893074abb73d9", "url": "https://github.com/IQSS/dataverse/commit/e866ae0f9bf89df5afca790d6c0893074abb73d9", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tsrc/test/java/edu/harvard/iq/dataverse/FileMetadataTest.java", "committedDate": "2021-02-08T19:55:38Z", "type": "commit"}, {"oid": "d5b8b45b5d37cfc292c8025b3ca8e09adf93a763", "url": "https://github.com/IQSS/dataverse/commit/d5b8b45b5d37cfc292c8025b3ca8e09adf93a763", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tsrc/main/java/edu/harvard/iq/dataverse/api/Datasets.java", "committedDate": "2021-02-23T18:09:57Z", "type": "commit"}, {"oid": "56acda8945bdb88ae3b21b9bac11ddef05101b4e", "url": "https://github.com/IQSS/dataverse/commit/56acda8945bdb88ae3b21b9bac11ddef05101b4e", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tconf/solr/7.7.2/schema_dv_mdb_copies.xml\n\tconf/solr/7.7.2/schema_dv_mdb_fields.xml\n\tsrc/main/java/edu/harvard/iq/dataverse/util/bagit/OREMap.java", "committedDate": "2021-04-07T21:28:27Z", "type": "commit"}, {"oid": "f19a1997e89ea1f6c4b66daf4070ac64619329a4", "url": "https://github.com/IQSS/dataverse/commit/f19a1997e89ea1f6c4b66daf4070ac64619329a4", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2021-04-13T18:35:32Z", "type": "commit"}, {"oid": "a7c6b3f427e647b2d8ae69fd666fdecbd94b4b59", "url": "https://github.com/IQSS/dataverse/commit/a7c6b3f427e647b2d8ae69fd666fdecbd94b4b59", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tsrc/main/java/edu/harvard/iq/dataverse/api/util/JsonResponseBuilder.java", "committedDate": "2021-04-26T18:32:08Z", "type": "commit"}, {"oid": "33fb8de59683747eb488fa8795241eddb0f49ae4", "url": "https://github.com/IQSS/dataverse/commit/33fb8de59683747eb488fa8795241eddb0f49ae4", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api\n\nConflicts:\n\tconf/solr/8.8.1/schema_dv_mdb_copies.xml", "committedDate": "2021-05-20T17:05:39Z", "type": "commit"}, {"oid": "87c581f0dfc89b5c457f9c45ea985a4d552034d2", "url": "https://github.com/IQSS/dataverse/commit/87c581f0dfc89b5c457f9c45ea985a4d552034d2", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2021-06-03T16:18:24Z", "type": "commit"}, {"oid": "f47b268fb83f81b09ef99514ec26c6806a70c47a", "url": "https://github.com/IQSS/dataverse/commit/f47b268fb83f81b09ef99514ec26c6806a70c47a", "message": "update StringUtils package", "committedDate": "2021-06-03T16:47:38Z", "type": "commit"}, {"oid": "6d73b61d45352deb79a1064ea159a0e1cbf59586", "url": "https://github.com/IQSS/dataverse/commit/6d73b61d45352deb79a1064ea159a0e1cbf59586", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2021-06-23T17:24:29Z", "type": "commit"}, {"oid": "4714ea628651cd0653f98ed31f7f07de75be9472", "url": "https://github.com/IQSS/dataverse/commit/4714ea628651cd0653f98ed31f7f07de75be9472", "message": "move metadataOnOrig out of citation block\n\nwhich makes it optional", "committedDate": "2021-06-23T17:36:43Z", "type": "commit"}, {"oid": "82a5b23842a46009c98f5da4ef671e30c9e05c37", "url": "https://github.com/IQSS/dataverse/commit/82a5b23842a46009c98f5da4ef671e30c9e05c37", "message": "sync with migration api branch (tests, docs, bug fixes)", "committedDate": "2021-06-30T15:58:49Z", "type": "commit"}, {"oid": "10ef9ff27eb38668bd06234f9bb79545782d36e7", "url": "https://github.com/IQSS/dataverse/commit/10ef9ff27eb38668bd06234f9bb79545782d36e7", "message": "Merge remote-tracking branch 'IQSS/develop' into IQSS/6497-semantic_api", "committedDate": "2021-06-30T15:59:22Z", "type": "commit"}]}