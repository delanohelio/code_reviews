{"pr_number": 1030, "pr_title": "issue #945 Add SPs support to PostgreSql and enable paremeterNameId and codesystemId caches", "pr_author": "albertwang-ibm", "pr_createdAt": "2020-05-06T02:18:30Z", "pr_url": "https://github.com/IBM/FHIR/pull/1030", "timeline": [{"oid": "335bdaf1e850695a9f4e48ede068365af57fa093", "url": "https://github.com/IBM/FHIR/commit/335bdaf1e850695a9f4e48ede068365af57fa093", "message": "Merge pull request #1017 from IBM/issue-945\n\nIssue 945", "committedDate": "2020-05-04T14:18:40Z", "type": "commit"}, {"oid": "27dc620d90c6831fe50ad359b89404a558fa84f9", "url": "https://github.com/IBM/FHIR/commit/27dc620d90c6831fe50ad359b89404a558fa84f9", "message": "Merge branch 'albert-master' into issue-945", "committedDate": "2020-05-06T00:26:10Z", "type": "commit"}, {"oid": "d14972b64e0253241270f3bd58dc1be318dd31bc", "url": "https://github.com/IBM/FHIR/commit/d14972b64e0253241270f3bd58dc1be318dd31bc", "message": "Merge pull request #1028 from IBM/issue-945\n\nIssue 945", "committedDate": "2020-05-06T00:26:22Z", "type": "commit"}, {"oid": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "url": "https://github.com/IBM/FHIR/commit/b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "message": "issue #945 SP support for postgresql inital code drop\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-06T02:17:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxNjgxMQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420716811", "body": "I do not think this should be in place of createOrReplaceProcedure.  There should be a new method for createOrReplaceFunction. Functions are a common db mechanism, I think this should remain as 153, and a new element for createOrReplaceFunction should be added.", "bodyText": "I do not think this should be in place of createOrReplaceProcedure.  There should be a new method for createOrReplaceFunction. Functions are a common db mechanism, I think this should remain as 153, and a new element for createOrReplaceFunction should be added.", "bodyHTML": "<p dir=\"auto\">I do not think this should be in place of createOrReplaceProcedure.  There should be a new method for createOrReplaceFunction. Functions are a common db mechanism, I think this should remain as 153, and a new element for createOrReplaceFunction should be added.</p>", "author": "prb112", "createdAt": "2020-05-06T11:23:50Z", "path": "fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java", "diffHunk": "@@ -150,7 +150,22 @@ public void dropType(String schemaName, String typeName) {\n \n     @Override\n     public void createOrReplaceProcedure(String schemaName, String procedureName, Supplier<String> supplier) {\n-        warnOnce(MessageKey.CREATE_PROC, \"Create procedure not supported in PostgreSql\");\n+        final String objectName = DataDefinitionUtil.getQualifiedName(schemaName, procedureName);\n+        logger.info(\"Create or replace procedure \" + objectName);\n+\n+        // Build the create procedure DDL and apply it\n+        final StringBuilder ddl = new StringBuilder();\n+        ddl.append(\"CREATE OR REPLACE FUNCTION \");", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxMTQwMA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421211400", "bodyText": "I would prefer to keep it simpler as it's now.\nI chose to use postgresql function(or fake stored procedure) instead of procedure simply because postgresql doesn't have out parameter support at present, when postgresql support out parameter, then we can just change it to a real stored procedure.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:03:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxNjgxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\nindex 65ad4e1eea..e5007fc9ed 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n", "chunk": "@@ -154,11 +154,11 @@ public class PostgreSqlAdapter extends CommonDatabaseAdapter {\n         logger.info(\"Create or replace procedure \" + objectName);\n \n         // Build the create procedure DDL and apply it\n-        final StringBuilder ddl = new StringBuilder();\n-        ddl.append(\"CREATE OR REPLACE FUNCTION \");\n-        ddl.append(objectName);\n-        ddl.append(System.lineSeparator());\n-        ddl.append(supplier.get());\n+        final StringBuilder ddl = new StringBuilder()\n+                .append(\"CREATE OR REPLACE FUNCTION \")\n+                .append(objectName)\n+                .append(System.lineSeparator())\n+                .append(supplier.get());\n \n         final String ddlString = ddl.toString();\n         if (logger.isLoggable(Level.FINE)) {\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\nindex e5007fc9ed..e9071d50c3 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n", "chunk": "@@ -148,31 +153,6 @@ public class PostgreSqlAdapter extends CommonDatabaseAdapter {\n         warnOnce(MessageKey.DROP_TYPE, \"Drop type not supported in PostgreSql\");\n     }\n \n-    @Override\n-    public void createOrReplaceProcedure(String schemaName, String procedureName, Supplier<String> supplier) {\n-        final String objectName = DataDefinitionUtil.getQualifiedName(schemaName, procedureName);\n-        logger.info(\"Create or replace procedure \" + objectName);\n-\n-        // Build the create procedure DDL and apply it\n-        final StringBuilder ddl = new StringBuilder()\n-                .append(\"CREATE OR REPLACE FUNCTION \")\n-                .append(objectName)\n-                .append(System.lineSeparator())\n-                .append(supplier.get());\n-\n-        final String ddlString = ddl.toString();\n-        if (logger.isLoggable(Level.FINE)) {\n-            logger.fine(ddlString);\n-        }\n-\n-        runStatement(ddlString);\n-    }\n-\n-    @Override\n-    public void dropProcedure(String schemaName, String procedureName) {\n-        warnOnce(MessageKey.DROP_PROC, \"Drop procedure not supported in PostgreSql\");\n-    }\n-\n     @Override\n     public void createTablespace(String tablespaceName) {\n         warnOnce(MessageKey.TABLESPACE, \"Create tablespace not supported in PostgreSql\");\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxNzEwOA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420717108", "body": "what does the line separator get you, a pretty print? ", "bodyText": "what does the line separator get you, a pretty print?", "bodyHTML": "<p dir=\"auto\">what does the line separator get you, a pretty print?</p>", "author": "prb112", "createdAt": "2020-05-06T11:24:25Z", "path": "fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java", "diffHunk": "@@ -150,7 +150,22 @@ public void dropType(String schemaName, String typeName) {\n \n     @Override\n     public void createOrReplaceProcedure(String schemaName, String procedureName, Supplier<String> supplier) {\n-        warnOnce(MessageKey.CREATE_PROC, \"Create procedure not supported in PostgreSql\");\n+        final String objectName = DataDefinitionUtil.getQualifiedName(schemaName, procedureName);\n+        logger.info(\"Create or replace procedure \" + objectName);\n+\n+        // Build the create procedure DDL and apply it\n+        final StringBuilder ddl = new StringBuilder();\n+        ddl.append(\"CREATE OR REPLACE FUNCTION \");\n+        ddl.append(objectName);\n+        ddl.append(System.lineSeparator());\n+        ddl.append(supplier.get());", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxMTcxOA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421211718", "bodyText": "this is interesting, just followed the existing pattern, let me change this.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxNzEwOA=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\nindex 65ad4e1eea..e5007fc9ed 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n", "chunk": "@@ -154,11 +154,11 @@ public class PostgreSqlAdapter extends CommonDatabaseAdapter {\n         logger.info(\"Create or replace procedure \" + objectName);\n \n         // Build the create procedure DDL and apply it\n-        final StringBuilder ddl = new StringBuilder();\n-        ddl.append(\"CREATE OR REPLACE FUNCTION \");\n-        ddl.append(objectName);\n-        ddl.append(System.lineSeparator());\n-        ddl.append(supplier.get());\n+        final StringBuilder ddl = new StringBuilder()\n+                .append(\"CREATE OR REPLACE FUNCTION \")\n+                .append(objectName)\n+                .append(System.lineSeparator())\n+                .append(supplier.get());\n \n         final String ddlString = ddl.toString();\n         if (logger.isLoggable(Level.FINE)) {\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\nindex e5007fc9ed..e9071d50c3 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n", "chunk": "@@ -148,31 +153,6 @@ public class PostgreSqlAdapter extends CommonDatabaseAdapter {\n         warnOnce(MessageKey.DROP_TYPE, \"Drop type not supported in PostgreSql\");\n     }\n \n-    @Override\n-    public void createOrReplaceProcedure(String schemaName, String procedureName, Supplier<String> supplier) {\n-        final String objectName = DataDefinitionUtil.getQualifiedName(schemaName, procedureName);\n-        logger.info(\"Create or replace procedure \" + objectName);\n-\n-        // Build the create procedure DDL and apply it\n-        final StringBuilder ddl = new StringBuilder()\n-                .append(\"CREATE OR REPLACE FUNCTION \")\n-                .append(objectName)\n-                .append(System.lineSeparator())\n-                .append(supplier.get());\n-\n-        final String ddlString = ddl.toString();\n-        if (logger.isLoggable(Level.FINE)) {\n-            logger.fine(ddlString);\n-        }\n-\n-        runStatement(ddlString);\n-    }\n-\n-    @Override\n-    public void dropProcedure(String schemaName, String procedureName) {\n-        warnOnce(MessageKey.DROP_PROC, \"Drop procedure not supported in PostgreSql\");\n-    }\n-\n     @Override\n     public void createTablespace(String tablespaceName) {\n         warnOnce(MessageKey.TABLESPACE, \"Create tablespace not supported in PostgreSql\");\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxODcyNQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420718725", "body": "merge 73, 74 to oneline", "bodyText": "merge 73, 74 to oneline", "bodyHTML": "<p dir=\"auto\">merge 73, 74 to oneline</p>", "author": "prb112", "createdAt": "2020-05-06T11:27:57Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +23,95 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, systemName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read code system id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n+                systemId = stmt.getInt(2);\n             }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n         }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n+        catch (Throwable e) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxMjg4MA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421212880", "bodyText": "followed Robin's code style, let me change. :)", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxODcyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex ae22e55fd6..dc86bbd3fc 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -70,48 +68,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n                 }\n                 systemId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return systemId;\n     }\n \n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxODc4OQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420718789", "body": "merge to one line", "bodyText": "merge to one line", "bodyHTML": "<p dir=\"auto\">merge to one line</p>", "author": "prb112", "createdAt": "2020-05-06T11:28:06Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +23,95 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, systemName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read code system id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n+                systemId = stmt.getInt(2);\n             }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n         }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex ae22e55fd6..dc86bbd3fc 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -70,48 +68,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n                 }\n                 systemId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return systemId;\n     }\n \n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxODk0NQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420718945", "body": "merge to oneline", "bodyText": "merge to oneline", "bodyHTML": "<p dir=\"auto\">merge to oneline</p>", "author": "prb112", "createdAt": "2020-05-06T11:28:22Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +23,95 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, systemName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read code system id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n+                systemId = stmt.getInt(2);\n             }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n         }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return systemId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param codeSystem\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getCodeSystemId(String codeSystem) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n+        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        String sql1 = \"SELECT code_system_id FROM code_systems WHERE code_system_name = ?\";\n+        FHIRPersistenceDBCleanupException ce;\n \n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql1)) {\n-            stmt.setString(1, codeSystem);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n+        if (stmt != null) {\n+            try {\n+                stmt.close();\n             }\n-            else {\n-                result = null;\n+            catch (Throwable e) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex ae22e55fd6..dc86bbd3fc 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -70,48 +68,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n                 }\n                 systemId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return systemId;\n     }\n \n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxOTAxNQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420719015", "body": "merge to oneline", "bodyText": "merge to oneline", "bodyHTML": "<p dir=\"auto\">merge to oneline</p>", "author": "prb112", "createdAt": "2020-05-06T11:28:31Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +23,95 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, systemName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read code system id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n+                systemId = stmt.getInt(2);\n             }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n         }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return systemId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param codeSystem\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getCodeSystemId(String codeSystem) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n+        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        String sql1 = \"SELECT code_system_id FROM code_systems WHERE code_system_name = ?\";\n+        FHIRPersistenceDBCleanupException ce;\n \n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql1)) {\n-            stmt.setString(1, codeSystem);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n+        if (stmt != null) {\n+            try {\n+                stmt.close();\n             }\n-            else {\n-                result = null;\n+            catch (Throwable e) {\n+                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n+                log.log(Level.SEVERE, ce.getMessage(), ce);\n             }\n         }\n-        catch (SQLException e) {\n-            throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n+        if(connection != null && this.getConnection() == null) {\n+            try {\n+                connection.close();\n+            }\n+            catch (Throwable e) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex ae22e55fd6..dc86bbd3fc 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -70,48 +68,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n                 }\n                 systemId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return systemId;\n     }\n \n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxOTU2NQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420719565", "body": "Why are you forceabling closing this? It's part of a pool? ", "bodyText": "Why are you forceabling closing this? It's part of a pool?", "bodyHTML": "<p dir=\"auto\">Why are you forceabling closing this? It's part of a pool?</p>", "author": "prb112", "createdAt": "2020-05-06T11:29:33Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +23,95 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, systemName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read code system id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n+                systemId = stmt.getInt(2);\n             }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n         }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return systemId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param codeSystem\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getCodeSystemId(String codeSystem) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n+        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        String sql1 = \"SELECT code_system_id FROM code_systems WHERE code_system_name = ?\";\n+        FHIRPersistenceDBCleanupException ce;\n \n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql1)) {\n-            stmt.setString(1, codeSystem);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n+        if (stmt != null) {\n+            try {\n+                stmt.close();\n             }\n-            else {\n-                result = null;\n+            catch (Throwable e) {\n+                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n+                log.log(Level.SEVERE, ce.getMessage(), ce);\n             }\n         }\n-        catch (SQLException e) {\n-            throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n+        if(connection != null && this.getConnection() == null) {\n+            try {\n+                connection.close();", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxNDcwOQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421214709", "bodyText": "this doesn't really close the connection, just return it to the pool. it's the same as what did for DB2.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:16:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxOTU2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex ae22e55fd6..dc86bbd3fc 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -70,48 +68,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n                 }\n                 systemId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return systemId;\n     }\n \n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxOTY1Mg==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420719652", "body": "this method is confusing to me", "bodyText": "this method is confusing to me", "bodyHTML": "<p dir=\"auto\">this method is confusing to me</p>", "author": "prb112", "createdAt": "2020-05-06T11:29:42Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +23,95 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, systemName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read code system id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n+                systemId = stmt.getInt(2);\n             }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n         }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return systemId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param codeSystem\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getCodeSystemId(String codeSystem) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxNzk0MQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421217941", "bodyText": "let me remove it.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:29:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcxOTY1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex ae22e55fd6..dc86bbd3fc 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -70,48 +68,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n                 }\n                 systemId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return systemId;\n     }\n \n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMDU3OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420720578", "body": "Add a different set and use the contains. \r\nCall it STORED_PROCEDURE_ENABLED and add to the set. \r\nThis is very hard to figure out if we constantly add. ", "bodyText": "Add a different set and use the contains.\nCall it STORED_PROCEDURE_ENABLED and add to the set.\nThis is very hard to figure out if we constantly add.", "bodyHTML": "<p dir=\"auto\">Add a different set and use the contains.<br>\nCall it STORED_PROCEDURE_ENABLED and add to the set.<br>\nThis is very hard to figure out if we constantly add.</p>", "author": "prb112", "createdAt": "2020-05-06T11:31:42Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java", "diffHunk": "@@ -638,7 +639,7 @@ protected void createFhirSchemas() {\n      * into the FHIR resource tables\n      */\n     protected void updateProcedures() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n+        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType) || DbType.POSTGRESQL == dbType) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxODE2OQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421218169", "bodyText": "good idea!", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMDU3OA=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 63524970dc..cca72c7a80 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -639,7 +640,7 @@ public class Main {\n      * into the FHIR resource tables\n      */\n     protected void updateProcedures() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType) || DbType.POSTGRESQL == dbType) {\n+        if (!STORED_PROCEDURE_ENABLED.contains(dbType)) {\n             return;\n         }\n         FhirSchemaGenerator gen = new FhirSchemaGenerator(adminSchemaName, schemaName);\n", "next_change": {"commit": "b88da7356848f84d2f45c925215861addfaaf6d5", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex cca72c7a80..3951de26c3 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -643,9 +427,10 @@ public class Main {\n         if (!STORED_PROCEDURE_ENABLED.contains(dbType)) {\n             return;\n         }\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(adminSchemaName, schemaName);\n+\n+        // Build/update the tables as well as the stored procedures\n         PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n+        buildCommonModel(pdm, updateFhirSchema, updateOauthSchema,updateJavaBatchSchema);\n \n         // Now only apply the procedures in the model. Much faster than\n         // going through the whole schema\n", "next_change": {"commit": "27239a865d214edd6361a939fbdd9322d19b5100", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 3951de26c3..12ec79ee70 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -430,7 +457,10 @@ public class Main {\n \n         // Build/update the tables as well as the stored procedures\n         PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, updateFhirSchema, updateOauthSchema,updateJavaBatchSchema);\n+        // Since this is a stored procedure, we need the model.\n+        // We must pass in true to flag to the underlying layer that the\n+        // Procedures need to be generated.\n+        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n \n         // Now only apply the procedures in the model. Much faster than\n         // going through the whole schema\n", "next_change": {"commit": "5b611c79856fd1fbd27cff7d703b95a2c747b925", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 12ec79ee70..699cfd66e4 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -457,10 +457,7 @@ public class Main {\n \n         // Build/update the tables as well as the stored procedures\n         PhysicalDataModel pdm = new PhysicalDataModel();\n-        // Since this is a stored procedure, we need the model.\n-        // We must pass in true to flag to the underlying layer that the\n-        // Procedures need to be generated.\n-        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n+        buildCommonModel(pdm, updateFhirSchema, updateOauthSchema,updateJavaBatchSchema);\n \n         // Now only apply the procedures in the model. Much faster than\n         // going through the whole schema\n", "next_change": {"commit": "01a95d24049168144cbb0445deaa0277617b2e70", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 699cfd66e4..6a8239cabd 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -457,7 +457,10 @@ public class Main {\n \n         // Build/update the tables as well as the stored procedures\n         PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, updateFhirSchema, updateOauthSchema,updateJavaBatchSchema);\n+        // Since this is a stored procedure, we need the model.\n+        // We must pass in true to flag to the underlying layer that the\n+        // Procedures need to be generated.\n+        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n \n         // Now only apply the procedures in the model. Much faster than\n         // going through the whole schema\n", "next_change": {"commit": "858fbb1331e7f20d7a04bdf40edaf71da5bbadda", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 6a8239cabd..af16fc6a87 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -464,20 +464,21 @@ public class Main {\n \n         // Now only apply the procedures in the model. Much faster than\n         // going through the whole schema\n-        try {\n-            try (Connection c = createConnection()) {\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try (Connection c = connectionPool.getConnection();) {\n                 try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n+                    IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n                     pdm.applyProcedures(adapter);\n                     pdm.applyFunctions(adapter);\n-                } catch (Exception x) {\n-                    c.rollback();\n+                } catch (DataAccessException x) {\n+                    // Something went wrong, so mark the transaction as failed\n+                    tx.setRollbackOnly();\n                     throw x;\n                 }\n                 c.commit();\n             }\n         } catch (SQLException x) {\n+            tx.setRollbackOnly();\n             throw translator.translate(x);\n         }\n     }\n", "next_change": {"commit": "1e6b10331aa2b2d62411ec4f673d0214cb4c7a21", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex af16fc6a87..7887824450 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -476,10 +476,10 @@ public class Main {\n                     throw x;\n                 }\n                 c.commit();\n+            } catch (SQLException x) {\n+                tx.setRollbackOnly();\n+                throw translator.translate(x);\n             }\n-        } catch (SQLException x) {\n-            tx.setRollbackOnly();\n-            throw translator.translate(x);\n         }\n     }\n \n", "next_change": {"commit": "41e95c7381ecb889f30f467e5a6cc7c0c78e5e60", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 7887824450..9455e61d76 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -475,7 +479,7 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                c.commit();\n+                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "c2193720060c03214cfab6924175a7a0b7854894", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 9455e61d76..69f4ea0c1d 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -479,7 +462,7 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n+                c.commit();\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "6833eb59b53e0764547500c9329ecddf6e9ca700", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 69f4ea0c1d..3c4c21c031 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -462,7 +466,7 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                c.commit();\n+                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "08003cabbd153c969c0f31c9eb6580ca86f7ae88", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 3c4c21c031..ba15a28613 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -466,7 +571,8 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n+                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the\n+                // transaction commit.\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "afceaba4a867a0af38a6cb431245b8b1854b9f74", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex ba15a28613..eff8be1420 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -580,6 +749,28 @@ public class Main {\n         }\n     }\n \n+    /**\n+     * Build a common PhysicalDataModel containing all the requested schemas\n+     * \n+     * @param pdm the model to construct\n+     * @param addFhirDataSchema include objects for the FHIR data schema\n+     * @param addOAuthSchema include objects for the Liberty OAuth schema\n+     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n+     */\n+    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n+        if (addFhirDataSchema) {\n+            buildFhirDataSchemaModel(pdm);\n+        }\n+        \n+        if (addOAuthSchema) {\n+            buildOAuthSchemaModel(pdm);\n+        }\n+        \n+        if (addJavaBatchSchema) {\n+            buildJavaBatchSchemaModel(pdm);\n+        }\n+    }\n+\n     // -----------------------------------------------------------------------------------------------------------------\n     // The following method is related to the Privilege feature\n     /**\n", "next_change": {"commit": "652c689992b6da38f3904766b4dfae672f23826a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex eff8be1420..f38f98eed9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -771,8 +804,67 @@ public class Main {\n         }\n     }\n \n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Privilege feature\n+    /**\n+     * Apply grants to the FHIR data schema objects\n+     */\n+    protected void grantPrivilegesForFhirData() {\n+\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildFhirDataSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+                \n+                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n+                // Note the constant comes from SchemaConstants on purpose\n+                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Apply grants to the OAuth schema objects\n+     */\n+    protected void grantPrivilegesForOAuth() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildOAuthSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n+                \n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+        \n+    }\n+\n+    /**\n+     * Apply grants to the JavaBatch schema objects\n+     */\n+    protected void grantPrivilegesForBatch() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildJavaBatchSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n     /**\n      * Grant the minimum required set of privileges on the FHIR schema objects\n      * to the grantTo user. All tenant data access is via this user, and is the\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\ndeleted file mode 100644\nindex f38f98eed9..0000000000\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ /dev/null\n", "chunk": "@@ -1,2526 +0,0 @@\n-/*\n- * (C) Copyright IBM Corp. 2019, 2021\n- *\n- * SPDX-License-Identifier: Apache-2.0\n- */\n-\n-package com.ibm.fhir.schema.app;\n-\n-import static com.ibm.fhir.schema.app.util.CommonUtil.configureLogger;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getDbAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getPropertyAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getRandomKey;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.loadDriver;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.logClasspath;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.printUsage;\n-\n-import java.io.FileInputStream;\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.sql.Connection;\n-import java.sql.DriverManager;\n-import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map.Entry;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.logging.Level;\n-import java.util.logging.Logger;\n-import java.util.stream.Collectors;\n-\n-import com.ibm.fhir.core.util.handler.HostnameHandler;\n-import com.ibm.fhir.database.utils.api.DataAccessException;\n-import com.ibm.fhir.database.utils.api.DatabaseNotReadyException;\n-import com.ibm.fhir.database.utils.api.IDatabaseAdapter;\n-import com.ibm.fhir.database.utils.api.IDatabaseTranslator;\n-import com.ibm.fhir.database.utils.api.ITransaction;\n-import com.ibm.fhir.database.utils.api.ITransactionProvider;\n-import com.ibm.fhir.database.utils.api.TableSpaceRemovalException;\n-import com.ibm.fhir.database.utils.api.TenantStatus;\n-import com.ibm.fhir.database.utils.api.UndefinedNameException;\n-import com.ibm.fhir.database.utils.common.DataDefinitionUtil;\n-import com.ibm.fhir.database.utils.common.JdbcConnectionProvider;\n-import com.ibm.fhir.database.utils.common.JdbcPropertyAdapter;\n-import com.ibm.fhir.database.utils.common.JdbcTarget;\n-import com.ibm.fhir.database.utils.db2.Db2Adapter;\n-import com.ibm.fhir.database.utils.db2.Db2GetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2SetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2Translator;\n-import com.ibm.fhir.database.utils.derby.DerbyTranslator;\n-import com.ibm.fhir.database.utils.model.DatabaseObjectType;\n-import com.ibm.fhir.database.utils.model.DbType;\n-import com.ibm.fhir.database.utils.model.PhysicalDataModel;\n-import com.ibm.fhir.database.utils.model.Table;\n-import com.ibm.fhir.database.utils.model.Tenant;\n-import com.ibm.fhir.database.utils.pool.PoolConnectionProvider;\n-import com.ibm.fhir.database.utils.postgres.GatherTablesDataModelVisitor;\n-import com.ibm.fhir.database.utils.postgres.PostgresAdapter;\n-import com.ibm.fhir.database.utils.postgres.PostgresTranslator;\n-import com.ibm.fhir.database.utils.postgres.PostgresVacuumSettingDAO;\n-import com.ibm.fhir.database.utils.tenant.AddTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.DeleteTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.GetTenantDAO;\n-import com.ibm.fhir.database.utils.transaction.SimpleTransactionProvider;\n-import com.ibm.fhir.database.utils.transaction.TransactionFactory;\n-import com.ibm.fhir.database.utils.version.CreateControl;\n-import com.ibm.fhir.database.utils.version.CreateWholeSchemaVersion;\n-import com.ibm.fhir.database.utils.version.SchemaConstants;\n-import com.ibm.fhir.database.utils.version.CreateVersionHistory;\n-import com.ibm.fhir.database.utils.version.VersionHistoryService;\n-import com.ibm.fhir.model.util.ModelSupport;\n-import com.ibm.fhir.schema.api.ConcurrentUpdateException;\n-import com.ibm.fhir.schema.api.ILeaseManagerConfig;\n-import com.ibm.fhir.schema.app.util.TenantKeyFileUtil;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLog;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLogDb2;\n-import com.ibm.fhir.schema.control.DisableForeignKey;\n-import com.ibm.fhir.schema.control.DropForeignKey;\n-import com.ibm.fhir.schema.control.EnableForeignKey;\n-import com.ibm.fhir.schema.control.FhirSchemaConstants;\n-import com.ibm.fhir.schema.control.FhirSchemaGenerator;\n-import com.ibm.fhir.schema.control.GetLogicalResourceNeedsV0014Migration;\n-import com.ibm.fhir.schema.control.GetResourceChangeLogEmpty;\n-import com.ibm.fhir.schema.control.GetResourceTypeList;\n-import com.ibm.fhir.schema.control.GetTenantInfo;\n-import com.ibm.fhir.schema.control.GetTenantList;\n-import com.ibm.fhir.schema.control.GetXXLogicalResourceNeedsMigration;\n-import com.ibm.fhir.schema.control.InitializeLogicalResourceDenorms;\n-import com.ibm.fhir.schema.control.JavaBatchSchemaGenerator;\n-import com.ibm.fhir.schema.control.MigrateV0014LogicalResourceIsDeletedLastUpdated;\n-import com.ibm.fhir.schema.control.OAuthSchemaGenerator;\n-import com.ibm.fhir.schema.control.PopulateParameterNames;\n-import com.ibm.fhir.schema.control.PopulateResourceTypes;\n-import com.ibm.fhir.schema.control.SetTenantIdDb2;\n-import com.ibm.fhir.schema.control.TenantInfo;\n-import com.ibm.fhir.schema.model.ResourceType;\n-import com.ibm.fhir.schema.model.Schema;\n-import com.ibm.fhir.task.api.ITaskCollector;\n-import com.ibm.fhir.task.api.ITaskGroup;\n-import com.ibm.fhir.task.core.service.TaskService;\n-\n-/**\n- * Utility app to connect to a database and create/update the IBM FHIR Server schema.\n- * The DDL processing is idempotent, with only the necessary changes applied.\n- * <br>\n- * This utility also includes an option to exercise the tenant partitioning code.\n- */\n-public class Main {\n-\n-    private static final Logger logger = Logger.getLogger(Main.class.getName());\n-    private static final int EXIT_OK = 0; // validation was successful\n-    private static final int EXIT_BAD_ARGS = 1; // invalid CLI arguments\n-    private static final int EXIT_RUNTIME_ERROR = 2; // programming error\n-    private static final int EXIT_VALIDATION_FAILED = 3; // validation test failed\n-    private static final int EXIT_NOT_READY = 4; // DATABASE NOT READY\n-    private static final int EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE = 5; // Tablespace Removal not complete\n-    private static final int EXIT_CONCURRENT_UPDATE = 6; // Another schema update is running and the wait time expired\n-    private static final double NANOS = 1e9;\n-\n-    // Indicates if the feature is enabled for the DbType\n-    public List<DbType> MULTITENANT_FEATURE_ENABLED = Arrays.asList(DbType.DB2);\n-    public List<DbType> STORED_PROCEDURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-    public List<DbType> PRIVILEGES_FEATURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-\n-    // Properties accumulated as we parse args and read configuration files\n-    private final Properties properties = new Properties();\n-\n-    // Default Values for schema names\n-    public static final String ADMIN_SCHEMANAME = \"FHIR_ADMIN\";\n-    public static final String OAUTH_SCHEMANAME = \"FHIR_OAUTH\";\n-    public static final String BATCH_SCHEMANAME = \"FHIR_JBATCH\";\n-    public static final String DATA_SCHEMANAME = \"FHIRDATA\";\n-\n-    // Force upper-case to avoid tricky-to-catch errors related to quoting names\n-    private Schema schema = new Schema();\n-\n-    // Arguments requesting we drop the objects from the schema\n-    private boolean dropAdmin = false;\n-    private boolean confirmDrop = false;\n-    private boolean updateProc = false;\n-    private boolean checkCompatibility = false;\n-\n-    // Action flags related to FHIR Schema\n-    private boolean createFhirSchema = false;\n-    private boolean updateFhirSchema = false;\n-    private boolean dropFhirSchema = false;\n-    private boolean grantFhirSchema = false;\n-\n-    // Action flags related to OAuth Schema\n-    private boolean createOauthSchema = false;\n-    private boolean updateOauthSchema = false;\n-    private boolean dropOauthSchema = false;\n-    private boolean grantOauthSchema = false;\n-\n-    // Action flags related to Java Batch Schema\n-    private boolean createJavaBatchSchema = false;\n-    private boolean updateJavaBatchSchema = false;\n-    private boolean dropJavaBatchSchema = false;\n-    private boolean grantJavaBatchSchema = false;\n-\n-    // Tenant Key\n-    private boolean skipIfTenantExists = false;\n-\n-    // The database user we will grant tenant data access privileges to\n-    private String grantTo;\n-\n-    // Action flag related to Vacuuming:\n-    private boolean updateVacuum = false;\n-    private String vacuumTableName = null;\n-    private int vacuumCostLimit = 2000;\n-    private int vacuumThreshold = 1000;\n-    private Double vacuumScaleFactor = null;\n-    \n-    // How many seconds to wait to obtain the update lease\n-    private int waitForUpdateLeaseSeconds = 10;\n-\n-    // The database type being populated (default: Db2)\n-    private DbType dbType = DbType.DB2;\n-    private IDatabaseTranslator translator = new Db2Translator();\n-\n-    // Optional subset of resource types (for faster schema builds when testing)\n-    private Set<String> resourceTypeSubset;\n-\n-    // Tenant management\n-    private boolean allocateTenant;\n-    private boolean refreshTenants;\n-    private boolean dropTenant;\n-    private boolean freezeTenant;\n-    private String tenantName;\n-    private boolean testTenant;\n-    private String tenantKey;\n-    private boolean listTenants;\n-    private boolean dropDetached;\n-    private boolean deleteTenantMeta;\n-    private boolean revokeTenantKey;\n-    private boolean revokeAllTenantKeys;\n-\n-    // Tenant Key Output or Input File\n-    private String tenantKeyFileName;\n-    private TenantKeyFileUtil tenantKeyFileUtil = new TenantKeyFileUtil();\n-\n-    // The tenant name for when we want to add a new tenant key\n-    private String addKeyForTenant;\n-\n-    // What status to leave with\n-    private int exitStatus = EXIT_OK;\n-\n-    // The connection pool and transaction provider to support concurrent operations\n-    private int maxConnectionPoolSize = FhirSchemaConstants.DEFAULT_POOL_SIZE;\n-    private PoolConnectionProvider connectionPool;\n-    private ITransactionProvider transactionProvider;\n-    \n-    // Configuration to control how the LeaseManager operates\n-    private ILeaseManagerConfig leaseManagerConfig;\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the common methods and functions\n-    /**\n-     * @return a created connection to the selected database\n-     */\n-    protected Connection createConnection() {\n-        Properties connectionProperties = new Properties();\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        adapter.getExtraProperties(connectionProperties);\n-\n-        String url = translator.getUrl(properties);\n-        logger.info(\"Opening connection to: \" + url);\n-        Connection connection;\n-        try {\n-            connection = DriverManager.getConnection(url, connectionProperties);\n-            connection.setAutoCommit(false);\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-        return connection;\n-    }\n-\n-    /**\n-     * Create a simple connection pool associated with our data source so that we\n-     * can perform the DDL deployment in parallel\n-     */\n-    protected void configureConnectionPool() {\n-        if (dbType == DbType.DERBY && maxConnectionPoolSize > 1) {\n-            logger.warning(\"Embedded Derby does not support concurrent schema updates;\" +\n-                    \" ignoring '--pool-size' and using a single thread.\");\n-            this.maxConnectionPoolSize = 1;\n-        }\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        JdbcConnectionProvider cp = new JdbcConnectionProvider(this.translator, adapter);\n-        this.connectionPool = new PoolConnectionProvider(cp, this.maxConnectionPoolSize);\n-        this.transactionProvider = new SimpleTransactionProvider(this.connectionPool);\n-    }\n-\n-    /**\n-     * Add the admin schema objects to the {@link PhysicalDataModel}\n-     *\n-     * @param pdm the data model to build\n-     */\n-    protected void buildAdminSchemaModel(PhysicalDataModel pdm) {\n-        // Add the tenant and tenant_keys tables and any other admin schema stuff\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        gen.buildAdminSchema(pdm);\n-    }\n-    \n-    /**\n-     * Add the OAuth schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm the model to build\n-     */\n-    protected void buildOAuthSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty OAuth-related tables\n-        OAuthSchemaGenerator oauthSchemaGenerator = new OAuthSchemaGenerator(schema.getOauthSchemaName());\n-        oauthSchemaGenerator.buildOAuthSchema(pdm);\n-    }\n-\n-    /**\n-     * Add the JavaBatch schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm\n-     */\n-    protected void buildJavaBatchSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty JBatch related tables\n-        JavaBatchSchemaGenerator javaBatchSchemaGenerator = new JavaBatchSchemaGenerator(schema.getJavaBatchSchemaName());\n-        javaBatchSchemaGenerator.buildJavaBatchSchema(pdm);\n-    }\n-\n-    /**\n-     * Start the schema object creation tasks and wait for everything to complete\n-     *\n-     * @param pdm\n-     * @param adapter\n-     * @param collector\n-     * @param vhs\n-     */\n-    protected void applyModel(PhysicalDataModel pdm, IDatabaseAdapter adapter, ITaskCollector collector, VersionHistoryService vhs) {\n-        logger.info(\"Collecting model update tasks\");\n-        pdm.collect(collector, adapter, this.transactionProvider, vhs);\n-\n-        // FHIR in the hole!\n-        logger.info(\"Starting model updates\");\n-        collector.startAndWait();\n-\n-        Collection<ITaskGroup> failedTaskGroups = collector.getFailedTaskGroups();\n-        if (failedTaskGroups.size() > 0) {\n-            this.exitStatus = EXIT_RUNTIME_ERROR;\n-\n-            final String failedStr =\n-                    failedTaskGroups.stream().map((tg) -> tg.getTaskId()).collect(Collectors.joining(\",\"));\n-            logger.severe(\"List of failed task groups: \" + failedStr);\n-        }\n-    }\n-\n-    /**\n-     * specific feature to check if it is compatible.\n-     *\n-     * @return\n-     */\n-    protected boolean checkCompatibility() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            return adapter.checkCompatibility(schema.getAdminSchemaName());\n-        }\n-    }\n-\n-    /**\n-     * Create the schemas\n-     */\n-    protected void createSchemas() {\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    // We always create the 'admin' schema to track to the changes to any of the other schemas.\n-                    adapter.createSchema(schema.getAdminSchemaName());\n-\n-                    // FHIR Data Schema\n-                    if (createFhirSchema) {\n-                        adapter.createSchema(schema.getSchemaName());\n-                        c.commit();\n-                    }\n-\n-                    // OAuth Schema\n-                    if (createOauthSchema) {\n-                        adapter.createSchema(schema.getOauthSchemaName());\n-                    }\n-\n-                    // Java Batch Schema\n-                    if (createJavaBatchSchema) {\n-                        adapter.createSchema(schema.getJavaBatchSchemaName());\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-    \n-    /**\n-     * Process the schemas configured to be updated\n-     */\n-    protected void updateSchemas() {\n-        \n-        // Make sure that we have the CONTROL table created before we try any\n-        // schema update work\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateControl.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        if (updateFhirSchema) {\n-            updateFhirSchema();\n-        }\n-        \n-        if (updateOauthSchema) {\n-            updateOauthSchema();\n-        }\n-        \n-        if (updateJavaBatchSchema) {\n-            updateJavaBatchSchema();\n-        }\n-    }\n-    \n-    /**\n-     * Add FHIR data schema objects to the given {@link PhysicalDataModel}\n-     * @param pdm the data model being built\n-     */\n-    protected void buildFhirDataSchemaModel(PhysicalDataModel pdm) {\n-        FhirSchemaGenerator gen;\n-        if (resourceTypeSubset == null || resourceTypeSubset.isEmpty()) {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        } else {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant(), resourceTypeSubset);\n-        }\n-\n-        gen.buildSchema(pdm);\n-        switch (dbType) {\n-        case DB2:\n-            gen.buildDatabaseSpecificArtifactsDb2(pdm);\n-            break;\n-        case DERBY:\n-            logger.info(\"No database specific artifacts\");\n-            break;\n-        case POSTGRESQL:\n-            gen.buildDatabaseSpecificArtifactsPostgres(pdm);\n-            break;\n-        default:\n-            throw new IllegalStateException(\"Unsupported db type: \" + dbType);\n-        }\n-    }\n-    \n-    /**\n-     * Update the FHIR data schema\n-     */\n-    protected void updateFhirSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for FHIR data schema: '\" + schema.getSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                // Build/update the FHIR-related tables as well as the stored procedures\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                boolean isNewDb = updateSchema(pdm);\n-                \n-                // If the db is multi-tenant, we populate the resource types and parameter names in allocate-tenant.\n-                // Otherwise, if its a new schema, populate the resource types and parameters names (codes) now\n-                if (!MULTITENANT_FEATURE_ENABLED.contains(dbType) && isNewDb) {\n-                    populateResourceTypeAndParameterNameTableEntries(null);\n-                }\n-        \n-                if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-                    logger.info(\"Refreshing tenant partitions\");\n-                    refreshTenants();\n-                }\n-        \n-                // backfill the resource_change_log table if needed\n-                backfillResourceChangeLog();\n-        \n-                // perform any updates we need related to the V0010 schema change (IS_DELETED flag)\n-                applyDataMigrationForV0010();\n-        \n-                // V0014 IS_DELETED and LAST_UPDATED added to whole-system LOGICAL_RESOURCES\n-                applyDataMigrationForV0014();\n-        \n-                // Log warning messages that unused tables will be removed in a future release.\n-                // TODO: This will no longer be needed after the tables are removed (https://github.com/IBM/FHIR/issues/713).\n-                logWarningMessagesForDeprecatedTables();\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForFhirData();\n-                }\n-                \n-                // Finally, update the whole schema version\n-                svm.updateSchemaVersion();\n-                \n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the OAuth schema changes\n-     */\n-    protected void updateOauthSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getOauthSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty OAuth schema: '\" + schema.getOauthSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getOauthSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForOAuth();\n-                }\n-                \n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the JavaBatch schema changes\n-     */\n-    protected void updateJavaBatchSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getJavaBatchSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty JavaBatch schema: '\" + schema.getJavaBatchSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getJavaBatchSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-\n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForBatch();\n-                }\n-\n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-    \n-    /**\n-     * Update the schema associated with the given {@link PhysicalDataModel}\n-     * @return true if the database is new\n-     */\n-    protected boolean updateSchema(PhysicalDataModel pdm) {\n-\n-        // The objects are applied in parallel, which relies on each object\n-        // expressing its dependencies correctly. Changes are only applied\n-        // if their version is greater than the current version.\n-        TaskService taskService = new TaskService();\n-        ExecutorService pool = Executors.newFixedThreadPool(this.maxConnectionPoolSize);\n-        ITaskCollector collector = taskService.makeTaskCollector(pool);\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-\n-        // Before we start anything, we need to make sure our schema history\n-        // and control tables are in place. These tables are used to manage \n-        // all FHIR data, oauth and JavaBatch schemas we build\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateVersionHistory.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        // Current version history for the data schema\n-        VersionHistoryService vhs =\n-                new VersionHistoryService(schema.getAdminSchemaName(), schema.getSchemaName(), schema.getOauthSchemaName(), schema.getJavaBatchSchemaName());\n-        vhs.setTransactionProvider(transactionProvider);\n-        vhs.setTarget(adapter);\n-        vhs.init();\n-\n-        // Use the version history service to determine if this table existed before we run `applyWithHistory`\n-        boolean isNewDb = vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == null ||\n-                vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == 0;\n-\n-        applyModel(pdm, adapter, collector, vhs);\n-        // The physical database objects should now match what was defined in the PhysicalDataModel\n-        \n-        return isNewDb;\n-    }\n-\n-    /**\n-     * populates for the given tenantId the RESOURCE_TYPE table.\n-     *\n-     * @implNote if you update this method, be sure to update\n-     *           DerbyBootstrapper.populateResourceTypeAndParameterNameTableEntries\n-     *           and DerbyFhirDatabase.populateResourceTypeAndParameterNameTableEntries\n-     *           The reason is there are three different ways of managing the transaction.\n-     * @param tenantId\n-     *            the mt_id that is used to setup the partition.\n-     *            passing in null signals not multi-tenant.\n-     */\n-    protected void populateResourceTypeAndParameterNameTableEntries(Integer tenantId) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                String logTenantId = tenantId != null ? Integer.toString(tenantId) : \"default\";\n-                logger.info(\"tenantId [\" + logTenantId + \"] is being pre-populated with lookup table data.\");\n-                PopulateResourceTypes populateResourceTypes =\n-                        new PopulateResourceTypes(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateResourceTypes.run(translator, c);\n-\n-                PopulateParameterNames populateParameterNames =\n-                        new PopulateParameterNames(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateParameterNames.run(translator, c);\n-                logger.info(\"Finished prepopulating the resource type and search parameter code/name tables tables\");\n-            } catch (SQLException ex) {\n-                tx.setRollbackOnly();\n-                throw new DataAccessException(ex);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Drop all the objects in the admin and data schemas.\n-     * Typically used during development.\n-     */\n-    protected void dropSchema() {\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, dropFhirSchema, dropOauthSchema, dropJavaBatchSchema);\n-\n-        // Dropping the schema in PostgreSQL can fail with an out of shared memory error\n-        // which is apparently related to max_locks_per_transaction. It may not be possible\n-        // to increase this value (e.g. in cloud databases) and so to work around this, before\n-        // dropping the schema objects, we knock out all the FOREIGN KEY constraints first.\n-        if (dropFhirSchema) {\n-            logger.info(\"Dropping FK constraints in the data schema: \" + this.schema.getSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-        }\n-\n-        if (dropOauthSchema) {\n-            logger.info(\"Dropping FK constraints in the OAuth schema: \" + this.schema.getOauthSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-        }\n-\n-        if (dropJavaBatchSchema) {\n-            logger.info(\"Dropping FK constraints in the Batch schema: \" + this.schema.getJavaBatchSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-        }\n-\n-        if (dropAdmin) {\n-            // Also drop the FK constraints within the administration schema\n-            logger.info(\"Dropping FK constraints in the admin schema: \" + this.schema.getAdminSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-        }\n-\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    if (dropFhirSchema || dropOauthSchema || dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the FHIRDATA schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-                    }\n-\n-                    if (dropOauthSchema) {\n-                        // Just drop the objects associated with the OAUTH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-                    }\n-\n-                    if (dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the BATCH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-                    }\n-\n-                    if (dropAdmin) {\n-                        // Just drop the objects associated with the ADMIN schema group\n-                        CreateVersionHistory.generateTable(pdm, ADMIN_SCHEMANAME, true);\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    /**\n-     * Add part of the schema drop process, we first kill all\n-     * the foreign key constraints. The rest of the drop is\n-     * performed in a second transaction.\n-     *\n-     * @param pdm\n-     */\n-    private void dropForeignKeyConstraints(PhysicalDataModel pdm, String tagGroup, String tag) {\n-        try (Connection c = createConnection()) {\n-            try {\n-                JdbcTarget target = new JdbcTarget(c);\n-                IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                Set<Table> referencedTables = new HashSet<>();\n-                DropForeignKey dropper = new DropForeignKey(adapter, referencedTables);\n-                pdm.visit(dropper, tagGroup, tag);\n-            } catch (Exception x) {\n-                c.rollback();\n-                throw x;\n-            }\n-            c.commit();\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Stored Procedures and Functions feature\n-    /**\n-     * Update the stored procedures used by FHIR to insert records\n-     * into the FHIR resource tables\n-     */\n-    protected void updateProcedures() {\n-        if (!STORED_PROCEDURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        // Since this is a stored procedure, we need the model.\n-        // We must pass in true to flag to the underlying layer that the\n-        // Procedures need to be generated.\n-        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n-\n-        // Now only apply the procedures in the model. Much faster than\n-        // going through the whole schema\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                try {\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-                    pdm.applyProcedures(adapter);\n-                    pdm.applyFunctions(adapter);\n-                    \n-                    // Because we're replacing the procedures, we should also check if\n-                    // we need to apply the associated privileges\n-                    if (this.grantTo != null) {\n-                        pdm.applyProcedureAndFunctionGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the\n-                // transaction commit.\n-            } catch (SQLException x) {\n-                tx.setRollbackOnly();\n-                throw translator.translate(x);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Build a common PhysicalDataModel containing all the requested schemas\n-     * \n-     * @param pdm the model to construct\n-     * @param addFhirDataSchema include objects for the FHIR data schema\n-     * @param addOAuthSchema include objects for the Liberty OAuth schema\n-     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n-     */\n-    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n-        if (addFhirDataSchema) {\n-            buildFhirDataSchemaModel(pdm);\n-        }\n-        \n-        if (addOAuthSchema) {\n-            buildOAuthSchemaModel(pdm);\n-        }\n-        \n-        if (addJavaBatchSchema) {\n-            buildJavaBatchSchemaModel(pdm);\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the FHIR data schema objects\n-     */\n-    protected void grantPrivilegesForFhirData() {\n-\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                \n-                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n-                // Note the constant comes from SchemaConstants on purpose\n-                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the OAuth schema objects\n-     */\n-    protected void grantPrivilegesForOAuth() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n-                \n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        \n-    }\n-\n-    /**\n-     * Apply grants to the JavaBatch schema objects\n-     */\n-    protected void grantPrivilegesForBatch() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Grant the minimum required set of privileges on the FHIR schema objects\n-     * to the grantTo user. All tenant data access is via this user, and is the\n-     * only user the FHIR server itself is configured with.\n-     */\n-    protected void grantPrivileges() {\n-        if (!PRIVILEGES_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // The case where all are to be granted on the default schemas.\n-        if (!(updateFhirSchema || grantFhirSchema || updateOauthSchema\n-                || grantOauthSchema || updateJavaBatchSchema || grantJavaBatchSchema)) {\n-            grantOauthSchema = true;\n-            grantFhirSchema = true;\n-            grantJavaBatchSchema = true;\n-        }\n-        \n-        if (grantFhirSchema) {\n-            grantPrivilegesForFhirData();\n-        }\n-        \n-        if (grantOauthSchema) {\n-            grantPrivilegesForOAuth();\n-        }\n-        \n-        if (grantJavaBatchSchema) {\n-            grantPrivilegesForBatch();\n-        }\n-    }\n-\n-    /**\n-     * Do we want to build the multitenant variant of the schema (currently only supported\n-     * by DB2)\n-     *\n-     * @return\n-     */\n-    protected boolean isMultitenant() {\n-        return MULTITENANT_FEATURE_ENABLED.contains(this.dbType);\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to Multi-Tenant only.\n-    /**\n-     * Add a new tenant key so that we can rotate the values (add a\n-     * new key, update config files, then remove the old key). This\n-     * avoids any service interruption.\n-     */\n-    protected void addTenantKey() {\n-        if (!isMultitenant()) {\n-            return;\n-        }\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, false);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantDAO tid = new GetTenantDAO(schema.getAdminSchemaName(), addKeyForTenant);\n-                Tenant tenant = adapter.runStatement(tid);\n-\n-                if (tenant != null) {\n-                    // Attach the new tenant key to the tenant:\n-                    AddTenantKeyDAO adder =\n-                            new AddTenantKeyDAO(schema.getAdminSchemaName(), tenant.getTenantId(), tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-                    adapter.runStatement(adder);\n-                } else {\n-                    throw new IllegalArgumentException(\"Tenant does not exist: \" + addKeyForTenant);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            // Generated\n-            logger.info(\"New tenant key: \" + addKeyForTenant + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            // Loaded from File\n-            logger.info(\"New tenant key from file: \" + addKeyForTenant + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * checks if tenant name and tenant key exists.\n-     *\n-     * @param adapter\n-     *            the db2 adapter as this is a db2 feature only now\n-     * @param tenantName\n-     *            the tenant's name\n-     * @param tenantKey\n-     *            tenant key\n-     * @param skip\n-     *            whether or not to skip over cases where this tenantName/tenantKey combination already exists\n-     *\n-     * @throws IllegalArgumentException if the tenantName/tenantKey combination already exists and the {@code skip} argument is false\n-     *\n-     * @return indicates if the tenantName/tenantKey exists\n-     */\n-    protected boolean checkIfTenantNameAndTenantKeyExists(Db2Adapter adapter, String tenantName, String tenantKey, boolean skip) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                final String sql =\n-                        \"SELECT t.tenant_status FROM fhir_admin.tenants t WHERE t.tenant_name = ? \"\n-                                + \"AND EXISTS (SELECT 1 FROM fhir_admin.tenant_keys tk WHERE tk.mt_id = t.mt_id \"\n-                                + \"AND tk.tenant_hash = sysibm.hash(tk.tenant_salt || ?, 2))\";\n-                try (PreparedStatement stmt = connectionPool.getConnection().prepareStatement(sql)) {\n-                    stmt.setString(1, tenantName);\n-                    stmt.setString(2, tenantKey);\n-                    if (stmt.execute()) {\n-                        try (ResultSet resultSet = stmt.getResultSet();) {\n-                            if (resultSet.next()) {\n-                                if (skip) {\n-                                    return true;\n-                                } else {\n-                                    throw new IllegalArgumentException(\"tenantName and tenantKey already exists\");\n-                                }\n-                            }\n-                        }\n-                    } else {\n-                        throw new IllegalArgumentException(\"Problem checking the results\");\n-                    }\n-                } catch (SQLException e) {\n-                    throw new IllegalArgumentException(\"Exception when querying backend to verify tenant key and tenant name\", e);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return false;\n-    }\n-\n-    /**\n-     * Allocate this tenant, creating new partitions if required.\n-     */\n-    protected void allocateTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // IMPORTANT! Check the schema name aligns with the actual schema for this tenant\n-        checkSchemaForTenant();\n-\n-        // The key we'll use for this tenant. This key should be used in subsequent\n-        // activities related to this tenant, such as setting the tenant context.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        // Conditionally skip if the tenant name and key exist (this enables idempotency)\n-        boolean skip = checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, skipIfTenantExists);\n-        if (skip) {\n-            return;\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-        }\n-\n-        // Open a new transaction and associate it with our connection pool. Remember\n-        // that we don't support distributed transactions, so all connections within\n-        // this transaction must come from the same pool\n-        int tenantId;\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                tenantId =\n-                        adapter.allocateTenant(schema.getAdminSchemaName(), schema.getSchemaName(), tenantName, tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-\n-                // The tenant-id is important because this is also used to identify the partition number\n-                logger.info(\"Tenant Id[\" + tenantName + \"] = [\" + tenantId + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Get the data model to create the table partitions. This is threaded, so transactions are\n-        // handled within each thread by the adapter. This means we should probably pull some of\n-        // that logic out of the adapter and handle it at a higher level. Note...the extent size used\n-        // for the partitions needs to match the extent size of the original table tablespace (FHIR_TS)\n-        // so this must be constant.\n-        pdm.addTenantPartitions(adapter, schema.getSchemaName(), tenantId, FhirSchemaConstants.FHIR_TS_EXTENT_KB);\n-\n-        // Fill any static data tables (which are also partitioned by tenant)\n-        // Prepopulate the Resource Type Tables and Parameters Name/Code Table\n-        populateResourceTypeAndParameterNameTableEntries(tenantId);\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as ready\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantId, TenantStatus.ALLOCATED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [key=\" + tenantKey + \"] with Id = \" + tenantId);\n-            logger.info(\"The tenantKey JSON follows: \\t\\n{\\\"tenantKey\\\": \\\"\" + tenantKey + \"\\\"}\");\n-        } else {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"] with Id = \"\n-                    + tenantId);\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Run a check to make sure that if the tenant already exists its schema\n-     * matches the specified schema. This prevents users from accidentally\n-     * creating a second instance of a tenant in a different schema\n-     */\n-    protected void checkSchemaForTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // only relevant for databases which support multiple tenants within one schema (like Db2)\n-            return;\n-        }\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // Scan over the list to see if the tenant we are working with\n-        // already exists\n-        for (TenantInfo ti : tenants) {\n-            if (ti.getTenantName().equals(this.tenantName)) {\n-                if (ti.getTenantSchema() == null) {\n-                    // The schema is empty so no chance of adding tenants\n-                    throw new IllegalArgumentException(\"Schema '\" + schema.getSchemaName() + \"'\"\n-                            + \" for tenant '\" + ti.getTenantName() + \"'\"\n-                            + \" does not contain a valid IBM FHIR Server schema\");\n-                } else if (!ti.getTenantSchema().equalsIgnoreCase(schema.getSchemaName())) {\n-                    // The given schema name doesn't match where we think this tenant\n-                    // should be located, so throw an error before any damage is done\n-                    throw new IllegalArgumentException(\"--schema-name argument '\" + schema.getSchemaName()\n-                            + \"' does not match schema '\" + ti.getTenantSchema() + \"' for tenant '\"\n-                            + ti.getTenantName() + \"'\");\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Get the list of tenants and the schemas each is currently defined in. Because\n-     * this tenant-schema mapping isn't stored directly, it has to be inferred by\n-     * looking up the schema from one of the tables we know should exist. The schema\n-     * name may therefore be null if the tenant record (in FHIR_ADMIN.TENANTS) exists,\n-     * but all the tables from that schema have been dropped.\n-     *\n-     * @return\n-     */\n-    protected List<TenantInfo> getTenantList() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return Collections.emptyList();\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants;\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                tenants = adapter.runStatement(rtListGetter);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        return tenants;\n-    }\n-\n-    /**\n-     * Make sure all the tables has a partition created for the configured tenant\n-     */\n-    protected void refreshTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // make sure the list is sorted by tenantId. Lambdas really do clean up this sort of code\n-        tenants.sort((TenantInfo left, TenantInfo right) -> left.getTenantId() < right.getTenantId() ? -1 : left.getTenantId() > right.getTenantId() ? 1 : 0);\n-        for (TenantInfo ti : tenants) {\n-            // For issue 1847 we only want to process for the named data schema if one is provided\n-            // If no -schema-name arg is given, we process all tenants.\n-            if (ti.getTenantSchema() != null && (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema()))) {\n-                // It's crucial we use the correct schema for each particular tenant, which\n-                // is why we have to build the PhysicalDataModel separately for each tenant\n-                FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), ti.getTenantSchema(), isMultitenant());\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                gen.buildSchema(pdm);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                pdm.addNewTenantPartitions(adapter, ti.getTenantSchema(), ti.getTenantId());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * List the tenants currently configured\n-     */\n-    protected void listTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                List<TenantInfo> tenants = adapter.runStatement(rtListGetter);\n-\n-                System.out.println(TenantInfo.getHeader());\n-                tenants.forEach(System.out::println);\n-            } catch (UndefinedNameException x) {\n-                System.out.println(\"The FHIR_ADMIN schema appears not to be deployed with the TENANTS table\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Check that we can call the set_tenant procedure successfully (which means\n-     * that the\n-     * tenant record exists in the tenants table)\n-     */\n-    protected void testTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        if (this.tenantName == null || this.tenantName.isEmpty()) {\n-            throw new IllegalStateException(\"Missing tenant name\");\n-        }\n-\n-        // Part of Bring your own Tenant Key\n-        if (tenantKeyFileName != null) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        if (this.tenantKey == null || this.tenantKey.isEmpty()) {\n-            throw new IllegalArgumentException(\"No tenant-key value provided\");\n-        }\n-\n-        logger.info(\"Testing tenant: [\" + tenantName + \"]\");\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // The tenants table, variable and set_tenant procedure are all located in\n-                // the admin schema. The data access user only has execute privileges on the\n-                // set_tenant procedure and read access to the variable. The variable can\n-                // only be set by calling the stored procedure\n-                Db2SetTenantVariable cmd = new Db2SetTenantVariable(schema.getAdminSchemaName(), tenantName, tenantKey);\n-                adapter.runStatement(cmd);\n-\n-                Db2GetTenantVariable getter = new Db2GetTenantVariable(schema.getAdminSchemaName());\n-                Integer tid = adapter.runStatement(getter);\n-                if (tid == null) {\n-                    throw new IllegalStateException(\"SV_TENANT_ID not set!\");\n-                }\n-\n-                // Print the id from the session variable (used for access control)\n-                logger.info(\"tenantName='\" + tenantName + \"', tenantId=\" + tid);\n-\n-                // Now let's check we can run a select against one our tenant-based\n-                // tables\n-                GetResourceTypeList rtListGetter = new GetResourceTypeList(schema.getSchemaName());\n-                List<ResourceType> rtList = adapter.runStatement(rtListGetter);\n-                rtList.forEach(rt -> logger.info(\"ResourceType: \" + rt.toString()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    protected TenantInfo getTenantInfo() {\n-        TenantInfo result;\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                GetTenantInfo command = new GetTenantInfo(schema.getAdminSchemaName(), tenantName);\n-                result = adapter.runStatement(command);\n-\n-                if (result == null) {\n-                    logger.info(\"Use --list-tenants to display the current tenants\");\n-                    throw new IllegalArgumentException(\"Tenant '\" + tenantName + \"' not found in admin schema \" + schema.getAdminSchemaName());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // make sure we set the schema name correctly if it couldn't be found in the database\n-        // (which happens after all the partitions for a particular tenant are detached)\n-        String tenantSchema = result.getTenantSchema();\n-        if (tenantSchema == null || tenantSchema.isEmpty()) {\n-            // the schema can no longer be derived from the database, so we\n-            // need it to be provided on the command line.\n-            if (schema.getSchemaName() == null || schema.getSchemaName().isEmpty()) {\n-                throw new IllegalArgumentException(\"Must provide the tenant schema with --schema-name\");\n-            }\n-            result.setTenantSchema(schema.getSchemaName());\n-        } else {\n-            // if a schema name was provided on the command line, let's double-check it matches\n-            // the schema used for this tenant in the database\n-            if (!tenantSchema.equalsIgnoreCase(schema.getSchemaName())) {\n-                throw new IllegalArgumentException(\"--schema-name '\" + schema.getSchemaName() + \"' argument does not match tenant schema: '\"\n-                        + tenantSchema + \"'\");\n-            }\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Mark the tenant so that it can no longer be accessed (this prevents\n-     * the SET_TENANT method from authenticating the tenantName/tenantKey\n-     * pair, so the SV_TENANT_ID variable never gets set).\n-     *\n-     * @return the TenantInfo associated with the tenant\n-     */\n-    protected TenantInfo freezeTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        TenantInfo result = getTenantInfo();\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        logger.info(\"Marking tenant for drop: \" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                // Mark the tenant as frozen before we proceed with dropping anything\n-                if (result.getTenantStatus() == TenantStatus.ALLOCATED) {\n-                    adapter.updateTenantStatus(schema.getAdminSchemaName(), result.getTenantId(), TenantStatus.FROZEN);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return result;\n-    }\n-\n-    /**\n-     * Deallocate this tenant, dropping all the related partitions. This needs to be\n-     * idempotent because there are steps which must be run in separate transactions\n-     * (due to how Db2 handles detaching partitions). This is further complicated by\n-     * referential integrity constraints in the schema. See:\n-     * - https://www.ibm.com/support/knowledgecenter/SSEPGG_11.5.0/com.ibm.db2.luw.admin.partition.doc/doc/t0021576.html\n-     *\n-     * The workaround described in the above link is:\n-     * // Change the RI constraint to informational:\n-     * 1. ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     *\n-     * 2. ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     *\n-     * 3. SET INTEGRITY FOR child OFF;\n-     *\n-     * // Change the RI constraint back to enforced:\n-     * 4. ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     *\n-     * 5. SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     * 6. Assuming that the CHILD table does not have any dependencies on partition P0,\n-     * 7. and that no updates on the CHILD table are permitted until this UOW is complete,\n-     * no RI violation is possible during this UOW.\n-     *\n-     * COMMIT WORK;\n-     *\n-     * Unfortunately, #7 above essentially requires that all writes cease until the\n-     * UOW is completed and the integrity is enabled again on all the child (leaf)\n-     * tables. Of course, this could be relaxed if the application is trusted not\n-     * to mess up the referential integrity...which we know to be true for the\n-     * FHIR server persistence layer.\n-     *\n-     * If the risk is deemed too high, tenant removal should be performed in a\n-     * maintenance window.\n-     */\n-    protected void dropTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Mark the tenant as being dropped. This should prevent it from\n-        // being used in any way because the SET_TENANT stored procedure\n-        // will reject any request for the tenant being dropped.\n-        TenantInfo tenantInfo = freezeTenant();\n-\n-        // Build the model of the data (FHIRDATA) schema which is then used to drive the drop\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Detach the tenant partition from each of the data tables\n-        detachTenantPartitions(pdm, tenantInfo);\n-\n-        // this may not complete successfully because Db2 runs the detach as an async\n-        // process. Just need to run --drop-detached to clean up.\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. The detach process is asynchronous,\n-     * so this is a sort of garbage collection, sweeping up cruft left in the database.\n-     */\n-    protected void dropDetachedPartitionTables() {\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. Once all tables have been\n-     * dropped, we go on to drop the tablespace. If the tablespace drop is successful,\n-     * we know the cleanup is complete so we can update the tenant status accordingly\n-     *\n-     * @param pdm\n-     * @param tenantInfo\n-     */\n-    protected void dropDetachedPartitionTables(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        // In a new transaction, drop any of the tables that were created by\n-        // the partition detach operation.\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                pdm.dropDetachedPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // We can drop the tenant's tablespace only after all the table drops have been committed\n-        logger.info(\"Dropping tablespace for tenant \" + tenantInfo.getTenantId() + \"/\" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            boolean retry = true;\n-            int wait = 0;\n-            while (retry) {\n-                try {\n-                    retry = false;\n-                    // With all the objects removed, it should be safe to remove the tablespace\n-                    pdm.dropTenantTablespace(adapter, tenantInfo.getTenantId());\n-                } catch (DataAccessException x) {\n-                    boolean error = x instanceof DataAccessException && x.getCause() instanceof SQLException\n-                            && (((SQLException) x.getCause()).getErrorCode() == -282);\n-                    if (error && wait++ <= 30) {\n-                        retry = true;\n-                        logger.warning(\"Waiting on async dettach dependency to finish - count '\" + wait + \"'\");\n-                        try {\n-                            Thread.sleep(2000);\n-                        } catch (InterruptedException e) {\n-                            throw new DataAccessException(e);\n-                        }\n-                    } else if (error) {\n-                        throw new TableSpaceRemovalException(x.getCause());\n-                    } else {\n-                        // Something went wrong, so mark the transaction as failed\n-                        tx.setRollbackOnly();\n-                        throw x;\n-                    }\n-                }\n-            }\n-        }\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as dropped\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantInfo.getTenantId(), TenantStatus.DROPPED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Temporarily suspend RI so that tables which are the subject of foreign\n-     * key relationships can have their partitions dropped. A bit frustrating\n-     * to have to go through this, because the child table partition will be\n-     * detached before the parent anyway, so theoretically this workaround\n-     * shouldn't be necessary.\n-     * ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     * ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     * SET INTEGRITY FOR child OFF;\n-     * ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     * SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     */\n-    protected void detachTenantPartitions(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // collect the set of all child tables with FK relationships to\n-                // partitioned tables\n-                Set<Table> childTables = new HashSet<>();\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-                pdm.visit(new DisableForeignKey(adapter, childTables));\n-\n-                // ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-                pdm.detachTenantPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-\n-                // SET INTEGRITY FOR child OFF;\n-                childTables.forEach(t -> adapter.setIntegrityOff(t.getSchemaName(), t.getObjectName()));\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-                pdm.visit(new EnableForeignKey(adapter));\n-\n-                // SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-                childTables.forEach(t -> adapter.setIntegrityUnchecked(t.getSchemaName(), t.getObjectName()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * Delete all the metadata associated with the named tenant.\n-     */\n-    protected void deleteTenantMeta() {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        TenantInfo tenantInfo = getTenantInfo();\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                if (tenantInfo.getTenantStatus() == TenantStatus.DROPPED) {\n-                    adapter.deleteTenantMeta(schema.getAdminSchemaName(), tenantInfo.getTenantId());\n-                } else {\n-                    throw new IllegalStateException(\"Cannot delete tenant meta data until status is \" + TenantStatus.DROPPED.name());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * revokes a tenant key or if no tenant key is specified remove all of them for the\n-     * given tenant.\n-     */\n-    protected void revokeTenantKey() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        int tenantId = tenantInfo.getTenantId();\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                DeleteTenantKeyDAO dtk = new DeleteTenantKeyDAO(schema.getAdminSchemaName(), tenantId, tenantKey);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                adapter.runStatement(dtk);\n-                int count = dtk.getCount();\n-                logger.info(\"Tenant Key revoked for '\" + tenantInfo.getTenantName() + \"' total removed=[\" + count + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to parsing arguments and action selection\n-    /**\n-     * Parse the command-line arguments, building up the environment and\n-     * establishing\n-     * the run-list\n-     *\n-     * @param args\n-     */\n-    protected void parseArgs(String[] args) {\n-        // Arguments are pretty simple, so we go with a basic switch instead of having\n-        // yet another dependency (e.g. commons-cli).\n-        LeaseManagerConfig.Builder lmConfig = LeaseManagerConfig.builder();\n-        lmConfig.withHost(new HostnameHandler().getHostname());\n-        lmConfig.withLeaseTimeSeconds(100); // default\n-        lmConfig.withStayAlive(true);       // default\n-        \n-        for (int i = 0; i < args.length; i++) {\n-            int nextIdx = (i + 1);\n-            String arg = args[i];\n-            switch (arg) {\n-            case \"--prop-file\":\n-                if (++i < args.length) {\n-                    loadPropertyFile(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--schema-name\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    schema.setSchemaName(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--grant-to\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-\n-                    // Force upper-case because user names are case-insensitive\n-                    this.grantTo = args[i].toUpperCase();\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--target\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    List<String> targets = Arrays.asList(args[i].split(\",\"));\n-                    for (String target : targets) {\n-                        String tmp = target.toUpperCase();\n-                        nextIdx++;\n-                        if (tmp.startsWith(\"BATCH\")) {\n-                            this.grantJavaBatchSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setJavaBatchSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"OAUTH\")) {\n-                            this.grantOauthSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setOauthSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"DATA\")) {\n-                            this.grantFhirSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else {\n-                            throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                        }\n-                    }\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--add-tenant-key\":\n-                if (++i < args.length) {\n-                    this.addKeyForTenant = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--revoke-tenant-key\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeTenantKey = true;\n-                break;\n-            case \"--revoke-all-tenant-keys\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeAllTenantKeys = true;\n-                break;\n-            case \"--update-proc\":\n-                this.updateProc = true;\n-                break;\n-            case \"--check-compatibility\":\n-                this.checkCompatibility = true;\n-                break;\n-            case \"--drop-admin\":\n-                this.dropAdmin = true;\n-                break;\n-            case \"--test-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.testTenant = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key\":\n-                if (++i < args.length) {\n-                    this.tenantKey = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key-file\":\n-                if (++i < args.length) {\n-                    tenantKeyFileName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--list-tenants\":\n-                this.listTenants = true;\n-                break;\n-            case \"--update-schema\":\n-                this.updateFhirSchema = true;\n-                this.updateOauthSchema = true;\n-                this.updateJavaBatchSchema = true;\n-                break;\n-            case \"--update-schema-fhir\":\n-                this.updateFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                } else {\n-                    schema.setSchemaName(DATA_SCHEMANAME);\n-                }\n-                break;\n-            case \"--update-schema-batch\":\n-                this.updateJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--update-schema-oauth\":\n-                this.updateOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schemas\":\n-                this.createFhirSchema = true;\n-                this.createOauthSchema = true;\n-                this.createJavaBatchSchema = true;\n-                break;\n-            case \"--create-schema-fhir\":\n-                this.createFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-batch\":\n-                this.createJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-oauth\":\n-                this.createOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema\":\n-                System.err.print(\"Option '--drop-schema' has been retired.  Please use '--drop-schema-fhir', \"\n-                        + \"'--drop-schema-batch', and/or '--drop-schema-oauth'.\");\n-                break;\n-            case \"--drop-schema-fhir\":\n-                this.dropFhirSchema = Boolean.TRUE;\n-                break;\n-            case \"--drop-schema-batch\":\n-                this.dropJavaBatchSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema-oauth\":\n-                this.dropOauthSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--pool-size\":\n-                if (++i < args.length) {\n-                    this.maxConnectionPoolSize = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--prop\":\n-                if (++i < args.length) {\n-                    // properties are given as name=value\n-                    addProperty(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--update-vacuum\":\n-                updateVacuum = true;\n-                break;\n-            case \"--vacuum-cost-limit\":\n-                if (++i < args.length) {\n-                    this.vacuumCostLimit = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-threshold\":\n-                if (++i < args.length) {\n-                    this.vacuumThreshold = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-scale-factor\":\n-                if (++i < args.length) {\n-                    this.vacuumScaleFactor = Double.parseDouble(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-table-name\":\n-                if (++i < args.length) {\n-                    this.vacuumTableName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--confirm-drop\":\n-                this.confirmDrop = true;\n-                break;\n-            case \"--allocate-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.allocateTenant = true;\n-                    this.dropTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--refresh-tenants\":\n-                this.refreshTenants = true;\n-                this.allocateTenant = false;\n-                this.dropTenant = false;\n-                break;\n-            case \"--drop-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropTenant = true;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--freeze-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.freezeTenant = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--drop-detached\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropDetached = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--delete-tenant-meta\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.deleteTenantMeta = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--db-type\":\n-                if (++i < args.length) {\n-                    this.dbType = DbType.from(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                switch (dbType) {\n-                case DERBY:\n-                    translator = new DerbyTranslator();\n-                    break;\n-                case POSTGRESQL:\n-                    translator = new PostgresTranslator();\n-                    break;\n-                case DB2:\n-                default:\n-                    break;\n-                }\n-                break;\n-            // Skips the allocateTenant action if the tenant exists (e.g. a shortcircuit)\n-            case \"--skip-allocate-if-tenant-exists\":\n-                skipIfTenantExists = true;\n-                break;\n-            default:\n-                throw new IllegalArgumentException(\"Invalid argument: '\" + arg + \"'\");\n-            }\n-        }\n-        \n-        this.leaseManagerConfig = lmConfig.build();\n-    }\n-\n-    /**\n-     * Read the properties from the given file\n-     *\n-     * @param filename\n-     */\n-    public void loadPropertyFile(String filename) {\n-        try (InputStream is = new FileInputStream(filename)) {\n-            properties.load(is);\n-            // Trim leading and trailing whitespace from property values (except password)\n-            for (Entry<Object, Object> entry : properties.entrySet()) {\n-                if (!\"password\".equals(entry.getKey())) {\n-                    String trimmedValue = entry.getValue().toString().trim();\n-                    if (!trimmedValue.equals(entry.getValue().toString())) {\n-                        logger.warning(\"Whitespace trimmed from value of property '\" + entry.getKey() + \"'\");\n-                        entry.setValue(trimmedValue);\n-                    }\n-                }\n-            }\n-        } catch (IOException x) {\n-            throw new IllegalArgumentException(x);\n-        }\n-    }\n-\n-    /**\n-     * Parse the given key=value string and add to the properties being collected\n-     *\n-     * @param pair\n-     */\n-    public void addProperty(String pair) {\n-        String[] kv = pair.split(\"=\");\n-        if (kv.length == 2) {\n-            // Trim leading and trailing whitespace from property value (except password)\n-            if (!\"password\".equals(kv[0])) {\n-                String trimmedValue = kv[1].trim();\n-                if (!trimmedValue.equals(kv[1])) {\n-                    logger.warning(\"Whitespace trimmed from value of property '\" + kv[0] + \"'\");\n-                }\n-                properties.put(kv[0], trimmedValue);\n-            } else {\n-                properties.put(kv[0], kv[1]);\n-            }\n-        } else {\n-            throw new IllegalArgumentException(\"Property must be defined as key=value, not: \" + pair);\n-        }\n-    }\n-\n-    /**\n-     * Perform the special data migration steps required for the V0010 version of the schema\n-     */\n-    protected void applyDataMigrationForV0010() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0010(ti);\n-                }\n-            }\n-        } else {\n-            doMigrationForV0010();\n-        }\n-    }\n-\n-    protected void applyDataMigrationForV0014() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0014(ti);\n-                }\n-            }\n-        } else {\n-            dataMigrationForV0014();\n-        }\n-    }\n-\n-    /**\n-     * Get the list of resource types to drive resource-by-resource operations\n-     *\n-     * @return the full list of FHIR R4 resource types, or a subset of names if so configured\n-     */\n-    private Set<String> getResourceTypes() {\n-        Set<String> result;\n-        if (this.resourceTypeSubset == null || this.resourceTypeSubset.isEmpty()) {\n-            // pass 'false' to getResourceTypes to avoid building tables for abstract resource types\n-            // Should simplify FhirSchemaGenerator and always pass in this list. When switching\n-            // over to false, migration is required to drop the tables no longer required.\n-            final boolean includeAbstractResourceTypes = true;\n-            result = ModelSupport.getResourceTypes(includeAbstractResourceTypes).stream().map(Class::getSimpleName).collect(Collectors.toSet());\n-        } else {\n-            result = this.resourceTypeSubset;\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Get the list of resource types from the database.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @return\n-     */\n-    private List<ResourceType> getResourceTypesList(IDatabaseAdapter adapter, String schemaName) {\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetResourceTypeList cmd = new GetResourceTypeList(schemaName);\n-                return adapter.runStatement(cmd);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the IS_DELETED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0010(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each update in its own transaction so we don't stress the tx log space\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES.IS_DELETED \"\n-                                + \"for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Perform the data migration for V0010 (non-multi-tenant schema)\n-     */\n-    private void doMigrationForV0010() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    // only process tables which have been converted to the V0010 schema but\n-                    // which have not yet had their data migrated. The migration can't be\n-                    // done as part of the schema change because some tables need a REORG which\n-                    // has to be done after the transaction in which the alter table was performed.\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010-V0012 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES denormalized columns in schema \"\n-                                + schema.getSchemaName());\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0014(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each update in its own transaction so we don't over-stress the tx log space\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    logger.info(\"V0014 Migration: Updating \" + \"LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for \" + resourceType.toString()\n-                            + \" for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-\n-                    dataMigrationForV0014(adapter, ti.getTenantSchema(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data\n-     */\n-    private void dataMigrationForV0014() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    dataMigrationForV0014(adapter, schema.getSchemaName(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * only process tables which have not yet had their data migrated. The migration can't be\n-     * done as part of the schema change because some tables need a REORG which\n-     * has to be done after the transaction in which the alter table was performed.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @param resourceType\n-     */\n-    private void dataMigrationForV0014(IDatabaseAdapter adapter, String schemaName, ResourceType resourceType) {\n-        GetLogicalResourceNeedsV0014Migration needsMigrating = new GetLogicalResourceNeedsV0014Migration(schemaName, resourceType.getId());\n-        if (adapter.runStatement(needsMigrating)) {\n-            logger.info(\"V0014 Migration: Updating LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for schema '\"\n-                    + schemaName + \"' and resource type '\" + resourceType.toString() + \"'\");\n-            MigrateV0014LogicalResourceIsDeletedLastUpdated cmd =\n-                    new MigrateV0014LogicalResourceIsDeletedLastUpdated(schemaName, resourceType.getName(), resourceType.getId());\n-            adapter.runStatement(cmd);\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table if it is empty\n-     */\n-    protected void backfillResourceChangeLog() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    backfillResourceChangeLogDb2(ti);\n-                }\n-            }\n-        } else {\n-            // Not a multi-tenant database, so we only have to do this once\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                    if (adapter.runStatement(isEmpty)) {\n-                        // change log is empty, so we need to backfill it with data\n-                        doBackfill(adapter);\n-                    } else {\n-                        logger.info(\"RESOURCE_CHANGE_LOG has data so skipping backfill\");\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * backfill the resource_change_log table if it is empty\n-     */\n-    protected void backfillResourceChangeLogDb2(TenantInfo ti) {\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                adapter.runStatement(setTenantId);\n-\n-                GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                if (adapter.runStatement(isEmpty)) {\n-                    // change log is empty, so we need to backfill it with data\n-                    for (String resourceTypeName : resourceTypes) {\n-                        logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                                + \" resources for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        BackfillResourceChangeLogDb2 backfill = new BackfillResourceChangeLogDb2(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(backfill);\n-                    }\n-                } else {\n-                    logger.info(\"RESOURCE_CHANGE_LOG has data for tenant '\" + ti.getTenantName() + \"' so skipping backfill\");\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table for all the resource types. Non-multi-tenant\n-     * implementation\n-     *\n-     * @param adapter\n-     */\n-    private void doBackfill(IDatabaseAdapter adapter) {\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        for (String resourceTypeName : resourceTypes) {\n-            logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                    + \" resources for schema '\" + schema.getSchemaName() + \"'\");\n-            BackfillResourceChangeLog backfill = new BackfillResourceChangeLog(schema.getSchemaName(), resourceTypeName);\n-            adapter.runStatement(backfill);\n-        }\n-    }\n-\n-    /**\n-     * updates the vacuum settings for postgres.\n-     */\n-    public void updateVacuumSettings() {\n-        if (dbType != DbType.POSTGRESQL) {\n-            logger.severe(\"Updating the vacuum settings is only supported on postgres and the setting is for '\" + dbType + \"'\");\n-            return;\n-        }\n-\n-        // Create the Physical Data Model\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, true, false, false);\n-\n-        // Setup the Connection Pool\n-        this.maxConnectionPoolSize = 10;\n-        configureConnectionPool();\n-        PostgresAdapter adapter = new PostgresAdapter(connectionPool);\n-\n-        if (vacuumTableName != null) {\n-            runSingleTable(adapter, pdm, schema.getSchemaName(), vacuumTableName);\n-        } else {\n-            // Process all tables in the schema ... except for XX_RESOURCES and COMMON_TOKEN_VALUES and COMMON_CANONICAL_VALUES\n-            GatherTablesDataModelVisitor visitor = new GatherTablesDataModelVisitor();\n-            pdm.visit(visitor);\n-\n-            for (Table tbl : visitor.getTables()) {\n-                runSingleTable(adapter, pdm, schema.getSchemaName(), tbl.getObjectName());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * runs the vacuum update inside a single connection and single transaction.\n-     *\n-     * @param adapter\n-     * @param pdm\n-     * @param schemaName\n-     * @param vacuumTableName\n-     */\n-    private void runSingleTable(PostgresAdapter adapter, PhysicalDataModel pdm, String schemaName, String vacuumTableName) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // If the vacuumTableName exists, then we try finding the table definition.\n-                Table table = pdm.findTable(schemaName, vacuumTableName);\n-                if (table == null) {\n-                    logger.severe(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                    throw new IllegalArgumentException(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                }\n-                PostgresVacuumSettingDAO alterVacuumSettings =\n-                        new PostgresVacuumSettingDAO(schemaName, table.getObjectName(), vacuumCostLimit, vacuumScaleFactor, vacuumThreshold);\n-                adapter.runStatement(alterVacuumSettings);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Process the requested operation\n-     */\n-    protected void process() {\n-        long start = System.nanoTime();\n-        loadDriver(translator);\n-        configureConnectionPool();\n-\n-        if (this.checkCompatibility) {\n-            checkCompatibility();\n-        }\n-\n-        if (translator.isDerby() && !\"APP\".equals(schema.getSchemaName())) {\n-            if (schema.isOverrideDataSchema()) {\n-                logger.warning(\"Only the APP schema is supported for Apache Derby; ignoring the passed\"\n-                        + \" schema name '\" + schema.getSchemaName() + \"' and using APP.\");\n-            }\n-            schema.setSchemaName(\"APP\");\n-        }\n-\n-        // [optional] use a subset of resource types to make testing quicker\n-        String resourceTypesString = properties.getProperty(\"resourceTypes\");\n-        if (resourceTypesString != null && resourceTypesString.length() > 0) {\n-            resourceTypeSubset = new HashSet<>(Arrays.asList(resourceTypesString.split(\",\")));\n-        }\n-\n-        if (addKeyForTenant != null) {\n-            addTenantKey();\n-        } else if (updateVacuum) {\n-            updateVacuumSettings();\n-        } else if (this.dropAdmin || this.dropFhirSchema || this.dropJavaBatchSchema || this.dropOauthSchema) {\n-            // only proceed with the drop if the user has provided additional confirmation\n-            if (this.confirmDrop) {\n-                dropSchema();\n-            } else {\n-                throw new IllegalArgumentException(\"[ERROR] Drop not confirmed with --confirm-drop\");\n-            }\n-        } else if (updateFhirSchema || updateOauthSchema || updateJavaBatchSchema) {\n-            updateSchemas();\n-        } else if (createFhirSchema || createOauthSchema || createJavaBatchSchema) {\n-            createSchemas();\n-        } else if (updateProc) {\n-            updateProcedures();\n-        } else if (grantTo != null) {\n-            grantPrivileges();\n-        } else if (this.listTenants) {\n-            listTenants();\n-        } else if (this.allocateTenant) {\n-            allocateTenant();\n-        } else if (this.refreshTenants) {\n-            refreshTenants();\n-        } else if (this.testTenant) {\n-            testTenant();\n-        } else if (this.freezeTenant) {\n-            freezeTenant();\n-        } else if (this.dropDetached) {\n-            dropDetachedPartitionTables();\n-        } else if (this.deleteTenantMeta) {\n-            deleteTenantMeta();\n-        } else if (this.dropTenant) {\n-            dropTenant();\n-        } else if (this.revokeTenantKey) {\n-            revokeTenantKey();\n-        } else if (this.revokeAllTenantKeys) {\n-            if (this.tenantKey != null) {\n-                throw new IllegalArgumentException(\"[ERROR] --tenant-key <key-value> should not be specified together with --drop-all-tenant-keys\");\n-            }\n-            revokeTenantKey();\n-        }\n-\n-        long elapsed = System.nanoTime() - start;\n-        logger.info(String.format(\"Processing took: %7.3f s\", elapsed / NANOS));\n-    }\n-\n-    /**\n-     * Get the program exit status from the environment\n-     *\n-     * @return\n-     */\n-    protected int getExitStatus() {\n-        return this.exitStatus;\n-    }\n-\n-    /**\n-     * Write a final status message - useful for QA to review when checking the\n-     * output\n-     */\n-    protected void logStatusMessage(int status) {\n-        switch (status) {\n-        case EXIT_OK:\n-            logger.info(\"SCHEMA CHANGE: OK\");\n-            break;\n-        case EXIT_BAD_ARGS:\n-            logger.severe(\"SCHEMA CHANGE: BAD ARGS\");\n-            break;\n-        case EXIT_RUNTIME_ERROR:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        case EXIT_VALIDATION_FAILED:\n-            logger.warning(\"SCHEMA CHANGE: FAILED\");\n-            break;\n-        default:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        }\n-    }\n-\n-    /**\n-     * Log warning messages for deprecated tables.\n-     */\n-    private void logWarningMessagesForDeprecatedTables() {\n-        List<String> deprecatedTables =\n-                Arrays.asList(\"DOMAINRESOURCE_DATE_VALUES\", \"DOMAINRESOURCE_LATLNG_VALUES\", \"DOMAINRESOURCE_LOGICAL_RESOURCES\", \"DOMAINRESOURCE_NUMBER_VALUES\", \"DOMAINRESOURCE_QUANTITY_VALUES\", \"DOMAINRESOURCE_RESOURCE_TOKEN_REFS\", \"DOMAINRESOURCE_RESOURCES\", \"DOMAINRESOURCE_STR_VALUES\", \"RESOURCE_DATE_VALUES\", \"RESOURCE_LATLNG_VALUES\", \"RESOURCE_LOGICAL_RESOURCES\", \"RESOURCE_NUMBER_VALUES\", \"RESOURCE_QUANTITY_VALUES\", \"RESOURCE_RESOURCE_TOKEN_REFS\", \"RESOURCE_RESOURCES\", \"RESOURCE_STR_VALUES\");\n-        for (String deprecatedTable : deprecatedTables) {\n-            logger.warning(\"Table '\" + deprecatedTable\n-                    + \"' will be dropped in a future release. No data should be written to this table. If any data exists in the table, that data should be deleted.\");\n-        }\n-    }\n-\n-    /**\n-     * Main entry point\n-     *\n-     * @param args\n-     */\n-    public static void main(String[] args) {\n-        logClasspath(logger);\n-\n-        int exitStatus;\n-        Main m = new Main();\n-        try {\n-            configureLogger();\n-            m.parseArgs(args);\n-            m.process();\n-            exitStatus = m.getExitStatus();\n-        } catch (TableSpaceRemovalException x) {\n-            logger.warning(\"Tablespace removal is not complete, as an async dependency has not finished dettaching. Please re-try.\");\n-            exitStatus = EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE;\n-        } catch (ConcurrentUpdateException x) {\n-            logger.log(Level.WARNING, \"Update is already running. Please re-try later.\", x);\n-            exitStatus = EXIT_CONCURRENT_UPDATE;\n-        } catch (DatabaseNotReadyException x) {\n-            logger.log(Level.SEVERE, \"The database is not yet available. Please re-try.\", x);\n-            exitStatus = EXIT_NOT_READY;\n-        } catch (IllegalArgumentException x) {\n-            logger.log(Level.SEVERE, \"bad argument\", x);\n-            printUsage();\n-            exitStatus = EXIT_BAD_ARGS;\n-        } catch (Exception x) {\n-            logger.log(Level.SEVERE, \"schema tool failed\", x);\n-            exitStatus = EXIT_RUNTIME_ERROR;\n-        }\n-\n-        // Write out a final status message to make it easy to see validation success/failure\n-        m.logStatusMessage(exitStatus);\n-\n-        // almost certainly will get flagged during code-scan, but this is intentional,\n-        // as we genuinely want to exit with the correct status here. The code-scan tool\n-        // really ought to be able to see that this is a main function in a J2SE environment\n-        System.exit(exitStatus);\n-    }\n-}\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 3c4c21c031..ba15a28613 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -474,7 +580,7 @@ public class Main {\n         }\n     }\n \n-    //-----------------------------------------------------------------------------------------------------------------\n+    // -----------------------------------------------------------------------------------------------------------------\n     // The following method is related to the Privilege feature\n     /**\n      * Grant the minimum required set of privileges on the FHIR schema objects\n", "next_change": {"commit": "afceaba4a867a0af38a6cb431245b8b1854b9f74", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex ba15a28613..eff8be1420 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -580,6 +749,28 @@ public class Main {\n         }\n     }\n \n+    /**\n+     * Build a common PhysicalDataModel containing all the requested schemas\n+     * \n+     * @param pdm the model to construct\n+     * @param addFhirDataSchema include objects for the FHIR data schema\n+     * @param addOAuthSchema include objects for the Liberty OAuth schema\n+     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n+     */\n+    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n+        if (addFhirDataSchema) {\n+            buildFhirDataSchemaModel(pdm);\n+        }\n+        \n+        if (addOAuthSchema) {\n+            buildOAuthSchemaModel(pdm);\n+        }\n+        \n+        if (addJavaBatchSchema) {\n+            buildJavaBatchSchemaModel(pdm);\n+        }\n+    }\n+\n     // -----------------------------------------------------------------------------------------------------------------\n     // The following method is related to the Privilege feature\n     /**\n", "next_change": {"commit": "652c689992b6da38f3904766b4dfae672f23826a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex eff8be1420..f38f98eed9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -771,8 +804,67 @@ public class Main {\n         }\n     }\n \n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Privilege feature\n+    /**\n+     * Apply grants to the FHIR data schema objects\n+     */\n+    protected void grantPrivilegesForFhirData() {\n+\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildFhirDataSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+                \n+                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n+                // Note the constant comes from SchemaConstants on purpose\n+                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Apply grants to the OAuth schema objects\n+     */\n+    protected void grantPrivilegesForOAuth() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildOAuthSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n+                \n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+        \n+    }\n+\n+    /**\n+     * Apply grants to the JavaBatch schema objects\n+     */\n+    protected void grantPrivilegesForBatch() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildJavaBatchSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n     /**\n      * Grant the minimum required set of privileges on the FHIR schema objects\n      * to the grantTo user. All tenant data access is via this user, and is the\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\ndeleted file mode 100644\nindex f38f98eed9..0000000000\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ /dev/null\n", "chunk": "@@ -1,2526 +0,0 @@\n-/*\n- * (C) Copyright IBM Corp. 2019, 2021\n- *\n- * SPDX-License-Identifier: Apache-2.0\n- */\n-\n-package com.ibm.fhir.schema.app;\n-\n-import static com.ibm.fhir.schema.app.util.CommonUtil.configureLogger;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getDbAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getPropertyAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getRandomKey;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.loadDriver;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.logClasspath;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.printUsage;\n-\n-import java.io.FileInputStream;\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.sql.Connection;\n-import java.sql.DriverManager;\n-import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map.Entry;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.logging.Level;\n-import java.util.logging.Logger;\n-import java.util.stream.Collectors;\n-\n-import com.ibm.fhir.core.util.handler.HostnameHandler;\n-import com.ibm.fhir.database.utils.api.DataAccessException;\n-import com.ibm.fhir.database.utils.api.DatabaseNotReadyException;\n-import com.ibm.fhir.database.utils.api.IDatabaseAdapter;\n-import com.ibm.fhir.database.utils.api.IDatabaseTranslator;\n-import com.ibm.fhir.database.utils.api.ITransaction;\n-import com.ibm.fhir.database.utils.api.ITransactionProvider;\n-import com.ibm.fhir.database.utils.api.TableSpaceRemovalException;\n-import com.ibm.fhir.database.utils.api.TenantStatus;\n-import com.ibm.fhir.database.utils.api.UndefinedNameException;\n-import com.ibm.fhir.database.utils.common.DataDefinitionUtil;\n-import com.ibm.fhir.database.utils.common.JdbcConnectionProvider;\n-import com.ibm.fhir.database.utils.common.JdbcPropertyAdapter;\n-import com.ibm.fhir.database.utils.common.JdbcTarget;\n-import com.ibm.fhir.database.utils.db2.Db2Adapter;\n-import com.ibm.fhir.database.utils.db2.Db2GetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2SetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2Translator;\n-import com.ibm.fhir.database.utils.derby.DerbyTranslator;\n-import com.ibm.fhir.database.utils.model.DatabaseObjectType;\n-import com.ibm.fhir.database.utils.model.DbType;\n-import com.ibm.fhir.database.utils.model.PhysicalDataModel;\n-import com.ibm.fhir.database.utils.model.Table;\n-import com.ibm.fhir.database.utils.model.Tenant;\n-import com.ibm.fhir.database.utils.pool.PoolConnectionProvider;\n-import com.ibm.fhir.database.utils.postgres.GatherTablesDataModelVisitor;\n-import com.ibm.fhir.database.utils.postgres.PostgresAdapter;\n-import com.ibm.fhir.database.utils.postgres.PostgresTranslator;\n-import com.ibm.fhir.database.utils.postgres.PostgresVacuumSettingDAO;\n-import com.ibm.fhir.database.utils.tenant.AddTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.DeleteTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.GetTenantDAO;\n-import com.ibm.fhir.database.utils.transaction.SimpleTransactionProvider;\n-import com.ibm.fhir.database.utils.transaction.TransactionFactory;\n-import com.ibm.fhir.database.utils.version.CreateControl;\n-import com.ibm.fhir.database.utils.version.CreateWholeSchemaVersion;\n-import com.ibm.fhir.database.utils.version.SchemaConstants;\n-import com.ibm.fhir.database.utils.version.CreateVersionHistory;\n-import com.ibm.fhir.database.utils.version.VersionHistoryService;\n-import com.ibm.fhir.model.util.ModelSupport;\n-import com.ibm.fhir.schema.api.ConcurrentUpdateException;\n-import com.ibm.fhir.schema.api.ILeaseManagerConfig;\n-import com.ibm.fhir.schema.app.util.TenantKeyFileUtil;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLog;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLogDb2;\n-import com.ibm.fhir.schema.control.DisableForeignKey;\n-import com.ibm.fhir.schema.control.DropForeignKey;\n-import com.ibm.fhir.schema.control.EnableForeignKey;\n-import com.ibm.fhir.schema.control.FhirSchemaConstants;\n-import com.ibm.fhir.schema.control.FhirSchemaGenerator;\n-import com.ibm.fhir.schema.control.GetLogicalResourceNeedsV0014Migration;\n-import com.ibm.fhir.schema.control.GetResourceChangeLogEmpty;\n-import com.ibm.fhir.schema.control.GetResourceTypeList;\n-import com.ibm.fhir.schema.control.GetTenantInfo;\n-import com.ibm.fhir.schema.control.GetTenantList;\n-import com.ibm.fhir.schema.control.GetXXLogicalResourceNeedsMigration;\n-import com.ibm.fhir.schema.control.InitializeLogicalResourceDenorms;\n-import com.ibm.fhir.schema.control.JavaBatchSchemaGenerator;\n-import com.ibm.fhir.schema.control.MigrateV0014LogicalResourceIsDeletedLastUpdated;\n-import com.ibm.fhir.schema.control.OAuthSchemaGenerator;\n-import com.ibm.fhir.schema.control.PopulateParameterNames;\n-import com.ibm.fhir.schema.control.PopulateResourceTypes;\n-import com.ibm.fhir.schema.control.SetTenantIdDb2;\n-import com.ibm.fhir.schema.control.TenantInfo;\n-import com.ibm.fhir.schema.model.ResourceType;\n-import com.ibm.fhir.schema.model.Schema;\n-import com.ibm.fhir.task.api.ITaskCollector;\n-import com.ibm.fhir.task.api.ITaskGroup;\n-import com.ibm.fhir.task.core.service.TaskService;\n-\n-/**\n- * Utility app to connect to a database and create/update the IBM FHIR Server schema.\n- * The DDL processing is idempotent, with only the necessary changes applied.\n- * <br>\n- * This utility also includes an option to exercise the tenant partitioning code.\n- */\n-public class Main {\n-\n-    private static final Logger logger = Logger.getLogger(Main.class.getName());\n-    private static final int EXIT_OK = 0; // validation was successful\n-    private static final int EXIT_BAD_ARGS = 1; // invalid CLI arguments\n-    private static final int EXIT_RUNTIME_ERROR = 2; // programming error\n-    private static final int EXIT_VALIDATION_FAILED = 3; // validation test failed\n-    private static final int EXIT_NOT_READY = 4; // DATABASE NOT READY\n-    private static final int EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE = 5; // Tablespace Removal not complete\n-    private static final int EXIT_CONCURRENT_UPDATE = 6; // Another schema update is running and the wait time expired\n-    private static final double NANOS = 1e9;\n-\n-    // Indicates if the feature is enabled for the DbType\n-    public List<DbType> MULTITENANT_FEATURE_ENABLED = Arrays.asList(DbType.DB2);\n-    public List<DbType> STORED_PROCEDURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-    public List<DbType> PRIVILEGES_FEATURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-\n-    // Properties accumulated as we parse args and read configuration files\n-    private final Properties properties = new Properties();\n-\n-    // Default Values for schema names\n-    public static final String ADMIN_SCHEMANAME = \"FHIR_ADMIN\";\n-    public static final String OAUTH_SCHEMANAME = \"FHIR_OAUTH\";\n-    public static final String BATCH_SCHEMANAME = \"FHIR_JBATCH\";\n-    public static final String DATA_SCHEMANAME = \"FHIRDATA\";\n-\n-    // Force upper-case to avoid tricky-to-catch errors related to quoting names\n-    private Schema schema = new Schema();\n-\n-    // Arguments requesting we drop the objects from the schema\n-    private boolean dropAdmin = false;\n-    private boolean confirmDrop = false;\n-    private boolean updateProc = false;\n-    private boolean checkCompatibility = false;\n-\n-    // Action flags related to FHIR Schema\n-    private boolean createFhirSchema = false;\n-    private boolean updateFhirSchema = false;\n-    private boolean dropFhirSchema = false;\n-    private boolean grantFhirSchema = false;\n-\n-    // Action flags related to OAuth Schema\n-    private boolean createOauthSchema = false;\n-    private boolean updateOauthSchema = false;\n-    private boolean dropOauthSchema = false;\n-    private boolean grantOauthSchema = false;\n-\n-    // Action flags related to Java Batch Schema\n-    private boolean createJavaBatchSchema = false;\n-    private boolean updateJavaBatchSchema = false;\n-    private boolean dropJavaBatchSchema = false;\n-    private boolean grantJavaBatchSchema = false;\n-\n-    // Tenant Key\n-    private boolean skipIfTenantExists = false;\n-\n-    // The database user we will grant tenant data access privileges to\n-    private String grantTo;\n-\n-    // Action flag related to Vacuuming:\n-    private boolean updateVacuum = false;\n-    private String vacuumTableName = null;\n-    private int vacuumCostLimit = 2000;\n-    private int vacuumThreshold = 1000;\n-    private Double vacuumScaleFactor = null;\n-    \n-    // How many seconds to wait to obtain the update lease\n-    private int waitForUpdateLeaseSeconds = 10;\n-\n-    // The database type being populated (default: Db2)\n-    private DbType dbType = DbType.DB2;\n-    private IDatabaseTranslator translator = new Db2Translator();\n-\n-    // Optional subset of resource types (for faster schema builds when testing)\n-    private Set<String> resourceTypeSubset;\n-\n-    // Tenant management\n-    private boolean allocateTenant;\n-    private boolean refreshTenants;\n-    private boolean dropTenant;\n-    private boolean freezeTenant;\n-    private String tenantName;\n-    private boolean testTenant;\n-    private String tenantKey;\n-    private boolean listTenants;\n-    private boolean dropDetached;\n-    private boolean deleteTenantMeta;\n-    private boolean revokeTenantKey;\n-    private boolean revokeAllTenantKeys;\n-\n-    // Tenant Key Output or Input File\n-    private String tenantKeyFileName;\n-    private TenantKeyFileUtil tenantKeyFileUtil = new TenantKeyFileUtil();\n-\n-    // The tenant name for when we want to add a new tenant key\n-    private String addKeyForTenant;\n-\n-    // What status to leave with\n-    private int exitStatus = EXIT_OK;\n-\n-    // The connection pool and transaction provider to support concurrent operations\n-    private int maxConnectionPoolSize = FhirSchemaConstants.DEFAULT_POOL_SIZE;\n-    private PoolConnectionProvider connectionPool;\n-    private ITransactionProvider transactionProvider;\n-    \n-    // Configuration to control how the LeaseManager operates\n-    private ILeaseManagerConfig leaseManagerConfig;\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the common methods and functions\n-    /**\n-     * @return a created connection to the selected database\n-     */\n-    protected Connection createConnection() {\n-        Properties connectionProperties = new Properties();\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        adapter.getExtraProperties(connectionProperties);\n-\n-        String url = translator.getUrl(properties);\n-        logger.info(\"Opening connection to: \" + url);\n-        Connection connection;\n-        try {\n-            connection = DriverManager.getConnection(url, connectionProperties);\n-            connection.setAutoCommit(false);\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-        return connection;\n-    }\n-\n-    /**\n-     * Create a simple connection pool associated with our data source so that we\n-     * can perform the DDL deployment in parallel\n-     */\n-    protected void configureConnectionPool() {\n-        if (dbType == DbType.DERBY && maxConnectionPoolSize > 1) {\n-            logger.warning(\"Embedded Derby does not support concurrent schema updates;\" +\n-                    \" ignoring '--pool-size' and using a single thread.\");\n-            this.maxConnectionPoolSize = 1;\n-        }\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        JdbcConnectionProvider cp = new JdbcConnectionProvider(this.translator, adapter);\n-        this.connectionPool = new PoolConnectionProvider(cp, this.maxConnectionPoolSize);\n-        this.transactionProvider = new SimpleTransactionProvider(this.connectionPool);\n-    }\n-\n-    /**\n-     * Add the admin schema objects to the {@link PhysicalDataModel}\n-     *\n-     * @param pdm the data model to build\n-     */\n-    protected void buildAdminSchemaModel(PhysicalDataModel pdm) {\n-        // Add the tenant and tenant_keys tables and any other admin schema stuff\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        gen.buildAdminSchema(pdm);\n-    }\n-    \n-    /**\n-     * Add the OAuth schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm the model to build\n-     */\n-    protected void buildOAuthSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty OAuth-related tables\n-        OAuthSchemaGenerator oauthSchemaGenerator = new OAuthSchemaGenerator(schema.getOauthSchemaName());\n-        oauthSchemaGenerator.buildOAuthSchema(pdm);\n-    }\n-\n-    /**\n-     * Add the JavaBatch schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm\n-     */\n-    protected void buildJavaBatchSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty JBatch related tables\n-        JavaBatchSchemaGenerator javaBatchSchemaGenerator = new JavaBatchSchemaGenerator(schema.getJavaBatchSchemaName());\n-        javaBatchSchemaGenerator.buildJavaBatchSchema(pdm);\n-    }\n-\n-    /**\n-     * Start the schema object creation tasks and wait for everything to complete\n-     *\n-     * @param pdm\n-     * @param adapter\n-     * @param collector\n-     * @param vhs\n-     */\n-    protected void applyModel(PhysicalDataModel pdm, IDatabaseAdapter adapter, ITaskCollector collector, VersionHistoryService vhs) {\n-        logger.info(\"Collecting model update tasks\");\n-        pdm.collect(collector, adapter, this.transactionProvider, vhs);\n-\n-        // FHIR in the hole!\n-        logger.info(\"Starting model updates\");\n-        collector.startAndWait();\n-\n-        Collection<ITaskGroup> failedTaskGroups = collector.getFailedTaskGroups();\n-        if (failedTaskGroups.size() > 0) {\n-            this.exitStatus = EXIT_RUNTIME_ERROR;\n-\n-            final String failedStr =\n-                    failedTaskGroups.stream().map((tg) -> tg.getTaskId()).collect(Collectors.joining(\",\"));\n-            logger.severe(\"List of failed task groups: \" + failedStr);\n-        }\n-    }\n-\n-    /**\n-     * specific feature to check if it is compatible.\n-     *\n-     * @return\n-     */\n-    protected boolean checkCompatibility() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            return adapter.checkCompatibility(schema.getAdminSchemaName());\n-        }\n-    }\n-\n-    /**\n-     * Create the schemas\n-     */\n-    protected void createSchemas() {\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    // We always create the 'admin' schema to track to the changes to any of the other schemas.\n-                    adapter.createSchema(schema.getAdminSchemaName());\n-\n-                    // FHIR Data Schema\n-                    if (createFhirSchema) {\n-                        adapter.createSchema(schema.getSchemaName());\n-                        c.commit();\n-                    }\n-\n-                    // OAuth Schema\n-                    if (createOauthSchema) {\n-                        adapter.createSchema(schema.getOauthSchemaName());\n-                    }\n-\n-                    // Java Batch Schema\n-                    if (createJavaBatchSchema) {\n-                        adapter.createSchema(schema.getJavaBatchSchemaName());\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-    \n-    /**\n-     * Process the schemas configured to be updated\n-     */\n-    protected void updateSchemas() {\n-        \n-        // Make sure that we have the CONTROL table created before we try any\n-        // schema update work\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateControl.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        if (updateFhirSchema) {\n-            updateFhirSchema();\n-        }\n-        \n-        if (updateOauthSchema) {\n-            updateOauthSchema();\n-        }\n-        \n-        if (updateJavaBatchSchema) {\n-            updateJavaBatchSchema();\n-        }\n-    }\n-    \n-    /**\n-     * Add FHIR data schema objects to the given {@link PhysicalDataModel}\n-     * @param pdm the data model being built\n-     */\n-    protected void buildFhirDataSchemaModel(PhysicalDataModel pdm) {\n-        FhirSchemaGenerator gen;\n-        if (resourceTypeSubset == null || resourceTypeSubset.isEmpty()) {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        } else {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant(), resourceTypeSubset);\n-        }\n-\n-        gen.buildSchema(pdm);\n-        switch (dbType) {\n-        case DB2:\n-            gen.buildDatabaseSpecificArtifactsDb2(pdm);\n-            break;\n-        case DERBY:\n-            logger.info(\"No database specific artifacts\");\n-            break;\n-        case POSTGRESQL:\n-            gen.buildDatabaseSpecificArtifactsPostgres(pdm);\n-            break;\n-        default:\n-            throw new IllegalStateException(\"Unsupported db type: \" + dbType);\n-        }\n-    }\n-    \n-    /**\n-     * Update the FHIR data schema\n-     */\n-    protected void updateFhirSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for FHIR data schema: '\" + schema.getSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                // Build/update the FHIR-related tables as well as the stored procedures\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                boolean isNewDb = updateSchema(pdm);\n-                \n-                // If the db is multi-tenant, we populate the resource types and parameter names in allocate-tenant.\n-                // Otherwise, if its a new schema, populate the resource types and parameters names (codes) now\n-                if (!MULTITENANT_FEATURE_ENABLED.contains(dbType) && isNewDb) {\n-                    populateResourceTypeAndParameterNameTableEntries(null);\n-                }\n-        \n-                if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-                    logger.info(\"Refreshing tenant partitions\");\n-                    refreshTenants();\n-                }\n-        \n-                // backfill the resource_change_log table if needed\n-                backfillResourceChangeLog();\n-        \n-                // perform any updates we need related to the V0010 schema change (IS_DELETED flag)\n-                applyDataMigrationForV0010();\n-        \n-                // V0014 IS_DELETED and LAST_UPDATED added to whole-system LOGICAL_RESOURCES\n-                applyDataMigrationForV0014();\n-        \n-                // Log warning messages that unused tables will be removed in a future release.\n-                // TODO: This will no longer be needed after the tables are removed (https://github.com/IBM/FHIR/issues/713).\n-                logWarningMessagesForDeprecatedTables();\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForFhirData();\n-                }\n-                \n-                // Finally, update the whole schema version\n-                svm.updateSchemaVersion();\n-                \n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the OAuth schema changes\n-     */\n-    protected void updateOauthSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getOauthSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty OAuth schema: '\" + schema.getOauthSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getOauthSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForOAuth();\n-                }\n-                \n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the JavaBatch schema changes\n-     */\n-    protected void updateJavaBatchSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getJavaBatchSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty JavaBatch schema: '\" + schema.getJavaBatchSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getJavaBatchSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-\n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForBatch();\n-                }\n-\n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-    \n-    /**\n-     * Update the schema associated with the given {@link PhysicalDataModel}\n-     * @return true if the database is new\n-     */\n-    protected boolean updateSchema(PhysicalDataModel pdm) {\n-\n-        // The objects are applied in parallel, which relies on each object\n-        // expressing its dependencies correctly. Changes are only applied\n-        // if their version is greater than the current version.\n-        TaskService taskService = new TaskService();\n-        ExecutorService pool = Executors.newFixedThreadPool(this.maxConnectionPoolSize);\n-        ITaskCollector collector = taskService.makeTaskCollector(pool);\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-\n-        // Before we start anything, we need to make sure our schema history\n-        // and control tables are in place. These tables are used to manage \n-        // all FHIR data, oauth and JavaBatch schemas we build\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateVersionHistory.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        // Current version history for the data schema\n-        VersionHistoryService vhs =\n-                new VersionHistoryService(schema.getAdminSchemaName(), schema.getSchemaName(), schema.getOauthSchemaName(), schema.getJavaBatchSchemaName());\n-        vhs.setTransactionProvider(transactionProvider);\n-        vhs.setTarget(adapter);\n-        vhs.init();\n-\n-        // Use the version history service to determine if this table existed before we run `applyWithHistory`\n-        boolean isNewDb = vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == null ||\n-                vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == 0;\n-\n-        applyModel(pdm, adapter, collector, vhs);\n-        // The physical database objects should now match what was defined in the PhysicalDataModel\n-        \n-        return isNewDb;\n-    }\n-\n-    /**\n-     * populates for the given tenantId the RESOURCE_TYPE table.\n-     *\n-     * @implNote if you update this method, be sure to update\n-     *           DerbyBootstrapper.populateResourceTypeAndParameterNameTableEntries\n-     *           and DerbyFhirDatabase.populateResourceTypeAndParameterNameTableEntries\n-     *           The reason is there are three different ways of managing the transaction.\n-     * @param tenantId\n-     *            the mt_id that is used to setup the partition.\n-     *            passing in null signals not multi-tenant.\n-     */\n-    protected void populateResourceTypeAndParameterNameTableEntries(Integer tenantId) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                String logTenantId = tenantId != null ? Integer.toString(tenantId) : \"default\";\n-                logger.info(\"tenantId [\" + logTenantId + \"] is being pre-populated with lookup table data.\");\n-                PopulateResourceTypes populateResourceTypes =\n-                        new PopulateResourceTypes(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateResourceTypes.run(translator, c);\n-\n-                PopulateParameterNames populateParameterNames =\n-                        new PopulateParameterNames(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateParameterNames.run(translator, c);\n-                logger.info(\"Finished prepopulating the resource type and search parameter code/name tables tables\");\n-            } catch (SQLException ex) {\n-                tx.setRollbackOnly();\n-                throw new DataAccessException(ex);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Drop all the objects in the admin and data schemas.\n-     * Typically used during development.\n-     */\n-    protected void dropSchema() {\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, dropFhirSchema, dropOauthSchema, dropJavaBatchSchema);\n-\n-        // Dropping the schema in PostgreSQL can fail with an out of shared memory error\n-        // which is apparently related to max_locks_per_transaction. It may not be possible\n-        // to increase this value (e.g. in cloud databases) and so to work around this, before\n-        // dropping the schema objects, we knock out all the FOREIGN KEY constraints first.\n-        if (dropFhirSchema) {\n-            logger.info(\"Dropping FK constraints in the data schema: \" + this.schema.getSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-        }\n-\n-        if (dropOauthSchema) {\n-            logger.info(\"Dropping FK constraints in the OAuth schema: \" + this.schema.getOauthSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-        }\n-\n-        if (dropJavaBatchSchema) {\n-            logger.info(\"Dropping FK constraints in the Batch schema: \" + this.schema.getJavaBatchSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-        }\n-\n-        if (dropAdmin) {\n-            // Also drop the FK constraints within the administration schema\n-            logger.info(\"Dropping FK constraints in the admin schema: \" + this.schema.getAdminSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-        }\n-\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    if (dropFhirSchema || dropOauthSchema || dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the FHIRDATA schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-                    }\n-\n-                    if (dropOauthSchema) {\n-                        // Just drop the objects associated with the OAUTH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-                    }\n-\n-                    if (dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the BATCH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-                    }\n-\n-                    if (dropAdmin) {\n-                        // Just drop the objects associated with the ADMIN schema group\n-                        CreateVersionHistory.generateTable(pdm, ADMIN_SCHEMANAME, true);\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    /**\n-     * Add part of the schema drop process, we first kill all\n-     * the foreign key constraints. The rest of the drop is\n-     * performed in a second transaction.\n-     *\n-     * @param pdm\n-     */\n-    private void dropForeignKeyConstraints(PhysicalDataModel pdm, String tagGroup, String tag) {\n-        try (Connection c = createConnection()) {\n-            try {\n-                JdbcTarget target = new JdbcTarget(c);\n-                IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                Set<Table> referencedTables = new HashSet<>();\n-                DropForeignKey dropper = new DropForeignKey(adapter, referencedTables);\n-                pdm.visit(dropper, tagGroup, tag);\n-            } catch (Exception x) {\n-                c.rollback();\n-                throw x;\n-            }\n-            c.commit();\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Stored Procedures and Functions feature\n-    /**\n-     * Update the stored procedures used by FHIR to insert records\n-     * into the FHIR resource tables\n-     */\n-    protected void updateProcedures() {\n-        if (!STORED_PROCEDURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        // Since this is a stored procedure, we need the model.\n-        // We must pass in true to flag to the underlying layer that the\n-        // Procedures need to be generated.\n-        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n-\n-        // Now only apply the procedures in the model. Much faster than\n-        // going through the whole schema\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                try {\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-                    pdm.applyProcedures(adapter);\n-                    pdm.applyFunctions(adapter);\n-                    \n-                    // Because we're replacing the procedures, we should also check if\n-                    // we need to apply the associated privileges\n-                    if (this.grantTo != null) {\n-                        pdm.applyProcedureAndFunctionGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the\n-                // transaction commit.\n-            } catch (SQLException x) {\n-                tx.setRollbackOnly();\n-                throw translator.translate(x);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Build a common PhysicalDataModel containing all the requested schemas\n-     * \n-     * @param pdm the model to construct\n-     * @param addFhirDataSchema include objects for the FHIR data schema\n-     * @param addOAuthSchema include objects for the Liberty OAuth schema\n-     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n-     */\n-    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n-        if (addFhirDataSchema) {\n-            buildFhirDataSchemaModel(pdm);\n-        }\n-        \n-        if (addOAuthSchema) {\n-            buildOAuthSchemaModel(pdm);\n-        }\n-        \n-        if (addJavaBatchSchema) {\n-            buildJavaBatchSchemaModel(pdm);\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the FHIR data schema objects\n-     */\n-    protected void grantPrivilegesForFhirData() {\n-\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                \n-                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n-                // Note the constant comes from SchemaConstants on purpose\n-                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the OAuth schema objects\n-     */\n-    protected void grantPrivilegesForOAuth() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n-                \n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        \n-    }\n-\n-    /**\n-     * Apply grants to the JavaBatch schema objects\n-     */\n-    protected void grantPrivilegesForBatch() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Grant the minimum required set of privileges on the FHIR schema objects\n-     * to the grantTo user. All tenant data access is via this user, and is the\n-     * only user the FHIR server itself is configured with.\n-     */\n-    protected void grantPrivileges() {\n-        if (!PRIVILEGES_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // The case where all are to be granted on the default schemas.\n-        if (!(updateFhirSchema || grantFhirSchema || updateOauthSchema\n-                || grantOauthSchema || updateJavaBatchSchema || grantJavaBatchSchema)) {\n-            grantOauthSchema = true;\n-            grantFhirSchema = true;\n-            grantJavaBatchSchema = true;\n-        }\n-        \n-        if (grantFhirSchema) {\n-            grantPrivilegesForFhirData();\n-        }\n-        \n-        if (grantOauthSchema) {\n-            grantPrivilegesForOAuth();\n-        }\n-        \n-        if (grantJavaBatchSchema) {\n-            grantPrivilegesForBatch();\n-        }\n-    }\n-\n-    /**\n-     * Do we want to build the multitenant variant of the schema (currently only supported\n-     * by DB2)\n-     *\n-     * @return\n-     */\n-    protected boolean isMultitenant() {\n-        return MULTITENANT_FEATURE_ENABLED.contains(this.dbType);\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to Multi-Tenant only.\n-    /**\n-     * Add a new tenant key so that we can rotate the values (add a\n-     * new key, update config files, then remove the old key). This\n-     * avoids any service interruption.\n-     */\n-    protected void addTenantKey() {\n-        if (!isMultitenant()) {\n-            return;\n-        }\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, false);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantDAO tid = new GetTenantDAO(schema.getAdminSchemaName(), addKeyForTenant);\n-                Tenant tenant = adapter.runStatement(tid);\n-\n-                if (tenant != null) {\n-                    // Attach the new tenant key to the tenant:\n-                    AddTenantKeyDAO adder =\n-                            new AddTenantKeyDAO(schema.getAdminSchemaName(), tenant.getTenantId(), tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-                    adapter.runStatement(adder);\n-                } else {\n-                    throw new IllegalArgumentException(\"Tenant does not exist: \" + addKeyForTenant);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            // Generated\n-            logger.info(\"New tenant key: \" + addKeyForTenant + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            // Loaded from File\n-            logger.info(\"New tenant key from file: \" + addKeyForTenant + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * checks if tenant name and tenant key exists.\n-     *\n-     * @param adapter\n-     *            the db2 adapter as this is a db2 feature only now\n-     * @param tenantName\n-     *            the tenant's name\n-     * @param tenantKey\n-     *            tenant key\n-     * @param skip\n-     *            whether or not to skip over cases where this tenantName/tenantKey combination already exists\n-     *\n-     * @throws IllegalArgumentException if the tenantName/tenantKey combination already exists and the {@code skip} argument is false\n-     *\n-     * @return indicates if the tenantName/tenantKey exists\n-     */\n-    protected boolean checkIfTenantNameAndTenantKeyExists(Db2Adapter adapter, String tenantName, String tenantKey, boolean skip) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                final String sql =\n-                        \"SELECT t.tenant_status FROM fhir_admin.tenants t WHERE t.tenant_name = ? \"\n-                                + \"AND EXISTS (SELECT 1 FROM fhir_admin.tenant_keys tk WHERE tk.mt_id = t.mt_id \"\n-                                + \"AND tk.tenant_hash = sysibm.hash(tk.tenant_salt || ?, 2))\";\n-                try (PreparedStatement stmt = connectionPool.getConnection().prepareStatement(sql)) {\n-                    stmt.setString(1, tenantName);\n-                    stmt.setString(2, tenantKey);\n-                    if (stmt.execute()) {\n-                        try (ResultSet resultSet = stmt.getResultSet();) {\n-                            if (resultSet.next()) {\n-                                if (skip) {\n-                                    return true;\n-                                } else {\n-                                    throw new IllegalArgumentException(\"tenantName and tenantKey already exists\");\n-                                }\n-                            }\n-                        }\n-                    } else {\n-                        throw new IllegalArgumentException(\"Problem checking the results\");\n-                    }\n-                } catch (SQLException e) {\n-                    throw new IllegalArgumentException(\"Exception when querying backend to verify tenant key and tenant name\", e);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return false;\n-    }\n-\n-    /**\n-     * Allocate this tenant, creating new partitions if required.\n-     */\n-    protected void allocateTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // IMPORTANT! Check the schema name aligns with the actual schema for this tenant\n-        checkSchemaForTenant();\n-\n-        // The key we'll use for this tenant. This key should be used in subsequent\n-        // activities related to this tenant, such as setting the tenant context.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        // Conditionally skip if the tenant name and key exist (this enables idempotency)\n-        boolean skip = checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, skipIfTenantExists);\n-        if (skip) {\n-            return;\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-        }\n-\n-        // Open a new transaction and associate it with our connection pool. Remember\n-        // that we don't support distributed transactions, so all connections within\n-        // this transaction must come from the same pool\n-        int tenantId;\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                tenantId =\n-                        adapter.allocateTenant(schema.getAdminSchemaName(), schema.getSchemaName(), tenantName, tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-\n-                // The tenant-id is important because this is also used to identify the partition number\n-                logger.info(\"Tenant Id[\" + tenantName + \"] = [\" + tenantId + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Get the data model to create the table partitions. This is threaded, so transactions are\n-        // handled within each thread by the adapter. This means we should probably pull some of\n-        // that logic out of the adapter and handle it at a higher level. Note...the extent size used\n-        // for the partitions needs to match the extent size of the original table tablespace (FHIR_TS)\n-        // so this must be constant.\n-        pdm.addTenantPartitions(adapter, schema.getSchemaName(), tenantId, FhirSchemaConstants.FHIR_TS_EXTENT_KB);\n-\n-        // Fill any static data tables (which are also partitioned by tenant)\n-        // Prepopulate the Resource Type Tables and Parameters Name/Code Table\n-        populateResourceTypeAndParameterNameTableEntries(tenantId);\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as ready\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantId, TenantStatus.ALLOCATED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [key=\" + tenantKey + \"] with Id = \" + tenantId);\n-            logger.info(\"The tenantKey JSON follows: \\t\\n{\\\"tenantKey\\\": \\\"\" + tenantKey + \"\\\"}\");\n-        } else {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"] with Id = \"\n-                    + tenantId);\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Run a check to make sure that if the tenant already exists its schema\n-     * matches the specified schema. This prevents users from accidentally\n-     * creating a second instance of a tenant in a different schema\n-     */\n-    protected void checkSchemaForTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // only relevant for databases which support multiple tenants within one schema (like Db2)\n-            return;\n-        }\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // Scan over the list to see if the tenant we are working with\n-        // already exists\n-        for (TenantInfo ti : tenants) {\n-            if (ti.getTenantName().equals(this.tenantName)) {\n-                if (ti.getTenantSchema() == null) {\n-                    // The schema is empty so no chance of adding tenants\n-                    throw new IllegalArgumentException(\"Schema '\" + schema.getSchemaName() + \"'\"\n-                            + \" for tenant '\" + ti.getTenantName() + \"'\"\n-                            + \" does not contain a valid IBM FHIR Server schema\");\n-                } else if (!ti.getTenantSchema().equalsIgnoreCase(schema.getSchemaName())) {\n-                    // The given schema name doesn't match where we think this tenant\n-                    // should be located, so throw an error before any damage is done\n-                    throw new IllegalArgumentException(\"--schema-name argument '\" + schema.getSchemaName()\n-                            + \"' does not match schema '\" + ti.getTenantSchema() + \"' for tenant '\"\n-                            + ti.getTenantName() + \"'\");\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Get the list of tenants and the schemas each is currently defined in. Because\n-     * this tenant-schema mapping isn't stored directly, it has to be inferred by\n-     * looking up the schema from one of the tables we know should exist. The schema\n-     * name may therefore be null if the tenant record (in FHIR_ADMIN.TENANTS) exists,\n-     * but all the tables from that schema have been dropped.\n-     *\n-     * @return\n-     */\n-    protected List<TenantInfo> getTenantList() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return Collections.emptyList();\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants;\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                tenants = adapter.runStatement(rtListGetter);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        return tenants;\n-    }\n-\n-    /**\n-     * Make sure all the tables has a partition created for the configured tenant\n-     */\n-    protected void refreshTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // make sure the list is sorted by tenantId. Lambdas really do clean up this sort of code\n-        tenants.sort((TenantInfo left, TenantInfo right) -> left.getTenantId() < right.getTenantId() ? -1 : left.getTenantId() > right.getTenantId() ? 1 : 0);\n-        for (TenantInfo ti : tenants) {\n-            // For issue 1847 we only want to process for the named data schema if one is provided\n-            // If no -schema-name arg is given, we process all tenants.\n-            if (ti.getTenantSchema() != null && (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema()))) {\n-                // It's crucial we use the correct schema for each particular tenant, which\n-                // is why we have to build the PhysicalDataModel separately for each tenant\n-                FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), ti.getTenantSchema(), isMultitenant());\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                gen.buildSchema(pdm);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                pdm.addNewTenantPartitions(adapter, ti.getTenantSchema(), ti.getTenantId());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * List the tenants currently configured\n-     */\n-    protected void listTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                List<TenantInfo> tenants = adapter.runStatement(rtListGetter);\n-\n-                System.out.println(TenantInfo.getHeader());\n-                tenants.forEach(System.out::println);\n-            } catch (UndefinedNameException x) {\n-                System.out.println(\"The FHIR_ADMIN schema appears not to be deployed with the TENANTS table\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Check that we can call the set_tenant procedure successfully (which means\n-     * that the\n-     * tenant record exists in the tenants table)\n-     */\n-    protected void testTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        if (this.tenantName == null || this.tenantName.isEmpty()) {\n-            throw new IllegalStateException(\"Missing tenant name\");\n-        }\n-\n-        // Part of Bring your own Tenant Key\n-        if (tenantKeyFileName != null) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        if (this.tenantKey == null || this.tenantKey.isEmpty()) {\n-            throw new IllegalArgumentException(\"No tenant-key value provided\");\n-        }\n-\n-        logger.info(\"Testing tenant: [\" + tenantName + \"]\");\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // The tenants table, variable and set_tenant procedure are all located in\n-                // the admin schema. The data access user only has execute privileges on the\n-                // set_tenant procedure and read access to the variable. The variable can\n-                // only be set by calling the stored procedure\n-                Db2SetTenantVariable cmd = new Db2SetTenantVariable(schema.getAdminSchemaName(), tenantName, tenantKey);\n-                adapter.runStatement(cmd);\n-\n-                Db2GetTenantVariable getter = new Db2GetTenantVariable(schema.getAdminSchemaName());\n-                Integer tid = adapter.runStatement(getter);\n-                if (tid == null) {\n-                    throw new IllegalStateException(\"SV_TENANT_ID not set!\");\n-                }\n-\n-                // Print the id from the session variable (used for access control)\n-                logger.info(\"tenantName='\" + tenantName + \"', tenantId=\" + tid);\n-\n-                // Now let's check we can run a select against one our tenant-based\n-                // tables\n-                GetResourceTypeList rtListGetter = new GetResourceTypeList(schema.getSchemaName());\n-                List<ResourceType> rtList = adapter.runStatement(rtListGetter);\n-                rtList.forEach(rt -> logger.info(\"ResourceType: \" + rt.toString()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    protected TenantInfo getTenantInfo() {\n-        TenantInfo result;\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                GetTenantInfo command = new GetTenantInfo(schema.getAdminSchemaName(), tenantName);\n-                result = adapter.runStatement(command);\n-\n-                if (result == null) {\n-                    logger.info(\"Use --list-tenants to display the current tenants\");\n-                    throw new IllegalArgumentException(\"Tenant '\" + tenantName + \"' not found in admin schema \" + schema.getAdminSchemaName());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // make sure we set the schema name correctly if it couldn't be found in the database\n-        // (which happens after all the partitions for a particular tenant are detached)\n-        String tenantSchema = result.getTenantSchema();\n-        if (tenantSchema == null || tenantSchema.isEmpty()) {\n-            // the schema can no longer be derived from the database, so we\n-            // need it to be provided on the command line.\n-            if (schema.getSchemaName() == null || schema.getSchemaName().isEmpty()) {\n-                throw new IllegalArgumentException(\"Must provide the tenant schema with --schema-name\");\n-            }\n-            result.setTenantSchema(schema.getSchemaName());\n-        } else {\n-            // if a schema name was provided on the command line, let's double-check it matches\n-            // the schema used for this tenant in the database\n-            if (!tenantSchema.equalsIgnoreCase(schema.getSchemaName())) {\n-                throw new IllegalArgumentException(\"--schema-name '\" + schema.getSchemaName() + \"' argument does not match tenant schema: '\"\n-                        + tenantSchema + \"'\");\n-            }\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Mark the tenant so that it can no longer be accessed (this prevents\n-     * the SET_TENANT method from authenticating the tenantName/tenantKey\n-     * pair, so the SV_TENANT_ID variable never gets set).\n-     *\n-     * @return the TenantInfo associated with the tenant\n-     */\n-    protected TenantInfo freezeTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        TenantInfo result = getTenantInfo();\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        logger.info(\"Marking tenant for drop: \" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                // Mark the tenant as frozen before we proceed with dropping anything\n-                if (result.getTenantStatus() == TenantStatus.ALLOCATED) {\n-                    adapter.updateTenantStatus(schema.getAdminSchemaName(), result.getTenantId(), TenantStatus.FROZEN);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return result;\n-    }\n-\n-    /**\n-     * Deallocate this tenant, dropping all the related partitions. This needs to be\n-     * idempotent because there are steps which must be run in separate transactions\n-     * (due to how Db2 handles detaching partitions). This is further complicated by\n-     * referential integrity constraints in the schema. See:\n-     * - https://www.ibm.com/support/knowledgecenter/SSEPGG_11.5.0/com.ibm.db2.luw.admin.partition.doc/doc/t0021576.html\n-     *\n-     * The workaround described in the above link is:\n-     * // Change the RI constraint to informational:\n-     * 1. ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     *\n-     * 2. ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     *\n-     * 3. SET INTEGRITY FOR child OFF;\n-     *\n-     * // Change the RI constraint back to enforced:\n-     * 4. ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     *\n-     * 5. SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     * 6. Assuming that the CHILD table does not have any dependencies on partition P0,\n-     * 7. and that no updates on the CHILD table are permitted until this UOW is complete,\n-     * no RI violation is possible during this UOW.\n-     *\n-     * COMMIT WORK;\n-     *\n-     * Unfortunately, #7 above essentially requires that all writes cease until the\n-     * UOW is completed and the integrity is enabled again on all the child (leaf)\n-     * tables. Of course, this could be relaxed if the application is trusted not\n-     * to mess up the referential integrity...which we know to be true for the\n-     * FHIR server persistence layer.\n-     *\n-     * If the risk is deemed too high, tenant removal should be performed in a\n-     * maintenance window.\n-     */\n-    protected void dropTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Mark the tenant as being dropped. This should prevent it from\n-        // being used in any way because the SET_TENANT stored procedure\n-        // will reject any request for the tenant being dropped.\n-        TenantInfo tenantInfo = freezeTenant();\n-\n-        // Build the model of the data (FHIRDATA) schema which is then used to drive the drop\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Detach the tenant partition from each of the data tables\n-        detachTenantPartitions(pdm, tenantInfo);\n-\n-        // this may not complete successfully because Db2 runs the detach as an async\n-        // process. Just need to run --drop-detached to clean up.\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. The detach process is asynchronous,\n-     * so this is a sort of garbage collection, sweeping up cruft left in the database.\n-     */\n-    protected void dropDetachedPartitionTables() {\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. Once all tables have been\n-     * dropped, we go on to drop the tablespace. If the tablespace drop is successful,\n-     * we know the cleanup is complete so we can update the tenant status accordingly\n-     *\n-     * @param pdm\n-     * @param tenantInfo\n-     */\n-    protected void dropDetachedPartitionTables(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        // In a new transaction, drop any of the tables that were created by\n-        // the partition detach operation.\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                pdm.dropDetachedPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // We can drop the tenant's tablespace only after all the table drops have been committed\n-        logger.info(\"Dropping tablespace for tenant \" + tenantInfo.getTenantId() + \"/\" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            boolean retry = true;\n-            int wait = 0;\n-            while (retry) {\n-                try {\n-                    retry = false;\n-                    // With all the objects removed, it should be safe to remove the tablespace\n-                    pdm.dropTenantTablespace(adapter, tenantInfo.getTenantId());\n-                } catch (DataAccessException x) {\n-                    boolean error = x instanceof DataAccessException && x.getCause() instanceof SQLException\n-                            && (((SQLException) x.getCause()).getErrorCode() == -282);\n-                    if (error && wait++ <= 30) {\n-                        retry = true;\n-                        logger.warning(\"Waiting on async dettach dependency to finish - count '\" + wait + \"'\");\n-                        try {\n-                            Thread.sleep(2000);\n-                        } catch (InterruptedException e) {\n-                            throw new DataAccessException(e);\n-                        }\n-                    } else if (error) {\n-                        throw new TableSpaceRemovalException(x.getCause());\n-                    } else {\n-                        // Something went wrong, so mark the transaction as failed\n-                        tx.setRollbackOnly();\n-                        throw x;\n-                    }\n-                }\n-            }\n-        }\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as dropped\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantInfo.getTenantId(), TenantStatus.DROPPED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Temporarily suspend RI so that tables which are the subject of foreign\n-     * key relationships can have their partitions dropped. A bit frustrating\n-     * to have to go through this, because the child table partition will be\n-     * detached before the parent anyway, so theoretically this workaround\n-     * shouldn't be necessary.\n-     * ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     * ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     * SET INTEGRITY FOR child OFF;\n-     * ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     * SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     */\n-    protected void detachTenantPartitions(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // collect the set of all child tables with FK relationships to\n-                // partitioned tables\n-                Set<Table> childTables = new HashSet<>();\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-                pdm.visit(new DisableForeignKey(adapter, childTables));\n-\n-                // ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-                pdm.detachTenantPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-\n-                // SET INTEGRITY FOR child OFF;\n-                childTables.forEach(t -> adapter.setIntegrityOff(t.getSchemaName(), t.getObjectName()));\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-                pdm.visit(new EnableForeignKey(adapter));\n-\n-                // SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-                childTables.forEach(t -> adapter.setIntegrityUnchecked(t.getSchemaName(), t.getObjectName()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * Delete all the metadata associated with the named tenant.\n-     */\n-    protected void deleteTenantMeta() {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        TenantInfo tenantInfo = getTenantInfo();\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                if (tenantInfo.getTenantStatus() == TenantStatus.DROPPED) {\n-                    adapter.deleteTenantMeta(schema.getAdminSchemaName(), tenantInfo.getTenantId());\n-                } else {\n-                    throw new IllegalStateException(\"Cannot delete tenant meta data until status is \" + TenantStatus.DROPPED.name());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * revokes a tenant key or if no tenant key is specified remove all of them for the\n-     * given tenant.\n-     */\n-    protected void revokeTenantKey() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        int tenantId = tenantInfo.getTenantId();\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                DeleteTenantKeyDAO dtk = new DeleteTenantKeyDAO(schema.getAdminSchemaName(), tenantId, tenantKey);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                adapter.runStatement(dtk);\n-                int count = dtk.getCount();\n-                logger.info(\"Tenant Key revoked for '\" + tenantInfo.getTenantName() + \"' total removed=[\" + count + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to parsing arguments and action selection\n-    /**\n-     * Parse the command-line arguments, building up the environment and\n-     * establishing\n-     * the run-list\n-     *\n-     * @param args\n-     */\n-    protected void parseArgs(String[] args) {\n-        // Arguments are pretty simple, so we go with a basic switch instead of having\n-        // yet another dependency (e.g. commons-cli).\n-        LeaseManagerConfig.Builder lmConfig = LeaseManagerConfig.builder();\n-        lmConfig.withHost(new HostnameHandler().getHostname());\n-        lmConfig.withLeaseTimeSeconds(100); // default\n-        lmConfig.withStayAlive(true);       // default\n-        \n-        for (int i = 0; i < args.length; i++) {\n-            int nextIdx = (i + 1);\n-            String arg = args[i];\n-            switch (arg) {\n-            case \"--prop-file\":\n-                if (++i < args.length) {\n-                    loadPropertyFile(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--schema-name\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    schema.setSchemaName(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--grant-to\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-\n-                    // Force upper-case because user names are case-insensitive\n-                    this.grantTo = args[i].toUpperCase();\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--target\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    List<String> targets = Arrays.asList(args[i].split(\",\"));\n-                    for (String target : targets) {\n-                        String tmp = target.toUpperCase();\n-                        nextIdx++;\n-                        if (tmp.startsWith(\"BATCH\")) {\n-                            this.grantJavaBatchSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setJavaBatchSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"OAUTH\")) {\n-                            this.grantOauthSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setOauthSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"DATA\")) {\n-                            this.grantFhirSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else {\n-                            throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                        }\n-                    }\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--add-tenant-key\":\n-                if (++i < args.length) {\n-                    this.addKeyForTenant = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--revoke-tenant-key\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeTenantKey = true;\n-                break;\n-            case \"--revoke-all-tenant-keys\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeAllTenantKeys = true;\n-                break;\n-            case \"--update-proc\":\n-                this.updateProc = true;\n-                break;\n-            case \"--check-compatibility\":\n-                this.checkCompatibility = true;\n-                break;\n-            case \"--drop-admin\":\n-                this.dropAdmin = true;\n-                break;\n-            case \"--test-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.testTenant = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key\":\n-                if (++i < args.length) {\n-                    this.tenantKey = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key-file\":\n-                if (++i < args.length) {\n-                    tenantKeyFileName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--list-tenants\":\n-                this.listTenants = true;\n-                break;\n-            case \"--update-schema\":\n-                this.updateFhirSchema = true;\n-                this.updateOauthSchema = true;\n-                this.updateJavaBatchSchema = true;\n-                break;\n-            case \"--update-schema-fhir\":\n-                this.updateFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                } else {\n-                    schema.setSchemaName(DATA_SCHEMANAME);\n-                }\n-                break;\n-            case \"--update-schema-batch\":\n-                this.updateJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--update-schema-oauth\":\n-                this.updateOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schemas\":\n-                this.createFhirSchema = true;\n-                this.createOauthSchema = true;\n-                this.createJavaBatchSchema = true;\n-                break;\n-            case \"--create-schema-fhir\":\n-                this.createFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-batch\":\n-                this.createJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-oauth\":\n-                this.createOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema\":\n-                System.err.print(\"Option '--drop-schema' has been retired.  Please use '--drop-schema-fhir', \"\n-                        + \"'--drop-schema-batch', and/or '--drop-schema-oauth'.\");\n-                break;\n-            case \"--drop-schema-fhir\":\n-                this.dropFhirSchema = Boolean.TRUE;\n-                break;\n-            case \"--drop-schema-batch\":\n-                this.dropJavaBatchSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema-oauth\":\n-                this.dropOauthSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--pool-size\":\n-                if (++i < args.length) {\n-                    this.maxConnectionPoolSize = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--prop\":\n-                if (++i < args.length) {\n-                    // properties are given as name=value\n-                    addProperty(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--update-vacuum\":\n-                updateVacuum = true;\n-                break;\n-            case \"--vacuum-cost-limit\":\n-                if (++i < args.length) {\n-                    this.vacuumCostLimit = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-threshold\":\n-                if (++i < args.length) {\n-                    this.vacuumThreshold = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-scale-factor\":\n-                if (++i < args.length) {\n-                    this.vacuumScaleFactor = Double.parseDouble(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-table-name\":\n-                if (++i < args.length) {\n-                    this.vacuumTableName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--confirm-drop\":\n-                this.confirmDrop = true;\n-                break;\n-            case \"--allocate-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.allocateTenant = true;\n-                    this.dropTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--refresh-tenants\":\n-                this.refreshTenants = true;\n-                this.allocateTenant = false;\n-                this.dropTenant = false;\n-                break;\n-            case \"--drop-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropTenant = true;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--freeze-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.freezeTenant = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--drop-detached\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropDetached = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--delete-tenant-meta\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.deleteTenantMeta = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--db-type\":\n-                if (++i < args.length) {\n-                    this.dbType = DbType.from(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                switch (dbType) {\n-                case DERBY:\n-                    translator = new DerbyTranslator();\n-                    break;\n-                case POSTGRESQL:\n-                    translator = new PostgresTranslator();\n-                    break;\n-                case DB2:\n-                default:\n-                    break;\n-                }\n-                break;\n-            // Skips the allocateTenant action if the tenant exists (e.g. a shortcircuit)\n-            case \"--skip-allocate-if-tenant-exists\":\n-                skipIfTenantExists = true;\n-                break;\n-            default:\n-                throw new IllegalArgumentException(\"Invalid argument: '\" + arg + \"'\");\n-            }\n-        }\n-        \n-        this.leaseManagerConfig = lmConfig.build();\n-    }\n-\n-    /**\n-     * Read the properties from the given file\n-     *\n-     * @param filename\n-     */\n-    public void loadPropertyFile(String filename) {\n-        try (InputStream is = new FileInputStream(filename)) {\n-            properties.load(is);\n-            // Trim leading and trailing whitespace from property values (except password)\n-            for (Entry<Object, Object> entry : properties.entrySet()) {\n-                if (!\"password\".equals(entry.getKey())) {\n-                    String trimmedValue = entry.getValue().toString().trim();\n-                    if (!trimmedValue.equals(entry.getValue().toString())) {\n-                        logger.warning(\"Whitespace trimmed from value of property '\" + entry.getKey() + \"'\");\n-                        entry.setValue(trimmedValue);\n-                    }\n-                }\n-            }\n-        } catch (IOException x) {\n-            throw new IllegalArgumentException(x);\n-        }\n-    }\n-\n-    /**\n-     * Parse the given key=value string and add to the properties being collected\n-     *\n-     * @param pair\n-     */\n-    public void addProperty(String pair) {\n-        String[] kv = pair.split(\"=\");\n-        if (kv.length == 2) {\n-            // Trim leading and trailing whitespace from property value (except password)\n-            if (!\"password\".equals(kv[0])) {\n-                String trimmedValue = kv[1].trim();\n-                if (!trimmedValue.equals(kv[1])) {\n-                    logger.warning(\"Whitespace trimmed from value of property '\" + kv[0] + \"'\");\n-                }\n-                properties.put(kv[0], trimmedValue);\n-            } else {\n-                properties.put(kv[0], kv[1]);\n-            }\n-        } else {\n-            throw new IllegalArgumentException(\"Property must be defined as key=value, not: \" + pair);\n-        }\n-    }\n-\n-    /**\n-     * Perform the special data migration steps required for the V0010 version of the schema\n-     */\n-    protected void applyDataMigrationForV0010() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0010(ti);\n-                }\n-            }\n-        } else {\n-            doMigrationForV0010();\n-        }\n-    }\n-\n-    protected void applyDataMigrationForV0014() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0014(ti);\n-                }\n-            }\n-        } else {\n-            dataMigrationForV0014();\n-        }\n-    }\n-\n-    /**\n-     * Get the list of resource types to drive resource-by-resource operations\n-     *\n-     * @return the full list of FHIR R4 resource types, or a subset of names if so configured\n-     */\n-    private Set<String> getResourceTypes() {\n-        Set<String> result;\n-        if (this.resourceTypeSubset == null || this.resourceTypeSubset.isEmpty()) {\n-            // pass 'false' to getResourceTypes to avoid building tables for abstract resource types\n-            // Should simplify FhirSchemaGenerator and always pass in this list. When switching\n-            // over to false, migration is required to drop the tables no longer required.\n-            final boolean includeAbstractResourceTypes = true;\n-            result = ModelSupport.getResourceTypes(includeAbstractResourceTypes).stream().map(Class::getSimpleName).collect(Collectors.toSet());\n-        } else {\n-            result = this.resourceTypeSubset;\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Get the list of resource types from the database.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @return\n-     */\n-    private List<ResourceType> getResourceTypesList(IDatabaseAdapter adapter, String schemaName) {\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetResourceTypeList cmd = new GetResourceTypeList(schemaName);\n-                return adapter.runStatement(cmd);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the IS_DELETED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0010(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each update in its own transaction so we don't stress the tx log space\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES.IS_DELETED \"\n-                                + \"for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Perform the data migration for V0010 (non-multi-tenant schema)\n-     */\n-    private void doMigrationForV0010() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    // only process tables which have been converted to the V0010 schema but\n-                    // which have not yet had their data migrated. The migration can't be\n-                    // done as part of the schema change because some tables need a REORG which\n-                    // has to be done after the transaction in which the alter table was performed.\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010-V0012 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES denormalized columns in schema \"\n-                                + schema.getSchemaName());\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0014(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each update in its own transaction so we don't over-stress the tx log space\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    logger.info(\"V0014 Migration: Updating \" + \"LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for \" + resourceType.toString()\n-                            + \" for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-\n-                    dataMigrationForV0014(adapter, ti.getTenantSchema(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data\n-     */\n-    private void dataMigrationForV0014() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    dataMigrationForV0014(adapter, schema.getSchemaName(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * only process tables which have not yet had their data migrated. The migration can't be\n-     * done as part of the schema change because some tables need a REORG which\n-     * has to be done after the transaction in which the alter table was performed.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @param resourceType\n-     */\n-    private void dataMigrationForV0014(IDatabaseAdapter adapter, String schemaName, ResourceType resourceType) {\n-        GetLogicalResourceNeedsV0014Migration needsMigrating = new GetLogicalResourceNeedsV0014Migration(schemaName, resourceType.getId());\n-        if (adapter.runStatement(needsMigrating)) {\n-            logger.info(\"V0014 Migration: Updating LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for schema '\"\n-                    + schemaName + \"' and resource type '\" + resourceType.toString() + \"'\");\n-            MigrateV0014LogicalResourceIsDeletedLastUpdated cmd =\n-                    new MigrateV0014LogicalResourceIsDeletedLastUpdated(schemaName, resourceType.getName(), resourceType.getId());\n-            adapter.runStatement(cmd);\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table if it is empty\n-     */\n-    protected void backfillResourceChangeLog() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    backfillResourceChangeLogDb2(ti);\n-                }\n-            }\n-        } else {\n-            // Not a multi-tenant database, so we only have to do this once\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                    if (adapter.runStatement(isEmpty)) {\n-                        // change log is empty, so we need to backfill it with data\n-                        doBackfill(adapter);\n-                    } else {\n-                        logger.info(\"RESOURCE_CHANGE_LOG has data so skipping backfill\");\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * backfill the resource_change_log table if it is empty\n-     */\n-    protected void backfillResourceChangeLogDb2(TenantInfo ti) {\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                adapter.runStatement(setTenantId);\n-\n-                GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                if (adapter.runStatement(isEmpty)) {\n-                    // change log is empty, so we need to backfill it with data\n-                    for (String resourceTypeName : resourceTypes) {\n-                        logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                                + \" resources for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        BackfillResourceChangeLogDb2 backfill = new BackfillResourceChangeLogDb2(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(backfill);\n-                    }\n-                } else {\n-                    logger.info(\"RESOURCE_CHANGE_LOG has data for tenant '\" + ti.getTenantName() + \"' so skipping backfill\");\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table for all the resource types. Non-multi-tenant\n-     * implementation\n-     *\n-     * @param adapter\n-     */\n-    private void doBackfill(IDatabaseAdapter adapter) {\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        for (String resourceTypeName : resourceTypes) {\n-            logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                    + \" resources for schema '\" + schema.getSchemaName() + \"'\");\n-            BackfillResourceChangeLog backfill = new BackfillResourceChangeLog(schema.getSchemaName(), resourceTypeName);\n-            adapter.runStatement(backfill);\n-        }\n-    }\n-\n-    /**\n-     * updates the vacuum settings for postgres.\n-     */\n-    public void updateVacuumSettings() {\n-        if (dbType != DbType.POSTGRESQL) {\n-            logger.severe(\"Updating the vacuum settings is only supported on postgres and the setting is for '\" + dbType + \"'\");\n-            return;\n-        }\n-\n-        // Create the Physical Data Model\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, true, false, false);\n-\n-        // Setup the Connection Pool\n-        this.maxConnectionPoolSize = 10;\n-        configureConnectionPool();\n-        PostgresAdapter adapter = new PostgresAdapter(connectionPool);\n-\n-        if (vacuumTableName != null) {\n-            runSingleTable(adapter, pdm, schema.getSchemaName(), vacuumTableName);\n-        } else {\n-            // Process all tables in the schema ... except for XX_RESOURCES and COMMON_TOKEN_VALUES and COMMON_CANONICAL_VALUES\n-            GatherTablesDataModelVisitor visitor = new GatherTablesDataModelVisitor();\n-            pdm.visit(visitor);\n-\n-            for (Table tbl : visitor.getTables()) {\n-                runSingleTable(adapter, pdm, schema.getSchemaName(), tbl.getObjectName());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * runs the vacuum update inside a single connection and single transaction.\n-     *\n-     * @param adapter\n-     * @param pdm\n-     * @param schemaName\n-     * @param vacuumTableName\n-     */\n-    private void runSingleTable(PostgresAdapter adapter, PhysicalDataModel pdm, String schemaName, String vacuumTableName) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // If the vacuumTableName exists, then we try finding the table definition.\n-                Table table = pdm.findTable(schemaName, vacuumTableName);\n-                if (table == null) {\n-                    logger.severe(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                    throw new IllegalArgumentException(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                }\n-                PostgresVacuumSettingDAO alterVacuumSettings =\n-                        new PostgresVacuumSettingDAO(schemaName, table.getObjectName(), vacuumCostLimit, vacuumScaleFactor, vacuumThreshold);\n-                adapter.runStatement(alterVacuumSettings);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Process the requested operation\n-     */\n-    protected void process() {\n-        long start = System.nanoTime();\n-        loadDriver(translator);\n-        configureConnectionPool();\n-\n-        if (this.checkCompatibility) {\n-            checkCompatibility();\n-        }\n-\n-        if (translator.isDerby() && !\"APP\".equals(schema.getSchemaName())) {\n-            if (schema.isOverrideDataSchema()) {\n-                logger.warning(\"Only the APP schema is supported for Apache Derby; ignoring the passed\"\n-                        + \" schema name '\" + schema.getSchemaName() + \"' and using APP.\");\n-            }\n-            schema.setSchemaName(\"APP\");\n-        }\n-\n-        // [optional] use a subset of resource types to make testing quicker\n-        String resourceTypesString = properties.getProperty(\"resourceTypes\");\n-        if (resourceTypesString != null && resourceTypesString.length() > 0) {\n-            resourceTypeSubset = new HashSet<>(Arrays.asList(resourceTypesString.split(\",\")));\n-        }\n-\n-        if (addKeyForTenant != null) {\n-            addTenantKey();\n-        } else if (updateVacuum) {\n-            updateVacuumSettings();\n-        } else if (this.dropAdmin || this.dropFhirSchema || this.dropJavaBatchSchema || this.dropOauthSchema) {\n-            // only proceed with the drop if the user has provided additional confirmation\n-            if (this.confirmDrop) {\n-                dropSchema();\n-            } else {\n-                throw new IllegalArgumentException(\"[ERROR] Drop not confirmed with --confirm-drop\");\n-            }\n-        } else if (updateFhirSchema || updateOauthSchema || updateJavaBatchSchema) {\n-            updateSchemas();\n-        } else if (createFhirSchema || createOauthSchema || createJavaBatchSchema) {\n-            createSchemas();\n-        } else if (updateProc) {\n-            updateProcedures();\n-        } else if (grantTo != null) {\n-            grantPrivileges();\n-        } else if (this.listTenants) {\n-            listTenants();\n-        } else if (this.allocateTenant) {\n-            allocateTenant();\n-        } else if (this.refreshTenants) {\n-            refreshTenants();\n-        } else if (this.testTenant) {\n-            testTenant();\n-        } else if (this.freezeTenant) {\n-            freezeTenant();\n-        } else if (this.dropDetached) {\n-            dropDetachedPartitionTables();\n-        } else if (this.deleteTenantMeta) {\n-            deleteTenantMeta();\n-        } else if (this.dropTenant) {\n-            dropTenant();\n-        } else if (this.revokeTenantKey) {\n-            revokeTenantKey();\n-        } else if (this.revokeAllTenantKeys) {\n-            if (this.tenantKey != null) {\n-                throw new IllegalArgumentException(\"[ERROR] --tenant-key <key-value> should not be specified together with --drop-all-tenant-keys\");\n-            }\n-            revokeTenantKey();\n-        }\n-\n-        long elapsed = System.nanoTime() - start;\n-        logger.info(String.format(\"Processing took: %7.3f s\", elapsed / NANOS));\n-    }\n-\n-    /**\n-     * Get the program exit status from the environment\n-     *\n-     * @return\n-     */\n-    protected int getExitStatus() {\n-        return this.exitStatus;\n-    }\n-\n-    /**\n-     * Write a final status message - useful for QA to review when checking the\n-     * output\n-     */\n-    protected void logStatusMessage(int status) {\n-        switch (status) {\n-        case EXIT_OK:\n-            logger.info(\"SCHEMA CHANGE: OK\");\n-            break;\n-        case EXIT_BAD_ARGS:\n-            logger.severe(\"SCHEMA CHANGE: BAD ARGS\");\n-            break;\n-        case EXIT_RUNTIME_ERROR:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        case EXIT_VALIDATION_FAILED:\n-            logger.warning(\"SCHEMA CHANGE: FAILED\");\n-            break;\n-        default:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        }\n-    }\n-\n-    /**\n-     * Log warning messages for deprecated tables.\n-     */\n-    private void logWarningMessagesForDeprecatedTables() {\n-        List<String> deprecatedTables =\n-                Arrays.asList(\"DOMAINRESOURCE_DATE_VALUES\", \"DOMAINRESOURCE_LATLNG_VALUES\", \"DOMAINRESOURCE_LOGICAL_RESOURCES\", \"DOMAINRESOURCE_NUMBER_VALUES\", \"DOMAINRESOURCE_QUANTITY_VALUES\", \"DOMAINRESOURCE_RESOURCE_TOKEN_REFS\", \"DOMAINRESOURCE_RESOURCES\", \"DOMAINRESOURCE_STR_VALUES\", \"RESOURCE_DATE_VALUES\", \"RESOURCE_LATLNG_VALUES\", \"RESOURCE_LOGICAL_RESOURCES\", \"RESOURCE_NUMBER_VALUES\", \"RESOURCE_QUANTITY_VALUES\", \"RESOURCE_RESOURCE_TOKEN_REFS\", \"RESOURCE_RESOURCES\", \"RESOURCE_STR_VALUES\");\n-        for (String deprecatedTable : deprecatedTables) {\n-            logger.warning(\"Table '\" + deprecatedTable\n-                    + \"' will be dropped in a future release. No data should be written to this table. If any data exists in the table, that data should be deleted.\");\n-        }\n-    }\n-\n-    /**\n-     * Main entry point\n-     *\n-     * @param args\n-     */\n-    public static void main(String[] args) {\n-        logClasspath(logger);\n-\n-        int exitStatus;\n-        Main m = new Main();\n-        try {\n-            configureLogger();\n-            m.parseArgs(args);\n-            m.process();\n-            exitStatus = m.getExitStatus();\n-        } catch (TableSpaceRemovalException x) {\n-            logger.warning(\"Tablespace removal is not complete, as an async dependency has not finished dettaching. Please re-try.\");\n-            exitStatus = EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE;\n-        } catch (ConcurrentUpdateException x) {\n-            logger.log(Level.WARNING, \"Update is already running. Please re-try later.\", x);\n-            exitStatus = EXIT_CONCURRENT_UPDATE;\n-        } catch (DatabaseNotReadyException x) {\n-            logger.log(Level.SEVERE, \"The database is not yet available. Please re-try.\", x);\n-            exitStatus = EXIT_NOT_READY;\n-        } catch (IllegalArgumentException x) {\n-            logger.log(Level.SEVERE, \"bad argument\", x);\n-            printUsage();\n-            exitStatus = EXIT_BAD_ARGS;\n-        } catch (Exception x) {\n-            logger.log(Level.SEVERE, \"schema tool failed\", x);\n-            exitStatus = EXIT_RUNTIME_ERROR;\n-        }\n-\n-        // Write out a final status message to make it easy to see validation success/failure\n-        m.logStatusMessage(exitStatus);\n-\n-        // almost certainly will get flagged during code-scan, but this is intentional,\n-        // as we genuinely want to exit with the correct status here. The code-scan tool\n-        // really ought to be able to see that this is a main function in a J2SE environment\n-        System.exit(exitStatus);\n-    }\n-}\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTA3Mg==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420721072", "body": "this is a repeated pattern, I'd suggest adding a single helper method available to all classes. ", "bodyText": "this is a repeated pattern, I'd suggest adding a single helper method available to all classes.", "bodyHTML": "<p dir=\"auto\">this is a repeated pattern, I'd suggest adding a single helper method available to all classes.</p>", "author": "prb112", "createdAt": "2020-05-06T11:32:46Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java", "diffHunk": "@@ -651,7 +652,12 @@ protected void updateProcedures() {\n             try (Connection c = createConnection()) {\n                 try {\n                     JdbcTarget target = new JdbcTarget(c);\n-                    Db2Adapter adapter = new Db2Adapter(target);\n+                    IDatabaseAdapter adapter;", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMTkzNw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421611937", "bodyText": "great point! changed to use existing function.", "author": "albertwang-ibm", "createdAt": "2020-05-07T15:52:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTA3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 63524970dc..2bbdb46fc0 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -652,12 +653,7 @@ public class Main {\n             try (Connection c = createConnection()) {\n                 try {\n                     JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter;\n-                    if (dbType == DbType.POSTGRESQL) {\n-                        adapter = new PostgreSqlAdapter(target);\n-                    } else {\n-                        adapter = new Db2Adapter(target);\n-                    }\n+                    IDatabaseAdapter adapter = getDbAdapter(target);\n                     pdm.applyProcedures(adapter);\n                 } catch (Exception x) {\n                     c.rollback();\n", "next_change": {"commit": "b88da7356848f84d2f45c925215861addfaaf6d5", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 2bbdb46fc0..3951de26c3 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -653,7 +438,7 @@ public class Main {\n             try (Connection c = createConnection()) {\n                 try {\n                     JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(target);\n+                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n                     pdm.applyProcedures(adapter);\n                 } catch (Exception x) {\n                     c.rollback();\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 3951de26c3..98ba9ea874 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -440,6 +453,7 @@ public class Main {\n                     JdbcTarget target = new JdbcTarget(c);\n                     IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n                     pdm.applyProcedures(adapter);\n+                    pdm.applyFunctions(adapter);\n                 } catch (Exception x) {\n                     c.rollback();\n                     throw x;\n", "next_change": {"commit": "858fbb1331e7f20d7a04bdf40edaf71da5bbadda", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 98ba9ea874..af16fc6a87 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -443,24 +457,28 @@ public class Main {\n \n         // Build/update the tables as well as the stored procedures\n         PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, updateFhirSchema, updateOauthSchema,updateJavaBatchSchema);\n+        // Since this is a stored procedure, we need the model.\n+        // We must pass in true to flag to the underlying layer that the\n+        // Procedures need to be generated.\n+        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n \n         // Now only apply the procedures in the model. Much faster than\n         // going through the whole schema\n-        try {\n-            try (Connection c = createConnection()) {\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try (Connection c = connectionPool.getConnection();) {\n                 try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n+                    IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n                     pdm.applyProcedures(adapter);\n                     pdm.applyFunctions(adapter);\n-                } catch (Exception x) {\n-                    c.rollback();\n+                } catch (DataAccessException x) {\n+                    // Something went wrong, so mark the transaction as failed\n+                    tx.setRollbackOnly();\n                     throw x;\n                 }\n                 c.commit();\n             }\n         } catch (SQLException x) {\n+            tx.setRollbackOnly();\n             throw translator.translate(x);\n         }\n     }\n", "next_change": {"commit": "1e6b10331aa2b2d62411ec4f673d0214cb4c7a21", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex af16fc6a87..7887824450 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -476,10 +476,10 @@ public class Main {\n                     throw x;\n                 }\n                 c.commit();\n+            } catch (SQLException x) {\n+                tx.setRollbackOnly();\n+                throw translator.translate(x);\n             }\n-        } catch (SQLException x) {\n-            tx.setRollbackOnly();\n-            throw translator.translate(x);\n         }\n     }\n \n", "next_change": {"commit": "41e95c7381ecb889f30f467e5a6cc7c0c78e5e60", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 7887824450..9455e61d76 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -475,7 +479,7 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                c.commit();\n+                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "c2193720060c03214cfab6924175a7a0b7854894", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 9455e61d76..69f4ea0c1d 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -479,7 +462,7 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n+                c.commit();\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "6833eb59b53e0764547500c9329ecddf6e9ca700", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 69f4ea0c1d..3c4c21c031 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -462,7 +466,7 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                c.commit();\n+                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "08003cabbd153c969c0f31c9eb6580ca86f7ae88", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 3c4c21c031..ba15a28613 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -466,7 +571,8 @@ public class Main {\n                     tx.setRollbackOnly();\n                     throw x;\n                 }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the transaction commit.\n+                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the\n+                // transaction commit.\n             } catch (SQLException x) {\n                 tx.setRollbackOnly();\n                 throw translator.translate(x);\n", "next_change": {"commit": "afceaba4a867a0af38a6cb431245b8b1854b9f74", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex ba15a28613..eff8be1420 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -580,6 +749,28 @@ public class Main {\n         }\n     }\n \n+    /**\n+     * Build a common PhysicalDataModel containing all the requested schemas\n+     * \n+     * @param pdm the model to construct\n+     * @param addFhirDataSchema include objects for the FHIR data schema\n+     * @param addOAuthSchema include objects for the Liberty OAuth schema\n+     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n+     */\n+    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n+        if (addFhirDataSchema) {\n+            buildFhirDataSchemaModel(pdm);\n+        }\n+        \n+        if (addOAuthSchema) {\n+            buildOAuthSchemaModel(pdm);\n+        }\n+        \n+        if (addJavaBatchSchema) {\n+            buildJavaBatchSchemaModel(pdm);\n+        }\n+    }\n+\n     // -----------------------------------------------------------------------------------------------------------------\n     // The following method is related to the Privilege feature\n     /**\n", "next_change": {"commit": "652c689992b6da38f3904766b4dfae672f23826a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex eff8be1420..f38f98eed9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -771,8 +804,67 @@ public class Main {\n         }\n     }\n \n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Privilege feature\n+    /**\n+     * Apply grants to the FHIR data schema objects\n+     */\n+    protected void grantPrivilegesForFhirData() {\n+\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildFhirDataSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+                \n+                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n+                // Note the constant comes from SchemaConstants on purpose\n+                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Apply grants to the OAuth schema objects\n+     */\n+    protected void grantPrivilegesForOAuth() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildOAuthSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n+                \n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+        \n+    }\n+\n+    /**\n+     * Apply grants to the JavaBatch schema objects\n+     */\n+    protected void grantPrivilegesForBatch() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildJavaBatchSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n     /**\n      * Grant the minimum required set of privileges on the FHIR schema objects\n      * to the grantTo user. All tenant data access is via this user, and is the\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\ndeleted file mode 100644\nindex f38f98eed9..0000000000\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ /dev/null\n", "chunk": "@@ -1,2526 +0,0 @@\n-/*\n- * (C) Copyright IBM Corp. 2019, 2021\n- *\n- * SPDX-License-Identifier: Apache-2.0\n- */\n-\n-package com.ibm.fhir.schema.app;\n-\n-import static com.ibm.fhir.schema.app.util.CommonUtil.configureLogger;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getDbAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getPropertyAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getRandomKey;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.loadDriver;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.logClasspath;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.printUsage;\n-\n-import java.io.FileInputStream;\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.sql.Connection;\n-import java.sql.DriverManager;\n-import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map.Entry;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.logging.Level;\n-import java.util.logging.Logger;\n-import java.util.stream.Collectors;\n-\n-import com.ibm.fhir.core.util.handler.HostnameHandler;\n-import com.ibm.fhir.database.utils.api.DataAccessException;\n-import com.ibm.fhir.database.utils.api.DatabaseNotReadyException;\n-import com.ibm.fhir.database.utils.api.IDatabaseAdapter;\n-import com.ibm.fhir.database.utils.api.IDatabaseTranslator;\n-import com.ibm.fhir.database.utils.api.ITransaction;\n-import com.ibm.fhir.database.utils.api.ITransactionProvider;\n-import com.ibm.fhir.database.utils.api.TableSpaceRemovalException;\n-import com.ibm.fhir.database.utils.api.TenantStatus;\n-import com.ibm.fhir.database.utils.api.UndefinedNameException;\n-import com.ibm.fhir.database.utils.common.DataDefinitionUtil;\n-import com.ibm.fhir.database.utils.common.JdbcConnectionProvider;\n-import com.ibm.fhir.database.utils.common.JdbcPropertyAdapter;\n-import com.ibm.fhir.database.utils.common.JdbcTarget;\n-import com.ibm.fhir.database.utils.db2.Db2Adapter;\n-import com.ibm.fhir.database.utils.db2.Db2GetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2SetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2Translator;\n-import com.ibm.fhir.database.utils.derby.DerbyTranslator;\n-import com.ibm.fhir.database.utils.model.DatabaseObjectType;\n-import com.ibm.fhir.database.utils.model.DbType;\n-import com.ibm.fhir.database.utils.model.PhysicalDataModel;\n-import com.ibm.fhir.database.utils.model.Table;\n-import com.ibm.fhir.database.utils.model.Tenant;\n-import com.ibm.fhir.database.utils.pool.PoolConnectionProvider;\n-import com.ibm.fhir.database.utils.postgres.GatherTablesDataModelVisitor;\n-import com.ibm.fhir.database.utils.postgres.PostgresAdapter;\n-import com.ibm.fhir.database.utils.postgres.PostgresTranslator;\n-import com.ibm.fhir.database.utils.postgres.PostgresVacuumSettingDAO;\n-import com.ibm.fhir.database.utils.tenant.AddTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.DeleteTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.GetTenantDAO;\n-import com.ibm.fhir.database.utils.transaction.SimpleTransactionProvider;\n-import com.ibm.fhir.database.utils.transaction.TransactionFactory;\n-import com.ibm.fhir.database.utils.version.CreateControl;\n-import com.ibm.fhir.database.utils.version.CreateWholeSchemaVersion;\n-import com.ibm.fhir.database.utils.version.SchemaConstants;\n-import com.ibm.fhir.database.utils.version.CreateVersionHistory;\n-import com.ibm.fhir.database.utils.version.VersionHistoryService;\n-import com.ibm.fhir.model.util.ModelSupport;\n-import com.ibm.fhir.schema.api.ConcurrentUpdateException;\n-import com.ibm.fhir.schema.api.ILeaseManagerConfig;\n-import com.ibm.fhir.schema.app.util.TenantKeyFileUtil;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLog;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLogDb2;\n-import com.ibm.fhir.schema.control.DisableForeignKey;\n-import com.ibm.fhir.schema.control.DropForeignKey;\n-import com.ibm.fhir.schema.control.EnableForeignKey;\n-import com.ibm.fhir.schema.control.FhirSchemaConstants;\n-import com.ibm.fhir.schema.control.FhirSchemaGenerator;\n-import com.ibm.fhir.schema.control.GetLogicalResourceNeedsV0014Migration;\n-import com.ibm.fhir.schema.control.GetResourceChangeLogEmpty;\n-import com.ibm.fhir.schema.control.GetResourceTypeList;\n-import com.ibm.fhir.schema.control.GetTenantInfo;\n-import com.ibm.fhir.schema.control.GetTenantList;\n-import com.ibm.fhir.schema.control.GetXXLogicalResourceNeedsMigration;\n-import com.ibm.fhir.schema.control.InitializeLogicalResourceDenorms;\n-import com.ibm.fhir.schema.control.JavaBatchSchemaGenerator;\n-import com.ibm.fhir.schema.control.MigrateV0014LogicalResourceIsDeletedLastUpdated;\n-import com.ibm.fhir.schema.control.OAuthSchemaGenerator;\n-import com.ibm.fhir.schema.control.PopulateParameterNames;\n-import com.ibm.fhir.schema.control.PopulateResourceTypes;\n-import com.ibm.fhir.schema.control.SetTenantIdDb2;\n-import com.ibm.fhir.schema.control.TenantInfo;\n-import com.ibm.fhir.schema.model.ResourceType;\n-import com.ibm.fhir.schema.model.Schema;\n-import com.ibm.fhir.task.api.ITaskCollector;\n-import com.ibm.fhir.task.api.ITaskGroup;\n-import com.ibm.fhir.task.core.service.TaskService;\n-\n-/**\n- * Utility app to connect to a database and create/update the IBM FHIR Server schema.\n- * The DDL processing is idempotent, with only the necessary changes applied.\n- * <br>\n- * This utility also includes an option to exercise the tenant partitioning code.\n- */\n-public class Main {\n-\n-    private static final Logger logger = Logger.getLogger(Main.class.getName());\n-    private static final int EXIT_OK = 0; // validation was successful\n-    private static final int EXIT_BAD_ARGS = 1; // invalid CLI arguments\n-    private static final int EXIT_RUNTIME_ERROR = 2; // programming error\n-    private static final int EXIT_VALIDATION_FAILED = 3; // validation test failed\n-    private static final int EXIT_NOT_READY = 4; // DATABASE NOT READY\n-    private static final int EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE = 5; // Tablespace Removal not complete\n-    private static final int EXIT_CONCURRENT_UPDATE = 6; // Another schema update is running and the wait time expired\n-    private static final double NANOS = 1e9;\n-\n-    // Indicates if the feature is enabled for the DbType\n-    public List<DbType> MULTITENANT_FEATURE_ENABLED = Arrays.asList(DbType.DB2);\n-    public List<DbType> STORED_PROCEDURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-    public List<DbType> PRIVILEGES_FEATURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-\n-    // Properties accumulated as we parse args and read configuration files\n-    private final Properties properties = new Properties();\n-\n-    // Default Values for schema names\n-    public static final String ADMIN_SCHEMANAME = \"FHIR_ADMIN\";\n-    public static final String OAUTH_SCHEMANAME = \"FHIR_OAUTH\";\n-    public static final String BATCH_SCHEMANAME = \"FHIR_JBATCH\";\n-    public static final String DATA_SCHEMANAME = \"FHIRDATA\";\n-\n-    // Force upper-case to avoid tricky-to-catch errors related to quoting names\n-    private Schema schema = new Schema();\n-\n-    // Arguments requesting we drop the objects from the schema\n-    private boolean dropAdmin = false;\n-    private boolean confirmDrop = false;\n-    private boolean updateProc = false;\n-    private boolean checkCompatibility = false;\n-\n-    // Action flags related to FHIR Schema\n-    private boolean createFhirSchema = false;\n-    private boolean updateFhirSchema = false;\n-    private boolean dropFhirSchema = false;\n-    private boolean grantFhirSchema = false;\n-\n-    // Action flags related to OAuth Schema\n-    private boolean createOauthSchema = false;\n-    private boolean updateOauthSchema = false;\n-    private boolean dropOauthSchema = false;\n-    private boolean grantOauthSchema = false;\n-\n-    // Action flags related to Java Batch Schema\n-    private boolean createJavaBatchSchema = false;\n-    private boolean updateJavaBatchSchema = false;\n-    private boolean dropJavaBatchSchema = false;\n-    private boolean grantJavaBatchSchema = false;\n-\n-    // Tenant Key\n-    private boolean skipIfTenantExists = false;\n-\n-    // The database user we will grant tenant data access privileges to\n-    private String grantTo;\n-\n-    // Action flag related to Vacuuming:\n-    private boolean updateVacuum = false;\n-    private String vacuumTableName = null;\n-    private int vacuumCostLimit = 2000;\n-    private int vacuumThreshold = 1000;\n-    private Double vacuumScaleFactor = null;\n-    \n-    // How many seconds to wait to obtain the update lease\n-    private int waitForUpdateLeaseSeconds = 10;\n-\n-    // The database type being populated (default: Db2)\n-    private DbType dbType = DbType.DB2;\n-    private IDatabaseTranslator translator = new Db2Translator();\n-\n-    // Optional subset of resource types (for faster schema builds when testing)\n-    private Set<String> resourceTypeSubset;\n-\n-    // Tenant management\n-    private boolean allocateTenant;\n-    private boolean refreshTenants;\n-    private boolean dropTenant;\n-    private boolean freezeTenant;\n-    private String tenantName;\n-    private boolean testTenant;\n-    private String tenantKey;\n-    private boolean listTenants;\n-    private boolean dropDetached;\n-    private boolean deleteTenantMeta;\n-    private boolean revokeTenantKey;\n-    private boolean revokeAllTenantKeys;\n-\n-    // Tenant Key Output or Input File\n-    private String tenantKeyFileName;\n-    private TenantKeyFileUtil tenantKeyFileUtil = new TenantKeyFileUtil();\n-\n-    // The tenant name for when we want to add a new tenant key\n-    private String addKeyForTenant;\n-\n-    // What status to leave with\n-    private int exitStatus = EXIT_OK;\n-\n-    // The connection pool and transaction provider to support concurrent operations\n-    private int maxConnectionPoolSize = FhirSchemaConstants.DEFAULT_POOL_SIZE;\n-    private PoolConnectionProvider connectionPool;\n-    private ITransactionProvider transactionProvider;\n-    \n-    // Configuration to control how the LeaseManager operates\n-    private ILeaseManagerConfig leaseManagerConfig;\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the common methods and functions\n-    /**\n-     * @return a created connection to the selected database\n-     */\n-    protected Connection createConnection() {\n-        Properties connectionProperties = new Properties();\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        adapter.getExtraProperties(connectionProperties);\n-\n-        String url = translator.getUrl(properties);\n-        logger.info(\"Opening connection to: \" + url);\n-        Connection connection;\n-        try {\n-            connection = DriverManager.getConnection(url, connectionProperties);\n-            connection.setAutoCommit(false);\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-        return connection;\n-    }\n-\n-    /**\n-     * Create a simple connection pool associated with our data source so that we\n-     * can perform the DDL deployment in parallel\n-     */\n-    protected void configureConnectionPool() {\n-        if (dbType == DbType.DERBY && maxConnectionPoolSize > 1) {\n-            logger.warning(\"Embedded Derby does not support concurrent schema updates;\" +\n-                    \" ignoring '--pool-size' and using a single thread.\");\n-            this.maxConnectionPoolSize = 1;\n-        }\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        JdbcConnectionProvider cp = new JdbcConnectionProvider(this.translator, adapter);\n-        this.connectionPool = new PoolConnectionProvider(cp, this.maxConnectionPoolSize);\n-        this.transactionProvider = new SimpleTransactionProvider(this.connectionPool);\n-    }\n-\n-    /**\n-     * Add the admin schema objects to the {@link PhysicalDataModel}\n-     *\n-     * @param pdm the data model to build\n-     */\n-    protected void buildAdminSchemaModel(PhysicalDataModel pdm) {\n-        // Add the tenant and tenant_keys tables and any other admin schema stuff\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        gen.buildAdminSchema(pdm);\n-    }\n-    \n-    /**\n-     * Add the OAuth schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm the model to build\n-     */\n-    protected void buildOAuthSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty OAuth-related tables\n-        OAuthSchemaGenerator oauthSchemaGenerator = new OAuthSchemaGenerator(schema.getOauthSchemaName());\n-        oauthSchemaGenerator.buildOAuthSchema(pdm);\n-    }\n-\n-    /**\n-     * Add the JavaBatch schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm\n-     */\n-    protected void buildJavaBatchSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty JBatch related tables\n-        JavaBatchSchemaGenerator javaBatchSchemaGenerator = new JavaBatchSchemaGenerator(schema.getJavaBatchSchemaName());\n-        javaBatchSchemaGenerator.buildJavaBatchSchema(pdm);\n-    }\n-\n-    /**\n-     * Start the schema object creation tasks and wait for everything to complete\n-     *\n-     * @param pdm\n-     * @param adapter\n-     * @param collector\n-     * @param vhs\n-     */\n-    protected void applyModel(PhysicalDataModel pdm, IDatabaseAdapter adapter, ITaskCollector collector, VersionHistoryService vhs) {\n-        logger.info(\"Collecting model update tasks\");\n-        pdm.collect(collector, adapter, this.transactionProvider, vhs);\n-\n-        // FHIR in the hole!\n-        logger.info(\"Starting model updates\");\n-        collector.startAndWait();\n-\n-        Collection<ITaskGroup> failedTaskGroups = collector.getFailedTaskGroups();\n-        if (failedTaskGroups.size() > 0) {\n-            this.exitStatus = EXIT_RUNTIME_ERROR;\n-\n-            final String failedStr =\n-                    failedTaskGroups.stream().map((tg) -> tg.getTaskId()).collect(Collectors.joining(\",\"));\n-            logger.severe(\"List of failed task groups: \" + failedStr);\n-        }\n-    }\n-\n-    /**\n-     * specific feature to check if it is compatible.\n-     *\n-     * @return\n-     */\n-    protected boolean checkCompatibility() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            return adapter.checkCompatibility(schema.getAdminSchemaName());\n-        }\n-    }\n-\n-    /**\n-     * Create the schemas\n-     */\n-    protected void createSchemas() {\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    // We always create the 'admin' schema to track to the changes to any of the other schemas.\n-                    adapter.createSchema(schema.getAdminSchemaName());\n-\n-                    // FHIR Data Schema\n-                    if (createFhirSchema) {\n-                        adapter.createSchema(schema.getSchemaName());\n-                        c.commit();\n-                    }\n-\n-                    // OAuth Schema\n-                    if (createOauthSchema) {\n-                        adapter.createSchema(schema.getOauthSchemaName());\n-                    }\n-\n-                    // Java Batch Schema\n-                    if (createJavaBatchSchema) {\n-                        adapter.createSchema(schema.getJavaBatchSchemaName());\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-    \n-    /**\n-     * Process the schemas configured to be updated\n-     */\n-    protected void updateSchemas() {\n-        \n-        // Make sure that we have the CONTROL table created before we try any\n-        // schema update work\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateControl.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        if (updateFhirSchema) {\n-            updateFhirSchema();\n-        }\n-        \n-        if (updateOauthSchema) {\n-            updateOauthSchema();\n-        }\n-        \n-        if (updateJavaBatchSchema) {\n-            updateJavaBatchSchema();\n-        }\n-    }\n-    \n-    /**\n-     * Add FHIR data schema objects to the given {@link PhysicalDataModel}\n-     * @param pdm the data model being built\n-     */\n-    protected void buildFhirDataSchemaModel(PhysicalDataModel pdm) {\n-        FhirSchemaGenerator gen;\n-        if (resourceTypeSubset == null || resourceTypeSubset.isEmpty()) {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        } else {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant(), resourceTypeSubset);\n-        }\n-\n-        gen.buildSchema(pdm);\n-        switch (dbType) {\n-        case DB2:\n-            gen.buildDatabaseSpecificArtifactsDb2(pdm);\n-            break;\n-        case DERBY:\n-            logger.info(\"No database specific artifacts\");\n-            break;\n-        case POSTGRESQL:\n-            gen.buildDatabaseSpecificArtifactsPostgres(pdm);\n-            break;\n-        default:\n-            throw new IllegalStateException(\"Unsupported db type: \" + dbType);\n-        }\n-    }\n-    \n-    /**\n-     * Update the FHIR data schema\n-     */\n-    protected void updateFhirSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for FHIR data schema: '\" + schema.getSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                // Build/update the FHIR-related tables as well as the stored procedures\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                boolean isNewDb = updateSchema(pdm);\n-                \n-                // If the db is multi-tenant, we populate the resource types and parameter names in allocate-tenant.\n-                // Otherwise, if its a new schema, populate the resource types and parameters names (codes) now\n-                if (!MULTITENANT_FEATURE_ENABLED.contains(dbType) && isNewDb) {\n-                    populateResourceTypeAndParameterNameTableEntries(null);\n-                }\n-        \n-                if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-                    logger.info(\"Refreshing tenant partitions\");\n-                    refreshTenants();\n-                }\n-        \n-                // backfill the resource_change_log table if needed\n-                backfillResourceChangeLog();\n-        \n-                // perform any updates we need related to the V0010 schema change (IS_DELETED flag)\n-                applyDataMigrationForV0010();\n-        \n-                // V0014 IS_DELETED and LAST_UPDATED added to whole-system LOGICAL_RESOURCES\n-                applyDataMigrationForV0014();\n-        \n-                // Log warning messages that unused tables will be removed in a future release.\n-                // TODO: This will no longer be needed after the tables are removed (https://github.com/IBM/FHIR/issues/713).\n-                logWarningMessagesForDeprecatedTables();\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForFhirData();\n-                }\n-                \n-                // Finally, update the whole schema version\n-                svm.updateSchemaVersion();\n-                \n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the OAuth schema changes\n-     */\n-    protected void updateOauthSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getOauthSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty OAuth schema: '\" + schema.getOauthSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getOauthSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForOAuth();\n-                }\n-                \n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the JavaBatch schema changes\n-     */\n-    protected void updateJavaBatchSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getJavaBatchSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty JavaBatch schema: '\" + schema.getJavaBatchSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getJavaBatchSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-\n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForBatch();\n-                }\n-\n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-    \n-    /**\n-     * Update the schema associated with the given {@link PhysicalDataModel}\n-     * @return true if the database is new\n-     */\n-    protected boolean updateSchema(PhysicalDataModel pdm) {\n-\n-        // The objects are applied in parallel, which relies on each object\n-        // expressing its dependencies correctly. Changes are only applied\n-        // if their version is greater than the current version.\n-        TaskService taskService = new TaskService();\n-        ExecutorService pool = Executors.newFixedThreadPool(this.maxConnectionPoolSize);\n-        ITaskCollector collector = taskService.makeTaskCollector(pool);\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-\n-        // Before we start anything, we need to make sure our schema history\n-        // and control tables are in place. These tables are used to manage \n-        // all FHIR data, oauth and JavaBatch schemas we build\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateVersionHistory.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        // Current version history for the data schema\n-        VersionHistoryService vhs =\n-                new VersionHistoryService(schema.getAdminSchemaName(), schema.getSchemaName(), schema.getOauthSchemaName(), schema.getJavaBatchSchemaName());\n-        vhs.setTransactionProvider(transactionProvider);\n-        vhs.setTarget(adapter);\n-        vhs.init();\n-\n-        // Use the version history service to determine if this table existed before we run `applyWithHistory`\n-        boolean isNewDb = vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == null ||\n-                vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == 0;\n-\n-        applyModel(pdm, adapter, collector, vhs);\n-        // The physical database objects should now match what was defined in the PhysicalDataModel\n-        \n-        return isNewDb;\n-    }\n-\n-    /**\n-     * populates for the given tenantId the RESOURCE_TYPE table.\n-     *\n-     * @implNote if you update this method, be sure to update\n-     *           DerbyBootstrapper.populateResourceTypeAndParameterNameTableEntries\n-     *           and DerbyFhirDatabase.populateResourceTypeAndParameterNameTableEntries\n-     *           The reason is there are three different ways of managing the transaction.\n-     * @param tenantId\n-     *            the mt_id that is used to setup the partition.\n-     *            passing in null signals not multi-tenant.\n-     */\n-    protected void populateResourceTypeAndParameterNameTableEntries(Integer tenantId) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                String logTenantId = tenantId != null ? Integer.toString(tenantId) : \"default\";\n-                logger.info(\"tenantId [\" + logTenantId + \"] is being pre-populated with lookup table data.\");\n-                PopulateResourceTypes populateResourceTypes =\n-                        new PopulateResourceTypes(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateResourceTypes.run(translator, c);\n-\n-                PopulateParameterNames populateParameterNames =\n-                        new PopulateParameterNames(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateParameterNames.run(translator, c);\n-                logger.info(\"Finished prepopulating the resource type and search parameter code/name tables tables\");\n-            } catch (SQLException ex) {\n-                tx.setRollbackOnly();\n-                throw new DataAccessException(ex);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Drop all the objects in the admin and data schemas.\n-     * Typically used during development.\n-     */\n-    protected void dropSchema() {\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, dropFhirSchema, dropOauthSchema, dropJavaBatchSchema);\n-\n-        // Dropping the schema in PostgreSQL can fail with an out of shared memory error\n-        // which is apparently related to max_locks_per_transaction. It may not be possible\n-        // to increase this value (e.g. in cloud databases) and so to work around this, before\n-        // dropping the schema objects, we knock out all the FOREIGN KEY constraints first.\n-        if (dropFhirSchema) {\n-            logger.info(\"Dropping FK constraints in the data schema: \" + this.schema.getSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-        }\n-\n-        if (dropOauthSchema) {\n-            logger.info(\"Dropping FK constraints in the OAuth schema: \" + this.schema.getOauthSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-        }\n-\n-        if (dropJavaBatchSchema) {\n-            logger.info(\"Dropping FK constraints in the Batch schema: \" + this.schema.getJavaBatchSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-        }\n-\n-        if (dropAdmin) {\n-            // Also drop the FK constraints within the administration schema\n-            logger.info(\"Dropping FK constraints in the admin schema: \" + this.schema.getAdminSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-        }\n-\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    if (dropFhirSchema || dropOauthSchema || dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the FHIRDATA schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-                    }\n-\n-                    if (dropOauthSchema) {\n-                        // Just drop the objects associated with the OAUTH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-                    }\n-\n-                    if (dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the BATCH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-                    }\n-\n-                    if (dropAdmin) {\n-                        // Just drop the objects associated with the ADMIN schema group\n-                        CreateVersionHistory.generateTable(pdm, ADMIN_SCHEMANAME, true);\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    /**\n-     * Add part of the schema drop process, we first kill all\n-     * the foreign key constraints. The rest of the drop is\n-     * performed in a second transaction.\n-     *\n-     * @param pdm\n-     */\n-    private void dropForeignKeyConstraints(PhysicalDataModel pdm, String tagGroup, String tag) {\n-        try (Connection c = createConnection()) {\n-            try {\n-                JdbcTarget target = new JdbcTarget(c);\n-                IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                Set<Table> referencedTables = new HashSet<>();\n-                DropForeignKey dropper = new DropForeignKey(adapter, referencedTables);\n-                pdm.visit(dropper, tagGroup, tag);\n-            } catch (Exception x) {\n-                c.rollback();\n-                throw x;\n-            }\n-            c.commit();\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Stored Procedures and Functions feature\n-    /**\n-     * Update the stored procedures used by FHIR to insert records\n-     * into the FHIR resource tables\n-     */\n-    protected void updateProcedures() {\n-        if (!STORED_PROCEDURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        // Since this is a stored procedure, we need the model.\n-        // We must pass in true to flag to the underlying layer that the\n-        // Procedures need to be generated.\n-        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n-\n-        // Now only apply the procedures in the model. Much faster than\n-        // going through the whole schema\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                try {\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-                    pdm.applyProcedures(adapter);\n-                    pdm.applyFunctions(adapter);\n-                    \n-                    // Because we're replacing the procedures, we should also check if\n-                    // we need to apply the associated privileges\n-                    if (this.grantTo != null) {\n-                        pdm.applyProcedureAndFunctionGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the\n-                // transaction commit.\n-            } catch (SQLException x) {\n-                tx.setRollbackOnly();\n-                throw translator.translate(x);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Build a common PhysicalDataModel containing all the requested schemas\n-     * \n-     * @param pdm the model to construct\n-     * @param addFhirDataSchema include objects for the FHIR data schema\n-     * @param addOAuthSchema include objects for the Liberty OAuth schema\n-     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n-     */\n-    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n-        if (addFhirDataSchema) {\n-            buildFhirDataSchemaModel(pdm);\n-        }\n-        \n-        if (addOAuthSchema) {\n-            buildOAuthSchemaModel(pdm);\n-        }\n-        \n-        if (addJavaBatchSchema) {\n-            buildJavaBatchSchemaModel(pdm);\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the FHIR data schema objects\n-     */\n-    protected void grantPrivilegesForFhirData() {\n-\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                \n-                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n-                // Note the constant comes from SchemaConstants on purpose\n-                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the OAuth schema objects\n-     */\n-    protected void grantPrivilegesForOAuth() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n-                \n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        \n-    }\n-\n-    /**\n-     * Apply grants to the JavaBatch schema objects\n-     */\n-    protected void grantPrivilegesForBatch() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Grant the minimum required set of privileges on the FHIR schema objects\n-     * to the grantTo user. All tenant data access is via this user, and is the\n-     * only user the FHIR server itself is configured with.\n-     */\n-    protected void grantPrivileges() {\n-        if (!PRIVILEGES_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // The case where all are to be granted on the default schemas.\n-        if (!(updateFhirSchema || grantFhirSchema || updateOauthSchema\n-                || grantOauthSchema || updateJavaBatchSchema || grantJavaBatchSchema)) {\n-            grantOauthSchema = true;\n-            grantFhirSchema = true;\n-            grantJavaBatchSchema = true;\n-        }\n-        \n-        if (grantFhirSchema) {\n-            grantPrivilegesForFhirData();\n-        }\n-        \n-        if (grantOauthSchema) {\n-            grantPrivilegesForOAuth();\n-        }\n-        \n-        if (grantJavaBatchSchema) {\n-            grantPrivilegesForBatch();\n-        }\n-    }\n-\n-    /**\n-     * Do we want to build the multitenant variant of the schema (currently only supported\n-     * by DB2)\n-     *\n-     * @return\n-     */\n-    protected boolean isMultitenant() {\n-        return MULTITENANT_FEATURE_ENABLED.contains(this.dbType);\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to Multi-Tenant only.\n-    /**\n-     * Add a new tenant key so that we can rotate the values (add a\n-     * new key, update config files, then remove the old key). This\n-     * avoids any service interruption.\n-     */\n-    protected void addTenantKey() {\n-        if (!isMultitenant()) {\n-            return;\n-        }\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, false);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantDAO tid = new GetTenantDAO(schema.getAdminSchemaName(), addKeyForTenant);\n-                Tenant tenant = adapter.runStatement(tid);\n-\n-                if (tenant != null) {\n-                    // Attach the new tenant key to the tenant:\n-                    AddTenantKeyDAO adder =\n-                            new AddTenantKeyDAO(schema.getAdminSchemaName(), tenant.getTenantId(), tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-                    adapter.runStatement(adder);\n-                } else {\n-                    throw new IllegalArgumentException(\"Tenant does not exist: \" + addKeyForTenant);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            // Generated\n-            logger.info(\"New tenant key: \" + addKeyForTenant + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            // Loaded from File\n-            logger.info(\"New tenant key from file: \" + addKeyForTenant + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * checks if tenant name and tenant key exists.\n-     *\n-     * @param adapter\n-     *            the db2 adapter as this is a db2 feature only now\n-     * @param tenantName\n-     *            the tenant's name\n-     * @param tenantKey\n-     *            tenant key\n-     * @param skip\n-     *            whether or not to skip over cases where this tenantName/tenantKey combination already exists\n-     *\n-     * @throws IllegalArgumentException if the tenantName/tenantKey combination already exists and the {@code skip} argument is false\n-     *\n-     * @return indicates if the tenantName/tenantKey exists\n-     */\n-    protected boolean checkIfTenantNameAndTenantKeyExists(Db2Adapter adapter, String tenantName, String tenantKey, boolean skip) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                final String sql =\n-                        \"SELECT t.tenant_status FROM fhir_admin.tenants t WHERE t.tenant_name = ? \"\n-                                + \"AND EXISTS (SELECT 1 FROM fhir_admin.tenant_keys tk WHERE tk.mt_id = t.mt_id \"\n-                                + \"AND tk.tenant_hash = sysibm.hash(tk.tenant_salt || ?, 2))\";\n-                try (PreparedStatement stmt = connectionPool.getConnection().prepareStatement(sql)) {\n-                    stmt.setString(1, tenantName);\n-                    stmt.setString(2, tenantKey);\n-                    if (stmt.execute()) {\n-                        try (ResultSet resultSet = stmt.getResultSet();) {\n-                            if (resultSet.next()) {\n-                                if (skip) {\n-                                    return true;\n-                                } else {\n-                                    throw new IllegalArgumentException(\"tenantName and tenantKey already exists\");\n-                                }\n-                            }\n-                        }\n-                    } else {\n-                        throw new IllegalArgumentException(\"Problem checking the results\");\n-                    }\n-                } catch (SQLException e) {\n-                    throw new IllegalArgumentException(\"Exception when querying backend to verify tenant key and tenant name\", e);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return false;\n-    }\n-\n-    /**\n-     * Allocate this tenant, creating new partitions if required.\n-     */\n-    protected void allocateTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // IMPORTANT! Check the schema name aligns with the actual schema for this tenant\n-        checkSchemaForTenant();\n-\n-        // The key we'll use for this tenant. This key should be used in subsequent\n-        // activities related to this tenant, such as setting the tenant context.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        // Conditionally skip if the tenant name and key exist (this enables idempotency)\n-        boolean skip = checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, skipIfTenantExists);\n-        if (skip) {\n-            return;\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-        }\n-\n-        // Open a new transaction and associate it with our connection pool. Remember\n-        // that we don't support distributed transactions, so all connections within\n-        // this transaction must come from the same pool\n-        int tenantId;\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                tenantId =\n-                        adapter.allocateTenant(schema.getAdminSchemaName(), schema.getSchemaName(), tenantName, tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-\n-                // The tenant-id is important because this is also used to identify the partition number\n-                logger.info(\"Tenant Id[\" + tenantName + \"] = [\" + tenantId + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Get the data model to create the table partitions. This is threaded, so transactions are\n-        // handled within each thread by the adapter. This means we should probably pull some of\n-        // that logic out of the adapter and handle it at a higher level. Note...the extent size used\n-        // for the partitions needs to match the extent size of the original table tablespace (FHIR_TS)\n-        // so this must be constant.\n-        pdm.addTenantPartitions(adapter, schema.getSchemaName(), tenantId, FhirSchemaConstants.FHIR_TS_EXTENT_KB);\n-\n-        // Fill any static data tables (which are also partitioned by tenant)\n-        // Prepopulate the Resource Type Tables and Parameters Name/Code Table\n-        populateResourceTypeAndParameterNameTableEntries(tenantId);\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as ready\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantId, TenantStatus.ALLOCATED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [key=\" + tenantKey + \"] with Id = \" + tenantId);\n-            logger.info(\"The tenantKey JSON follows: \\t\\n{\\\"tenantKey\\\": \\\"\" + tenantKey + \"\\\"}\");\n-        } else {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"] with Id = \"\n-                    + tenantId);\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Run a check to make sure that if the tenant already exists its schema\n-     * matches the specified schema. This prevents users from accidentally\n-     * creating a second instance of a tenant in a different schema\n-     */\n-    protected void checkSchemaForTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // only relevant for databases which support multiple tenants within one schema (like Db2)\n-            return;\n-        }\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // Scan over the list to see if the tenant we are working with\n-        // already exists\n-        for (TenantInfo ti : tenants) {\n-            if (ti.getTenantName().equals(this.tenantName)) {\n-                if (ti.getTenantSchema() == null) {\n-                    // The schema is empty so no chance of adding tenants\n-                    throw new IllegalArgumentException(\"Schema '\" + schema.getSchemaName() + \"'\"\n-                            + \" for tenant '\" + ti.getTenantName() + \"'\"\n-                            + \" does not contain a valid IBM FHIR Server schema\");\n-                } else if (!ti.getTenantSchema().equalsIgnoreCase(schema.getSchemaName())) {\n-                    // The given schema name doesn't match where we think this tenant\n-                    // should be located, so throw an error before any damage is done\n-                    throw new IllegalArgumentException(\"--schema-name argument '\" + schema.getSchemaName()\n-                            + \"' does not match schema '\" + ti.getTenantSchema() + \"' for tenant '\"\n-                            + ti.getTenantName() + \"'\");\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Get the list of tenants and the schemas each is currently defined in. Because\n-     * this tenant-schema mapping isn't stored directly, it has to be inferred by\n-     * looking up the schema from one of the tables we know should exist. The schema\n-     * name may therefore be null if the tenant record (in FHIR_ADMIN.TENANTS) exists,\n-     * but all the tables from that schema have been dropped.\n-     *\n-     * @return\n-     */\n-    protected List<TenantInfo> getTenantList() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return Collections.emptyList();\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants;\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                tenants = adapter.runStatement(rtListGetter);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        return tenants;\n-    }\n-\n-    /**\n-     * Make sure all the tables has a partition created for the configured tenant\n-     */\n-    protected void refreshTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // make sure the list is sorted by tenantId. Lambdas really do clean up this sort of code\n-        tenants.sort((TenantInfo left, TenantInfo right) -> left.getTenantId() < right.getTenantId() ? -1 : left.getTenantId() > right.getTenantId() ? 1 : 0);\n-        for (TenantInfo ti : tenants) {\n-            // For issue 1847 we only want to process for the named data schema if one is provided\n-            // If no -schema-name arg is given, we process all tenants.\n-            if (ti.getTenantSchema() != null && (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema()))) {\n-                // It's crucial we use the correct schema for each particular tenant, which\n-                // is why we have to build the PhysicalDataModel separately for each tenant\n-                FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), ti.getTenantSchema(), isMultitenant());\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                gen.buildSchema(pdm);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                pdm.addNewTenantPartitions(adapter, ti.getTenantSchema(), ti.getTenantId());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * List the tenants currently configured\n-     */\n-    protected void listTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                List<TenantInfo> tenants = adapter.runStatement(rtListGetter);\n-\n-                System.out.println(TenantInfo.getHeader());\n-                tenants.forEach(System.out::println);\n-            } catch (UndefinedNameException x) {\n-                System.out.println(\"The FHIR_ADMIN schema appears not to be deployed with the TENANTS table\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Check that we can call the set_tenant procedure successfully (which means\n-     * that the\n-     * tenant record exists in the tenants table)\n-     */\n-    protected void testTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        if (this.tenantName == null || this.tenantName.isEmpty()) {\n-            throw new IllegalStateException(\"Missing tenant name\");\n-        }\n-\n-        // Part of Bring your own Tenant Key\n-        if (tenantKeyFileName != null) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        if (this.tenantKey == null || this.tenantKey.isEmpty()) {\n-            throw new IllegalArgumentException(\"No tenant-key value provided\");\n-        }\n-\n-        logger.info(\"Testing tenant: [\" + tenantName + \"]\");\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // The tenants table, variable and set_tenant procedure are all located in\n-                // the admin schema. The data access user only has execute privileges on the\n-                // set_tenant procedure and read access to the variable. The variable can\n-                // only be set by calling the stored procedure\n-                Db2SetTenantVariable cmd = new Db2SetTenantVariable(schema.getAdminSchemaName(), tenantName, tenantKey);\n-                adapter.runStatement(cmd);\n-\n-                Db2GetTenantVariable getter = new Db2GetTenantVariable(schema.getAdminSchemaName());\n-                Integer tid = adapter.runStatement(getter);\n-                if (tid == null) {\n-                    throw new IllegalStateException(\"SV_TENANT_ID not set!\");\n-                }\n-\n-                // Print the id from the session variable (used for access control)\n-                logger.info(\"tenantName='\" + tenantName + \"', tenantId=\" + tid);\n-\n-                // Now let's check we can run a select against one our tenant-based\n-                // tables\n-                GetResourceTypeList rtListGetter = new GetResourceTypeList(schema.getSchemaName());\n-                List<ResourceType> rtList = adapter.runStatement(rtListGetter);\n-                rtList.forEach(rt -> logger.info(\"ResourceType: \" + rt.toString()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    protected TenantInfo getTenantInfo() {\n-        TenantInfo result;\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                GetTenantInfo command = new GetTenantInfo(schema.getAdminSchemaName(), tenantName);\n-                result = adapter.runStatement(command);\n-\n-                if (result == null) {\n-                    logger.info(\"Use --list-tenants to display the current tenants\");\n-                    throw new IllegalArgumentException(\"Tenant '\" + tenantName + \"' not found in admin schema \" + schema.getAdminSchemaName());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // make sure we set the schema name correctly if it couldn't be found in the database\n-        // (which happens after all the partitions for a particular tenant are detached)\n-        String tenantSchema = result.getTenantSchema();\n-        if (tenantSchema == null || tenantSchema.isEmpty()) {\n-            // the schema can no longer be derived from the database, so we\n-            // need it to be provided on the command line.\n-            if (schema.getSchemaName() == null || schema.getSchemaName().isEmpty()) {\n-                throw new IllegalArgumentException(\"Must provide the tenant schema with --schema-name\");\n-            }\n-            result.setTenantSchema(schema.getSchemaName());\n-        } else {\n-            // if a schema name was provided on the command line, let's double-check it matches\n-            // the schema used for this tenant in the database\n-            if (!tenantSchema.equalsIgnoreCase(schema.getSchemaName())) {\n-                throw new IllegalArgumentException(\"--schema-name '\" + schema.getSchemaName() + \"' argument does not match tenant schema: '\"\n-                        + tenantSchema + \"'\");\n-            }\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Mark the tenant so that it can no longer be accessed (this prevents\n-     * the SET_TENANT method from authenticating the tenantName/tenantKey\n-     * pair, so the SV_TENANT_ID variable never gets set).\n-     *\n-     * @return the TenantInfo associated with the tenant\n-     */\n-    protected TenantInfo freezeTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        TenantInfo result = getTenantInfo();\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        logger.info(\"Marking tenant for drop: \" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                // Mark the tenant as frozen before we proceed with dropping anything\n-                if (result.getTenantStatus() == TenantStatus.ALLOCATED) {\n-                    adapter.updateTenantStatus(schema.getAdminSchemaName(), result.getTenantId(), TenantStatus.FROZEN);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return result;\n-    }\n-\n-    /**\n-     * Deallocate this tenant, dropping all the related partitions. This needs to be\n-     * idempotent because there are steps which must be run in separate transactions\n-     * (due to how Db2 handles detaching partitions). This is further complicated by\n-     * referential integrity constraints in the schema. See:\n-     * - https://www.ibm.com/support/knowledgecenter/SSEPGG_11.5.0/com.ibm.db2.luw.admin.partition.doc/doc/t0021576.html\n-     *\n-     * The workaround described in the above link is:\n-     * // Change the RI constraint to informational:\n-     * 1. ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     *\n-     * 2. ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     *\n-     * 3. SET INTEGRITY FOR child OFF;\n-     *\n-     * // Change the RI constraint back to enforced:\n-     * 4. ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     *\n-     * 5. SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     * 6. Assuming that the CHILD table does not have any dependencies on partition P0,\n-     * 7. and that no updates on the CHILD table are permitted until this UOW is complete,\n-     * no RI violation is possible during this UOW.\n-     *\n-     * COMMIT WORK;\n-     *\n-     * Unfortunately, #7 above essentially requires that all writes cease until the\n-     * UOW is completed and the integrity is enabled again on all the child (leaf)\n-     * tables. Of course, this could be relaxed if the application is trusted not\n-     * to mess up the referential integrity...which we know to be true for the\n-     * FHIR server persistence layer.\n-     *\n-     * If the risk is deemed too high, tenant removal should be performed in a\n-     * maintenance window.\n-     */\n-    protected void dropTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Mark the tenant as being dropped. This should prevent it from\n-        // being used in any way because the SET_TENANT stored procedure\n-        // will reject any request for the tenant being dropped.\n-        TenantInfo tenantInfo = freezeTenant();\n-\n-        // Build the model of the data (FHIRDATA) schema which is then used to drive the drop\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Detach the tenant partition from each of the data tables\n-        detachTenantPartitions(pdm, tenantInfo);\n-\n-        // this may not complete successfully because Db2 runs the detach as an async\n-        // process. Just need to run --drop-detached to clean up.\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. The detach process is asynchronous,\n-     * so this is a sort of garbage collection, sweeping up cruft left in the database.\n-     */\n-    protected void dropDetachedPartitionTables() {\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. Once all tables have been\n-     * dropped, we go on to drop the tablespace. If the tablespace drop is successful,\n-     * we know the cleanup is complete so we can update the tenant status accordingly\n-     *\n-     * @param pdm\n-     * @param tenantInfo\n-     */\n-    protected void dropDetachedPartitionTables(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        // In a new transaction, drop any of the tables that were created by\n-        // the partition detach operation.\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                pdm.dropDetachedPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // We can drop the tenant's tablespace only after all the table drops have been committed\n-        logger.info(\"Dropping tablespace for tenant \" + tenantInfo.getTenantId() + \"/\" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            boolean retry = true;\n-            int wait = 0;\n-            while (retry) {\n-                try {\n-                    retry = false;\n-                    // With all the objects removed, it should be safe to remove the tablespace\n-                    pdm.dropTenantTablespace(adapter, tenantInfo.getTenantId());\n-                } catch (DataAccessException x) {\n-                    boolean error = x instanceof DataAccessException && x.getCause() instanceof SQLException\n-                            && (((SQLException) x.getCause()).getErrorCode() == -282);\n-                    if (error && wait++ <= 30) {\n-                        retry = true;\n-                        logger.warning(\"Waiting on async dettach dependency to finish - count '\" + wait + \"'\");\n-                        try {\n-                            Thread.sleep(2000);\n-                        } catch (InterruptedException e) {\n-                            throw new DataAccessException(e);\n-                        }\n-                    } else if (error) {\n-                        throw new TableSpaceRemovalException(x.getCause());\n-                    } else {\n-                        // Something went wrong, so mark the transaction as failed\n-                        tx.setRollbackOnly();\n-                        throw x;\n-                    }\n-                }\n-            }\n-        }\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as dropped\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantInfo.getTenantId(), TenantStatus.DROPPED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Temporarily suspend RI so that tables which are the subject of foreign\n-     * key relationships can have their partitions dropped. A bit frustrating\n-     * to have to go through this, because the child table partition will be\n-     * detached before the parent anyway, so theoretically this workaround\n-     * shouldn't be necessary.\n-     * ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     * ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     * SET INTEGRITY FOR child OFF;\n-     * ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     * SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     */\n-    protected void detachTenantPartitions(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // collect the set of all child tables with FK relationships to\n-                // partitioned tables\n-                Set<Table> childTables = new HashSet<>();\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-                pdm.visit(new DisableForeignKey(adapter, childTables));\n-\n-                // ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-                pdm.detachTenantPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-\n-                // SET INTEGRITY FOR child OFF;\n-                childTables.forEach(t -> adapter.setIntegrityOff(t.getSchemaName(), t.getObjectName()));\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-                pdm.visit(new EnableForeignKey(adapter));\n-\n-                // SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-                childTables.forEach(t -> adapter.setIntegrityUnchecked(t.getSchemaName(), t.getObjectName()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * Delete all the metadata associated with the named tenant.\n-     */\n-    protected void deleteTenantMeta() {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        TenantInfo tenantInfo = getTenantInfo();\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                if (tenantInfo.getTenantStatus() == TenantStatus.DROPPED) {\n-                    adapter.deleteTenantMeta(schema.getAdminSchemaName(), tenantInfo.getTenantId());\n-                } else {\n-                    throw new IllegalStateException(\"Cannot delete tenant meta data until status is \" + TenantStatus.DROPPED.name());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * revokes a tenant key or if no tenant key is specified remove all of them for the\n-     * given tenant.\n-     */\n-    protected void revokeTenantKey() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        int tenantId = tenantInfo.getTenantId();\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                DeleteTenantKeyDAO dtk = new DeleteTenantKeyDAO(schema.getAdminSchemaName(), tenantId, tenantKey);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                adapter.runStatement(dtk);\n-                int count = dtk.getCount();\n-                logger.info(\"Tenant Key revoked for '\" + tenantInfo.getTenantName() + \"' total removed=[\" + count + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to parsing arguments and action selection\n-    /**\n-     * Parse the command-line arguments, building up the environment and\n-     * establishing\n-     * the run-list\n-     *\n-     * @param args\n-     */\n-    protected void parseArgs(String[] args) {\n-        // Arguments are pretty simple, so we go with a basic switch instead of having\n-        // yet another dependency (e.g. commons-cli).\n-        LeaseManagerConfig.Builder lmConfig = LeaseManagerConfig.builder();\n-        lmConfig.withHost(new HostnameHandler().getHostname());\n-        lmConfig.withLeaseTimeSeconds(100); // default\n-        lmConfig.withStayAlive(true);       // default\n-        \n-        for (int i = 0; i < args.length; i++) {\n-            int nextIdx = (i + 1);\n-            String arg = args[i];\n-            switch (arg) {\n-            case \"--prop-file\":\n-                if (++i < args.length) {\n-                    loadPropertyFile(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--schema-name\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    schema.setSchemaName(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--grant-to\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-\n-                    // Force upper-case because user names are case-insensitive\n-                    this.grantTo = args[i].toUpperCase();\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--target\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    List<String> targets = Arrays.asList(args[i].split(\",\"));\n-                    for (String target : targets) {\n-                        String tmp = target.toUpperCase();\n-                        nextIdx++;\n-                        if (tmp.startsWith(\"BATCH\")) {\n-                            this.grantJavaBatchSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setJavaBatchSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"OAUTH\")) {\n-                            this.grantOauthSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setOauthSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"DATA\")) {\n-                            this.grantFhirSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else {\n-                            throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                        }\n-                    }\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--add-tenant-key\":\n-                if (++i < args.length) {\n-                    this.addKeyForTenant = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--revoke-tenant-key\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeTenantKey = true;\n-                break;\n-            case \"--revoke-all-tenant-keys\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeAllTenantKeys = true;\n-                break;\n-            case \"--update-proc\":\n-                this.updateProc = true;\n-                break;\n-            case \"--check-compatibility\":\n-                this.checkCompatibility = true;\n-                break;\n-            case \"--drop-admin\":\n-                this.dropAdmin = true;\n-                break;\n-            case \"--test-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.testTenant = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key\":\n-                if (++i < args.length) {\n-                    this.tenantKey = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key-file\":\n-                if (++i < args.length) {\n-                    tenantKeyFileName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--list-tenants\":\n-                this.listTenants = true;\n-                break;\n-            case \"--update-schema\":\n-                this.updateFhirSchema = true;\n-                this.updateOauthSchema = true;\n-                this.updateJavaBatchSchema = true;\n-                break;\n-            case \"--update-schema-fhir\":\n-                this.updateFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                } else {\n-                    schema.setSchemaName(DATA_SCHEMANAME);\n-                }\n-                break;\n-            case \"--update-schema-batch\":\n-                this.updateJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--update-schema-oauth\":\n-                this.updateOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schemas\":\n-                this.createFhirSchema = true;\n-                this.createOauthSchema = true;\n-                this.createJavaBatchSchema = true;\n-                break;\n-            case \"--create-schema-fhir\":\n-                this.createFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-batch\":\n-                this.createJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-oauth\":\n-                this.createOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema\":\n-                System.err.print(\"Option '--drop-schema' has been retired.  Please use '--drop-schema-fhir', \"\n-                        + \"'--drop-schema-batch', and/or '--drop-schema-oauth'.\");\n-                break;\n-            case \"--drop-schema-fhir\":\n-                this.dropFhirSchema = Boolean.TRUE;\n-                break;\n-            case \"--drop-schema-batch\":\n-                this.dropJavaBatchSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema-oauth\":\n-                this.dropOauthSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--pool-size\":\n-                if (++i < args.length) {\n-                    this.maxConnectionPoolSize = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--prop\":\n-                if (++i < args.length) {\n-                    // properties are given as name=value\n-                    addProperty(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--update-vacuum\":\n-                updateVacuum = true;\n-                break;\n-            case \"--vacuum-cost-limit\":\n-                if (++i < args.length) {\n-                    this.vacuumCostLimit = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-threshold\":\n-                if (++i < args.length) {\n-                    this.vacuumThreshold = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-scale-factor\":\n-                if (++i < args.length) {\n-                    this.vacuumScaleFactor = Double.parseDouble(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-table-name\":\n-                if (++i < args.length) {\n-                    this.vacuumTableName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--confirm-drop\":\n-                this.confirmDrop = true;\n-                break;\n-            case \"--allocate-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.allocateTenant = true;\n-                    this.dropTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--refresh-tenants\":\n-                this.refreshTenants = true;\n-                this.allocateTenant = false;\n-                this.dropTenant = false;\n-                break;\n-            case \"--drop-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropTenant = true;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--freeze-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.freezeTenant = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--drop-detached\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropDetached = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--delete-tenant-meta\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.deleteTenantMeta = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--db-type\":\n-                if (++i < args.length) {\n-                    this.dbType = DbType.from(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                switch (dbType) {\n-                case DERBY:\n-                    translator = new DerbyTranslator();\n-                    break;\n-                case POSTGRESQL:\n-                    translator = new PostgresTranslator();\n-                    break;\n-                case DB2:\n-                default:\n-                    break;\n-                }\n-                break;\n-            // Skips the allocateTenant action if the tenant exists (e.g. a shortcircuit)\n-            case \"--skip-allocate-if-tenant-exists\":\n-                skipIfTenantExists = true;\n-                break;\n-            default:\n-                throw new IllegalArgumentException(\"Invalid argument: '\" + arg + \"'\");\n-            }\n-        }\n-        \n-        this.leaseManagerConfig = lmConfig.build();\n-    }\n-\n-    /**\n-     * Read the properties from the given file\n-     *\n-     * @param filename\n-     */\n-    public void loadPropertyFile(String filename) {\n-        try (InputStream is = new FileInputStream(filename)) {\n-            properties.load(is);\n-            // Trim leading and trailing whitespace from property values (except password)\n-            for (Entry<Object, Object> entry : properties.entrySet()) {\n-                if (!\"password\".equals(entry.getKey())) {\n-                    String trimmedValue = entry.getValue().toString().trim();\n-                    if (!trimmedValue.equals(entry.getValue().toString())) {\n-                        logger.warning(\"Whitespace trimmed from value of property '\" + entry.getKey() + \"'\");\n-                        entry.setValue(trimmedValue);\n-                    }\n-                }\n-            }\n-        } catch (IOException x) {\n-            throw new IllegalArgumentException(x);\n-        }\n-    }\n-\n-    /**\n-     * Parse the given key=value string and add to the properties being collected\n-     *\n-     * @param pair\n-     */\n-    public void addProperty(String pair) {\n-        String[] kv = pair.split(\"=\");\n-        if (kv.length == 2) {\n-            // Trim leading and trailing whitespace from property value (except password)\n-            if (!\"password\".equals(kv[0])) {\n-                String trimmedValue = kv[1].trim();\n-                if (!trimmedValue.equals(kv[1])) {\n-                    logger.warning(\"Whitespace trimmed from value of property '\" + kv[0] + \"'\");\n-                }\n-                properties.put(kv[0], trimmedValue);\n-            } else {\n-                properties.put(kv[0], kv[1]);\n-            }\n-        } else {\n-            throw new IllegalArgumentException(\"Property must be defined as key=value, not: \" + pair);\n-        }\n-    }\n-\n-    /**\n-     * Perform the special data migration steps required for the V0010 version of the schema\n-     */\n-    protected void applyDataMigrationForV0010() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0010(ti);\n-                }\n-            }\n-        } else {\n-            doMigrationForV0010();\n-        }\n-    }\n-\n-    protected void applyDataMigrationForV0014() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0014(ti);\n-                }\n-            }\n-        } else {\n-            dataMigrationForV0014();\n-        }\n-    }\n-\n-    /**\n-     * Get the list of resource types to drive resource-by-resource operations\n-     *\n-     * @return the full list of FHIR R4 resource types, or a subset of names if so configured\n-     */\n-    private Set<String> getResourceTypes() {\n-        Set<String> result;\n-        if (this.resourceTypeSubset == null || this.resourceTypeSubset.isEmpty()) {\n-            // pass 'false' to getResourceTypes to avoid building tables for abstract resource types\n-            // Should simplify FhirSchemaGenerator and always pass in this list. When switching\n-            // over to false, migration is required to drop the tables no longer required.\n-            final boolean includeAbstractResourceTypes = true;\n-            result = ModelSupport.getResourceTypes(includeAbstractResourceTypes).stream().map(Class::getSimpleName).collect(Collectors.toSet());\n-        } else {\n-            result = this.resourceTypeSubset;\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Get the list of resource types from the database.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @return\n-     */\n-    private List<ResourceType> getResourceTypesList(IDatabaseAdapter adapter, String schemaName) {\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetResourceTypeList cmd = new GetResourceTypeList(schemaName);\n-                return adapter.runStatement(cmd);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the IS_DELETED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0010(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each update in its own transaction so we don't stress the tx log space\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES.IS_DELETED \"\n-                                + \"for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Perform the data migration for V0010 (non-multi-tenant schema)\n-     */\n-    private void doMigrationForV0010() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    // only process tables which have been converted to the V0010 schema but\n-                    // which have not yet had their data migrated. The migration can't be\n-                    // done as part of the schema change because some tables need a REORG which\n-                    // has to be done after the transaction in which the alter table was performed.\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010-V0012 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES denormalized columns in schema \"\n-                                + schema.getSchemaName());\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0014(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each update in its own transaction so we don't over-stress the tx log space\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    logger.info(\"V0014 Migration: Updating \" + \"LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for \" + resourceType.toString()\n-                            + \" for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-\n-                    dataMigrationForV0014(adapter, ti.getTenantSchema(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data\n-     */\n-    private void dataMigrationForV0014() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    dataMigrationForV0014(adapter, schema.getSchemaName(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * only process tables which have not yet had their data migrated. The migration can't be\n-     * done as part of the schema change because some tables need a REORG which\n-     * has to be done after the transaction in which the alter table was performed.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @param resourceType\n-     */\n-    private void dataMigrationForV0014(IDatabaseAdapter adapter, String schemaName, ResourceType resourceType) {\n-        GetLogicalResourceNeedsV0014Migration needsMigrating = new GetLogicalResourceNeedsV0014Migration(schemaName, resourceType.getId());\n-        if (adapter.runStatement(needsMigrating)) {\n-            logger.info(\"V0014 Migration: Updating LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for schema '\"\n-                    + schemaName + \"' and resource type '\" + resourceType.toString() + \"'\");\n-            MigrateV0014LogicalResourceIsDeletedLastUpdated cmd =\n-                    new MigrateV0014LogicalResourceIsDeletedLastUpdated(schemaName, resourceType.getName(), resourceType.getId());\n-            adapter.runStatement(cmd);\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table if it is empty\n-     */\n-    protected void backfillResourceChangeLog() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    backfillResourceChangeLogDb2(ti);\n-                }\n-            }\n-        } else {\n-            // Not a multi-tenant database, so we only have to do this once\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                    if (adapter.runStatement(isEmpty)) {\n-                        // change log is empty, so we need to backfill it with data\n-                        doBackfill(adapter);\n-                    } else {\n-                        logger.info(\"RESOURCE_CHANGE_LOG has data so skipping backfill\");\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * backfill the resource_change_log table if it is empty\n-     */\n-    protected void backfillResourceChangeLogDb2(TenantInfo ti) {\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                adapter.runStatement(setTenantId);\n-\n-                GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                if (adapter.runStatement(isEmpty)) {\n-                    // change log is empty, so we need to backfill it with data\n-                    for (String resourceTypeName : resourceTypes) {\n-                        logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                                + \" resources for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        BackfillResourceChangeLogDb2 backfill = new BackfillResourceChangeLogDb2(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(backfill);\n-                    }\n-                } else {\n-                    logger.info(\"RESOURCE_CHANGE_LOG has data for tenant '\" + ti.getTenantName() + \"' so skipping backfill\");\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table for all the resource types. Non-multi-tenant\n-     * implementation\n-     *\n-     * @param adapter\n-     */\n-    private void doBackfill(IDatabaseAdapter adapter) {\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        for (String resourceTypeName : resourceTypes) {\n-            logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                    + \" resources for schema '\" + schema.getSchemaName() + \"'\");\n-            BackfillResourceChangeLog backfill = new BackfillResourceChangeLog(schema.getSchemaName(), resourceTypeName);\n-            adapter.runStatement(backfill);\n-        }\n-    }\n-\n-    /**\n-     * updates the vacuum settings for postgres.\n-     */\n-    public void updateVacuumSettings() {\n-        if (dbType != DbType.POSTGRESQL) {\n-            logger.severe(\"Updating the vacuum settings is only supported on postgres and the setting is for '\" + dbType + \"'\");\n-            return;\n-        }\n-\n-        // Create the Physical Data Model\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, true, false, false);\n-\n-        // Setup the Connection Pool\n-        this.maxConnectionPoolSize = 10;\n-        configureConnectionPool();\n-        PostgresAdapter adapter = new PostgresAdapter(connectionPool);\n-\n-        if (vacuumTableName != null) {\n-            runSingleTable(adapter, pdm, schema.getSchemaName(), vacuumTableName);\n-        } else {\n-            // Process all tables in the schema ... except for XX_RESOURCES and COMMON_TOKEN_VALUES and COMMON_CANONICAL_VALUES\n-            GatherTablesDataModelVisitor visitor = new GatherTablesDataModelVisitor();\n-            pdm.visit(visitor);\n-\n-            for (Table tbl : visitor.getTables()) {\n-                runSingleTable(adapter, pdm, schema.getSchemaName(), tbl.getObjectName());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * runs the vacuum update inside a single connection and single transaction.\n-     *\n-     * @param adapter\n-     * @param pdm\n-     * @param schemaName\n-     * @param vacuumTableName\n-     */\n-    private void runSingleTable(PostgresAdapter adapter, PhysicalDataModel pdm, String schemaName, String vacuumTableName) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // If the vacuumTableName exists, then we try finding the table definition.\n-                Table table = pdm.findTable(schemaName, vacuumTableName);\n-                if (table == null) {\n-                    logger.severe(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                    throw new IllegalArgumentException(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                }\n-                PostgresVacuumSettingDAO alterVacuumSettings =\n-                        new PostgresVacuumSettingDAO(schemaName, table.getObjectName(), vacuumCostLimit, vacuumScaleFactor, vacuumThreshold);\n-                adapter.runStatement(alterVacuumSettings);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Process the requested operation\n-     */\n-    protected void process() {\n-        long start = System.nanoTime();\n-        loadDriver(translator);\n-        configureConnectionPool();\n-\n-        if (this.checkCompatibility) {\n-            checkCompatibility();\n-        }\n-\n-        if (translator.isDerby() && !\"APP\".equals(schema.getSchemaName())) {\n-            if (schema.isOverrideDataSchema()) {\n-                logger.warning(\"Only the APP schema is supported for Apache Derby; ignoring the passed\"\n-                        + \" schema name '\" + schema.getSchemaName() + \"' and using APP.\");\n-            }\n-            schema.setSchemaName(\"APP\");\n-        }\n-\n-        // [optional] use a subset of resource types to make testing quicker\n-        String resourceTypesString = properties.getProperty(\"resourceTypes\");\n-        if (resourceTypesString != null && resourceTypesString.length() > 0) {\n-            resourceTypeSubset = new HashSet<>(Arrays.asList(resourceTypesString.split(\",\")));\n-        }\n-\n-        if (addKeyForTenant != null) {\n-            addTenantKey();\n-        } else if (updateVacuum) {\n-            updateVacuumSettings();\n-        } else if (this.dropAdmin || this.dropFhirSchema || this.dropJavaBatchSchema || this.dropOauthSchema) {\n-            // only proceed with the drop if the user has provided additional confirmation\n-            if (this.confirmDrop) {\n-                dropSchema();\n-            } else {\n-                throw new IllegalArgumentException(\"[ERROR] Drop not confirmed with --confirm-drop\");\n-            }\n-        } else if (updateFhirSchema || updateOauthSchema || updateJavaBatchSchema) {\n-            updateSchemas();\n-        } else if (createFhirSchema || createOauthSchema || createJavaBatchSchema) {\n-            createSchemas();\n-        } else if (updateProc) {\n-            updateProcedures();\n-        } else if (grantTo != null) {\n-            grantPrivileges();\n-        } else if (this.listTenants) {\n-            listTenants();\n-        } else if (this.allocateTenant) {\n-            allocateTenant();\n-        } else if (this.refreshTenants) {\n-            refreshTenants();\n-        } else if (this.testTenant) {\n-            testTenant();\n-        } else if (this.freezeTenant) {\n-            freezeTenant();\n-        } else if (this.dropDetached) {\n-            dropDetachedPartitionTables();\n-        } else if (this.deleteTenantMeta) {\n-            deleteTenantMeta();\n-        } else if (this.dropTenant) {\n-            dropTenant();\n-        } else if (this.revokeTenantKey) {\n-            revokeTenantKey();\n-        } else if (this.revokeAllTenantKeys) {\n-            if (this.tenantKey != null) {\n-                throw new IllegalArgumentException(\"[ERROR] --tenant-key <key-value> should not be specified together with --drop-all-tenant-keys\");\n-            }\n-            revokeTenantKey();\n-        }\n-\n-        long elapsed = System.nanoTime() - start;\n-        logger.info(String.format(\"Processing took: %7.3f s\", elapsed / NANOS));\n-    }\n-\n-    /**\n-     * Get the program exit status from the environment\n-     *\n-     * @return\n-     */\n-    protected int getExitStatus() {\n-        return this.exitStatus;\n-    }\n-\n-    /**\n-     * Write a final status message - useful for QA to review when checking the\n-     * output\n-     */\n-    protected void logStatusMessage(int status) {\n-        switch (status) {\n-        case EXIT_OK:\n-            logger.info(\"SCHEMA CHANGE: OK\");\n-            break;\n-        case EXIT_BAD_ARGS:\n-            logger.severe(\"SCHEMA CHANGE: BAD ARGS\");\n-            break;\n-        case EXIT_RUNTIME_ERROR:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        case EXIT_VALIDATION_FAILED:\n-            logger.warning(\"SCHEMA CHANGE: FAILED\");\n-            break;\n-        default:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        }\n-    }\n-\n-    /**\n-     * Log warning messages for deprecated tables.\n-     */\n-    private void logWarningMessagesForDeprecatedTables() {\n-        List<String> deprecatedTables =\n-                Arrays.asList(\"DOMAINRESOURCE_DATE_VALUES\", \"DOMAINRESOURCE_LATLNG_VALUES\", \"DOMAINRESOURCE_LOGICAL_RESOURCES\", \"DOMAINRESOURCE_NUMBER_VALUES\", \"DOMAINRESOURCE_QUANTITY_VALUES\", \"DOMAINRESOURCE_RESOURCE_TOKEN_REFS\", \"DOMAINRESOURCE_RESOURCES\", \"DOMAINRESOURCE_STR_VALUES\", \"RESOURCE_DATE_VALUES\", \"RESOURCE_LATLNG_VALUES\", \"RESOURCE_LOGICAL_RESOURCES\", \"RESOURCE_NUMBER_VALUES\", \"RESOURCE_QUANTITY_VALUES\", \"RESOURCE_RESOURCE_TOKEN_REFS\", \"RESOURCE_RESOURCES\", \"RESOURCE_STR_VALUES\");\n-        for (String deprecatedTable : deprecatedTables) {\n-            logger.warning(\"Table '\" + deprecatedTable\n-                    + \"' will be dropped in a future release. No data should be written to this table. If any data exists in the table, that data should be deleted.\");\n-        }\n-    }\n-\n-    /**\n-     * Main entry point\n-     *\n-     * @param args\n-     */\n-    public static void main(String[] args) {\n-        logClasspath(logger);\n-\n-        int exitStatus;\n-        Main m = new Main();\n-        try {\n-            configureLogger();\n-            m.parseArgs(args);\n-            m.process();\n-            exitStatus = m.getExitStatus();\n-        } catch (TableSpaceRemovalException x) {\n-            logger.warning(\"Tablespace removal is not complete, as an async dependency has not finished dettaching. Please re-try.\");\n-            exitStatus = EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE;\n-        } catch (ConcurrentUpdateException x) {\n-            logger.log(Level.WARNING, \"Update is already running. Please re-try later.\", x);\n-            exitStatus = EXIT_CONCURRENT_UPDATE;\n-        } catch (DatabaseNotReadyException x) {\n-            logger.log(Level.SEVERE, \"The database is not yet available. Please re-try.\", x);\n-            exitStatus = EXIT_NOT_READY;\n-        } catch (IllegalArgumentException x) {\n-            logger.log(Level.SEVERE, \"bad argument\", x);\n-            printUsage();\n-            exitStatus = EXIT_BAD_ARGS;\n-        } catch (Exception x) {\n-            logger.log(Level.SEVERE, \"schema tool failed\", x);\n-            exitStatus = EXIT_RUNTIME_ERROR;\n-        }\n-\n-        // Write out a final status message to make it easy to see validation success/failure\n-        m.logStatusMessage(exitStatus);\n-\n-        // almost certainly will get flagged during code-scan, but this is intentional,\n-        // as we genuinely want to exit with the correct status here. The code-scan tool\n-        // really ought to be able to see that this is a main function in a J2SE environment\n-        System.exit(exitStatus);\n-    }\n-}\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex 3c4c21c031..ba15a28613 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -474,7 +580,7 @@ public class Main {\n         }\n     }\n \n-    //-----------------------------------------------------------------------------------------------------------------\n+    // -----------------------------------------------------------------------------------------------------------------\n     // The following method is related to the Privilege feature\n     /**\n      * Grant the minimum required set of privileges on the FHIR schema objects\n", "next_change": {"commit": "afceaba4a867a0af38a6cb431245b8b1854b9f74", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex ba15a28613..eff8be1420 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -580,6 +749,28 @@ public class Main {\n         }\n     }\n \n+    /**\n+     * Build a common PhysicalDataModel containing all the requested schemas\n+     * \n+     * @param pdm the model to construct\n+     * @param addFhirDataSchema include objects for the FHIR data schema\n+     * @param addOAuthSchema include objects for the Liberty OAuth schema\n+     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n+     */\n+    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n+        if (addFhirDataSchema) {\n+            buildFhirDataSchemaModel(pdm);\n+        }\n+        \n+        if (addOAuthSchema) {\n+            buildOAuthSchemaModel(pdm);\n+        }\n+        \n+        if (addJavaBatchSchema) {\n+            buildJavaBatchSchemaModel(pdm);\n+        }\n+    }\n+\n     // -----------------------------------------------------------------------------------------------------------------\n     // The following method is related to the Privilege feature\n     /**\n", "next_change": {"commit": "652c689992b6da38f3904766b4dfae672f23826a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\nindex eff8be1420..f38f98eed9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n", "chunk": "@@ -771,8 +804,67 @@ public class Main {\n         }\n     }\n \n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Privilege feature\n+    /**\n+     * Apply grants to the FHIR data schema objects\n+     */\n+    protected void grantPrivilegesForFhirData() {\n+\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildFhirDataSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+                \n+                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n+                // Note the constant comes from SchemaConstants on purpose\n+                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Apply grants to the OAuth schema objects\n+     */\n+    protected void grantPrivilegesForOAuth() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildOAuthSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n+                \n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+        \n+    }\n+\n+    /**\n+     * Apply grants to the JavaBatch schema objects\n+     */\n+    protected void grantPrivilegesForBatch() {\n+        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n+        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n+            try {\n+                PhysicalDataModel pdm = new PhysicalDataModel();\n+                buildJavaBatchSchemaModel(pdm);\n+                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n+            } catch (DataAccessException x) {\n+                // Something went wrong, so mark the transaction as failed\n+                tx.setRollbackOnly();\n+                throw x;\n+            }\n+        }\n+    }\n+\n     /**\n      * Grant the minimum required set of privileges on the FHIR schema objects\n      * to the grantTo user. All tenant data access is via this user, and is the\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\ndeleted file mode 100644\nindex f38f98eed9..0000000000\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/app/Main.java\n+++ /dev/null\n", "chunk": "@@ -1,2526 +0,0 @@\n-/*\n- * (C) Copyright IBM Corp. 2019, 2021\n- *\n- * SPDX-License-Identifier: Apache-2.0\n- */\n-\n-package com.ibm.fhir.schema.app;\n-\n-import static com.ibm.fhir.schema.app.util.CommonUtil.configureLogger;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getDbAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getPropertyAdapter;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.getRandomKey;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.loadDriver;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.logClasspath;\n-import static com.ibm.fhir.schema.app.util.CommonUtil.printUsage;\n-\n-import java.io.FileInputStream;\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.sql.Connection;\n-import java.sql.DriverManager;\n-import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map.Entry;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.logging.Level;\n-import java.util.logging.Logger;\n-import java.util.stream.Collectors;\n-\n-import com.ibm.fhir.core.util.handler.HostnameHandler;\n-import com.ibm.fhir.database.utils.api.DataAccessException;\n-import com.ibm.fhir.database.utils.api.DatabaseNotReadyException;\n-import com.ibm.fhir.database.utils.api.IDatabaseAdapter;\n-import com.ibm.fhir.database.utils.api.IDatabaseTranslator;\n-import com.ibm.fhir.database.utils.api.ITransaction;\n-import com.ibm.fhir.database.utils.api.ITransactionProvider;\n-import com.ibm.fhir.database.utils.api.TableSpaceRemovalException;\n-import com.ibm.fhir.database.utils.api.TenantStatus;\n-import com.ibm.fhir.database.utils.api.UndefinedNameException;\n-import com.ibm.fhir.database.utils.common.DataDefinitionUtil;\n-import com.ibm.fhir.database.utils.common.JdbcConnectionProvider;\n-import com.ibm.fhir.database.utils.common.JdbcPropertyAdapter;\n-import com.ibm.fhir.database.utils.common.JdbcTarget;\n-import com.ibm.fhir.database.utils.db2.Db2Adapter;\n-import com.ibm.fhir.database.utils.db2.Db2GetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2SetTenantVariable;\n-import com.ibm.fhir.database.utils.db2.Db2Translator;\n-import com.ibm.fhir.database.utils.derby.DerbyTranslator;\n-import com.ibm.fhir.database.utils.model.DatabaseObjectType;\n-import com.ibm.fhir.database.utils.model.DbType;\n-import com.ibm.fhir.database.utils.model.PhysicalDataModel;\n-import com.ibm.fhir.database.utils.model.Table;\n-import com.ibm.fhir.database.utils.model.Tenant;\n-import com.ibm.fhir.database.utils.pool.PoolConnectionProvider;\n-import com.ibm.fhir.database.utils.postgres.GatherTablesDataModelVisitor;\n-import com.ibm.fhir.database.utils.postgres.PostgresAdapter;\n-import com.ibm.fhir.database.utils.postgres.PostgresTranslator;\n-import com.ibm.fhir.database.utils.postgres.PostgresVacuumSettingDAO;\n-import com.ibm.fhir.database.utils.tenant.AddTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.DeleteTenantKeyDAO;\n-import com.ibm.fhir.database.utils.tenant.GetTenantDAO;\n-import com.ibm.fhir.database.utils.transaction.SimpleTransactionProvider;\n-import com.ibm.fhir.database.utils.transaction.TransactionFactory;\n-import com.ibm.fhir.database.utils.version.CreateControl;\n-import com.ibm.fhir.database.utils.version.CreateWholeSchemaVersion;\n-import com.ibm.fhir.database.utils.version.SchemaConstants;\n-import com.ibm.fhir.database.utils.version.CreateVersionHistory;\n-import com.ibm.fhir.database.utils.version.VersionHistoryService;\n-import com.ibm.fhir.model.util.ModelSupport;\n-import com.ibm.fhir.schema.api.ConcurrentUpdateException;\n-import com.ibm.fhir.schema.api.ILeaseManagerConfig;\n-import com.ibm.fhir.schema.app.util.TenantKeyFileUtil;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLog;\n-import com.ibm.fhir.schema.control.BackfillResourceChangeLogDb2;\n-import com.ibm.fhir.schema.control.DisableForeignKey;\n-import com.ibm.fhir.schema.control.DropForeignKey;\n-import com.ibm.fhir.schema.control.EnableForeignKey;\n-import com.ibm.fhir.schema.control.FhirSchemaConstants;\n-import com.ibm.fhir.schema.control.FhirSchemaGenerator;\n-import com.ibm.fhir.schema.control.GetLogicalResourceNeedsV0014Migration;\n-import com.ibm.fhir.schema.control.GetResourceChangeLogEmpty;\n-import com.ibm.fhir.schema.control.GetResourceTypeList;\n-import com.ibm.fhir.schema.control.GetTenantInfo;\n-import com.ibm.fhir.schema.control.GetTenantList;\n-import com.ibm.fhir.schema.control.GetXXLogicalResourceNeedsMigration;\n-import com.ibm.fhir.schema.control.InitializeLogicalResourceDenorms;\n-import com.ibm.fhir.schema.control.JavaBatchSchemaGenerator;\n-import com.ibm.fhir.schema.control.MigrateV0014LogicalResourceIsDeletedLastUpdated;\n-import com.ibm.fhir.schema.control.OAuthSchemaGenerator;\n-import com.ibm.fhir.schema.control.PopulateParameterNames;\n-import com.ibm.fhir.schema.control.PopulateResourceTypes;\n-import com.ibm.fhir.schema.control.SetTenantIdDb2;\n-import com.ibm.fhir.schema.control.TenantInfo;\n-import com.ibm.fhir.schema.model.ResourceType;\n-import com.ibm.fhir.schema.model.Schema;\n-import com.ibm.fhir.task.api.ITaskCollector;\n-import com.ibm.fhir.task.api.ITaskGroup;\n-import com.ibm.fhir.task.core.service.TaskService;\n-\n-/**\n- * Utility app to connect to a database and create/update the IBM FHIR Server schema.\n- * The DDL processing is idempotent, with only the necessary changes applied.\n- * <br>\n- * This utility also includes an option to exercise the tenant partitioning code.\n- */\n-public class Main {\n-\n-    private static final Logger logger = Logger.getLogger(Main.class.getName());\n-    private static final int EXIT_OK = 0; // validation was successful\n-    private static final int EXIT_BAD_ARGS = 1; // invalid CLI arguments\n-    private static final int EXIT_RUNTIME_ERROR = 2; // programming error\n-    private static final int EXIT_VALIDATION_FAILED = 3; // validation test failed\n-    private static final int EXIT_NOT_READY = 4; // DATABASE NOT READY\n-    private static final int EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE = 5; // Tablespace Removal not complete\n-    private static final int EXIT_CONCURRENT_UPDATE = 6; // Another schema update is running and the wait time expired\n-    private static final double NANOS = 1e9;\n-\n-    // Indicates if the feature is enabled for the DbType\n-    public List<DbType> MULTITENANT_FEATURE_ENABLED = Arrays.asList(DbType.DB2);\n-    public List<DbType> STORED_PROCEDURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-    public List<DbType> PRIVILEGES_FEATURE_ENABLED = Arrays.asList(DbType.DB2, DbType.POSTGRESQL);\n-\n-    // Properties accumulated as we parse args and read configuration files\n-    private final Properties properties = new Properties();\n-\n-    // Default Values for schema names\n-    public static final String ADMIN_SCHEMANAME = \"FHIR_ADMIN\";\n-    public static final String OAUTH_SCHEMANAME = \"FHIR_OAUTH\";\n-    public static final String BATCH_SCHEMANAME = \"FHIR_JBATCH\";\n-    public static final String DATA_SCHEMANAME = \"FHIRDATA\";\n-\n-    // Force upper-case to avoid tricky-to-catch errors related to quoting names\n-    private Schema schema = new Schema();\n-\n-    // Arguments requesting we drop the objects from the schema\n-    private boolean dropAdmin = false;\n-    private boolean confirmDrop = false;\n-    private boolean updateProc = false;\n-    private boolean checkCompatibility = false;\n-\n-    // Action flags related to FHIR Schema\n-    private boolean createFhirSchema = false;\n-    private boolean updateFhirSchema = false;\n-    private boolean dropFhirSchema = false;\n-    private boolean grantFhirSchema = false;\n-\n-    // Action flags related to OAuth Schema\n-    private boolean createOauthSchema = false;\n-    private boolean updateOauthSchema = false;\n-    private boolean dropOauthSchema = false;\n-    private boolean grantOauthSchema = false;\n-\n-    // Action flags related to Java Batch Schema\n-    private boolean createJavaBatchSchema = false;\n-    private boolean updateJavaBatchSchema = false;\n-    private boolean dropJavaBatchSchema = false;\n-    private boolean grantJavaBatchSchema = false;\n-\n-    // Tenant Key\n-    private boolean skipIfTenantExists = false;\n-\n-    // The database user we will grant tenant data access privileges to\n-    private String grantTo;\n-\n-    // Action flag related to Vacuuming:\n-    private boolean updateVacuum = false;\n-    private String vacuumTableName = null;\n-    private int vacuumCostLimit = 2000;\n-    private int vacuumThreshold = 1000;\n-    private Double vacuumScaleFactor = null;\n-    \n-    // How many seconds to wait to obtain the update lease\n-    private int waitForUpdateLeaseSeconds = 10;\n-\n-    // The database type being populated (default: Db2)\n-    private DbType dbType = DbType.DB2;\n-    private IDatabaseTranslator translator = new Db2Translator();\n-\n-    // Optional subset of resource types (for faster schema builds when testing)\n-    private Set<String> resourceTypeSubset;\n-\n-    // Tenant management\n-    private boolean allocateTenant;\n-    private boolean refreshTenants;\n-    private boolean dropTenant;\n-    private boolean freezeTenant;\n-    private String tenantName;\n-    private boolean testTenant;\n-    private String tenantKey;\n-    private boolean listTenants;\n-    private boolean dropDetached;\n-    private boolean deleteTenantMeta;\n-    private boolean revokeTenantKey;\n-    private boolean revokeAllTenantKeys;\n-\n-    // Tenant Key Output or Input File\n-    private String tenantKeyFileName;\n-    private TenantKeyFileUtil tenantKeyFileUtil = new TenantKeyFileUtil();\n-\n-    // The tenant name for when we want to add a new tenant key\n-    private String addKeyForTenant;\n-\n-    // What status to leave with\n-    private int exitStatus = EXIT_OK;\n-\n-    // The connection pool and transaction provider to support concurrent operations\n-    private int maxConnectionPoolSize = FhirSchemaConstants.DEFAULT_POOL_SIZE;\n-    private PoolConnectionProvider connectionPool;\n-    private ITransactionProvider transactionProvider;\n-    \n-    // Configuration to control how the LeaseManager operates\n-    private ILeaseManagerConfig leaseManagerConfig;\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the common methods and functions\n-    /**\n-     * @return a created connection to the selected database\n-     */\n-    protected Connection createConnection() {\n-        Properties connectionProperties = new Properties();\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        adapter.getExtraProperties(connectionProperties);\n-\n-        String url = translator.getUrl(properties);\n-        logger.info(\"Opening connection to: \" + url);\n-        Connection connection;\n-        try {\n-            connection = DriverManager.getConnection(url, connectionProperties);\n-            connection.setAutoCommit(false);\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-        return connection;\n-    }\n-\n-    /**\n-     * Create a simple connection pool associated with our data source so that we\n-     * can perform the DDL deployment in parallel\n-     */\n-    protected void configureConnectionPool() {\n-        if (dbType == DbType.DERBY && maxConnectionPoolSize > 1) {\n-            logger.warning(\"Embedded Derby does not support concurrent schema updates;\" +\n-                    \" ignoring '--pool-size' and using a single thread.\");\n-            this.maxConnectionPoolSize = 1;\n-        }\n-        JdbcPropertyAdapter adapter = getPropertyAdapter(dbType, properties);\n-        JdbcConnectionProvider cp = new JdbcConnectionProvider(this.translator, adapter);\n-        this.connectionPool = new PoolConnectionProvider(cp, this.maxConnectionPoolSize);\n-        this.transactionProvider = new SimpleTransactionProvider(this.connectionPool);\n-    }\n-\n-    /**\n-     * Add the admin schema objects to the {@link PhysicalDataModel}\n-     *\n-     * @param pdm the data model to build\n-     */\n-    protected void buildAdminSchemaModel(PhysicalDataModel pdm) {\n-        // Add the tenant and tenant_keys tables and any other admin schema stuff\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        gen.buildAdminSchema(pdm);\n-    }\n-    \n-    /**\n-     * Add the OAuth schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm the model to build\n-     */\n-    protected void buildOAuthSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty OAuth-related tables\n-        OAuthSchemaGenerator oauthSchemaGenerator = new OAuthSchemaGenerator(schema.getOauthSchemaName());\n-        oauthSchemaGenerator.buildOAuthSchema(pdm);\n-    }\n-\n-    /**\n-     * Add the JavaBatch schema objects to the given {@link PhysicalDataModel}\n-     * \n-     * @param pdm\n-     */\n-    protected void buildJavaBatchSchemaModel(PhysicalDataModel pdm) {\n-        // Build/update the Liberty JBatch related tables\n-        JavaBatchSchemaGenerator javaBatchSchemaGenerator = new JavaBatchSchemaGenerator(schema.getJavaBatchSchemaName());\n-        javaBatchSchemaGenerator.buildJavaBatchSchema(pdm);\n-    }\n-\n-    /**\n-     * Start the schema object creation tasks and wait for everything to complete\n-     *\n-     * @param pdm\n-     * @param adapter\n-     * @param collector\n-     * @param vhs\n-     */\n-    protected void applyModel(PhysicalDataModel pdm, IDatabaseAdapter adapter, ITaskCollector collector, VersionHistoryService vhs) {\n-        logger.info(\"Collecting model update tasks\");\n-        pdm.collect(collector, adapter, this.transactionProvider, vhs);\n-\n-        // FHIR in the hole!\n-        logger.info(\"Starting model updates\");\n-        collector.startAndWait();\n-\n-        Collection<ITaskGroup> failedTaskGroups = collector.getFailedTaskGroups();\n-        if (failedTaskGroups.size() > 0) {\n-            this.exitStatus = EXIT_RUNTIME_ERROR;\n-\n-            final String failedStr =\n-                    failedTaskGroups.stream().map((tg) -> tg.getTaskId()).collect(Collectors.joining(\",\"));\n-            logger.severe(\"List of failed task groups: \" + failedStr);\n-        }\n-    }\n-\n-    /**\n-     * specific feature to check if it is compatible.\n-     *\n-     * @return\n-     */\n-    protected boolean checkCompatibility() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            return adapter.checkCompatibility(schema.getAdminSchemaName());\n-        }\n-    }\n-\n-    /**\n-     * Create the schemas\n-     */\n-    protected void createSchemas() {\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    // We always create the 'admin' schema to track to the changes to any of the other schemas.\n-                    adapter.createSchema(schema.getAdminSchemaName());\n-\n-                    // FHIR Data Schema\n-                    if (createFhirSchema) {\n-                        adapter.createSchema(schema.getSchemaName());\n-                        c.commit();\n-                    }\n-\n-                    // OAuth Schema\n-                    if (createOauthSchema) {\n-                        adapter.createSchema(schema.getOauthSchemaName());\n-                    }\n-\n-                    // Java Batch Schema\n-                    if (createJavaBatchSchema) {\n-                        adapter.createSchema(schema.getJavaBatchSchemaName());\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-    \n-    /**\n-     * Process the schemas configured to be updated\n-     */\n-    protected void updateSchemas() {\n-        \n-        // Make sure that we have the CONTROL table created before we try any\n-        // schema update work\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateControl.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        if (updateFhirSchema) {\n-            updateFhirSchema();\n-        }\n-        \n-        if (updateOauthSchema) {\n-            updateOauthSchema();\n-        }\n-        \n-        if (updateJavaBatchSchema) {\n-            updateJavaBatchSchema();\n-        }\n-    }\n-    \n-    /**\n-     * Add FHIR data schema objects to the given {@link PhysicalDataModel}\n-     * @param pdm the data model being built\n-     */\n-    protected void buildFhirDataSchemaModel(PhysicalDataModel pdm) {\n-        FhirSchemaGenerator gen;\n-        if (resourceTypeSubset == null || resourceTypeSubset.isEmpty()) {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        } else {\n-            gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant(), resourceTypeSubset);\n-        }\n-\n-        gen.buildSchema(pdm);\n-        switch (dbType) {\n-        case DB2:\n-            gen.buildDatabaseSpecificArtifactsDb2(pdm);\n-            break;\n-        case DERBY:\n-            logger.info(\"No database specific artifacts\");\n-            break;\n-        case POSTGRESQL:\n-            gen.buildDatabaseSpecificArtifactsPostgres(pdm);\n-            break;\n-        default:\n-            throw new IllegalStateException(\"Unsupported db type: \" + dbType);\n-        }\n-    }\n-    \n-    /**\n-     * Update the FHIR data schema\n-     */\n-    protected void updateFhirSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for FHIR data schema: '\" + schema.getSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                // Build/update the FHIR-related tables as well as the stored procedures\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                boolean isNewDb = updateSchema(pdm);\n-                \n-                // If the db is multi-tenant, we populate the resource types and parameter names in allocate-tenant.\n-                // Otherwise, if its a new schema, populate the resource types and parameters names (codes) now\n-                if (!MULTITENANT_FEATURE_ENABLED.contains(dbType) && isNewDb) {\n-                    populateResourceTypeAndParameterNameTableEntries(null);\n-                }\n-        \n-                if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-                    logger.info(\"Refreshing tenant partitions\");\n-                    refreshTenants();\n-                }\n-        \n-                // backfill the resource_change_log table if needed\n-                backfillResourceChangeLog();\n-        \n-                // perform any updates we need related to the V0010 schema change (IS_DELETED flag)\n-                applyDataMigrationForV0010();\n-        \n-                // V0014 IS_DELETED and LAST_UPDATED added to whole-system LOGICAL_RESOURCES\n-                applyDataMigrationForV0014();\n-        \n-                // Log warning messages that unused tables will be removed in a future release.\n-                // TODO: This will no longer be needed after the tables are removed (https://github.com/IBM/FHIR/issues/713).\n-                logWarningMessagesForDeprecatedTables();\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForFhirData();\n-                }\n-                \n-                // Finally, update the whole schema version\n-                svm.updateSchemaVersion();\n-                \n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the OAuth schema changes\n-     */\n-    protected void updateOauthSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getOauthSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty OAuth schema: '\" + schema.getOauthSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getOauthSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-            \n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForOAuth();\n-                }\n-                \n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-\n-    /**\n-     * Build and apply the JavaBatch schema changes\n-     */\n-    protected void updateJavaBatchSchema() {\n-        LeaseManager leaseManager = new LeaseManager(this.translator, connectionPool, transactionProvider, schema.getAdminSchemaName(), schema.getJavaBatchSchemaName(),\n-            leaseManagerConfig);\n-\n-        try {\n-            if (!leaseManager.waitForLease(waitForUpdateLeaseSeconds)) {\n-                throw new ConcurrentUpdateException(\"Concurrent update for Liberty JavaBatch schema: '\" + schema.getJavaBatchSchemaName() + \"'\");\n-            }\n-            \n-            final String targetSchemaName = schema.getJavaBatchSchemaName();\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = transactionProvider.getTransaction()) {\n-                CreateWholeSchemaVersion.createTableIfNeeded(targetSchemaName, adapter);\n-            }\n-\n-            // If our schema is already at the latest version, we can skip a lot of processing\n-            SchemaVersionsManager svm = new SchemaVersionsManager(translator, connectionPool, transactionProvider, targetSchemaName);\n-            if (svm.isLatestSchema()) {\n-                logger.info(\"Already at latest version; skipping update for: '\" + targetSchemaName + \"'\");\n-            } else {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                updateSchema(pdm);\n-                \n-                // Apply privileges if asked\n-                if (grantTo != null) {\n-                    grantPrivilegesForBatch();\n-                }\n-\n-                // Mark the schema as up-to-date\n-                svm.updateSchemaVersion();\n-            }\n-        } finally {\n-            leaseManager.cancelLease();\n-        }\n-    }\n-    \n-    /**\n-     * Update the schema associated with the given {@link PhysicalDataModel}\n-     * @return true if the database is new\n-     */\n-    protected boolean updateSchema(PhysicalDataModel pdm) {\n-\n-        // The objects are applied in parallel, which relies on each object\n-        // expressing its dependencies correctly. Changes are only applied\n-        // if their version is greater than the current version.\n-        TaskService taskService = new TaskService();\n-        ExecutorService pool = Executors.newFixedThreadPool(this.maxConnectionPoolSize);\n-        ITaskCollector collector = taskService.makeTaskCollector(pool);\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-\n-        // Before we start anything, we need to make sure our schema history\n-        // and control tables are in place. These tables are used to manage \n-        // all FHIR data, oauth and JavaBatch schemas we build\n-        try (ITransaction tx = transactionProvider.getTransaction()) {\n-            CreateVersionHistory.createTableIfNeeded(schema.getAdminSchemaName(), adapter);\n-        }\n-\n-        // Current version history for the data schema\n-        VersionHistoryService vhs =\n-                new VersionHistoryService(schema.getAdminSchemaName(), schema.getSchemaName(), schema.getOauthSchemaName(), schema.getJavaBatchSchemaName());\n-        vhs.setTransactionProvider(transactionProvider);\n-        vhs.setTarget(adapter);\n-        vhs.init();\n-\n-        // Use the version history service to determine if this table existed before we run `applyWithHistory`\n-        boolean isNewDb = vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == null ||\n-                vhs.getVersion(schema.getSchemaName(), DatabaseObjectType.TABLE.name(), \"PARAMETER_NAMES\") == 0;\n-\n-        applyModel(pdm, adapter, collector, vhs);\n-        // The physical database objects should now match what was defined in the PhysicalDataModel\n-        \n-        return isNewDb;\n-    }\n-\n-    /**\n-     * populates for the given tenantId the RESOURCE_TYPE table.\n-     *\n-     * @implNote if you update this method, be sure to update\n-     *           DerbyBootstrapper.populateResourceTypeAndParameterNameTableEntries\n-     *           and DerbyFhirDatabase.populateResourceTypeAndParameterNameTableEntries\n-     *           The reason is there are three different ways of managing the transaction.\n-     * @param tenantId\n-     *            the mt_id that is used to setup the partition.\n-     *            passing in null signals not multi-tenant.\n-     */\n-    protected void populateResourceTypeAndParameterNameTableEntries(Integer tenantId) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                String logTenantId = tenantId != null ? Integer.toString(tenantId) : \"default\";\n-                logger.info(\"tenantId [\" + logTenantId + \"] is being pre-populated with lookup table data.\");\n-                PopulateResourceTypes populateResourceTypes =\n-                        new PopulateResourceTypes(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateResourceTypes.run(translator, c);\n-\n-                PopulateParameterNames populateParameterNames =\n-                        new PopulateParameterNames(schema.getAdminSchemaName(), schema.getSchemaName(), tenantId);\n-                populateParameterNames.run(translator, c);\n-                logger.info(\"Finished prepopulating the resource type and search parameter code/name tables tables\");\n-            } catch (SQLException ex) {\n-                tx.setRollbackOnly();\n-                throw new DataAccessException(ex);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Drop all the objects in the admin and data schemas.\n-     * Typically used during development.\n-     */\n-    protected void dropSchema() {\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, dropFhirSchema, dropOauthSchema, dropJavaBatchSchema);\n-\n-        // Dropping the schema in PostgreSQL can fail with an out of shared memory error\n-        // which is apparently related to max_locks_per_transaction. It may not be possible\n-        // to increase this value (e.g. in cloud databases) and so to work around this, before\n-        // dropping the schema objects, we knock out all the FOREIGN KEY constraints first.\n-        if (dropFhirSchema) {\n-            logger.info(\"Dropping FK constraints in the data schema: \" + this.schema.getSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-        }\n-\n-        if (dropOauthSchema) {\n-            logger.info(\"Dropping FK constraints in the OAuth schema: \" + this.schema.getOauthSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-        }\n-\n-        if (dropJavaBatchSchema) {\n-            logger.info(\"Dropping FK constraints in the Batch schema: \" + this.schema.getJavaBatchSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-        }\n-\n-        if (dropAdmin) {\n-            // Also drop the FK constraints within the administration schema\n-            logger.info(\"Dropping FK constraints in the admin schema: \" + this.schema.getAdminSchemaName());\n-            dropForeignKeyConstraints(pdm, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-        }\n-\n-        try {\n-            try (Connection c = createConnection()) {\n-                try {\n-                    JdbcTarget target = new JdbcTarget(c);\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                    if (dropFhirSchema || dropOauthSchema || dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the FHIRDATA schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.FHIRDATA_GROUP);\n-                    }\n-\n-                    if (dropOauthSchema) {\n-                        // Just drop the objects associated with the OAUTH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, OAuthSchemaGenerator.OAUTH_GROUP);\n-                    }\n-\n-                    if (dropJavaBatchSchema) {\n-                        // Just drop the objects associated with the BATCH schema group\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, JavaBatchSchemaGenerator.BATCH_GROUP);\n-                    }\n-\n-                    if (dropAdmin) {\n-                        // Just drop the objects associated with the ADMIN schema group\n-                        CreateVersionHistory.generateTable(pdm, ADMIN_SCHEMANAME, true);\n-                        pdm.drop(adapter, FhirSchemaGenerator.SCHEMA_GROUP_TAG, FhirSchemaGenerator.ADMIN_GROUP);\n-                    }\n-                } catch (Exception x) {\n-                    c.rollback();\n-                    throw x;\n-                }\n-                c.commit();\n-            }\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    /**\n-     * Add part of the schema drop process, we first kill all\n-     * the foreign key constraints. The rest of the drop is\n-     * performed in a second transaction.\n-     *\n-     * @param pdm\n-     */\n-    private void dropForeignKeyConstraints(PhysicalDataModel pdm, String tagGroup, String tag) {\n-        try (Connection c = createConnection()) {\n-            try {\n-                JdbcTarget target = new JdbcTarget(c);\n-                IDatabaseAdapter adapter = getDbAdapter(dbType, target);\n-\n-                Set<Table> referencedTables = new HashSet<>();\n-                DropForeignKey dropper = new DropForeignKey(adapter, referencedTables);\n-                pdm.visit(dropper, tagGroup, tag);\n-            } catch (Exception x) {\n-                c.rollback();\n-                throw x;\n-            }\n-            c.commit();\n-        } catch (SQLException x) {\n-            throw translator.translate(x);\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following method is related to the Stored Procedures and Functions feature\n-    /**\n-     * Update the stored procedures used by FHIR to insert records\n-     * into the FHIR resource tables\n-     */\n-    protected void updateProcedures() {\n-        if (!STORED_PROCEDURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        // Since this is a stored procedure, we need the model.\n-        // We must pass in true to flag to the underlying layer that the\n-        // Procedures need to be generated.\n-        buildCommonModel(pdm, true, updateOauthSchema, updateJavaBatchSchema);\n-\n-        // Now only apply the procedures in the model. Much faster than\n-        // going through the whole schema\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try (Connection c = connectionPool.getConnection();) {\n-                try {\n-                    IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-                    pdm.applyProcedures(adapter);\n-                    pdm.applyFunctions(adapter);\n-                    \n-                    // Because we're replacing the procedures, we should also check if\n-                    // we need to apply the associated privileges\n-                    if (this.grantTo != null) {\n-                        pdm.applyProcedureAndFunctionGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-                // Reminder: Don't fall into the trap, let the connectionPool and Transaction Management handle the\n-                // transaction commit.\n-            } catch (SQLException x) {\n-                tx.setRollbackOnly();\n-                throw translator.translate(x);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Build a common PhysicalDataModel containing all the requested schemas\n-     * \n-     * @param pdm the model to construct\n-     * @param addFhirDataSchema include objects for the FHIR data schema\n-     * @param addOAuthSchema include objects for the Liberty OAuth schema\n-     * @param addJavaBatchSchema include objects for the Liberty JavaBatch schema\n-     */\n-    protected void buildCommonModel(PhysicalDataModel pdm, boolean addFhirDataSchema, boolean addOAuthSchema, boolean addJavaBatchSchema) {\n-        if (addFhirDataSchema) {\n-            buildFhirDataSchemaModel(pdm);\n-        }\n-        \n-        if (addOAuthSchema) {\n-            buildOAuthSchemaModel(pdm);\n-        }\n-        \n-        if (addJavaBatchSchema) {\n-            buildJavaBatchSchemaModel(pdm);\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the FHIR data schema objects\n-     */\n-    protected void grantPrivilegesForFhirData() {\n-\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildFhirDataSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-                \n-                // Grant SELECT on WHOLE_SCHEMA_VERSION to the FHIR server user\n-                // Note the constant comes from SchemaConstants on purpose\n-                CreateWholeSchemaVersion.grantPrivilegesTo(adapter, schema.getSchemaName(), SchemaConstants.FHIR_USER_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Apply grants to the OAuth schema objects\n-     */\n-    protected void grantPrivilegesForOAuth() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildOAuthSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_OAUTH_GRANT_GROUP, grantTo);\n-                \n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        \n-    }\n-\n-    /**\n-     * Apply grants to the JavaBatch schema objects\n-     */\n-    protected void grantPrivilegesForBatch() {\n-        final IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                buildJavaBatchSchemaModel(pdm);\n-                pdm.applyGrants(adapter, FhirSchemaConstants.FHIR_BATCH_GRANT_GROUP, grantTo);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Grant the minimum required set of privileges on the FHIR schema objects\n-     * to the grantTo user. All tenant data access is via this user, and is the\n-     * only user the FHIR server itself is configured with.\n-     */\n-    protected void grantPrivileges() {\n-        if (!PRIVILEGES_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // The case where all are to be granted on the default schemas.\n-        if (!(updateFhirSchema || grantFhirSchema || updateOauthSchema\n-                || grantOauthSchema || updateJavaBatchSchema || grantJavaBatchSchema)) {\n-            grantOauthSchema = true;\n-            grantFhirSchema = true;\n-            grantJavaBatchSchema = true;\n-        }\n-        \n-        if (grantFhirSchema) {\n-            grantPrivilegesForFhirData();\n-        }\n-        \n-        if (grantOauthSchema) {\n-            grantPrivilegesForOAuth();\n-        }\n-        \n-        if (grantJavaBatchSchema) {\n-            grantPrivilegesForBatch();\n-        }\n-    }\n-\n-    /**\n-     * Do we want to build the multitenant variant of the schema (currently only supported\n-     * by DB2)\n-     *\n-     * @return\n-     */\n-    protected boolean isMultitenant() {\n-        return MULTITENANT_FEATURE_ENABLED.contains(this.dbType);\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to Multi-Tenant only.\n-    /**\n-     * Add a new tenant key so that we can rotate the values (add a\n-     * new key, update config files, then remove the old key). This\n-     * avoids any service interruption.\n-     */\n-    protected void addTenantKey() {\n-        if (!isMultitenant()) {\n-            return;\n-        }\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, false);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantDAO tid = new GetTenantDAO(schema.getAdminSchemaName(), addKeyForTenant);\n-                Tenant tenant = adapter.runStatement(tid);\n-\n-                if (tenant != null) {\n-                    // Attach the new tenant key to the tenant:\n-                    AddTenantKeyDAO adder =\n-                            new AddTenantKeyDAO(schema.getAdminSchemaName(), tenant.getTenantId(), tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-                    adapter.runStatement(adder);\n-                } else {\n-                    throw new IllegalArgumentException(\"Tenant does not exist: \" + addKeyForTenant);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            // Generated\n-            logger.info(\"New tenant key: \" + addKeyForTenant + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            // Loaded from File\n-            logger.info(\"New tenant key from file: \" + addKeyForTenant + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * checks if tenant name and tenant key exists.\n-     *\n-     * @param adapter\n-     *            the db2 adapter as this is a db2 feature only now\n-     * @param tenantName\n-     *            the tenant's name\n-     * @param tenantKey\n-     *            tenant key\n-     * @param skip\n-     *            whether or not to skip over cases where this tenantName/tenantKey combination already exists\n-     *\n-     * @throws IllegalArgumentException if the tenantName/tenantKey combination already exists and the {@code skip} argument is false\n-     *\n-     * @return indicates if the tenantName/tenantKey exists\n-     */\n-    protected boolean checkIfTenantNameAndTenantKeyExists(Db2Adapter adapter, String tenantName, String tenantKey, boolean skip) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                final String sql =\n-                        \"SELECT t.tenant_status FROM fhir_admin.tenants t WHERE t.tenant_name = ? \"\n-                                + \"AND EXISTS (SELECT 1 FROM fhir_admin.tenant_keys tk WHERE tk.mt_id = t.mt_id \"\n-                                + \"AND tk.tenant_hash = sysibm.hash(tk.tenant_salt || ?, 2))\";\n-                try (PreparedStatement stmt = connectionPool.getConnection().prepareStatement(sql)) {\n-                    stmt.setString(1, tenantName);\n-                    stmt.setString(2, tenantKey);\n-                    if (stmt.execute()) {\n-                        try (ResultSet resultSet = stmt.getResultSet();) {\n-                            if (resultSet.next()) {\n-                                if (skip) {\n-                                    return true;\n-                                } else {\n-                                    throw new IllegalArgumentException(\"tenantName and tenantKey already exists\");\n-                                }\n-                            }\n-                        }\n-                    } else {\n-                        throw new IllegalArgumentException(\"Problem checking the results\");\n-                    }\n-                } catch (SQLException e) {\n-                    throw new IllegalArgumentException(\"Exception when querying backend to verify tenant key and tenant name\", e);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return false;\n-    }\n-\n-    /**\n-     * Allocate this tenant, creating new partitions if required.\n-     */\n-    protected void allocateTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // IMPORTANT! Check the schema name aligns with the actual schema for this tenant\n-        checkSchemaForTenant();\n-\n-        // The key we'll use for this tenant. This key should be used in subsequent\n-        // activities related to this tenant, such as setting the tenant context.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        } else {\n-            tenantKey = getRandomKey();\n-        }\n-\n-        // The salt is used when we hash the tenantKey. We're just using SHA-256 for\n-        // the hash here, not multiple rounds of a password hashing algorithm. It's\n-        // sufficient in our case because we are using a 32-byte random value as the\n-        // key, giving 256 bits of entropy.\n-        final String tenantSalt = getRandomKey();\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        // Conditionally skip if the tenant name and key exist (this enables idempotency)\n-        boolean skip = checkIfTenantNameAndTenantKeyExists(adapter, tenantName, tenantKey, skipIfTenantExists);\n-        if (skip) {\n-            return;\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [key=\" + tenantKey + \"]\");\n-        } else {\n-            logger.info(\"Allocating new tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"]\");\n-        }\n-\n-        // Open a new transaction and associate it with our connection pool. Remember\n-        // that we don't support distributed transactions, so all connections within\n-        // this transaction must come from the same pool\n-        int tenantId;\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                tenantId =\n-                        adapter.allocateTenant(schema.getAdminSchemaName(), schema.getSchemaName(), tenantName, tenantKey, tenantSalt, FhirSchemaConstants.TENANT_SEQUENCE);\n-\n-                // The tenant-id is important because this is also used to identify the partition number\n-                logger.info(\"Tenant Id[\" + tenantName + \"] = [\" + tenantId + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // Build/update the tables as well as the stored procedures\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), schema.getSchemaName(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Get the data model to create the table partitions. This is threaded, so transactions are\n-        // handled within each thread by the adapter. This means we should probably pull some of\n-        // that logic out of the adapter and handle it at a higher level. Note...the extent size used\n-        // for the partitions needs to match the extent size of the original table tablespace (FHIR_TS)\n-        // so this must be constant.\n-        pdm.addTenantPartitions(adapter, schema.getSchemaName(), tenantId, FhirSchemaConstants.FHIR_TS_EXTENT_KB);\n-\n-        // Fill any static data tables (which are also partitioned by tenant)\n-        // Prepopulate the Resource Type Tables and Parameters Name/Code Table\n-        populateResourceTypeAndParameterNameTableEntries(tenantId);\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as ready\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantId, TenantStatus.ALLOCATED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        if (tenantKeyFileName == null) {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [key=\" + tenantKey + \"] with Id = \" + tenantId);\n-            logger.info(\"The tenantKey JSON follows: \\t\\n{\\\"tenantKey\\\": \\\"\" + tenantKey + \"\\\"}\");\n-        } else {\n-            logger.info(\"Allocated tenant: \" + tenantName + \" [tenantKeyFileName=\" + tenantKeyFileName + \"] with Id = \"\n-                    + tenantId);\n-            if (!tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-                tenantKeyFileUtil.writeTenantFile(tenantKeyFileName, tenantKey);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Run a check to make sure that if the tenant already exists its schema\n-     * matches the specified schema. This prevents users from accidentally\n-     * creating a second instance of a tenant in a different schema\n-     */\n-    protected void checkSchemaForTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // only relevant for databases which support multiple tenants within one schema (like Db2)\n-            return;\n-        }\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // Scan over the list to see if the tenant we are working with\n-        // already exists\n-        for (TenantInfo ti : tenants) {\n-            if (ti.getTenantName().equals(this.tenantName)) {\n-                if (ti.getTenantSchema() == null) {\n-                    // The schema is empty so no chance of adding tenants\n-                    throw new IllegalArgumentException(\"Schema '\" + schema.getSchemaName() + \"'\"\n-                            + \" for tenant '\" + ti.getTenantName() + \"'\"\n-                            + \" does not contain a valid IBM FHIR Server schema\");\n-                } else if (!ti.getTenantSchema().equalsIgnoreCase(schema.getSchemaName())) {\n-                    // The given schema name doesn't match where we think this tenant\n-                    // should be located, so throw an error before any damage is done\n-                    throw new IllegalArgumentException(\"--schema-name argument '\" + schema.getSchemaName()\n-                            + \"' does not match schema '\" + ti.getTenantSchema() + \"' for tenant '\"\n-                            + ti.getTenantName() + \"'\");\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Get the list of tenants and the schemas each is currently defined in. Because\n-     * this tenant-schema mapping isn't stored directly, it has to be inferred by\n-     * looking up the schema from one of the tables we know should exist. The schema\n-     * name may therefore be null if the tenant record (in FHIR_ADMIN.TENANTS) exists,\n-     * but all the tables from that schema have been dropped.\n-     *\n-     * @return\n-     */\n-    protected List<TenantInfo> getTenantList() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return Collections.emptyList();\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants;\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                tenants = adapter.runStatement(rtListGetter);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        return tenants;\n-    }\n-\n-    /**\n-     * Make sure all the tables has a partition created for the configured tenant\n-     */\n-    protected void refreshTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Similar to the allocate tenant processing, except in this case we want to\n-        // make sure that each table has all the tenant partitions required. This is\n-        // to handle the case where a schema update has added a new table.\n-        List<TenantInfo> tenants = getTenantList();\n-\n-        // make sure the list is sorted by tenantId. Lambdas really do clean up this sort of code\n-        tenants.sort((TenantInfo left, TenantInfo right) -> left.getTenantId() < right.getTenantId() ? -1 : left.getTenantId() > right.getTenantId() ? 1 : 0);\n-        for (TenantInfo ti : tenants) {\n-            // For issue 1847 we only want to process for the named data schema if one is provided\n-            // If no -schema-name arg is given, we process all tenants.\n-            if (ti.getTenantSchema() != null && (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema()))) {\n-                // It's crucial we use the correct schema for each particular tenant, which\n-                // is why we have to build the PhysicalDataModel separately for each tenant\n-                FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), ti.getTenantSchema(), isMultitenant());\n-                PhysicalDataModel pdm = new PhysicalDataModel();\n-                gen.buildSchema(pdm);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                pdm.addNewTenantPartitions(adapter, ti.getTenantSchema(), ti.getTenantId());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * List the tenants currently configured\n-     */\n-    protected void listTenants() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetTenantList rtListGetter = new GetTenantList(schema.getAdminSchemaName());\n-                List<TenantInfo> tenants = adapter.runStatement(rtListGetter);\n-\n-                System.out.println(TenantInfo.getHeader());\n-                tenants.forEach(System.out::println);\n-            } catch (UndefinedNameException x) {\n-                System.out.println(\"The FHIR_ADMIN schema appears not to be deployed with the TENANTS table\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Check that we can call the set_tenant procedure successfully (which means\n-     * that the\n-     * tenant record exists in the tenants table)\n-     */\n-    protected void testTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        if (this.tenantName == null || this.tenantName.isEmpty()) {\n-            throw new IllegalStateException(\"Missing tenant name\");\n-        }\n-\n-        // Part of Bring your own Tenant Key\n-        if (tenantKeyFileName != null) {\n-            // Only if the Tenant Key file is provided as a parameter is it not null.\n-            // in this case we want special behavior.\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        if (this.tenantKey == null || this.tenantKey.isEmpty()) {\n-            throw new IllegalArgumentException(\"No tenant-key value provided\");\n-        }\n-\n-        logger.info(\"Testing tenant: [\" + tenantName + \"]\");\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // The tenants table, variable and set_tenant procedure are all located in\n-                // the admin schema. The data access user only has execute privileges on the\n-                // set_tenant procedure and read access to the variable. The variable can\n-                // only be set by calling the stored procedure\n-                Db2SetTenantVariable cmd = new Db2SetTenantVariable(schema.getAdminSchemaName(), tenantName, tenantKey);\n-                adapter.runStatement(cmd);\n-\n-                Db2GetTenantVariable getter = new Db2GetTenantVariable(schema.getAdminSchemaName());\n-                Integer tid = adapter.runStatement(getter);\n-                if (tid == null) {\n-                    throw new IllegalStateException(\"SV_TENANT_ID not set!\");\n-                }\n-\n-                // Print the id from the session variable (used for access control)\n-                logger.info(\"tenantName='\" + tenantName + \"', tenantId=\" + tid);\n-\n-                // Now let's check we can run a select against one our tenant-based\n-                // tables\n-                GetResourceTypeList rtListGetter = new GetResourceTypeList(schema.getSchemaName());\n-                List<ResourceType> rtList = adapter.runStatement(rtListGetter);\n-                rtList.forEach(rt -> logger.info(\"ResourceType: \" + rt.toString()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    protected TenantInfo getTenantInfo() {\n-        TenantInfo result;\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                GetTenantInfo command = new GetTenantInfo(schema.getAdminSchemaName(), tenantName);\n-                result = adapter.runStatement(command);\n-\n-                if (result == null) {\n-                    logger.info(\"Use --list-tenants to display the current tenants\");\n-                    throw new IllegalArgumentException(\"Tenant '\" + tenantName + \"' not found in admin schema \" + schema.getAdminSchemaName());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // make sure we set the schema name correctly if it couldn't be found in the database\n-        // (which happens after all the partitions for a particular tenant are detached)\n-        String tenantSchema = result.getTenantSchema();\n-        if (tenantSchema == null || tenantSchema.isEmpty()) {\n-            // the schema can no longer be derived from the database, so we\n-            // need it to be provided on the command line.\n-            if (schema.getSchemaName() == null || schema.getSchemaName().isEmpty()) {\n-                throw new IllegalArgumentException(\"Must provide the tenant schema with --schema-name\");\n-            }\n-            result.setTenantSchema(schema.getSchemaName());\n-        } else {\n-            // if a schema name was provided on the command line, let's double-check it matches\n-            // the schema used for this tenant in the database\n-            if (!tenantSchema.equalsIgnoreCase(schema.getSchemaName())) {\n-                throw new IllegalArgumentException(\"--schema-name '\" + schema.getSchemaName() + \"' argument does not match tenant schema: '\"\n-                        + tenantSchema + \"'\");\n-            }\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Mark the tenant so that it can no longer be accessed (this prevents\n-     * the SET_TENANT method from authenticating the tenantName/tenantKey\n-     * pair, so the SV_TENANT_ID variable never gets set).\n-     *\n-     * @return the TenantInfo associated with the tenant\n-     */\n-    protected TenantInfo freezeTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            throw new IllegalStateException(\"Not a multi-tenant database\");\n-        }\n-\n-        TenantInfo result = getTenantInfo();\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        logger.info(\"Marking tenant for drop: \" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-\n-            try {\n-                // Mark the tenant as frozen before we proceed with dropping anything\n-                if (result.getTenantStatus() == TenantStatus.ALLOCATED) {\n-                    adapter.updateTenantStatus(schema.getAdminSchemaName(), result.getTenantId(), TenantStatus.FROZEN);\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-        return result;\n-    }\n-\n-    /**\n-     * Deallocate this tenant, dropping all the related partitions. This needs to be\n-     * idempotent because there are steps which must be run in separate transactions\n-     * (due to how Db2 handles detaching partitions). This is further complicated by\n-     * referential integrity constraints in the schema. See:\n-     * - https://www.ibm.com/support/knowledgecenter/SSEPGG_11.5.0/com.ibm.db2.luw.admin.partition.doc/doc/t0021576.html\n-     *\n-     * The workaround described in the above link is:\n-     * // Change the RI constraint to informational:\n-     * 1. ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     *\n-     * 2. ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     *\n-     * 3. SET INTEGRITY FOR child OFF;\n-     *\n-     * // Change the RI constraint back to enforced:\n-     * 4. ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     *\n-     * 5. SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     * 6. Assuming that the CHILD table does not have any dependencies on partition P0,\n-     * 7. and that no updates on the CHILD table are permitted until this UOW is complete,\n-     * no RI violation is possible during this UOW.\n-     *\n-     * COMMIT WORK;\n-     *\n-     * Unfortunately, #7 above essentially requires that all writes cease until the\n-     * UOW is completed and the integrity is enabled again on all the child (leaf)\n-     * tables. Of course, this could be relaxed if the application is trusted not\n-     * to mess up the referential integrity...which we know to be true for the\n-     * FHIR server persistence layer.\n-     *\n-     * If the risk is deemed too high, tenant removal should be performed in a\n-     * maintenance window.\n-     */\n-    protected void dropTenant() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        // Mark the tenant as being dropped. This should prevent it from\n-        // being used in any way because the SET_TENANT stored procedure\n-        // will reject any request for the tenant being dropped.\n-        TenantInfo tenantInfo = freezeTenant();\n-\n-        // Build the model of the data (FHIRDATA) schema which is then used to drive the drop\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        // Detach the tenant partition from each of the data tables\n-        detachTenantPartitions(pdm, tenantInfo);\n-\n-        // this may not complete successfully because Db2 runs the detach as an async\n-        // process. Just need to run --drop-detached to clean up.\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. The detach process is asynchronous,\n-     * so this is a sort of garbage collection, sweeping up cruft left in the database.\n-     */\n-    protected void dropDetachedPartitionTables() {\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        FhirSchemaGenerator gen = new FhirSchemaGenerator(schema.getAdminSchemaName(), tenantInfo.getTenantSchema(), isMultitenant());\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        gen.buildSchema(pdm);\n-\n-        dropDetachedPartitionTables(pdm, tenantInfo);\n-    }\n-\n-    /**\n-     * Drop any tables which have previously been detached. Once all tables have been\n-     * dropped, we go on to drop the tablespace. If the tablespace drop is successful,\n-     * we know the cleanup is complete so we can update the tenant status accordingly\n-     *\n-     * @param pdm\n-     * @param tenantInfo\n-     */\n-    protected void dropDetachedPartitionTables(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        // In a new transaction, drop any of the tables that were created by\n-        // the partition detach operation.\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                pdm.dropDetachedPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-        // We can drop the tenant's tablespace only after all the table drops have been committed\n-        logger.info(\"Dropping tablespace for tenant \" + tenantInfo.getTenantId() + \"/\" + tenantName);\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            boolean retry = true;\n-            int wait = 0;\n-            while (retry) {\n-                try {\n-                    retry = false;\n-                    // With all the objects removed, it should be safe to remove the tablespace\n-                    pdm.dropTenantTablespace(adapter, tenantInfo.getTenantId());\n-                } catch (DataAccessException x) {\n-                    boolean error = x instanceof DataAccessException && x.getCause() instanceof SQLException\n-                            && (((SQLException) x.getCause()).getErrorCode() == -282);\n-                    if (error && wait++ <= 30) {\n-                        retry = true;\n-                        logger.warning(\"Waiting on async dettach dependency to finish - count '\" + wait + \"'\");\n-                        try {\n-                            Thread.sleep(2000);\n-                        } catch (InterruptedException e) {\n-                            throw new DataAccessException(e);\n-                        }\n-                    } else if (error) {\n-                        throw new TableSpaceRemovalException(x.getCause());\n-                    } else {\n-                        // Something went wrong, so mark the transaction as failed\n-                        tx.setRollbackOnly();\n-                        throw x;\n-                    }\n-                }\n-            }\n-        }\n-\n-        // Now all the table partitions have been allocated, we can mark the tenant as dropped\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                adapter.updateTenantStatus(schema.getAdminSchemaName(), tenantInfo.getTenantId(), TenantStatus.DROPPED);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Temporarily suspend RI so that tables which are the subject of foreign\n-     * key relationships can have their partitions dropped. A bit frustrating\n-     * to have to go through this, because the child table partition will be\n-     * detached before the parent anyway, so theoretically this workaround\n-     * shouldn't be necessary.\n-     * ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-     * ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-     * SET INTEGRITY FOR child OFF;\n-     * ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-     * SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-     */\n-    protected void detachTenantPartitions(PhysicalDataModel pdm, TenantInfo tenantInfo) {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // collect the set of all child tables with FK relationships to\n-                // partitioned tables\n-                Set<Table> childTables = new HashSet<>();\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk NOT ENFORCED;\n-                pdm.visit(new DisableForeignKey(adapter, childTables));\n-\n-                // ALTER TABLE parent DETACH PARTITION p0 INTO TABLE pdet;\n-                pdm.detachTenantPartitions(adapter, tenantInfo.getTenantSchema(), tenantInfo.getTenantId());\n-\n-                // SET INTEGRITY FOR child OFF;\n-                childTables.forEach(t -> adapter.setIntegrityOff(t.getSchemaName(), t.getObjectName()));\n-\n-                // ALTER TABLE child ALTER FOREIGN KEY fk ENFORCED;\n-                pdm.visit(new EnableForeignKey(adapter));\n-\n-                // SET INTEGRITY FOR child ALL IMMEDIATE UNCHECKED;\n-                childTables.forEach(t -> adapter.setIntegrityUnchecked(t.getSchemaName(), t.getObjectName()));\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * Delete all the metadata associated with the named tenant.\n-     */\n-    protected void deleteTenantMeta() {\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-        TenantInfo tenantInfo = getTenantInfo();\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                if (tenantInfo.getTenantStatus() == TenantStatus.DROPPED) {\n-                    adapter.deleteTenantMeta(schema.getAdminSchemaName(), tenantInfo.getTenantId());\n-                } else {\n-                    throw new IllegalStateException(\"Cannot delete tenant meta data until status is \" + TenantStatus.DROPPED.name());\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * revokes a tenant key or if no tenant key is specified remove all of them for the\n-     * given tenant.\n-     */\n-    protected void revokeTenantKey() {\n-        if (!MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            return;\n-        }\n-\n-        TenantInfo tenantInfo = getTenantInfo();\n-        int tenantId = tenantInfo.getTenantId();\n-\n-        // Only if the Tenant Key file is provided as a parameter is it not null.\n-        // in this case we want special behavior.\n-        if (tenantKeyFileUtil.keyFileExists(tenantKeyFileName)) {\n-            tenantKey = this.tenantKeyFileUtil.readTenantFile(tenantKeyFileName);\n-        }\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                DeleteTenantKeyDAO dtk = new DeleteTenantKeyDAO(schema.getAdminSchemaName(), tenantId, tenantKey);\n-\n-                Db2Adapter adapter = new Db2Adapter(connectionPool);\n-                adapter.runStatement(dtk);\n-                int count = dtk.getCount();\n-                logger.info(\"Tenant Key revoked for '\" + tenantInfo.getTenantName() + \"' total removed=[\" + count + \"]\");\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    // -----------------------------------------------------------------------------------------------------------------\n-    // The following methods are related to parsing arguments and action selection\n-    /**\n-     * Parse the command-line arguments, building up the environment and\n-     * establishing\n-     * the run-list\n-     *\n-     * @param args\n-     */\n-    protected void parseArgs(String[] args) {\n-        // Arguments are pretty simple, so we go with a basic switch instead of having\n-        // yet another dependency (e.g. commons-cli).\n-        LeaseManagerConfig.Builder lmConfig = LeaseManagerConfig.builder();\n-        lmConfig.withHost(new HostnameHandler().getHostname());\n-        lmConfig.withLeaseTimeSeconds(100); // default\n-        lmConfig.withStayAlive(true);       // default\n-        \n-        for (int i = 0; i < args.length; i++) {\n-            int nextIdx = (i + 1);\n-            String arg = args[i];\n-            switch (arg) {\n-            case \"--prop-file\":\n-                if (++i < args.length) {\n-                    loadPropertyFile(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--schema-name\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    schema.setSchemaName(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--grant-to\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-\n-                    // Force upper-case because user names are case-insensitive\n-                    this.grantTo = args[i].toUpperCase();\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--target\":\n-                if (++i < args.length) {\n-                    DataDefinitionUtil.assertValidName(args[i]);\n-                    List<String> targets = Arrays.asList(args[i].split(\",\"));\n-                    for (String target : targets) {\n-                        String tmp = target.toUpperCase();\n-                        nextIdx++;\n-                        if (tmp.startsWith(\"BATCH\")) {\n-                            this.grantJavaBatchSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setJavaBatchSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"OAUTH\")) {\n-                            this.grantOauthSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setOauthSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else if (tmp.startsWith(\"DATA\")) {\n-                            this.grantFhirSchema = true;\n-                            if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                                schema.setSchemaName(args[nextIdx]);\n-                                i++;\n-                            } else {\n-                                throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                            }\n-                        } else {\n-                            throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                        }\n-                    }\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--add-tenant-key\":\n-                if (++i < args.length) {\n-                    this.addKeyForTenant = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--revoke-tenant-key\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeTenantKey = true;\n-                break;\n-            case \"--revoke-all-tenant-keys\":\n-                if (++i >= args.length) {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                this.tenantName = args[i];\n-                this.revokeAllTenantKeys = true;\n-                break;\n-            case \"--update-proc\":\n-                this.updateProc = true;\n-                break;\n-            case \"--check-compatibility\":\n-                this.checkCompatibility = true;\n-                break;\n-            case \"--drop-admin\":\n-                this.dropAdmin = true;\n-                break;\n-            case \"--test-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.testTenant = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key\":\n-                if (++i < args.length) {\n-                    this.tenantKey = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--tenant-key-file\":\n-                if (++i < args.length) {\n-                    tenantKeyFileName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--list-tenants\":\n-                this.listTenants = true;\n-                break;\n-            case \"--update-schema\":\n-                this.updateFhirSchema = true;\n-                this.updateOauthSchema = true;\n-                this.updateJavaBatchSchema = true;\n-                break;\n-            case \"--update-schema-fhir\":\n-                this.updateFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                } else {\n-                    schema.setSchemaName(DATA_SCHEMANAME);\n-                }\n-                break;\n-            case \"--update-schema-batch\":\n-                this.updateJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--update-schema-oauth\":\n-                this.updateOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schemas\":\n-                this.createFhirSchema = true;\n-                this.createOauthSchema = true;\n-                this.createJavaBatchSchema = true;\n-                break;\n-            case \"--create-schema-fhir\":\n-                this.createFhirSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-batch\":\n-                this.createJavaBatchSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--create-schema-oauth\":\n-                this.createOauthSchema = true;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema\":\n-                System.err.print(\"Option '--drop-schema' has been retired.  Please use '--drop-schema-fhir', \"\n-                        + \"'--drop-schema-batch', and/or '--drop-schema-oauth'.\");\n-                break;\n-            case \"--drop-schema-fhir\":\n-                this.dropFhirSchema = Boolean.TRUE;\n-                break;\n-            case \"--drop-schema-batch\":\n-                this.dropJavaBatchSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setJavaBatchSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--drop-schema-oauth\":\n-                this.dropOauthSchema = Boolean.TRUE;\n-                if (nextIdx < args.length && !args[nextIdx].startsWith(\"--\")) {\n-                    schema.setOauthSchemaName(args[nextIdx]);\n-                    i++;\n-                }\n-                break;\n-            case \"--pool-size\":\n-                if (++i < args.length) {\n-                    this.maxConnectionPoolSize = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--prop\":\n-                if (++i < args.length) {\n-                    // properties are given as name=value\n-                    addProperty(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--update-vacuum\":\n-                updateVacuum = true;\n-                break;\n-            case \"--vacuum-cost-limit\":\n-                if (++i < args.length) {\n-                    this.vacuumCostLimit = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-threshold\":\n-                if (++i < args.length) {\n-                    this.vacuumThreshold = Integer.parseInt(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-scale-factor\":\n-                if (++i < args.length) {\n-                    this.vacuumScaleFactor = Double.parseDouble(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--vacuum-table-name\":\n-                if (++i < args.length) {\n-                    this.vacuumTableName = args[i];\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--confirm-drop\":\n-                this.confirmDrop = true;\n-                break;\n-            case \"--allocate-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.allocateTenant = true;\n-                    this.dropTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--refresh-tenants\":\n-                this.refreshTenants = true;\n-                this.allocateTenant = false;\n-                this.dropTenant = false;\n-                break;\n-            case \"--drop-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropTenant = true;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--freeze-tenant\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.freezeTenant = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--drop-detached\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.dropDetached = true;\n-                    this.dropTenant = false;\n-                    this.allocateTenant = false;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--delete-tenant-meta\":\n-                if (++i < args.length) {\n-                    this.tenantName = args[i];\n-                    this.deleteTenantMeta = true;\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                break;\n-            case \"--db-type\":\n-                if (++i < args.length) {\n-                    this.dbType = DbType.from(args[i]);\n-                } else {\n-                    throw new IllegalArgumentException(\"Missing value for argument at posn: \" + i);\n-                }\n-                switch (dbType) {\n-                case DERBY:\n-                    translator = new DerbyTranslator();\n-                    break;\n-                case POSTGRESQL:\n-                    translator = new PostgresTranslator();\n-                    break;\n-                case DB2:\n-                default:\n-                    break;\n-                }\n-                break;\n-            // Skips the allocateTenant action if the tenant exists (e.g. a shortcircuit)\n-            case \"--skip-allocate-if-tenant-exists\":\n-                skipIfTenantExists = true;\n-                break;\n-            default:\n-                throw new IllegalArgumentException(\"Invalid argument: '\" + arg + \"'\");\n-            }\n-        }\n-        \n-        this.leaseManagerConfig = lmConfig.build();\n-    }\n-\n-    /**\n-     * Read the properties from the given file\n-     *\n-     * @param filename\n-     */\n-    public void loadPropertyFile(String filename) {\n-        try (InputStream is = new FileInputStream(filename)) {\n-            properties.load(is);\n-            // Trim leading and trailing whitespace from property values (except password)\n-            for (Entry<Object, Object> entry : properties.entrySet()) {\n-                if (!\"password\".equals(entry.getKey())) {\n-                    String trimmedValue = entry.getValue().toString().trim();\n-                    if (!trimmedValue.equals(entry.getValue().toString())) {\n-                        logger.warning(\"Whitespace trimmed from value of property '\" + entry.getKey() + \"'\");\n-                        entry.setValue(trimmedValue);\n-                    }\n-                }\n-            }\n-        } catch (IOException x) {\n-            throw new IllegalArgumentException(x);\n-        }\n-    }\n-\n-    /**\n-     * Parse the given key=value string and add to the properties being collected\n-     *\n-     * @param pair\n-     */\n-    public void addProperty(String pair) {\n-        String[] kv = pair.split(\"=\");\n-        if (kv.length == 2) {\n-            // Trim leading and trailing whitespace from property value (except password)\n-            if (!\"password\".equals(kv[0])) {\n-                String trimmedValue = kv[1].trim();\n-                if (!trimmedValue.equals(kv[1])) {\n-                    logger.warning(\"Whitespace trimmed from value of property '\" + kv[0] + \"'\");\n-                }\n-                properties.put(kv[0], trimmedValue);\n-            } else {\n-                properties.put(kv[0], kv[1]);\n-            }\n-        } else {\n-            throw new IllegalArgumentException(\"Property must be defined as key=value, not: \" + pair);\n-        }\n-    }\n-\n-    /**\n-     * Perform the special data migration steps required for the V0010 version of the schema\n-     */\n-    protected void applyDataMigrationForV0010() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0010(ti);\n-                }\n-            }\n-        } else {\n-            doMigrationForV0010();\n-        }\n-    }\n-\n-    protected void applyDataMigrationForV0014() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    dataMigrationForV0014(ti);\n-                }\n-            }\n-        } else {\n-            dataMigrationForV0014();\n-        }\n-    }\n-\n-    /**\n-     * Get the list of resource types to drive resource-by-resource operations\n-     *\n-     * @return the full list of FHIR R4 resource types, or a subset of names if so configured\n-     */\n-    private Set<String> getResourceTypes() {\n-        Set<String> result;\n-        if (this.resourceTypeSubset == null || this.resourceTypeSubset.isEmpty()) {\n-            // pass 'false' to getResourceTypes to avoid building tables for abstract resource types\n-            // Should simplify FhirSchemaGenerator and always pass in this list. When switching\n-            // over to false, migration is required to drop the tables no longer required.\n-            final boolean includeAbstractResourceTypes = true;\n-            result = ModelSupport.getResourceTypes(includeAbstractResourceTypes).stream().map(Class::getSimpleName).collect(Collectors.toSet());\n-        } else {\n-            result = this.resourceTypeSubset;\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Get the list of resource types from the database.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @return\n-     */\n-    private List<ResourceType> getResourceTypesList(IDatabaseAdapter adapter, String schemaName) {\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                GetResourceTypeList cmd = new GetResourceTypeList(schemaName);\n-                return adapter.runStatement(cmd);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the IS_DELETED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0010(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each update in its own transaction so we don't stress the tx log space\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES.IS_DELETED \"\n-                                + \"for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Perform the data migration for V0010 (non-multi-tenant schema)\n-     */\n-    private void doMigrationForV0010() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (String resourceTypeName : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    // only process tables which have been converted to the V0010 schema but\n-                    // which have not yet had their data migrated. The migration can't be\n-                    // done as part of the schema change because some tables need a REORG which\n-                    // has to be done after the transaction in which the alter table was performed.\n-                    GetXXLogicalResourceNeedsMigration needsMigrating = new GetXXLogicalResourceNeedsMigration(schema.getSchemaName(), resourceTypeName);\n-                    if (adapter.runStatement(needsMigrating)) {\n-                        logger.info(\"V0010-V0012 Migration: Updating \" + resourceTypeName + \"_LOGICAL_RESOURCES denormalized columns in schema \"\n-                                + schema.getSchemaName());\n-                        InitializeLogicalResourceDenorms cmd = new InitializeLogicalResourceDenorms(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(cmd);\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data for the given tenant\n-     *\n-     * @param ti\n-     */\n-    private void dataMigrationForV0014(TenantInfo ti) {\n-        // Multi-tenant schema so we know this is Db2:\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each update in its own transaction so we don't over-stress the tx log space\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                    adapter.runStatement(setTenantId);\n-\n-                    logger.info(\"V0014 Migration: Updating \" + \"LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for \" + resourceType.toString()\n-                            + \" for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-\n-                    dataMigrationForV0014(adapter, ti.getTenantSchema(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Migrate the LOGICAL_RESOURCE IS_DELETED and LAST_UPDATED data\n-     */\n-    private void dataMigrationForV0014() {\n-        IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-        List<ResourceType> resourceTypes = getResourceTypesList(adapter, schema.getSchemaName());\n-\n-        // Process each resource type in its own transaction to avoid pressure on the tx log\n-        for (ResourceType resourceType : resourceTypes) {\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    dataMigrationForV0014(adapter, schema.getSchemaName(), resourceType);\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * only process tables which have not yet had their data migrated. The migration can't be\n-     * done as part of the schema change because some tables need a REORG which\n-     * has to be done after the transaction in which the alter table was performed.\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @param resourceType\n-     */\n-    private void dataMigrationForV0014(IDatabaseAdapter adapter, String schemaName, ResourceType resourceType) {\n-        GetLogicalResourceNeedsV0014Migration needsMigrating = new GetLogicalResourceNeedsV0014Migration(schemaName, resourceType.getId());\n-        if (adapter.runStatement(needsMigrating)) {\n-            logger.info(\"V0014 Migration: Updating LOGICAL_RESOURCES.IS_DELETED and LAST_UPDATED for schema '\"\n-                    + schemaName + \"' and resource type '\" + resourceType.toString() + \"'\");\n-            MigrateV0014LogicalResourceIsDeletedLastUpdated cmd =\n-                    new MigrateV0014LogicalResourceIsDeletedLastUpdated(schemaName, resourceType.getName(), resourceType.getId());\n-            adapter.runStatement(cmd);\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table if it is empty\n-     */\n-    protected void backfillResourceChangeLog() {\n-        if (MULTITENANT_FEATURE_ENABLED.contains(dbType)) {\n-            // Process each tenant one-by-one\n-            List<TenantInfo> tenants = getTenantList();\n-            for (TenantInfo ti : tenants) {\n-\n-                // If no --schema-name override was specified, we process all tenants, otherwise we\n-                // process only tenants which belong to the override schema name\n-                if (!schema.isOverrideDataSchema() || schema.matchesDataSchema(ti.getTenantSchema())) {\n-                    backfillResourceChangeLogDb2(ti);\n-                }\n-            }\n-        } else {\n-            // Not a multi-tenant database, so we only have to do this once\n-            IDatabaseAdapter adapter = getDbAdapter(dbType, connectionPool);\n-            try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-                try {\n-                    GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                    if (adapter.runStatement(isEmpty)) {\n-                        // change log is empty, so we need to backfill it with data\n-                        doBackfill(adapter);\n-                    } else {\n-                        logger.info(\"RESOURCE_CHANGE_LOG has data so skipping backfill\");\n-                    }\n-                } catch (DataAccessException x) {\n-                    // Something went wrong, so mark the transaction as failed\n-                    tx.setRollbackOnly();\n-                    throw x;\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * backfill the resource_change_log table if it is empty\n-     */\n-    protected void backfillResourceChangeLogDb2(TenantInfo ti) {\n-\n-        Db2Adapter adapter = new Db2Adapter(connectionPool);\n-\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                SetTenantIdDb2 setTenantId = new SetTenantIdDb2(schema.getAdminSchemaName(), ti.getTenantId());\n-                adapter.runStatement(setTenantId);\n-\n-                GetResourceChangeLogEmpty isEmpty = new GetResourceChangeLogEmpty(schema.getSchemaName());\n-                if (adapter.runStatement(isEmpty)) {\n-                    // change log is empty, so we need to backfill it with data\n-                    for (String resourceTypeName : resourceTypes) {\n-                        logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                                + \" resources for tenant '\" + ti.getTenantName() + \"', schema '\" + ti.getTenantSchema() + \"'\");\n-                        BackfillResourceChangeLogDb2 backfill = new BackfillResourceChangeLogDb2(schema.getSchemaName(), resourceTypeName);\n-                        adapter.runStatement(backfill);\n-                    }\n-                } else {\n-                    logger.info(\"RESOURCE_CHANGE_LOG has data for tenant '\" + ti.getTenantName() + \"' so skipping backfill\");\n-                }\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Backfill the RESOURCE_CHANGE_LOG table for all the resource types. Non-multi-tenant\n-     * implementation\n-     *\n-     * @param adapter\n-     */\n-    private void doBackfill(IDatabaseAdapter adapter) {\n-        Set<String> resourceTypes = getResourceTypes();\n-\n-        for (String resourceTypeName : resourceTypes) {\n-            logger.info(\"Backfilling RESOURCE_CHANGE_LOG with \" + resourceTypeName\n-                    + \" resources for schema '\" + schema.getSchemaName() + \"'\");\n-            BackfillResourceChangeLog backfill = new BackfillResourceChangeLog(schema.getSchemaName(), resourceTypeName);\n-            adapter.runStatement(backfill);\n-        }\n-    }\n-\n-    /**\n-     * updates the vacuum settings for postgres.\n-     */\n-    public void updateVacuumSettings() {\n-        if (dbType != DbType.POSTGRESQL) {\n-            logger.severe(\"Updating the vacuum settings is only supported on postgres and the setting is for '\" + dbType + \"'\");\n-            return;\n-        }\n-\n-        // Create the Physical Data Model\n-        PhysicalDataModel pdm = new PhysicalDataModel();\n-        buildCommonModel(pdm, true, false, false);\n-\n-        // Setup the Connection Pool\n-        this.maxConnectionPoolSize = 10;\n-        configureConnectionPool();\n-        PostgresAdapter adapter = new PostgresAdapter(connectionPool);\n-\n-        if (vacuumTableName != null) {\n-            runSingleTable(adapter, pdm, schema.getSchemaName(), vacuumTableName);\n-        } else {\n-            // Process all tables in the schema ... except for XX_RESOURCES and COMMON_TOKEN_VALUES and COMMON_CANONICAL_VALUES\n-            GatherTablesDataModelVisitor visitor = new GatherTablesDataModelVisitor();\n-            pdm.visit(visitor);\n-\n-            for (Table tbl : visitor.getTables()) {\n-                runSingleTable(adapter, pdm, schema.getSchemaName(), tbl.getObjectName());\n-            }\n-        }\n-    }\n-\n-    /**\n-     * runs the vacuum update inside a single connection and single transaction.\n-     *\n-     * @param adapter\n-     * @param pdm\n-     * @param schemaName\n-     * @param vacuumTableName\n-     */\n-    private void runSingleTable(PostgresAdapter adapter, PhysicalDataModel pdm, String schemaName, String vacuumTableName) {\n-        try (ITransaction tx = TransactionFactory.openTransaction(connectionPool)) {\n-            try {\n-                // If the vacuumTableName exists, then we try finding the table definition.\n-                Table table = pdm.findTable(schemaName, vacuumTableName);\n-                if (table == null) {\n-                    logger.severe(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                    throw new IllegalArgumentException(\"Table [\" + vacuumTableName + \"] is not found, and no vacuum settings are able to be updated.\");\n-                }\n-                PostgresVacuumSettingDAO alterVacuumSettings =\n-                        new PostgresVacuumSettingDAO(schemaName, table.getObjectName(), vacuumCostLimit, vacuumScaleFactor, vacuumThreshold);\n-                adapter.runStatement(alterVacuumSettings);\n-            } catch (DataAccessException x) {\n-                // Something went wrong, so mark the transaction as failed\n-                tx.setRollbackOnly();\n-                throw x;\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Process the requested operation\n-     */\n-    protected void process() {\n-        long start = System.nanoTime();\n-        loadDriver(translator);\n-        configureConnectionPool();\n-\n-        if (this.checkCompatibility) {\n-            checkCompatibility();\n-        }\n-\n-        if (translator.isDerby() && !\"APP\".equals(schema.getSchemaName())) {\n-            if (schema.isOverrideDataSchema()) {\n-                logger.warning(\"Only the APP schema is supported for Apache Derby; ignoring the passed\"\n-                        + \" schema name '\" + schema.getSchemaName() + \"' and using APP.\");\n-            }\n-            schema.setSchemaName(\"APP\");\n-        }\n-\n-        // [optional] use a subset of resource types to make testing quicker\n-        String resourceTypesString = properties.getProperty(\"resourceTypes\");\n-        if (resourceTypesString != null && resourceTypesString.length() > 0) {\n-            resourceTypeSubset = new HashSet<>(Arrays.asList(resourceTypesString.split(\",\")));\n-        }\n-\n-        if (addKeyForTenant != null) {\n-            addTenantKey();\n-        } else if (updateVacuum) {\n-            updateVacuumSettings();\n-        } else if (this.dropAdmin || this.dropFhirSchema || this.dropJavaBatchSchema || this.dropOauthSchema) {\n-            // only proceed with the drop if the user has provided additional confirmation\n-            if (this.confirmDrop) {\n-                dropSchema();\n-            } else {\n-                throw new IllegalArgumentException(\"[ERROR] Drop not confirmed with --confirm-drop\");\n-            }\n-        } else if (updateFhirSchema || updateOauthSchema || updateJavaBatchSchema) {\n-            updateSchemas();\n-        } else if (createFhirSchema || createOauthSchema || createJavaBatchSchema) {\n-            createSchemas();\n-        } else if (updateProc) {\n-            updateProcedures();\n-        } else if (grantTo != null) {\n-            grantPrivileges();\n-        } else if (this.listTenants) {\n-            listTenants();\n-        } else if (this.allocateTenant) {\n-            allocateTenant();\n-        } else if (this.refreshTenants) {\n-            refreshTenants();\n-        } else if (this.testTenant) {\n-            testTenant();\n-        } else if (this.freezeTenant) {\n-            freezeTenant();\n-        } else if (this.dropDetached) {\n-            dropDetachedPartitionTables();\n-        } else if (this.deleteTenantMeta) {\n-            deleteTenantMeta();\n-        } else if (this.dropTenant) {\n-            dropTenant();\n-        } else if (this.revokeTenantKey) {\n-            revokeTenantKey();\n-        } else if (this.revokeAllTenantKeys) {\n-            if (this.tenantKey != null) {\n-                throw new IllegalArgumentException(\"[ERROR] --tenant-key <key-value> should not be specified together with --drop-all-tenant-keys\");\n-            }\n-            revokeTenantKey();\n-        }\n-\n-        long elapsed = System.nanoTime() - start;\n-        logger.info(String.format(\"Processing took: %7.3f s\", elapsed / NANOS));\n-    }\n-\n-    /**\n-     * Get the program exit status from the environment\n-     *\n-     * @return\n-     */\n-    protected int getExitStatus() {\n-        return this.exitStatus;\n-    }\n-\n-    /**\n-     * Write a final status message - useful for QA to review when checking the\n-     * output\n-     */\n-    protected void logStatusMessage(int status) {\n-        switch (status) {\n-        case EXIT_OK:\n-            logger.info(\"SCHEMA CHANGE: OK\");\n-            break;\n-        case EXIT_BAD_ARGS:\n-            logger.severe(\"SCHEMA CHANGE: BAD ARGS\");\n-            break;\n-        case EXIT_RUNTIME_ERROR:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        case EXIT_VALIDATION_FAILED:\n-            logger.warning(\"SCHEMA CHANGE: FAILED\");\n-            break;\n-        default:\n-            logger.severe(\"SCHEMA CHANGE: RUNTIME ERROR\");\n-            break;\n-        }\n-    }\n-\n-    /**\n-     * Log warning messages for deprecated tables.\n-     */\n-    private void logWarningMessagesForDeprecatedTables() {\n-        List<String> deprecatedTables =\n-                Arrays.asList(\"DOMAINRESOURCE_DATE_VALUES\", \"DOMAINRESOURCE_LATLNG_VALUES\", \"DOMAINRESOURCE_LOGICAL_RESOURCES\", \"DOMAINRESOURCE_NUMBER_VALUES\", \"DOMAINRESOURCE_QUANTITY_VALUES\", \"DOMAINRESOURCE_RESOURCE_TOKEN_REFS\", \"DOMAINRESOURCE_RESOURCES\", \"DOMAINRESOURCE_STR_VALUES\", \"RESOURCE_DATE_VALUES\", \"RESOURCE_LATLNG_VALUES\", \"RESOURCE_LOGICAL_RESOURCES\", \"RESOURCE_NUMBER_VALUES\", \"RESOURCE_QUANTITY_VALUES\", \"RESOURCE_RESOURCE_TOKEN_REFS\", \"RESOURCE_RESOURCES\", \"RESOURCE_STR_VALUES\");\n-        for (String deprecatedTable : deprecatedTables) {\n-            logger.warning(\"Table '\" + deprecatedTable\n-                    + \"' will be dropped in a future release. No data should be written to this table. If any data exists in the table, that data should be deleted.\");\n-        }\n-    }\n-\n-    /**\n-     * Main entry point\n-     *\n-     * @param args\n-     */\n-    public static void main(String[] args) {\n-        logClasspath(logger);\n-\n-        int exitStatus;\n-        Main m = new Main();\n-        try {\n-            configureLogger();\n-            m.parseArgs(args);\n-            m.process();\n-            exitStatus = m.getExitStatus();\n-        } catch (TableSpaceRemovalException x) {\n-            logger.warning(\"Tablespace removal is not complete, as an async dependency has not finished dettaching. Please re-try.\");\n-            exitStatus = EXIT_TABLESPACE_REMOVAL_NOT_COMPLETE;\n-        } catch (ConcurrentUpdateException x) {\n-            logger.log(Level.WARNING, \"Update is already running. Please re-try later.\", x);\n-            exitStatus = EXIT_CONCURRENT_UPDATE;\n-        } catch (DatabaseNotReadyException x) {\n-            logger.log(Level.SEVERE, \"The database is not yet available. Please re-try.\", x);\n-            exitStatus = EXIT_NOT_READY;\n-        } catch (IllegalArgumentException x) {\n-            logger.log(Level.SEVERE, \"bad argument\", x);\n-            printUsage();\n-            exitStatus = EXIT_BAD_ARGS;\n-        } catch (Exception x) {\n-            logger.log(Level.SEVERE, \"schema tool failed\", x);\n-            exitStatus = EXIT_RUNTIME_ERROR;\n-        }\n-\n-        // Write out a final status message to make it easy to see validation success/failure\n-        m.logStatusMessage(exitStatus);\n-\n-        // almost certainly will get flagged during code-scan, but this is intentional,\n-        // as we genuinely want to exit with the correct status here. The code-scan tool\n-        // really ought to be able to see that this is a main function in a J2SE environment\n-        System.exit(exitStatus);\n-    }\n-}\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTI4NQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420721285", "body": "same line", "bodyText": "same line", "bodyHTML": "<p dir=\"auto\">same line</p>", "author": "prb112", "createdAt": "2020-05-06T11:33:14Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java", "diffHunk": "@@ -6,75 +6,101 @@\n \n package com.ibm.fhir.persistence.jdbc.postgresql;\n \n+import java.sql.CallableStatement;\n import java.sql.Connection;\n import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n-import com.ibm.fhir.persistence.jdbc.dao.api.FhirRefSequenceDAO;\n import com.ibm.fhir.persistence.jdbc.dao.impl.ParameterNameDAOImpl;\n+import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBCleanupException;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlParameterNamesDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlParameterNamesDAO.class.getName();\n+    private static final String SQL_CALL_ADD_PARAMETER_NAME = \"{CALL %s.add_parameter_name(?, ?)}\";\n \n-    public PostgreSqlParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlParameterNamesDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param parameterName\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n     public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getParameterId(parameterName);\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n+        int parameterNameId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n \n-                final String INS = \"INSERT INTO parameter_names (parameter_name_id, parameter_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, parameterName);\n-                    stmt.executeUpdate();\n+        try {\n+            // TODO: schema should be known by application. Fix to avoid an extra round-trip.\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, parameterName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read/store parameter name id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n-            } catch (SQLException e) {\n-                throw new FHIRPersistenceDataAccessException(\"Error while getting or inserting parameterName '\" + parameterName + \"'\", e);\n+                parameterNameId = stmt.getInt(2);\n             }\n         }\n-\n-        // cannot be null, so safe to return as an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return parameterNameId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param parameterName\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getParameterId(String parameterName) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n+        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        String sql = \"SELECT parameter_name_id FROM parameter_names WHERE parameter_name = ?\";\n+        FHIRPersistenceDBCleanupException ce;\n \n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql)) {\n-            stmt.setString(1, parameterName);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n-            }  else {\n-                result = null;\n+        if (stmt != null) {\n+            try {\n+                stmt.close();\n+            }\n+            catch (Throwable e) {\n+                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n+                log.log(Level.SEVERE, ce.getMessage(), ce);\n             }\n         }\n-        catch (SQLException x) {\n-            throw new FHIRPersistenceDataAccessException(\"parameterName=\" + parameterName, x);\n+        if(connection != null && this.getConnection() == null) {\n+            try {\n+                connection.close();\n+            }\n+            catch (Throwable e) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\nindex 27c92520e7..30334a2e6a 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n", "chunk": "@@ -60,47 +58,11 @@ public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n                 }\n                 parameterNameId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return parameterNameId;\n     }\n-\n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTM0MQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420721341", "body": "same line", "bodyText": "same line", "bodyHTML": "<p dir=\"auto\">same line</p>", "author": "prb112", "createdAt": "2020-05-06T11:33:21Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java", "diffHunk": "@@ -6,75 +6,101 @@\n \n package com.ibm.fhir.persistence.jdbc.postgresql;\n \n+import java.sql.CallableStatement;\n import java.sql.Connection;\n import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n-import com.ibm.fhir.persistence.jdbc.dao.api.FhirRefSequenceDAO;\n import com.ibm.fhir.persistence.jdbc.dao.impl.ParameterNameDAOImpl;\n+import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBCleanupException;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlParameterNamesDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlParameterNamesDAO.class.getName();\n+    private static final String SQL_CALL_ADD_PARAMETER_NAME = \"{CALL %s.add_parameter_name(?, ?)}\";\n \n-    public PostgreSqlParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlParameterNamesDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param parameterName\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n     public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getParameterId(parameterName);\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n+        int parameterNameId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n \n-                final String INS = \"INSERT INTO parameter_names (parameter_name_id, parameter_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, parameterName);\n-                    stmt.executeUpdate();\n+        try {\n+            // TODO: schema should be known by application. Fix to avoid an extra round-trip.\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, parameterName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read/store parameter name id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n-            } catch (SQLException e) {\n-                throw new FHIRPersistenceDataAccessException(\"Error while getting or inserting parameterName '\" + parameterName + \"'\", e);\n+                parameterNameId = stmt.getInt(2);\n             }\n         }\n-\n-        // cannot be null, so safe to return as an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return parameterNameId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param parameterName\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getParameterId(String parameterName) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n+        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        String sql = \"SELECT parameter_name_id FROM parameter_names WHERE parameter_name = ?\";\n+        FHIRPersistenceDBCleanupException ce;\n \n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql)) {\n-            stmt.setString(1, parameterName);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n-            }  else {\n-                result = null;\n+        if (stmt != null) {\n+            try {\n+                stmt.close();\n+            }\n+            catch (Throwable e) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\nindex 27c92520e7..30334a2e6a 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n", "chunk": "@@ -60,47 +58,11 @@ public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n                 }\n                 parameterNameId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return parameterNameId;\n     }\n-\n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTg4Nw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420721887", "body": "once again, it's a pool, this is a confusing method, when is it called, why is it called, why is it used. \r\nThe preparedstatement should be autocloseable. \r\n\r\nIn fact in this case, I think it should be removed all together. ", "bodyText": "once again, it's a pool, this is a confusing method, when is it called, why is it called, why is it used.\nThe preparedstatement should be autocloseable.\nIn fact in this case, I think it should be removed all together.", "bodyHTML": "<p dir=\"auto\">once again, it's a pool, this is a confusing method, when is it called, why is it called, why is it used.<br>\nThe preparedstatement should be autocloseable.</p>\n<p dir=\"auto\">In fact in this case, I think it should be removed all together.</p>", "author": "prb112", "createdAt": "2020-05-06T11:34:28Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java", "diffHunk": "@@ -6,75 +6,101 @@\n \n package com.ibm.fhir.persistence.jdbc.postgresql;\n \n+import java.sql.CallableStatement;\n import java.sql.Connection;\n import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n-import com.ibm.fhir.persistence.jdbc.dao.api.FhirRefSequenceDAO;\n import com.ibm.fhir.persistence.jdbc.dao.impl.ParameterNameDAOImpl;\n+import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBCleanupException;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlParameterNamesDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlParameterNamesDAO.class.getName();\n+    private static final String SQL_CALL_ADD_PARAMETER_NAME = \"{CALL %s.add_parameter_name(?, ?)}\";\n \n-    public PostgreSqlParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlParameterNamesDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param parameterName\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n     public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getParameterId(parameterName);\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n+        int parameterNameId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n \n-                final String INS = \"INSERT INTO parameter_names (parameter_name_id, parameter_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, parameterName);\n-                    stmt.executeUpdate();\n+        try {\n+            // TODO: schema should be known by application. Fix to avoid an extra round-trip.\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, parameterName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read/store parameter name id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n-            } catch (SQLException e) {\n-                throw new FHIRPersistenceDataAccessException(\"Error while getting or inserting parameterName '\" + parameterName + \"'\", e);\n+                parameterNameId = stmt.getInt(2);\n             }\n         }\n-\n-        // cannot be null, so safe to return as an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {\n+            this.cleanup(null, getConnection());\n+            log.exiting(CLASSNAME, METHODNAME);\n+        }\n+        return parameterNameId;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param parameterName\n-     * @return the database id, or null if the named record is not found\n-     * @throws FHIRPersistenceDataAccessException\n+     * Closes the passed PreparedStatement and Connection objects.\n+     * @param stmt\n+     * @param connection\n      */\n-    protected Integer getParameterId(String parameterName) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    protected void cleanup(PreparedStatement stmt, Connection connection)  {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIyMDc2OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421220768", "bodyText": "this doesn't really close the connection, just return the connection to the pool. it's the same in db2 codes. but seems no harm to just drop it here.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:41:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTg4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\nindex 27c92520e7..30334a2e6a 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n", "chunk": "@@ -60,47 +58,11 @@ public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n                 }\n                 parameterNameId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return parameterNameId;\n     }\n-\n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTk1Ng==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420721956", "body": "same line", "bodyText": "same line", "bodyHTML": "<p dir=\"auto\">same line</p>", "author": "prb112", "createdAt": "2020-05-06T11:34:35Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java", "diffHunk": "@@ -6,75 +6,101 @@\n \n package com.ibm.fhir.persistence.jdbc.postgresql;\n \n+import java.sql.CallableStatement;\n import java.sql.Connection;\n import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n-import com.ibm.fhir.persistence.jdbc.dao.api.FhirRefSequenceDAO;\n import com.ibm.fhir.persistence.jdbc.dao.impl.ParameterNameDAOImpl;\n+import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBCleanupException;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlParameterNamesDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlParameterNamesDAO.class.getName();\n+    private static final String SQL_CALL_ADD_PARAMETER_NAME = \"{CALL %s.add_parameter_name(?, ?)}\";\n \n-    public PostgreSqlParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlParameterNamesDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param parameterName\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n     public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getParameterId(parameterName);\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n+        int parameterNameId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n \n-                final String INS = \"INSERT INTO parameter_names (parameter_name_id, parameter_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, parameterName);\n-                    stmt.executeUpdate();\n+        try {\n+            // TODO: schema should be known by application. Fix to avoid an extra round-trip.\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, parameterName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read/store parameter name id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n-            } catch (SQLException e) {\n-                throw new FHIRPersistenceDataAccessException(\"Error while getting or inserting parameterName '\" + parameterName + \"'\", e);\n+                parameterNameId = stmt.getInt(2);\n             }\n         }\n-\n-        // cannot be null, so safe to return as an int\n-        return result;\n+        catch (Throwable e) {\n+            throw new FHIRPersistenceDataAccessException(errMsg,e);\n+        }\n+        finally {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\nindex 27c92520e7..30334a2e6a 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n", "chunk": "@@ -60,47 +58,11 @@ public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n                 }\n                 parameterNameId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return parameterNameId;\n     }\n-\n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjAzMw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420722033", "body": "same line", "bodyText": "same line", "bodyHTML": "<p dir=\"auto\">same line</p>", "author": "prb112", "createdAt": "2020-05-06T11:34:41Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java", "diffHunk": "@@ -6,75 +6,101 @@\n \n package com.ibm.fhir.persistence.jdbc.postgresql;\n \n+import java.sql.CallableStatement;\n import java.sql.Connection;\n import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n-import com.ibm.fhir.persistence.jdbc.dao.api.FhirRefSequenceDAO;\n import com.ibm.fhir.persistence.jdbc.dao.impl.ParameterNameDAOImpl;\n+import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBCleanupException;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlParameterNamesDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlParameterNamesDAO.class.getName();\n+    private static final String SQL_CALL_ADD_PARAMETER_NAME = \"{CALL %s.add_parameter_name(?, ?)}\";\n \n-    public PostgreSqlParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlParameterNamesDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n     }\n \n+    /**\n+     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param parameterName\n+     * @return The generated id of the stored system.\n+     * @throws FHIRPersistenceDataAccessException\n+     */\n     @Override\n     public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getParameterId(parameterName);\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n+        int parameterNameId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n \n-                final String INS = \"INSERT INTO parameter_names (parameter_name_id, parameter_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, parameterName);\n-                    stmt.executeUpdate();\n+        try {\n+            // TODO: schema should be known by application. Fix to avoid an extra round-trip.\n+            currentSchema = getConnection().getSchema().trim();\n+            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, currentSchema);\n+            try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n+                stmt.setString(1, parameterName);\n+                stmt.registerOutParameter(2, Types.INTEGER);\n+                dbCallStartTime = System.nanoTime();\n+                stmt.execute();\n+                dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+                if (log.isLoggable(Level.FINE)) {\n+                        log.fine(\"DB read/store parameter name id complete. executionTime=\" + dbCallDuration + \"ms\");\n                 }\n-            } catch (SQLException e) {\n-                throw new FHIRPersistenceDataAccessException(\"Error while getting or inserting parameterName '\" + parameterName + \"'\", e);\n+                parameterNameId = stmt.getInt(2);\n             }\n         }\n-\n-        // cannot be null, so safe to return as an int\n-        return result;\n+        catch (Throwable e) {", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\nindex 27c92520e7..30334a2e6a 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n", "chunk": "@@ -60,47 +58,11 @@ public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n                 }\n                 parameterNameId = stmt.getInt(2);\n             }\n-        }\n-        catch (Throwable e) {\n+        } catch (Throwable e) {\n             throw new FHIRPersistenceDataAccessException(errMsg,e);\n-        }\n-        finally {\n-            this.cleanup(null, getConnection());\n+        } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n         return parameterNameId;\n     }\n-\n-    /**\n-     * Closes the passed PreparedStatement and Connection objects.\n-     * @param stmt\n-     * @param connection\n-     */\n-    protected void cleanup(PreparedStatement stmt, Connection connection)  {\n-        final String METHODNAME = \"cleanup(PreparedStatement, Connection)\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        FHIRPersistenceDBCleanupException ce;\n-\n-        if (stmt != null) {\n-            try {\n-                stmt.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing PreparedStatement.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        if(connection != null && this.getConnection() == null) {\n-            try {\n-                connection.close();\n-            }\n-            catch (Throwable e) {\n-                ce =  new FHIRPersistenceDBCleanupException(\"Failure closing Connection.\",e);\n-                log.log(Level.SEVERE, ce.getMessage(), ce);\n-            }\n-        }\n-        log.exiting(CLASSNAME, METHODNAME);\n-    }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjUyOQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420722529", "body": "it says postgres above, why does it state db2 on this line. ", "bodyText": "it says postgres above, why does it state db2 on this line.", "bodyHTML": "<p dir=\"auto\">it says postgres above, why does it state db2 on this line.</p>", "author": "prb112", "createdAt": "2020-05-06T11:35:37Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java", "diffHunk": "@@ -367,31 +369,72 @@ public void buildSchema(PhysicalDataModel model) {\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Add stored procedures/functions for postgresql.\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIyMTIyOA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421221228", "bodyText": "typo error, fixed.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:43:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjUyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex ee8a8954db..06a3316e70 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -416,7 +416,7 @@ public class FhirSchemaGenerator {\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n", "next_change": {"commit": "dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 06a3316e70..131031893d 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -420,7 +422,7 @@ public class FhirSchemaGenerator {\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n-                ADD_RESOURCE_TYPE,\n+                ADD_RESOURCE_TYPE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n", "next_change": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 131031893d..b24ad9ffca 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -421,7 +421,7 @@ public class FhirSchemaGenerator {\n                 procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        pd = model.addProcedureAndFunctions(this.schemaName,\n                 ADD_RESOURCE_TYPE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b24ad9ffca..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,85 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n         // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n-        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_CODE_SYSTEM + \"_pg\",\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_PARAMETER_NAME + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_RESOURCE_TYPE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_ANY_RESOURCE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 131031893d..b24ad9ffca 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -430,7 +430,7 @@ public class FhirSchemaGenerator {\n                 procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        pd = model.addProcedureAndFunctions(this.schemaName,\n                 ADD_ANY_RESOURCE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b24ad9ffca..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,85 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n         // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n-        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_CODE_SYSTEM + \"_pg\",\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_PARAMETER_NAME + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_RESOURCE_TYPE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_ANY_RESOURCE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjU1OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420722558", "body": "it says postgres above, why does it state db2 on this line. ", "bodyText": "it says postgres above, why does it state db2 on this line.", "bodyHTML": "<p dir=\"auto\">it says postgres above, why does it state db2 on this line.</p>", "author": "prb112", "createdAt": "2020-05-06T11:35:41Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java", "diffHunk": "@@ -367,31 +369,72 @@ public void buildSchema(PhysicalDataModel model) {\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Add stored procedures/functions for postgresql.\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex ee8a8954db..06a3316e70 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -407,7 +407,7 @@ public class FhirSchemaGenerator {\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n", "next_change": {"commit": "dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 06a3316e70..131031893d 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -411,7 +413,7 @@ public class FhirSchemaGenerator {\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n-                ADD_PARAMETER_NAME,\n+                ADD_PARAMETER_NAME + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n", "next_change": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 131031893d..b24ad9ffca 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -412,7 +412,7 @@ public class FhirSchemaGenerator {\n                 procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        pd = model.addProcedureAndFunctions(this.schemaName,\n                 ADD_PARAMETER_NAME + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b24ad9ffca..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,85 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n         // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n-        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_CODE_SYSTEM + \"_pg\",\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_PARAMETER_NAME + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_RESOURCE_TYPE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_ANY_RESOURCE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 131031893d..b24ad9ffca 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -421,7 +421,7 @@ public class FhirSchemaGenerator {\n                 procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        pd = model.addProcedureAndFunctions(this.schemaName,\n                 ADD_RESOURCE_TYPE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b24ad9ffca..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,85 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n         // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n-        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_CODE_SYSTEM + \"_pg\",\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_PARAMETER_NAME + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_RESOURCE_TYPE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_ANY_RESOURCE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjYwMg==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420722602", "body": "it says postgres above, why does it state db2 on this line. ", "bodyText": "it says postgres above, why does it state db2 on this line.", "bodyHTML": "<p dir=\"auto\">it says postgres above, why does it state db2 on this line.</p>", "author": "prb112", "createdAt": "2020-05-06T11:35:49Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java", "diffHunk": "@@ -367,31 +369,72 @@ public void buildSchema(PhysicalDataModel model) {\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Add stored procedures/functions for postgresql.\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex ee8a8954db..06a3316e70 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,7 +425,7 @@ public class FhirSchemaGenerator {\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n", "next_change": {"commit": "dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 06a3316e70..131031893d 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -429,7 +431,7 @@ public class FhirSchemaGenerator {\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n-                ADD_ANY_RESOURCE,\n+                ADD_ANY_RESOURCE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n", "next_change": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 131031893d..b24ad9ffca 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -430,7 +430,7 @@ public class FhirSchemaGenerator {\n                 procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        pd = model.addProcedureAndFunctions(this.schemaName,\n                 ADD_ANY_RESOURCE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b24ad9ffca..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,85 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n+        pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n         // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n-        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_CODE_SYSTEM + \"_pg\",\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_PARAMETER_NAME + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_RESOURCE_TYPE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedureAndFunctions(this.schemaName,\n-                ADD_ANY_RESOURCE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjY0Ng==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420722646", "body": "it says postgres above, why does it state db2 on this line. ", "bodyText": "it says postgres above, why does it state db2 on this line.", "bodyHTML": "<p dir=\"auto\">it says postgres above, why does it state db2 on this line.</p>", "author": "prb112", "createdAt": "2020-05-06T11:35:54Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java", "diffHunk": "@@ -367,31 +369,72 @@ public void buildSchema(PhysicalDataModel model) {\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Add stored procedures/functions for postgresql.\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        pd = model.addProcedure(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaConstants.INITIAL_VERSION,\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n+                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+                procedurePrivileges, DbType.DB2);", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex ee8a8954db..06a3316e70 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -434,7 +434,7 @@ public class FhirSchemaGenerator {\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 06a3316e70..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,83 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedure(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n-        pd = model.addProcedure(this.schemaName,\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        fd = model.addFunction(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        fd = model.addFunction(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n+        fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjc4OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420722788", "body": "This should be in a different method specific to functions. \r\n", "bodyText": "This should be in a different method specific to functions.", "bodyHTML": "<p dir=\"auto\">This should be in a different method specific to functions.</p>", "author": "prb112", "createdAt": "2020-05-06T11:36:10Z", "path": "fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java", "diffHunk": "@@ -367,31 +369,72 @@ public void buildSchema(PhysicalDataModel model) {\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges);\n+                procedurePrivileges,\n+                DbType.DB2);\n+        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Add stored procedures/functions for postgresql.", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIyMTYyNw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421221627", "bodyText": "as answered above, want to keep it simpler for now, we may just need to change to use the real postgresql stored procedure in the future when it support out parameter.", "author": "albertwang-ibm", "createdAt": "2020-05-07T03:45:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMjc4OA=="}], "type": "inlineReview", "revised_code": {"commit": "dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex ee8a8954db..131031893d 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -401,40 +401,42 @@ public class FhirSchemaGenerator {\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         // Add stored procedures/functions for postgresql.\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n         pd = model.addProcedure(this.schemaName,\n-                ADD_CODE_SYSTEM,\n+                ADD_CODE_SYSTEM + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n-                ADD_PARAMETER_NAME,\n+                ADD_PARAMETER_NAME + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n-                ADD_RESOURCE_TYPE,\n+                ADD_RESOURCE_TYPE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n-                ADD_ANY_RESOURCE,\n+                ADD_ANY_RESOURCE + \"_pg\",\n                 FhirSchemaConstants.INITIAL_VERSION,\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n                         + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.DB2);\n+                procedurePrivileges, DbType.POSTGRESQL);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 131031893d..2dd28147f7 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -359,85 +354,81 @@ public class FhirSchemaGenerator {\n         this.allTablesComplete.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n         this.allTablesComplete.addDependencies(procedureDependencies);\n         model.addObject(allTablesComplete);\n-\n+    }\n+    \n+    public void buildDatabaseSpecificArtifactsDb2(PhysicalDataModel model) {\n         // These procedures just depend on the table they are manipulating and the fhir sequence. But\n         // to avoid deadlocks, we only apply them after all the tables are done, so we make all\n         // procedures depend on the allTablesComplete marker.\n-        ProcedureDef pd;\n-        pd = model.addProcedure(this.schemaName,\n+        final String ROOT_DIR = \"db2/\";\n+        ProcedureDef pd = model.addProcedure(this.schemaName,\n                 ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         pd = model.addProcedure(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges,\n-                DbType.DB2);\n+                procedurePrivileges);\n         pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n \n+    public void buildDatabaseSpecificArtifactsPostgres(PhysicalDataModel model) {\n         // Add stored procedures/functions for postgresql.\n         // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n-        // and the appended \"_pg\" will be removed when creating the stored procedure for postgresql.\n-        pd = model.addProcedure(this.schemaName,\n-                ADD_CODE_SYSTEM + \"_pg\",\n+        final String ROOT_DIR = \"postgres/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_CODE_SYSTEM.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n                 Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n-                ADD_PARAMETER_NAME + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_PARAMETER_NAME.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n-                ADD_RESOURCE_TYPE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_RESOURCE_TYPE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        pd = model.addProcedure(this.schemaName,\n-                ADD_ANY_RESOURCE + \"_pg\",\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n                 FhirSchemaConstants.INITIAL_VERSION,\n-                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ADD_ANY_RESOURCE.toLowerCase()\n-                        + \"_\" + DbType.POSTGRESQL.value() + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-                procedurePrivileges, DbType.POSTGRESQL);\n-        pd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "130ee61c106cda5fb9dd88625179da01b947e703", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2dd28147f7..0a1fa356a9 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -424,7 +420,7 @@ public class FhirSchemaGenerator {\n \n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n-                FhirSchemaConstants.INITIAL_VERSION,\n+                FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n", "next_change": {"commit": "924cff2310953a498a8d253fd92e3125b26ae1f0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 0a1fa356a9..099874bc05 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -425,6 +473,13 @@ public class FhirSchemaGenerator {\n                         + \".sql\", null),\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n", "next_change": {"commit": "9cdcd4d8a03927880dd4545c6bd01f7f67c1e1f6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 099874bc05..b98b72ace5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -466,19 +496,28 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n         fd = model.addFunction(this.schemaName,\n                 ADD_ANY_RESOURCE,\n                 FhirSchemaVersion.V0001.vid(),\n                 () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n                         + \".sql\", null),\n-                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n             () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n", "next_change": {"commit": "7244dcee90fb87bbff0296b3b35cfb78bbcd85b6", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex b98b72ace5..2d4e218c03 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -521,6 +526,65 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * @implNote following the current pattern, which is why all this stuff is replicated\n+     * @param model\n+     */\n+    public void buildDatabaseSpecificArtifactsCitus(PhysicalDataModel model) {\n+        // Add stored procedures/functions for postgresql and Citus\n+        // Have to use different object names from DB2, because the group processing doesn't support 2 objects with the same name.\n+        final String ROOT_DIR = \"postgres/\";\n+        final String CITUS_ROOT_DIR = \"citus/\";\n+        FunctionDef fd = model.addFunction(this.schemaName,\n+                ADD_CODE_SYSTEM,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_CODE_SYSTEM.toLowerCase() + \".sql\", null),\n+                Arrays.asList(fhirSequence, codeSystemsTable, allTablesComplete),\n+                procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_PARAMETER_NAME,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_PARAMETER_NAME.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, parameterNamesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+                ADD_RESOURCE_TYPE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ADD_RESOURCE_TYPE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n+            DELETE_RESOURCE_PARAMETERS,\n+            FhirSchemaVersion.V0020.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n+            procedurePrivileges);\n+        deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        // Use the Citus-specific variant of add_any_resource (supports sharding)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n+                        + \".sql\", null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+\n+        fd = model.addFunction(this.schemaName,\n+            ERASE_RESOURCE,\n+            FhirSchemaVersion.V0013.vid(),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n+        fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "68819abc2f1c859263598931f2cddb61f8987eb0", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 2d4e218c03..d149072491 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -585,6 +610,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "390febe5f6e5f0ce9f8fd41bc2d314a51bbce0f3", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex d149072491..7bdd123870 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -610,14 +524,6 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n-    /**\n-     * Are we building the Db2-specific multitenant schema variant\n-     * @return\n-     */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n-    }\n-\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "7125f67a9527113265dcd566acc20e4ab2f39b27", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 7bdd123870..5687302faf 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -524,6 +626,14 @@ public class FhirSchemaGenerator {\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n+    /**\n+     * Are we building the Db2-specific multitenant schema variant\n+     * @return\n+     */\n+    private boolean isMultitenant() {\n+        return this.schemaType == SchemaType.MULTITENANT;\n+    }\n+\n     /**\n      * Add the system-wide logical_resources table. Note that LOGICAL_ID is\n      * denormalized, stored in both LOGICAL_RESOURCES and <RESOURCE_TYPE>_LOGICAL_RESOURCES.\n", "next_change": {"commit": "2da203161b972bc56757ae655009283659b12c6a", "changed_code": [{"header": "diff --git a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\nindex 5687302faf..9a841a19c5 100644\n--- a/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n+++ b/fhir-persistence-schema/src/main/java/com/ibm/fhir/schema/control/FhirSchemaGenerator.java\n", "chunk": "@@ -591,47 +503,63 @@ public class FhirSchemaGenerator {\n                 Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Add the delete resource parameters function and distribute using logical_resource_id (param $2)\n+        // We currently only support functions with PostgreSQL, although this is really just a procedure\n+        final String deleteResourceParametersScript;\n+        final String addAnyResourceScript;\n+        final String eraseResourceScript;\n+        final String schemaTypeSuffix = getSchemaTypeSuffix();\n+        addAnyResourceScript = CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase() + schemaTypeSuffix;\n+        deleteResourceParametersScript = ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\";\n+        eraseResourceScript = ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\";\n+        final String addLogicalResourceIdentScript = CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE_IDENT.toLowerCase() + \".sql\";\n+        \n         FunctionDef deleteResourceParameters = model.addFunction(this.schemaName,\n             DELETE_RESOURCE_PARAMETERS,\n             FhirSchemaVersion.V0020.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + DELETE_RESOURCE_PARAMETERS.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, deleteResourceParametersScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, allTablesComplete),\n-            procedurePrivileges, 2);\n+            procedurePrivileges, 2); // distributed by p_logical_resource_id\n         deleteResourceParameters.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n-        // Use the Citus-specific function which is distributed using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_LOGICAL_RESOURCE,\n+        // For Citus, we use an additional function to create/lock the logical_resource_ident record\n+        // Function is distributed by p_logical_id (parameter 2)\n+        fd = model.addFunction(this.schemaName,\n+            ADD_LOGICAL_RESOURCE_IDENT,\n             FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_LOGICAL_RESOURCE.toLowerCase() + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete),\n-            procedurePrivileges, 1);\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addLogicalResourceIdentScript, null),\n+            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 2);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n-        final FunctionDef addLogicalResource = fd;\n \n-        // Use the Citus-specific variant of add_any_resource and distribute using logical_resource_id (param $1)\n-        fd = model.addFunction(this.schemaName, ADD_ANY_RESOURCE,\n-            FhirSchemaVersion.V0001.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, CITUS_ROOT_DIR + ADD_ANY_RESOURCE.toLowerCase()\n-                    + \".sql\", null),\n-            Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete, addLogicalResource),\n-            procedurePrivileges, 1);\n+        // Function is distributed by p_logical_resource_id (parameter 1)\n+        fd = model.addFunction(this.schemaName,\n+                ADD_ANY_RESOURCE,\n+                FhirSchemaVersion.V0001.vid(),\n+                () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, addAnyResourceScript, null),\n+                Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges, 1);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n \n         fd = model.addFunction(this.schemaName,\n             ERASE_RESOURCE,\n             FhirSchemaVersion.V0013.vid(),\n-            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, ROOT_DIR + ERASE_RESOURCE.toLowerCase() + \".sql\", null),\n+            () -> SchemaGeneratorUtil.readTemplate(adminSchemaName, schemaName, eraseResourceScript, null),\n             Arrays.asList(fhirSequence, resourceTypesTable, deleteResourceParameters, allTablesComplete), procedurePrivileges);\n         fd.addTag(SCHEMA_GROUP_TAG, FHIRDATA_GROUP);\n     }\n \n     /**\n-     * Are we building the Db2-specific multitenant schema variant\n+     * Get the suffix to select the appropriate procedure/function script \n+     * for the schema type\n      * @return\n      */\n-    private boolean isMultitenant() {\n-        return this.schemaType == SchemaType.MULTITENANT;\n+    private String getSchemaTypeSuffix() {\n+        switch (this.schemaType) {\n+        case DISTRIBUTED:\n+            return \".sql\";\n+        case SHARDED:\n+            return \"_sharded.sql\";\n+        default:\n+            return \".sql\";\n+        }\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNjI4MQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420726281", "body": "`throws` don't match.", "bodyText": "throws don't match.", "bodyHTML": "<p dir=\"auto\"><code>throws</code> don't match.</p>", "author": "prb112", "createdAt": "2020-05-06T11:43:08Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -78,13 +82,104 @@ public PostgreSqlResourceDAO(TransactionSynchronizationRegistry trxSynchRegistry\n      * @throws FHIRPersistenceDBConnectException\n      * @throws FHIRPersistenceVersionIdMismatchException", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTQ2MTE1MA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421461150", "bodyText": "yeah, good catch, better to be consistent with the codes, even though the exceptions are detailed sub-classes of FHIRPersistenceException from inside the function.", "author": "albertwang-ibm", "createdAt": "2020-05-07T12:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNjI4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..207477c74c 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -72,8 +66,6 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n \n     /**\n      * Inserts the passed FHIR Resource and associated search parameters to a postgresql FHIR database.\n-     * The search parameters are stored first by calling the passed parameterDao. Then the Resource is stored\n-     * by sql.\n      * @param resource The FHIR Resource to be inserted.\n      * @param parameters The Resource's search parameters to be inserted.\n      * @param parameterDao\n", "next_change": {"commit": "2f31e8de502ff9aeaf5937f4cd20903a1ac1b440", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 207477c74c..d4ff638edf 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -70,14 +70,12 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n      * @param parameters The Resource's search parameters to be inserted.\n      * @param parameterDao\n      * @return The Resource DTO\n-     * @throws FHIRPersistenceDataAccessException\n-     * @throws FHIRPersistenceDBConnectException\n-     * @throws FHIRPersistenceVersionIdMismatchException\n+     * @throws FHIRPersistenceException\n      */\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n-        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue>\";\n+        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n         Connection connection = null;\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex d4ff638edf..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -78,9 +77,8 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n-        String currentSchema;\n         String stmtString = null;\n         Integer resourceTypeId;\n         Timestamp lastUpdated;\n", "next_change": {"commit": "071291da2a9ddd8d704c5b4ed3ae89380756a4cf", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 86db7765ca..1a6caa65d6 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = getConnection(); // do not close\n+        final Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n         String stmtString = null;\n         Integer resourceTypeId;\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..207477c74c 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -82,94 +74,6 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n      * @throws FHIRPersistenceDBConnectException\n      * @throws FHIRPersistenceVersionIdMismatchException\n      */\n-//    @Override\n-//    public Resource  insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n-//            throws FHIRPersistenceException {\n-//        final String METHODNAME = \"insert\";\n-//        logger.entering(CLASSNAME, METHODNAME);\n-//\n-//        Connection connection = null;\n-//        Integer resourceTypeId;\n-//        Timestamp lastUpdated;\n-//        boolean acquiredFromCache;\n-//        long dbCallStartTime;\n-//        double dbCallDuration;\n-//\n-//        try {\n-//            connection = this.getConnection();\n-//\n-//            this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(connection);\n-//            this.parameterNameDAO = new PostgreSqlParameterNamesDAO(connection, fhirRefSequenceDAO);\n-//            this.codeSystemDAO = new PostgreSqlCodeSystemDAO(connection, fhirRefSequenceDAO);\n-//\n-//            // Get resourceTypeId from ResourceTypesCache first.\n-//            resourceTypeId = ResourceTypesCache.getResourceTypeId(resource.getResourceType());\n-//            // If no found, then get resourceTypeId from local newResourceTypeIds in case this id is already in newResourceTypeIds\n-//            // but has not been updated to ResourceTypesCache yet. newResourceTypeIds is updated to ResourceTypesCache only when the\n-//            // current transaction is committed.\n-//            if (resourceTypeId == null) {\n-//                resourceTypeId = getResourceTypeIdFromCandidatorsCache(resource.getResourceType());\n-//            }\n-//\n-//            if (resourceTypeId == null) {\n-//                acquiredFromCache = false;\n-//                resourceTypeId = getOrCreateResourceType(resource.getResourceType(), connection);\n-//                this.addResourceTypeCacheCandidate(resource.getResourceType(), resourceTypeId);\n-//            } else {\n-//                acquiredFromCache = true;\n-//            }\n-//\n-//            if (logger.isLoggable(Level.FINE)) {\n-//                logger.fine(\"resourceType=\" + resource.getResourceType() + \"  resourceTypeId=\" + resourceTypeId +\n-//                         \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ResourceTypesCache.getCacheNameForTenantDatastore());\n-//            }\n-//\n-//            lastUpdated = resource.getLastUpdated();\n-//            dbCallStartTime = System.nanoTime();\n-//\n-//            final String sourceKey = UUID.randomUUID().toString();\n-//\n-//            long resourceId = this.storeResource(resource.getResourceType(),\n-//                parameters,\n-//                resource.getLogicalId(),\n-//                resource.getData(),\n-//                lastUpdated,\n-//                resource.isDeleted(),\n-//                sourceKey,\n-//                resource.getVersionId(),\n-//                connection\n-//                );\n-//            dbCallDuration = (System.nanoTime() - dbCallStartTime)/1e6;\n-//\n-//            resource.setId(resourceId);\n-//            if (logger.isLoggable(Level.FINE)) {\n-//                logger.fine(\"Successfully inserted Resource. id=\" + resource.getId() + \" executionTime=\" + dbCallDuration + \"ms\");\n-//            }\n-//        } catch(FHIRPersistenceDBConnectException | FHIRPersistenceDataAccessException e) {\n-//            throw e;\n-//        } catch(SQLIntegrityConstraintViolationException e) {\n-//            FHIRPersistenceFKVException fx = new FHIRPersistenceFKVException(\"Encountered FK violation while inserting Resource.\");\n-//            throw severe(logger, fx, e);\n-//        } catch(SQLException e) {\n-//            if (\"99001\".equals(e.getSQLState())) {\n-//                // this is just a concurrency update, so there's no need to log the SQLException here\n-//                throw new FHIRPersistenceVersionIdMismatchException(\"Encountered version id mismatch while inserting Resource\");\n-//            } else {\n-//                FHIRPersistenceException fx = new FHIRPersistenceException(\"SQLException encountered while inserting Resource.\");\n-//                throw severe(logger, fx, e);\n-//            }\n-//        } catch(Throwable e) {\n-//            FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"Failure inserting Resource.\");\n-//            throw severe(logger, fx, e);\n-//        } finally {\n-//            this.cleanup(null, connection);\n-//            logger.exiting(CLASSNAME, METHODNAME);\n-//        }\n-//\n-//        return resource;\n-//    }\n-\n-\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n", "next_change": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 207477c74c..497144306b 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n-        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue>\";\n+        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n         Connection connection = null;\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 497144306b..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -80,9 +77,8 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n-        String currentSchema;\n         String stmtString = null;\n         Integer resourceTypeId;\n         Timestamp lastUpdated;\n", "next_change": {"commit": "071291da2a9ddd8d704c5b4ed3ae89380756a4cf", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 86db7765ca..1a6caa65d6 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = getConnection(); // do not close\n+        final Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n         String stmtString = null;\n         Integer resourceTypeId;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNjMwNA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420726304", "body": "Why is this here?  prior methodology? ", "bodyText": "Why is this here?  prior methodology?", "bodyHTML": "<p dir=\"auto\">Why is this here?  prior methodology?</p>", "author": "prb112", "createdAt": "2020-05-06T11:43:11Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -78,13 +82,104 @@ public PostgreSqlResourceDAO(TransactionSynchronizationRegistry trxSynchRegistry\n      * @throws FHIRPersistenceDBConnectException\n      * @throws FHIRPersistenceVersionIdMismatchException\n      */\n+//    @Override", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..207477c74c 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -82,94 +74,6 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n      * @throws FHIRPersistenceDBConnectException\n      * @throws FHIRPersistenceVersionIdMismatchException\n      */\n-//    @Override\n-//    public Resource  insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n-//            throws FHIRPersistenceException {\n-//        final String METHODNAME = \"insert\";\n-//        logger.entering(CLASSNAME, METHODNAME);\n-//\n-//        Connection connection = null;\n-//        Integer resourceTypeId;\n-//        Timestamp lastUpdated;\n-//        boolean acquiredFromCache;\n-//        long dbCallStartTime;\n-//        double dbCallDuration;\n-//\n-//        try {\n-//            connection = this.getConnection();\n-//\n-//            this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(connection);\n-//            this.parameterNameDAO = new PostgreSqlParameterNamesDAO(connection, fhirRefSequenceDAO);\n-//            this.codeSystemDAO = new PostgreSqlCodeSystemDAO(connection, fhirRefSequenceDAO);\n-//\n-//            // Get resourceTypeId from ResourceTypesCache first.\n-//            resourceTypeId = ResourceTypesCache.getResourceTypeId(resource.getResourceType());\n-//            // If no found, then get resourceTypeId from local newResourceTypeIds in case this id is already in newResourceTypeIds\n-//            // but has not been updated to ResourceTypesCache yet. newResourceTypeIds is updated to ResourceTypesCache only when the\n-//            // current transaction is committed.\n-//            if (resourceTypeId == null) {\n-//                resourceTypeId = getResourceTypeIdFromCandidatorsCache(resource.getResourceType());\n-//            }\n-//\n-//            if (resourceTypeId == null) {\n-//                acquiredFromCache = false;\n-//                resourceTypeId = getOrCreateResourceType(resource.getResourceType(), connection);\n-//                this.addResourceTypeCacheCandidate(resource.getResourceType(), resourceTypeId);\n-//            } else {\n-//                acquiredFromCache = true;\n-//            }\n-//\n-//            if (logger.isLoggable(Level.FINE)) {\n-//                logger.fine(\"resourceType=\" + resource.getResourceType() + \"  resourceTypeId=\" + resourceTypeId +\n-//                         \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ResourceTypesCache.getCacheNameForTenantDatastore());\n-//            }\n-//\n-//            lastUpdated = resource.getLastUpdated();\n-//            dbCallStartTime = System.nanoTime();\n-//\n-//            final String sourceKey = UUID.randomUUID().toString();\n-//\n-//            long resourceId = this.storeResource(resource.getResourceType(),\n-//                parameters,\n-//                resource.getLogicalId(),\n-//                resource.getData(),\n-//                lastUpdated,\n-//                resource.isDeleted(),\n-//                sourceKey,\n-//                resource.getVersionId(),\n-//                connection\n-//                );\n-//            dbCallDuration = (System.nanoTime() - dbCallStartTime)/1e6;\n-//\n-//            resource.setId(resourceId);\n-//            if (logger.isLoggable(Level.FINE)) {\n-//                logger.fine(\"Successfully inserted Resource. id=\" + resource.getId() + \" executionTime=\" + dbCallDuration + \"ms\");\n-//            }\n-//        } catch(FHIRPersistenceDBConnectException | FHIRPersistenceDataAccessException e) {\n-//            throw e;\n-//        } catch(SQLIntegrityConstraintViolationException e) {\n-//            FHIRPersistenceFKVException fx = new FHIRPersistenceFKVException(\"Encountered FK violation while inserting Resource.\");\n-//            throw severe(logger, fx, e);\n-//        } catch(SQLException e) {\n-//            if (\"99001\".equals(e.getSQLState())) {\n-//                // this is just a concurrency update, so there's no need to log the SQLException here\n-//                throw new FHIRPersistenceVersionIdMismatchException(\"Encountered version id mismatch while inserting Resource\");\n-//            } else {\n-//                FHIRPersistenceException fx = new FHIRPersistenceException(\"SQLException encountered while inserting Resource.\");\n-//                throw severe(logger, fx, e);\n-//            }\n-//        } catch(Throwable e) {\n-//            FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"Failure inserting Resource.\");\n-//            throw severe(logger, fx, e);\n-//        } finally {\n-//            this.cleanup(null, connection);\n-//            logger.exiting(CLASSNAME, METHODNAME);\n-//        }\n-//\n-//        return resource;\n-//    }\n-\n-\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n", "next_change": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 207477c74c..497144306b 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n-        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue>\";\n+        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n         Connection connection = null;\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 497144306b..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -80,9 +77,8 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n-        String currentSchema;\n         String stmtString = null;\n         Integer resourceTypeId;\n         Timestamp lastUpdated;\n", "next_change": {"commit": "071291da2a9ddd8d704c5b4ed3ae89380756a4cf", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 86db7765ca..1a6caa65d6 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = getConnection(); // do not close\n+        final Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n         String stmtString = null;\n         Integer resourceTypeId;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNjUyNA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420726524", "body": "signature doesnt' match since the ParameterDao is passed in", "bodyText": "signature doesnt' match since the ParameterDao is passed in", "bodyHTML": "<p dir=\"auto\">signature doesnt' match since the ParameterDao is passed in</p>", "author": "prb112", "createdAt": "2020-05-06T11:43:36Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -78,13 +82,104 @@ public PostgreSqlResourceDAO(TransactionSynchronizationRegistry trxSynchRegistry\n      * @throws FHIRPersistenceDBConnectException\n      * @throws FHIRPersistenceVersionIdMismatchException\n      */\n+//    @Override\n+//    public Resource  insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n+//            throws FHIRPersistenceException {\n+//        final String METHODNAME = \"insert\";\n+//        logger.entering(CLASSNAME, METHODNAME);\n+//\n+//        Connection connection = null;\n+//        Integer resourceTypeId;\n+//        Timestamp lastUpdated;\n+//        boolean acquiredFromCache;\n+//        long dbCallStartTime;\n+//        double dbCallDuration;\n+//\n+//        try {\n+//            connection = this.getConnection();\n+//\n+//            this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(connection);\n+//            this.parameterNameDAO = new PostgreSqlParameterNamesDAO(connection, fhirRefSequenceDAO);\n+//            this.codeSystemDAO = new PostgreSqlCodeSystemDAO(connection, fhirRefSequenceDAO);\n+//\n+//            // Get resourceTypeId from ResourceTypesCache first.\n+//            resourceTypeId = ResourceTypesCache.getResourceTypeId(resource.getResourceType());\n+//            // If no found, then get resourceTypeId from local newResourceTypeIds in case this id is already in newResourceTypeIds\n+//            // but has not been updated to ResourceTypesCache yet. newResourceTypeIds is updated to ResourceTypesCache only when the\n+//            // current transaction is committed.\n+//            if (resourceTypeId == null) {\n+//                resourceTypeId = getResourceTypeIdFromCandidatorsCache(resource.getResourceType());\n+//            }\n+//\n+//            if (resourceTypeId == null) {\n+//                acquiredFromCache = false;\n+//                resourceTypeId = getOrCreateResourceType(resource.getResourceType(), connection);\n+//                this.addResourceTypeCacheCandidate(resource.getResourceType(), resourceTypeId);\n+//            } else {\n+//                acquiredFromCache = true;\n+//            }\n+//\n+//            if (logger.isLoggable(Level.FINE)) {\n+//                logger.fine(\"resourceType=\" + resource.getResourceType() + \"  resourceTypeId=\" + resourceTypeId +\n+//                         \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ResourceTypesCache.getCacheNameForTenantDatastore());\n+//            }\n+//\n+//            lastUpdated = resource.getLastUpdated();\n+//            dbCallStartTime = System.nanoTime();\n+//\n+//            final String sourceKey = UUID.randomUUID().toString();\n+//\n+//            long resourceId = this.storeResource(resource.getResourceType(),\n+//                parameters,\n+//                resource.getLogicalId(),\n+//                resource.getData(),\n+//                lastUpdated,\n+//                resource.isDeleted(),\n+//                sourceKey,\n+//                resource.getVersionId(),\n+//                connection\n+//                );\n+//            dbCallDuration = (System.nanoTime() - dbCallStartTime)/1e6;\n+//\n+//            resource.setId(resourceId);\n+//            if (logger.isLoggable(Level.FINE)) {\n+//                logger.fine(\"Successfully inserted Resource. id=\" + resource.getId() + \" executionTime=\" + dbCallDuration + \"ms\");\n+//            }\n+//        } catch(FHIRPersistenceDBConnectException | FHIRPersistenceDataAccessException e) {\n+//            throw e;\n+//        } catch(SQLIntegrityConstraintViolationException e) {\n+//            FHIRPersistenceFKVException fx = new FHIRPersistenceFKVException(\"Encountered FK violation while inserting Resource.\");\n+//            throw severe(logger, fx, e);\n+//        } catch(SQLException e) {\n+//            if (\"99001\".equals(e.getSQLState())) {\n+//                // this is just a concurrency update, so there's no need to log the SQLException here\n+//                throw new FHIRPersistenceVersionIdMismatchException(\"Encountered version id mismatch while inserting Resource\");\n+//            } else {\n+//                FHIRPersistenceException fx = new FHIRPersistenceException(\"SQLException encountered while inserting Resource.\");\n+//                throw severe(logger, fx, e);\n+//            }\n+//        } catch(Throwable e) {\n+//            FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"Failure inserting Resource.\");\n+//            throw severe(logger, fx, e);\n+//        } finally {\n+//            this.cleanup(null, connection);\n+//            logger.exiting(CLASSNAME, METHODNAME);\n+//        }\n+//\n+//        return resource;\n+//    }\n+\n+\n     @Override\n-    public Resource  insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n+    public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n-        final String METHODNAME = \"insert\";\n+        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue>\";", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "49cc2920a957bfc31c7d6490751e089d8afd2165", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..207477c74c 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -82,94 +74,6 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n      * @throws FHIRPersistenceDBConnectException\n      * @throws FHIRPersistenceVersionIdMismatchException\n      */\n-//    @Override\n-//    public Resource  insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n-//            throws FHIRPersistenceException {\n-//        final String METHODNAME = \"insert\";\n-//        logger.entering(CLASSNAME, METHODNAME);\n-//\n-//        Connection connection = null;\n-//        Integer resourceTypeId;\n-//        Timestamp lastUpdated;\n-//        boolean acquiredFromCache;\n-//        long dbCallStartTime;\n-//        double dbCallDuration;\n-//\n-//        try {\n-//            connection = this.getConnection();\n-//\n-//            this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(connection);\n-//            this.parameterNameDAO = new PostgreSqlParameterNamesDAO(connection, fhirRefSequenceDAO);\n-//            this.codeSystemDAO = new PostgreSqlCodeSystemDAO(connection, fhirRefSequenceDAO);\n-//\n-//            // Get resourceTypeId from ResourceTypesCache first.\n-//            resourceTypeId = ResourceTypesCache.getResourceTypeId(resource.getResourceType());\n-//            // If no found, then get resourceTypeId from local newResourceTypeIds in case this id is already in newResourceTypeIds\n-//            // but has not been updated to ResourceTypesCache yet. newResourceTypeIds is updated to ResourceTypesCache only when the\n-//            // current transaction is committed.\n-//            if (resourceTypeId == null) {\n-//                resourceTypeId = getResourceTypeIdFromCandidatorsCache(resource.getResourceType());\n-//            }\n-//\n-//            if (resourceTypeId == null) {\n-//                acquiredFromCache = false;\n-//                resourceTypeId = getOrCreateResourceType(resource.getResourceType(), connection);\n-//                this.addResourceTypeCacheCandidate(resource.getResourceType(), resourceTypeId);\n-//            } else {\n-//                acquiredFromCache = true;\n-//            }\n-//\n-//            if (logger.isLoggable(Level.FINE)) {\n-//                logger.fine(\"resourceType=\" + resource.getResourceType() + \"  resourceTypeId=\" + resourceTypeId +\n-//                         \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ResourceTypesCache.getCacheNameForTenantDatastore());\n-//            }\n-//\n-//            lastUpdated = resource.getLastUpdated();\n-//            dbCallStartTime = System.nanoTime();\n-//\n-//            final String sourceKey = UUID.randomUUID().toString();\n-//\n-//            long resourceId = this.storeResource(resource.getResourceType(),\n-//                parameters,\n-//                resource.getLogicalId(),\n-//                resource.getData(),\n-//                lastUpdated,\n-//                resource.isDeleted(),\n-//                sourceKey,\n-//                resource.getVersionId(),\n-//                connection\n-//                );\n-//            dbCallDuration = (System.nanoTime() - dbCallStartTime)/1e6;\n-//\n-//            resource.setId(resourceId);\n-//            if (logger.isLoggable(Level.FINE)) {\n-//                logger.fine(\"Successfully inserted Resource. id=\" + resource.getId() + \" executionTime=\" + dbCallDuration + \"ms\");\n-//            }\n-//        } catch(FHIRPersistenceDBConnectException | FHIRPersistenceDataAccessException e) {\n-//            throw e;\n-//        } catch(SQLIntegrityConstraintViolationException e) {\n-//            FHIRPersistenceFKVException fx = new FHIRPersistenceFKVException(\"Encountered FK violation while inserting Resource.\");\n-//            throw severe(logger, fx, e);\n-//        } catch(SQLException e) {\n-//            if (\"99001\".equals(e.getSQLState())) {\n-//                // this is just a concurrency update, so there's no need to log the SQLException here\n-//                throw new FHIRPersistenceVersionIdMismatchException(\"Encountered version id mismatch while inserting Resource\");\n-//            } else {\n-//                FHIRPersistenceException fx = new FHIRPersistenceException(\"SQLException encountered while inserting Resource.\");\n-//                throw severe(logger, fx, e);\n-//            }\n-//        } catch(Throwable e) {\n-//            FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"Failure inserting Resource.\");\n-//            throw severe(logger, fx, e);\n-//        } finally {\n-//            this.cleanup(null, connection);\n-//            logger.exiting(CLASSNAME, METHODNAME);\n-//        }\n-//\n-//        return resource;\n-//    }\n-\n-\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n", "next_change": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 207477c74c..497144306b 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n     @Override\n     public Resource insert(Resource resource, List<ExtractedParameterValue> parameters, ParameterDAO parameterDao)\n             throws FHIRPersistenceException {\n-        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue>\";\n+        final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n         Connection connection = null;\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 497144306b..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -80,9 +77,8 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n-        String currentSchema;\n         String stmtString = null;\n         Integer resourceTypeId;\n         Timestamp lastUpdated;\n", "next_change": {"commit": "071291da2a9ddd8d704c5b4ed3ae89380756a4cf", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 86db7765ca..1a6caa65d6 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -77,7 +77,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         final String METHODNAME = \"insert(Resource, List<ExtractedParameterValue, ParameterDAO>\";\n         logger.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = getConnection(); // do not close\n+        final Connection connection = getConnection(); // do not close\n         CallableStatement stmt = null;\n         String stmtString = null;\n         Integer resourceTypeId;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNjg1OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420726858", "body": "this is very strange to me", "bodyText": "this is very strange to me", "bodyHTML": "<p dir=\"auto\">this is very strange to me</p>", "author": "prb112", "createdAt": "2020-05-06T11:44:17Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -143,14 +253,14 @@ public Resource  insert(Resource resource, List<ExtractedParameterValue> paramet\n                 // this is just a concurrency update, so there's no need to log the SQLException here\n                 throw new FHIRPersistenceVersionIdMismatchException(\"Encountered version id mismatch while inserting Resource\");\n             } else {\n-                FHIRPersistenceException fx = new FHIRPersistenceException(\"SQLException encountered while inserting Resource.\");\n+                FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"SQLException encountered while inserting Resource.\");\n                 throw severe(logger, fx, e);\n             }\n         } catch(Throwable e) {\n             FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"Failure inserting Resource.\");\n             throw severe(logger, fx, e);\n         } finally {\n-            this.cleanup(null, connection);\n+            this.cleanup(stmt, connection);", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIyNzcxNQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421227715", "bodyText": "do the cleanup same as DB2 codes, it just returns the connection to the pool", "author": "albertwang-ibm", "createdAt": "2020-05-07T04:10:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNjg1OA=="}], "type": "inlineReview", "revised_code": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -260,284 +153,12 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n             FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(\"Failure inserting Resource.\");\n             throw severe(logger, fx, e);\n         } finally {\n-            this.cleanup(stmt, connection);\n             logger.exiting(CLASSNAME, METHODNAME);\n         }\n \n         return resource;\n     }\n \n-    /**\n-     * Store the resource in the database, creating a new logical_resource entry if this is\n-     * the first version of this resource, or creating a new resource entry if this a new\n-     * version of an existing logical resource. The logic tracks closely the DB2 stored\n-     * procedure implementation, including locking of the logical_resource and handling\n-     * concurrency issues using the standard insert-or-update pattern:\n-     * <pre>\n-     *   SELECT FOR UPDATE                 -- try and get a write lock\n-     *   IF NOT FOUND THEN                 -- doesn't exist, so we don't have a lock\n-     *     INSERT new logical resource     -- create the record - if OK, we own the lock\n-     *     IF DUPLICATE THEN               -- someone else beat us to the create\n-     *       SELECT FOR UPDATE             -- so we need to try again for a write lock\n-     *     ...\n-     *   ...\n-     * </pre>\n-     *\n-     * This works because we never delete a logical_resource record, and so don't have to deal\n-     * with concurrency issues caused when deletes are mingled with inserts/updates\n-     *\n-     * Note the execution flow aligns very closely with the DB2 stored procedure\n-     * implementation (fhir-persistence-schema/src/main/resources/add_any_resource.sql)\n-     *\n-     * @param tablePrefix\n-     * @param parameters\n-     * @param p_logical_id\n-     * @param p_payload\n-     * @param p_last_updated\n-     * @param p_is_deleted\n-     * @param p_source_key\n-     * @param p_version\n-     *\n-     * @return the resource_id for the entry we created\n-     * @throws Exception\n-     */\n-//    public long storeResource(String tablePrefix, List<ExtractedParameterValue> parameters, String p_logical_id, byte[] p_payload, Timestamp p_last_updated, boolean p_is_deleted,\n-//        String p_source_key, Integer p_version, Connection conn) throws Exception {\n-//\n-//        final String METHODNAME = \"storeResource() for \" + tablePrefix + \" resource\";\n-//        logger.entering(CLASSNAME, METHODNAME);\n-//\n-//        Long v_logical_resource_id = null;\n-//        Long v_current_resource_id = null;\n-//        Long v_resource_id = null;\n-//        Integer v_resource_type_id = null;\n-//        boolean v_new_resource = false;\n-//        boolean v_not_found = false;\n-//        boolean v_duplicate = false;\n-//        int v_version = 0;\n-//        int v_insert_version = 0;\n-//\n-//        String v_resource_type = tablePrefix;\n-//\n-//        // Map the resource type name to the normalized id value in the database\n-//        v_resource_type_id = getResourceTypeId(v_resource_type, conn);\n-//        if (v_resource_type_id == null) {\n-//            // programming error, as this should've been created earlier\n-//            throw new IllegalStateException(\"resource type not found: \" + v_resource_type);\n-//        }\n-//\n-//        // Get a lock at the system-wide logical resource level.\n-//        final String SELECT_FOR_UPDATE = \"SELECT logical_resource_id FROM logical_resources WHERE resource_type_id = ? AND logical_id = ? FOR UPDATE\";\n-//        try (PreparedStatement stmt = conn.prepareStatement(SELECT_FOR_UPDATE)) {\n-//            stmt.setInt(1, v_resource_type_id);\n-//            stmt.setString(2, p_logical_id);\n-//            ResultSet rs = stmt.executeQuery();\n-//            if (rs.next()) {\n-//                v_logical_resource_id = rs.getLong(1);\n-//            } else {\n-//                v_not_found = true;\n-//                v_logical_resource_id = -1L; // just to be careful\n-//            }\n-//        }\n-//\n-//        // Create the logical resource if we don't have it already\n-//        if (v_not_found) {\n-//            // grab the id we want to use for the new logical resource instance\n-//            final String sql2 = \"SELECT nextval('fhir_sequence')\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql2)) {\n-//                ResultSet res = stmt.executeQuery();\n-//                if (res.next()) {\n-//                    v_logical_resource_id = res.getLong(1);\n-//                } else {\n-//                    // not going to happen, unless someone butchers the statement being executed\n-//                    throw new IllegalStateException(\"VALUES failed to return a row: \" + sql2);\n-//                }\n-//            }\n-//\n-//            try {\n-//                // insert the system-wide logical resource record.\n-//                final String sql3 = \"INSERT INTO logical_resources (logical_resource_id, resource_type_id, logical_id) VALUES (?, ?, ?)\";\n-//                try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//                    // bind parameters\n-//                    stmt.setLong(1, v_logical_resource_id);\n-//                    stmt.setInt(2, v_resource_type_id);\n-//                    stmt.setString(3, p_logical_id);\n-//                    stmt.executeUpdate();\n-//                }\n-//            } catch (SQLException e) {\n-//                if (translator.isDuplicate(e)) {\n-//                    v_duplicate = true;\n-//                }  else {\n-//                    throw e;\n-//                }\n-//            }\n-//\n-//            /**\n-//             * remember that we have a concurrent system...so there is a possibility\n-//             * that another thread snuck in before us and created the logical resource. This\n-//             * is easy to handle, just turn around and read it\n-//             */\n-//            if (v_duplicate) {\n-//                try (PreparedStatement stmt = conn.prepareStatement(SELECT_FOR_UPDATE)) {\n-//                    // bind parameters\n-//                    stmt.setInt(1, v_resource_type_id);\n-//                    stmt.setString(2, p_logical_id);\n-//                    ResultSet res = stmt.executeQuery();\n-//                    if (res.next()) {\n-//                        v_logical_resource_id = res.getLong(1);\n-//                    } else {\n-//                        // Extremely unlikely as we should never delete logical resource records\n-//                        throw new IllegalStateException(\"Logical resource was deleted: \" + tablePrefix + \"/\" + p_logical_id);\n-//                    }\n-//                }\n-//            } else {\n-//                v_new_resource = true;\n-//\n-//                // Insert the resource-specific logical resource record. Remember that logical_id is denormalized\n-//                // so it gets stored again here for convenience\n-//                final String sql3 = \"INSERT INTO \" + tablePrefix + \"_logical_resources (logical_resource_id, logical_id) VALUES (?, ?)\";\n-//                try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//                    // bind parameters\n-//                    stmt.setLong(1, v_logical_resource_id);\n-//                    stmt.setString(2, p_logical_id);\n-//                    stmt.executeUpdate();\n-//                }\n-//            }\n-//        }\n-//\n-//        if (!v_new_resource) {\n-//            // existing resource.  We need to know the current version from the\n-//            // resource-specific logical resources table.\n-//            final String sql3 = \"SELECT current_resource_id FROM \" + tablePrefix + \"_logical_resources WHERE logical_resource_id = ?\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//                stmt.setLong(1, v_logical_resource_id);\n-//                ResultSet rs = stmt.executeQuery();\n-//                if (rs.next()) {\n-//                    v_current_resource_id = rs.getLong(1);\n-//                } else {\n-//                    // This database is broken, because we shouldn't have logical_resource records without\n-//                    // corresponding resource-specific logical_resource records.\n-//                    throw new SQLException(\"Logical_id record '\" + p_logical_id + \"' missing for resource \" + tablePrefix);\n-//                }\n-//            }\n-//\n-//            // so if we are storing a specific version, do a quick check to make\n-//            // sure that this version doesn't currently exist. This is only done when processing\n-//            // replication messages which might be duplicated. We want the operation to be idempotent,\n-//            // so if the resource already exists, we don't need to do anything else.\n-//\n-//            if (p_version != null) {\n-//                final String sqlStmt = \"SELECT resource_id FROM \" + tablePrefix + \"_resources dr WHERE dr.logical_resource_id = ? AND dr.version_id = ?\";\n-//                try (PreparedStatement stmt = conn.prepareStatement(sqlStmt)) {\n-//                    // bind parameters\n-//                    stmt.setLong(1, v_logical_resource_id);\n-//                    stmt.setLong(2, p_version);\n-//                    ResultSet res = stmt.executeQuery();\n-//                    if (res.next()) {\n-//                        // this version of this resource already exists, so we bail out right away\n-//                        v_resource_id = res.getLong(1);\n-//                        return v_resource_id;\n-//                    }\n-//                }\n-//            }\n-//\n-//            // Grab the version value for the current version (identified by v_current_resource_id)\n-//            final String sql4 = \"SELECT version_id FROM \" + tablePrefix + \"_resources WHERE resource_id = ?\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql4)) {\n-//                stmt.setLong(1, v_current_resource_id);\n-//                ResultSet res = stmt.executeQuery();\n-//                if (res.next()) {\n-//                    v_version = res.getInt(1);\n-//                } else {\n-//                    throw new IllegalStateException(\"current resource not found: \"\n-//                            + tablePrefix + \"_resources.resource_id=\" + v_current_resource_id);\n-//                }\n-//            }\n-//\n-//            //If we have been passed a version number, this means that this is a replicated\n-//            //resource, and so we only need to delete parameters if the given version is\n-//            // later than the current version\n-//            if (p_version == null || p_version > v_version) {\n-//                // existing resource, so need to delete all its parameters\n-//                // delete composites first, or else the foreign keys there restrict deletes on referenced tables\n-//                deleteFromParameterTable(conn, tablePrefix + \"_composites\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_str_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_number_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_date_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_latlng_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_token_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_quantity_values\", v_logical_resource_id);\n-//            }\n-//        }\n-//\n-//        // Persist the data using the given version number if required\n-//        if (p_version != null) {\n-//            v_insert_version = p_version;\n-//        } else {\n-//            // remember we have a write (update) lock on the logical version, so we can safely calculate\n-//            // the next version value here\n-//            v_insert_version = v_version + 1;\n-//\n-//        }\n-//\n-//        /**\n-//         * Create the new resource version.\n-//         * uses last_updated time from the app-server, so we have consistency between the various DAOs\n-//         */\n-//        String sql2 = \"SELECT nextval('fhir_sequence')\";\n-//        try (PreparedStatement stmt = conn.prepareStatement(sql2)) {\n-//            ResultSet res = stmt.executeQuery();\n-//            if (res.next()) {\n-//                v_resource_id = res.getLong(1); //Assign result of the above query\n-//            } else {\n-//                // unlikely\n-//                throw new IllegalStateException(\"no row returned: \" + sql2);\n-//            }\n-//        }\n-//\n-//        // Finally we get to the big resource data insert\n-//        String sql3 = \"INSERT INTO \" + tablePrefix + \"_resources (resource_id, logical_resource_id, version_id, data, last_updated, is_deleted) \"\n-//                + \"VALUES (?,?,?,?,?,?)\";\n-//        try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//            // bind parameters\n-//            stmt.setLong(1, v_resource_id);\n-//            stmt.setLong(2, v_logical_resource_id);\n-//            stmt.setInt(3, v_insert_version);\n-//            stmt.setBytes(4, p_payload);\n-//            stmt.setTimestamp(5, p_last_updated, UTC);\n-//            stmt.setString(6, p_is_deleted ? \"Y\" : \"N\");\n-//            stmt.executeUpdate();\n-//        }\n-//\n-//        if (p_version == null || p_version > v_version) {\n-//            //only update the logical resource if the resource we are adding supercedes the\n-//            //current resource\n-//            String sql4 = \"UPDATE \" + tablePrefix + \"_logical_resources SET current_resource_id = ? WHERE logical_resource_id = ?\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql4)) {\n-//                // bind parameters\n-//                stmt.setLong(1, v_resource_id);\n-//                stmt.setLong(2, v_logical_resource_id);\n-//                stmt.executeUpdate();\n-//            }\n-//\n-//            // To keep things simple for the postgresql use-case, we just use a visitor to\n-//            // handle inserts of parameters directly in the resource parameter tables.\n-//            // Note we don't get any parameters for the resource soft-delete operation\n-//            if (parameters != null) {\n-//                // postgresql doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n-//                try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-//                    new ParameterNameCacheAdapter(parameterNameDAO), new CodeSystemCacheAdapter(codeSystemDAO))) {\n-//                    for (ExtractedParameterValue p: parameters) {\n-//                        p.accept(pvd);\n-//                    }\n-//                }\n-//            }\n-//        }\n-//        logger.exiting(CLASSNAME, METHODNAME);\n-//        return v_resource_id;\n-//    }\n-\n-\n     /**\n      * Delete all parameters for the given resourceId from the parameters table\n      *\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyNzY0Mw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420727643", "body": "removal candidate? ", "bodyText": "removal candidate?", "bodyHTML": "<p dir=\"auto\">removal candidate?</p>", "author": "prb112", "createdAt": "2020-05-06T11:45:42Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -191,241 +301,241 @@ public Resource  insert(Resource resource, List<ExtractedParameterValue> paramet\n      * @return the resource_id for the entry we created\n      * @throws Exception\n      */\n-    public long storeResource(String tablePrefix, List<ExtractedParameterValue> parameters, String p_logical_id, byte[] p_payload, Timestamp p_last_updated, boolean p_is_deleted,\n-        String p_source_key, Integer p_version, Connection conn) throws Exception {\n-\n-        final String METHODNAME = \"storeResource() for \" + tablePrefix + \" resource\";\n-        logger.entering(CLASSNAME, METHODNAME);\n-\n-        Long v_logical_resource_id = null;\n-        Long v_current_resource_id = null;\n-        Long v_resource_id = null;\n-        Integer v_resource_type_id = null;\n-        boolean v_new_resource = false;\n-        boolean v_not_found = false;\n-        boolean v_duplicate = false;\n-        int v_version = 0;\n-        int v_insert_version = 0;\n-\n-        String v_resource_type = tablePrefix;\n-\n-        // Map the resource type name to the normalized id value in the database\n-        v_resource_type_id = getResourceTypeId(v_resource_type, conn);\n-        if (v_resource_type_id == null) {\n-            // programming error, as this should've been created earlier\n-            throw new IllegalStateException(\"resource type not found: \" + v_resource_type);\n-        }\n-\n-        // Get a lock at the system-wide logical resource level.\n-        final String SELECT_FOR_UPDATE = \"SELECT logical_resource_id FROM logical_resources WHERE resource_type_id = ? AND logical_id = ? FOR UPDATE\";\n-        try (PreparedStatement stmt = conn.prepareStatement(SELECT_FOR_UPDATE)) {\n-            stmt.setInt(1, v_resource_type_id);\n-            stmt.setString(2, p_logical_id);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                v_logical_resource_id = rs.getLong(1);\n-            } else {\n-                v_not_found = true;\n-                v_logical_resource_id = -1L; // just to be careful\n-            }\n-        }\n-\n-        // Create the logical resource if we don't have it already\n-        if (v_not_found) {\n-            // grab the id we want to use for the new logical resource instance\n-            final String sql2 = \"SELECT nextval('fhir_sequence')\";\n-            try (PreparedStatement stmt = conn.prepareStatement(sql2)) {\n-                ResultSet res = stmt.executeQuery();\n-                if (res.next()) {\n-                    v_logical_resource_id = res.getLong(1);\n-                } else {\n-                    // not going to happen, unless someone butchers the statement being executed\n-                    throw new IllegalStateException(\"VALUES failed to return a row: \" + sql2);\n-                }\n-            }\n-\n-            try {\n-                // insert the system-wide logical resource record.\n-                final String sql3 = \"INSERT INTO logical_resources (logical_resource_id, resource_type_id, logical_id) VALUES (?, ?, ?)\";\n-                try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-                    // bind parameters\n-                    stmt.setLong(1, v_logical_resource_id);\n-                    stmt.setInt(2, v_resource_type_id);\n-                    stmt.setString(3, p_logical_id);\n-                    stmt.executeUpdate();\n-                }\n-            } catch (SQLException e) {\n-                if (translator.isDuplicate(e)) {\n-                    v_duplicate = true;\n-                }  else {\n-                    throw e;\n-                }\n-            }\n-\n-            /**\n-             * remember that we have a concurrent system...so there is a possibility\n-             * that another thread snuck in before us and created the logical resource. This\n-             * is easy to handle, just turn around and read it\n-             */\n-            if (v_duplicate) {\n-                try (PreparedStatement stmt = conn.prepareStatement(SELECT_FOR_UPDATE)) {\n-                    // bind parameters\n-                    stmt.setInt(1, v_resource_type_id);\n-                    stmt.setString(2, p_logical_id);\n-                    ResultSet res = stmt.executeQuery();\n-                    if (res.next()) {\n-                        v_logical_resource_id = res.getLong(1);\n-                    } else {\n-                        // Extremely unlikely as we should never delete logical resource records\n-                        throw new IllegalStateException(\"Logical resource was deleted: \" + tablePrefix + \"/\" + p_logical_id);\n-                    }\n-                }\n-            } else {\n-                v_new_resource = true;\n-\n-                // Insert the resource-specific logical resource record. Remember that logical_id is denormalized\n-                // so it gets stored again here for convenience\n-                final String sql3 = \"INSERT INTO \" + tablePrefix + \"_logical_resources (logical_resource_id, logical_id) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-                    // bind parameters\n-                    stmt.setLong(1, v_logical_resource_id);\n-                    stmt.setString(2, p_logical_id);\n-                    stmt.executeUpdate();\n-                }\n-            }\n-        }\n-\n-        if (!v_new_resource) {\n-            // existing resource.  We need to know the current version from the\n-            // resource-specific logical resources table.\n-            final String sql3 = \"SELECT current_resource_id FROM \" + tablePrefix + \"_logical_resources WHERE logical_resource_id = ?\";\n-            try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-                stmt.setLong(1, v_logical_resource_id);\n-                ResultSet rs = stmt.executeQuery();\n-                if (rs.next()) {\n-                    v_current_resource_id = rs.getLong(1);\n-                } else {\n-                    // This database is broken, because we shouldn't have logical_resource records without\n-                    // corresponding resource-specific logical_resource records.\n-                    throw new SQLException(\"Logical_id record '\" + p_logical_id + \"' missing for resource \" + tablePrefix);\n-                }\n-            }\n-\n-            // so if we are storing a specific version, do a quick check to make\n-            // sure that this version doesn't currently exist. This is only done when processing\n-            // replication messages which might be duplicated. We want the operation to be idempotent,\n-            // so if the resource already exists, we don't need to do anything else.\n-\n-            if (p_version != null) {\n-                final String sqlStmt = \"SELECT resource_id FROM \" + tablePrefix + \"_resources dr WHERE dr.logical_resource_id = ? AND dr.version_id = ?\";\n-                try (PreparedStatement stmt = conn.prepareStatement(sqlStmt)) {\n-                    // bind parameters\n-                    stmt.setLong(1, v_logical_resource_id);\n-                    stmt.setLong(2, p_version);\n-                    ResultSet res = stmt.executeQuery();\n-                    if (res.next()) {\n-                        // this version of this resource already exists, so we bail out right away\n-                        v_resource_id = res.getLong(1);\n-                        return v_resource_id;\n-                    }\n-                }\n-            }\n-\n-            // Grab the version value for the current version (identified by v_current_resource_id)\n-            final String sql4 = \"SELECT version_id FROM \" + tablePrefix + \"_resources WHERE resource_id = ?\";\n-            try (PreparedStatement stmt = conn.prepareStatement(sql4)) {\n-                stmt.setLong(1, v_current_resource_id);\n-                ResultSet res = stmt.executeQuery();\n-                if (res.next()) {\n-                    v_version = res.getInt(1);\n-                } else {\n-                    throw new IllegalStateException(\"current resource not found: \"\n-                            + tablePrefix + \"_resources.resource_id=\" + v_current_resource_id);\n-                }\n-            }\n-\n-            //If we have been passed a version number, this means that this is a replicated\n-            //resource, and so we only need to delete parameters if the given version is\n-            // later than the current version\n-            if (p_version == null || p_version > v_version) {\n-                // existing resource, so need to delete all its parameters\n-                // delete composites first, or else the foreign keys there restrict deletes on referenced tables\n-                deleteFromParameterTable(conn, tablePrefix + \"_composites\", v_logical_resource_id);\n-                deleteFromParameterTable(conn, tablePrefix + \"_str_values\", v_logical_resource_id);\n-                deleteFromParameterTable(conn, tablePrefix + \"_number_values\", v_logical_resource_id);\n-                deleteFromParameterTable(conn, tablePrefix + \"_date_values\", v_logical_resource_id);\n-                deleteFromParameterTable(conn, tablePrefix + \"_latlng_values\", v_logical_resource_id);\n-                deleteFromParameterTable(conn, tablePrefix + \"_token_values\", v_logical_resource_id);\n-                deleteFromParameterTable(conn, tablePrefix + \"_quantity_values\", v_logical_resource_id);\n-            }\n-        }\n-\n-        // Persist the data using the given version number if required\n-        if (p_version != null) {\n-            v_insert_version = p_version;\n-        } else {\n-            // remember we have a write (update) lock on the logical version, so we can safely calculate\n-            // the next version value here\n-            v_insert_version = v_version + 1;\n-\n-        }\n-\n-        /**\n-         * Create the new resource version.\n-         * uses last_updated time from the app-server, so we have consistency between the various DAOs\n-         */\n-        String sql2 = \"SELECT nextval('fhir_sequence')\";\n-        try (PreparedStatement stmt = conn.prepareStatement(sql2)) {\n-            ResultSet res = stmt.executeQuery();\n-            if (res.next()) {\n-                v_resource_id = res.getLong(1); //Assign result of the above query\n-            } else {\n-                // unlikely\n-                throw new IllegalStateException(\"no row returned: \" + sql2);\n-            }\n-        }\n-\n-        // Finally we get to the big resource data insert\n-        String sql3 = \"INSERT INTO \" + tablePrefix + \"_resources (resource_id, logical_resource_id, version_id, data, last_updated, is_deleted) \"\n-                + \"VALUES (?,?,?,?,?,?)\";\n-        try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-            // bind parameters\n-            stmt.setLong(1, v_resource_id);\n-            stmt.setLong(2, v_logical_resource_id);\n-            stmt.setInt(3, v_insert_version);\n-            stmt.setBytes(4, p_payload);\n-            stmt.setTimestamp(5, p_last_updated, UTC);\n-            stmt.setString(6, p_is_deleted ? \"Y\" : \"N\");\n-            stmt.executeUpdate();\n-        }\n-\n-        if (p_version == null || p_version > v_version) {\n-            //only update the logical resource if the resource we are adding supercedes the\n-            //current resource\n-            String sql4 = \"UPDATE \" + tablePrefix + \"_logical_resources SET current_resource_id = ? WHERE logical_resource_id = ?\";\n-            try (PreparedStatement stmt = conn.prepareStatement(sql4)) {\n-                // bind parameters\n-                stmt.setLong(1, v_resource_id);\n-                stmt.setLong(2, v_logical_resource_id);\n-                stmt.executeUpdate();\n-            }\n-\n-            // To keep things simple for the postgresql use-case, we just use a visitor to\n-            // handle inserts of parameters directly in the resource parameter tables.\n-            // Note we don't get any parameters for the resource soft-delete operation\n-            if (parameters != null) {\n-                // postgresql doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n-                try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-                    new ParameterNameCacheAdapter(parameterNameDAO), new CodeSystemCacheAdapter(codeSystemDAO))) {\n-                    for (ExtractedParameterValue p: parameters) {\n-                        p.accept(pvd);\n-                    }\n-                }\n-            }\n-        }\n-        logger.exiting(CLASSNAME, METHODNAME);\n-        return v_resource_id;\n-    }\n+//    public long storeResource(String tablePrefix, List<ExtractedParameterValue> parameters, String p_logical_id, byte[] p_payload, Timestamp p_last_updated, boolean p_is_deleted,", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..497144306b 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -267,277 +167,6 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n         return resource;\n     }\n \n-    /**\n-     * Store the resource in the database, creating a new logical_resource entry if this is\n-     * the first version of this resource, or creating a new resource entry if this a new\n-     * version of an existing logical resource. The logic tracks closely the DB2 stored\n-     * procedure implementation, including locking of the logical_resource and handling\n-     * concurrency issues using the standard insert-or-update pattern:\n-     * <pre>\n-     *   SELECT FOR UPDATE                 -- try and get a write lock\n-     *   IF NOT FOUND THEN                 -- doesn't exist, so we don't have a lock\n-     *     INSERT new logical resource     -- create the record - if OK, we own the lock\n-     *     IF DUPLICATE THEN               -- someone else beat us to the create\n-     *       SELECT FOR UPDATE             -- so we need to try again for a write lock\n-     *     ...\n-     *   ...\n-     * </pre>\n-     *\n-     * This works because we never delete a logical_resource record, and so don't have to deal\n-     * with concurrency issues caused when deletes are mingled with inserts/updates\n-     *\n-     * Note the execution flow aligns very closely with the DB2 stored procedure\n-     * implementation (fhir-persistence-schema/src/main/resources/add_any_resource.sql)\n-     *\n-     * @param tablePrefix\n-     * @param parameters\n-     * @param p_logical_id\n-     * @param p_payload\n-     * @param p_last_updated\n-     * @param p_is_deleted\n-     * @param p_source_key\n-     * @param p_version\n-     *\n-     * @return the resource_id for the entry we created\n-     * @throws Exception\n-     */\n-//    public long storeResource(String tablePrefix, List<ExtractedParameterValue> parameters, String p_logical_id, byte[] p_payload, Timestamp p_last_updated, boolean p_is_deleted,\n-//        String p_source_key, Integer p_version, Connection conn) throws Exception {\n-//\n-//        final String METHODNAME = \"storeResource() for \" + tablePrefix + \" resource\";\n-//        logger.entering(CLASSNAME, METHODNAME);\n-//\n-//        Long v_logical_resource_id = null;\n-//        Long v_current_resource_id = null;\n-//        Long v_resource_id = null;\n-//        Integer v_resource_type_id = null;\n-//        boolean v_new_resource = false;\n-//        boolean v_not_found = false;\n-//        boolean v_duplicate = false;\n-//        int v_version = 0;\n-//        int v_insert_version = 0;\n-//\n-//        String v_resource_type = tablePrefix;\n-//\n-//        // Map the resource type name to the normalized id value in the database\n-//        v_resource_type_id = getResourceTypeId(v_resource_type, conn);\n-//        if (v_resource_type_id == null) {\n-//            // programming error, as this should've been created earlier\n-//            throw new IllegalStateException(\"resource type not found: \" + v_resource_type);\n-//        }\n-//\n-//        // Get a lock at the system-wide logical resource level.\n-//        final String SELECT_FOR_UPDATE = \"SELECT logical_resource_id FROM logical_resources WHERE resource_type_id = ? AND logical_id = ? FOR UPDATE\";\n-//        try (PreparedStatement stmt = conn.prepareStatement(SELECT_FOR_UPDATE)) {\n-//            stmt.setInt(1, v_resource_type_id);\n-//            stmt.setString(2, p_logical_id);\n-//            ResultSet rs = stmt.executeQuery();\n-//            if (rs.next()) {\n-//                v_logical_resource_id = rs.getLong(1);\n-//            } else {\n-//                v_not_found = true;\n-//                v_logical_resource_id = -1L; // just to be careful\n-//            }\n-//        }\n-//\n-//        // Create the logical resource if we don't have it already\n-//        if (v_not_found) {\n-//            // grab the id we want to use for the new logical resource instance\n-//            final String sql2 = \"SELECT nextval('fhir_sequence')\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql2)) {\n-//                ResultSet res = stmt.executeQuery();\n-//                if (res.next()) {\n-//                    v_logical_resource_id = res.getLong(1);\n-//                } else {\n-//                    // not going to happen, unless someone butchers the statement being executed\n-//                    throw new IllegalStateException(\"VALUES failed to return a row: \" + sql2);\n-//                }\n-//            }\n-//\n-//            try {\n-//                // insert the system-wide logical resource record.\n-//                final String sql3 = \"INSERT INTO logical_resources (logical_resource_id, resource_type_id, logical_id) VALUES (?, ?, ?)\";\n-//                try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//                    // bind parameters\n-//                    stmt.setLong(1, v_logical_resource_id);\n-//                    stmt.setInt(2, v_resource_type_id);\n-//                    stmt.setString(3, p_logical_id);\n-//                    stmt.executeUpdate();\n-//                }\n-//            } catch (SQLException e) {\n-//                if (translator.isDuplicate(e)) {\n-//                    v_duplicate = true;\n-//                }  else {\n-//                    throw e;\n-//                }\n-//            }\n-//\n-//            /**\n-//             * remember that we have a concurrent system...so there is a possibility\n-//             * that another thread snuck in before us and created the logical resource. This\n-//             * is easy to handle, just turn around and read it\n-//             */\n-//            if (v_duplicate) {\n-//                try (PreparedStatement stmt = conn.prepareStatement(SELECT_FOR_UPDATE)) {\n-//                    // bind parameters\n-//                    stmt.setInt(1, v_resource_type_id);\n-//                    stmt.setString(2, p_logical_id);\n-//                    ResultSet res = stmt.executeQuery();\n-//                    if (res.next()) {\n-//                        v_logical_resource_id = res.getLong(1);\n-//                    } else {\n-//                        // Extremely unlikely as we should never delete logical resource records\n-//                        throw new IllegalStateException(\"Logical resource was deleted: \" + tablePrefix + \"/\" + p_logical_id);\n-//                    }\n-//                }\n-//            } else {\n-//                v_new_resource = true;\n-//\n-//                // Insert the resource-specific logical resource record. Remember that logical_id is denormalized\n-//                // so it gets stored again here for convenience\n-//                final String sql3 = \"INSERT INTO \" + tablePrefix + \"_logical_resources (logical_resource_id, logical_id) VALUES (?, ?)\";\n-//                try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//                    // bind parameters\n-//                    stmt.setLong(1, v_logical_resource_id);\n-//                    stmt.setString(2, p_logical_id);\n-//                    stmt.executeUpdate();\n-//                }\n-//            }\n-//        }\n-//\n-//        if (!v_new_resource) {\n-//            // existing resource.  We need to know the current version from the\n-//            // resource-specific logical resources table.\n-//            final String sql3 = \"SELECT current_resource_id FROM \" + tablePrefix + \"_logical_resources WHERE logical_resource_id = ?\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//                stmt.setLong(1, v_logical_resource_id);\n-//                ResultSet rs = stmt.executeQuery();\n-//                if (rs.next()) {\n-//                    v_current_resource_id = rs.getLong(1);\n-//                } else {\n-//                    // This database is broken, because we shouldn't have logical_resource records without\n-//                    // corresponding resource-specific logical_resource records.\n-//                    throw new SQLException(\"Logical_id record '\" + p_logical_id + \"' missing for resource \" + tablePrefix);\n-//                }\n-//            }\n-//\n-//            // so if we are storing a specific version, do a quick check to make\n-//            // sure that this version doesn't currently exist. This is only done when processing\n-//            // replication messages which might be duplicated. We want the operation to be idempotent,\n-//            // so if the resource already exists, we don't need to do anything else.\n-//\n-//            if (p_version != null) {\n-//                final String sqlStmt = \"SELECT resource_id FROM \" + tablePrefix + \"_resources dr WHERE dr.logical_resource_id = ? AND dr.version_id = ?\";\n-//                try (PreparedStatement stmt = conn.prepareStatement(sqlStmt)) {\n-//                    // bind parameters\n-//                    stmt.setLong(1, v_logical_resource_id);\n-//                    stmt.setLong(2, p_version);\n-//                    ResultSet res = stmt.executeQuery();\n-//                    if (res.next()) {\n-//                        // this version of this resource already exists, so we bail out right away\n-//                        v_resource_id = res.getLong(1);\n-//                        return v_resource_id;\n-//                    }\n-//                }\n-//            }\n-//\n-//            // Grab the version value for the current version (identified by v_current_resource_id)\n-//            final String sql4 = \"SELECT version_id FROM \" + tablePrefix + \"_resources WHERE resource_id = ?\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql4)) {\n-//                stmt.setLong(1, v_current_resource_id);\n-//                ResultSet res = stmt.executeQuery();\n-//                if (res.next()) {\n-//                    v_version = res.getInt(1);\n-//                } else {\n-//                    throw new IllegalStateException(\"current resource not found: \"\n-//                            + tablePrefix + \"_resources.resource_id=\" + v_current_resource_id);\n-//                }\n-//            }\n-//\n-//            //If we have been passed a version number, this means that this is a replicated\n-//            //resource, and so we only need to delete parameters if the given version is\n-//            // later than the current version\n-//            if (p_version == null || p_version > v_version) {\n-//                // existing resource, so need to delete all its parameters\n-//                // delete composites first, or else the foreign keys there restrict deletes on referenced tables\n-//                deleteFromParameterTable(conn, tablePrefix + \"_composites\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_str_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_number_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_date_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_latlng_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_token_values\", v_logical_resource_id);\n-//                deleteFromParameterTable(conn, tablePrefix + \"_quantity_values\", v_logical_resource_id);\n-//            }\n-//        }\n-//\n-//        // Persist the data using the given version number if required\n-//        if (p_version != null) {\n-//            v_insert_version = p_version;\n-//        } else {\n-//            // remember we have a write (update) lock on the logical version, so we can safely calculate\n-//            // the next version value here\n-//            v_insert_version = v_version + 1;\n-//\n-//        }\n-//\n-//        /**\n-//         * Create the new resource version.\n-//         * uses last_updated time from the app-server, so we have consistency between the various DAOs\n-//         */\n-//        String sql2 = \"SELECT nextval('fhir_sequence')\";\n-//        try (PreparedStatement stmt = conn.prepareStatement(sql2)) {\n-//            ResultSet res = stmt.executeQuery();\n-//            if (res.next()) {\n-//                v_resource_id = res.getLong(1); //Assign result of the above query\n-//            } else {\n-//                // unlikely\n-//                throw new IllegalStateException(\"no row returned: \" + sql2);\n-//            }\n-//        }\n-//\n-//        // Finally we get to the big resource data insert\n-//        String sql3 = \"INSERT INTO \" + tablePrefix + \"_resources (resource_id, logical_resource_id, version_id, data, last_updated, is_deleted) \"\n-//                + \"VALUES (?,?,?,?,?,?)\";\n-//        try (PreparedStatement stmt = conn.prepareStatement(sql3)) {\n-//            // bind parameters\n-//            stmt.setLong(1, v_resource_id);\n-//            stmt.setLong(2, v_logical_resource_id);\n-//            stmt.setInt(3, v_insert_version);\n-//            stmt.setBytes(4, p_payload);\n-//            stmt.setTimestamp(5, p_last_updated, UTC);\n-//            stmt.setString(6, p_is_deleted ? \"Y\" : \"N\");\n-//            stmt.executeUpdate();\n-//        }\n-//\n-//        if (p_version == null || p_version > v_version) {\n-//            //only update the logical resource if the resource we are adding supercedes the\n-//            //current resource\n-//            String sql4 = \"UPDATE \" + tablePrefix + \"_logical_resources SET current_resource_id = ? WHERE logical_resource_id = ?\";\n-//            try (PreparedStatement stmt = conn.prepareStatement(sql4)) {\n-//                // bind parameters\n-//                stmt.setLong(1, v_resource_id);\n-//                stmt.setLong(2, v_logical_resource_id);\n-//                stmt.executeUpdate();\n-//            }\n-//\n-//            // To keep things simple for the postgresql use-case, we just use a visitor to\n-//            // handle inserts of parameters directly in the resource parameter tables.\n-//            // Note we don't get any parameters for the resource soft-delete operation\n-//            if (parameters != null) {\n-//                // postgresql doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n-//                try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-//                    new ParameterNameCacheAdapter(parameterNameDAO), new CodeSystemCacheAdapter(codeSystemDAO))) {\n-//                    for (ExtractedParameterValue p: parameters) {\n-//                        p.accept(pvd);\n-//                    }\n-//                }\n-//            }\n-//        }\n-//        logger.exiting(CLASSNAME, METHODNAME);\n-//        return v_resource_id;\n-//    }\n-\n-\n     /**\n      * Delete all parameters for the given resourceId from the parameters table\n      *\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyODM1NQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r420728355", "body": "really strange to me. ", "bodyText": "really strange to me.", "bodyHTML": "<p dir=\"auto\">really strange to me.</p>", "author": "prb112", "createdAt": "2020-05-06T11:47:05Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -479,17 +589,62 @@ public int getOrCreateResourceType(String resourceTypeName, Connection conn) thr\n \n         // Create the resource if we don't have it already (set by the continue handler)\n         if (result == null) {\n-            result = fhirRefSequenceDAO.nextValue();\n-\n-            final String INS = \"INSERT INTO resource_types (resource_type_id, resource_type) VALUES (?, ?)\";\n-            try (PreparedStatement stmt = conn.prepareStatement(INS)) {\n-                // bind parameters\n-                stmt.setInt(1, result);\n-                stmt.setString(2, resourceTypeName);\n-                stmt.executeUpdate();\n+            try {\n+                result = fhirRefSequenceDAO.nextValue();\n+                final String INS = \"INSERT INTO resource_types (resource_type_id, resource_type) VALUES (?, ?)\";\n+                try (PreparedStatement stmt = conn.prepareStatement(INS)) {\n+                    // bind parameters\n+                    stmt.setInt(1, result);\n+                    stmt.setString(2, resourceTypeName);\n+                    stmt.executeUpdate();\n+                }\n+            } catch (SQLException e) {\n+                throw e;\n             }\n         }\n \n         return result;\n     }\n+\n+\n+    @Override\n+    public Integer readResourceTypeId(String resourceType) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException  {\n+        final String METHODNAME = \"readResourceTypeId\";\n+        logger.entering(CLASSNAME, METHODNAME);\n+\n+        Connection connection = null;\n+        CallableStatement stmt = null;\n+        Integer resourceTypeId = null;\n+        String currentSchema;\n+        String stmtString;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n+\n+        try {\n+            connection = this.getConnection();\n+            currentSchema = connection.getSchema().trim();\n+            stmtString = String.format(SQL_READ_RESOURCE_TYPE, currentSchema);\n+            stmt = connection.prepareCall(stmtString);\n+            stmt.setString(1, resourceType);\n+            stmt.registerOutParameter(2, Types.INTEGER);\n+            dbCallStartTime = System.nanoTime();\n+            stmt.execute();\n+            dbCallDuration = (System.nanoTime()-dbCallStartTime)/1e6;\n+            if (logger.isLoggable(Level.FINER)) {\n+                logger.finer(\"DB read resource type id complete. executionTime=\" + dbCallDuration + \"ms\");\n+            }\n+            resourceTypeId = stmt.getInt(2);\n+        } catch(FHIRPersistenceDBConnectException e) {\n+            throw e;\n+        } catch (Throwable e) {\n+            final String errMsg = \"Failure storing Resource type name id: name=\" + resourceType;\n+            FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(errMsg);\n+            throw severe(logger, fx, e);\n+        } finally {\n+            this.cleanup(stmt, connection);", "originalCommit": "b7ab6c3e372bbdc19b7224fb24966c4e461154c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIyNzg0Mg==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421227842", "bodyText": "same as in db2 codes.", "author": "albertwang-ibm", "createdAt": "2020-05-07T04:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyODM1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 1d8aa08dfb..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -634,14 +252,11 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n                 logger.finer(\"DB read resource type id complete. executionTime=\" + dbCallDuration + \"ms\");\n             }\n             resourceTypeId = stmt.getInt(2);\n-        } catch(FHIRPersistenceDBConnectException e) {\n-            throw e;\n         } catch (Throwable e) {\n             final String errMsg = \"Failure storing Resource type name id: name=\" + resourceType;\n             FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(errMsg);\n             throw severe(logger, fx, e);\n         } finally {\n-            this.cleanup(stmt, connection);\n             logger.exiting(CLASSNAME, METHODNAME);\n         }\n         return resourceTypeId;\n", "next_change": {"commit": "460c0af7eb65fc3825987479c0dc5ce164462d58", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex 86db7765ca..07db035348 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -257,6 +257,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n             FHIRPersistenceDataAccessException fx = new FHIRPersistenceDataAccessException(errMsg);\n             throw severe(logger, fx, e);\n         } finally {\n+            cleanup(stmt);\n             logger.exiting(CLASSNAME, METHODNAME);\n         }\n         return resourceTypeId;\n", "next_change": null}]}}]}}, {"oid": "81ed39c897f68e68efa55901be929721cba5d33c", "url": "https://github.com/IBM/FHIR/commit/81ed39c897f68e68efa55901be929721cba5d33c", "message": "issue #945 remove changes to DB2 SPs\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-06T16:06:15Z", "type": "commit"}, {"oid": "a33a5fba1b62504c0c52918853ce048c9275c36f", "url": "https://github.com/IBM/FHIR/commit/a33a5fba1b62504c0c52918853ce048c9275c36f", "message": "Merge pull request #1034 from IBM/issue-945\n\nIssue 945", "committedDate": "2020-05-06T16:07:27Z", "type": "commit"}, {"oid": "fb66eed2b4f878145556c1ddb8fd51ea481604cf", "url": "https://github.com/IBM/FHIR/commit/fb66eed2b4f878145556c1ddb8fd51ea481604cf", "message": "Merge pull request #1037 from IBM/issue-945\n\nIssue 945 - sync with master", "committedDate": "2020-05-06T18:33:12Z", "type": "commit"}, {"oid": "49cc2920a957bfc31c7d6490751e089d8afd2165", "url": "https://github.com/IBM/FHIR/commit/49cc2920a957bfc31c7d6490751e089d8afd2165", "message": "issue #945 enable caches for postgresql and derby\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T01:59:41Z", "type": "commit"}, {"oid": "191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "url": "https://github.com/IBM/FHIR/commit/191abc117e55d6f9c38cec7cc1fb8d8e95f3f927", "message": "issue #945 update 1 per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T04:13:01Z", "type": "commit"}, {"oid": "2f31e8de502ff9aeaf5937f4cd20903a1ac1b440", "url": "https://github.com/IBM/FHIR/commit/2f31e8de502ff9aeaf5937f4cd20903a1ac1b440", "message": "issue #945 update 2 per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T12:32:53Z", "type": "commit"}, {"oid": "dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "url": "https://github.com/IBM/FHIR/commit/dccb3972d197e99b3a9b93dddb5f21d3b56e6b0e", "message": "issue #945 update schema procedure tool for pgsql\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T15:56:44Z", "type": "commit"}, {"oid": "b9320124879c57b243f085c591275ccb7131bbcc", "url": "https://github.com/IBM/FHIR/commit/b9320124879c57b243f085c591275ccb7131bbcc", "message": "issue #945 minor code style updates\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T16:11:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NDg4MA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421664880", "body": "If there isn't going to be a split. I suggest changing the name of this to addProcedureAndFunctions", "bodyText": "If there isn't going to be a split. I suggest changing the name of this to addProcedureAndFunctions", "bodyHTML": "<p dir=\"auto\">If there isn't going to be a split. I suggest changing the name of this to addProcedureAndFunctions</p>", "author": "prb112", "createdAt": "2020-05-07T17:16:32Z", "path": "fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java", "diffHunk": "@@ -247,8 +247,8 @@ public void removeTenantPartitions(IDatabaseAdapter adapter, String schemaName,\n      * @return\n      */\n     public ProcedureDef addProcedure(String schemaName, String objectName, int version, Supplier<String> templateProvider,", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3ODQ2MA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421678460", "bodyText": "Ok, good point, let me change", "author": "albertwang-ibm", "createdAt": "2020-05-07T17:39:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NDg4MA=="}], "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\nindex 27b11753fe..759848cf39 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\n", "chunk": "@@ -246,7 +246,7 @@ public class PhysicalDataModel implements IDataModel {\n      * @param privileges\n      * @return\n      */\n-    public ProcedureDef addProcedure(String schemaName, String objectName, int version, Supplier<String> templateProvider,\n+    public ProcedureDef addProcedureAndFunctions(String schemaName, String objectName, int version, Supplier<String> templateProvider,\n             Collection<IDatabaseObject> dependencies, Collection<GroupPrivilege> privileges, DbType dbType) {\n         ProcedureDef proc = new ProcedureDef(schemaName, objectName, version, templateProvider, dbType);\n         privileges.forEach(p -> p.addToObject(proc));\n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\nindex 759848cf39..5446958602 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\n", "chunk": "@@ -246,9 +261,9 @@ public class PhysicalDataModel implements IDataModel {\n      * @param privileges\n      * @return\n      */\n-    public ProcedureDef addProcedureAndFunctions(String schemaName, String objectName, int version, Supplier<String> templateProvider,\n-            Collection<IDatabaseObject> dependencies, Collection<GroupPrivilege> privileges, DbType dbType) {\n-        ProcedureDef proc = new ProcedureDef(schemaName, objectName, version, templateProvider, dbType);\n+    public ProcedureDef addProcedure(String schemaName, String objectName, int version, Supplier<String> templateProvider,\n+            Collection<IDatabaseObject> dependencies, Collection<GroupPrivilege> privileges) {\n+        ProcedureDef proc = new ProcedureDef(schemaName, objectName, version, templateProvider);\n         privileges.forEach(p -> p.addToObject(proc));\n \n         if (dependencies != null) {\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\ndeleted file mode 100644\nindex 5446958602..0000000000\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/model/PhysicalDataModel.java\n+++ /dev/null\n", "chunk": "@@ -1,423 +0,0 @@\n-/*\n- * (C) Copyright IBM Corp. 2019, 2020\n- *\n- * SPDX-License-Identifier: Apache-2.0\n- */\n-\n-package com.ibm.fhir.database.utils.model;\n-\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.function.Consumer;\n-import java.util.function.Supplier;\n-import java.util.logging.Logger;\n-\n-import com.ibm.fhir.database.utils.api.IDatabaseAdapter;\n-import com.ibm.fhir.database.utils.api.ITransactionProvider;\n-import com.ibm.fhir.database.utils.api.IVersionHistoryService;\n-import com.ibm.fhir.database.utils.common.DataDefinitionUtil;\n-import com.ibm.fhir.database.utils.db2.Db2Adapter;\n-import com.ibm.fhir.task.api.ITaskCollector;\n-\n-/**\n- * Represents the set of tables and other schema objects that make up the\n- * schema we want to build and manage. This is created as code and not in a DDL text file\n- * on purpose. Doing so makes it much easier to test.\n- */\n-public class PhysicalDataModel implements IDataModel {\n-    private static final Logger logger = Logger.getLogger(PhysicalDataModel.class.getName());\n-\n-    // Schema objects will be applied in the order they are added to this list\n-    private final List<IDatabaseObject> allObjects = new ArrayList<>();\n-\n-    // Map of the table objects\n-    private final Map<String, Table> tables = new HashMap<>();\n-\n-    // A list of just procedures, which we may want to update separately\n-    private final List<ProcedureDef> procedures = new ArrayList<>();\n-\n-    // A list of just functions, which we may want to update separately\n-    private final List<FunctionDef> functions = new ArrayList<>();\n-\n-    // A map of tags which can be used to look up objects in the model\n-    private final Map<String, Map<String, Set<IDatabaseObject>>> tagMap = new HashMap<>();\n-\n-    // Common models that we rely on (e.g. for FK constraints)\n-    private final List<PhysicalDataModel> federatedModels = new ArrayList<>();\n-\n-    /**\n-     * Default constructor. No federated models\n-     */\n-    public PhysicalDataModel() {\n-        // No Op\n-    }\n-\n-    /**\n-     * Constructor supporting federated data models\n-     * @param federatedModels\n-     */\n-    public PhysicalDataModel(PhysicalDataModel... federatedModels) {\n-        this.federatedModels.addAll(Arrays.asList(federatedModels));\n-    }\n-\n-    /**\n-     * Add the table to the list of objects in this model\n-     * @param t\n-     */\n-    public void addTable(Table t) {\n-        if (tables.containsKey(t.getName())) {\n-            throw new IllegalStateException(\"Duplicate table definition: \" + t.getName());\n-        }\n-\n-        // Update our tag index for this object\n-        collectTags(t);\n-        tables.put(t.getName(), t);\n-    }\n-\n-    /**\n-     * Just a general object we don't need to know the details of\n-     * @param obj\n-     */\n-    public void addObject(IDatabaseObject obj) {\n-        // Update our tag index for this object\n-        collectTags(obj);\n-        allObjects.add(obj);\n-    }\n-\n-    /**\n-     * Collect all the database objects we know of, describing their\n-     * interdependencies so that the task collector implementation can\n-     * execute them in parallel. This greatly reduces the amount of\n-     * time it takes to provision a schema.\n-     * @param tc collects and manages the object creation tasks and their dependencies\n-     * @param target the target database adapter\n-     * @param tp\n-     * @param vhs\n-     */\n-    public void collect(ITaskCollector tc, IDatabaseAdapter target, ITransactionProvider tp, IVersionHistoryService vhs) {\n-        for (IDatabaseObject obj: allObjects) {\n-            obj.collect(tc, target, tp, vhs);\n-        }\n-    }\n-\n-    /**\n-     * Apply the entire model to the target in order\n-     * @param target\n-     */\n-    public void apply(IDatabaseAdapter target) {\n-        int total = allObjects.size();\n-        int count = 1;\n-        for (IDatabaseObject obj: allObjects) {\n-            logger.fine(String.format(\"Creating [%d/%d] %s\", count++, total, obj.toString()));\n-            obj.apply(target);\n-        }\n-    }\n-\n-    /**\n-     * Apply all the objects linearly, but using the version history service to determine\n-     * what's new and what already exists\n-     * @param target\n-     * @param vhs\n-     */\n-    public void applyWithHistory(IDatabaseAdapter target, IVersionHistoryService vhs) {\n-        int total = allObjects.size();\n-        int count = 1;\n-        for (IDatabaseObject obj: allObjects) {\n-            logger.fine(String.format(\"Creating [%d/%d] %s\", count++, total, obj.toString()));\n-            obj.applyVersion(target, vhs);\n-        }\n-    }\n-\n-    /**\n-     * Apply all the procedures in the order in which they were added to the model\n-     * @param adapter\n-     */\n-    public void applyProcedures(IDatabaseAdapter adapter) {\n-        int total = procedures.size();\n-        int count = 1;\n-        for (ProcedureDef obj: procedures) {\n-            logger.fine(String.format(\"Applying [%d/%d] %s\", count++, total, obj.toString()));\n-            obj.apply(adapter);\n-        }\n-    }\n-\n-    /**\n-     * Apply all the functions in the order in which they were added to the model\n-     * @param adapter\n-     */\n-    public void applyFunctions(IDatabaseAdapter adapter) {\n-        int total = functions.size();\n-        int count = 1;\n-        for (FunctionDef obj: functions) {\n-            logger.fine(String.format(\"Applying [%d/%d] %s\", count++, total, obj.toString()));\n-            obj.apply(adapter);\n-        }\n-    }\n-\n-    /**\n-     * Drop the model from the target database. This is done\n-     * in reverse order\n-     *\n-     * @param target\n-     * @param tagGroup\n-     * @param tag\n-     */\n-    public void drop(IDatabaseAdapter target, String tagGroup, String tag) {\n-        // The simplest way to reverse the list is add everything into an array list\n-        // which we then simply traverse end to start\n-        ArrayList<IDatabaseObject> copy = new ArrayList<>();\n-        copy.addAll(allObjects);\n-\n-        int total = allObjects.size();\n-        int count = 1;\n-        for (int i=total-1; i>=0; i--) {\n-            IDatabaseObject obj = copy.get(i);\n-\n-            if (tag == null || obj.getTags().get(tagGroup) != null && tag.equals(obj.getTags().get(tagGroup))) {\n-                logger.fine(String.format(\"Dropping [%d/%d] %s\", count++, total, obj.toString()));\n-                obj.drop(target);\n-            }\n-            else {\n-                logger.fine(String.format(\"Skipping [%d/%d] %s\", count++, total, obj.toString()));\n-            }\n-        }\n-\n-    }\n-\n-    /**\n-     * Drop the lot\n-     * @param target\n-     */\n-    public void drop(IDatabaseAdapter target) {\n-        drop(target, null, null);\n-    }\n-\n-    /**\n-     * Return all the tables partitioned by the given column name\n-     * @return\n-     */\n-    public Collection<Table> getTenantPartitionedTables(String partitionColumn) {\n-        List<Table> result = new ArrayList<>();\n-\n-        for (Table t: this.tables.values()) {\n-            String cn = t.getTenantColumnName();\n-            if (cn != null && cn.equals(partitionColumn)) {\n-                result.add(t);\n-            }\n-        }\n-        return result;\n-    }\n-\n-    /**\n-     * Make sure every tenant-partitioned table has a partition for the given\n-     * tenantId\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @param tenantId\n-     * @param extentSizeKB\n-     */\n-    public void addTenantPartitions(IDatabaseAdapter adapter, String schemaName, int tenantId, int extentSizeKB) {\n-        final String tenantIdColumn = \"MT_ID\";\n-\n-        // We have to delegate all the fun to the adapter, which knows how\n-        // to manage this most efficiently\n-        adapter.createTenantPartitions(getTenantPartitionedTables(tenantIdColumn), schemaName, tenantId, extentSizeKB);\n-    }\n-\n-    /**\n-     * remove the partition from each of the tenant-based tables\n-     *\n-     * @param adapter\n-     * @param schemaName\n-     * @param tenantId\n-     * @param partitionStagingTable\n-     */\n-    public void removeTenantPartitions(IDatabaseAdapter adapter, String schemaName, int tenantId, String partitionStagingTable) {\n-        final String tenantIdColumn = \"MT_ID\";\n-\n-        // We have to delegate all the fun to the adapter, which knows how\n-        // to manage this most efficiently\n-        adapter.removeTenantPartitions(getTenantPartitionedTables(tenantIdColumn), schemaName, tenantId, partitionStagingTable);\n-    }\n-\n-    /**\n-     * Add a stored procedure definition. The given {@link Supplier} will be called upon\n-     * to provide the DDL body for the procedure at the point in time it is being applied\n-     * to the database, not when constructing the model.\n-     *\n-     * @param schemaName\n-     * @param objectName the name of the procedure object\n-     * @param version\n-     * @param templateProvider supplier of the procedure text\n-     * @param dependencies\n-     * @param privileges\n-     * @return\n-     */\n-    public ProcedureDef addProcedure(String schemaName, String objectName, int version, Supplier<String> templateProvider,\n-            Collection<IDatabaseObject> dependencies, Collection<GroupPrivilege> privileges) {\n-        ProcedureDef proc = new ProcedureDef(schemaName, objectName, version, templateProvider);\n-        privileges.forEach(p -> p.addToObject(proc));\n-\n-        if (dependencies != null) {\n-            proc.addDependencies(dependencies);\n-        }\n-        allObjects.add(proc);\n-        procedures.add(proc);\n-\n-        return proc;\n-    }\n-\n-    /**\n-     * adds the function to the model. \n-     * \n-     * @param schemaName\n-     * @param objectName\n-     * @param version\n-     * @param templateProvider\n-     * @param dependencies\n-     * @param privileges\n-     * @return\n-     */\n-    public FunctionDef addFunction(String schemaName, String objectName, int version, Supplier<String> templateProvider,\n-        Collection<IDatabaseObject> dependencies, Collection<GroupPrivilege> privileges) {\n-        FunctionDef func = new FunctionDef(schemaName, objectName, version, templateProvider);\n-        privileges.forEach(p -> p.addToObject(func));\n-    \n-        if (dependencies != null) {\n-            func.addDependencies(dependencies);\n-        }\n-        allObjects.add(func);\n-        functions.add(func);\n-        return func;\n-    }\n-\n-    @Override\n-    public Table findTable(String schemaName, String tableName) {\n-        Table result = tables.get(DataDefinitionUtil.getQualifiedName(schemaName, tableName));\n-\n-        if (result == null) {\n-            // Look up the object in one of our federated models\n-            for (int i=0; i<this.federatedModels.size() && result == null; i++) {\n-                result = federatedModels.get(i).findTable(schemaName, tableName);\n-            }\n-        }\n-\n-        return result;\n-    }\n-\n-    /**\n-     * Add the object's tags to our tag map\n-     * @param obj\n-     */\n-    private void collectTags(IDatabaseObject obj) {\n-        for (Map.Entry<String,String> tag: obj.getTags().entrySet()) {\n-            String tagName = tag.getKey();\n-            String tagValue = tag.getValue();\n-\n-            Map<String, Set<IDatabaseObject>> tm = tagMap.get(tagName);\n-            if (tm == null) {\n-                tm = new HashMap<>();\n-                tagMap.put(tagName, tm);\n-            }\n-\n-            Set<IDatabaseObject> tagSet = tm.get(tagValue);\n-            if (tagSet == null) {\n-                tagSet = new HashSet<>();\n-                tm.put(tagValue, tagSet);\n-            }\n-\n-            // Add this object to the set of objects associated with this particular tag\n-            tagSet.add(obj);\n-        }\n-    }\n-\n-    /**\n-     * Find all the objects matching the given tag name and value. Think of the tagName\n-     * as the indexed field, and the tagValue as the matching rows (which are the objects\n-     * we're trying to locate).\n-     * @param tagName\n-     * @param tagValue\n-     * @return\n-     */\n-    public Collection<IDatabaseObject> searchByTag(String tagName, String tagValue) {\n-\n-        Map<String, Set<IDatabaseObject>> tm = tagMap.get(tagName);\n-        if (tm != null) {\n-            // at least we've seen the name. So check the value\n-            Set<IDatabaseObject> tagSet = tm.get(tagValue);\n-            if (tagSet != null) {\n-                return Collections.unmodifiableSet(tagSet);\n-            }\n-            else {\n-                // value doesn't match anything\n-                return Collections.emptySet();\n-            }\n-        }\n-        else {\n-            // name doesn't match anything\n-            return Collections.emptySet();\n-        }\n-\n-    }\n-\n-    /**\n-     * Call the given {@link Consumer} for each of the tables found in the\n-     * schema identified by schemaName\n-     * @param schemaName\n-     * @param c\n-     */\n-    public void processTablesInSchema(String schemaName, Consumer<Table> c) {\n-        for (Table t: tables.values()) {\n-            if (t.getSchemaName().equals(schemaName)) {\n-                c.accept(t);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Call the consumer for each object matching the given tag name/value tuple\n-     * @param tagName\n-     * @param tagValue\n-     * @param c\n-     */\n-    public void processObjectsWithTag(String tagName, String tagValue, Consumer<IDatabaseObject> c) {\n-        for (IDatabaseObject obj: searchByTag(tagName, tagValue)) {\n-            c.accept(obj);\n-        }\n-    }\n-\n-    /**\n-     * Apply the grants for the given group to the user\n-     * @param target\n-     * @param groupName\n-     * @param username\n-     */\n-    public void applyGrants(IDatabaseAdapter target, String groupName, String username) {\n-        int total = allObjects.size();\n-        int count = 1;\n-        for (IDatabaseObject obj: allObjects) {\n-            logger.fine(String.format(\"Granting privileges [%d/%d] %s\", count++, total, obj.toString()));\n-            obj.grant(target, groupName, username);\n-        }\n-    }\n-\n-    public void removeTenantPartitions(Db2Adapter adapter, String schemaName, int tenantId) {\n-        // TODO: Need Implementation\n-    }\n-\n-    public void dropOldTenantTables() {\n-        // TODO: Needs Implementation\n-    }\n-\n-    public void dropTenantTablespace() {\n-        // TODO: Needs implementation\n-    }\n-}\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTM4OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421665388", "body": "I suggest changing the interface to createOrReplaceProcedureAndFunctions", "bodyText": "I suggest changing the interface to createOrReplaceProcedureAndFunctions", "bodyHTML": "<p dir=\"auto\">I suggest changing the interface to createOrReplaceProcedureAndFunctions</p>", "author": "prb112", "createdAt": "2020-05-07T17:17:26Z", "path": "fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java", "diffHunk": "@@ -150,7 +150,24 @@ public void dropType(String schemaName, String typeName) {\n \n     @Override\n     public void createOrReplaceProcedure(String schemaName, String procedureName, Supplier<String> supplier) {", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\nindex 0d897bc16a..931a7f104c 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n", "chunk": "@@ -149,7 +149,7 @@ public class PostgreSqlAdapter extends CommonDatabaseAdapter {\n     }\n \n     @Override\n-    public void createOrReplaceProcedure(String schemaName, String procedureName, Supplier<String> supplier) {\n+    public void createOrReplaceProcedureAndFunctions(String schemaName, String procedureName, Supplier<String> supplier) {\n         final String objectName = DataDefinitionUtil.getQualifiedName(schemaName, procedureName);\n         logger.info(\"Create or replace procedure \" + objectName);\n \n", "next_change": {"commit": "fec138e8cc3ef17080703a7fa3e5c2be322356dd", "changed_code": [{"header": "diff --git a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\nindex 931a7f104c..e9071d50c3 100644\n--- a/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n+++ b/fhir-database-utils/src/main/java/com/ibm/fhir/database/utils/postgresql/PostgreSqlAdapter.java\n", "chunk": "@@ -148,33 +153,6 @@ public class PostgreSqlAdapter extends CommonDatabaseAdapter {\n         warnOnce(MessageKey.DROP_TYPE, \"Drop type not supported in PostgreSql\");\n     }\n \n-    @Override\n-    public void createOrReplaceProcedureAndFunctions(String schemaName, String procedureName, Supplier<String> supplier) {\n-        final String objectName = DataDefinitionUtil.getQualifiedName(schemaName, procedureName);\n-        logger.info(\"Create or replace procedure \" + objectName);\n-\n-        // Build the create procedure DDL and apply it\n-        // Because postgresql version 12 doesn't support OUT parameter yet, so we use Function with exactly the similar\n-        // parameters as DB2 stored procedures for now.\n-        final StringBuilder ddl = new StringBuilder()\n-                .append(\"CREATE OR REPLACE FUNCTION \")\n-                .append(objectName)\n-                .append(System.lineSeparator())\n-                .append(supplier.get());\n-\n-        final String ddlString = ddl.toString();\n-        if (logger.isLoggable(Level.FINE)) {\n-            logger.fine(ddlString);\n-        }\n-\n-        runStatement(ddlString);\n-    }\n-\n-    @Override\n-    public void dropProcedure(String schemaName, String procedureName) {\n-        warnOnce(MessageKey.DROP_PROC, \"Drop procedure not supported in PostgreSql\");\n-    }\n-\n     @Override\n     public void createTablespace(String tablespaceName) {\n         warnOnce(MessageKey.TABLESPACE, \"Create tablespace not supported in PostgreSql\");\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2ODMxOQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421668319", "body": ", 2020", "bodyText": ", 2020", "bodyHTML": "<p dir=\"auto\">, 2020</p>", "author": "prb112", "createdAt": "2020-05-07T17:22:27Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java", "diffHunk": "@@ -7,19 +7,25 @@\n package com.ibm.fhir.persistence.jdbc.dao.impl;", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e6506b69a4..e5d4e8e0cb 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -1,5 +1,5 @@\n /*\n- * (C) Copyright IBM Corp. 2017,2019\n+ * (C) Copyright IBM Corp. 2017,2020\n  *\n  * SPDX-License-Identifier: Apache-2.0\n  */\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e5d4e8e0cb..7088b11cd7 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -7,7 +7,6 @@\n package com.ibm.fhir.persistence.jdbc.dao.impl;\n \n import java.sql.Connection;\n-import java.sql.SQLException;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.logging.Level;\n", "next_change": {"commit": "c08e43467019df620a6758bfab6de6b4ec243628", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 7088b11cd7..2d7cc79d67 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -15,6 +15,7 @@ import java.util.logging.Logger;\n import javax.transaction.TransactionSynchronizationRegistry;\n \n import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n+import com.ibm.fhir.persistence.jdbc.JDBCConstants;\n import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n", "next_change": {"commit": "36ba7ba48c8e0967b7ed73cafed1aa46940228d5", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 2d7cc79d67..1be7a08cbe 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -7,15 +7,12 @@\n package com.ibm.fhir.persistence.jdbc.dao.impl;\n \n import java.sql.Connection;\n-import java.util.HashMap;\n import java.util.Map;\n-import java.util.logging.Level;\n import java.util.logging.Logger;\n \n import javax.transaction.TransactionSynchronizationRegistry;\n \n import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n-import com.ibm.fhir.persistence.jdbc.JDBCConstants;\n import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n", "next_change": {"commit": "a8acdb895f1cb7166fd1583a61903cf098112001", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 1be7a08cbe..ca7908b81e 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -12,6 +12,7 @@ import java.util.logging.Logger;\n \n import javax.transaction.TransactionSynchronizationRegistry;\n \n+import com.ibm.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n", "next_change": {"commit": "7c772477ac815669a527ab976f6f551bddaaac39", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex ca7908b81e..5e32691b88 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -17,12 +17,13 @@ import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterNameDAO;\n import com.ibm.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.derby.DerbyParameterNamesDAO;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n import com.ibm.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n+import com.ibm.fhir.persistence.params.api.ParameterNameDAO;\n+import com.ibm.fhir.persistence.params.database.DerbyParameterNamesDAO;\n+import com.ibm.fhir.persistence.params.database.ParameterNameDAOImpl;\n \n /**\n  * This Data Access Object implements the ParameterDAO interface for creating, updating,\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/org/linuxforhealth/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nsimilarity index 88%\nrename from fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nrename to fhir-persistence-jdbc/src/main/java/org/linuxforhealth/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 5e32691b88..37affb8d2e 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/org/linuxforhealth/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -12,18 +12,18 @@ import java.util.logging.Logger;\n \n import javax.transaction.TransactionSynchronizationRegistry;\n \n-import com.ibm.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n-import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n-import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n-import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n-import com.ibm.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n-import com.ibm.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n-import com.ibm.fhir.persistence.params.api.ParameterNameDAO;\n-import com.ibm.fhir.persistence.params.database.DerbyParameterNamesDAO;\n-import com.ibm.fhir.persistence.params.database.ParameterNameDAOImpl;\n+import org.linuxforhealth.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n+import org.linuxforhealth.fhir.persistence.exception.FHIRPersistenceException;\n+import org.linuxforhealth.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n+import org.linuxforhealth.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.dao.api.ParameterDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n+import org.linuxforhealth.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n+import org.linuxforhealth.fhir.persistence.params.api.ParameterNameDAO;\n+import org.linuxforhealth.fhir.persistence.params.database.DerbyParameterNamesDAO;\n+import org.linuxforhealth.fhir.persistence.params.database.ParameterNameDAOImpl;\n \n /**\n  * This Data Access Object implements the ParameterDAO interface for creating, updating,\n", "next_change": null}]}}]}}, {"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 1be7a08cbe..ca7908b81e 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -20,7 +21,6 @@ import com.ibm.fhir.persistence.jdbc.dao.api.ParameterNameDAO;\n import com.ibm.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.derby.DerbyParameterNamesDAO;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n-import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n import com.ibm.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n \n", "next_change": {"commit": "7c772477ac815669a527ab976f6f551bddaaac39", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex ca7908b81e..5e32691b88 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -17,12 +17,13 @@ import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterNameDAO;\n import com.ibm.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.derby.DerbyParameterNamesDAO;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n import com.ibm.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n import com.ibm.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n+import com.ibm.fhir.persistence.params.api.ParameterNameDAO;\n+import com.ibm.fhir.persistence.params.database.DerbyParameterNamesDAO;\n+import com.ibm.fhir.persistence.params.database.ParameterNameDAOImpl;\n \n /**\n  * This Data Access Object implements the ParameterDAO interface for creating, updating,\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/org/linuxforhealth/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nsimilarity index 88%\nrename from fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nrename to fhir-persistence-jdbc/src/main/java/org/linuxforhealth/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 5e32691b88..37affb8d2e 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/org/linuxforhealth/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -12,18 +12,18 @@ import java.util.logging.Logger;\n \n import javax.transaction.TransactionSynchronizationRegistry;\n \n-import com.ibm.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n-import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n-import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n-import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n-import com.ibm.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n-import com.ibm.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n-import com.ibm.fhir.persistence.params.api.ParameterNameDAO;\n-import com.ibm.fhir.persistence.params.database.DerbyParameterNamesDAO;\n-import com.ibm.fhir.persistence.params.database.ParameterNameDAOImpl;\n+import org.linuxforhealth.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n+import org.linuxforhealth.fhir.persistence.exception.FHIRPersistenceException;\n+import org.linuxforhealth.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n+import org.linuxforhealth.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.dao.api.ParameterDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n+import org.linuxforhealth.fhir.persistence.jdbc.postgres.PostgresCodeSystemDAO;\n+import org.linuxforhealth.fhir.persistence.jdbc.postgres.PostgresParameterNamesDAO;\n+import org.linuxforhealth.fhir.persistence.params.api.ParameterNameDAO;\n+import org.linuxforhealth.fhir.persistence.params.database.DerbyParameterNamesDAO;\n+import org.linuxforhealth.fhir.persistence.params.database.ParameterNameDAOImpl;\n \n /**\n  * This Data Access Object implements the ParameterDAO interface for creating, updating,\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2OTEzNg==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421669136", "body": "same line as previous close", "bodyText": "same line as previous close", "bodyHTML": "<p dir=\"auto\">same line as previous close</p>", "author": "prb112", "createdAt": "2020-05-07T17:23:48Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java", "diffHunk": "@@ -110,16 +116,28 @@ public ParameterDAOImpl(Connection managedConnection) {\n      */\n     @Override\n     public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException  {\n-        final String METHODNAME = \"readParameterNameId\";\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n         Connection connection = null;\n \n         try {\n             connection = this.getConnection();\n-            ParameterNameDAO pnd = new ParameterNameDAOImpl(connection);\n+            String dbProductName = connection.getMetaData().getDatabaseProductName().toLowerCase();\n+            ParameterNameDAO pnd;\n+            if (dbProductName.equals(DbType.POSTGRESQL.value())) {\n+                pnd = new PostgreSqlParameterNamesDAO(connection);\n+            } else if (dbProductName.contains(DbType.DERBY.value())) {\n+                pnd = new DerbyParameterNamesDAO(connection);\n+            } else {\n+                pnd = new ParameterNameDAOImpl(connection);\n+            }\n+\n             return pnd.readOrAddParameterNameId(parameterName);\n         }\n+        catch (SQLException e) {", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e6506b69a4..e5d4e8e0cb 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -134,11 +132,9 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n             }\n \n             return pnd.readOrAddParameterNameId(parameterName);\n-        }\n-        catch (SQLException e) {\n+        } catch (SQLException e) {\n             throw new FHIRPersistenceDataAccessException(\"Failed to tell database type from connection!\", e);\n-        }\n-        finally {\n+        } finally {\n             this.cleanup(null, connection);\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e5d4e8e0cb..7088b11cd7 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -117,25 +116,25 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n         final String METHODNAME = \"readOrAddParameterNameId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        Connection connection = getConnection(); // do not close\n \n         try {\n-            connection = this.getConnection();\n-            String dbProductName = connection.getMetaData().getDatabaseProductName().toLowerCase();\n             ParameterNameDAO pnd;\n-            if (dbProductName.equals(DbType.POSTGRESQL.value())) {\n-                pnd = new PostgreSqlParameterNamesDAO(connection);\n-            } else if (dbProductName.contains(DbType.DERBY.value())) {\n-                pnd = new DerbyParameterNamesDAO(connection);\n-            } else {\n-                pnd = new ParameterNameDAOImpl(connection);\n+            switch (getFlavor().getType()) {\n+            case Derby:\n+                pnd = new DerbyParameterNamesDAO(connection, getSchemaName());\n+                break;\n+            case PostgreSQL:\n+                pnd = new PostgreSqlParameterNamesDAO(connection, getSchemaName());\n+                break;\n+            default:\n+                pnd = new ParameterNameDAOImpl(connection, getSchemaName());\n+                break;\n+            \n             }\n \n             return pnd.readOrAddParameterNameId(parameterName);\n-        } catch (SQLException e) {\n-            throw new FHIRPersistenceDataAccessException(\"Failed to tell database type from connection!\", e);\n         } finally {\n-            this.cleanup(null, connection);\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n     }\n", "next_change": {"commit": "72c66695b368a5a8c6e19f78d58e69e2cc13f902", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 7088b11cd7..9cb1f6be7f 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -116,21 +122,21 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n         final String METHODNAME = \"readOrAddParameterNameId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = getConnection(); // do not close\n+        final Connection connection = getConnection(); // do not close\n \n         try {\n             ParameterNameDAO pnd;\n             switch (getFlavor().getType()) {\n-            case Derby:\n+            case DERBY:\n                 pnd = new DerbyParameterNamesDAO(connection, getSchemaName());\n                 break;\n-            case PostgreSQL:\n+            case POSTGRESQL:\n                 pnd = new PostgreSqlParameterNamesDAO(connection, getSchemaName());\n                 break;\n             default:\n                 pnd = new ParameterNameDAOImpl(connection, getSchemaName());\n                 break;\n-            \n+\n             }\n \n             return pnd.readOrAddParameterNameId(parameterName);\n", "next_change": {"commit": "e4f30db890b96be3175c03632905cdbc83f1fdd7", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\ndeleted file mode 100644\nindex 9cb1f6be7f..0000000000\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,373 +0,0 @@\n-/*\n- * (C) Copyright IBM Corp. 2017,2020\n- *\n- * SPDX-License-Identifier: Apache-2.0\n- */\n-\n-package com.ibm.fhir.persistence.jdbc.dao.impl;\n-\n-import java.sql.Connection;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.logging.Level;\n-import java.util.logging.Logger;\n-\n-import javax.transaction.TransactionSynchronizationRegistry;\n-\n-import com.ibm.fhir.persistence.exception.FHIRPersistenceException;\n-import com.ibm.fhir.persistence.jdbc.connection.FHIRDbFlavor;\n-import com.ibm.fhir.persistence.jdbc.dao.api.CodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterDAO;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterNameDAO;\n-import com.ibm.fhir.persistence.jdbc.derby.DerbyCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.derby.DerbyParameterNamesDAO;\n-import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDBConnectException;\n-import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n-import com.ibm.fhir.persistence.jdbc.postgresql.PostgreSqlCodeSystemDAO;\n-import com.ibm.fhir.persistence.jdbc.postgresql.PostgreSqlParameterNamesDAO;\n-import com.ibm.fhir.persistence.jdbc.util.CodeSystemsCache;\n-import com.ibm.fhir.persistence.jdbc.util.CodeSystemsCacheUpdater;\n-import com.ibm.fhir.persistence.jdbc.util.ParameterNamesCache;\n-import com.ibm.fhir.persistence.jdbc.util.ParameterNamesCacheUpdater;\n-import com.ibm.fhir.persistence.jdbc.util.SqlParameterEncoder;\n-\n-/**\n- * This Data Access Object implements the ParameterDAO interface for creating, updating,\n- * and retrieving rows in the IBM FHIR Server parameter-related tables.\n- */\n-public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n-    private static final Logger log = Logger.getLogger(ParameterDAOImpl.class.getName());\n-    private static final String CLASSNAME = ParameterDAOImpl.class.getName();\n-\n-    public static final String DEFAULT_TOKEN_SYSTEM = \"default-token-system\";\n-\n-    private Map<String, Integer> newParameterNameIds = new HashMap<>();\n-    private Map<String, Integer> newCodeSystemIds = new HashMap<>();\n-\n-    private final TransactionSynchronizationRegistry trxSynchRegistry;\n-    private final boolean runningInTrx;\n-    private CodeSystemsCacheUpdater csCacheUpdater = null;\n-    private ParameterNamesCacheUpdater pnCacheUpdater = null;\n-\n-\n-    /**\n-     * Constructs a DAO instance suitable for acquiring connections from a JDBC Datasource object.\n-     * @param Connection - A database connection that will be managed by the caller.\n-     * @param schemaName\n-     * @param flavor\n-     * @param trxSynchRegistry\n-     */\n-    public ParameterDAOImpl(Connection connection, String schemaName, FHIRDbFlavor flavor, TransactionSynchronizationRegistry trxSynchRegistry) {\n-        super(connection, schemaName, flavor);\n-        this.trxSynchRegistry = trxSynchRegistry;\n-        this.runningInTrx = true;\n-    }\n-\n-    /**\n-     * Constructs a DAO using the passed externally managed database connection.\n-     * The connection used by this instance for all DB operations will be the passed connection.\n-     * @param Connection - A database connection that will be managed by the caller.\n-     * @param schemaName\n-     * @param flavor\n-     */\n-    public ParameterDAOImpl(Connection connection, String schemaName, FHIRDbFlavor flavor) {\n-        super(connection, schemaName, flavor);\n-\n-        // For unit-tests, we don't use managed transactions, so don't have any sync registry.\n-        this.trxSynchRegistry = null;\n-        this.runningInTrx = false;\n-    }\n-\n-    @Override\n-    public Map<String, Integer> readAllSearchParameterNames()\n-                                         throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException {\n-        final String METHODNAME = \"readAllSearchParameterNames\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        final Connection connection = getConnection(); // do not close\n-        try {\n-            ParameterNameDAO pnd = new ParameterNameDAOImpl(connection, getSchemaName());\n-            return pnd.readAllSearchParameterNames();\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-    }\n-\n-    @Override\n-    public Map<String, Integer> readAllCodeSystems()\n-            throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException {\n-        final String METHODNAME = \"readAllCodeSystems\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        final Connection connection = getConnection(); // do not close\n-        try {\n-            CodeSystemDAO csd = new CodeSystemDAOImpl(connection, getSchemaName());\n-            return csd.readAllCodeSystems();\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-    }\n-\n-    /**\n-     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n-     * If it's not in the DB, it will be stored and a unique id will be returned.\n-     * @param parameter\n-     * @return Integer - The generated id of the stored system.\n-     * @throws FHIRPersistenceDBConnectException\n-     * @throws FHIRPersistenceDataAccessException\n-     *\n-     */\n-    @Override\n-    public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException  {\n-        final String METHODNAME = \"readOrAddParameterNameId\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        final Connection connection = getConnection(); // do not close\n-\n-        try {\n-            ParameterNameDAO pnd;\n-            switch (getFlavor().getType()) {\n-            case DERBY:\n-                pnd = new DerbyParameterNamesDAO(connection, getSchemaName());\n-                break;\n-            case POSTGRESQL:\n-                pnd = new PostgreSqlParameterNamesDAO(connection, getSchemaName());\n-                break;\n-            default:\n-                pnd = new ParameterNameDAOImpl(connection, getSchemaName());\n-                break;\n-\n-            }\n-\n-            return pnd.readOrAddParameterNameId(parameterName);\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-    }\n-\n-    /**\n-     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n-     * If it's not in the DB, it will be stored and a unique id will be returned.\n-     * @param parameter\n-     * @return Integer - The generated id of the stored system.\n-     * @throws FHIRPersistenceDBConnectException\n-     * @throws FHIRPersistenceDataAccessException\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public int readOrAddCodeSystemId(String codeSystemName) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException   {\n-        final String METHODNAME = \"readOrAddCodeSystemId\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        final Connection connection = getConnection(); // do not close\n-        try {\n-            CodeSystemDAO csd;\n-\n-            switch (getFlavor().getType()) {\n-            case DERBY:\n-                csd = new DerbyCodeSystemDAO(connection, getSchemaName());\n-                break;\n-            case POSTGRESQL:\n-                csd = new PostgreSqlCodeSystemDAO(connection, getSchemaName());\n-                break;\n-            default:\n-                csd = new CodeSystemDAOImpl(connection, getSchemaName());\n-                break;\n-            }\n-\n-            return csd.readOrAddCodeSystem(codeSystemName);\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-    }\n-\n-    /**\n-     * Adds a code system name / code system id pair to a candidate collection for population into the CodeSystemsCache.\n-     * This pair must be present as a row in the FHIR DB CODE_SYSTEMS table.\n-     * @param codeSystemName A valid code system name.\n-     * @param codeSystemId The id corresponding to the code system name.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public void addCodeSystemsCacheCandidate(String codeSystemName, Integer codeSystemId)  throws FHIRPersistenceException {\n-        final String METHODNAME = \"addCodeSystemsCacheCandidate\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        if (this.runningInTrx && CodeSystemsCache.isEnabled()) {\n-            if (this.csCacheUpdater == null) {\n-                // Register a new CodeSystemsCacheUpdater for this thread/trx, if one hasn't been already registered.\n-                this.csCacheUpdater = new CodeSystemsCacheUpdater(CodeSystemsCache.getCacheNameForTenantDatastore(), this.newCodeSystemIds);\n-                try {\n-                    trxSynchRegistry.registerInterposedSynchronization(csCacheUpdater);\n-                    log.fine(\"Registered CodeSystemsCacheUpdater.\");\n-                } catch(Throwable e) {\n-                    FHIRPersistenceException fx = new FHIRPersistenceException(\"Failure registering CodeSystemsCacheUpdater\");\n-                    throw severe(log, fx, e);\n-                }\n-            }\n-            this.newCodeSystemIds.put(codeSystemName, codeSystemId);\n-        }\n-\n-        log.exiting(CLASSNAME, METHODNAME);\n-\n-    }\n-\n-    /**\n-     * Adds a parameter name / parameter id pair to a candidate collection for population into the ParameterNamesCache.\n-     * This pair must be present as a row in the FHIR DB PARAMETER_NAMES table.\n-     * @param parameterName A valid search or sort parameter name.\n-     * @param parameterId The id corresponding to the parameter name.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public void addParameterNamesCacheCandidate(String parameterName, Integer parameterId) throws FHIRPersistenceException {\n-        final String METHODNAME = \"addParameterNamesCacheCandidate\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        if (this.runningInTrx && ParameterNamesCache.isEnabled()) {\n-            if (this.pnCacheUpdater == null) {\n-                // Register a new ParameterNamesCacheUpdater for this thread/trx, if one hasn't been already registered.\n-                this.pnCacheUpdater = new ParameterNamesCacheUpdater(ParameterNamesCache.getCacheNameForTenantDatastore(), this.newParameterNameIds);\n-                try {\n-                    trxSynchRegistry.registerInterposedSynchronization(pnCacheUpdater);\n-                    log.fine(\"Registered ParameterNamesCacheUpdater.\");\n-                } catch(Throwable e) {\n-                    FHIRPersistenceException fx = new FHIRPersistenceException(\"Failure registering ParameterNamesCacheUpdater\");\n-                    throw severe(log, fx, e);\n-                }\n-            }\n-            this.newParameterNameIds.put(parameterName, parameterId);\n-        }\n-\n-        log.exiting(CLASSNAME, METHODNAME);\n-\n-    }\n-\n-\n-    protected  Integer getParameterNameIdFromCaches(String parameterName) {\n-        // Get ParameterNameId from ParameterNameIdCache first.\n-        Integer parameterNameId = ParameterNamesCache.getParameterNameId(parameterName);\n-        // If not found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\n-        // but has not been updated to ParameterNamesCache yet. newParameterNameIds is updated to ParameterNamesCache only when the\n-        // current transaction is committed.\n-        if (parameterNameId == null) {\n-            parameterNameId = this.newParameterNameIds.get(parameterName);\n-        }\n-        return parameterNameId;\n-    }\n-\n-    /**\n-     * Acquire and return the id associated with the passed parameter name.\n-     * @param parameterName The name of a valid FHIR search parameter.\n-     * @return Integer A parameter id.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public int acquireParameterNameId(String parameterName) throws FHIRPersistenceException {\n-        final String METHODNAME = \"acquireParameterNameId\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        Integer parameterNameId;\n-        boolean acquiredFromCache;\n-\n-        try {\n-            parameterNameId = getParameterNameIdFromCaches(parameterName);\n-            if (parameterNameId == null) {\n-                acquiredFromCache = false;\n-                parameterNameId = this.readOrAddParameterNameId(parameterName);\n-                this.addParameterNamesCacheCandidate(parameterName, parameterNameId);\n-            } else {\n-                acquiredFromCache = true;\n-            }\n-            if (log.isLoggable(Level.FINE)) {\n-                log.fine(\"parameterName=\" + parameterName + \"  parameterNameId=\" + parameterNameId +\n-                          \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ParameterNamesCache.getCacheNameForTenantDatastore());\n-            }\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-        return parameterNameId;\n-\n-    }\n-\n-    protected  Integer getCodeSystemIdFromCaches(String codeSystemName) {\n-        // Get CodeSystemId from CodeSystemsCache first.\n-        Integer codeSystemId = CodeSystemsCache.getCodeSystemId(codeSystemName);\n-        // If no found, then get codeSystemId from local newCodeSystemIds in case this id is already in newCodeSystemIds\n-        // but has not been updated to CodeSystemsCache yet. newCodeSystemIds is updated to CodeSystemsCache only when the\n-        // current transaction is committed.\n-        if (codeSystemId == null) {\n-            codeSystemId = this.newCodeSystemIds.get(codeSystemName);\n-        }\n-        return codeSystemId;\n-    }\n-\n-    /**\n-     * Acquire and return the id associated with the passed code-system name.\n-     * @param codeSystemName The name of a valid code-system.\n-     * @return Integer A code-system id.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public int acquireCodeSystemId(String codeSystemName) throws FHIRPersistenceException {\n-        final String METHODNAME = \"acquireCodeSystemId\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        String myCodeSystemName = codeSystemName;\n-        Integer codeSystemId;\n-        boolean acquiredFromCache;\n-\n-        try {\n-            if (myCodeSystemName == null || myCodeSystemName.isEmpty()) {\n-                myCodeSystemName = DEFAULT_TOKEN_SYSTEM;\n-            }\n-            codeSystemId = getCodeSystemIdFromCaches(myCodeSystemName);\n-\n-            if (codeSystemId == null) {\n-                acquiredFromCache = false;\n-                myCodeSystemName = SqlParameterEncoder.encode(myCodeSystemName);\n-                codeSystemId = this.readOrAddCodeSystemId(myCodeSystemName);\n-                this.addCodeSystemsCacheCandidate(myCodeSystemName, codeSystemId);\n-            } else {\n-                acquiredFromCache = true;\n-            }\n-            if (log.isLoggable(Level.FINE)) {\n-                log.fine(\"codeSystemName=\" + myCodeSystemName + \"  codeSystemId=\" + codeSystemId +\n-                          \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + CodeSystemsCache.getCacheNameForTenantDatastore());\n-            }\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-\n-        return codeSystemId;\n-    }\n-\n-    @Override\n-    public Integer readParameterNameId(String parameterName) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException {\n-        final String METHODNAME = \"readParameterNameId\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        final Connection connection = getConnection(); // do not close\n-        try {\n-            ParameterNameDAO pnd = new ParameterNameDAOImpl(connection, getSchemaName());\n-            return pnd.readParameterNameId(parameterName);\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-    }\n-\n-    @Override\n-    public Integer readCodeSystemId(String codeSystemName) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException {\n-        final String METHODNAME = \"readCodeSystemId\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        final Connection connection = getConnection(); // do not close\n-        try {\n-            CodeSystemDAO csd = new CodeSystemDAOImpl(connection, getSchemaName());\n-            return csd.readCodeSystemId(codeSystemName);\n-        } finally {\n-            log.exiting(CLASSNAME, METHODNAME);\n-        }\n-    }\n-\n-}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2OTIwMA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421669200", "body": "same line as previous", "bodyText": "same line as previous", "bodyHTML": "<p dir=\"auto\">same line as previous</p>", "author": "prb112", "createdAt": "2020-05-07T17:23:56Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java", "diffHunk": "@@ -137,15 +155,27 @@ public int readOrAddParameterNameId(String parameterName) throws FHIRPersistence\n      */\n     @Override\n     public int readOrAddCodeSystemId(String codeSystemName) throws FHIRPersistenceDBConnectException, FHIRPersistenceDataAccessException   {\n-        final String METHODNAME = \"storeCodeSystemId\";\n+        final String METHODNAME = \"readOrAddCodeSystemId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n         Connection connection = null;\n         try {\n             connection = this.getConnection();\n-            CodeSystemDAO csd = new CodeSystemDAOImpl(connection);\n+            String dbProductName = connection.getMetaData().getDatabaseProductName().toLowerCase();\n+            CodeSystemDAO csd;\n+            if (dbProductName.equals(DbType.POSTGRESQL.value())) {\n+                csd = new PostgreSqlCodeSystemDAO(connection);\n+            } else if (dbProductName.contains(DbType.DERBY.value())) {\n+                csd = new DerbyCodeSystemDAO(connection);\n+            } else {\n+                csd = new CodeSystemDAOImpl(connection);\n+            }\n+\n             return csd.readOrAddCodeSystem(codeSystemName);\n         }\n+        catch (SQLException e) {", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e6506b69a4..e5d4e8e0cb 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -172,11 +168,9 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n             }\n \n             return csd.readOrAddCodeSystem(codeSystemName);\n-        }\n-        catch (SQLException e) {\n+        } catch (SQLException e) {\n             throw new FHIRPersistenceDataAccessException(\"Failed to tell database type from connection!\", e);\n-        }\n-        finally {\n+        } finally {\n             this.cleanup(null, connection);\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e5d4e8e0cb..7088b11cd7 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -154,24 +153,24 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n         final String METHODNAME = \"readOrAddCodeSystemId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        Connection connection = getConnection(); // do not close\n         try {\n-            connection = this.getConnection();\n-            String dbProductName = connection.getMetaData().getDatabaseProductName().toLowerCase();\n             CodeSystemDAO csd;\n-            if (dbProductName.equals(DbType.POSTGRESQL.value())) {\n-                csd = new PostgreSqlCodeSystemDAO(connection);\n-            } else if (dbProductName.contains(DbType.DERBY.value())) {\n-                csd = new DerbyCodeSystemDAO(connection);\n-            } else {\n-                csd = new CodeSystemDAOImpl(connection);\n+            \n+            switch (getFlavor().getType()) {\n+            case Derby:\n+                csd = new DerbyCodeSystemDAO(connection, getSchemaName());\n+                break;\n+            case PostgreSQL:\n+                csd = new PostgreSqlCodeSystemDAO(connection, getSchemaName());\n+                break;\n+            default:\n+                csd = new CodeSystemDAOImpl(connection, getSchemaName());\n+                break;\n             }\n-\n+            \n             return csd.readOrAddCodeSystem(codeSystemName);\n-        } catch (SQLException e) {\n-            throw new FHIRPersistenceDataAccessException(\"Failed to tell database type from connection!\", e);\n         } finally {\n-            this.cleanup(null, connection);\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n     }\n", "next_change": {"commit": "72c66695b368a5a8c6e19f78d58e69e2cc13f902", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 7088b11cd7..9cb1f6be7f 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -153,22 +159,22 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n         final String METHODNAME = \"readOrAddCodeSystemId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = getConnection(); // do not close\n+        final Connection connection = getConnection(); // do not close\n         try {\n             CodeSystemDAO csd;\n-            \n+\n             switch (getFlavor().getType()) {\n-            case Derby:\n+            case DERBY:\n                 csd = new DerbyCodeSystemDAO(connection, getSchemaName());\n                 break;\n-            case PostgreSQL:\n+            case POSTGRESQL:\n                 csd = new PostgreSqlCodeSystemDAO(connection, getSchemaName());\n                 break;\n             default:\n                 csd = new CodeSystemDAOImpl(connection, getSchemaName());\n                 break;\n             }\n-            \n+\n             return csd.readOrAddCodeSystem(codeSystemName);\n         } finally {\n             log.exiting(CLASSNAME, METHODNAME);\n", "next_change": {"commit": "36ba7ba48c8e0967b7ed73cafed1aa46940228d5", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex 9cb1f6be7f..1be7a08cbe 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -182,82 +168,8 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n     }\n \n     /**\n-     * Adds a code system name / code system id pair to a candidate collection for population into the CodeSystemsCache.\n-     * This pair must be present as a row in the FHIR DB CODE_SYSTEMS table.\n-     * @param codeSystemName A valid code system name.\n-     * @param codeSystemId The id corresponding to the code system name.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public void addCodeSystemsCacheCandidate(String codeSystemName, Integer codeSystemId)  throws FHIRPersistenceException {\n-        final String METHODNAME = \"addCodeSystemsCacheCandidate\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        if (this.runningInTrx && CodeSystemsCache.isEnabled()) {\n-            if (this.csCacheUpdater == null) {\n-                // Register a new CodeSystemsCacheUpdater for this thread/trx, if one hasn't been already registered.\n-                this.csCacheUpdater = new CodeSystemsCacheUpdater(CodeSystemsCache.getCacheNameForTenantDatastore(), this.newCodeSystemIds);\n-                try {\n-                    trxSynchRegistry.registerInterposedSynchronization(csCacheUpdater);\n-                    log.fine(\"Registered CodeSystemsCacheUpdater.\");\n-                } catch(Throwable e) {\n-                    FHIRPersistenceException fx = new FHIRPersistenceException(\"Failure registering CodeSystemsCacheUpdater\");\n-                    throw severe(log, fx, e);\n-                }\n-            }\n-            this.newCodeSystemIds.put(codeSystemName, codeSystemId);\n-        }\n-\n-        log.exiting(CLASSNAME, METHODNAME);\n-\n-    }\n-\n-    /**\n-     * Adds a parameter name / parameter id pair to a candidate collection for population into the ParameterNamesCache.\n-     * This pair must be present as a row in the FHIR DB PARAMETER_NAMES table.\n-     * @param parameterName A valid search or sort parameter name.\n-     * @param parameterId The id corresponding to the parameter name.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public void addParameterNamesCacheCandidate(String parameterName, Integer parameterId) throws FHIRPersistenceException {\n-        final String METHODNAME = \"addParameterNamesCacheCandidate\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        if (this.runningInTrx && ParameterNamesCache.isEnabled()) {\n-            if (this.pnCacheUpdater == null) {\n-                // Register a new ParameterNamesCacheUpdater for this thread/trx, if one hasn't been already registered.\n-                this.pnCacheUpdater = new ParameterNamesCacheUpdater(ParameterNamesCache.getCacheNameForTenantDatastore(), this.newParameterNameIds);\n-                try {\n-                    trxSynchRegistry.registerInterposedSynchronization(pnCacheUpdater);\n-                    log.fine(\"Registered ParameterNamesCacheUpdater.\");\n-                } catch(Throwable e) {\n-                    FHIRPersistenceException fx = new FHIRPersistenceException(\"Failure registering ParameterNamesCacheUpdater\");\n-                    throw severe(log, fx, e);\n-                }\n-            }\n-            this.newParameterNameIds.put(parameterName, parameterId);\n-        }\n-\n-        log.exiting(CLASSNAME, METHODNAME);\n-\n-    }\n-\n-\n-    protected  Integer getParameterNameIdFromCaches(String parameterName) {\n-        // Get ParameterNameId from ParameterNameIdCache first.\n-        Integer parameterNameId = ParameterNamesCache.getParameterNameId(parameterName);\n-        // If not found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\n-        // but has not been updated to ParameterNamesCache yet. newParameterNameIds is updated to ParameterNamesCache only when the\n-        // current transaction is committed.\n-        if (parameterNameId == null) {\n-            parameterNameId = this.newParameterNameIds.get(parameterName);\n-        }\n-        return parameterNameId;\n-    }\n-\n-    /**\n-     * Acquire and return the id associated with the passed parameter name.\n+     * Acquire and return the id associated with the passed parameter name. Being called here\n+     * means that we've already had a cache miss in the JDBCIdentityCache\n      * @param parameterName The name of a valid FHIR search parameter.\n      * @return Integer A parameter id.\n      * @throws FHIRPersistenceException\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2OTc2NA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421669764", "body": "```suggestion\r\n        // If not found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // If no found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\n          \n          \n            \n                    // If not found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-c\"><span class=\"pl-c\">//</span> If <span class=\"x x-first x-last\">no</span> found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-c\"><span class=\"pl-c\">//</span> If <span class=\"x x-first x-last\">not</span> found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds</span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "prb112", "createdAt": "2020-05-07T17:24:54Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java", "diffHunk": "@@ -216,6 +246,19 @@ public void addParameterNamesCacheCandidate(String parameterName, Integer parame\n \n     }\n \n+\n+    protected  Integer getParameterNameIdFromCaches(String parameterName) {\n+        // Get ParameterNameId from ParameterNameIdCache first.\n+        Integer parameterNameId = ParameterNamesCache.getParameterNameId(parameterName);\n+        // If no found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e6506b69a4..e5d4e8e0cb 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -250,7 +242,7 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n     protected  Integer getParameterNameIdFromCaches(String parameterName) {\n         // Get ParameterNameId from ParameterNameIdCache first.\n         Integer parameterNameId = ParameterNamesCache.getParameterNameId(parameterName);\n-        // If no found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\n+        // If not found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\n         // but has not been updated to ParameterNamesCache yet. newParameterNameIds is updated to ParameterNamesCache only when the\n         // current transaction is committed.\n         if (parameterNameId == null) {\n", "next_change": {"commit": "36ba7ba48c8e0967b7ed73cafed1aa46940228d5", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\nindex e5d4e8e0cb..1be7a08cbe 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterDAOImpl.java\n", "chunk": "@@ -154,105 +145,31 @@ public class ParameterDAOImpl extends FHIRDbDAOImpl implements ParameterDAO {\n         final String METHODNAME = \"readOrAddCodeSystemId\";\n         log.entering(CLASSNAME, METHODNAME);\n \n-        Connection connection = null;\n+        final Connection connection = getConnection(); // do not close\n         try {\n-            connection = this.getConnection();\n-            String dbProductName = connection.getMetaData().getDatabaseProductName().toLowerCase();\n             CodeSystemDAO csd;\n-            if (dbProductName.equals(DbType.POSTGRESQL.value())) {\n-                csd = new PostgreSqlCodeSystemDAO(connection);\n-            } else if (dbProductName.contains(DbType.DERBY.value())) {\n-                csd = new DerbyCodeSystemDAO(connection);\n-            } else {\n-                csd = new CodeSystemDAOImpl(connection);\n+\n+            switch (getFlavor().getType()) {\n+            case DERBY:\n+                csd = new DerbyCodeSystemDAO(connection, getSchemaName());\n+                break;\n+            case POSTGRESQL:\n+                csd = new PostgresCodeSystemDAO(connection, getSchemaName());\n+                break;\n+            default:\n+                csd = new CodeSystemDAOImpl(connection, getSchemaName());\n+                break;\n             }\n \n             return csd.readOrAddCodeSystem(codeSystemName);\n-        } catch (SQLException e) {\n-            throw new FHIRPersistenceDataAccessException(\"Failed to tell database type from connection!\", e);\n         } finally {\n-            this.cleanup(null, connection);\n             log.exiting(CLASSNAME, METHODNAME);\n         }\n     }\n \n     /**\n-     * Adds a code system name / code system id pair to a candidate collection for population into the CodeSystemsCache.\n-     * This pair must be present as a row in the FHIR DB CODE_SYSTEMS table.\n-     * @param codeSystemName A valid code system name.\n-     * @param codeSystemId The id corresponding to the code system name.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public void addCodeSystemsCacheCandidate(String codeSystemName, Integer codeSystemId)  throws FHIRPersistenceException {\n-        final String METHODNAME = \"addCodeSystemsCacheCandidate\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        if (this.runningInTrx && CodeSystemsCache.isEnabled()) {\n-            if (this.csCacheUpdater == null) {\n-                // Register a new CodeSystemsCacheUpdater for this thread/trx, if one hasn't been already registered.\n-                this.csCacheUpdater = new CodeSystemsCacheUpdater(CodeSystemsCache.getCacheNameForTenantDatastore(), this.newCodeSystemIds);\n-                try {\n-                    trxSynchRegistry.registerInterposedSynchronization(csCacheUpdater);\n-                    log.fine(\"Registered CodeSystemsCacheUpdater.\");\n-                } catch(Throwable e) {\n-                    FHIRPersistenceException fx = new FHIRPersistenceException(\"Failure registering CodeSystemsCacheUpdater\");\n-                    throw severe(log, fx, e);\n-                }\n-            }\n-            this.newCodeSystemIds.put(codeSystemName, codeSystemId);\n-        }\n-\n-        log.exiting(CLASSNAME, METHODNAME);\n-\n-    }\n-\n-    /**\n-     * Adds a parameter name / parameter id pair to a candidate collection for population into the ParameterNamesCache.\n-     * This pair must be present as a row in the FHIR DB PARAMETER_NAMES table.\n-     * @param parameterName A valid search or sort parameter name.\n-     * @param parameterId The id corresponding to the parameter name.\n-     * @throws FHIRPersistenceException\n-     */\n-    @Override\n-    public void addParameterNamesCacheCandidate(String parameterName, Integer parameterId) throws FHIRPersistenceException {\n-        final String METHODNAME = \"addParameterNamesCacheCandidate\";\n-        log.entering(CLASSNAME, METHODNAME);\n-\n-        if (this.runningInTrx && ParameterNamesCache.isEnabled()) {\n-            if (this.pnCacheUpdater == null) {\n-                // Register a new ParameterNamesCacheUpdater for this thread/trx, if one hasn't been already registered.\n-                this.pnCacheUpdater = new ParameterNamesCacheUpdater(ParameterNamesCache.getCacheNameForTenantDatastore(), this.newParameterNameIds);\n-                try {\n-                    trxSynchRegistry.registerInterposedSynchronization(pnCacheUpdater);\n-                    log.fine(\"Registered ParameterNamesCacheUpdater.\");\n-                } catch(Throwable e) {\n-                    FHIRPersistenceException fx = new FHIRPersistenceException(\"Failure registering ParameterNamesCacheUpdater\");\n-                    throw severe(log, fx, e);\n-                }\n-            }\n-            this.newParameterNameIds.put(parameterName, parameterId);\n-        }\n-\n-        log.exiting(CLASSNAME, METHODNAME);\n-\n-    }\n-\n-\n-    protected  Integer getParameterNameIdFromCaches(String parameterName) {\n-        // Get ParameterNameId from ParameterNameIdCache first.\n-        Integer parameterNameId = ParameterNamesCache.getParameterNameId(parameterName);\n-        // If not found, then get ParameterNameId from local newParameterNameIds in case this id is already in newParameterNameIds\n-        // but has not been updated to ParameterNamesCache yet. newParameterNameIds is updated to ParameterNamesCache only when the\n-        // current transaction is committed.\n-        if (parameterNameId == null) {\n-            parameterNameId = this.newParameterNameIds.get(parameterName);\n-        }\n-        return parameterNameId;\n-    }\n-\n-    /**\n-     * Acquire and return the id associated with the passed parameter name.\n+     * Acquire and return the id associated with the passed parameter name. Being called here\n+     * means that we've already had a cache miss in the JDBCIdentityCache\n      * @param parameterName The name of a valid FHIR search parameter.\n      * @return Integer A parameter id.\n      * @throws FHIRPersistenceException\n", "next_change": null}]}}]}}, {"oid": "5effe479f2dd32a2e5707f6d2f656a5dfff7d752", "url": "https://github.com/IBM/FHIR/commit/5effe479f2dd32a2e5707f6d2f656a5dfff7d752", "message": "issue #945 update schema tool\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T17:25:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MDQ5NQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421670495", "body": ", 2020", "bodyText": ", 2020", "bodyHTML": "<p dir=\"auto\">, 2020</p>", "author": "prb112", "createdAt": "2020-05-07T17:26:05Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java", "diffHunk": "@@ -22,21 +22,21 @@\n /**", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8acdb895f1cb7166fd1583a61903cf098112001", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java\nindex 015ee772a9..443f9ba5d5 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java\n", "chunk": "@@ -16,8 +16,8 @@ import java.util.Map;\n import java.util.logging.Level;\n import java.util.logging.Logger;\n \n+import com.ibm.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n import com.ibm.fhir.persistence.jdbc.dao.api.ParameterNameDAO;\n-import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n /**\n  * Database interaction for parameter_names. Caching etc is handled\n", "next_change": {"commit": "7c772477ac815669a527ab976f6f551bddaaac39", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java b/fhir-persistence-params/src/main/java/com/ibm/fhir/persistence/params/database/ParameterNameDAOImpl.java\nsimilarity index 98%\nrename from fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java\nrename to fhir-persistence-params/src/main/java/com/ibm/fhir/persistence/params/database/ParameterNameDAOImpl.java\nindex 443f9ba5d5..5fa4184fe3 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/dao/impl/ParameterNameDAOImpl.java\n+++ b/fhir-persistence-params/src/main/java/com/ibm/fhir/persistence/params/database/ParameterNameDAOImpl.java\n", "chunk": "@@ -17,7 +17,7 @@ import java.util.logging.Level;\n import java.util.logging.Logger;\n \n import com.ibm.fhir.persistence.exception.FHIRPersistenceDataAccessException;\n-import com.ibm.fhir.persistence.jdbc.dao.api.ParameterNameDAO;\n+import com.ibm.fhir.persistence.params.api.ParameterNameDAO;\n \n /**\n  * Database interaction for parameter_names. Caching etc is handled\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MDk0OA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421670948", "body": ", 2020", "bodyText": ", 2020", "bodyHTML": "<p dir=\"auto\">, 2020</p>", "author": "prb112", "createdAt": "2020-05-07T17:26:46Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java", "diffHunk": "@@ -28,47 +28,45 @@\n      * @param c\n      * @param fsd\n      */\n-    public DerbyCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java\nindex baba11de3a..8d7c6ff790 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java\n", "chunk": "@@ -28,8 +28,8 @@ public class DerbyCodeSystemDAO extends CodeSystemDAOImpl {\n      * @param c\n      * @param fsd\n      */\n-    public DerbyCodeSystemDAO(Connection c) {\n-        super(c);\n+    public DerbyCodeSystemDAO(Connection c, String schemaName) {\n+        super(c, schemaName);\n         this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(c);\n     }\n \n", "next_change": {"commit": "460c0af7eb65fc3825987479c0dc5ce164462d58", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java\nindex 8d7c6ff790..831f084e3b 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyCodeSystemDAO.java\n", "chunk": "@@ -26,7 +26,7 @@ public class DerbyCodeSystemDAO extends CodeSystemDAOImpl {\n     /**\n      * Public constructor\n      * @param c\n-     * @param fsd\n+     * @param schemaName\n      */\n     public DerbyCodeSystemDAO(Connection c, String schemaName) {\n         super(c, schemaName);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MTI1NA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421671254", "body": ", 2020", "bodyText": ", 2020", "bodyHTML": "<p dir=\"auto\">, 2020</p>", "author": "prb112", "createdAt": "2020-05-07T17:27:17Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java", "diffHunk": "@@ -21,23 +21,24 @@\n  */\n public class DerbyParameterNamesDAO extends ParameterNameDAOImpl {\n     private final FhirRefSequenceDAO fhirRefSequenceDAO;\n-    \n-    public DerbyParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java\nindex 91e1949ff6..996965a81f 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java\n", "chunk": "@@ -22,8 +22,8 @@ import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessExceptio\n public class DerbyParameterNamesDAO extends ParameterNameDAOImpl {\n     private final FhirRefSequenceDAO fhirRefSequenceDAO;\n \n-    public DerbyParameterNamesDAO(Connection c) {\n-        super(c);\n+    public DerbyParameterNamesDAO(Connection c, String schemaName) {\n+        super(c, schemaName);\n         this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(c);\n \n     }\n", "next_change": {"commit": "7c772477ac815669a527ab976f6f551bddaaac39", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java b/fhir-persistence-params/src/main/java/com/ibm/fhir/persistence/params/database/DerbyParameterNamesDAO.java\nsimilarity index 91%\nrename from fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java\nrename to fhir-persistence-params/src/main/java/com/ibm/fhir/persistence/params/database/DerbyParameterNamesDAO.java\nindex 996965a81f..62f5ff44a5 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyParameterNamesDAO.java\n+++ b/fhir-persistence-params/src/main/java/com/ibm/fhir/persistence/params/database/DerbyParameterNamesDAO.java\n", "chunk": "@@ -25,7 +24,6 @@ public class DerbyParameterNamesDAO extends ParameterNameDAOImpl {\n     public DerbyParameterNamesDAO(Connection c, String schemaName) {\n         super(c, schemaName);\n         this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(c);\n-\n     }\n \n     @Override\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MTc4OQ==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421671789", "body": "why does codeSystemCacheAdapter now get the parameterDao? ", "bodyText": "why does codeSystemCacheAdapter now get the parameterDao?", "bodyHTML": "<p dir=\"auto\">why does codeSystemCacheAdapter now get the parameterDao?</p>", "author": "prb112", "createdAt": "2020-05-07T17:28:12Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java", "diffHunk": "@@ -437,7 +423,7 @@ public long storeResource(String tablePrefix, List<ExtractedParameterValue> para\n             if (parameters != null) {\n                 // Derby doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n                 try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-                    new ParameterNameCacheAdapter(parameterNameDAO), new CodeSystemCacheAdapter(codeSystemDAO))) {\n+                    new ParameterNameCacheAdapter(parameterDao), new CodeSystemCacheAdapter(parameterDao))) {", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY4NjA4MA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421686080", "bodyText": "the parameterDao is actually a wrap for both parameterNameDAO and codeSystemDAO, the the cache implemenation is done inside parameterDao.  very interesting implementation.", "author": "albertwang-ibm", "createdAt": "2020-05-07T17:51:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MTc4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "f29f3032f2317cfd22f65e705c3592013acb52d6", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex ccd9567232..785e629222 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -422,8 +429,9 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n             // Note we don't get any parameters for the resource soft-delete operation\n             if (parameters != null) {\n                 // Derby doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n+                IResourceTypeCache resourceTypeCache = new ResourceTypeCacheAdapter(this);\n                 try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-                    new ParameterNameCacheAdapter(parameterDao), new CodeSystemCacheAdapter(parameterDao))) {\n+                    new ParameterNameCacheAdapter(parameterDao), new CodeSystemCacheAdapter(parameterDao), getResourceReferenceDAO(), resourceTypeCache)) {\n                     for (ExtractedParameterValue p: parameters) {\n                         p.accept(pvd);\n                     }\n", "next_change": {"commit": "36f31f42837adbba786f158a4792f96162f777b7", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex 785e629222..468ce56d5e 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -429,9 +428,9 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n             // Note we don't get any parameters for the resource soft-delete operation\n             if (parameters != null) {\n                 // Derby doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n-                IResourceTypeCache resourceTypeCache = new ResourceTypeCacheAdapter(this);\n+                JDBCIdentityCache identityCache = new JDBCIdentityCacheImpl(getCache(), this, parameterDao);\n                 try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-                    new ParameterNameCacheAdapter(parameterDao), new CodeSystemCacheAdapter(parameterDao), getResourceReferenceDAO(), resourceTypeCache)) {\n+                    identityCache, getResourceReferenceDAO())) {\n                     for (ExtractedParameterValue p: parameters) {\n                         p.accept(pvd);\n                     }\n", "next_change": {"commit": "9120003a95c31b6e58102cf7b1dd7537e1235297", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex 468ce56d5e..66e02aaca1 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -430,7 +433,7 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n                 // Derby doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n                 JDBCIdentityCache identityCache = new JDBCIdentityCacheImpl(getCache(), this, parameterDao);\n                 try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n-                    identityCache, getResourceReferenceDAO())) {\n+                    identityCache, getResourceReferenceDAO(), getTransactionData())) {\n                     for (ExtractedParameterValue p: parameters) {\n                         p.accept(pvd);\n                     }\n", "next_change": {"commit": "cbd3aa9ac3f312abe24b6dd0e0d7c6a6357f55ba", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex 66e02aaca1..4d949d13ee 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -431,7 +431,7 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n             // Note we don't get any parameters for the resource soft-delete operation\n             if (parameters != null) {\n                 // Derby doesn't support partitioned multi-tenancy, so we disable it on the DAO:\n-                JDBCIdentityCache identityCache = new JDBCIdentityCacheImpl(getCache(), this, parameterDao);\n+                JDBCIdentityCache identityCache = new JDBCIdentityCacheImpl(getCache(), this, parameterDao, getResourceReferenceDAO());\n                 try (ParameterVisitorBatchDAO pvd = new ParameterVisitorBatchDAO(conn, null, tablePrefix, false, v_logical_resource_id, 100,\n                     identityCache, getResourceReferenceDAO(), getTransactionData())) {\n                     for (ExtractedParameterValue p: parameters) {\n", "next_change": {"commit": "5d4d796d31926790c636785c928aebb806e43af7", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex 4d949d13ee..4a006c0fff 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -440,6 +442,22 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n                 }\n             }\n         }\n+\n+        // Finally, write a record to RESOURCE_CHANGE_LOG which records each event\n+        // related to resources changes (issue-1955)\n+        String changeType = p_is_deleted ? \"D\" : v_new_resource ? \"C\" :  \"U\";\n+        String INSERT_CHANGE_LOG = \"INSERT INTO resource_change_log(resource_id, change_tstamp, resource_type_id, logical_resource_id, version_id, change_type)\"\n+                + \" VALUES (?,?,?,?,?,?)\";\n+        try (PreparedStatement ps = conn.prepareStatement(INSERT_CHANGE_LOG)) {\n+            ps.setLong(     1, v_resource_id);\n+            ps.setTimestamp(2, p_last_updated, UTC);\n+            ps.setInt(      3, v_resource_type_id);\n+            ps.setLong(     4, v_logical_resource_id);\n+            ps.setInt(      5, v_insert_version);\n+            ps.setString(   6, changeType);\n+            ps.executeUpdate();\n+        }\n+\n         logger.exiting(CLASSNAME, METHODNAME);\n         return v_resource_id;\n     }\n", "next_change": {"commit": "e288f56ad4e5991ebc28801bbe584cfe8118aa33", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex 4a006c0fff..31e54a2ab3 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -453,7 +416,7 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n             ps.setTimestamp(2, p_last_updated, UTC);\n             ps.setInt(      3, v_resource_type_id);\n             ps.setLong(     4, v_logical_resource_id);\n-            ps.setInt(      5, v_insert_version);\n+            ps.setInt(      5, p_version);\n             ps.setString(   6, changeType);\n             ps.executeUpdate();\n         }\n", "next_change": {"commit": "1498d614cc73212e82395229f10abd9a187504fe", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex 31e54a2ab3..ea72cb3714 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -425,25 +509,6 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n         return v_resource_id;\n     }\n \n-\n-    /**\n-     * Delete all parameters for the given resourceId from the parameters table\n-     *\n-     * @param conn\n-     * @param tableName\n-     * @param logicalResourceId\n-     * @throws SQLException\n-     */\n-    protected void deleteFromParameterTable(Connection conn, String tableName, long logicalResourceId) throws SQLException {\n-        final String delStrValues = \"DELETE FROM \" + tableName + \" WHERE logical_resource_id = ?\";\n-        try (PreparedStatement stmt = conn.prepareStatement(delStrValues)) {\n-            // bind parameters\n-            stmt.setLong(1, logicalResourceId);\n-            stmt.executeUpdate();\n-        }\n-\n-    }\n-\n     /**\n      * Read the id for the named type\n      * @param resourceTypeName\n", "next_change": {"commit": "583903ae7bf3422875d32eee49316459441b4f72", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\nindex ea72cb3714..b157878c47 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/derby/DerbyResourceDAO.java\n", "chunk": "@@ -506,7 +577,7 @@ public class DerbyResourceDAO extends ResourceDAOImpl {\n         }\n \n         logger.exiting(CLASSNAME, METHODNAME);\n-        return v_resource_id;\n+        return v_logical_resource_id;\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MjYwNw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421672607", "body": "I think logically this should go in the catch block. ", "bodyText": "I think logically this should go in the catch block.", "bodyHTML": "<p dir=\"auto\">I think logically this should go in the catch block.</p>", "author": "prb112", "createdAt": "2020-05-07T17:29:23Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java", "diffHunk": "@@ -21,84 +21,59 @@\n  *\n  */\n public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlCodeSystemDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlCodeSystemDAO.class.getName();\n+    private static final String SQL_CALL_ADD_CODE_SYSTEM_ID = \"{CALL %s.add_code_system(?, ?)}\";\n \n     /**\n      * Public constructor\n      * @param c\n      * @param fsd\n      */\n-    public PostgreSqlCodeSystemDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlCodeSystemDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n-    }\n-\n-    @Override\n-    public int readOrAddCodeSystem(String codeSystem) throws FHIRPersistenceDataAccessException   {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getCodeSystemId(codeSystem);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                String INS = \"INSERT INTO code_systems (code_system_id, code_system_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, codeSystem);\n-                    stmt.executeUpdate();\n-                }\n-            }\n-            catch (SQLException e) {\n-                if (\"23505\".equals(e.getSQLState())) {\n-                    // another thread snuck in and created the record, so we need to fetch the correct id\n-                    result = getCodeSystemId(codeSystem);\n-\n-                    if (result == null) {\n-                        // This would be truly weird, but we protect against it anyway\n-                        throw new IllegalStateException(\"No code system returned after duplicate found!\");\n-                    }\n-                }\n-                else {\n-                    throw new FHIRPersistenceDataAccessException(\"codeSystem=\" + codeSystem, e);\n-                }\n-            }\n-\n-        }\n-\n-        // There's no way result can be null here, so we're OK returning an int\n-        return result;\n     }\n \n     /**\n-     * Read the id for the named type\n-     * @param codeSystem\n-     * @return the database id, or null if the named record is not found\n+     * Calls a stored procedure to read the system contained in the passed Parameter in the Code_Systems table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n+     * @param systemName\n+     *\n+     * @return The generated id of the stored system.\n      * @throws FHIRPersistenceDataAccessException\n      */\n-    protected Integer getCodeSystemId(String codeSystem) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n-\n-        String sql1 = \"SELECT code_system_id FROM code_systems WHERE code_system_name = ?\";\n-\n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql1)) {\n-            stmt.setString(1, codeSystem);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n-            }\n-            else {\n-                result = null;\n+    @Override\n+    public int readOrAddCodeSystem(String systemName) throws FHIRPersistenceDataAccessException   {\n+        final String METHODNAME = \"readOrAddCodeSystem\";\n+        log.entering(CLASSNAME, METHODNAME);\n+\n+        int systemId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing code system id: name=\" + systemName;", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY4NzYxNw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421687617", "bodyText": "I agree", "author": "albertwang-ibm", "createdAt": "2020-05-07T17:54:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MjYwNw=="}], "type": "inlineReview", "revised_code": {"commit": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex dc86bbd3fc..09fca34ccd 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -50,7 +50,6 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n         int systemId;\n         String currentSchema;\n         String stmtString;\n-        String errMsg = \"Failure storing code system id: name=\" + systemName;\n         long dbCallStartTime;\n         double dbCallDuration;\n \n", "next_change": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\nindex 09fca34ccd..9e90b682b0 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlCodeSystemDAO.java\n", "chunk": "@@ -48,14 +48,12 @@ public class PostgreSqlCodeSystemDAO extends CodeSystemDAOImpl {\n         log.entering(CLASSNAME, METHODNAME);\n \n         int systemId;\n-        String currentSchema;\n         String stmtString;\n         long dbCallStartTime;\n         double dbCallDuration;\n \n         try {\n-            currentSchema = getConnection().getSchema().trim();\n-            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, currentSchema);\n+            stmtString = String.format(SQL_CALL_ADD_CODE_SYSTEM_ID, getSchemaName());\n             try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n                 stmt.setString(1, systemName);\n                 stmt.registerOutParameter(2, Types.INTEGER);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzIwNA==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421673204", "body": "It should be set by the connection.\r\nWe can enforce this as part of the creation of the datasource", "bodyText": "It should be set by the connection.\nWe can enforce this as part of the creation of the datasource", "bodyHTML": "<p dir=\"auto\">It should be set by the connection.<br>\nWe can enforce this as part of the creation of the datasource</p>", "author": "prb112", "createdAt": "2020-05-07T17:30:22Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java", "diffHunk": "@@ -6,75 +6,63 @@\n \n package com.ibm.fhir.persistence.jdbc.postgresql;\n \n+import java.sql.CallableStatement;\n import java.sql.Connection;\n-import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n+import java.sql.Types;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n \n-import com.ibm.fhir.persistence.jdbc.dao.api.FhirRefSequenceDAO;\n import com.ibm.fhir.persistence.jdbc.dao.impl.ParameterNameDAOImpl;\n import com.ibm.fhir.persistence.jdbc.exception.FHIRPersistenceDataAccessException;\n \n public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n-    private final FhirRefSequenceDAO fhirRefSequenceDAO;\n+    private static final Logger log = Logger.getLogger(PostgreSqlParameterNamesDAO.class.getName());\n+    private static final String CLASSNAME = PostgreSqlParameterNamesDAO.class.getName();\n+    private static final String SQL_CALL_ADD_PARAMETER_NAME = \"{CALL %s.add_parameter_name(?, ?)}\";\n \n-    public PostgreSqlParameterNamesDAO(Connection c, FhirRefSequenceDAO fsd) {\n+    public PostgreSqlParameterNamesDAO(Connection c) {\n         super(c);\n-        this.fhirRefSequenceDAO = fsd;\n-    }\n-\n-    @Override\n-    public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n-        // As the system is concurrent, we have to handle cases where another thread\n-        // might create the entry after we selected and found nothing\n-        Integer result = getParameterId(parameterName);\n-\n-        // Create the resource if we don't have it already (set by the continue handler)\n-        if (result == null) {\n-            try {\n-                result = fhirRefSequenceDAO.nextValue();\n-\n-                final String INS = \"INSERT INTO parameter_names (parameter_name_id, parameter_name) VALUES (?, ?)\";\n-                try (PreparedStatement stmt = getConnection().prepareStatement(INS)) {\n-                    // bind parameters\n-                    stmt.setInt(1, result);\n-                    stmt.setString(2, parameterName);\n-                    stmt.executeUpdate();\n-                }\n-            } catch (SQLException e) {\n-                throw new FHIRPersistenceDataAccessException(\"Error while getting or inserting parameterName '\" + parameterName + \"'\", e);\n-            }\n-        }\n-\n-        // cannot be null, so safe to return as an int\n-        return result;\n     }\n \n     /**\n-     * Read the id for the named type\n+     * Calls a stored procedure to read the name contained in the passed Parameter in the Parameter_Names table.\n+     * If it's not in the DB, it will be stored and a unique id will be returned.\n      * @param parameterName\n-     * @return the database id, or null if the named record is not found\n+     * @return The generated id of the stored system.\n      * @throws FHIRPersistenceDataAccessException\n      */\n-    protected Integer getParameterId(String parameterName) throws FHIRPersistenceDataAccessException {\n-        Integer result;\n+    @Override\n+    public int readOrAddParameterNameId(String parameterName) throws FHIRPersistenceDataAccessException  {\n+        final String METHODNAME = \"readOrAddParameterNameId\";\n+        log.entering(CLASSNAME, METHODNAME);\n \n-        String sql = \"SELECT parameter_name_id FROM parameter_names WHERE parameter_name = ?\";\n+        int parameterNameId;\n+        String currentSchema;\n+        String stmtString;\n+        String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n+        long dbCallStartTime;\n+        double dbCallDuration;\n \n-        try (PreparedStatement stmt = getConnection().prepareStatement(sql)) {\n-            stmt.setString(1, parameterName);\n-            ResultSet rs = stmt.executeQuery();\n-            if (rs.next()) {\n-                result = rs.getInt(1);\n-            }  else {\n-                result = null;\n+        try {\n+            // TODO: schema should be known by application. Fix to avoid an extra round-trip.", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY4ODE3Mw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421688173", "bodyText": "agree, we can improve this in future PR.", "author": "albertwang-ibm", "createdAt": "2020-05-07T17:55:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzIwNA=="}], "type": "inlineReview", "revised_code": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\nindex 30334a2e6a..44454e5d77 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlParameterNamesDAO.java\n", "chunk": "@@ -37,16 +37,13 @@ public class PostgreSqlParameterNamesDAO extends ParameterNameDAOImpl {\n         log.entering(CLASSNAME, METHODNAME);\n \n         int parameterNameId;\n-        String currentSchema;\n         String stmtString;\n         String errMsg = \"Failure storing search parameter name id: name=\" + parameterName;\n         long dbCallStartTime;\n         double dbCallDuration;\n \n         try {\n-            // TODO: schema should be known by application. Fix to avoid an extra round-trip.\n-            currentSchema = getConnection().getSchema().trim();\n-            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, currentSchema);\n+            stmtString = String.format(SQL_CALL_ADD_PARAMETER_NAME, getSchemaName());\n             try (CallableStatement stmt = getConnection().prepareCall(stmtString)) {\n                 stmt.setString(1, parameterName);\n                 stmt.registerOutParameter(2, Types.INTEGER);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzkzNg==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421673936", "body": "Nice the function doing a lot of work.  ", "bodyText": "Nice the function doing a lot of work.", "bodyHTML": "<p dir=\"auto\">Nice the function doing a lot of work.</p>", "author": "prb112", "createdAt": "2020-05-07T17:31:37Z", "path": "fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java", "diffHunk": "@@ -93,43 +90,54 @@ public Resource  insert(Resource resource, List<ExtractedParameterValue> paramet\n \n         try {\n             connection = this.getConnection();\n-\n-            this.fhirRefSequenceDAO = new FhirRefSequenceDAOImpl(connection);\n-            this.parameterNameDAO = new PostgreSqlParameterNamesDAO(connection, fhirRefSequenceDAO);\n-            this.codeSystemDAO = new PostgreSqlCodeSystemDAO(connection, fhirRefSequenceDAO);\n-\n             resourceTypeId = getResourceTypeIdFromCaches(resource.getResourceType());\n             if (resourceTypeId == null) {\n                 acquiredFromCache = false;\n-                resourceTypeId = getOrCreateResourceType(resource.getResourceType(), connection);\n+                resourceTypeId = this.readResourceTypeId(resource.getResourceType());\n                 this.addResourceTypeCacheCandidate(resource.getResourceType(), resourceTypeId);\n             } else {\n                 acquiredFromCache = true;\n             }\n-\n-            if (logger.isLoggable(Level.FINE)) {\n-                logger.fine(\"resourceType=\" + resource.getResourceType() + \"  resourceTypeId=\" + resourceTypeId +\n+            if (logger.isLoggable(Level.FINER)) {\n+                logger.finer(\"resourceType=\" + resource.getResourceType() + \"  resourceTypeId=\" + resourceTypeId +\n                          \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ResourceTypesCache.getCacheNameForTenantDatastore());\n             }\n \n+            // TODO avoid the round-trip and use the configured data schema name\n+            currentSchema = connection.getSchema().trim();\n+            stmtString = String.format(SQL_INSERT_WITH_PARAMETERS, currentSchema);\n+            stmt = connection.prepareCall(stmtString);\n+            stmt.setString(1, resource.getResourceType());\n+            stmt.setString(2, resource.getLogicalId());\n+            stmt.setBytes(3, resource.getData());", "originalCommit": "b9320124879c57b243f085c591275ccb7131bbcc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY4OTM0Nw==", "url": "https://github.com/IBM/FHIR/pull/1030#discussion_r421689347", "bodyText": "yeah", "author": "albertwang-ibm", "createdAt": "2020-05-07T17:57:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzkzNg=="}], "type": "inlineReview", "revised_code": {"commit": "b54bab634bbf178b49745220a80b870a862fb268", "changed_code": [{"header": "diff --git a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\nindex d4ff638edf..86db7765ca 100644\n--- a/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n+++ b/fhir-persistence-jdbc/src/main/java/com/ibm/fhir/persistence/jdbc/postgresql/PostgreSqlResourceDAO.java\n", "chunk": "@@ -103,9 +100,7 @@ public class PostgreSqlResourceDAO extends ResourceDAOImpl {\n                          \"  acquiredFromCache=\" + acquiredFromCache + \"  tenantDatastoreCacheName=\" + ResourceTypesCache.getCacheNameForTenantDatastore());\n             }\n \n-            // TODO avoid the round-trip and use the configured data schema name\n-            currentSchema = connection.getSchema().trim();\n-            stmtString = String.format(SQL_INSERT_WITH_PARAMETERS, currentSchema);\n+            stmtString = String.format(SQL_INSERT_WITH_PARAMETERS, getSchemaName());\n             stmt = connection.prepareCall(stmtString);\n             stmt.setString(1, resource.getResourceType());\n             stmt.setString(2, resource.getLogicalId());\n", "next_change": null}]}}, {"oid": "4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "url": "https://github.com/IBM/FHIR/commit/4f22d7c0d87041ebba81e57c25f70f60dd94ce5f", "message": "issue #945 updates per review  comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T18:24:21Z", "type": "commit"}, {"oid": "cedffdd0df3fe17ac4d6bb16fd5ca9647b19a041", "url": "https://github.com/IBM/FHIR/commit/cedffdd0df3fe17ac4d6bb16fd5ca9647b19a041", "message": "issue #945 log change\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-07T19:25:24Z", "type": "commit"}]}