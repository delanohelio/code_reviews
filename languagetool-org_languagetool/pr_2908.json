{"pr_number": 2908, "pr_title": "Fix HunspellRuleTest on Windows", "pr_author": "asashour", "pr_createdAt": "2020-05-11T15:20:13Z", "pr_url": "https://github.com/languagetool-org/languagetool/pull/2908", "merge_commit": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEyNDU1OQ==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423124559", "body": "I'm not sure if this is a good idea, the input file could be very large and would be loaded into memory this way (the same is true for other cases in HttpApiSentenceChecler)...", "bodyText": "I'm not sure if this is a good idea, the input file could be very large and would be loaded into memory this way (the same is true for other cases in HttpApiSentenceChecler)...", "bodyHTML": "<p dir=\"auto\">I'm not sure if this is a good idea, the input file could be very large and would be loaded into memory this way (the same is true for other cases in HttpApiSentenceChecler)...</p>", "author": "danielnaber", "createdAt": "2020-05-11T15:28:57Z", "path": "languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java", "diffHunk": "@@ -80,15 +80,8 @@ private String formatDuration(Duration duration) {\n     return String.format(\"%d:%02d:%02d\", absSeconds / 3600, (absSeconds % 3600) / 60, absSeconds % 60);\n   }\n \n-  private int countLines(File input) throws FileNotFoundException {\n-    int count = 0;\n-    try (Scanner sc = new Scanner(input)) {\n-      while (sc.hasNextLine()) {\n-        sc.nextLine();\n-        count++;\n-      }\n-    }\n-    return count;\n+  private int countLines(File input) throws IOException {\n+    return Files.readAllLines(input.toPath()).size();", "originalCommit": "018ed4f577081d1ad23bf6cc3cc05b0048fd128d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE0ODY3Nw==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423148677", "bodyText": "You are definitely right, this approach doesn't work for large files.\nIt has been changed, please let me know if other places also need lines to be read one-by-one.", "author": "asashour", "createdAt": "2020-05-11T16:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEyNDU1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex 8e18eaefb1..1e3b121695 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n", "chunk": "@@ -81,7 +81,13 @@ class HttpApiSentenceChecker {\n   }\n \n   private int countLines(File input) throws IOException {\n-    return Files.readAllLines(input.toPath()).size();\n+    int count = 0;\n+    try (BufferedReader reader = Files.newBufferedReader(input.toPath())) {\n+      while (reader.readLine() != null) {\n+        count++;\n+      }\n+    }\n+    return count;\n   }\n \n   private List<File> splitInput(int lines, File input, int threadCount) throws IOException {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex 8e18eaefb1..1e3b121695 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n", "chunk": "@@ -81,7 +81,13 @@ class HttpApiSentenceChecker {\n   }\n \n   private int countLines(File input) throws IOException {\n-    return Files.readAllLines(input.toPath()).size();\n+    int count = 0;\n+    try (BufferedReader reader = Files.newBufferedReader(input.toPath())) {\n+      while (reader.readLine() != null) {\n+        count++;\n+      }\n+    }\n+    return count;\n   }\n \n   private List<File> splitInput(int lines, File input, int threadCount) throws IOException {\n", "next_change": {"commit": "595d641ed5ba2eb36fe75b63be4479f975a070e6", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex 1e3b121695..dc57deeb46 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n", "chunk": "@@ -80,10 +80,11 @@ class HttpApiSentenceChecker {\n     return String.format(\"%d:%02d:%02d\", absSeconds / 3600, (absSeconds % 3600) / 60, absSeconds % 60);\n   }\n \n-  private int countLines(File input) throws IOException {\n+  private int countLines(File input) throws FileNotFoundException {\n     int count = 0;\n-    try (BufferedReader reader = Files.newBufferedReader(input.toPath())) {\n-      while (reader.readLine() != null) {\n+    try (Scanner sc = new Scanner(input)) {\n+      while (sc.hasNextLine()) {\n+        sc.nextLine();\n         count++;\n       }\n     }\n", "next_change": {"commit": "36de7a6f20641e35bf2e703337e3cf2acd49cb9f", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex dc57deeb46..0146615362 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n", "chunk": "@@ -91,54 +91,62 @@ class HttpApiSentenceChecker {\n     return count;\n   }\n \n-  private List<File> splitInput(int lines, File input, int threadCount) throws IOException {\n-    List<File> tempFiles = new ArrayList<>();\n-    int batchSize = lines / threadCount;\n+  private List<String> splitInput(File input, int threadCount) throws IOException {\n+    List<String> texts = new ArrayList<>();\n+    final int batchSize = 10;  // do not modify - this would change the results\n     System.out.println(\"Working with \" + threadCount + \" threads, single batch size: \" + batchSize + \" lines\");\n-    int fileCount = 0;\n-    int startLine = 0;\n     int lineCount = 0;\n-    File tempFile = getTempFile(fileCount);\n-    tempFiles.add(tempFile);\n-    FileWriter fw = new FileWriter(tempFile);\n+    StringBuilder sb = new StringBuilder();\n     try (Scanner sc = new Scanner(input)) {\n       while (sc.hasNextLine()) {\n         String line = sc.nextLine();\n-        fw.write(line + \"\\n\");\n+        sb.append(line);\n+        sb.append(\"\\n\");\n         lineCount++;\n         if (lineCount > 0 && lineCount % batchSize == 0) {\n-          fileCount++;\n-          fw.close();\n-          File destFile = new File(tempFile.getParentFile(), HttpApiSentenceChecker.class.getSimpleName() + \"-\" + startLine + \"-to-\" + lineCount + \".json\");\n-          startLine = lineCount;\n-          FileUtils.moveFile(tempFile, destFile);\n-          tempFile = getTempFile(fileCount);\n-          tempFiles.add(destFile);\n-          fw = new FileWriter(tempFile);\n+          texts.add(sb.toString());\n+          sb = new StringBuilder();\n         }\n       }\n     }\n-    fw.close();\n-    return tempFiles;\n-  }\n-\n-  @NotNull\n-  private File getTempFile(int fileCount) throws IOException {\n-    return File.createTempFile(HttpApiSentenceChecker.class.getSimpleName() + \"-split-input-\" + fileCount + \"-\", \".txt\");\n+    System.out.println(lineCount + \" lines from \" + input + \" split into \" + texts.size() + \" text of \" + batchSize + \" lines each\");\n+    return texts;\n   }\n \n-  private List<File> runOnFiles(List<File> files) throws InterruptedException, ExecutionException {\n+  private List<File> runOnTexts(List<String> texts) throws InterruptedException, ExecutionException {\n     List<File> resultFiles = new ArrayList<>();\n     ExecutorService execService = new ForkJoinPool(threadCount, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, false);\n     List<Callable<File>> callables = new ArrayList<>();\n     int count = 0;\n-    for (File file : files) {\n-      if (file.length() == 0) {\n-        continue;\n+    int textsPerThread = texts.size() / threadCount;\n+    System.out.println(\"textsPerThread: \" + textsPerThread);\n+    /*SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd_HH:mm:ss\");\n+    String date = sdf.format(new Date());\n+    File dir = new File(\"/tmp/HttpApi-\" + date);\n+    dir.mkdir();*/\n+    for (int i = 0; i < threadCount; i++) {\n+      List<String> tmpTexts = new ArrayList<>();\n+      for (int j = 0; j < textsPerThread; j++) {\n+        // TODO: check?\n+        if (texts.size() == 0) {\n+          System.out.println(\"No more texts to be collected\");\n+          break;\n+        }\n+        tmpTexts.add(texts.remove(0));\n       }\n-      callables.add(new CheckCallable(count, baseUrl, token, file, langCode));\n+      //debugTexts(tmpTexts, dir, i);\n+      callables.add(new CheckCallable(count, baseUrl, token, tmpTexts, langCode, user, password));\n+      System.out.println(\"Created thread \" + count + \" with \" + tmpTexts.size() + \" texts\");\n       count++;\n     }\n+    if (texts.size() > 0) {\n+      System.out.println(texts.size() + \" texts remaining, creating another thread for them\");\n+      callables.add(new CheckCallable(count, baseUrl, token, texts, langCode, user, password));\n+      //debugTexts(texts, dir, 999);\n+    } else {\n+      System.out.println(\"No texts remaining\");\n+    }\n+    System.out.println(\"Created \" + callables.size() + \" threads\");\n     List<Future<File>> futures = execService.invokeAll(callables);\n     for (Future<File> future : futures) {\n       resultFiles.add(future.get());\n", "next_change": {"commit": "6fdba286dd6063f0ef199de0046b516471230890", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex 0146615362..1cb57a6d82 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n", "chunk": "@@ -142,7 +141,6 @@ class HttpApiSentenceChecker {\n     if (texts.size() > 0) {\n       System.out.println(texts.size() + \" texts remaining, creating another thread for them\");\n       callables.add(new CheckCallable(count, baseUrl, token, texts, langCode, user, password));\n-      //debugTexts(texts, dir, 999);\n     } else {\n       System.out.println(\"No texts remaining\");\n     }\n", "next_change": null}, {"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex 0146615362..1cb57a6d82 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n", "chunk": "@@ -155,17 +153,6 @@ class HttpApiSentenceChecker {\n     return resultFiles;\n   }\n \n-  private void debugTexts(List<String> texts, File dir, int k) throws IOException {\n-    int i = 0;\n-    for (String text : texts) {\n-      i++;\n-      File file = new File(dir, i + \"-\" + k + \".txt\");\n-      try (FileWriter fw = new FileWriter(file)) {\n-        fw.write(text);\n-      }\n-    }\n-  }\n-\n   private void joinResults(List<File> threadFiles, File output) throws IOException {\n     // for the diff in RuleMatchDiffFinder, order doesn't matter...\n     System.out.println(\"Joining \" + threadFiles.size() + \" result files...\");\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "message": "Merge commit", "committedDate": null}, {"oid": "595d641ed5ba2eb36fe75b63be4479f975a070e6", "committedDate": "2020-05-12 21:52:44 +0200", "message": "Revert \"Fix HunspellRuleTest\""}, {"oid": "cd6fc8879defe6ec9aa4ef5753fd85363d3dca8c", "committedDate": "2020-06-02 18:25:08 +0200", "message": "Basic Auth for HttpApiSentenceChecker"}, {"oid": "00e5d7f62f29b609695f9e213842263ec9ffa0ec", "committedDate": "2020-07-17 09:35:41 +0200", "message": "warn on 'null' date"}, {"oid": "57fa433788e720475bfb058f5b1ed652cf182e06", "committedDate": "2020-07-21 09:29:52 +0200", "message": "small logging improvements"}, {"oid": "e380a7b5c91e8a3ac46e4df782bf53f6329f1016", "committedDate": "2020-09-02 10:51:33 +0200", "message": "log input if parsing fails"}, {"oid": "bb4b7051dbc7eef58544a502cebf29b7625e8ae2", "committedDate": "2020-09-03 16:51:43 +0200", "message": "try making process slightly more robust by using more unique file names"}, {"oid": "bd2319f6a812be4accf07b09795b1d18f4f1c240", "committedDate": "2020-09-04 08:29:05 +0200", "message": "improve usage message"}, {"oid": "36de7a6f20641e35bf2e703337e3cf2acd49cb9f", "committedDate": "2020-09-19 10:55:55 +0200", "message": "change text splitting so that changing the number of threads doesn't change the way the texts are split, keeping the result stable"}, {"oid": "6fdba286dd6063f0ef199de0046b516471230890", "committedDate": "2020-09-19 10:55:55 +0200", "message": "remove debug code"}, {"oid": "559ff9e689df8023cd48105d9c152a0f5d02a730", "committedDate": "2020-09-20 13:53:45 +0200", "message": "shuffle batches for a more uniform distribution"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDkxNQ==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423570915", "body": "This should also use scanner to avoid reading everything into RAM.", "bodyText": "This should also use scanner to avoid reading everything into RAM.", "bodyHTML": "<p dir=\"auto\">This should also use scanner to avoid reading everything into RAM.</p>", "author": "danielnaber", "createdAt": "2020-05-12T08:52:19Z", "path": "languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java", "diffHunk": "@@ -56,16 +57,13 @@ private void index(File outputDir, String[] inputFiles) throws IOException {\n   private void indexFile(IndexWriter indexWriter, String inputFile) throws IOException {\n     System.out.println(\"Indexing \" + inputFile);\n     int lineCount = 0;\n-    try (Scanner scanner = new Scanner(new File(inputFile))) {\n-      while (scanner.hasNextLine()) {\n-        String line = scanner.nextLine();\n-        Document doc = new Document();\n-        doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n-        doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n-        indexWriter.addDocument(doc);\n-        if (++lineCount % 10_000 == 0) {\n-          System.out.println(lineCount + \"...\");\n-        }\n+    for (String line : Files.readAllLines(Paths.get(inputFile))) {", "originalCommit": "5eaf9a64758588ab86fc824341e850020b676390", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java b/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\nindex e4f07cfee8..018910fc59 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\n", "chunk": "@@ -57,13 +58,16 @@ class TextIndexCreator {\n   private void indexFile(IndexWriter indexWriter, String inputFile) throws IOException {\n     System.out.println(\"Indexing \" + inputFile);\n     int lineCount = 0;\n-    for (String line : Files.readAllLines(Paths.get(inputFile))) {\n-      Document doc = new Document();\n-      doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n-      doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n-      indexWriter.addDocument(doc);\n-      if (++lineCount % 10_000 == 0) {\n-        System.out.println(lineCount + \"...\");\n+    try (BufferedReader br = Files.newBufferedReader(Paths.get(inputFile))) {\n+      String line;\n+      while ((line = br.readLine()) != null) {\n+        Document doc = new Document();\n+        doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n+        doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n+        indexWriter.addDocument(doc);\n+        if (++lineCount % 10_000 == 0) {\n+          System.out.println(lineCount + \"...\");\n+        }\n       }\n     }\n   }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java b/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\nindex e4f07cfee8..018910fc59 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\n", "chunk": "@@ -57,13 +58,16 @@ class TextIndexCreator {\n   private void indexFile(IndexWriter indexWriter, String inputFile) throws IOException {\n     System.out.println(\"Indexing \" + inputFile);\n     int lineCount = 0;\n-    for (String line : Files.readAllLines(Paths.get(inputFile))) {\n-      Document doc = new Document();\n-      doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n-      doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n-      indexWriter.addDocument(doc);\n-      if (++lineCount % 10_000 == 0) {\n-        System.out.println(lineCount + \"...\");\n+    try (BufferedReader br = Files.newBufferedReader(Paths.get(inputFile))) {\n+      String line;\n+      while ((line = br.readLine()) != null) {\n+        Document doc = new Document();\n+        doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n+        doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n+        indexWriter.addDocument(doc);\n+        if (++lineCount % 10_000 == 0) {\n+          System.out.println(lineCount + \"...\");\n+        }\n       }\n     }\n   }\n", "next_change": null}]}, "commits_in_main": [{"oid": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "message": "Merge commit", "committedDate": null}, {"oid": "595d641ed5ba2eb36fe75b63be4479f975a070e6", "committedDate": "2020-05-12 21:52:44 +0200", "message": "Revert \"Fix HunspellRuleTest\""}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTA5OA==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423571098", "body": "This should also use scanner to avoid reading everything into RAM.", "bodyText": "This should also use scanner to avoid reading everything into RAM.", "bodyHTML": "<p dir=\"auto\">This should also use scanner to avoid reading everything into RAM.</p>", "author": "danielnaber", "createdAt": "2020-05-12T08:52:35Z", "path": "languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java", "diffHunk": "@@ -54,18 +55,17 @@\n     ObjectMapper mapper = new ObjectMapper();\n     List<LightRuleMatch> ruleMatches = new ArrayList<>();\n     int lineCount = 1;\n-    try (Scanner scanner = new Scanner(inputFile)) {\n-      while (scanner.hasNextLine()) {\n-        String line = scanner.nextLine();\n+    for (String line : Files.readAllLines(inputFile.toPath())) {", "originalCommit": "5eaf9a64758588ab86fc824341e850020b676390", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU4MjQwNQ==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423582405", "bodyText": "Done, and I removed the try/catch, because no exception is thrown from the enclosed methods.", "author": "asashour", "createdAt": "2020-05-12T09:09:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTA5OA=="}], "type": "inlineReview", "revised_code": {"commit": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\nindex 346871bdfc..2187aaf3f4 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n", "chunk": "@@ -54,17 +55,14 @@ class LightRuleMatchParser {\n   private List<LightRuleMatch> parseAggregatedJson(File inputFile) throws IOException {\n     ObjectMapper mapper = new ObjectMapper();\n     List<LightRuleMatch> ruleMatches = new ArrayList<>();\n-    int lineCount = 1;\n-    for (String line : Files.readAllLines(inputFile.toPath())) {\n-      try {\n+    try (BufferedReader br = Files.newBufferedReader(inputFile.toPath())) {\n+      String line;\n+      while ((line = br.readLine()) != null) {\n         JsonNode node = mapper.readTree(line);\n         JsonNode matches = node.get(\"matches\");\n         for (JsonNode match : matches) {\n           ruleMatches.add(nodeToLightMatch(node.get(\"title\").asText(), match));\n         }\n-        lineCount++;\n-      } catch (Exception e) {\n-        throw new RuntimeException(\"Failed to parse line \" + lineCount + \" of \" + inputFile, e);\n       }\n     }\n     return ruleMatches;\n", "next_change": null}]}, "revised_code_in_main": {"commit": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\nindex 346871bdfc..2187aaf3f4 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n", "chunk": "@@ -54,17 +55,14 @@ class LightRuleMatchParser {\n   private List<LightRuleMatch> parseAggregatedJson(File inputFile) throws IOException {\n     ObjectMapper mapper = new ObjectMapper();\n     List<LightRuleMatch> ruleMatches = new ArrayList<>();\n-    int lineCount = 1;\n-    for (String line : Files.readAllLines(inputFile.toPath())) {\n-      try {\n+    try (BufferedReader br = Files.newBufferedReader(inputFile.toPath())) {\n+      String line;\n+      while ((line = br.readLine()) != null) {\n         JsonNode node = mapper.readTree(line);\n         JsonNode matches = node.get(\"matches\");\n         for (JsonNode match : matches) {\n           ruleMatches.add(nodeToLightMatch(node.get(\"title\").asText(), match));\n         }\n-        lineCount++;\n-      } catch (Exception e) {\n-        throw new RuntimeException(\"Failed to parse line \" + lineCount + \" of \" + inputFile, e);\n       }\n     }\n     return ruleMatches;\n", "next_change": {"commit": "595d641ed5ba2eb36fe75b63be4479f975a070e6", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\nindex 2187aaf3f4..3410c38dbe 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n", "chunk": "@@ -55,15 +53,19 @@ class LightRuleMatchParser {\n   private List<LightRuleMatch> parseAggregatedJson(File inputFile) throws IOException {\n     ObjectMapper mapper = new ObjectMapper();\n     List<LightRuleMatch> ruleMatches = new ArrayList<>();\n-    try (BufferedReader br = Files.newBufferedReader(inputFile.toPath())) {\n-      String line;\n-      while ((line = br.readLine()) != null) {\n+    int lineCount = 1;\n+    try (Scanner scanner = new Scanner(inputFile)) {\n+      while (scanner.hasNextLine()) {\n+        String line = scanner.nextLine();\n         JsonNode node = mapper.readTree(line);\n         JsonNode matches = node.get(\"matches\");\n         for (JsonNode match : matches) {\n           ruleMatches.add(nodeToLightMatch(node.get(\"title\").asText(), match));\n         }\n+        lineCount++;\n       }\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed to parse line \" + lineCount + \" of \" + inputFile, e);\n     }\n     return ruleMatches;\n   }\n", "next_change": {"commit": "1f4247b080c6513b50a7e5f9d968b20f17d38651", "changed_code": [{"header": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\nindex 3410c38dbe..6c6f9ffd2d 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n", "chunk": "@@ -67,7 +71,7 @@ class LightRuleMatchParser {\n     } catch (Exception e) {\n       throw new RuntimeException(\"Failed to parse line \" + lineCount + \" of \" + inputFile, e);\n     }\n-    return ruleMatches;\n+    return new JsonParseResult(ruleMatches, buildDates);\n   }\n \n   @NotNull\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "c9e39292d35b9051f7b9cb0d516ff7fdfbe9c728", "message": "Merge commit", "committedDate": null}, {"oid": "595d641ed5ba2eb36fe75b63be4479f975a070e6", "committedDate": "2020-05-12 21:52:44 +0200", "message": "Revert \"Fix HunspellRuleTest\""}, {"oid": "5a2a1f5a1bd0f97e7e6d8862ec090ff605e070f9", "committedDate": "2020-05-13 15:27:16 +0200", "message": "improve method name"}, {"oid": "1226240d04382c99f0221735ac582789d5bcbaed", "committedDate": "2020-05-17 14:36:03 +0200", "message": "limit number of suggestions to 5, just like for users"}, {"oid": "3adc9918b331269a27aad143003bb7784c3d64e7", "committedDate": "2020-05-17 14:58:14 +0200", "message": "use full sentence if possible"}, {"oid": "94777b6f8460359a42f1f643bc15d68c5ac9329e", "committedDate": "2020-05-29 14:05:56 +0200", "message": "fix: subId was lost"}, {"oid": "4e05176681340429d64ac5e57e497d217ad478a8", "committedDate": "2020-05-30 10:19:09 +0200", "message": "slightly more verbose output"}, {"oid": "97111088acdb8427c1cdf34c051c78c5f39073d0", "committedDate": "2020-08-16 09:27:25 +0200", "message": "print a hint when a \"removed\" match was actually just replaced by another match"}, {"oid": "ea211b57ece9b1b4899cdfed07f27ad97cb11b95", "committedDate": "2020-08-28 13:49:26 +0200", "message": "avoid collapsing consecutive spaces"}, {"oid": "b3e3cfc3e4ce68fc3990160816ab6dabf67bf8dd", "committedDate": "2020-08-29 23:13:44 +0200", "message": "revert recent change, it broke the \"replaced by\" detection"}, {"oid": "e648903c0da9e58246e6d5be9fcf22eddd014846", "committedDate": "2020-09-02 10:32:07 +0200", "message": "print tags in nightly diff"}, {"oid": "0af2d516d5c4c3854e6c9a8091d2b1c0ec845bd7", "committedDate": "2020-09-08 12:20:44 +0200", "message": "tiny improvement"}, {"oid": "782249642cdf3624fc50844ccd9e0881f4580eec", "committedDate": "2020-11-18 17:55:19 +0100", "message": "show category of matches"}, {"oid": "010e508ef9c5e9b01bbc36f8e7ec1a76e0eeeab5", "committedDate": "2021-08-19 13:35:30 +0200", "message": "show leading and trailing white spaces"}, {"oid": "ab5e80e94cbc59f8cc4f2ed82b4ada920735eaeb", "committedDate": "2021-11-05 16:34:13 +0100", "message": "try a bit harder to get a good context for each match"}, {"oid": "1f4247b080c6513b50a7e5f9d968b20f17d38651", "committedDate": "2022-01-18 15:19:40 +0100", "message": "add API build dates to HTML result to ease debugging / add transparency in case results look wrong"}, {"oid": "16c636f1d21ff095e3da0aa5961fe33cd593070d", "committedDate": "2022-03-16 17:32:27 +0100", "message": "Show isPremium in RegressionTests"}]}, {"oid": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "url": "https://github.com/languagetool-org/languagetool/commit/1baebe695df3229b46aaa68f78292ac2f34ab20f", "message": "Fix HunspellRuleTest\n\nFixes #2202", "committedDate": "2020-05-12T09:04:48Z", "type": "commit"}]}