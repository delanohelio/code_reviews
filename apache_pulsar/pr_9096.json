{"pr_number": 9096, "pr_title": "PIP 76: Streaming Offload(Part I)", "pr_author": "Renkai", "pr_createdAt": "2020-12-30T14:24:56Z", "pr_url": "https://github.com/apache/pulsar/pull/9096", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODE3NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528174", "body": "Do we need to expose the SegmentInfo here?", "bodyText": "Do we need to expose the SegmentInfo here?", "bodyHTML": "<p dir=\"auto\">Do we need to expose the SegmentInfo here?</p>", "author": "codelipenghui", "createdAt": "2021-01-10T07:58:31Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NDgxOQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554694819", "bodyText": "This should be an interface not a class.", "author": "sijie", "createdAt": "2021-01-11T04:16:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODE3NA=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -33,16 +34,22 @@ import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n     @ToString\n-    class SegmentInfo {\n-        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n-                           Map<String, String> driverMetadata) {\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n             this.uuid = uuid;\n             this.beginLedger = beginLedger;\n             this.beginEntry = beginEntry;\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -46,43 +43,6 @@ public interface LedgerOffloader {\n         OffloadResult result();\n     }\n \n-    @ToString\n-    class SegmentInfoImpl implements SegmentInfo {\n-        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n-                               Map<String, String> driverMetadata) {\n-            this.uuid = uuid;\n-            this.beginLedger = beginLedger;\n-            this.beginEntry = beginEntry;\n-            this.driverName = driverName;\n-            this.driverMetadata = driverMetadata;\n-        }\n-\n-\n-        public final UUID uuid;\n-        public final long beginLedger;\n-        public final long beginEntry;\n-        public final String driverName;\n-        volatile private long endLedger;\n-        volatile private long endEntry;\n-        volatile boolean closed = false;\n-        public final Map<String, String> driverMetadata;\n-\n-        public boolean isClosed() {\n-            return closed;\n-        }\n-\n-        public void closeSegment(long endLedger, long endEntry) {\n-            this.endLedger = endLedger;\n-            this.endEntry = endEntry;\n-            this.closed = true;\n-        }\n-\n-        public OffloadResult result() {\n-            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n-        }\n-    }\n-\n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "3f59f16a32888538a15ee9ee6189372f556f795f", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..facff2cb3c0 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -37,12 +35,6 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n-    interface SegmentInfo {\n-        boolean isClosed();\n-\n-        OffloadResult result();\n-    }\n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex facff2cb3c0..8c81499c528 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -35,6 +36,7 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODUyMg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528522", "body": "Is it possible to check the consecutive in the offloader? I think it's more easy to handle in the managedledger.", "bodyText": "Is it possible to check the consecutive in the offloader? I think it's more easy to handle in the managedledger.", "bodyHTML": "<p dir=\"auto\">Is it possible to check the consecutive in the offloader? I think it's more easy to handle in the managedledger.</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:02:10Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                ManagedLedgerException.OffloadNotConsecutiveException;", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDkwMTU0Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554901542", "bodyText": "@codelipenghui managedledger can do a full in-depth check use for ledger information, but managed ledger will also use a naive check(if ledger id equals and entry id is consecutive, then it is consecutive, that's most common case), that can be used to spot bugs when managedledger not work properly.", "author": "Renkai", "createdAt": "2021-01-11T09:03:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODUyMg=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -103,10 +110,23 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n         PositionImpl lastOffered();\n \n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n         boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                ManagedLedgerException.OffloadNotConsecutiveException;\n+                OffloadNotConsecutiveException;\n+\n+        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                OffloadNotConsecutiveException {\n+            return CompletableFuture.completedFuture(offerEntry(entry));\n+        }\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n     }\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -120,15 +86,26 @@ public interface LedgerOffloader {\n             return CompletableFuture.completedFuture(lastOffered());\n         }\n \n-        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException;\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException {\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n             return CompletableFuture.completedFuture(offerEntry(entry));\n         }\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());\n+        }\n     }\n \n     // TODO: improve the user metadata in subsequent changes\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODk3OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528979", "body": "It's better to also add async method for these 3 methods. Usually, we should implement the sync method based on the async method.", "bodyText": "It's better to also add async method for these 3 methods. Usually, we should implement the sync method based on the async method.", "bodyHTML": "<p dir=\"auto\">It's better to also add async method for these 3 methods. Usually, we should implement the sync method based on the async method.</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:06:35Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTY2NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554695665", "bodyText": "+1", "author": "sijie", "createdAt": "2021-01-11T04:17:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODk3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -103,10 +110,23 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n         PositionImpl lastOffered();\n \n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n         boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                ManagedLedgerException.OffloadNotConsecutiveException;\n+                OffloadNotConsecutiveException;\n+\n+        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                OffloadNotConsecutiveException {\n+            return CompletableFuture.completedFuture(offerEntry(entry));\n+        }\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n     }\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -120,15 +86,26 @@ public interface LedgerOffloader {\n             return CompletableFuture.completedFuture(lastOffered());\n         }\n \n-        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException;\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException {\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n             return CompletableFuture.completedFuture(offerEntry(entry));\n         }\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());\n+        }\n     }\n \n     // TODO: improve the user metadata in subsequent changes\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTIzMw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529233", "body": "Please check the comment of this method, I think here is not correct, The result just return a future for the OffloadHandle, this does not mean that the data has been persisted", "bodyText": "Please check the comment of this method, I think here is not correct, The result just return a future for the OffloadHandle, this does not mean that the data has been persisted", "bodyHTML": "<p dir=\"auto\">Please check the comment of this method, I think here is not correct, The result just return a future for the OffloadHandle, this does not mean that the data has been persisted</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:09:02Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +161,32 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Offload the passed in ledger to longterm storage.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned future completes, the ledger has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjExNA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555032114", "bodyText": "Comment updated", "author": "Renkai", "createdAt": "2021-01-11T13:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTIzMw=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -162,17 +182,19 @@ public interface LedgerOffloader {\n                                     Map<String, String> extraMetadata);\n \n     /**\n-     * Offload the passed in ledger to longterm storage.\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n      * Metadata passed in is for inspection purposes only and should be stored\n      * alongside the segment data.\n      *\n-     * When the returned future completes, the ledger has been persisted to the\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n      * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n      *\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n      * This uid will be stored in the managed ledger metadata before attempting the\n-     * call to offload(). If a subsequent or concurrent call to offload() finds\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n      * a uid in the metadata, it will attempt to cleanup this attempt with a call\n      * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n      * the managed ledger will update its metadata again, to record the completion,\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..26ef810c91e 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -189,12 +145,12 @@ public interface LedgerOffloader {\n      *\n      * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n      * ledgers has been persisted to the\n-     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     * longterm storage, so it is safe to delete the original copy in bookkeeper.\n      *\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n      * This uid will be stored in the managed ledger metadata before attempting the\n-     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * call to streamingOffload(). If a subsequent or concurrent call to streamingOffload() finds\n      * a uid in the metadata, it will attempt to cleanup this attempt with a call\n      * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n      * the managed ledger will update its metadata again, to record the completion,\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTI4NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529284", "body": "```suggestion\r\n    interface OffloadHandle {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                interface OffloaderHandle {\n          \n          \n            \n                interface OffloadHandle {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">interface</span> <span class=\"pl-en x x-first x-last\">OffloaderHandle</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">interface</span> <span class=\"pl-en x x-first x-last\">OffloadHandle</span> {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "codelipenghui", "createdAt": "2021-01-10T08:09:40Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -94,7 +101,7 @@ public interface LedgerOffloader {\n      * Used to store driver info, buffer entries, mark progress, etc.\n      * Create one per second.\n      */\n-    interface OffloaderHandle {\n+    interface OffloadHandle {\n \n         /**\n          * return true when both buffer have enough size and ledger/entry id is next to the current one.\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -99,9 +59,15 @@ public interface LedgerOffloader {\n \n     /**\n      * Used to store driver info, buffer entries, mark progress, etc.\n-     * Create one per second.\n+     * Create one per segment.\n      */\n     interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n \n         /**\n          * return true when both buffer have enough size and ledger/entry id is next to the current one.\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -76,24 +74,18 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n         /**\n          * The caller should manually release entry no matter what the offer result is.\n          */\n         OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n \n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529357", "body": "UnsupportedOperationException?", "bodyText": "UnsupportedOperationException?", "bodyHTML": "<p dir=\"auto\">UnsupportedOperationException?</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:10:19Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzNDkyOQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555034929", "bodyText": "It's the default behavior of the interface, useful when a new implementation only implements a part of the interface but still useful.", "author": "Renkai", "createdAt": "2021-01-11T13:10:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMjE2MA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555102160", "bodyText": "you should return a CompletableFuture that reports the UnsupportedOperationException\nthe caller of a method that returns a Future does not expect the method to throw exceptions.", "author": "eolivelli", "createdAt": "2021-01-11T14:54:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE5NzI3Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555197277", "bodyText": "Maybe the exception should be UnsupportedOperationException?", "author": "gaoran10", "createdAt": "2021-01-11T16:58:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -219,7 +241,7 @@ public interface LedgerOffloader {\n \n     default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n                                                         Map<String, String> offloadDriverMetadata) {\n-        throw new UnsupportedClassVersionError();\n+        throw new UnsupportedOperationException();\n     }\n \n     default CompletableFuture<Void> deleteOffloaded(UUID uid,\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTU5Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529597", "body": "maxOffloadSegmentRolloverTimeInSeconds?", "bodyText": "maxOffloadSegmentRolloverTimeInSeconds?", "bodyHTML": "<p dir=\"auto\">maxOffloadSegmentRolloverTimeInSeconds?</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:13:22Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\nindex 1042ff6bf2b..23d8720148b 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n", "chunk": "@@ -63,8 +63,10 @@ public class TieredStorageConfiguration {\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n-    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final String MAX_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"maxOffloadSegmentRolloverTimeInSeconds\";\n+    public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n     public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n     public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n     public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;\n \n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\nindex 23d8720148b..4c934b74890 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n", "chunk": "@@ -67,7 +67,7 @@ public class TieredStorageConfiguration {\n     public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n     public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n     public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n-    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final String MAX_OFFLOAD_SEGMENT_SIZE_IN_BYTES = \"maxOffloadSegmentSizeInBytes\";\n     public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;\n \n     protected static final int MB = 1024 * 1024;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529925", "body": "We also need to add the minOffloadSegmentRolloverTimeInSeconds to avoid the segments rollover too often.", "bodyText": "We also need to add the minOffloadSegmentRolloverTimeInSeconds to avoid the segments rollover too often.", "bodyHTML": "<p dir=\"auto\">We also need to add the minOffloadSegmentRolloverTimeInSeconds to avoid the segments rollover too often.</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:16:28Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA1MzA4NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555053085", "bodyText": "Do you mean segment may become larger than MAX_SEGMENT_SIZE_IN_BYTES if the time it reaches MAX_SEGMENT_SIZE_IN_BYTES is shorter than minOffloadSegmentRolloverTimeInSeconds? If so, maybe we need a REAL_MAX_SEGMENT_SIZE_IN_BYTES to avoid the segment become too big.", "author": "Renkai", "createdAt": "2021-01-11T13:40:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTcwNjQzNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555706436", "bodyText": "minOffloadSegmentRolloverTimeInSeconds related implementations added", "author": "Renkai", "createdAt": "2021-01-12T11:36:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\nindex 1042ff6bf2b..23d8720148b 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n", "chunk": "@@ -63,8 +63,10 @@ public class TieredStorageConfiguration {\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n-    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final String MAX_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"maxOffloadSegmentRolloverTimeInSeconds\";\n+    public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n     public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n     public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n     public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;\n \n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\nindex 23d8720148b..4c934b74890 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n", "chunk": "@@ -67,7 +67,7 @@ public class TieredStorageConfiguration {\n     public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n     public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n     public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n-    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final String MAX_OFFLOAD_SEGMENT_SIZE_IN_BYTES = \"maxOffloadSegmentSizeInBytes\";\n     public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;\n \n     protected static final int MB = 1024 * 1024;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530658", "body": "Can we reuse the `OffloadIndexBlock`? In my opinion, we just add some fields at the index header. Shall we need to introduce a new interface here? I think this will introduce more duplicate code", "bodyText": "Can we reuse the OffloadIndexBlock? In my opinion, we just add some fields at the index header. Shall we need to introduce a new interface here? I think this will introduce more duplicate code", "bodyHTML": "<p dir=\"auto\">Can we reuse the <code>OffloadIndexBlock</code>? In my opinion, we just add some fields at the index header. Shall we need to introduce a new interface here? I think this will introduce more duplicate code</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:23:43Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMDI5OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554700298", "bodyText": "+1", "author": "sijie", "createdAt": "2021-01-11T04:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2MDExNQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555060115", "bodyText": "We not only add some fields at the index header but also make the content repeatable, it actually makes every method in the OffloadIndexBlock a bit different from before. If we reuse OffloadIndexBlock, I think the methods of OffloadIndexBlock will be doubled, and we need to use extra checks to make sure users use the right version of a method, I don't think it will make less duplicate code.", "author": "Renkai", "createdAt": "2021-01-11T13:52:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MzI5NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557583295", "bodyText": "okay works for me.", "author": "sijie", "createdAt": "2021-01-14T17:54:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzMzQxMQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560033411", "bodyText": "@Renkai, we are talking about the interface, not the implementation. From the OffloadIndexBlock interface, most of the methods are the same as the StreamingOffloadIndexBlock  right?\nAnother unreasonable place is the index block is format concept, Not only streaming offload can use this format right? If we want a new offloaded that offload based on the time window or data size but not streaming offloaded, this new version IndexBlock also can be used?", "author": "codelipenghui", "createdAt": "2021-01-19T09:30:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\nindex 178e1b5df90..6b0b8f0d425 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n", "chunk": "@@ -22,7 +22,6 @@ import java.io.Closeable;\n import java.io.FilterInputStream;\n import java.io.IOException;\n import java.io.InputStream;\n-import java.util.Map;\n import org.apache.bookkeeper.client.api.LedgerMetadata;\n import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n \n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\nindex 6b0b8f0d425..5952dc672bd 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n", "chunk": "@@ -19,9 +19,7 @@\n package org.apache.bookkeeper.mledger.offload.jcloud;\n \n import java.io.Closeable;\n-import java.io.FilterInputStream;\n import java.io.IOException;\n-import java.io.InputStream;\n import org.apache.bookkeeper.client.api.LedgerMetadata;\n import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n \n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2.java\nsimilarity index 97%\nrename from tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\nrename to tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2.java\nindex 5952dc672bd..793d97494d7 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2.java\n", "chunk": "@@ -27,7 +27,7 @@ import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n  * The Index block abstraction used for offload a ledger to long term storage.\n  */\n @Unstable\n-public interface StreamingOffloadIndexBlock extends Closeable {\n+public interface OffloadIndexBlockV2 extends Closeable {\n \n     /**\n      * Get the content of the index block as InputStream.\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530713", "body": "Please consider reuse the `OffloadIndexBlockBuilder`", "bodyText": "Please consider reuse the OffloadIndexBlockBuilder", "bodyHTML": "<p dir=\"auto\">Please consider reuse the <code>OffloadIndexBlockBuilder</code></p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:24:11Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.StreamingOffloadIndexBlockBuilderImpl;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2MTE4OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555061189", "bodyText": "Reuse builder is OK to me, I will reuse the builder after we decide on the design of OffloadIndexBlock and StreamingOffloadIndexBlock", "author": "Renkai", "createdAt": "2021-01-11T13:53:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTU2NDA4NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555564085", "bodyText": "OffloadIndexBlockBuilder and StreamingOffloadIndexBlockBuilder now are using the same implementation\npublic class OffloadIndexBlockBuilderImpl implements OffloadIndexBlockBuilder, StreamingOffloadIndexBlockBuilder", "author": "Renkai", "createdAt": "2021-01-12T07:34:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\nindex c6da7ec02b1..df49473ee75 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\n", "chunk": "@@ -20,10 +20,10 @@ package org.apache.bookkeeper.mledger.offload.jcloud;\n \n import java.io.IOException;\n import java.io.InputStream;\n-import org.apache.bookkeeper.client.api.LedgerMetadata;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n-import org.apache.bookkeeper.mledger.offload.jcloud.impl.StreamingOffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n \n /**\n  * Interface for builder of index block used for offload a ledger to long term storage.\n", "next_change": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nsimilarity index 77%\nrename from tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\nrename to tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nindex df49473ee75..83dbff5ca22 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\n", "chunk": "@@ -22,7 +22,7 @@ import java.io.IOException;\n import java.io.InputStream;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n-import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockV2BuilderImpl;\n import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n \n /**\n", "next_change": null}, {"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nsimilarity index 77%\nrename from tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\nrename to tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nindex df49473ee75..83dbff5ca22 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\n", "chunk": "@@ -30,7 +30,7 @@ import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.Ledge\n  */\n @Unstable\n @LimitedPrivate\n-public interface StreamingOffloadIndexBlockBuilder {\n+public interface OffloadIndexBlockV2Builder {\n \n     /**\n      * Build index block with the passed in ledger metadata.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDg1Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530857", "body": "Why change it to getFirstEntryId? The index always point to one entryId right?", "bodyText": "Why change it to getFirstEntryId? The index always point to one entryId right?", "bodyHTML": "<p dir=\"auto\">Why change it to getFirstEntryId? The index always point to one entryId right?</p>", "author": "codelipenghui", "createdAt": "2021-01-10T08:25:23Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java", "diffHunk": "@@ -33,7 +33,7 @@\n     /**\n      * Get the entryId that this entry contains.\n      */\n-    long getEntryId();\n+    long getFirstEntryId();", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2MjgxMw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555062813", "bodyText": "No, the index point to a block, I think the former name has some misleading.", "author": "Renkai", "createdAt": "2021-01-11T13:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDg1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java\nindex 381c87e1247..e51e9282a4f 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java\n", "chunk": "@@ -33,7 +33,7 @@ public interface OffloadIndexEntry {\n     /**\n      * Get the entryId that this entry contains.\n      */\n-    long getFirstEntryId();\n+    long getEntryId();\n \n     /**\n      * Get the block part id of code storage.\n", "next_change": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java\nindex e51e9282a4f..99d2206ac75 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java\n", "chunk": "@@ -36,7 +36,7 @@ public interface OffloadIndexEntry {\n     long getEntryId();\n \n     /**\n-     * Get the block part id of code storage.\n+     * Get the block part id of tiered storage.\n      */\n     int getPartId();\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTIwNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554695207", "body": "Same question as above. Can we make it an interface?", "bodyText": "Same question as above. Can we make it an interface?", "bodyHTML": "<p dir=\"auto\">Same question as above. Can we make it an interface?</p>", "author": "sijie", "createdAt": "2021-01-11T04:17:02Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA2NDkwNA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555064904", "bodyText": "It's a data object like a POJO or Java Bean, I don't see the benefit to make it an interface.", "author": "Renkai", "createdAt": "2021-01-11T13:59:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTIwNw=="}], "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex a22a507f70d..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -22,60 +22,27 @@ import java.util.Collections;\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n-import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n import org.apache.bookkeeper.mledger.impl.EntryImpl;\n import org.apache.bookkeeper.mledger.impl.PositionImpl;\n import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n-    @ToString\n-    class SegmentInfo {\n-        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n-                           Map<String, String> driverMetadata) {\n-            this.uuid = uuid;\n-            this.beginLedger = beginLedger;\n-            this.beginEntry = beginEntry;\n-            this.driverName = driverName;\n-            this.driverMetadata = driverMetadata;\n-        }\n-\n-\n-        public final UUID uuid;\n-        public final long beginLedger;\n-        public final long beginEntry;\n-        public final String driverName;\n-        volatile private long endLedger;\n-        volatile private long endEntry;\n-        volatile boolean closed = false;\n-        public final Map<String, String> driverMetadata;\n-\n-        public boolean isClosed() {\n-            return closed;\n-        }\n+    interface SegmentInfo {\n+        boolean isClosed();\n \n-        public void closeSegment(long endLedger, long endEntry) {\n-            this.endLedger = endLedger;\n-            this.endEntry = endEntry;\n-            this.closed = true;\n-        }\n-\n-        public OffloadResult result() {\n-            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n-        }\n+        OffloadResult result();\n     }\n \n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "3f59f16a32888538a15ee9ee6189372f556f795f", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..facff2cb3c0 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -37,12 +35,6 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n-    interface SegmentInfo {\n-        boolean isClosed();\n-\n-        OffloadResult result();\n-    }\n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex facff2cb3c0..8c81499c528 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -35,6 +36,7 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554697575", "body": "Can you explain why do we need this method? Also, add a comment to this method?", "bodyText": "Can you explain why do we need this method? Also, add a comment to this method?", "bodyHTML": "<p dir=\"auto\">Can you explain why do we need this method? Also, add a comment to this method?</p>", "author": "sijie", "createdAt": "2021-01-11T04:20:35Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5OTA5Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554699093", "bodyText": "I would like to see if we can avoid adding LedgerMetadata here. Because LedgerMetadata is a specific interface for bookkeeper. We should avoid binding the metadata format to bookkeeper's ledger metadata. This would simplify tiered storage integration.", "author": "sijie", "createdAt": "2021-01-11T04:22:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDgxMzE2MA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554813160", "bodyText": "We use LedgerMetadata because we need to use tiered storage to implement a org.apache.bookkeeper.client.api.ReadHandle, which is also a specific interface for bookkeeper, I think it's not avoidable.", "author": "Renkai", "createdAt": "2021-01-11T06:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA3MzE4Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555073182", "bodyText": "Can you explain why do we need this method? Also, add a comment to this method?\n\nFormer offloader get a ReadHandle from ManagedLedger, and get LedgerMetadata from ReadHandle, our new offloader does not hold any ReadHandle but it still needs LedgerMetadata to make the block index", "author": "Renkai", "createdAt": "2021-01-11T14:12:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA3NTk4Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555075983", "bodyText": "Actually, I want to name this method to getLedgerMetadata, but a method with this name already exists \n  \n    \n      pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n    \n    \n         Line 1685\n      in\n      138390c\n    \n    \n    \n    \n\n        \n          \n           public CompletableFuture<String> getLedgerMetadata(long ledgerId) { \n        \n    \n  \n\n\nMaybe it's better to name the existing method getLedgerMetadataStr", "author": "Renkai", "createdAt": "2021-01-11T14:16:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex f69c4c38b08..dbb2147c31a 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -594,5 +595,9 @@ public interface ManagedLedger {\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n \n-    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException;\n }\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex dbb2147c31a..6804d75b2e7 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -599,5 +599,5 @@ public interface ManagedLedger {\n      * Get basic ledger summary after the ledger is closed.\n      * will got exception if corresponding ledger was not closed when the method called.\n      */\n-    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException;\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);\n }\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex 6804d75b2e7..e1b1c7953f8 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -599,5 +599,5 @@ public interface ManagedLedger {\n      * Get basic ledger summary after the ledger is closed.\n      * will got exception if corresponding ledger was not closed when the method called.\n      */\n-    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);\n+    CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId);\n }\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex e1b1c7953f8..a2e0ba00b59 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -596,8 +596,8 @@ public interface ManagedLedger {\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n \n     /**\n-     * Get basic ledger summary after the ledger is closed.\n-     * will got exception if corresponding ledger was not closed when the method called.\n+     * Get basic ledger summary.\n+     * will got null if corresponding ledger not exists.\n      */\n     CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId);\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554702038", "body": "Can you explain why do you add a \"Mock\" method in the actual implementation?", "bodyText": "Can you explain why do you add a \"Mock\" method in the actual implementation?", "bodyHTML": "<p dir=\"auto\">Can you explain why do you add a \"Mock\" method in the actual implementation?</p>", "author": "sijie", "createdAt": "2021-01-11T04:26:56Z", "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "diffHunk": "@@ -82,7 +71,11 @@ protected static MockZooKeeper createMockZooKeeper() throws Exception {\n                 CreateMode.PERSISTENT);\n         return zk;\n     }\n-    \n+\n+    protected static MockManagedLedger createMockManagedLedger() {", "originalCommit": "527b319ebe57b41bd087e757637a2bf787d22584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA3OTM3Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555079372", "bodyText": "BlobStoreManagedLedgerOffloaderBase is a class for test, not implementation. Its name doesn't like a test class, but you can see its directory src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java is a test directory.", "author": "Renkai", "createdAt": "2021-01-11T14:21:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4ODU5Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557588592", "bodyText": "Make sense now.", "author": "sijie", "createdAt": "2021-01-14T18:02:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxOTAzNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555219036", "body": "Does one `StreamingOffloadIndexBlock` will contain multiple ledgers indexes?", "bodyText": "Does one StreamingOffloadIndexBlock will contain multiple ledgers indexes?", "bodyHTML": "<p dir=\"auto\">Does one <code>StreamingOffloadIndexBlock</code> will contain multiple ledgers indexes?</p>", "author": "gaoran10", "createdAt": "2021-01-11T17:30:37Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     */\n+    Map<Long, LedgerMetadata> getLedgerMetadata();", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMzE5Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555433193", "bodyText": "Yes", "author": "Renkai", "createdAt": "2021-01-12T00:42:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxOTAzNg=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\nindex 178e1b5df90..6b0b8f0d425 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n", "chunk": "@@ -58,8 +57,9 @@ public interface StreamingOffloadIndexBlock extends Closeable {\n \n     /**\n      * Get LedgerMetadata.\n+     * @return\n      */\n-    Map<Long, LedgerMetadata> getLedgerMetadata();\n+    LedgerMetadata getLedgerMetadata(long ledgerId);\n \n     /**\n      * Get the total size of the data object.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMDY4OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555100688", "body": "typo: uid", "bodyText": "typo: uid", "bodyHTML": "<p dir=\"auto\">typo: uid</p>", "author": "eolivelli", "createdAt": "2021-01-11T14:51:58Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex c2fc204bb16..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -189,7 +166,7 @@ public interface LedgerOffloader {\n      *\n      * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n      * ledgers has been persisted to the\n-     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     * longterm storage, so it is safe to delete the original copy in bookkeeper.\n      *\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..26ef810c91e 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -171,7 +150,7 @@ public interface LedgerOffloader {\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n      * This uid will be stored in the managed ledger metadata before attempting the\n-     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * call to streamingOffload(). If a subsequent or concurrent call to streamingOffload() finds\n      * a uid in the metadata, it will attempt to cleanup this attempt with a call\n      * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n      * the managed ledger will update its metadata again, to record the completion,\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555101311", "body": "what happens if I call this method for the same ManagedLedger more times, with overlapping intervals ?", "bodyText": "what happens if I call this method for the same ManagedLedger more times, with overlapping intervals ?", "bodyHTML": "<p dir=\"auto\">what happens if I call this method for the same ManagedLedger more times, with overlapping intervals ?</p>", "author": "eolivelli", "createdAt": "2021-01-11T14:52:54Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIxNTA3NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556215074", "bodyText": "what happens if I call this method for the same ManagedLedger more times, with overlapping intervals?\n\nYes, the caller should prevent this happens.", "author": "Renkai", "createdAt": "2021-01-13T02:02:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMzNzEzNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556337136", "bodyText": "if the caller invokes this method with overlapping intervals, will the system be in a corrupted state ?\nis there any way to detect the problem and fail ?", "author": "eolivelli", "createdAt": "2021-01-13T08:20:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM2ODk4NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556368985", "bodyText": "ManagedLedger will check the begin entry and endEntryId in https://github.com/apache/pulsar/wiki/PIP-76:-Streaming-Offload#metadata-changes to avoid corruption, it's not included in this PR yet because it will make the PR too big and include too many details. This PR focused on the interface change of Offloader, I will submit another PR with corruption detection you mentioned.", "author": "Renkai", "createdAt": "2021-01-13T09:14:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM4NzM4Ng==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556387386", "bodyText": "works for me, thanks", "author": "eolivelli", "createdAt": "2021-01-13T09:42:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex c2fc204bb16..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -203,7 +203,7 @@ public interface LedgerOffloader {\n      *\n      * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n      */\n-    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uid, long beginLedger,\n                                                               long beginEntry,\n                                                               Map<String, String> driverMetadata) {\n         throw new UnsupportedOperationException();\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMjIzNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555102236", "body": "the same here", "bodyText": "the same here", "bodyHTML": "<p dir=\"auto\">the same here</p>", "author": "eolivelli", "createdAt": "2021-01-11T14:54:09Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +239,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();\n+    }\n+\n+    default CompletableFuture<Void> deleteOffloaded(UUID uid,\n+                                                    Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedOperationException();", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex c2fc204bb16..ba43aa8b5a9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -241,7 +241,7 @@ public interface LedgerOffloader {\n \n     default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n                                                         Map<String, String> offloadDriverMetadata) {\n-        throw new UnsupportedClassVersionError();\n+        throw new UnsupportedOperationException();\n     }\n \n     default CompletableFuture<Void> deleteOffloaded(UUID uid,\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555104508", "body": "should not we perform this operation only after the end of the loop above ?\r\nwhat happens if the streamingOffloadLoop does not complete in time ?", "bodyText": "should not we perform this operation only after the end of the loop above ?\nwhat happens if the streamingOffloadLoop does not complete in time ?", "bodyHTML": "<p dir=\"auto\">should not we perform this operation only after the end of the loop above ?<br>\nwhat happens if the streamingOffloadLoop does not complete in time ?</p>", "author": "eolivelli", "createdAt": "2021-01-11T14:57:11Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIxNzE2OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556217168", "bodyText": "should not we perform this operation only after the end of the loop above ?\nwhat happens if the streamingOffloadLoop does not complete in time ?\n\nWhat's 'this operation' do you mean here?", "author": "Renkai", "createdAt": "2021-01-13T02:09:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMzNjEyNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556336127", "bodyText": "closeSegment", "author": "eolivelli", "createdAt": "2021-01-13T08:18:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM2NTMwNA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556365304", "bodyText": "The segment will be closed when the time limit reached, and the streamingOffloadLoop will aware of it and stop looping.", "author": "Renkai", "createdAt": "2021-01-13T09:08:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjM4NzMzMw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r556387333", "bodyText": "ok, thanks for your clarification", "author": "eolivelli", "createdAt": "2021-01-13T09:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex 80ad2518509..115dc02da38 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -288,7 +293,7 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             log.info(\"start offloading segment: {}\", segmentInfo);\n             streamingOffloadLoop(1, 0);\n         });\n-        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n \n         return CompletableFuture.completedFuture(new OffloadHandle() {\n             @Override\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex 115dc02da38..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -302,20 +304,39 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             }\n \n             @Override\n-            public PositionImpl lastOffered() {\n+            public CompletableFuture<Boolean> canOfferAsync(long size) {\n+                return CompletableFuture.completedFuture(canOffer(size));\n+            }\n+\n+            @Override\n+            public Position lastOffered() {\n                 return BlobStoreManagedLedgerOffloader.this.lastOffered();\n             }\n \n             @Override\n-            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                    OffloadNotConsecutiveException {\n+            public CompletableFuture<Position> lastOfferedAsync() {\n+                return CompletableFuture.completedFuture(lastOffered());\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n                 return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n             }\n \n+            @Override\n+            public CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry) {\n+                return CompletableFuture.completedFuture(offerEntry(entry));\n+            }\n+\n             @Override\n             public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n                 return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n             }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n         });\n     }\n \n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -343,19 +332,17 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n     private void streamingOffloadLoop(int partId, int dataObjectLength) {\n         log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            buildIndexAndCompleteResult(dataObjectLength);\n             offloadResult.complete(segmentInfo.result());\n             return;\n         }\n \n-        while (offloadBuffer.isEmpty()) {\n-            if (segmentInfo.isClosed()) {\n-                offloadResult.complete(segmentInfo.result());\n-            } else {\n-                scheduler.chooseThread(segmentInfo)\n-                        .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n-                return;\n-            }\n+        if (offloadBuffer.isEmpty()) {\n+            scheduler.chooseThread(segmentInfo)\n+                    .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n+            return;\n         }\n+\n         final Entry peek = offloadBuffer.peek();\n         //initialize payload when there is at least one entry\n         final long blockLedgerId = peek.getLedgerId();\n", "next_change": {"commit": "8f4510a2c868dc905d41081a8119be14adb686bb", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex c67507bd581..d788eec6d51 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -338,8 +338,9 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         }\n \n         if (offloadBuffer.isEmpty()) {\n+            log.debug(\"segment not closed but buffer is empty {} {}\", partId, dataObjectLength);\n             scheduler.chooseThread(segmentInfo)\n-                    .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n+                    .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 10000, TimeUnit.MILLISECONDS);\n             return;\n         }\n \n", "next_change": {"commit": "ce767aef96654be789c265600ad1f3a1065a08fe", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex d788eec6d51..a1f8e4beba5 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -340,7 +347,7 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         if (offloadBuffer.isEmpty()) {\n             log.debug(\"segment not closed but buffer is empty {} {}\", partId, dataObjectLength);\n             scheduler.chooseThread(segmentInfo)\n-                    .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 10000, TimeUnit.MILLISECONDS);\n+                    .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n             return;\n         }\n \n", "next_change": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex a1f8e4beba5..3b5ae5ee5a7 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -341,35 +344,49 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n             buildIndexAndCompleteResult(dataObjectLength);\n             offloadResult.complete(segmentInfo.result());\n-            return;\n-        }\n-\n-        if (offloadBuffer.isEmpty()) {\n-            log.debug(\"segment not closed but buffer is empty {} {}\", partId, dataObjectLength);\n+        } else if ((segmentInfo.isClosed() && !offloadBuffer.isEmpty())\n+                // last time to build and upload block\n+                || bufferLength.get() >= streamingBlockSize\n+            // buffer size full, build and upload block\n+        ) {\n+            List<Entry> entries = new LinkedList<>();\n+            int blockEntrySize = 0;\n+            final Entry firstEntry = offloadBuffer.poll();\n+            entries.add(firstEntry);\n+            long blockLedgerId = firstEntry.getLedgerId();\n+            long blockEntryId = firstEntry.getEntryId();\n+\n+            while (!offloadBuffer.isEmpty() && offloadBuffer.peek().getLedgerId() == blockLedgerId\n+                    && blockEntrySize <= streamingBlockSize) {\n+                final Entry entryInBlock = offloadBuffer.poll();\n+                final int entrySize = entryInBlock.getLength();\n+                bufferLength.addAndGet(-entrySize);\n+                blockEntrySize += entrySize;\n+                entries.add(entryInBlock);\n+            }\n+            final int blockSize = BufferedOffloadStream\n+                    .calculateBlockSize(streamingBlockSize, entries.size(), blockEntrySize);\n+            buildBlockAndUpload(blockSize, entries, blockLedgerId, blockEntryId, partId);\n+            streamingOffloadLoop(partId + 1, dataObjectLength + blockSize);\n+        } else {\n+            log.debug(\"not enough data, delay schedule for part: {} length: {}\", partId, dataObjectLength);\n             scheduler.chooseThread(segmentInfo)\n-                    .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n-            return;\n-        }\n-\n-        final Entry peek = offloadBuffer.peek();\n-        //initialize payload when there is at least one entry\n-        final long blockLedgerId = peek.getLedgerId();\n-        final long blockEntryId = peek.getEntryId();\n-        int tempBlockSize = streamingBlockSize;\n-        while (tempBlockSize <= peek\n-                .getLength() + StreamingDataBlockHeaderImpl.HEADER_MAX_SIZE + BufferedOffloadStream.ENTRY_HEADER_SIZE) {\n-            tempBlockSize = tempBlockSize + tempBlockSize;\n+                    .schedule(() -> {\n+                        streamingOffloadLoop(partId, dataObjectLength);\n+                    }, 100, TimeUnit.MILLISECONDS);\n         }\n+    }\n \n-        try (final BufferedOffloadStream payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer,\n-                segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength)) {\n-            log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n+    private void buildBlockAndUpload(int blockSize, List<Entry> entries, long blockLedgerId, long beginEntryId,\n+                                     int partId) {\n+        try (final BufferedOffloadStream payloadStream = new BufferedOffloadStream(blockSize, entries,\n+                blockLedgerId, beginEntryId)) {\n+            log.debug(\"begin upload payload: {} {}\", blockLedgerId, beginEntryId);\n             Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n             partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n             streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n             streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-            streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n+            streamingIndexBuilder.addBlock(blockLedgerId, beginEntryId, partId, blockSize);\n             final MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n             final MLDataFormats.ManagedLedgerInfo.LedgerInfo.Builder ledgerInfoBuilder = MLDataFormats.ManagedLedgerInfo.LedgerInfo\n                     .newBuilder();\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDY4Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555104683", "body": "we can provide more information here", "bodyText": "we can provide more information here", "bodyHTML": "<p dir=\"auto\">we can provide more information here</p>", "author": "eolivelli", "createdAt": "2021-01-11T14:57:26Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MzU3Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560043577", "bodyText": "+1", "author": "codelipenghui", "createdAt": "2021-01-19T09:45:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDY4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex 80ad2518509..115dc02da38 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -340,9 +345,9 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n                 blockLedgerId, blockEntryId, bufferLength);\n         try {\n-            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n             streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-        } catch (InterruptedException | ExecutionException e) {\n+        } catch (InterruptedException | ExecutionException | ManagedLedgerException e) {\n             offloadResult.completeExceptionally(e);\n             return;\n         }\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex 115dc02da38..b248247171e 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -347,7 +351,7 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         try {\n             streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n             streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-        } catch (InterruptedException | ExecutionException | ManagedLedgerException e) {\n+        } catch (InterruptedException | ExecutionException e) {\n             offloadResult.completeExceptionally(e);\n             return;\n         }\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -329,48 +346,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             offloadResult.complete(segmentInfo.result());\n             return;\n         }\n-        final BufferedOffloadStream payloadStream;\n \n         while (offloadBuffer.isEmpty()) {\n             if (segmentInfo.isClosed()) {\n                 offloadResult.complete(segmentInfo.result());\n             } else {\n-                try {\n-                    Thread.sleep(100);\n-                } catch (InterruptedException e) {\n-                    e.printStackTrace();\n-                }\n+                scheduler.chooseThread(segmentInfo)\n+                        .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n+                return;\n             }\n         }\n         final Entry peek = offloadBuffer.peek();\n         //initialize payload when there is at least one entry\n         final long blockLedgerId = peek.getLedgerId();\n         final long blockEntryId = peek.getEntryId();\n-        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        try {\n-            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n-            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-        } catch (InterruptedException | ExecutionException e) {\n-            offloadResult.completeExceptionally(e);\n-            return;\n+        int tempBlockSize = streamingBlockSize;\n+        while (tempBlockSize <= peek\n+                .getLength() + StreamingDataBlockHeaderImpl.HEADER_MAX_SIZE + BufferedOffloadStream.ENTRY_HEADER_SIZE) {\n+            tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n-        log.debug(\"begin upload payload\");\n+\n+        final BufferedOffloadStream payloadStream;\n+        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n         Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n         partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n         streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n \n         log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n                 config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty\");\n+            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n             try {\n                 blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n                 final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n                 final IndexInputStream indexStream = index.toStream();\n                 final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n+                if (ledgerInfo != null) {\n+                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+                }\n+                if (ledgerInfoBuilder.getEntries() == 0) {\n+                    //ledger unclosed, use last offered\n+                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n+                }\n+                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n                 DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n                 final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -366,39 +353,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n \n-        final BufferedOffloadStream payloadStream;\n-        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n-        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n-        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n-        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n-\n-        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n-                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        try (final BufferedOffloadStream payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer,\n+                segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength)) {\n+            log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n+            Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+            partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+            streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+            streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo.Builder ledgerInfoBuilder = MLDataFormats.ManagedLedgerInfo.LedgerInfo\n+                    .newBuilder();\n+            if (ledgerInfo != null) {\n+                ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+            }\n+            if (ledgerInfoBuilder.getEntries() == 0) {\n+                //ledger unclosed, use last entry id of the block\n+                ledgerInfoBuilder.setEntries(payloadStream.getEndEntryId() + 1);\n+            }\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+            log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                    config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        } catch (Exception e) {\n+            blobStore.abortMultipartUpload(streamingMpu);\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n-            try {\n-                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n-                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n-                final IndexInputStream indexStream = index.toStream();\n-                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n-                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n-                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n-                if (ledgerInfo != null) {\n-                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n-                }\n-                if (ledgerInfoBuilder.getEntries() == 0) {\n-                    //ledger unclosed, use last offered\n-                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n-                }\n-                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n-                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+            buildIndexAndCompleteResult(dataObjectLength + tempBlockSize);\n+        } else {\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n+        }\n+    }\n \n-                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n-                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+    private void buildIndexAndCompleteResult(long dataObjectLength) {\n+        try {\n+            blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+            streamingIndexBuilder.withDataObjectLength(dataObjectLength);\n+            final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+            final IndexInputStream indexStream = index.toStream();\n+            final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n+            DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+            try (final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream)) {\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n                 indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n                 final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNTQzOQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555105439", "body": "nit: static ?", "bodyText": "nit: static ?", "bodyHTML": "<p dir=\"auto\">nit: static ?</p>", "author": "eolivelli", "createdAt": "2021-01-11T14:58:28Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.build();\n+                final StreamingOffloadIndexBlock.IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+        } else {\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+            OffloadNotConsecutiveException {\n+        if (segmentInfo.isClosed()) {\n+            throw new OffloadSegmentClosedException(\"Segment already closed \" + segmentInfo);\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition, entry.getPosition())) {\n+                throw new OffloadNotConsecutiveException(\n+                        Strings.lenientFormat(\"position %s and %s are not consecutive\", lastOfferedPosition,\n+                                entry.getPosition()));\n+            }\n+            entry.retain();\n+            offloadBuffer.add(entry);\n+            bufferLength.getAndAdd(entry.getLength());\n+            segmentLength.getAndAdd(entry.getLength());\n+            lastOfferedPosition = entry.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength) {\n+                closeSegment();\n+            }\n+            return true;\n+        }\n+    }\n+\n+    private synchronized void closeSegment() {\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+    }\n+\n+    private boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {", "originalCommit": "8c48c61b4d825783a9743fd56f4e0bab65805e88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex 80ad2518509..115dc02da38 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -412,7 +421,7 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n     }\n \n-    private boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n         if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n                 && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n             return true;\n", "next_change": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex 115dc02da38..b248247171e 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -393,32 +397,41 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return this.offloadResult;\n     }\n \n-    private synchronized boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-            OffloadNotConsecutiveException {\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n         if (segmentInfo.isClosed()) {\n-            throw new OffloadSegmentClosedException(\"Segment already closed \" + segmentInfo);\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n         } else {\n-            if (!naiveCheckConsecutive(lastOfferedPosition, entry.getPosition())) {\n-                throw new OffloadNotConsecutiveException(\n-                        Strings.lenientFormat(\"position %s and %s are not consecutive\", lastOfferedPosition,\n-                                entry.getPosition()));\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n             }\n-            entry.retain();\n-            offloadBuffer.add(entry);\n-            bufferLength.getAndAdd(entry.getLength());\n-            segmentLength.getAndAdd(entry.getLength());\n-            lastOfferedPosition = entry.getPosition();\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n             if (segmentLength.get() >= maxSegmentLength\n                     && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n                 closeSegment();\n             }\n-            return true;\n+            return OfferEntryResult.SUCCESS;\n         }\n     }\n \n-    private synchronized void closeSegment() {\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n         log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n         this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n     }\n \n     private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -434,18 +458,6 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return result;\n     }\n \n-    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n-        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n-                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n-            return true;\n-        } else if (offeringPosition.getEntryId() == 0) {\n-            return true;\n-        } else {\n-            // lastOfferedPosition not initialized\n-            return lastOfferedPosition.equals(PositionImpl.latest);\n-        }\n-    }\n-\n     private PositionImpl lastOffered() {\n         return lastOfferedPosition;\n     }\n", "next_change": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..3b5ae5ee5a7 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -462,17 +477,6 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return lastOfferedPosition;\n     }\n \n-    private boolean canOffer(long size) {\n-        if (segmentInfo.isClosed()) {\n-            return false;\n-        } else if (maxBufferLength >= bufferLength.get() + size) {\n-            return true;\n-        } else {\n-            //if single message size larger than full buffer size, then ok to offer\n-            return size > maxBufferLength && offloadBuffer.isEmpty();\n-        }\n-    }\n-\n     /**\n      * Attempts to create a BlobStoreLocation from the values in the offloadDriverMetadata,\n      * however, if no values are available, it defaults to the currently configured\n", "next_change": null}]}}]}}]}}]}}, {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "url": "https://github.com/apache/pulsar/commit/d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "message": "implement streaming offloader\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-13T09:01:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3NzYyNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557577627", "body": "Can you move the implementation outside of an interface?", "bodyText": "Can you move the implementation outside of an interface?", "bodyHTML": "<p dir=\"auto\">Can you move the implementation outside of an interface?</p>", "author": "sijie", "createdAt": "2021-01-14T17:44:51Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -46,43 +43,6 @@ public interface LedgerOffloader {\n         OffloadResult result();\n     }\n \n-    @ToString\n-    class SegmentInfoImpl implements SegmentInfo {\n-        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n-                               Map<String, String> driverMetadata) {\n-            this.uuid = uuid;\n-            this.beginLedger = beginLedger;\n-            this.beginEntry = beginEntry;\n-            this.driverName = driverName;\n-            this.driverMetadata = driverMetadata;\n-        }\n-\n-\n-        public final UUID uuid;\n-        public final long beginLedger;\n-        public final long beginEntry;\n-        public final String driverName;\n-        volatile private long endLedger;\n-        volatile private long endEntry;\n-        volatile boolean closed = false;\n-        public final Map<String, String> driverMetadata;\n-\n-        public boolean isClosed() {\n-            return closed;\n-        }\n-\n-        public void closeSegment(long endLedger, long endEntry) {\n-            this.endLedger = endLedger;\n-            this.endEntry = endEntry;\n-            this.closed = true;\n-        }\n-\n-        public OffloadResult result() {\n-            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n-        }\n-    }\n-\n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "3f59f16a32888538a15ee9ee6189372f556f795f", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..facff2cb3c0 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -37,12 +35,6 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n-    interface SegmentInfo {\n-        boolean isClosed();\n-\n-        OffloadResult result();\n-    }\n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex facff2cb3c0..8c81499c528 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -35,6 +36,7 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODA3OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557578079", "body": "What does \"create one per second\" mean?", "bodyText": "What does \"create one per second\" mean?", "bodyHTML": "<p dir=\"auto\">What does \"create one per second\" mean?</p>", "author": "sijie", "createdAt": "2021-01-14T17:45:34Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkzNjM5Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557936392", "bodyText": "'per segment' typo fixed", "author": "Renkai", "createdAt": "2021-01-15T07:18:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODA3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -99,9 +59,15 @@ public interface LedgerOffloader {\n \n     /**\n      * Used to store driver info, buffer entries, mark progress, etc.\n-     * Create one per second.\n+     * Create one per segment.\n      */\n     interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n \n         /**\n          * return true when both buffer have enough size and ledger/entry id is next to the current one.\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -76,24 +74,18 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n         /**\n          * The caller should manually release entry no matter what the offer result is.\n          */\n         OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557578717", "body": "It is a bit strange to implement an async method over a sync method. We usually implement the other way around.", "bodyText": "It is a bit strange to implement an async method over a sync method. We usually implement the other way around.", "bodyHTML": "<p dir=\"auto\">It is a bit strange to implement an async method over a sync method. We usually implement the other way around.</p>", "author": "sijie", "createdAt": "2021-01-14T17:46:32Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkzOTYxNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557939617", "bodyText": "Our current sync method implementation is quite efficient (just compare two existing number and return), though a bit strange, I still don't think we should sacrifice the performance to make the implementation conform common practice.", "author": "Renkai", "createdAt": "2021-01-15T07:22:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MDE3MA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559990170", "bodyText": "You can't assume the canOffer always \"efficient\", it depends on the implementations. From the interface perspective, this is not the right way.\nuse default for the interface method, this means it's not required for the implementation to implement this method, so an implementation can only implement the sync method. If the sync method need some time-consuming operations, This destroys the original intention of the interface", "author": "codelipenghui", "createdAt": "2021-01-19T08:24:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -110,25 +74,30 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n-        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException;\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());\n+        }\n     }\n \n     // TODO: improve the user metadata in subsequent changes\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3OTIzOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557579238", "body": "```suggestion\r\n     * longterm storage, so it is safe to delete the original copy in bookkeeper.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n          \n          \n            \n                 * longterm storage, so it is safe to delete the original copy in bookkeeper.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"x x-first x-last\">loadterm</span> storage, so it is safe to delete the original copy in bookkeeper.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"x x-first x-last\">longterm</span> storage, so it is safe to delete the original copy in bookkeeper.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "sijie", "createdAt": "2021-01-14T17:47:24Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -189,7 +166,7 @@ public interface LedgerOffloader {\n      *\n      * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n      * ledgers has been persisted to the\n-     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     * longterm storage, so it is safe to delete the original copy in bookkeeper.\n      *\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..26ef810c91e 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -171,7 +150,7 @@ public interface LedgerOffloader {\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n      * This uid will be stored in the managed ledger metadata before attempting the\n-     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * call to streamingOffload(). If a subsequent or concurrent call to streamingOffload() finds\n      * a uid in the metadata, it will attempt to cleanup this attempt with a call\n      * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n      * the managed ledger will update its metadata again, to record the completion,\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MTU2MA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557581560", "body": "If this interface is designed to be an async method, the exception should be returned from the `CompletableFuture`. The interface seems to be mix async semantic with sync semantic together.", "bodyText": "If this interface is designed to be an async method, the exception should be returned from the CompletableFuture. The interface seems to be mix async semantic with sync semantic together.", "bodyHTML": "<p dir=\"auto\">If this interface is designed to be an async method, the exception should be returned from the <code>CompletableFuture</code>. The interface seems to be mix async semantic with sync semantic together.</p>", "author": "sijie", "createdAt": "2021-01-14T17:51:07Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException;", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex dbb2147c31a..6804d75b2e7 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -599,5 +599,5 @@ public interface ManagedLedger {\n      * Get basic ledger summary after the ledger is closed.\n      * will got exception if corresponding ledger was not closed when the method called.\n      */\n-    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException;\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);\n }\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex 6804d75b2e7..e1b1c7953f8 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -599,5 +599,5 @@ public interface ManagedLedger {\n      * Get basic ledger summary after the ledger is closed.\n      * will got exception if corresponding ledger was not closed when the method called.\n      */\n-    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);\n+    CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId);\n }\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex e1b1c7953f8..a2e0ba00b59 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -596,8 +596,8 @@ public interface ManagedLedger {\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n \n     /**\n-     * Get basic ledger summary after the ledger is closed.\n-     * will got exception if corresponding ledger was not closed when the method called.\n+     * Get basic ledger summary.\n+     * will got null if corresponding ledger not exists.\n      */\n     CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId);\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MjgwMQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557582801", "body": "What happens if the ledger is closed with zero entries?", "bodyText": "What happens if the ledger is closed with zero entries?", "bodyHTML": "<p dir=\"auto\">What happens if the ledger is closed with zero entries?</p>", "author": "sijie", "createdAt": "2021-01-14T17:53:20Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,20 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException {\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            throw new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+        } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkxNTU2Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557915567", "bodyText": "What happens if the ledger is closed with zero entries?\n\nIt will be deleted from metadata, see \n  \n    \n      pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n    \n    \n        Lines 1535 to 1547\n      in\n      d3a6a8c\n    \n    \n    \n    \n\n        \n          \n           if (entriesInLedger > 0) { \n        \n\n        \n          \n               LedgerInfo info = LedgerInfo.newBuilder().setLedgerId(lh.getId()).setEntries(entriesInLedger) \n        \n\n        \n          \n                       .setSize(lh.getLength()).setTimestamp(clock.millis()).build(); \n        \n\n        \n          \n               ledgers.put(lh.getId(), info); \n        \n\n        \n          \n           } else { \n        \n\n        \n          \n               // The last ledger was empty, so we can discard it \n        \n\n        \n          \n               ledgers.remove(lh.getId()); \n        \n\n        \n          \n               mbean.startDataLedgerDeleteOp(); \n        \n\n        \n          \n               bookKeeper.asyncDeleteLedger(lh.getId(), (rc, ctx) -> { \n        \n\n        \n          \n                   mbean.endDataLedgerDeleteOp(); \n        \n\n        \n          \n                   log.info(\"[{}] Delete complete for empty ledger {}. rc={}\", name, lh.getId(), rc); \n        \n\n        \n          \n               }, null); \n        \n\n        \n          \n           }", "author": "Renkai", "createdAt": "2021-01-15T06:53:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MjgwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\nindex 065c571cf85..23e52c47b18 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n", "chunk": "@@ -1687,17 +1687,20 @@ public class ManagedLedgerImpl implements ManagedLedger, CreateCallback {\n     }\n \n     @Override\n-    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException {\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n         final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n         if (ledgerInfo == null) {\n-            throw new ManagedLedgerException(\n+            final ManagedLedgerException exception = new ManagedLedgerException(\n                     Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+            result.completeExceptionally(exception);\n         } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {\n-            throw new ManagedLedgerException(\n+            final ManagedLedgerException exception = new ManagedLedgerException(\n                     Strings.lenientFormat(\"ledger with id %s has not closed yet\", ledgerId));\n+            result.completeExceptionally(exception);\n         }\n-\n-        return CompletableFuture.completedFuture(ledgerInfo);\n+        result.complete(ledgerInfo);\n+        return result;\n     }\n \n     CompletableFuture<ReadHandle> getLedgerHandle(long ledgerId) {\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\nindex 23e52c47b18..94478a19529 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n", "chunk": "@@ -1687,18 +1686,9 @@ public class ManagedLedgerImpl implements ManagedLedger, CreateCallback {\n     }\n \n     @Override\n-    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) {\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n         CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n         final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n-        if (ledgerInfo == null) {\n-            final ManagedLedgerException exception = new ManagedLedgerException(\n-                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n-            result.completeExceptionally(exception);\n-        } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {\n-            final ManagedLedgerException exception = new ManagedLedgerException(\n-                    Strings.lenientFormat(\"ledger with id %s has not closed yet\", ledgerId));\n-            result.completeExceptionally(exception);\n-        }\n         result.complete(ledgerInfo);\n         return result;\n     }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4Mzk4Ng==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557583986", "body": "Can we move implementation out of this interface?", "bodyText": "Can we move implementation out of this interface?", "bodyHTML": "<p dir=\"auto\">Can we move implementation out of this interface?</p>", "author": "sijie", "createdAt": "2021-01-14T17:55:26Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     * @return\n+     */\n+    LedgerMetadata getLedgerMetadata(long ledgerId);\n+\n+    /**\n+     * Get the total size of the data object.\n+     */\n+    long getDataObjectLength();\n+\n+    /**\n+     * Get the length of the header in the blocks in the data object.\n+     */\n+    long getDataBlockHeaderLength();\n+\n+    /**\n+     * An input stream which knows the size of the stream upfront.\n+     */\n+    class IndexInputStream extends FilterInputStream {", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\nindex 6b0b8f0d425..5952dc672bd 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java\n", "chunk": "@@ -70,24 +68,5 @@ public interface StreamingOffloadIndexBlock extends Closeable {\n      * Get the length of the header in the blocks in the data object.\n      */\n     long getDataBlockHeaderLength();\n-\n-    /**\n-     * An input stream which knows the size of the stream upfront.\n-     */\n-    class IndexInputStream extends FilterInputStream {\n-        final long streamSize;\n-\n-        public IndexInputStream(InputStream in, long streamSize) {\n-            super(in);\n-            this.streamSize = streamSize;\n-        }\n-\n-        /**\n-         * @return the number of bytes in the stream.\n-         */\n-        public long getStreamSize() {\n-            return streamSize;\n-        }\n-    }\n }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557585554", "body": "Put `log.debug` into `if (log.isDebugEnabled()) { ... }`", "bodyText": "Put log.debug into if (log.isDebugEnabled()) { ... }", "bodyHTML": "<p dir=\"auto\">Put <code>log.debug</code> into <code>if (log.isDebugEnabled()) { ... }</code></p>", "author": "sijie", "createdAt": "2021-01-14T17:57:59Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NjQyOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557586428", "bodyText": "Please address all the occurrences.", "author": "sijie", "createdAt": "2021-01-14T17:59:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODAxMDM0NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r558010345", "bodyText": "@sijie I don't think put log.debug into if (log.isDebugEnabled()) { ... } is a good practice today. It was originally designed to reduce string construction cost in log4j1, but today every log framework implemented slf4j provided a lazy formatter to prevent string construction when debug is not enabled. It can not only reduce boilerplate code and avoid check the log level twice.\nif (log.isDebugEnabled()) { ... } should only happened when we have extra computation for debug.\nSee\nhttps://logging.apache.org/log4j/2.x/manual/api.html (Section: Substituting Parameters)\nhttps://logging.apache.org/log4j/log4j-2.3/performance.html", "author": "Renkai", "createdAt": "2021-01-15T08:15:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODAzODQ4OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r558038488", "bodyText": "@Renkai that would be a very long discussion, thanks for bringing it up!\nin my opinion it is better to have a consistent way of using the logger thru all of the codebase.\nif we want to change this pattern please start a new discussion, and so we can start a new set of patches.", "author": "eolivelli", "createdAt": "2021-01-15T08:34:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\nindex 41c59b96add..889923aad43 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n", "chunk": "@@ -125,7 +126,7 @@ public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n         if (firstEntry > lastEntry\n                 || firstEntry < 0\n                 || lastEntry > getLastAddConfirmed()) {\n-            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            promise.completeExceptionally(new IllegalArgumentException());\n             return promise;\n         }\n         executor.submit(() -> {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4ODI0OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557588248", "body": "Can you rename it to `maxOffloadSegmentSizeInBytes`?", "bodyText": "Can you rename it to maxOffloadSegmentSizeInBytes?", "bodyHTML": "<p dir=\"auto\">Can you rename it to <code>maxOffloadSegmentSizeInBytes</code>?</p>", "author": "sijie", "createdAt": "2021-01-14T18:02:07Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,12 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"maxOffloadSegmentRolloverTimeInSeconds\";\n+    public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\nindex 23d8720148b..4c934b74890 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java\n", "chunk": "@@ -67,7 +67,7 @@ public class TieredStorageConfiguration {\n     public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n     public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n     public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n-    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final String MAX_OFFLOAD_SEGMENT_SIZE_IN_BYTES = \"maxOffloadSegmentSizeInBytes\";\n     public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;\n \n     protected static final int MB = 1024 * 1024;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxMzY2NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557713664", "body": "Should this be `info` or `debug`?", "bodyText": "Should this be info or debug?", "bodyHTML": "<p dir=\"auto\">Should this be <code>info</code> or <code>debug</code>?</p>", "author": "sijie", "createdAt": "2021-01-14T21:35:45Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {\n+                long entriesToRead = (groupedReader.lastEntry - groupedReader.firstEntry) + 1;\n+                long nextExpectedId = groupedReader.firstEntry;\n+                try {\n+                    while (entriesToRead > 0) {\n+                        int length = groupedReader.dataStream.readInt();\n+                        if (length < 0) { // hit padding or new block\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        }\n+                        long entryId = groupedReader.dataStream.readLong();\n+\n+                        if (entryId == nextExpectedId) {\n+                            ByteBuf buf = PulsarByteBufAllocator.DEFAULT.buffer(length, length);\n+                            entries.add(LedgerEntryImpl.create(ledgerId, entryId, length, buf));\n+                            int toWrite = length;\n+                            while (toWrite > 0) {\n+                                toWrite -= buf.writeBytes(groupedReader.dataStream, toWrite);\n+                            }\n+                            entriesToRead--;\n+                            nextExpectedId++;\n+                        } else if (entryId > nextExpectedId) {\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        } else if (entryId < nextExpectedId\n+                                && !groupedReader.index.getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                .equals(\n+                                        groupedReader.index.getIndexEntryForEntry(groupedReader.ledgerId, entryId))) {\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        } else if (entryId > groupedReader.lastEntry) {\n+                            log.info(\"Expected to read {}, but read {}, which is greater than last entry {}\",\n+                                    nextExpectedId, entryId, groupedReader.lastEntry);\n+                            throw new BKException.BKUnexpectedConditionException();\n+                        } else {\n+                            val skipped = groupedReader.inputStream.skip(length);\n+                            log.info(\"Skipped {} bytes.\", skipped);", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\nindex 41c59b96add..e0f638e9ee5 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n", "chunk": "@@ -183,7 +183,6 @@ public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n                             throw new BKException.BKUnexpectedConditionException();\n                         } else {\n                             val skipped = groupedReader.inputStream.skip(length);\n-                            log.info(\"Skipped {} bytes.\", skipped);\n                         }\n                     }\n                 } catch (Throwable t) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557715312", "body": "`PositionImpl` is an implementation. Should this be `Position`?", "bodyText": "PositionImpl is an implementation. Should this be Position?", "bodyHTML": "<p dir=\"auto\"><code>PositionImpl</code> is an implementation. Should this be <code>Position</code>?</p>", "author": "sijie", "createdAt": "2021-01-14T21:39:00Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzkyMTQ2Ng==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557921466", "bodyText": "Position exposes too little methods, I'm not sure if I should add some methods to it.\n\n  \n    \n      pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/Position.java\n    \n    \n        Lines 29 to 37\n      in\n      3b2c852\n    \n    \n    \n    \n\n        \n          \n           public interface Position { \n        \n\n        \n          \n               /** \n        \n\n        \n          \n                * Get the position of the entry next to this one. The returned position might point to a non-existing, or not-yet \n        \n\n        \n          \n                * existing entry \n        \n\n        \n          \n                * \n        \n\n        \n          \n                * @return the position of the next logical entry \n        \n\n        \n          \n                */ \n        \n\n        \n          \n               Position getNext(); \n        \n\n        \n          \n           }", "author": "Renkai", "createdAt": "2021-01-15T07:00:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MTA3MQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559991071", "bodyText": "From the interface perspective, we should use Position", "author": "codelipenghui", "createdAt": "2021-01-19T08:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -110,25 +74,30 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n-        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException;\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());\n+        }\n     }\n \n     // TODO: improve the user metadata in subsequent changes\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTkzNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557715936", "body": "Should this be `EntryImpl` or `Entry`?", "bodyText": "Should this be EntryImpl or Entry?", "bodyHTML": "<p dir=\"auto\">Should this be <code>EntryImpl</code> or <code>Entry</code>?</p>", "author": "sijie", "createdAt": "2021-01-14T21:40:16Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -120,15 +86,26 @@ public interface LedgerOffloader {\n             return CompletableFuture.completedFuture(lastOffered());\n         }\n \n-        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException;\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<Boolean> asyncOfferEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n-                OffloadNotConsecutiveException {\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n             return CompletableFuture.completedFuture(offerEntry(entry));\n         }\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());\n+        }\n     }\n \n     // TODO: improve the user metadata in subsequent changes\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNzA2MA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557717060", "body": "Don't we need a `close` method to seal the offloaded segment?", "bodyText": "Don't we need a close method to seal the offloaded segment?", "bodyHTML": "<p dir=\"auto\">Don't we need a <code>close</code> method to seal the offloaded segment?</p>", "author": "sijie", "createdAt": "2021-01-14T21:42:34Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {", "originalCommit": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODEwNDM0MQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r558104341", "bodyText": "close method added", "author": "Renkai", "createdAt": "2021-01-15T09:17:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNzA2MA=="}], "type": "inlineReview", "revised_code": {"commit": "bb0c55b637e9622ed22306b9236d8a874c03a187", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex ba43aa8b5a9..93956407977 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -99,9 +59,15 @@ public interface LedgerOffloader {\n \n     /**\n      * Used to store driver info, buffer entries, mark progress, etc.\n-     * Create one per second.\n+     * Create one per segment.\n      */\n     interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n \n         /**\n          * return true when both buffer have enough size and ledger/entry id is next to the current one.\n", "next_change": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -76,24 +74,18 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n         /**\n          * The caller should manually release entry no matter what the offer result is.\n          */\n         OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n \n", "next_change": null}]}}]}}, {"oid": "bb0c55b637e9622ed22306b9236d8a874c03a187", "url": "https://github.com/apache/pulsar/commit/bb0c55b637e9622ed22306b9236d8a874c03a187", "message": "polish offerEntry method\nadd async close\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-15T09:16:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk4NTIwNQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559985205", "body": "```suggestion\r\n        default CompletableFuture<Boolean> canOfferAsync(long size) {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    default CompletableFuture<Boolean> asyncCanOffer(long size) {\n          \n          \n            \n                    default CompletableFuture<Boolean> canOfferAsync(long size) {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">default</span> <span class=\"pl-k\">CompletableFuture&lt;<span class=\"pl-smi\">Boolean</span>&gt;</span> <span class=\"x x-first x-last\">asyncCanOffer</span>(<span class=\"pl-k\">long</span> size) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">default</span> <span class=\"pl-k\">CompletableFuture&lt;<span class=\"pl-smi\">Boolean</span>&gt;</span> <span class=\"x x-first x-last\">canOfferAsync</span>(<span class=\"pl-k\">long</span> size) {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "codelipenghui", "createdAt": "2021-01-19T08:16:11Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -76,24 +74,18 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n         /**\n          * The caller should manually release entry no matter what the offer result is.\n          */\n         OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzM3OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993378", "body": "same as the above comment, you can remove the default implementation from the interface.", "bodyText": "same as the above comment, you can remove the default implementation from the interface.", "bodyHTML": "<p dir=\"auto\">same as the above comment, you can remove the default implementation from the interface.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T08:30:08Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -76,24 +74,18 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n         /**\n          * The caller should manually release entry no matter what the offer result is.\n          */\n         OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzUxNQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993515", "body": "Same as above comment.", "bodyText": "Same as above comment.", "bodyHTML": "<p dir=\"auto\">Same as above comment.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T08:30:22Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n+\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n+            return CompletableFuture.completedFuture(offerEntry(entry));", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..1f17159d476 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -76,24 +74,18 @@ public interface LedgerOffloader {\n          */\n         boolean canOffer(long size);\n \n-        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n-            return CompletableFuture.completedFuture(canOffer(size));\n-        }\n+        CompletableFuture<Boolean> canOfferAsync(long size);\n \n-        PositionImpl lastOffered();\n+        Position lastOffered();\n \n-        default CompletableFuture<PositionImpl> asyncLastOffered() {\n-            return CompletableFuture.completedFuture(lastOffered());\n-        }\n+        CompletableFuture<Position> lastOfferedAsync();\n \n         /**\n          * The caller should manually release entry no matter what the offer result is.\n          */\n         OfferEntryResult offerEntry(Entry entry);\n \n-        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n-            return CompletableFuture.completedFuture(offerEntry(entry));\n-        }\n+        CompletableFuture<OfferEntryResult> offerEntryAsync(Entry entry);\n \n         CompletableFuture<OffloadResult> getOffloadResultAsync();\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzY5Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993693", "body": "Same as the above comment", "bodyText": "Same as the above comment", "bodyHTML": "<p dir=\"auto\">Same as the above comment</p>", "author": "codelipenghui", "createdAt": "2021-01-19T08:30:43Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n+\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n+            return CompletableFuture.completedFuture(offerEntry(entry));\n+        }\n+\n+        CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwMzU5OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560003599", "body": "Do we need this exception? As I mentioned before, there are some markers in the managed ledger, this will affect the continuity of entry id when offload data to the tiered storage", "bodyText": "Do we need this exception? As I mentioned before, there are some markers in the managed ledger, this will affect the continuity of entry id when offload data to the tiered storage", "bodyHTML": "<p dir=\"auto\">Do we need this exception? As I mentioned before, there are some markers in the managed ledger, this will affect the continuity of entry id when offload data to the tiered storage</p>", "author": "codelipenghui", "createdAt": "2021-01-19T08:46:57Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java", "diffHunk": "@@ -151,6 +151,18 @@ public OffloadInProgressException(String msg) {\n         }\n     }\n \n+    public static class OffloadSegmentClosedException extends ManagedLedgerException {\n+        public OffloadSegmentClosedException(String msg) {\n+            super(msg);\n+        }\n+    }\n+\n+    public static class OffloadNotConsecutiveException extends ManagedLedgerException {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java\nindex 106dd72d9e0..0f56b993912 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java\n", "chunk": "@@ -151,18 +151,6 @@ public class ManagedLedgerException extends Exception {\n         }\n     }\n \n-    public static class OffloadSegmentClosedException extends ManagedLedgerException {\n-        public OffloadSegmentClosedException(String msg) {\n-            super(msg);\n-        }\n-    }\n-\n-    public static class OffloadNotConsecutiveException extends ManagedLedgerException {\n-        public OffloadNotConsecutiveException(String msg) {\n-            super(msg);\n-        }\n-    }\n-\n     public static class CursorNotFoundException extends ManagedLedgerException {\n         public CursorNotFoundException(String msg) {\n             super(msg);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwNTU0NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560005544", "body": "Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)", "bodyText": "Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)", "bodyHTML": "<p dir=\"auto\">Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)</p>", "author": "codelipenghui", "createdAt": "2021-01-19T08:49:52Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE3MDE3MQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560170171", "bodyText": "Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)\n\nMy design is refuse to return an unclosed result to prevent caller to get an incomplete result in accident.", "author": "Renkai", "createdAt": "2021-01-19T13:20:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwNTU0NA=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex 6804d75b2e7..e1b1c7953f8 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -599,5 +599,5 @@ public interface ManagedLedger {\n      * Get basic ledger summary after the ledger is closed.\n      * will got exception if corresponding ledger was not closed when the method called.\n      */\n-    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);\n+    CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId);\n }\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\nindex e1b1c7953f8..a2e0ba00b59 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java\n", "chunk": "@@ -596,8 +596,8 @@ public interface ManagedLedger {\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n \n     /**\n-     * Get basic ledger summary after the ledger is closed.\n-     * will got exception if corresponding ledger was not closed when the method called.\n+     * Get basic ledger summary.\n+     * will got null if corresponding ledger not exists.\n      */\n     CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId);\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwOTg5NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560009895", "body": "It's better to define the result as CompletableFuture<Optional<LedgerInfo>>? If use exception, it's better to define a specific exception because we need a way to determine if the exception is `ledger not found` exception? Use ManagedLedgerException to determine if the ledger is existed or not seem a bit confuse.", "bodyText": "It's better to define the result as CompletableFuture<Optional>? If use exception, it's better to define a specific exception because we need a way to determine if the exception is ledger not found exception? Use ManagedLedgerException to determine if the ledger is existed or not seem a bit confuse.", "bodyHTML": "<p dir=\"auto\">It's better to define the result as CompletableFuture&lt;Optional&gt;? If use exception, it's better to define a specific exception because we need a way to determine if the exception is <code>ledger not found</code> exception? Use ManagedLedgerException to determine if the ledger is existed or not seem a bit confuse.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T08:56:20Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,23 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            final ManagedLedgerException exception = new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+            result.completeExceptionally(exception);", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\nindex 23e52c47b18..94478a19529 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java\n", "chunk": "@@ -1687,18 +1686,9 @@ public class ManagedLedgerImpl implements ManagedLedger, CreateCallback {\n     }\n \n     @Override\n-    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) {\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n         CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n         final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n-        if (ledgerInfo == null) {\n-            final ManagedLedgerException exception = new ManagedLedgerException(\n-                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n-            result.completeExceptionally(exception);\n-        } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {\n-            final ManagedLedgerException exception = new ManagedLedgerException(\n-                    Strings.lenientFormat(\"ledger with id %s has not closed yet\", ledgerId));\n-            result.completeExceptionally(exception);\n-        }\n         result.complete(ledgerInfo);\n         return result;\n     }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAxMzQ2OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560013468", "body": "```suggestion\r\n    public final long beginLedgerId;\r\n```\r\n\r\nPlease check all.", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public final long beginLedger;\n          \n          \n            \n                public final long beginLedgerId;\n          \n      \n    \n    \n  \n\nPlease check all.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\">long</span> <span class=\"x x-first x-last\">beginLedger</span>;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\">long</span> <span class=\"x x-first x-last\">beginLedgerId</span>;</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">Please check all.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T09:01:49Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import java.util.Map;\n+import java.util.UUID;\n+import lombok.ToString;\n+import org.apache.bookkeeper.mledger.LedgerOffloader;\n+\n+@ToString\n+public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n+    public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+        this.uuid = uuid;\n+        this.beginLedger = beginLedger;\n+        this.beginEntry = beginEntry;\n+        this.driverName = driverName;\n+        this.driverMetadata = driverMetadata;\n+    }\n+\n+\n+    public final UUID uuid;\n+    public final long beginLedger;", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/OffloadSegmentInfoImpl.java\nsimilarity index 68%\nrename from managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java\nrename to managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/OffloadSegmentInfoImpl.java\nindex f096230c030..47723127c9a 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/OffloadSegmentInfoImpl.java\n", "chunk": "@@ -25,23 +25,23 @@ import lombok.ToString;\n import org.apache.bookkeeper.mledger.LedgerOffloader;\n \n @ToString\n-public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n-    public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n-                           Map<String, String> driverMetadata) {\n+public class OffloadSegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n+    public OffloadSegmentInfoImpl(UUID uuid, long beginLedgerId, long beginEntryId, String driverName,\n+                                  Map<String, String> driverMetadata) {\n         this.uuid = uuid;\n-        this.beginLedger = beginLedger;\n-        this.beginEntry = beginEntry;\n+        this.beginLedgerId = beginLedgerId;\n+        this.beginEntryId = beginEntryId;\n         this.driverName = driverName;\n         this.driverMetadata = driverMetadata;\n     }\n \n \n     public final UUID uuid;\n-    public final long beginLedger;\n-    public final long beginEntry;\n+    public final long beginLedgerId;\n+    public final long beginEntryId;\n     public final String driverName;\n-    volatile private long endLedger;\n-    volatile private long endEntry;\n+    volatile private long endLedgerId;\n+    volatile private long endEntryId;\n     volatile boolean closed = false;\n     public final Map<String, String> driverMetadata;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAxNDAxMw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560014013", "body": "```suggestion\r\npublic class OffloadSegmentInfoImpl implements LedgerOffloader.SegmentInfo {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n          \n          \n            \n            public class OffloadSegmentInfoImpl implements LedgerOffloader.SegmentInfo {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en x x-first x-last\">SegmentInfoImpl</span> <span class=\"pl-k\">implements</span> <span class=\"pl-e\">LedgerOffloader</span>.<span class=\"pl-e\">SegmentInfo</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en x x-first x-last\">OffloadSegmentInfoImpl</span> <span class=\"pl-k\">implements</span> <span class=\"pl-e\">LedgerOffloader</span>.<span class=\"pl-e\">SegmentInfo</span> {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "codelipenghui", "createdAt": "2021-01-19T09:02:43Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import java.util.Map;\n+import java.util.UUID;\n+import lombok.ToString;\n+import org.apache.bookkeeper.mledger.LedgerOffloader;\n+\n+@ToString\n+public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/OffloadSegmentInfoImpl.java\nsimilarity index 68%\nrename from managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java\nrename to managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/OffloadSegmentInfoImpl.java\nindex f096230c030..47723127c9a 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/OffloadSegmentInfoImpl.java\n", "chunk": "@@ -25,23 +25,23 @@ import lombok.ToString;\n import org.apache.bookkeeper.mledger.LedgerOffloader;\n \n @ToString\n-public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n-    public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n-                           Map<String, String> driverMetadata) {\n+public class OffloadSegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n+    public OffloadSegmentInfoImpl(UUID uuid, long beginLedgerId, long beginEntryId, String driverName,\n+                                  Map<String, String> driverMetadata) {\n         this.uuid = uuid;\n-        this.beginLedger = beginLedger;\n-        this.beginEntry = beginEntry;\n+        this.beginLedgerId = beginLedgerId;\n+        this.beginEntryId = beginEntryId;\n         this.driverName = driverName;\n         this.driverMetadata = driverMetadata;\n     }\n \n \n     public final UUID uuid;\n-    public final long beginLedger;\n-    public final long beginEntry;\n+    public final long beginLedgerId;\n+    public final long beginEntryId;\n     public final String driverName;\n-    volatile private long endLedger;\n-    volatile private long endEntry;\n+    volatile private long endLedgerId;\n+    volatile private long endEntryId;\n     volatile boolean closed = false;\n     public final Map<String, String> driverMetadata;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560025234", "body": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.\r\n", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.", "bodyHTML": "<p dir=\"auto\">Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T09:19:32Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE4OTQxNA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560189414", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.\n\nWill be used in managed ledger", "author": "Renkai", "createdAt": "2021-01-19T13:51:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE4OTc3NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560189775", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.\n\nWill be used in managed ledger", "author": "Renkai", "createdAt": "2021-01-19T13:52:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI3OTI2Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560279267", "bodyText": "Could you provide more information about how the managed ledger uses this interface? in my opinion, the ledger offloader only create a ledgerHandle then offer entry by the ledgerHandle and get the offload result. And I think the PIP https://github.com/apache/pulsar/wiki/PIP-76%3A-Streaming-Offload also does not mention this interface. Does the offload result can't work here?", "author": "codelipenghui", "createdAt": "2021-01-19T15:49:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDU5NDA4OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560594089", "bodyText": "Could you provide more information about how the managed ledger uses this interface? in my opinion, the ledger offloader only create a ledgerHandle then offer entry by the ledgerHandle and get the offload result. And I think the PIP https://github.com/apache/pulsar/wiki/PIP-76%3A-Streaming-Offload also does not mention this interface. Does the offload result can't work here?\n\nIn my current implementation, the managed ledger will keep a reference of the SegmentInfo, and once the offload got result, it will check if the result is the same with the kept one.", "author": "Renkai", "createdAt": "2021-01-20T00:36:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA=="}], "type": "inlineReview", "revised_code": {"commit": "3f59f16a32888538a15ee9ee6189372f556f795f", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 93956407977..facff2cb3c0 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -37,12 +35,6 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n-    interface SegmentInfo {\n-        boolean isClosed();\n-\n-        OffloadResult result();\n-    }\n-\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex facff2cb3c0..8c81499c528 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -35,6 +36,7 @@ import org.apache.pulsar.common.policies.data.OffloadPolicies;\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n     class OffloadResult {\n         public final long beginLedger;\n         public final long beginEntry;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560026429", "body": "Any reason to modify this method?", "bodyText": "Any reason to modify this method?", "bodyHTML": "<p dir=\"auto\">Any reason to modify this method?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T09:21:19Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "diffHunk": "@@ -71,7 +71,7 @@\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock fromStream(InputStream is) throws IOException;\n+    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE5MjM5OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560192398", "bodyText": "Because now we have two different method with similar behavior, it's better to have a distinguish\n   @Override\n    public OffloadIndexBlock indexFromStream(InputStream is) throws IOException {\n        return OffloadIndexBlockImpl.get(is);\n    }\n\n    @Override\n    public StreamingOffloadIndexBlock streamingIndexFromStream(InputStream is) throws IOException {\n        return StreamingOffloadIndexBlockImpl.get(is);\n    }", "author": "Renkai", "createdAt": "2021-01-19T13:56:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI4MjAyMA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560282020", "bodyText": "Sorry, I can't get the point here. Do you mean the method name will duplicated?", "author": "codelipenghui", "createdAt": "2021-01-19T15:53:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDU4NTI0OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560585248", "bodyText": "Sorry, I can't get the point here. Do you mean the method name will duplicated?\n\nYes", "author": "Renkai", "createdAt": "2021-01-20T00:09:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java\nindex cc68c6b9ae3..f288c90c66c 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java\n", "chunk": "@@ -71,7 +71,7 @@ public interface OffloadIndexBlockBuilder {\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;\n+    OffloadIndexBlockV2 fromStream(InputStream is) throws IOException;\n \n     /**\n      * create an OffloadIndexBlockBuilder.\n", "next_change": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java\nindex f288c90c66c..41a7009c90b 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java\n", "chunk": "@@ -77,6 +77,6 @@ public interface OffloadIndexBlockBuilder {\n      * create an OffloadIndexBlockBuilder.\n      */\n     static OffloadIndexBlockBuilder create() {\n-        return new OffloadIndexBlockBuilderImpl();\n+        return new OffloadIndexBlockV2BuilderImpl();\n     }\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzOTE5Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560039193", "body": "It's not correct here, because might skip all messages of a ledger. As I mentioned before, it's hard to determine the `Consecutive` at the offloader. And the marker also will affect this behavior in the future.", "bodyText": "It's not correct here, because might skip all messages of a ledger. As I mentioned before, it's hard to determine the Consecutive at the offloader. And the marker also will affect this behavior in the future.", "bodyHTML": "<p dir=\"auto\">It's not correct here, because might skip all messages of a ledger. As I mentioned before, it's hard to determine the <code>Consecutive</code> at the offloader. And the marker also will affect this behavior in the future.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T09:39:10Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0ODgwOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560248808", "bodyText": "consecutive check removed", "author": "Renkai", "createdAt": "2021-01-19T15:10:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzOTE5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -434,18 +458,6 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return result;\n     }\n \n-    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n-        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n-                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n-            return true;\n-        } else if (offeringPosition.getEntryId() == 0) {\n-            return true;\n-        } else {\n-            // lastOfferedPosition not initialized\n-            return lastOfferedPosition.equals(PositionImpl.latest);\n-        }\n-    }\n-\n     private PositionImpl lastOffered() {\n         return lastOfferedPosition;\n     }\n", "next_change": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..3b5ae5ee5a7 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -462,17 +477,6 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return lastOfferedPosition;\n     }\n \n-    private boolean canOffer(long size) {\n-        if (segmentInfo.isClosed()) {\n-            return false;\n-        } else if (maxBufferLength >= bufferLength.get() + size) {\n-            return true;\n-        } else {\n-            //if single message size larger than full buffer size, then ok to offer\n-            return size > maxBufferLength && offloadBuffer.isEmpty();\n-        }\n-    }\n-\n     /**\n      * Attempts to create a BlobStoreLocation from the values in the offloadDriverMetadata,\n      * however, if no values are available, it defaults to the currently configured\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560040376", "body": "If the segment closed return false, the buffer fills up return false, how to determine at the managed ledger?", "bodyText": "If the segment closed return false, the buffer fills up return false, how to determine at the managed ledger?", "bodyHTML": "<p dir=\"auto\">If the segment closed return false, the buffer fills up return false, how to determine at the managed ledger?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T09:40:49Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {\n+            return true;\n+        } else {\n+            // lastOfferedPosition not initialized\n+            return lastOfferedPosition.equals(PositionImpl.latest);\n+        }\n+    }\n+\n+    private PositionImpl lastOffered() {\n+        return lastOfferedPosition;\n+    }\n+\n+    private boolean canOffer(long size) {\n+        if (segmentInfo.isClosed()) {\n+            return false;", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI1MDc5Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560250792", "bodyText": "My new offerEntry implementation returns an enum with more rich info, so we may no need to call canOffer anymore\n        enum OfferEntryResult {\n            SUCCESS,\n            FAIL_BUFFER_FULL,\n            FAIL_SEGMENT_CLOSED,\n            FAIL_NOT_CONSECUTIVE\n        }", "author": "Renkai", "createdAt": "2021-01-19T15:13:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI4NDUyOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560284528", "bodyText": "But canOffer return boolean right? If broker call canOffer it return false here, then the broker need to try to add one more entry to check if the offload segment closed? Is my understanding correct?", "author": "codelipenghui", "createdAt": "2021-01-19T15:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -434,18 +458,6 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return result;\n     }\n \n-    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n-        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n-                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n-            return true;\n-        } else if (offeringPosition.getEntryId() == 0) {\n-            return true;\n-        } else {\n-            // lastOfferedPosition not initialized\n-            return lastOfferedPosition.equals(PositionImpl.latest);\n-        }\n-    }\n-\n     private PositionImpl lastOffered() {\n         return lastOfferedPosition;\n     }\n", "next_change": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..3b5ae5ee5a7 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -462,17 +477,6 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n         return lastOfferedPosition;\n     }\n \n-    private boolean canOffer(long size) {\n-        if (segmentInfo.isClosed()) {\n-            return false;\n-        } else if (maxBufferLength >= bufferLength.get() + size) {\n-            return true;\n-        } else {\n-            //if single message size larger than full buffer size, then ok to offer\n-            return size > maxBufferLength && offloadBuffer.isEmpty();\n-        }\n-    }\n-\n     /**\n      * Attempts to create a BlobStoreLocation from the values in the offloadDriverMetadata,\n      * however, if no values are available, it defaults to the currently configured\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0NjMzOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560046338", "body": "we can provide more information here", "bodyText": "we can provide more information here", "bodyHTML": "<p dir=\"auto\">we can provide more information here</p>", "author": "codelipenghui", "createdAt": "2021-01-19T09:49:19Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -329,48 +346,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             offloadResult.complete(segmentInfo.result());\n             return;\n         }\n-        final BufferedOffloadStream payloadStream;\n \n         while (offloadBuffer.isEmpty()) {\n             if (segmentInfo.isClosed()) {\n                 offloadResult.complete(segmentInfo.result());\n             } else {\n-                try {\n-                    Thread.sleep(100);\n-                } catch (InterruptedException e) {\n-                    e.printStackTrace();\n-                }\n+                scheduler.chooseThread(segmentInfo)\n+                        .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n+                return;\n             }\n         }\n         final Entry peek = offloadBuffer.peek();\n         //initialize payload when there is at least one entry\n         final long blockLedgerId = peek.getLedgerId();\n         final long blockEntryId = peek.getEntryId();\n-        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        try {\n-            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n-            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-        } catch (InterruptedException | ExecutionException e) {\n-            offloadResult.completeExceptionally(e);\n-            return;\n+        int tempBlockSize = streamingBlockSize;\n+        while (tempBlockSize <= peek\n+                .getLength() + StreamingDataBlockHeaderImpl.HEADER_MAX_SIZE + BufferedOffloadStream.ENTRY_HEADER_SIZE) {\n+            tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n-        log.debug(\"begin upload payload\");\n+\n+        final BufferedOffloadStream payloadStream;\n+        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n         Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n         partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n         streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n \n         log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n                 config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty\");\n+            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n             try {\n                 blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n                 final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n                 final IndexInputStream indexStream = index.toStream();\n                 final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n+                if (ledgerInfo != null) {\n+                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+                }\n+                if (ledgerInfoBuilder.getEntries() == 0) {\n+                    //ledger unclosed, use last offered\n+                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n+                }\n+                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n                 DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n                 final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -366,39 +353,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n \n-        final BufferedOffloadStream payloadStream;\n-        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n-        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n-        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n-        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n-\n-        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n-                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        try (final BufferedOffloadStream payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer,\n+                segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength)) {\n+            log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n+            Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+            partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+            streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+            streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo.Builder ledgerInfoBuilder = MLDataFormats.ManagedLedgerInfo.LedgerInfo\n+                    .newBuilder();\n+            if (ledgerInfo != null) {\n+                ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+            }\n+            if (ledgerInfoBuilder.getEntries() == 0) {\n+                //ledger unclosed, use last entry id of the block\n+                ledgerInfoBuilder.setEntries(payloadStream.getEndEntryId() + 1);\n+            }\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+            log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                    config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        } catch (Exception e) {\n+            blobStore.abortMultipartUpload(streamingMpu);\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n-            try {\n-                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n-                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n-                final IndexInputStream indexStream = index.toStream();\n-                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n-                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n-                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n-                if (ledgerInfo != null) {\n-                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n-                }\n-                if (ledgerInfoBuilder.getEntries() == 0) {\n-                    //ledger unclosed, use last offered\n-                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n-                }\n-                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n-                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+            buildIndexAndCompleteResult(dataObjectLength + tempBlockSize);\n+        } else {\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n+        }\n+    }\n \n-                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n-                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+    private void buildIndexAndCompleteResult(long dataObjectLength) {\n+        try {\n+            blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+            streamingIndexBuilder.withDataObjectLength(dataObjectLength);\n+            final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+            final IndexInputStream indexStream = index.toStream();\n+            final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n+            DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+            try (final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream)) {\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n                 indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n                 final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560061575", "body": "`StreamingDataBlockHeaderImpl` -> `DataBlockHeaderImplV2`? @Renkai @sijie The header format can be used by different offload implementations, I think coupling with streaming offload is not a good choice.", "bodyText": "StreamingDataBlockHeaderImpl -> DataBlockHeaderImplV2? @Renkai @sijie The header format can be used by different offload implementations, I think coupling with streaming offload is not a good choice.", "bodyHTML": "<p dir=\"auto\"><code>StreamingDataBlockHeaderImpl</code> -&gt; <code>DataBlockHeaderImplV2</code>? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/Renkai/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Renkai\">@Renkai</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/sijie/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sijie\">@sijie</a> The header format can be used by different offload implementations, I think coupling with streaming offload is not a good choice.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:11:54Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.io.CountingInputStream;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import java.io.DataInputStream;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+/**\n+ * The data block header in code storage for each data block.\n+ */\n+public class StreamingDataBlockHeaderImpl implements DataBlockHeader {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzMwMw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153303", "bodyText": "Have you checked this comment @Renkai?", "author": "codelipenghui", "createdAt": "2021-01-23T13:33:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzMwMTAxNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563301017", "bodyText": "@codelipenghui It's copied from other source code, I think the original author want to use 'cold storage', which is more commonly called 'tiered storage' now, I have changed the comment to tiered storage", "author": "Renkai", "createdAt": "2021-01-24T14:31:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java\nindex 574220ffc07..ed383a67e3a 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java\n", "chunk": "@@ -29,7 +29,7 @@ import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n \n /**\n- * The data block header in code storage for each data block.\n+ * The data block header in tiered storage for each data block.\n  */\n public class StreamingDataBlockHeaderImpl implements DataBlockHeader {\n     // Magic Word for streaming data block.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2ODU0OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560068549", "body": "Is the BufferedOffloadStream need to be close after offload complete? I notice during the offload loop, the `BufferedOffloadStream` is created for each loop, but can't find where to close it.", "bodyText": "Is the BufferedOffloadStream need to be close after offload complete? I notice during the offload loop, the BufferedOffloadStream is created for each loop, but can't find where to close it.", "bodyHTML": "<p dir=\"auto\">Is the BufferedOffloadStream need to be close after offload complete? I notice during the offload loop, the <code>BufferedOffloadStream</code> is created for each loop, but can't find where to close it.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:22:31Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDE5OTM3Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560199377", "bodyText": "The JCloud API should closed it, original ledger based offloader created a stream without call close, too.", "author": "Renkai", "createdAt": "2021-01-19T14:06:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2ODU0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex 7f21c9e770f..6fa0786092d 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -26,13 +26,13 @@ import java.util.concurrent.ConcurrentLinkedQueue;\n import java.util.concurrent.atomic.AtomicLong;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.bookkeeper.mledger.Entry;\n-import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.bookkeeper.mledger.impl.OffloadSegmentInfoImpl;\n import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n \n @Slf4j\n public class BufferedOffloadStream extends InputStream {\n     static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n-    private final SegmentInfoImpl segmentInfo;\n+    private final OffloadSegmentInfoImpl segmentInfo;\n \n     private final long ledgerId;\n     private final long beginEntryId;\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex 6fa0786092d..a5c94c1bcb6 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -36,6 +36,12 @@ public class BufferedOffloadStream extends InputStream {\n \n     private final long ledgerId;\n     private final long beginEntryId;\n+\n+    public long getEndEntryId() {\n+        return endEntryId;\n+    }\n+\n+    private volatile long endEntryId;\n     private AtomicLong bufferLength;\n     static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n     private final long blockSize;\n", "next_change": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex a5c94c1bcb6..3a323ce2d7f 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -22,30 +22,36 @@ import io.netty.buffer.ByteBuf;\n import io.netty.buffer.CompositeByteBuf;\n import java.io.IOException;\n import java.io.InputStream;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.atomic.AtomicLong;\n+import java.util.List;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.bookkeeper.mledger.Entry;\n-import org.apache.bookkeeper.mledger.impl.OffloadSegmentInfoImpl;\n import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n \n @Slf4j\n public class BufferedOffloadStream extends InputStream {\n     static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n-    private final OffloadSegmentInfoImpl segmentInfo;\n \n     private final long ledgerId;\n     private final long beginEntryId;\n \n+    public BufferedOffloadStream(int blockSize, List<Entry> entries, long ledgerId, long beginEntryId) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.endEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.entryBuffer = entries;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n     public long getEndEntryId() {\n         return endEntryId;\n     }\n \n     private volatile long endEntryId;\n-    private AtomicLong bufferLength;\n     static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n     private final long blockSize;\n-    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final List<Entry> entryBuffer;\n     private final InputStream blockHead;\n     int offset = 0;\n     static final int NOT_INITIALIZED = -1;\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3NTk3Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560075973", "body": "final?", "bodyText": "final?", "bodyHTML": "<p dir=\"auto\">final?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:34:30Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex 7f21c9e770f..6fa0786092d 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -42,7 +42,7 @@ public class BufferedOffloadStream extends InputStream {\n     private final ConcurrentLinkedQueue<Entry> entryBuffer;\n     private final InputStream blockHead;\n     int offset = 0;\n-    static int NOT_INITIALIZED = -1;\n+    static final int NOT_INITIALIZED = -1;\n     int validDataOffset = NOT_INITIALIZED;\n     CompositeByteBuf currentEntry;\n \n", "next_change": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex 6fa0786092d..3a323ce2d7f 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -22,24 +22,36 @@ import io.netty.buffer.ByteBuf;\n import io.netty.buffer.CompositeByteBuf;\n import java.io.IOException;\n import java.io.InputStream;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.atomic.AtomicLong;\n+import java.util.List;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.bookkeeper.mledger.Entry;\n-import org.apache.bookkeeper.mledger.impl.OffloadSegmentInfoImpl;\n import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n \n @Slf4j\n public class BufferedOffloadStream extends InputStream {\n     static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n-    private final OffloadSegmentInfoImpl segmentInfo;\n \n     private final long ledgerId;\n     private final long beginEntryId;\n-    private AtomicLong bufferLength;\n+\n+    public BufferedOffloadStream(int blockSize, List<Entry> entries, long ledgerId, long beginEntryId) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.endEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.entryBuffer = entries;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+    public long getEndEntryId() {\n+        return endEntryId;\n+    }\n+\n+    private volatile long endEntryId;\n     static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n     private final long blockSize;\n-    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final List<Entry> entryBuffer;\n     private final InputStream blockHead;\n     int offset = 0;\n     static final int NOT_INITIALIZED = -1;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4MjAyNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560082026", "body": "Should peek first? If the next entry exceeds the max block size, what the behavior? ", "bodyText": "Should peek first? If the next entry exceeds the max block size, what the behavior?", "bodyHTML": "<p dir=\"auto\">Should peek first? If the next entry exceeds the max block size, what the behavior?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:44:02Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDIxMjMzOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560212338", "bodyText": "Should peek first? If the next entry exceeds the max block size, what the behavior?\n\nSince block size is decided when block is created, I'm afraid we have to make the next block larger than an entry, I will supplement the code.", "author": "Renkai", "createdAt": "2021-01-19T14:25:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4MjAyNg=="}], "type": "inlineReview", "revised_code": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex 7f21c9e770f..3a323ce2d7f 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -99,50 +93,43 @@ public class BufferedOffloadStream extends InputStream {\n             return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n         }\n \n-        Entry headEntry;\n \n-        while ((headEntry = entryBuffer.peek()) == null) {\n-            if (segmentInfo.isClosed()) {\n-                if (validDataOffset == NOT_INITIALIZED) {\n-                    validDataOffset = offset;\n-                }\n-                return read();\n-            } else {\n-                try {\n-                    Thread.sleep(100);\n-                } catch (InterruptedException e) {\n-                    log.error(\"sleep failed\", e);\n-                }\n-            }\n+        if (entryBuffer.isEmpty()) {\n+            validDataOffset = offset;\n+            return read();\n         }\n \n+        Entry headEntry = entryBuffer.remove(0);\n+\n         //create new block when a ledger end\n         if (headEntry.getLedgerId() != this.ledgerId) {\n-            if (validDataOffset == NOT_INITIALIZED) {\n-                validDataOffset = offset;\n-            }\n-            return read();\n+            throw new RuntimeException(\n+                    String.format(\"there should not be multi ledger in a block %s %s\", headEntry.getLedgerId(),\n+                            this.ledgerId));\n         }\n \n-        if (blockSize >= offset\n-                + ENTRY_HEADER_SIZE\n-                + headEntry.getLength()) {\n-            entryBuffer.poll();\n-            final int entryLength = headEntry.getLength();\n-            bufferLength.getAndAdd(-entryLength);\n-            final long entryId = headEntry.getEntryId();\n-            CompositeByteBuf entryBuf = PulsarByteBufAllocator.DEFAULT.compositeBuffer(2);\n-            ByteBuf entryHeaderBuf = PulsarByteBufAllocator.DEFAULT.buffer(ENTRY_HEADER_SIZE, ENTRY_HEADER_SIZE);\n-            entryHeaderBuf.writeInt(entryLength).writeLong(entryId);\n-            entryBuf.addComponents(true, entryHeaderBuf, headEntry.getDataBuffer().retain());\n-            currentEntry = entryBuf;\n-            return read();\n-        } else {\n-            //over sized, fill padding\n-            if (validDataOffset == NOT_INITIALIZED) {\n-                validDataOffset = offset;\n-            }\n-            return BLOCK_END_PADDING[offset++ - validDataOffset];\n-        }\n+        final int entryLength = headEntry.getLength();\n+        final long entryId = headEntry.getEntryId();\n+        CompositeByteBuf entryBuf = PulsarByteBufAllocator.DEFAULT.compositeBuffer(2);\n+        ByteBuf entryHeaderBuf = PulsarByteBufAllocator.DEFAULT.buffer(ENTRY_HEADER_SIZE, ENTRY_HEADER_SIZE);\n+        entryHeaderBuf.writeInt(entryLength).writeLong(entryId);\n+        entryBuf.addComponents(true, entryHeaderBuf, headEntry.getDataBuffer().retain());\n+        endEntryId = headEntry.getEntryId();\n+        headEntry.release();\n+        currentEntry = entryBuf;\n+        return read();\n+\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        blockHead.close();\n+    }\n+\n+    public static int calculateBlockSize(int streamingBlockSize, int entryCount, int entrySize) {\n+        int validDataSize = (entryCount * ENTRY_HEADER_SIZE\n+                + entrySize\n+                + StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        return Math.max(streamingBlockSize, validDataSize);\n     }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560087291", "body": "is the `streamingParts` clear automatically after complete the upload? I can't find any places to clear the `streamingParts`. BTW, the `streamingParts` seems can be a local variable", "bodyText": "is the streamingParts clear automatically after complete the upload? I can't find any places to clear the streamingParts. BTW, the streamingParts seems can be a local variable", "bodyHTML": "<p dir=\"auto\">is the <code>streamingParts</code> clear automatically after complete the upload? I can't find any places to clear the <code>streamingParts</code>. BTW, the <code>streamingParts</code> seems can be a local variable</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:52:12Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDIxMzU4MQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560213581", "bodyText": "is the streamingParts clear automatically after complete the upload? I can't find any places to clear the streamingParts. BTW, the streamingParts seems can be a local variable\n\nAs we discussed formerly, a new offloader will be created once the segment offloaded, so streamingParts will be garbage collected with the offloader.", "author": "Renkai", "createdAt": "2021-01-19T14:26:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI4NjIyOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560286228", "bodyText": "If the streamingParts does not clear, for the next offload loop, how to avoid offload the duplicate data?", "author": "codelipenghui", "createdAt": "2021-01-19T15:58:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -329,48 +346,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             offloadResult.complete(segmentInfo.result());\n             return;\n         }\n-        final BufferedOffloadStream payloadStream;\n \n         while (offloadBuffer.isEmpty()) {\n             if (segmentInfo.isClosed()) {\n                 offloadResult.complete(segmentInfo.result());\n             } else {\n-                try {\n-                    Thread.sleep(100);\n-                } catch (InterruptedException e) {\n-                    e.printStackTrace();\n-                }\n+                scheduler.chooseThread(segmentInfo)\n+                        .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n+                return;\n             }\n         }\n         final Entry peek = offloadBuffer.peek();\n         //initialize payload when there is at least one entry\n         final long blockLedgerId = peek.getLedgerId();\n         final long blockEntryId = peek.getEntryId();\n-        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        try {\n-            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n-            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-        } catch (InterruptedException | ExecutionException e) {\n-            offloadResult.completeExceptionally(e);\n-            return;\n+        int tempBlockSize = streamingBlockSize;\n+        while (tempBlockSize <= peek\n+                .getLength() + StreamingDataBlockHeaderImpl.HEADER_MAX_SIZE + BufferedOffloadStream.ENTRY_HEADER_SIZE) {\n+            tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n-        log.debug(\"begin upload payload\");\n+\n+        final BufferedOffloadStream payloadStream;\n+        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n         Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n         partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n         streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n \n         log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n                 config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty\");\n+            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n             try {\n                 blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n                 final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n                 final IndexInputStream indexStream = index.toStream();\n                 final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n+                if (ledgerInfo != null) {\n+                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+                }\n+                if (ledgerInfoBuilder.getEntries() == 0) {\n+                    //ledger unclosed, use last offered\n+                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n+                }\n+                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n                 DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n                 final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -366,39 +353,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n \n-        final BufferedOffloadStream payloadStream;\n-        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n-        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n-        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n-        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n-\n-        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n-                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        try (final BufferedOffloadStream payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer,\n+                segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength)) {\n+            log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n+            Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+            partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+            streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+            streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo.Builder ledgerInfoBuilder = MLDataFormats.ManagedLedgerInfo.LedgerInfo\n+                    .newBuilder();\n+            if (ledgerInfo != null) {\n+                ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+            }\n+            if (ledgerInfoBuilder.getEntries() == 0) {\n+                //ledger unclosed, use last entry id of the block\n+                ledgerInfoBuilder.setEntries(payloadStream.getEndEntryId() + 1);\n+            }\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+            log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                    config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        } catch (Exception e) {\n+            blobStore.abortMultipartUpload(streamingMpu);\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n-            try {\n-                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n-                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n-                final IndexInputStream indexStream = index.toStream();\n-                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n-                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n-                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n-                if (ledgerInfo != null) {\n-                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n-                }\n-                if (ledgerInfoBuilder.getEntries() == 0) {\n-                    //ledger unclosed, use last offered\n-                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n-                }\n-                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n-                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+            buildIndexAndCompleteResult(dataObjectLength + tempBlockSize);\n+        } else {\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n+        }\n+    }\n \n-                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n-                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+    private void buildIndexAndCompleteResult(long dataObjectLength) {\n+        try {\n+            blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+            streamingIndexBuilder.withDataObjectLength(dataObjectLength);\n+            final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+            final IndexInputStream indexStream = index.toStream();\n+            final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n+            DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+            try (final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream)) {\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n                 indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n                 final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4ODI1Ng==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560088256", "body": "Is it need to close?", "bodyText": "Is it need to close?", "bodyHTML": "<p dir=\"auto\">Is it need to close?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:53:50Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -329,48 +346,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             offloadResult.complete(segmentInfo.result());\n             return;\n         }\n-        final BufferedOffloadStream payloadStream;\n \n         while (offloadBuffer.isEmpty()) {\n             if (segmentInfo.isClosed()) {\n                 offloadResult.complete(segmentInfo.result());\n             } else {\n-                try {\n-                    Thread.sleep(100);\n-                } catch (InterruptedException e) {\n-                    e.printStackTrace();\n-                }\n+                scheduler.chooseThread(segmentInfo)\n+                        .schedule(() -> streamingOffloadLoop(partId, dataObjectLength), 100, TimeUnit.MILLISECONDS);\n+                return;\n             }\n         }\n         final Entry peek = offloadBuffer.peek();\n         //initialize payload when there is at least one entry\n         final long blockLedgerId = peek.getLedgerId();\n         final long blockEntryId = peek.getEntryId();\n-        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        try {\n-            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n-            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n-        } catch (InterruptedException | ExecutionException e) {\n-            offloadResult.completeExceptionally(e);\n-            return;\n+        int tempBlockSize = streamingBlockSize;\n+        while (tempBlockSize <= peek\n+                .getLength() + StreamingDataBlockHeaderImpl.HEADER_MAX_SIZE + BufferedOffloadStream.ENTRY_HEADER_SIZE) {\n+            tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n-        log.debug(\"begin upload payload\");\n+\n+        final BufferedOffloadStream payloadStream;\n+        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n         Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n         partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n         streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n \n         log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n                 config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty\");\n+            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n             try {\n                 blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n                 final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n                 final IndexInputStream indexStream = index.toStream();\n                 final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n+                if (ledgerInfo != null) {\n+                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+                }\n+                if (ledgerInfoBuilder.getEntries() == 0) {\n+                    //ledger unclosed, use last offered\n+                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n+                }\n+                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n                 DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n                 final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -366,39 +353,57 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n             tempBlockSize = tempBlockSize + tempBlockSize;\n         }\n \n-        final BufferedOffloadStream payloadStream;\n-        payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer, segmentInfo,\n-                blockLedgerId, blockEntryId, bufferLength);\n-        log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n-        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n-        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n-        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n-        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n-\n-        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n-                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        try (final BufferedOffloadStream payloadStream = new BufferedOffloadStream(tempBlockSize, offloadBuffer,\n+                segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength)) {\n+            log.debug(\"begin upload payload: {} {}\", blockLedgerId, blockEntryId);\n+            Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+            partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+            streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+            streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, tempBlockSize);\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n+            final MLDataFormats.ManagedLedgerInfo.LedgerInfo.Builder ledgerInfoBuilder = MLDataFormats.ManagedLedgerInfo.LedgerInfo\n+                    .newBuilder();\n+            if (ledgerInfo != null) {\n+                ledgerInfoBuilder.mergeFrom(ledgerInfo);\n+            }\n+            if (ledgerInfoBuilder.getEntries() == 0) {\n+                //ledger unclosed, use last entry id of the block\n+                ledgerInfoBuilder.setEntries(payloadStream.getEndEntryId() + 1);\n+            }\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n+            log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                    config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        } catch (Exception e) {\n+            blobStore.abortMultipartUpload(streamingMpu);\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+\n         if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n-            log.debug(\"segment closed, buffer is empty, ledger id: {}\", blockLedgerId);\n-            try {\n-                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n-                streamingIndexBuilder.withDataObjectLength(dataObjectLength + tempBlockSize);\n-                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n-                final IndexInputStream indexStream = index.toStream();\n-                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n-                final LedgerInfo ledgerInfo = ml.getLedgerInfo(blockLedgerId).get();\n-                final LedgerInfo.Builder ledgerInfoBuilder = LedgerInfo.newBuilder();\n-                if (ledgerInfo != null) {\n-                    ledgerInfoBuilder.mergeFrom(ledgerInfo);\n-                }\n-                if (ledgerInfoBuilder.getEntries() == 0) {\n-                    //ledger unclosed, use last offered\n-                    ledgerInfoBuilder.setEntries(lastOfferedPosition.getEntryId() + 1);\n-                }\n-                streamingIndexBuilder.addLedgerMeta(blockLedgerId, ledgerInfoBuilder.build());\n-                streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+            buildIndexAndCompleteResult(dataObjectLength + tempBlockSize);\n+        } else {\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n+        }\n+    }\n \n-                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n-                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+    private void buildIndexAndCompleteResult(long dataObjectLength) {\n+        try {\n+            blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+            streamingIndexBuilder.withDataObjectLength(dataObjectLength);\n+            final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+            final IndexInputStream indexStream = index.toStream();\n+            final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+\n+            DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+            try (final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream)) {\n                 indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n                 indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n                 final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4ODk2NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560088964", "body": "Please provide more information, if you have many topics, the debug log can't help find any thing here.", "bodyText": "Please provide more information, if you have many topics, the debug log can't help find any thing here.", "bodyHTML": "<p dir=\"auto\">Please provide more information, if you have many topics, the debug log can't help find any thing here.</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:55:05Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -385,11 +411,15 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n                 log.error(\"streaming offload failed\", e);\n                 offloadResult.completeExceptionally(e);\n             }\n-            log.debug(\"offload done\");\n+            log.debug(\"offload done, begin ledgerId: {}, begin entryId: {}\", blockLedgerId, blockEntryId);\n         } else {\n-            log.debug(\"continue offload loop\");\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n             scheduler.chooseThread(segmentInfo)\n-                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n         }\n     }\n \n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -406,20 +411,16 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n                         .build();\n                 blobStore.putBlob(config.getBucket(), indexBlob);\n \n-                offloadResult.complete(segmentInfo.result());\n+                final OffloadResult result = segmentInfo.result();\n+                offloadResult.complete(result);\n+                log.debug(\"offload segment completed {}\", result);\n             } catch (Exception e) {\n                 log.error(\"streaming offload failed\", e);\n                 offloadResult.completeExceptionally(e);\n             }\n-            log.debug(\"offload done, begin ledgerId: {}, begin entryId: {}\", blockLedgerId, blockEntryId);\n-        } else {\n-            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n-            final int newPartId = partId + 1;\n-            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n-            scheduler.chooseThread(segmentInfo)\n-                    .execute(() -> {\n-                        streamingOffloadLoop(newPartId, newDataObjectLength);\n-                    });\n+        } catch (Exception e) {\n+            log.error(\"streaming offload failed\", e);\n+            offloadResult.completeExceptionally(e);\n         }\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4OTA2Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560089063", "body": "Same as above comment", "bodyText": "Same as above comment", "bodyHTML": "<p dir=\"auto\">Same as above comment</p>", "author": "codelipenghui", "createdAt": "2021-01-19T10:55:15Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -385,11 +411,15 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n                 log.error(\"streaming offload failed\", e);\n                 offloadResult.completeExceptionally(e);\n             }\n-            log.debug(\"offload done\");\n+            log.debug(\"offload done, begin ledgerId: {}, begin entryId: {}\", blockLedgerId, blockEntryId);\n         } else {\n-            log.debug(\"continue offload loop\");\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n             scheduler.chooseThread(segmentInfo)\n-                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n         }\n     }\n \n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -406,20 +411,16 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n                         .build();\n                 blobStore.putBlob(config.getBucket(), indexBlob);\n \n-                offloadResult.complete(segmentInfo.result());\n+                final OffloadResult result = segmentInfo.result();\n+                offloadResult.complete(result);\n+                log.debug(\"offload segment completed {}\", result);\n             } catch (Exception e) {\n                 log.error(\"streaming offload failed\", e);\n                 offloadResult.completeExceptionally(e);\n             }\n-            log.debug(\"offload done, begin ledgerId: {}, begin entryId: {}\", blockLedgerId, blockEntryId);\n-        } else {\n-            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n-            final int newPartId = partId + 1;\n-            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n-            scheduler.chooseThread(segmentInfo)\n-                    .execute(() -> {\n-                        streamingOffloadLoop(newPartId, newDataObjectLength);\n-                    });\n+        } catch (Exception e) {\n+            log.error(\"streaming offload failed\", e);\n+            offloadResult.completeExceptionally(e);\n         }\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NDcyNg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560094726", "body": "here will be a serious problem because the streaming offload will retry to get entry from the queue for every 100ms, if a topic does not write any messages, the thread will available for other topic offloading until the offload segment timeout(closed) right?", "bodyText": "here will be a serious problem because the streaming offload will retry to get entry from the queue for every 100ms, if a topic does not write any messages, the thread will available for other topic offloading until the offload segment timeout(closed) right?", "bodyHTML": "<p dir=\"auto\">here will be a serious problem because the streaming offload will retry to get entry from the queue for every 100ms, if a topic does not write any messages, the thread will available for other topic offloading until the offload segment timeout(closed) right?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T11:04:34Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0NjY0OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560246648", "bodyText": "I used schedule instead of sleep", "author": "Renkai", "createdAt": "2021-01-19T15:08:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NDcyNg=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex b248247171e..e53efa3de27 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -385,11 +411,15 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n                 log.error(\"streaming offload failed\", e);\n                 offloadResult.completeExceptionally(e);\n             }\n-            log.debug(\"offload done\");\n+            log.debug(\"offload done, begin ledgerId: {}, begin entryId: {}\", blockLedgerId, blockEntryId);\n         } else {\n-            log.debug(\"continue offload loop\");\n+            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n+            final int newPartId = partId + 1;\n+            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n             scheduler.chooseThread(segmentInfo)\n-                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+                    .execute(() -> {\n+                        streamingOffloadLoop(newPartId, newDataObjectLength);\n+                    });\n         }\n     }\n \n", "next_change": {"commit": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..c67507bd581 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -406,20 +411,16 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n                         .build();\n                 blobStore.putBlob(config.getBucket(), indexBlob);\n \n-                offloadResult.complete(segmentInfo.result());\n+                final OffloadResult result = segmentInfo.result();\n+                offloadResult.complete(result);\n+                log.debug(\"offload segment completed {}\", result);\n             } catch (Exception e) {\n                 log.error(\"streaming offload failed\", e);\n                 offloadResult.completeExceptionally(e);\n             }\n-            log.debug(\"offload done, begin ledgerId: {}, begin entryId: {}\", blockLedgerId, blockEntryId);\n-        } else {\n-            final int newDataObjectLength = dataObjectLength + tempBlockSize;\n-            final int newPartId = partId + 1;\n-            log.debug(\"continue offload loop, partId: {} ,current length: {}\", newPartId, newDataObjectLength);\n-            scheduler.chooseThread(segmentInfo)\n-                    .execute(() -> {\n-                        streamingOffloadLoop(newPartId, newDataObjectLength);\n-                    });\n+        } catch (Exception e) {\n+            log.error(\"streaming offload failed\", e);\n+            offloadResult.completeExceptionally(e);\n         }\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NjA3OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560096079", "body": "We should to recycle the entries after read complete?", "bodyText": "We should to recycle the entries after read complete?", "bodyHTML": "<p dir=\"auto\">We should to recycle the entries after read complete?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T11:06:54Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0NzA1Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560247053", "bodyText": "headEntry.release added", "author": "Renkai", "createdAt": "2021-01-19T15:08:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NjA3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\nindex 7f21c9e770f..3a323ce2d7f 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java\n", "chunk": "@@ -99,50 +93,43 @@ public class BufferedOffloadStream extends InputStream {\n             return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n         }\n \n-        Entry headEntry;\n \n-        while ((headEntry = entryBuffer.peek()) == null) {\n-            if (segmentInfo.isClosed()) {\n-                if (validDataOffset == NOT_INITIALIZED) {\n-                    validDataOffset = offset;\n-                }\n-                return read();\n-            } else {\n-                try {\n-                    Thread.sleep(100);\n-                } catch (InterruptedException e) {\n-                    log.error(\"sleep failed\", e);\n-                }\n-            }\n+        if (entryBuffer.isEmpty()) {\n+            validDataOffset = offset;\n+            return read();\n         }\n \n+        Entry headEntry = entryBuffer.remove(0);\n+\n         //create new block when a ledger end\n         if (headEntry.getLedgerId() != this.ledgerId) {\n-            if (validDataOffset == NOT_INITIALIZED) {\n-                validDataOffset = offset;\n-            }\n-            return read();\n+            throw new RuntimeException(\n+                    String.format(\"there should not be multi ledger in a block %s %s\", headEntry.getLedgerId(),\n+                            this.ledgerId));\n         }\n \n-        if (blockSize >= offset\n-                + ENTRY_HEADER_SIZE\n-                + headEntry.getLength()) {\n-            entryBuffer.poll();\n-            final int entryLength = headEntry.getLength();\n-            bufferLength.getAndAdd(-entryLength);\n-            final long entryId = headEntry.getEntryId();\n-            CompositeByteBuf entryBuf = PulsarByteBufAllocator.DEFAULT.compositeBuffer(2);\n-            ByteBuf entryHeaderBuf = PulsarByteBufAllocator.DEFAULT.buffer(ENTRY_HEADER_SIZE, ENTRY_HEADER_SIZE);\n-            entryHeaderBuf.writeInt(entryLength).writeLong(entryId);\n-            entryBuf.addComponents(true, entryHeaderBuf, headEntry.getDataBuffer().retain());\n-            currentEntry = entryBuf;\n-            return read();\n-        } else {\n-            //over sized, fill padding\n-            if (validDataOffset == NOT_INITIALIZED) {\n-                validDataOffset = offset;\n-            }\n-            return BLOCK_END_PADDING[offset++ - validDataOffset];\n-        }\n+        final int entryLength = headEntry.getLength();\n+        final long entryId = headEntry.getEntryId();\n+        CompositeByteBuf entryBuf = PulsarByteBufAllocator.DEFAULT.compositeBuffer(2);\n+        ByteBuf entryHeaderBuf = PulsarByteBufAllocator.DEFAULT.buffer(ENTRY_HEADER_SIZE, ENTRY_HEADER_SIZE);\n+        entryHeaderBuf.writeInt(entryLength).writeLong(entryId);\n+        entryBuf.addComponents(true, entryHeaderBuf, headEntry.getDataBuffer().retain());\n+        endEntryId = headEntry.getEntryId();\n+        headEntry.release();\n+        currentEntry = entryBuf;\n+        return read();\n+\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        blockHead.close();\n+    }\n+\n+    public static int calculateBlockSize(int streamingBlockSize, int entryCount, int entrySize) {\n+        int validDataSize = (entryCount * ENTRY_HEADER_SIZE\n+                + entrySize\n+                + StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        return Math.max(streamingBlockSize, validDataSize);\n     }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMDc4NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560100784", "body": "also close the `dataStreams`?", "bodyText": "also close the dataStreams?", "bodyHTML": "<p dir=\"auto\">also close the <code>dataStreams</code>?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T11:14:28Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDIxODAxNA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560218014", "bodyText": "Seems close dataStreams will close inputStreams,too.\nSo I replaced close inputStreams to input close dataStreams", "author": "Renkai", "createdAt": "2021-01-19T14:32:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMDc4NA=="}], "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\nindex e0f638e9ee5..889923aad43 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n", "chunk": "@@ -107,8 +108,8 @@ public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n                 for (StreamingOffloadIndexBlock indexBlock : indices) {\n                     indexBlock.close();\n                 }\n-                for (BackedInputStream inputStream : inputStreams) {\n-                    inputStream.close();\n+                for (DataInputStream dataStream : dataStreams) {\n+                    dataStream.close();\n                 }\n                 promise.complete(null);\n             } catch (IOException t) {\n", "next_change": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\nindex 889923aad43..10607770b50 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n", "chunk": "@@ -105,7 +115,7 @@ public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n         CompletableFuture<Void> promise = new CompletableFuture<>();\n         executor.submit(() -> {\n             try {\n-                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                for (OffloadIndexBlockV2 indexBlock : indices) {\n                     indexBlock.close();\n                 }\n                 for (DataInputStream dataStream : dataStreams) {\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMTc5NA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560101794", "body": "Why throw bk exception here? does `IllegalArgumentException` works?", "bodyText": "Why throw bk exception here? does IllegalArgumentException works?", "bodyHTML": "<p dir=\"auto\">Why throw bk exception here? does <code>IllegalArgumentException</code> works?</p>", "author": "codelipenghui", "createdAt": "2021-01-19T11:16:15Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\nindex e0f638e9ee5..889923aad43 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java\n", "chunk": "@@ -125,7 +126,7 @@ public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n         if (firstEntry > lastEntry\n                 || firstEntry < 0\n                 || lastEntry > getLastAddConfirmed()) {\n-            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            promise.completeExceptionally(new IllegalArgumentException());\n             return promise;\n         }\n         executor.submit(() -> {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwNTc1Ng==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560105756", "body": "Please double confirm the `groupedReaders` are sorted by ledger Id, entry id, Otherwise, this will bread the entry read in order guarantee", "bodyText": "Please double confirm the groupedReaders are sorted by ledger Id, entry id, Otherwise, this will bread the entry read in order guarantee", "bodyHTML": "<p dir=\"auto\">Please double confirm the <code>groupedReaders</code> are sorted by ledger Id, entry id, Otherwise, this will bread the entry read in order guarantee</p>", "author": "codelipenghui", "createdAt": "2021-01-19T11:23:08Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {", "originalCommit": "acc18e061a2437b69f05b30c021a9fd911711bcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI0NzI5NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560247295", "bodyText": "double confirm code added", "author": "Renkai", "createdAt": "2021-01-19T15:09:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwNTc1Ng=="}], "type": "inlineReview", "revised_code": null}, {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "url": "https://github.com/apache/pulsar/commit/45d435c5bd42e5206f714a2f349cebb81ba1b575", "message": "snapshot 20210120\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T02:52:49Z", "type": "commit"}, {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "url": "https://github.com/apache/pulsar/commit/45d435c5bd42e5206f714a2f349cebb81ba1b575", "message": "snapshot 20210120\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T02:52:49Z", "type": "forcePushed"}, {"oid": "3f59f16a32888538a15ee9ee6189372f556f795f", "url": "https://github.com/apache/pulsar/commit/3f59f16a32888538a15ee9ee6189372f556f795f", "message": "remove interface segmentInfo\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T03:07:09Z", "type": "commit"}, {"oid": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "url": "https://github.com/apache/pulsar/commit/7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "message": "use auto-close to streams\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T04:09:32Z", "type": "commit"}, {"oid": "9faedd44431de79bfc761fb20ee565f728dbd09d", "url": "https://github.com/apache/pulsar/commit/9faedd44431de79bfc761fb20ee565f728dbd09d", "message": "use throwable instead of Exception\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T04:23:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1Nzk1OQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560657959", "body": "streamingoffload()?", "bodyText": "streamingoffload()?", "bodyHTML": "<p dir=\"auto\">streamingoffload()?</p>", "author": "zymap", "createdAt": "2021-01-20T03:55:20Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +150,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * longterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds", "originalCommit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "changed_code": [{"header": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\nindex 1f17159d476..26ef810c91e 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java\n", "chunk": "@@ -163,7 +150,7 @@ public interface LedgerOffloader {\n      * The uid is used to identify an attempt to offload. The implementation should\n      * use this to deterministically generate a unique name for the offloaded object.\n      * This uid will be stored in the managed ledger metadata before attempting the\n-     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * call to streamingOffload(). If a subsequent or concurrent call to streamingOffload() finds\n      * a uid in the metadata, it will attempt to cleanup this attempt with a call\n      * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n      * the managed ledger will update its metadata again, to record the completion,\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560659329", "body": "Do we need to check the returned value? It's might be null.", "bodyText": "Do we need to check the returned value? It's might be null.", "bodyHTML": "<p dir=\"auto\">Do we need to check the returned value? It's might be null.</p>", "author": "zymap", "createdAt": "2021-01-20T03:59:59Z", "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "originalCommit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc0MjAxMA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560742010", "bodyText": "I added comment for the interface, yes it may return a future with null, the caller should deal with it.", "author": "Renkai", "createdAt": "2021-01-20T07:53:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc1NjU1Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560756552", "bodyText": "We might can throw an exception for that?", "author": "zymap", "createdAt": "2021-01-20T08:19:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzEwMDYyOA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563100628", "bodyText": "And please consider returns a copy of LedgerInfo to void be modified from external?", "author": "codelipenghui", "createdAt": "2021-01-23T11:03:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzMwMDI0NQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563300245", "bodyText": "@codelipenghui The LedgerInfo class is generated by protobuf, which is already an immutable class, we don't need to do extra things to make it immutable.", "author": "Renkai", "createdAt": "2021-01-24T14:25:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560660780", "body": "any() should be any type, why we need to cast it to the UUID?", "bodyText": "any() should be any type, why we need to cast it to the UUID?", "bodyHTML": "<p dir=\"auto\">any() should be any type, why we need to cast it to the UUID?</p>", "author": "zymap", "createdAt": "2021-01-20T04:05:24Z", "path": "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/OffloadPrefixReadTest.java", "diffHunk": "@@ -97,21 +97,21 @@ public void testOffloadRead() throws Exception {\n             assertEquals(new String(e.getData()), \"entry-\" + i++);\n         }\n         verify(offloader, times(1))\n-            .readOffloaded(anyLong(), any(), anyMap());\n+                .readOffloaded(anyLong(), (UUID) any(), anyMap());", "originalCommit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc0MjU5MQ==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560742591", "bodyText": "Because readOffloaded have different version of overload, I used cast to avoid ambiguous method call.", "author": "Renkai", "createdAt": "2021-01-20T07:54:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc1NzE1OA==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560757158", "bodyText": "okay, you can use any(UUID.class) to do that.", "author": "zymap", "createdAt": "2021-01-20T08:20:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzE0Mg==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560673142", "body": "If we have another call for the `streamingOffloading`, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.", "bodyText": "If we have another call for the streamingOffloading, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.", "bodyHTML": "<p dir=\"auto\">If we have another call for the <code>streamingOffloading</code>, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.</p>", "author": "zymap", "createdAt": "2021-01-20T04:35:58Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);", "originalCommit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc0NjYzNw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560746637", "bodyText": "If we have another call for the streamingOffloading, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.\n\nIn our design, an offloader instance can only call streamingOffload once, I will add some document and check on it.", "author": "Renkai", "createdAt": "2021-01-20T08:02:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzE0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..275638ddf5e 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -273,16 +276,22 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n     List<MultipartPart> streamingParts = Lists.newArrayList();\n \n     @Override\n-    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+    public CompletableFuture<OffloadHandle> streamingOffload(@NonNull ManagedLedger ml, UUID uuid, long beginLedger,\n                                                              long beginEntry,\n                                                              Map<String, String> driverMetadata) {\n+        if (this.ml != null) {\n+            log.error(\"streamingOffload should only be called once\");\n+            final CompletableFuture<OffloadHandle> result = new CompletableFuture<>();\n+            result.completeExceptionally(new RuntimeException(\"streamingOffload should only be called once\"));\n+        }\n+\n         this.ml = ml;\n         this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n                 driverMetadata);\n         log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n         this.offloadResult = new CompletableFuture<>();\n         blobStore = blobStores.get(config.getBlobStoreLocation());\n-        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingIndexBuilder = OffloadIndexBlockV2Builder.create();\n         streamingDataBlockKey = segmentInfo.uuid.toString();\n         streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n         BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzI0Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560673247", "body": "same above.", "bodyText": "same above.", "bodyHTML": "<p dir=\"auto\">same above.</p>", "author": "zymap", "createdAt": "2021-01-20T04:36:17Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore", "originalCommit": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\nindex e53efa3de27..275638ddf5e 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java\n", "chunk": "@@ -273,16 +276,22 @@ public class BlobStoreManagedLedgerOffloader implements LedgerOffloader {\n     List<MultipartPart> streamingParts = Lists.newArrayList();\n \n     @Override\n-    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+    public CompletableFuture<OffloadHandle> streamingOffload(@NonNull ManagedLedger ml, UUID uuid, long beginLedger,\n                                                              long beginEntry,\n                                                              Map<String, String> driverMetadata) {\n+        if (this.ml != null) {\n+            log.error(\"streamingOffload should only be called once\");\n+            final CompletableFuture<OffloadHandle> result = new CompletableFuture<>();\n+            result.completeExceptionally(new RuntimeException(\"streamingOffload should only be called once\"));\n+        }\n+\n         this.ml = ml;\n         this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n                 driverMetadata);\n         log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n         this.offloadResult = new CompletableFuture<>();\n         blobStore = blobStores.get(config.getBlobStoreLocation());\n-        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingIndexBuilder = OffloadIndexBlockV2Builder.create();\n         streamingDataBlockKey = segmentInfo.uuid.toString();\n         streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n         BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n", "next_change": null}]}}, {"oid": "8f4510a2c868dc905d41081a8119be14adb686bb", "url": "https://github.com/apache/pulsar/commit/8f4510a2c868dc905d41081a8119be14adb686bb", "message": "fix bug to pass tests\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T06:20:13Z", "type": "commit"}, {"oid": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "url": "https://github.com/apache/pulsar/commit/b8b53dcc1f0787176f66f7533dcb13df1a05b586", "message": "merge the from stream method of two version index\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T07:51:16Z", "type": "commit"}, {"oid": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "url": "https://github.com/apache/pulsar/commit/b8b53dcc1f0787176f66f7533dcb13df1a05b586", "message": "merge the from stream method of two version index\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T07:51:16Z", "type": "forcePushed"}, {"oid": "26cdd20e099dd6a3b56d9e38947c962ae32feec7", "url": "https://github.com/apache/pulsar/commit/26cdd20e099dd6a3b56d9e38947c962ae32feec7", "message": "add info to prevent offload multi times\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T08:12:52Z", "type": "commit"}, {"oid": "ce767aef96654be789c265600ad1f3a1065a08fe", "url": "https://github.com/apache/pulsar/commit/ce767aef96654be789c265600ad1f3a1065a08fe", "message": "reduce sleep time\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-20T13:26:34Z", "type": "commit"}, {"oid": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "url": "https://github.com/apache/pulsar/commit/6ecde448b62b5e4336f98c72bdd194fe06d41401", "message": "put blob after buffer reaches threshold\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-21T03:47:11Z", "type": "commit"}, {"oid": "7794e184a56fd7ac007a1180e2263563d060d364", "url": "https://github.com/apache/pulsar/commit/7794e184a56fd7ac007a1180e2263563d060d364", "message": "Merge branch 'master' into new-offloader", "committedDate": "2021-01-22T09:05:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzA3Mw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153073", "body": "This should be OffloadIndexBlockV2Builder?", "bodyText": "This should be OffloadIndexBlockV2Builder?", "bodyHTML": "<p dir=\"auto\">This should be OffloadIndexBlockV2Builder?</p>", "author": "codelipenghui", "createdAt": "2021-01-23T13:30:22Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "originalCommit": "7794e184a56fd7ac007a1180e2263563d060d364", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nsimilarity index 82%\nrename from tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\nrename to tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nindex 547d11aa7e8..83dbff5ca22 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\n", "chunk": "@@ -22,7 +22,7 @@ import java.io.IOException;\n import java.io.InputStream;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n-import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockV2BuilderImpl;\n import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n \n /**\n", "next_change": null}, {"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nsimilarity index 82%\nrename from tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\nrename to tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\nindex 547d11aa7e8..83dbff5ca22 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockV2Builder.java\n", "chunk": "@@ -30,7 +30,7 @@ import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.Ledge\n  */\n @Unstable\n @LimitedPrivate\n-public interface StreamingOffloadIndexBlockBuilder {\n+public interface OffloadIndexBlockV2Builder {\n \n     /**\n      * Build index block with the passed in ledger metadata.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzE5Nw==", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153197", "body": "```suggestion\r\npublic class OffloadIndexBlockV2Impl implements OffloadIndexBlockV2 {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {\n          \n          \n            \n            public class OffloadIndexBlockV2Impl implements OffloadIndexBlockV2 {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en x x-first x-last\">StreamingOffloadIndexBlockImpl</span> <span class=\"pl-k\">implements</span> <span class=\"pl-e\">OffloadIndexBlockV2</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en x x-first x-last\">OffloadIndexBlockV2Impl</span> <span class=\"pl-k\">implements</span> <span class=\"pl-e\">OffloadIndexBlockV2</span> {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "codelipenghui", "createdAt": "2021-01-23T13:32:11Z", "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.Maps;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import io.netty.util.Recycler;\n+import io.netty.util.Recycler.Handle;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableMap;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+import org.apache.bookkeeper.client.api.DigestType;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexBlock.IndexInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexBlockV2;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexEntry;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+import org.apache.bookkeeper.net.BookieId;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {", "originalCommit": "7794e184a56fd7ac007a1180e2263563d060d364", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c622056775a8a3fd0b165341618b0ee644ccc922", "changed_code": [{"header": "diff --git a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/OffloadIndexBlockV2Impl.java\nsimilarity index 91%\nrename from tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java\nrename to tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/OffloadIndexBlockV2Impl.java\nindex 25a312393e8..d58a4c1d2e1 100644\n--- a/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java\n+++ b/tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/OffloadIndexBlockV2Impl.java\n", "chunk": "@@ -43,7 +43,7 @@ import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {\n+public class OffloadIndexBlockV2Impl implements OffloadIndexBlockV2 {\n     private static final Logger log = LoggerFactory.getLogger(OffloadIndexBlockImpl.class);\n \n     private static final int INDEX_MAGIC_WORD = 0x3D1FB0BC;\n", "next_change": null}]}}, {"oid": "82c6cb1b9fce171dee3907d7fbb6fbf207b3640d", "url": "https://github.com/apache/pulsar/commit/82c6cb1b9fce171dee3907d7fbb6fbf207b3640d", "message": "Merge branch 'master' into new-offloader", "committedDate": "2021-01-24T14:23:58Z", "type": "commit"}, {"oid": "c622056775a8a3fd0b165341618b0ee644ccc922", "url": "https://github.com/apache/pulsar/commit/c622056775a8a3fd0b165341618b0ee644ccc922", "message": "polish\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-24T14:31:53Z", "type": "commit"}, {"oid": "9e9b1c6fff551d949e5aba17894efc60ed7e05a2", "url": "https://github.com/apache/pulsar/commit/9e9b1c6fff551d949e5aba17894efc60ed7e05a2", "message": "change streaming to v2\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-25T01:01:59Z", "type": "commit"}, {"oid": "ea69a1df3cb22f90bd93a1db601db012908be42e", "url": "https://github.com/apache/pulsar/commit/ea69a1df3cb22f90bd93a1db601db012908be42e", "message": "rename streaming to v2\n\nSigned-off-by: Renkai <gaelookair@gmail.com>", "committedDate": "2021-01-25T01:18:59Z", "type": "commit"}, {"oid": "e4835d43f1abba4183f2e93814690307de72d787", "url": "https://github.com/apache/pulsar/commit/e4835d43f1abba4183f2e93814690307de72d787", "message": "Merge branch 'master' into new-offloader", "committedDate": "2021-01-25T14:04:52Z", "type": "commit"}]}