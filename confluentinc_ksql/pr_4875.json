{"pr_number": 4875, "pr_title": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "pr_author": "stevenpyzhang", "pr_createdAt": "2020-03-23T22:01:33Z", "pr_url": "https://github.com/confluentinc/ksql/pull/4875", "timeline": [{"oid": "5a871718d2401b79c45548a52994b37e3106d778", "url": "https://github.com/confluentinc/ksql/commit/5a871718d2401b79c45548a52994b37e3106d778", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-24T00:12:34Z", "type": "forcePushed"}, {"oid": "8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "url": "https://github.com/confluentinc/ksql/commit/8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-24T18:58:12Z", "type": "forcePushed"}, {"oid": "865e158a791082b48f6c11e75bcf26befd28b1d0", "url": "https://github.com/confluentinc/ksql/commit/865e158a791082b48f6c11e75bcf26befd28b1d0", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-25T18:46:27Z", "type": "forcePushed"}, {"oid": "115659497df719d8e1913ed113d2d61a4056a302", "url": "https://github.com/confluentinc/ksql/commit/115659497df719d8e1913ed113d2d61a4056a302", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-25T22:36:51Z", "type": "forcePushed"}, {"oid": "fcd157bf075d61c840bab2bab86b1013f28a3204", "url": "https://github.com/confluentinc/ksql/commit/fcd157bf075d61c840bab2bab86b1013f28a3204", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T00:04:19Z", "type": "forcePushed"}, {"oid": "80f552536a53dcf361f7de8165e21fd20e47808a", "url": "https://github.com/confluentinc/ksql/commit/80f552536a53dcf361f7de8165e21fd20e47808a", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T00:05:54Z", "type": "forcePushed"}, {"oid": "4cc10dbfcf6030635899df8a758da0c3ba7ff519", "url": "https://github.com/confluentinc/ksql/commit/4cc10dbfcf6030635899df8a758da0c3ba7ff519", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T03:00:11Z", "type": "forcePushed"}, {"oid": "413146c650913a86bce395aff75949e0104e5e7a", "url": "https://github.com/confluentinc/ksql/commit/413146c650913a86bce395aff75949e0104e5e7a", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T03:35:16Z", "type": "forcePushed"}, {"oid": "157df014f2f5adb180949d2b07a132b957a4d0f2", "url": "https://github.com/confluentinc/ksql/commit/157df014f2f5adb180949d2b07a132b957a4d0f2", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T06:45:19Z", "type": "forcePushed"}, {"oid": "470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "url": "https://github.com/confluentinc/ksql/commit/470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T07:18:50Z", "type": "forcePushed"}, {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "url": "https://github.com/confluentinc/ksql/commit/d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T23:14:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r398969428", "body": "Changing this to reduce the amount of logging from creating the KsqlRequestConfig", "bodyText": "Changing this to reduce the amount of logging from creating the KsqlRequestConfig", "bodyHTML": "<p dir=\"auto\">Changing this to reduce the amount of logging from creating the KsqlRequestConfig</p>", "author": "stevenpyzhang", "createdAt": "2020-03-27T00:26:43Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java", "diffHunk": "@@ -247,8 +247,9 @@ public Response handleKsqlStatements(\n           request,\n           distributedCmdResponseTimeout);\n \n-      final KsqlRequestConfig requestConfig =\n-          new KsqlRequestConfig(request.getRequestProperties());\n+      final boolean internalRequest =", "originalCommit": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTIwMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400871202", "bodyText": "Rather than change this, just make KsqlRequstConfig not log on construction.  You can do this by changing its constructor to pass false for the doLog param of AbstractConfig's constructor:\npublic KsqlRequestConfig(final Map<?, ?> props) {\n    super(CURRENT_DEF, props, false);\n  }", "author": "big-andy-coates", "createdAt": "2020-03-31T12:26:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5MTk5MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401891990", "bodyText": "Thanks! I didn't realize this was an option", "author": "stevenpyzhang", "createdAt": "2020-04-01T20:33:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\nindex 461c246891..dd3a2285e5 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n", "chunk": "@@ -247,9 +247,8 @@ public class KsqlResource implements KsqlConfigurable {\n           request,\n           distributedCmdResponseTimeout);\n \n-      final boolean internalRequest =\n-          (boolean) request.getRequestProperties()\n-              .getOrDefault(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, false);\n+      final KsqlRequestConfig requestConfig =\n+          new KsqlRequestConfig(request.getRequestProperties());\n       final List<ParsedStatement> statements = ksqlEngine.parse(request.getKsql());\n       validator.validate(\n           SandboxedServiceContext.create(securityContext.getServiceContext()),\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\nindex dd3a2285e5..461c246891 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n", "chunk": "@@ -247,8 +247,9 @@ public class KsqlResource implements KsqlConfigurable {\n           request,\n           distributedCmdResponseTimeout);\n \n-      final KsqlRequestConfig requestConfig =\n-          new KsqlRequestConfig(request.getRequestProperties());\n+      final boolean internalRequest =\n+          (boolean) request.getRequestProperties()\n+              .getOrDefault(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, false);\n       final List<ParsedStatement> statements = ksqlEngine.parse(request.getKsql());\n       validator.validate(\n           SandboxedServiceContext.create(securityContext.getServiceContext()),\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\nindex 461c246891..dd3a2285e5 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n", "chunk": "@@ -247,9 +247,8 @@ public class KsqlResource implements KsqlConfigurable {\n           request,\n           distributedCmdResponseTimeout);\n \n-      final boolean internalRequest =\n-          (boolean) request.getRequestProperties()\n-              .getOrDefault(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, false);\n+      final KsqlRequestConfig requestConfig =\n+          new KsqlRequestConfig(request.getRequestProperties());\n       final List<ParsedStatement> statements = ksqlEngine.parse(request.getKsql());\n       validator.validate(\n           SandboxedServiceContext.create(securityContext.getServiceContext()),\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\nindex 461c246891..dd3a2285e5 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n", "chunk": "@@ -258,7 +257,7 @@ public class KsqlResource implements KsqlConfigurable {\n               request.getConfigOverrides(),\n               localHost, \n               localUrl,\n-              internalRequest\n+              requestConfig.getBoolean(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST)\n           ),\n           request.getKsql()\n       );\n", "next_change": null}]}}, {"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\nindex dd3a2285e5..461c246891 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n", "chunk": "@@ -257,7 +258,7 @@ public class KsqlResource implements KsqlConfigurable {\n               request.getConfigOverrides(),\n               localHost, \n               localUrl,\n-              requestConfig.getBoolean(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST)\n+              internalRequest\n           ),\n           request.getKsql()\n       );\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\nindex 461c246891..dd3a2285e5 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java\n", "chunk": "@@ -258,7 +257,7 @@ public class KsqlResource implements KsqlConfigurable {\n               request.getConfigOverrides(),\n               localHost, \n               localUrl,\n-              internalRequest\n+              requestConfig.getBoolean(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST)\n           ),\n           request.getKsql()\n       );\n", "next_change": null}]}}]}}]}}, {"oid": "5784bc7d76ce514960fe7116a3aeb898bed15188", "url": "https://github.com/confluentinc/ksql/commit/5784bc7d76ce514960fe7116a3aeb898bed15188", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-27T00:54:45Z", "type": "forcePushed"}, {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693", "url": "https://github.com/confluentinc/ksql/commit/5271edf3d2fbf858bde71926fedd246edd9fa693", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-27T00:55:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r398977351", "body": "This has to be set in order for `waitForClusterToBeDiscovered(REST_APP_0, 2);` to work properly. The wait is necessary in order to make sure the queries are in a `RUNNING` state before proceeding with the test", "bodyText": "This has to be set in order for waitForClusterToBeDiscovered(REST_APP_0, 2); to work properly. The wait is necessary in order to make sure the queries are in a RUNNING state before proceeding with the test", "bodyHTML": "<p dir=\"auto\">This has to be set in order for <code>waitForClusterToBeDiscovered(REST_APP_0, 2);</code> to work properly. The wait is necessary in order to make sure the queries are in a <code>RUNNING</code> state before proceeding with the test</p>", "author": "stevenpyzhang", "createdAt": "2020-03-27T00:56:47Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NzIzNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400857235", "bodyText": "When I run this test I see this reported in the output:\njava.lang.UnsupportedOperationException: KSQL client is disabled\n\tat io.confluent.ksql.services.DisabledKsqlClient.makeAsyncHeartbeatRequest(DisabledKsqlClient.java:70)\n\tat io.confluent.ksql.rest.server.HeartbeatAgent$SendHeartbeatService.runOneIteration(HeartbeatAgent.java:322)\n\tat com.google.common.util.concurrent.AbstractScheduledService$ServiceDelegate$Task.run(AbstractScheduledService.java:193)\n\tat com.google.common.util.concurrent.Callables$4.run(Callables.java:119)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nWhich seems to suggest that maybe this isn't doing what you think it is.\nRather than relying on another feature to ensure the queries are running before proceeding, might it not be better to code the tests to await the expected final state?  This way, we can be sure that your change works even if heartbeats are disabled.\nTo achieve this, you can change your tests to use assertThatEventually, as I've shown below. assertThatEventually takes a Supplier which it polls to get a result.", "author": "big-andy-coates", "createdAt": "2020-03-31T12:03:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkyMDI2MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401920261", "bodyText": "Resolving as this dependency is now removed.", "author": "stevenpyzhang", "createdAt": "2020-04-01T21:27:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -59,15 +59,11 @@ public class ShowQueriesMultiNodeFunctionalTest {\n       .builder(TEST_HARNESS::kafkaBootstrapServers)\n       .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n       .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n-      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n-      .withProperties(ClientTrustStore.trustStoreProps())\n       .build();\n   private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n       .builder(TEST_HARNESS::kafkaBootstrapServers)\n       .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n       .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n-      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n-      .withProperties(ClientTrustStore.trustStoreProps())\n       .build();\n \n   @ClassRule\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 9a1472e0c7..2aa4bcc400 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -59,11 +59,15 @@ public class ShowQueriesMultiNodeFunctionalTest {\n       .builder(TEST_HARNESS::kafkaBootstrapServers)\n       .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n       .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n       .build();\n   private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n       .builder(TEST_HARNESS::kafkaBootstrapServers)\n       .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n       .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n       .build();\n \n   @ClassRule\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -59,15 +59,11 @@ public class ShowQueriesMultiNodeFunctionalTest {\n       .builder(TEST_HARNESS::kafkaBootstrapServers)\n       .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n       .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n-      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n-      .withProperties(ClientTrustStore.trustStoreProps())\n       .build();\n   private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n       .builder(TEST_HARNESS::kafkaBootstrapServers)\n       .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n       .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n-      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n-      .withProperties(ClientTrustStore.trustStoreProps())\n       .build();\n \n   @ClassRule\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2NjgwOQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399366809", "body": "nit: I believe the `toString` is superfluous here", "bodyText": "nit: I believe the toString is superfluous here", "bodyHTML": "<p dir=\"auto\">nit: I believe the <code>toString</code> is superfluous here</p>", "author": "agavra", "createdAt": "2020-03-27T15:55:03Z", "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -659,6 +659,11 @@ private void printQueryDescription(final QueryDescription query) {\n     if (query.getState().isPresent()) {\n       writer().println(String.format(\"%-20s : %s\", \"Status\", query.getState().get()));\n     }\n+    if (query.getKsqlHostQueryState().size() > 0) {\n+      writer().println(String.format(\n+          \"%-20s : %s\", \"Host Query Status\",\n+          query.getKsqlHostQueryState().toString()));", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex d8670990b8..174677686c 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -662,7 +662,7 @@ public class Console implements Closeable {\n     if (query.getKsqlHostQueryState().size() > 0) {\n       writer().println(String.format(\n           \"%-20s : %s\", \"Host Query Status\",\n-          query.getKsqlHostQueryState().toString()));\n+          query.getKsqlHostQueryState()));\n     }\n     writer().println();\n     printSchema(query.getWindowType(), query.getFields(), \"\");\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex 174677686c..d9999010b9 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -662,7 +664,7 @@ public class Console implements Closeable {\n     if (query.getKsqlHostQueryState().size() > 0) {\n       writer().println(String.format(\n           \"%-20s : %s\", \"Host Query Status\",\n-          query.getKsqlHostQueryState()));\n+          query.getKsqlHostQueryState().toString()));\n     }\n     writer().println();\n     printSchema(query.getWindowType(), query.getFields(), \"\");\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex d9999010b9..82db473a50 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -664,7 +664,7 @@ public class Console implements Closeable {\n     if (query.getKsqlHostQueryState().size() > 0) {\n       writer().println(String.format(\n           \"%-20s : %s\", \"Host Query Status\",\n-          query.getKsqlHostQueryState().toString()));\n+          query.getKsqlHostQueryState()));\n     }\n     writer().println();\n     printSchema(query.getWindowType(), query.getFields(), \"\");\n", "next_change": {"commit": "293e001f7a95180faa8acee22006e4dd023c41de", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex 82db473a50..73104d6ca2 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -661,7 +661,7 @@ public class Console implements Closeable {\n     if (query.getState().isPresent()) {\n       writer().println(String.format(\"%-20s : %s\", \"Status\", query.getState().get()));\n     }\n-    if (query.getKsqlHostQueryState().size() > 0) {\n+    if (!query.getKsqlHostQueryState().isEmpty()) {\n       writer().println(String.format(\n           \"%-20s : %s\", \"Host Query Status\",\n           query.getKsqlHostQueryState()));\n", "next_change": {"commit": "8c62c220495be00a406c5f0936fda64c140109a4", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex 73104d6ca2..73414e48a7 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -658,9 +658,6 @@ public class Console implements Closeable {\n     if (query.getStatementText().length() > 0) {\n       writer().println(String.format(\"%-20s : %s\", \"SQL\", query.getStatementText()));\n     }\n-    if (query.getState().isPresent()) {\n-      writer().println(String.format(\"%-20s : %s\", \"Status\", query.getState().get()));\n-    }\n     if (!query.getKsqlHostQueryState().isEmpty()) {\n       writer().println(String.format(\n           \"%-20s : %s\", \"Host Query Status\",\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2OTQ3NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399369474", "body": "can we just use `KafkaStreams.State#valueOf` instead of this map?", "bodyText": "can we just use KafkaStreams.State#valueOf instead of this map?", "bodyHTML": "<p dir=\"auto\">can we just use <code>KafkaStreams.State#valueOf</code> instead of this map?</p>", "author": "agavra", "createdAt": "2020-03-27T15:58:52Z", "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java", "diffHunk": "@@ -46,6 +51,17 @@ private KsqlConstants() {\n   public static final String DEFAULT_AVRO_SCHEMA_FULL_NAME =\n           AVRO_SCHEMA_NAMESPACE + \".\" + AVRO_SCHEMA_NAME;\n \n+  public static final ImmutableMap<String, KafkaStreams.State>\n+      STRING_TO_KAFKA_STREAMS_STATE_MAPPING;\n+\n+  static {\n+    final  Map<String, KafkaStreams.State> stringToStateMapping = new HashMap<>();\n+    for (KafkaStreams.State state: KafkaStreams.State.values()) {\n+      stringToStateMapping.put(state.toString(), state);\n+    }\n+    STRING_TO_KAFKA_STREAMS_STATE_MAPPING = ImmutableMap.copyOf(stringToStateMapping);", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java b/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\nindex 690b45fa96..0f3ce1aeee 100644\n--- a/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\n+++ b/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\n", "chunk": "@@ -51,17 +46,6 @@ public final class KsqlConstants {\n   public static final String DEFAULT_AVRO_SCHEMA_FULL_NAME =\n           AVRO_SCHEMA_NAMESPACE + \".\" + AVRO_SCHEMA_NAME;\n \n-  public static final ImmutableMap<String, KafkaStreams.State>\n-      STRING_TO_KAFKA_STREAMS_STATE_MAPPING;\n-\n-  static {\n-    final  Map<String, KafkaStreams.State> stringToStateMapping = new HashMap<>();\n-    for (KafkaStreams.State state: KafkaStreams.State.values()) {\n-      stringToStateMapping.put(state.toString(), state);\n-    }\n-    STRING_TO_KAFKA_STREAMS_STATE_MAPPING = ImmutableMap.copyOf(stringToStateMapping);\n-  }\n-\n   /**\n    * Default time and date patterns\n    */\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java b/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\nindex 0f3ce1aeee..690b45fa96 100644\n--- a/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\n+++ b/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\n", "chunk": "@@ -46,6 +51,17 @@ public final class KsqlConstants {\n   public static final String DEFAULT_AVRO_SCHEMA_FULL_NAME =\n           AVRO_SCHEMA_NAMESPACE + \".\" + AVRO_SCHEMA_NAME;\n \n+  public static final ImmutableMap<String, KafkaStreams.State>\n+      STRING_TO_KAFKA_STREAMS_STATE_MAPPING;\n+\n+  static {\n+    final  Map<String, KafkaStreams.State> stringToStateMapping = new HashMap<>();\n+    for (KafkaStreams.State state: KafkaStreams.State.values()) {\n+      stringToStateMapping.put(state.toString(), state);\n+    }\n+    STRING_TO_KAFKA_STREAMS_STATE_MAPPING = ImmutableMap.copyOf(stringToStateMapping);\n+  }\n+\n   /**\n    * Default time and date patterns\n    */\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java b/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\nindex 690b45fa96..0f3ce1aeee 100644\n--- a/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\n+++ b/ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java\n", "chunk": "@@ -51,17 +46,6 @@ public final class KsqlConstants {\n   public static final String DEFAULT_AVRO_SCHEMA_FULL_NAME =\n           AVRO_SCHEMA_NAMESPACE + \".\" + AVRO_SCHEMA_NAME;\n \n-  public static final ImmutableMap<String, KafkaStreams.State>\n-      STRING_TO_KAFKA_STREAMS_STATE_MAPPING;\n-\n-  static {\n-    final  Map<String, KafkaStreams.State> stringToStateMapping = new HashMap<>();\n-    for (KafkaStreams.State state: KafkaStreams.State.values()) {\n-      stringToStateMapping.put(state.toString(), state);\n-    }\n-    STRING_TO_KAFKA_STREAMS_STATE_MAPPING = ImmutableMap.copyOf(stringToStateMapping);\n-  }\n-\n   /**\n    * Default time and date patterns\n    */\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2OTczMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399369732", "body": "nit: javadoc ;) ", "bodyText": "nit: javadoc ;)", "bodyHTML": "<p dir=\"auto\">nit: javadoc ;)</p>", "author": "agavra", "createdAt": "2020-03-27T15:59:15Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,12 @@\n       String sql\n   );\n \n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex bf2639325f..d943930df9 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -34,6 +34,13 @@ public interface SimpleKsqlClient {\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n   RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n", "next_change": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex d943930df9..a9e430a671 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -41,11 +36,10 @@ public interface SimpleKsqlClient {\n    * @param requestProperties the request metadata provided by the server\n    * @return the result of sql statement execution\n    */\n-  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+  RestResponse<KsqlEntityList> makeKsqlRequest(\n       URI serverEndPoint,\n       String sql,\n-      Map<String, ?> requestProperties\n-  );\n+      Map<String, ?> requestProperties);\n \n   /**\n    * Send pull query request to remote Ksql server.\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex a9e430a671..bf2639325f 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -29,17 +29,16 @@ import javax.annotation.concurrent.ThreadSafe;\n @ThreadSafe\n public interface SimpleKsqlClient {\n \n-  /**\n-   * Send a request to remote Ksql server.\n-   * @param serverEndPoint the remote destination\n-   * @param sql the sql statement\n-   * @param requestProperties the request metadata provided by the server\n-   * @return the result of sql statement execution\n-   */\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n+      URI serverEndPoint,\n+      String sql\n+  );\n+\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n-      Map<String, ?> requestProperties);\n+      Map<String, ?> requestProperties\n+  );\n \n   /**\n    * Send pull query request to remote Ksql server.\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex bf2639325f..d215f1663f 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -29,12 +29,14 @@ import javax.annotation.concurrent.ThreadSafe;\n @ThreadSafe\n public interface SimpleKsqlClient {\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n-      URI serverEndPoint,\n-      String sql\n-  );\n-\n-  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n       Map<String, ?> requestProperties\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM3MzI4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399373286", "body": "nit: up to you, but I would recommend replacing all of these `.forEach` calls with vanilla for-each loops. It will make the stack traces way more readable, error handling easier and debugging anything with remote calls a little simpler. the way it stands, I think we have four nested lambdas, which were really designed for stateless transforms", "bodyText": "nit: up to you, but I would recommend replacing all of these .forEach calls with vanilla for-each loops. It will make the stack traces way more readable, error handling easier and debugging anything with remote calls a little simpler. the way it stands, I think we have four nested lambdas, which were really designed for stateless transforms", "bodyHTML": "<p dir=\"auto\">nit: up to you, but I would recommend replacing all of these <code>.forEach</code> calls with vanilla for-each loops. It will make the stack traces way more readable, error handling easier and debugging anything with remote calls a little simpler. the way it stands, I think we have four nested lambdas, which were really designed for stateless transforms</p>", "author": "agavra", "createdAt": "2020-03-27T16:04:24Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()\n+            .makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+            .getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+            \n+            // If the query has already been discovered, update the KafkaStreamsStateCount object\n+            if (queryToRunningQuery.containsKey(queryId)) {\n+              q.getState().getState()\n+                  .forEach((state, count) ->", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3MjIxOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400472218", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-03-30T20:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM3MzI4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "35a707ccf27366ed8f44f71aa302c7159d3826ad", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex e6a1aa6c6e..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,36 +93,48 @@ public final class ListQueriesExecutor {\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      hosts.forEach(hostInfo -> {\n-        final KsqlEntityList response = serviceContext.getKsqlClient()\n-            .makeKsqlRequestWithRequestProperties(\n-                ServerUtil.buildRemoteUri(\n-                    sessionProperties.getLocalUrl(),\n-                    hostInfo.host(),\n-                    hostInfo.port()\n-                ),\n-                statement.getStatementText(),\n-                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-            .getResponse();\n-\n-        response.forEach(remoteQueries -> {\n-          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n-          queries.forEach(q -> {\n-            final String queryId = q.getId().toString();\n-            \n-            // If the query has already been discovered, update the KafkaStreamsStateCount object\n-            if (queryToRunningQuery.containsKey(queryId)) {\n-              q.getState().getState()\n-                  .forEach((state, count) ->\n-                      queryToRunningQuery\n-                          .get(queryId)\n-                          .getState()\n-                          .updateStateCount(state, count));\n-            } else {\n-              queryToRunningQuery.put(queryId, q);\n-            }\n-          });\n-        });\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n+        }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n       });\n     }\n \n", "next_change": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..8f3cb99da9 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,56 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry : q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 8f3cb99da9..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,56 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (remoteHosts.size() != 0) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry : q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4MjQ0MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399382440", "body": "for SerDe of the maps, I would recommend using:\r\n```java\r\n    Map<String, String> pairs = Splitter.on(\",\").withKeyValueSeparator(\":\").split(serialized);\r\n    state =  pairs.entrySet().stream()\r\n        .collect(Collectors.toMap(\r\n            e -> KafkaStreams.State.valueOf(e.getKey()),\r\n            e -> Integer.parseInt(e.getValue()),\r\n            (v1, v2) -> {throw new IllegalStateException(\"duplicate keys\")},\r\n            TreeMap::new\r\n        ));\r\n```\r\nAnd you can use the correspond method to serialize: `Joiner.on(\",\").withKeyValueSeparator(\":\").join(values);`", "bodyText": "for SerDe of the maps, I would recommend using:\n    Map<String, String> pairs = Splitter.on(\",\").withKeyValueSeparator(\":\").split(serialized);\n    state =  pairs.entrySet().stream()\n        .collect(Collectors.toMap(\n            e -> KafkaStreams.State.valueOf(e.getKey()),\n            e -> Integer.parseInt(e.getValue()),\n            (v1, v2) -> {throw new IllegalStateException(\"duplicate keys\")},\n            TreeMap::new\n        ));\nAnd you can use the correspond method to serialize: Joiner.on(\",\").withKeyValueSeparator(\":\").join(values);", "bodyHTML": "<p dir=\"auto\">for SerDe of the maps, I would recommend using:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"    Map&lt;String, String&gt; pairs = Splitter.on(&quot;,&quot;).withKeyValueSeparator(&quot;:&quot;).split(serialized);\n    state =  pairs.entrySet().stream()\n        .collect(Collectors.toMap(\n            e -&gt; KafkaStreams.State.valueOf(e.getKey()),\n            e -&gt; Integer.parseInt(e.getValue()),\n            (v1, v2) -&gt; {throw new IllegalStateException(&quot;duplicate keys&quot;)},\n            TreeMap::new\n        ));\"><pre>    <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, <span class=\"pl-smi\">String</span>&gt;</span> pairs <span class=\"pl-k\">=</span> <span class=\"pl-smi\">Splitter</span><span class=\"pl-k\">.</span>on(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>)<span class=\"pl-k\">.</span>withKeyValueSeparator(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>:<span class=\"pl-pds\">\"</span></span>)<span class=\"pl-k\">.</span>split(serialized);\n    state <span class=\"pl-k\">=</span>  pairs<span class=\"pl-k\">.</span>entrySet()<span class=\"pl-k\">.</span>stream()\n        .collect(<span class=\"pl-smi\">Collectors</span><span class=\"pl-k\">.</span>toMap(\n            e <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-smi\">KafkaStreams</span><span class=\"pl-k\">.</span><span class=\"pl-smi\">State</span><span class=\"pl-k\">.</span>valueOf(e<span class=\"pl-k\">.</span>getKey()),\n            e <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-smi\">Integer</span><span class=\"pl-k\">.</span>parseInt(e<span class=\"pl-k\">.</span>getValue()),\n            (v1, v2) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {<span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IllegalStateException</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>duplicate keys<span class=\"pl-pds\">\"</span></span>)},\n            <span class=\"pl-smi\">TreeMap</span><span class=\"pl-k\">::</span><span class=\"pl-k\">new</span>\n        ));</pre></div>\n<p dir=\"auto\">And you can use the correspond method to serialize: <code>Joiner.on(\",\").withKeyValueSeparator(\":\").join(values);</code></p>", "author": "agavra", "createdAt": "2020-03-27T16:18:20Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlConstants;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n+\n+  public KafkaStreamsStateCount() {\n+    this.state = returnTreeMap();\n+  }\n+\n+  @JsonCreator\n+  public KafkaStreamsStateCount(final String serializedPair) {\n+    final String [] parts = serializedPair.split(\",\");", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MTQ0Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401361443", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-01T05:19:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4MjQ0MA=="}], "type": "inlineReview", "revised_code": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 2993d3a777..f9a742237e 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -35,17 +33,17 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a TreeMap so toString() will always return the same string\n-  private final TreeMap<KafkaStreams.State, Integer> state;\n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnTreeMap();\n+    this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n     final String [] parts = serializedPair.split(\",\");\n-    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n+    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n     for (String stateCount : parts) {\n       final String[] split = stateCount.split(\":\");\n       if (split.length != 2) {\n", "next_change": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex f9a742237e..81246bdf25 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -42,30 +44,16 @@ public class KafkaStreamsStateCount {\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n-    final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n-    for (String stateCount : parts) {\n-      final String[] split = stateCount.split(\":\");\n-      if (split.length != 2) {\n-        throw new KsqlException(\n-            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair);\n-      }\n-\n-      final String currentState = split[0].trim();\n-\n-      try {\n-        final int count = Integer.parseInt(split[1]);\n-        deserializedKafkaStreamsStateCount.put(\n-            KafkaStreams.State.valueOf(currentState), count);\n-      } catch (final Exception e) {\n-        throw new KsqlException(\n-            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair, e);\n-      }\n-    }\n-\n-    this.state = deserializedKafkaStreamsStateCount;\n+    final Map<String, String> pairs =\n+        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n+    this.state = pairs.entrySet().stream().collect(\n+        Collectors.toMap(\n+            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n+            e -> Integer.parseInt(e.getValue()),\n+            (k1, k2) -> {\n+              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n+            },\n+            () -> new EnumMap<>(KafkaStreams.State.class)));\n   }\n \n   public void updateStateCount(final String state, final int change) {\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 81246bdf25..2993d3a777 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -35,29 +35,53 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a EnumMap so toString() will always return the same string\n-  private final EnumMap<KafkaStreams.State, Integer> state;\n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnEnumMap();\n+    this.state = returnTreeMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n-    final Map<String, String> pairs =\n-        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n-    this.state = pairs.entrySet().stream().collect(\n-        Collectors.toMap(\n-            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n-            e -> Integer.parseInt(e.getValue()),\n-            (k1, k2) -> {\n-              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n-            },\n-            () -> new EnumMap<>(KafkaStreams.State.class)));\n+    final String [] parts = serializedPair.split(\",\");\n+    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n+    for (String stateCount : parts) {\n+      final String[] split = stateCount.split(\":\");\n+      if (split.length != 2) {\n+        throw new KsqlException(\n+            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n+                + serializedPair);\n+      }\n+\n+      final String currentState = split[0].trim();\n+      if (!KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.containsKey(currentState)) {\n+        throw new KsqlException(\"Invalid KafkaStreams State present: \" + currentState);\n+      }\n+\n+      try {\n+        final int count = Integer.parseInt(split[1]);\n+        deserializedKafkaStreamsStateCount.put(\n+            KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.get(currentState), count);\n+      } catch (final Exception e) {\n+        throw new KsqlException(\n+            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n+                + serializedPair, e);\n+      }\n+    }\n+\n+    this.state = deserializedKafkaStreamsStateCount;\n+  }\n+\n+  private void checkValidState(final String stringState) {\n+    if (!KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.containsKey(stringState)) {\n+      throw new KsqlException(\"Invalid KafkaStreams.State: \" + stringState);\n+    }\n   }\n \n   public void updateStateCount(final String state, final int change) {\n-    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+    checkValidState(state);\n+    updateStateCount(KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.get(state), change);\n   }\n \n   public void updateStateCount(final KafkaStreams.State state, final int change) {\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 2993d3a777..f9a742237e 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -73,15 +68,8 @@ public class KafkaStreamsStateCount {\n     this.state = deserializedKafkaStreamsStateCount;\n   }\n \n-  private void checkValidState(final String stringState) {\n-    if (!KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.containsKey(stringState)) {\n-      throw new KsqlException(\"Invalid KafkaStreams.State: \" + stringState);\n-    }\n-  }\n-\n   public void updateStateCount(final String state, final int change) {\n-    checkValidState(state);\n-    updateStateCount(KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.get(state), change);\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n   }\n \n   public void updateStateCount(final KafkaStreams.State state, final int change) {\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nsimilarity index 58%\nrename from ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nrename to ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nindex f9a742237e..64d6143d85 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\n", "chunk": "@@ -31,41 +33,27 @@ import org.apache.kafka.streams.KafkaStreams;\n  * across multiple servers. Used in {@link RunningQuery}.\n  */\n @JsonIgnoreProperties(ignoreUnknown = true)\n-public class KafkaStreamsStateCount {\n+public class QueryStateCount {\n   \n   // Use a EnumMap so toString() will always return the same string\n   private final EnumMap<KafkaStreams.State, Integer> state;\n \n-  public KafkaStreamsStateCount() {\n+  public QueryStateCount() {\n     this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n-  public KafkaStreamsStateCount(final String serializedPair) {\n-    final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n-    for (String stateCount : parts) {\n-      final String[] split = stateCount.split(\":\");\n-      if (split.length != 2) {\n-        throw new KsqlException(\n-            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair);\n-      }\n-\n-      final String currentState = split[0].trim();\n-\n-      try {\n-        final int count = Integer.parseInt(split[1]);\n-        deserializedKafkaStreamsStateCount.put(\n-            KafkaStreams.State.valueOf(currentState), count);\n-      } catch (final Exception e) {\n-        throw new KsqlException(\n-            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair, e);\n-      }\n-    }\n-\n-    this.state = deserializedKafkaStreamsStateCount;\n+  public QueryStateCount(final String serializedPair) {\n+    final Map<String, String> pairs =\n+        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n+    this.state = pairs.entrySet().stream().collect(\n+        Collectors.toMap(\n+            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n+            e -> Integer.parseInt(e.getValue()),\n+            (k1, k2) -> {\n+              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n+            },\n+            () -> new EnumMap<>(KafkaStreams.State.class)));\n   }\n \n   public void updateStateCount(final String state, final int change) {\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4NzMyNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399387325", "body": "a lot of this seems duplicated from above, can we simplify it?", "bodyText": "a lot of this seems duplicated from above, can we simplify it?", "bodyHTML": "<p dir=\"auto\">a lot of this seems duplicated from above, can we simplify it?</p>", "author": "agavra", "createdAt": "2020-03-27T16:25:28Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()\n+            .makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+            .getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+            \n+            // If the query has already been discovered, update the KafkaStreamsStateCount object\n+            if (queryToRunningQuery.containsKey(queryId)) {\n+              q.getState().getState()\n+                  .forEach((state, count) ->\n+                      queryToRunningQuery\n+                          .get(queryId)\n+                          .getState()\n+                          .updateStateCount(state, count));\n+            } else {\n+              queryToRunningQuery.put(queryId, q);\n+            }\n+          });\n+        });\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ListQueries listQueries,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =\n+        queryDescriptions.stream().collect(\n+            Collectors.toMap(\n+                query -> query.getId().toString(),\n+                query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = \n+            serviceContext.getKsqlClient().makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true)\n+        ).getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<QueryDescription> queries =\n+              ((QueryDescriptionList) remoteQueries).getQueryDescriptions();\n+\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+\n+            // If the query has already been discovered, add to the ksqlQueryHostState mapping", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "35a707ccf27366ed8f44f71aa302c7159d3826ad", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex e6a1aa6c6e..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -157,38 +171,48 @@ public final class ListQueriesExecutor {\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      hosts.forEach(hostInfo -> {\n-        final KsqlEntityList response = \n-            serviceContext.getKsqlClient().makeKsqlRequestWithRequestProperties(\n-                ServerUtil.buildRemoteUri(\n-                    sessionProperties.getLocalUrl(),\n-                    hostInfo.host(),\n-                    hostInfo.port()\n-                ),\n-                statement.getStatementText(),\n-                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true)\n-        ).getResponse();\n-\n-        response.forEach(remoteQueries -> {\n-          final List<QueryDescription> queries =\n-              ((QueryDescriptionList) remoteQueries).getQueryDescriptions();\n-\n-          queries.forEach(q -> {\n-            final String queryId = q.getId().toString();\n-\n-            // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-            if (queryToQueryDescription.containsKey(queryId)) {\n-              q.getKsqlHostQueryState()\n-                  .forEach((host, state) ->\n-                      queryToQueryDescription\n-                          .get(queryId)\n-                          .getKsqlHostQueryState()\n-                          .put(host, state));\n-            } else {\n-              queryToQueryDescription.put(queryId, q);\n-            }\n-          });\n-        });\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureQueryDescriptions.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n+          new ConcurrentLinkedQueue<>();\n+      futureQueryDescriptions.forEach(future -> {\n+        try {\n+          remoteQueryDescriptions.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n+        }\n+      });\n+\n+      remoteQueryDescriptions.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+        if (queryToQueryDescription.containsKey(queryId)) {\n+          q.getKsqlHostQueryState()\n+              .forEach((host, state) ->\n+                  queryToQueryDescription\n+                      .get(queryId)\n+                      .getKsqlHostQueryState()\n+                      .put(host, state));\n+        } else {\n+          queryToQueryDescription.put(queryId, q);\n+        }\n       });\n     }\n \n", "next_change": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..8f3cb99da9 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -166,54 +170,56 @@ public final class ListQueriesExecutor {\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureQueryDescriptions.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n-          new ConcurrentLinkedQueue<>();\n-      futureQueryDescriptions.forEach(future -> {\n-        try {\n-          remoteQueryDescriptions.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureQueryDescriptions.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n+          }));\n         }\n-      });\n-\n-      remoteQueryDescriptions.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-        if (queryToQueryDescription.containsKey(queryId)) {\n-          q.getKsqlHostQueryState()\n-              .forEach((host, state) ->\n-                  queryToQueryDescription\n-                      .get(queryId)\n-                      .getKsqlHostQueryState()\n-                      .put(host, state));\n-        } else {\n-          queryToQueryDescription.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n+                new ConcurrentLinkedQueue<>();\n+        futureQueryDescriptions.forEach(future -> {\n+          try {\n+            remoteQueryDescriptions.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (QueryDescription q : remoteQueryDescriptions) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+          if (queryToQueryDescription.containsKey(queryId)) {\n+            for (Map.Entry<KsqlHostInfoEntity, String> entry : q.getKsqlHostQueryState().entrySet()) {\n+              queryToQueryDescription\n+                  .get(queryId)\n+                  .getKsqlHostQueryState()\n+                  .put(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToQueryDescription.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new QueryDescriptionList(\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 8f3cb99da9..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -170,56 +166,54 @@ public final class ListQueriesExecutor {\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      if (remoteHosts.size() != 0) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureQueryDescriptions.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n+          new ConcurrentLinkedQueue<>();\n+      futureQueryDescriptions.forEach(future -> {\n+        try {\n+          remoteQueryDescriptions.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-\n-        final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n-                new ConcurrentLinkedQueue<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry : q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToQueryDescription.put(queryId, q);\n-          }\n+      });\n+\n+      remoteQueryDescriptions.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+        if (queryToQueryDescription.containsKey(queryId)) {\n+          q.getKsqlHostQueryState()\n+              .forEach((host, state) ->\n+                  queryToQueryDescription\n+                      .get(queryId)\n+                      .getKsqlHostQueryState()\n+                      .put(host, state));\n+        } else {\n+          queryToQueryDescription.put(queryId, q);\n         }\n-      }\n+      });\n     }\n \n     return Optional.of(new QueryDescriptionList(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -166,54 +171,57 @@ public final class ListQueriesExecutor {\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureQueryDescriptions.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n-          new ConcurrentLinkedQueue<>();\n-      futureQueryDescriptions.forEach(future -> {\n-        try {\n-          remoteQueryDescriptions.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureQueryDescriptions.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n+          }));\n         }\n-      });\n-\n-      remoteQueryDescriptions.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-        if (queryToQueryDescription.containsKey(queryId)) {\n-          q.getKsqlHostQueryState()\n-              .forEach((host, state) ->\n-                  queryToQueryDescription\n-                      .get(queryId)\n-                      .getKsqlHostQueryState()\n-                      .put(host, state));\n-        } else {\n-          queryToQueryDescription.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n+                new ConcurrentLinkedQueue<>();\n+        futureQueryDescriptions.forEach(future -> {\n+          try {\n+            remoteQueryDescriptions.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (QueryDescription q : remoteQueryDescriptions) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+          if (queryToQueryDescription.containsKey(queryId)) {\n+            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+                q.getKsqlHostQueryState().entrySet()) {\n+              queryToQueryDescription\n+                  .get(queryId)\n+                  .getKsqlHostQueryState()\n+                  .put(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToQueryDescription.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new QueryDescriptionList(\n", "next_change": {"commit": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..2c9408b3c2 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -226,6 +234,6 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToQueryDescription.values())));\n+       queryToQueryDescription.values()));\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 2c9408b3c2..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -234,6 +231,6 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-       queryToQueryDescription.values()));\n+        queryToQueryDescription.values()));\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4NzY3Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399387677", "body": "what happens if there's an error with this? also I believe we have an `async` execute call on ksql client. Can we use that instead so that we don't handle them one at a time? (as your comment in the description mentions)", "bodyText": "what happens if there's an error with this? also I believe we have an async execute call on ksql client. Can we use that instead so that we don't handle them one at a time? (as your comment in the description mentions)", "bodyHTML": "<p dir=\"auto\">what happens if there's an error with this? also I believe we have an <code>async</code> execute call on ksql client. Can we use that instead so that we don't handle them one at a time? (as your comment in the description mentions)</p>", "author": "agavra", "createdAt": "2020-03-27T16:26:03Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "35a707ccf27366ed8f44f71aa302c7159d3826ad", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex e6a1aa6c6e..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,36 +93,48 @@ public final class ListQueriesExecutor {\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      hosts.forEach(hostInfo -> {\n-        final KsqlEntityList response = serviceContext.getKsqlClient()\n-            .makeKsqlRequestWithRequestProperties(\n-                ServerUtil.buildRemoteUri(\n-                    sessionProperties.getLocalUrl(),\n-                    hostInfo.host(),\n-                    hostInfo.port()\n-                ),\n-                statement.getStatementText(),\n-                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-            .getResponse();\n-\n-        response.forEach(remoteQueries -> {\n-          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n-          queries.forEach(q -> {\n-            final String queryId = q.getId().toString();\n-            \n-            // If the query has already been discovered, update the KafkaStreamsStateCount object\n-            if (queryToRunningQuery.containsKey(queryId)) {\n-              q.getState().getState()\n-                  .forEach((state, count) ->\n-                      queryToRunningQuery\n-                          .get(queryId)\n-                          .getState()\n-                          .updateStateCount(state, count));\n-            } else {\n-              queryToRunningQuery.put(queryId, q);\n-            }\n-          });\n-        });\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n+        }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n       });\n     }\n \n", "next_change": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..8f3cb99da9 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,56 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry : q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 8f3cb99da9..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,56 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (remoteHosts.size() != 0) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry : q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MDQ1NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399390454", "body": "instead of actually spinning up a rest app, which takes forever and probably tests more than we want to test - can we make this test mock out any network communication? I think adding an integration for this is overkill as it's a relatively minor feature and we'd be testing way more than we need to", "bodyText": "instead of actually spinning up a rest app, which takes forever and probably tests more than we want to test - can we make this test mock out any network communication? I think adding an integration for this is overkill as it's a relatively minor feature and we'd be testing way more than we need to", "bodyHTML": "<p dir=\"auto\">instead of actually spinning up a rest app, which takes forever and probably tests more than we want to test - can we make this test mock out any network communication? I think adding an integration for this is overkill as it's a relatively minor feature and we'd be testing way more than we need to</p>", "author": "agavra", "createdAt": "2020-03-27T16:30:12Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMjUxOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400822518", "bodyText": "I actually think this is a worthwhile test, (replying to @agavra's comment). We need to test somewhere that two nodes can actually talk to each other to resolve the full list of states.  The more we mock out the less sure we are that this all functionally hangs together.\nAt the moment we don't have some centralised was of communicating between nodes with its own set of tests.  If we did, then I'd agree with this test testing too much.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:58:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MDQ1NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MTU1Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399391553", "body": "can we test the exceptional cases here as well? and follow `Given/When/Then` for all tests?", "bodyText": "can we test the exceptional cases here as well? and follow Given/When/Then for all tests?", "bodyHTML": "<p dir=\"auto\">can we test the exceptional cases here as well? and follow <code>Given/When/Then</code> for all tests?</p>", "author": "agavra", "createdAt": "2020-03-27T16:32:02Z", "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.ksql.util.KsqlException;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@SuppressWarnings(\"SameParameterValue\")\n+public class KafkaStreamsStateCountTest {\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  \n+  @Before\n+  public void setup() {\n+    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+  }\n+\n+  @Test\n+  public void shouldUpdateExistingStateCount() {\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    assertThat(\n+        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        is(2));\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n+    assertThat(\n+        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        is(6));\n+  }\n+\n+  @Test\n+  public void shouldToString() {\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    assertThat(\n+        kafkaStreamsStateCount.toString(),\n+        is(\"RUNNING:2\"));\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n+    assertThat(\n+        kafkaStreamsStateCount.toString(),\n+        is(\"NOT_RUNNING:1, RUNNING:2\"));\n+  }\n+\n+  @Test\n+  public void shouldConvertStringToKafkaStreamsStateCount() {", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nindex 5b9cb28abf..fea38ac4b0 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n", "chunk": "@@ -58,7 +56,7 @@ public class KafkaStreamsStateCountTest {\n     kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n     assertThat(\n         kafkaStreamsStateCount.toString(),\n-        is(\"NOT_RUNNING:1, RUNNING:2\"));\n+        is(\"RUNNING:2, NOT_RUNNING:1\"));\n   }\n \n   @Test\n", "next_change": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nindex fea38ac4b0..27c64f59e9 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n", "chunk": "@@ -56,32 +56,42 @@ public class KafkaStreamsStateCountTest {\n     kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n     assertThat(\n         kafkaStreamsStateCount.toString(),\n-        is(\"RUNNING:2, NOT_RUNNING:1\"));\n+        is(\"RUNNING:2,NOT_RUNNING:1\"));\n   }\n \n   @Test\n   public void shouldConvertStringToKafkaStreamsStateCount() {\n+    // Given:\n     final String testString = \"REBALANCING:4, ERROR:1,    RUNNING:2\";\n+    \n+    // When:\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(testString);\n+    \n+    // Then:\n     final Map<KafkaStreams.State, Integer> state = kafkaStreamsStateCount.getState();\n     assertThat(state.get(KafkaStreams.State.REBALANCING), is(4));\n     assertThat(state.get(KafkaStreams.State.ERROR), is(1));\n     assertThat(state.get(KafkaStreams.State.RUNNING), is(2));\n-    assertThat(kafkaStreamsStateCount.toString(), is(\"REBALANCING:4, RUNNING:2, ERROR:1\"));\n+    assertThat(kafkaStreamsStateCount.toString(), is(\"REBALANCING:4,RUNNING:2,ERROR:1\"));\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidFormat() {\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:2:2\");\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidCount() {\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:q\");\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidState() {\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(\"other state:2\");\n   }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void shouldThrowIllegalArgumentExceptionIfDuplicateState() {\n+    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:4,RUNNING:2,\");\n+  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nindex 27c64f59e9..5b9cb28abf 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n", "chunk": "@@ -56,42 +58,32 @@ public class KafkaStreamsStateCountTest {\n     kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n     assertThat(\n         kafkaStreamsStateCount.toString(),\n-        is(\"RUNNING:2,NOT_RUNNING:1\"));\n+        is(\"NOT_RUNNING:1, RUNNING:2\"));\n   }\n \n   @Test\n   public void shouldConvertStringToKafkaStreamsStateCount() {\n-    // Given:\n     final String testString = \"REBALANCING:4, ERROR:1,    RUNNING:2\";\n-    \n-    // When:\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(testString);\n-    \n-    // Then:\n     final Map<KafkaStreams.State, Integer> state = kafkaStreamsStateCount.getState();\n     assertThat(state.get(KafkaStreams.State.REBALANCING), is(4));\n     assertThat(state.get(KafkaStreams.State.ERROR), is(1));\n     assertThat(state.get(KafkaStreams.State.RUNNING), is(2));\n-    assertThat(kafkaStreamsStateCount.toString(), is(\"REBALANCING:4,RUNNING:2,ERROR:1\"));\n+    assertThat(kafkaStreamsStateCount.toString(), is(\"ERROR:1, REBALANCING:4, RUNNING:2\"));\n   }\n \n-  @Test(expected = Exception.class)\n+  @Test(expected = KsqlException.class)\n   public void shouldThrowExceptionIfInvalidFormat() {\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:2:2\");\n   }\n \n-  @Test(expected = Exception.class)\n+  @Test(expected = KsqlException.class)\n   public void shouldThrowExceptionIfInvalidCount() {\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:q\");\n   }\n \n-  @Test(expected = Exception.class)\n+  @Test(expected = KsqlException.class)\n   public void shouldThrowExceptionIfInvalidState() {\n     kafkaStreamsStateCount = new KafkaStreamsStateCount(\"other state:2\");\n   }\n-\n-  @Test(expected = IllegalArgumentException.class)\n-  public void shouldThrowIllegalArgumentExceptionIfDuplicateState() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:4,RUNNING:2,\");\n-  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\nsimilarity index 53%\nrename from ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nrename to ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\nindex 5b9cb28abf..50217f82b3 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\n", "chunk": "@@ -15,75 +15,82 @@\n \n package io.confluent.ksql.rest.entity;\n \n-import static org.hamcrest.CoreMatchers.containsString;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.is;\n \n-import io.confluent.ksql.util.KsqlException;\n import org.apache.kafka.streams.KafkaStreams;\n import org.junit.Before;\n import org.junit.Test;\n \n-import java.util.HashMap;\n import java.util.Map;\n \n @SuppressWarnings(\"SameParameterValue\")\n-public class KafkaStreamsStateCountTest {\n+public class QueryStateCountTest {\n \n-  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  QueryStateCount queryStateCount;\n   \n   @Before\n   public void setup() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+    queryStateCount = new QueryStateCount();\n   }\n \n   @Test\n   public void shouldUpdateExistingStateCount() {\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    queryStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n     assertThat(\n-        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        queryStateCount.getState().get(KafkaStreams.State.RUNNING),\n         is(2));\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n+    queryStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n     assertThat(\n-        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        queryStateCount.getState().get(KafkaStreams.State.RUNNING),\n         is(6));\n   }\n \n   @Test\n   public void shouldToString() {\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    queryStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n     assertThat(\n-        kafkaStreamsStateCount.toString(),\n+        queryStateCount.toString(),\n         is(\"RUNNING:2\"));\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n+    queryStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n     assertThat(\n-        kafkaStreamsStateCount.toString(),\n-        is(\"NOT_RUNNING:1, RUNNING:2\"));\n+        queryStateCount.toString(),\n+        is(\"RUNNING:2,NOT_RUNNING:1\"));\n   }\n \n   @Test\n   public void shouldConvertStringToKafkaStreamsStateCount() {\n+    // Given:\n     final String testString = \"REBALANCING:4, ERROR:1,    RUNNING:2\";\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(testString);\n-    final Map<KafkaStreams.State, Integer> state = kafkaStreamsStateCount.getState();\n+    \n+    // When:\n+    queryStateCount = new QueryStateCount(testString);\n+    \n+    // Then:\n+    final Map<KafkaStreams.State, Integer> state = queryStateCount.getState();\n     assertThat(state.get(KafkaStreams.State.REBALANCING), is(4));\n     assertThat(state.get(KafkaStreams.State.ERROR), is(1));\n     assertThat(state.get(KafkaStreams.State.RUNNING), is(2));\n-    assertThat(kafkaStreamsStateCount.toString(), is(\"ERROR:1, REBALANCING:4, RUNNING:2\"));\n+    assertThat(queryStateCount.toString(), is(\"REBALANCING:4,RUNNING:2,ERROR:1\"));\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidFormat() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:2:2\");\n+    queryStateCount = new QueryStateCount(\"RUNNING:2:2\");\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidCount() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:q\");\n+    queryStateCount = new QueryStateCount(\"RUNNING:q\");\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidState() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"other state:2\");\n+    queryStateCount = new QueryStateCount(\"other state:2\");\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void shouldThrowIllegalArgumentExceptionIfDuplicateState() {\n+    queryStateCount = new QueryStateCount(\"RUNNING:4,RUNNING:2,\");\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MjIxMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399392212", "body": "I believe you can use `EnumMap` here - as the order is deterministic based on the ordering of the State enum ordinal", "bodyText": "I believe you can use EnumMap here - as the order is deterministic based on the ordering of the State enum ordinal", "bodyHTML": "<p dir=\"auto\">I believe you can use <code>EnumMap</code> here - as the order is deterministic based on the ordering of the State enum ordinal</p>", "author": "agavra", "createdAt": "2020-03-27T16:33:03Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlConstants;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "15fc917b558b649851a97563869bc2b80ec8d0a0", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 2993d3a777..f9a742237e 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -35,17 +33,17 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a TreeMap so toString() will always return the same string\n-  private final TreeMap<KafkaStreams.State, Integer> state;\n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnTreeMap();\n+    this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n     final String [] parts = serializedPair.split(\",\");\n-    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n+    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n     for (String stateCount : parts) {\n       final String[] split = stateCount.split(\":\");\n       if (split.length != 2) {\n", "next_change": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex f9a742237e..81246bdf25 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -42,30 +44,16 @@ public class KafkaStreamsStateCount {\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n-    final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n-    for (String stateCount : parts) {\n-      final String[] split = stateCount.split(\":\");\n-      if (split.length != 2) {\n-        throw new KsqlException(\n-            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair);\n-      }\n-\n-      final String currentState = split[0].trim();\n-\n-      try {\n-        final int count = Integer.parseInt(split[1]);\n-        deserializedKafkaStreamsStateCount.put(\n-            KafkaStreams.State.valueOf(currentState), count);\n-      } catch (final Exception e) {\n-        throw new KsqlException(\n-            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair, e);\n-      }\n-    }\n-\n-    this.state = deserializedKafkaStreamsStateCount;\n+    final Map<String, String> pairs =\n+        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n+    this.state = pairs.entrySet().stream().collect(\n+        Collectors.toMap(\n+            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n+            e -> Integer.parseInt(e.getValue()),\n+            (k1, k2) -> {\n+              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n+            },\n+            () -> new EnumMap<>(KafkaStreams.State.class)));\n   }\n \n   public void updateStateCount(final String state, final int change) {\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 81246bdf25..2993d3a777 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -35,29 +35,53 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a EnumMap so toString() will always return the same string\n-  private final EnumMap<KafkaStreams.State, Integer> state;\n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnEnumMap();\n+    this.state = returnTreeMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n-    final Map<String, String> pairs =\n-        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n-    this.state = pairs.entrySet().stream().collect(\n-        Collectors.toMap(\n-            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n-            e -> Integer.parseInt(e.getValue()),\n-            (k1, k2) -> {\n-              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n-            },\n-            () -> new EnumMap<>(KafkaStreams.State.class)));\n+    final String [] parts = serializedPair.split(\",\");\n+    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n+    for (String stateCount : parts) {\n+      final String[] split = stateCount.split(\":\");\n+      if (split.length != 2) {\n+        throw new KsqlException(\n+            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n+                + serializedPair);\n+      }\n+\n+      final String currentState = split[0].trim();\n+      if (!KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.containsKey(currentState)) {\n+        throw new KsqlException(\"Invalid KafkaStreams State present: \" + currentState);\n+      }\n+\n+      try {\n+        final int count = Integer.parseInt(split[1]);\n+        deserializedKafkaStreamsStateCount.put(\n+            KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.get(currentState), count);\n+      } catch (final Exception e) {\n+        throw new KsqlException(\n+            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n+                + serializedPair, e);\n+      }\n+    }\n+\n+    this.state = deserializedKafkaStreamsStateCount;\n+  }\n+\n+  private void checkValidState(final String stringState) {\n+    if (!KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.containsKey(stringState)) {\n+      throw new KsqlException(\"Invalid KafkaStreams.State: \" + stringState);\n+    }\n   }\n \n   public void updateStateCount(final String state, final int change) {\n-    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+    checkValidState(state);\n+    updateStateCount(KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.get(state), change);\n   }\n \n   public void updateStateCount(final KafkaStreams.State state, final int change) {\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 2993d3a777..f9a742237e 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -73,15 +68,8 @@ public class KafkaStreamsStateCount {\n     this.state = deserializedKafkaStreamsStateCount;\n   }\n \n-  private void checkValidState(final String stringState) {\n-    if (!KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.containsKey(stringState)) {\n-      throw new KsqlException(\"Invalid KafkaStreams.State: \" + stringState);\n-    }\n-  }\n-\n   public void updateStateCount(final String state, final int change) {\n-    checkValidState(state);\n-    updateStateCount(KsqlConstants.STRING_TO_KAFKA_STREAMS_STATE_MAPPING.get(state), change);\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n   }\n \n   public void updateStateCount(final KafkaStreams.State state, final int change) {\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nsimilarity index 58%\nrename from ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nrename to ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nindex f9a742237e..64d6143d85 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\n", "chunk": "@@ -31,41 +33,27 @@ import org.apache.kafka.streams.KafkaStreams;\n  * across multiple servers. Used in {@link RunningQuery}.\n  */\n @JsonIgnoreProperties(ignoreUnknown = true)\n-public class KafkaStreamsStateCount {\n+public class QueryStateCount {\n   \n   // Use a EnumMap so toString() will always return the same string\n   private final EnumMap<KafkaStreams.State, Integer> state;\n \n-  public KafkaStreamsStateCount() {\n+  public QueryStateCount() {\n     this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n-  public KafkaStreamsStateCount(final String serializedPair) {\n-    final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n-    for (String stateCount : parts) {\n-      final String[] split = stateCount.split(\":\");\n-      if (split.length != 2) {\n-        throw new KsqlException(\n-            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair);\n-      }\n-\n-      final String currentState = split[0].trim();\n-\n-      try {\n-        final int count = Integer.parseInt(split[1]);\n-        deserializedKafkaStreamsStateCount.put(\n-            KafkaStreams.State.valueOf(currentState), count);\n-      } catch (final Exception e) {\n-        throw new KsqlException(\n-            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair, e);\n-      }\n-    }\n-\n-    this.state = deserializedKafkaStreamsStateCount;\n+  public QueryStateCount(final String serializedPair) {\n+    final Map<String, String> pairs =\n+        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n+    this.state = pairs.entrySet().stream().collect(\n+        Collectors.toMap(\n+            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n+            e -> Integer.parseInt(e.getValue()),\n+            (k1, k2) -> {\n+              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n+            },\n+            () -> new EnumMap<>(KafkaStreams.State.class)));\n   }\n \n   public void updateStateCount(final String state, final int change) {\n", "next_change": null}]}}]}}]}}]}}]}}, {"oid": "35a707ccf27366ed8f44f71aa302c7159d3826ad", "url": "https://github.com/confluentinc/ksql/commit/35a707ccf27366ed8f44f71aa302c7159d3826ad", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-27T18:41:31Z", "type": "forcePushed"}, {"oid": "15fc917b558b649851a97563869bc2b80ec8d0a0", "url": "https://github.com/confluentinc/ksql/commit/15fc917b558b649851a97563869bc2b80ec8d0a0", "message": "address comments", "committedDate": "2020-03-29T16:31:38Z", "type": "forcePushed"}, {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "url": "https://github.com/confluentinc/ksql/commit/e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "message": "address comments", "committedDate": "2020-03-30T17:33:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDQwNA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400794404", "body": "nit: `toString` is superfluous here.", "bodyText": "nit: toString is superfluous here.", "bodyHTML": "<p dir=\"auto\">nit: <code>toString</code> is superfluous here.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:08:36Z", "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -530,7 +530,7 @@ private void printQueries(\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState().orElse(\"N/A\")\n+            + \" (\" + writeQuery.getState().toString()", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex 174677686c..fb4c24357c 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -530,7 +532,7 @@ public class Console implements Closeable {\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState().toString()\n+            + \" (\" + writeQuery.getState()\n             + \") : \" + writeQuery.getQuerySingleLine());\n       }\n       writer().println(\"\\nFor query topology and execution plan please run: EXPLAIN <QueryId>\");\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex fb4c24357c..d9999010b9 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -532,7 +532,7 @@ public class Console implements Closeable {\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState()\n+            + \" (\" + writeQuery.getState().toString()\n             + \") : \" + writeQuery.getQuerySingleLine());\n       }\n       writer().println(\"\\nFor query topology and execution plan please run: EXPLAIN <QueryId>\");\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex d9999010b9..fb4c24357c 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -532,7 +532,7 @@ public class Console implements Closeable {\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState().toString()\n+            + \" (\" + writeQuery.getState()\n             + \") : \" + writeQuery.getQuerySingleLine());\n       }\n       writer().println(\"\\nFor query topology and execution plan please run: EXPLAIN <QueryId>\");\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\nindex fb4c24357c..17aa55f796 100644\n--- a/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n+++ b/ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java\n", "chunk": "@@ -532,7 +532,7 @@ public class Console implements Closeable {\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState()\n+            + \" (\" + writeQuery.getState().orElse(\"N/A\")\n             + \") : \" + writeQuery.getQuerySingleLine());\n       }\n       writer().println(\"\\nFor query topology and execution plan please run: EXPLAIN <QueryId>\");\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400794902", "body": "The test would be less coupled to `KafkaStreamsStateCount` if you use a mock.  \r\n\r\n```suggestion\r\n  @Mock(name = \"RUNNING:1, ERROR:2\")\r\n  private KafkaStreamsStateCount kafkaStreamsStateCount;\r\n```\r\n\r\nThen `kafkaStreamsStateCount.toString()` will return `RUNNING:1, ERROR:2`, which you can check for in your test.\r\n\r\nNow if the output of toString changes you don't need to update this test. ", "bodyText": "The test would be less coupled to KafkaStreamsStateCount if you use a mock.\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private KafkaStreamsStateCount kafkaStreamsStateCount;\n          \n          \n            \n              @Mock(name = \"RUNNING:1, ERROR:2\")\n          \n          \n            \n              private KafkaStreamsStateCount kafkaStreamsStateCount;\n          \n      \n    \n    \n  \n\nThen kafkaStreamsStateCount.toString() will return RUNNING:1, ERROR:2, which you can check for in your test.\nNow if the output of toString changes you don't need to update this test.", "bodyHTML": "<p dir=\"auto\">The test would be less coupled to <code>KafkaStreamsStateCount</code> if you use a mock.</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">  <span class=\"pl-k x x-first\">private</span><span class=\"x\"> </span><span class=\"pl-smi x\">KafkaStreamsStateCount</span><span class=\"x x-last\"> kafkaStreamsStateCount;</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">  <span class=\"pl-k x x-first\">@Mock</span><span class=\"x\">(</span><span class=\"pl-c1 x\">name</span><span class=\"x\"> </span><span class=\"pl-k x\">=</span><span class=\"x\"> </span><span class=\"pl-s\"><span class=\"pl-pds x\">\"</span><span class=\"x\">RUNNING:1, ERROR:2</span><span class=\"pl-pds x\">\"</span></span><span class=\"x x-last\">)</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">  <span class=\"pl-k\">private</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> kafkaStreamsStateCount;</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">Then <code>kafkaStreamsStateCount.toString()</code> will return <code>RUNNING:1, ERROR:2</code>, which you can check for in your test.</p>\n<p dir=\"auto\">Now if the output of toString changes you don't need to update this test.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:09:32Z", "path": "ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java", "diffHunk": "@@ -129,6 +131,7 @@\n       1,\n       \"statement\"\n   );\n+  private KafkaStreamsStateCount kafkaStreamsStateCount;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAwNDc0Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401004747", "bodyText": "woah I had no idea this was a thing, that's so cool!", "author": "agavra", "createdAt": "2020-03-31T15:27:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgwODI0Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401808243", "bodyText": "Hmm, this isn't working for me. The tests have RUNNING:1,ERROR:2 in the cases, but they're still passing after setting @Mock(name = \"RUNNING:1, ERROR:2\") (no space in between the state counts)", "author": "stevenpyzhang", "createdAt": "2020-04-01T18:04:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIyOTEwOQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402229109", "bodyText": "Just a thought, but you have removed the code that assigns a new instance to this field, right?  If not, have you tried debugging? Cos this does work...", "author": "big-andy-coates", "createdAt": "2020-04-02T11:03:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NDAxNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402654015", "bodyText": "I ended up just mocking this regularly since I also needed to mock the getStates method", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:29:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}], "type": "inlineReview", "revised_code": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java b/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java\nindex fc4f78c119..77a094982c 100644\n--- a/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java\n+++ b/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java\n", "chunk": "@@ -131,7 +131,7 @@ public class ConsoleTest {\n       1,\n       \"statement\"\n   );\n-  private KafkaStreamsStateCount kafkaStreamsStateCount;\n+  private QueryStateCount queryStateCount;\n \n   @Parameterized.Parameters(name = \"{0}\")\n   public static Collection<OutputFormat> data() {\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java b/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java\nindex 77a094982c..344310c064 100644\n--- a/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java\n+++ b/ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java\n", "chunk": "@@ -131,6 +137,8 @@ public class ConsoleTest {\n       1,\n       \"statement\"\n   );\n+\n+  @Mock\n   private QueryStateCount queryStateCount;\n \n   @Parameterized.Parameters(name = \"{0}\")\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMzA1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400803057", "body": "This looks a lot like interface bloat to me.  It looks like what you needed to do was add an additional map parameter to the existing `makeKsqlRequest` method.  Instead you've added a whole new method. \r\n\r\nThis has two disadvantages:\r\n 1. implementations of the interface now need to implement an additional method\r\n 2. users to the interface may need to check the implementation to work out what the two methods do so they can work out which to call.\r\n\r\nThink what would happen in a year of twos time if this pattern was followed when people added a few more variants to add additional parameters?  The result is a bloated interface which is hard to use and to implement.\r\n\r\nA better way....\r\n\r\nQ: Is there any difference between calling:\r\n\r\n```java\r\nmakeKsqlRequest(uri, sql);\r\n// or\r\nmakeKsqlRequestWithRequestProperties(uri, sql, emptyMap);\r\n```\r\n\r\nI'm guessing / hoping not.\r\n\r\nIf this is the case, I'd suggest one of two approaches:\r\n\r\n1. Add the new param to the existing `makeKsqlRequest` method and default all existing calls to passing an `ImmutableMap.of()` for the new param, i.e. passing an empty map.\r\n2. Have two separate methods, but provide a default implementation for one that calls the other:\r\n\r\n```java\r\npublic interface SimpleKsqlClient {\r\n  \r\n default RestResponse<KsqlEntityList> makeKsqlRequest(\r\n      URI serverEndPoint,\r\n      String sql\r\n  ) {\r\n    return makeKsqlRequest(serverEndPoint, sql, ImmutableMap.of());\r\n  }\r\n\r\n   RestResponse<KsqlEntityList> makeKsqlRequest(\r\n      URI serverEndPoint,\r\n      String sql,\r\n      Map<String, ?> props\r\n  );\r\n}\r\n```\r\n\r\nOf these, my preference would be for the first option as this solves both issues, where as the second option only removes the need for implementations to implement a second method, while still leaving users of the interface to work out which method they need to call.\r\n", "bodyText": "This looks a lot like interface bloat to me.  It looks like what you needed to do was add an additional map parameter to the existing makeKsqlRequest method.  Instead you've added a whole new method.\nThis has two disadvantages:\n\nimplementations of the interface now need to implement an additional method\nusers to the interface may need to check the implementation to work out what the two methods do so they can work out which to call.\n\nThink what would happen in a year of twos time if this pattern was followed when people added a few more variants to add additional parameters?  The result is a bloated interface which is hard to use and to implement.\nA better way....\nQ: Is there any difference between calling:\nmakeKsqlRequest(uri, sql);\n// or\nmakeKsqlRequestWithRequestProperties(uri, sql, emptyMap);\nI'm guessing / hoping not.\nIf this is the case, I'd suggest one of two approaches:\n\nAdd the new param to the existing makeKsqlRequest method and default all existing calls to passing an ImmutableMap.of() for the new param, i.e. passing an empty map.\nHave two separate methods, but provide a default implementation for one that calls the other:\n\npublic interface SimpleKsqlClient {\n  \n default RestResponse<KsqlEntityList> makeKsqlRequest(\n      URI serverEndPoint,\n      String sql\n  ) {\n    return makeKsqlRequest(serverEndPoint, sql, ImmutableMap.of());\n  }\n\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n      URI serverEndPoint,\n      String sql,\n      Map<String, ?> props\n  );\n}\nOf these, my preference would be for the first option as this solves both issues, where as the second option only removes the need for implementations to implement a second method, while still leaving users of the interface to work out which method they need to call.", "bodyHTML": "<p dir=\"auto\">This looks a lot like interface bloat to me.  It looks like what you needed to do was add an additional map parameter to the existing <code>makeKsqlRequest</code> method.  Instead you've added a whole new method.</p>\n<p dir=\"auto\">This has two disadvantages:</p>\n<ol dir=\"auto\">\n<li>implementations of the interface now need to implement an additional method</li>\n<li>users to the interface may need to check the implementation to work out what the two methods do so they can work out which to call.</li>\n</ol>\n<p dir=\"auto\">Think what would happen in a year of twos time if this pattern was followed when people added a few more variants to add additional parameters?  The result is a bloated interface which is hard to use and to implement.</p>\n<p dir=\"auto\">A better way....</p>\n<p dir=\"auto\">Q: Is there any difference between calling:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"makeKsqlRequest(uri, sql);\n// or\nmakeKsqlRequestWithRequestProperties(uri, sql, emptyMap);\"><pre>makeKsqlRequest(uri, sql);\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> or</span>\nmakeKsqlRequestWithRequestProperties(uri, sql, emptyMap);</pre></div>\n<p dir=\"auto\">I'm guessing / hoping not.</p>\n<p dir=\"auto\">If this is the case, I'd suggest one of two approaches:</p>\n<ol dir=\"auto\">\n<li>Add the new param to the existing <code>makeKsqlRequest</code> method and default all existing calls to passing an <code>ImmutableMap.of()</code> for the new param, i.e. passing an empty map.</li>\n<li>Have two separate methods, but provide a default implementation for one that calls the other:</li>\n</ol>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"public interface SimpleKsqlClient {\n  \n default RestResponse&lt;KsqlEntityList&gt; makeKsqlRequest(\n      URI serverEndPoint,\n      String sql\n  ) {\n    return makeKsqlRequest(serverEndPoint, sql, ImmutableMap.of());\n  }\n\n   RestResponse&lt;KsqlEntityList&gt; makeKsqlRequest(\n      URI serverEndPoint,\n      String sql,\n      Map&lt;String, ?&gt; props\n  );\n}\"><pre><span class=\"pl-k\">public</span> <span class=\"pl-k\">interface</span> <span class=\"pl-en\">SimpleKsqlClient</span> {\n  \n default <span class=\"pl-k\">RestResponse&lt;<span class=\"pl-smi\">KsqlEntityList</span>&gt;</span> <span class=\"pl-en\">makeKsqlRequest</span>(\n      <span class=\"pl-smi\">URI</span> <span class=\"pl-v\">serverEndPoint</span>,\n      <span class=\"pl-smi\">String</span> <span class=\"pl-v\">sql</span>\n  ) {\n    <span class=\"pl-k\">return</span> makeKsqlRequest(serverEndPoint, sql, <span class=\"pl-smi\">ImmutableMap</span><span class=\"pl-k\">.</span>of());\n  }\n\n   <span class=\"pl-k\">RestResponse&lt;<span class=\"pl-smi\">KsqlEntityList</span>&gt;</span> <span class=\"pl-en\">makeKsqlRequest</span>(\n      <span class=\"pl-smi\">URI</span> <span class=\"pl-v\">serverEndPoint</span>,\n      <span class=\"pl-smi\">String</span> <span class=\"pl-v\">sql</span>,\n      <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, ?&gt;</span> <span class=\"pl-v\">props</span>\n  );\n}</pre></div>\n<p dir=\"auto\">Of these, my preference would be for the first option as this solves both issues, where as the second option only removes the need for implementations to implement a second method, while still leaving users of the interface to work out which method they need to call.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:23:06Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,19 @@\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+      URI serverEndPoint,\n+      String sql,\n+      Map<String, ?> requestProperties\n+  );\n+", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2MzU3Mg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401963572", "bodyText": "Went with your first suggestion.", "author": "stevenpyzhang", "createdAt": "2020-04-01T23:14:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMzA1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex d943930df9..a9e430a671 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -41,11 +36,10 @@ public interface SimpleKsqlClient {\n    * @param requestProperties the request metadata provided by the server\n    * @return the result of sql statement execution\n    */\n-  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+  RestResponse<KsqlEntityList> makeKsqlRequest(\n       URI serverEndPoint,\n       String sql,\n-      Map<String, ?> requestProperties\n-  );\n+      Map<String, ?> requestProperties);\n \n   /**\n    * Send pull query request to remote Ksql server.\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex a9e430a671..bf2639325f 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -29,17 +29,16 @@ import javax.annotation.concurrent.ThreadSafe;\n @ThreadSafe\n public interface SimpleKsqlClient {\n \n-  /**\n-   * Send a request to remote Ksql server.\n-   * @param serverEndPoint the remote destination\n-   * @param sql the sql statement\n-   * @param requestProperties the request metadata provided by the server\n-   * @return the result of sql statement execution\n-   */\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n+      URI serverEndPoint,\n+      String sql\n+  );\n+\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n-      Map<String, ?> requestProperties);\n+      Map<String, ?> requestProperties\n+  );\n \n   /**\n    * Send pull query request to remote Ksql server.\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex bf2639325f..d215f1663f 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -29,12 +29,14 @@ import javax.annotation.concurrent.ThreadSafe;\n @ThreadSafe\n public interface SimpleKsqlClient {\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n-      URI serverEndPoint,\n-      String sql\n-  );\n-\n-  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n       Map<String, ?> requestProperties\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400805655", "body": "nit: duplicate code. Why not create the map in the calling function and pass it down, rather than passing sessionProperites?", "bodyText": "nit: duplicate code. Why not create the map in the calling function and pass it down, rather than passing sessionProperites?", "bodyHTML": "<p dir=\"auto\">nit: duplicate code. Why not create the map in the calling function and pass it down, rather than passing sessionProperites?</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:27:34Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java", "diffHunk": "@@ -118,20 +125,29 @@ private static QueryDescription explainStatement(\n               new IllegalStateException(\"The provided statement did not run a ksql query\"));\n     }\n \n-    return QueryDescriptionFactory.forQueryMetadata(metadata);\n+    return QueryDescriptionFactory.forQueryMetadata(\n+        metadata,\n+        Collections.singletonMap(\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            metadata.getState()));\n   }\n \n   private static QueryDescription explainQuery(\n       final String queryId,\n-      final KsqlExecutionContext executionContext\n+      final KsqlExecutionContext executionContext,\n+      final SessionProperties sessionProperties\n   ) {\n     final PersistentQueryMetadata metadata = executionContext\n         .getPersistentQuery(new QueryId(queryId))\n         .orElseThrow(() -> new KsqlException(\n             \"Query with id:\" + queryId + \" does not exist, \"\n                 + \"use SHOW QUERIES to view the full set of queries.\"));\n \n-    return QueryDescriptionFactory.forQueryMetadata(metadata);\n+    return QueryDescriptionFactory.forQueryMetadata(\n+        metadata,\n+        Collections.singletonMap(\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            metadata.getState()));", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg3OTIwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401879205", "bodyText": "I changed it to pass down the KsqlHostInfoEntity object, but the map would still need to be made separately in each function since the QueryMetadata isn't available for the Explain statement case.", "author": "stevenpyzhang", "createdAt": "2020-04-01T20:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NzE5MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401957191", "bodyText": "Actually, I realized, for explainStatement, the ksqlQueryHostState should actually be an emptyMap since we're not actually running the statement yet.", "author": "stevenpyzhang", "createdAt": "2020-04-01T22:55:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java\nindex b4db16b3c1..14a8fd48b1 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java\n", "chunk": "@@ -146,7 +148,7 @@ public final class ExplainExecutor {\n     return QueryDescriptionFactory.forQueryMetadata(\n         metadata,\n         Collections.singletonMap(\n-            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            ksqlHostInfo,\n             metadata.getState()));\n   }\n \n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java\nindex 14a8fd48b1..b4db16b3c1 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java\n", "chunk": "@@ -148,7 +146,7 @@ public final class ExplainExecutor {\n     return QueryDescriptionFactory.forQueryMetadata(\n         metadata,\n         Collections.singletonMap(\n-            ksqlHostInfo,\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n             metadata.getState()));\n   }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxMDE5Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400810193", "body": "This is called `sessionProperties` on the receiving end... consider calling it `sessionProperties` here?", "bodyText": "This is called sessionProperties on the receiving end... consider calling it sessionProperties here?", "bodyHTML": "<p dir=\"auto\">This is called <code>sessionProperties</code> on the receiving end... consider calling it <code>sessionProperties</code> here?</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:35:22Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,19 @@\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+      URI serverEndPoint,\n+      String sql,\n+      Map<String, ?> requestProperties", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NDI1OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401964258", "bodyText": "It should still be requestProperties, SessionProperties is created in the REST resource by looking at the incoming requests's requestProperties so they're not exactly the same object", "author": "stevenpyzhang", "createdAt": "2020-04-01T23:16:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxMDE5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex d943930df9..a9e430a671 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -41,11 +36,10 @@ public interface SimpleKsqlClient {\n    * @param requestProperties the request metadata provided by the server\n    * @return the result of sql statement execution\n    */\n-  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+  RestResponse<KsqlEntityList> makeKsqlRequest(\n       URI serverEndPoint,\n       String sql,\n-      Map<String, ?> requestProperties\n-  );\n+      Map<String, ?> requestProperties);\n \n   /**\n    * Send pull query request to remote Ksql server.\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex a9e430a671..bf2639325f 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -29,17 +29,16 @@ import javax.annotation.concurrent.ThreadSafe;\n @ThreadSafe\n public interface SimpleKsqlClient {\n \n-  /**\n-   * Send a request to remote Ksql server.\n-   * @param serverEndPoint the remote destination\n-   * @param sql the sql statement\n-   * @param requestProperties the request metadata provided by the server\n-   * @return the result of sql statement execution\n-   */\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n+      URI serverEndPoint,\n+      String sql\n+  );\n+\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n-      Map<String, ?> requestProperties);\n+      Map<String, ?> requestProperties\n+  );\n \n   /**\n    * Send pull query request to remote Ksql server.\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\nindex bf2639325f..d215f1663f 100644\n--- a/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n+++ b/ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java\n", "chunk": "@@ -29,12 +29,14 @@ import javax.annotation.concurrent.ThreadSafe;\n @ThreadSafe\n public interface SimpleKsqlClient {\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n-      URI serverEndPoint,\n-      String sql\n-  );\n-\n-  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n       URI serverEndPoint,\n       String sql,\n       Map<String, ?> requestProperties\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979", "body": "Humm... silently excluding results on failure is probably not ideal.  Better to capture this information and return it as part of the result, e.g. have a list of unresponsive hosts.", "bodyText": "Humm... silently excluding results on failure is probably not ideal.  Better to capture this information and return it as part of the result, e.g. have a list of unresponsive hosts.", "bodyHTML": "<p dir=\"auto\">Humm... silently excluding results on failure is probably not ideal.  Better to capture this information and return it as part of the result, e.g. have a list of unresponsive hosts.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:44:25Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjcxODczMQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402718731", "bodyText": "I'm not sure how that would exactly fit in with the current outputs that's proposed. Would it be fine to just log the failure for now and I'll file a issue for improving the response to indicate unresponsive hosts?", "author": "stevenpyzhang", "createdAt": "2020-04-03T03:34:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMDg1MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404730850", "bodyText": "If you're planning on do that as the next task, then sure, by all means get this one merged and then enhance to include unresponsive hosts.\nIf you mean just raise it as a task and then it gets lost in the backlog... never to see the light of day again... ;).   Then I'd say no.\nThis piece of work you're doing, (which is awesome!), would be incomplete IMHO if the user wasn't informed that the results were incomplete.  One of the main reasons they may be looking into the query status on the different hosts is because something is wrong and they're investigating.  Hence we should be providing them with the info they need, not hiding errors from them.\nThe current output has two modes, right?\nNormal outputs something like status: RUNNING:1, CREATED: 2.  So why not include a UNRESPONSIVE: 2 in that list?\nExtended output goes a step further and outputs the state on each host, e.g. Host Query Status    : {Host1=RUNNING, Host2=RUNNING}. This too could easily be extended to include Host3=UNRESPONSIVE.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:18:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..f206c3c92d 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -115,7 +115,7 @@ public final class ListQueriesExecutor {\n         }\n \n         final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n+            new ConcurrentLinkedQueue<>();\n         futureRunningQueries.forEach(future -> {\n           try {\n             remoteRunningQueries.addAll(future.get());\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex f206c3c92d..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,57 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-            new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxODQyNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400818426", "body": "Rather than wrap `values` in `new ArrayList`, why not change `Queries` constructor to take a `Collection` and internally take a defensive immutable copy using `ImmutableList.copyOf(queries)`?", "bodyText": "Rather than wrap values in new ArrayList, why not change Queries constructor to take a Collection and internally take a defensive immutable copy using ImmutableList.copyOf(queries)?", "bodyHTML": "<p dir=\"auto\">Rather than wrap <code>values</code> in <code>new ArrayList</code>, why not change <code>Queries</code> constructor to take a <code>Collection</code> and internally take a defensive immutable copy using <code>ImmutableList.copyOf(queries)</code>?</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:51:14Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,57 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (remoteHosts.size() != 0) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDI5Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820296", "body": "nit: private", "bodyText": "nit: private", "bodyHTML": "<p dir=\"auto\">nit: private</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:54:33Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java", "diffHunk": "@@ -37,21 +38,35 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlHostInfo;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n import java.util.Optional;\n+\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.ExpectedException;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ExplainExecutorTest {\n \n+  private static final KsqlHostInfo LOCAL_HOST = new KsqlHostInfo(\"host\", 8080);\n   @Rule\n   public final TemporaryEngine engine = new TemporaryEngine();\n   @Rule\n   public ExpectedException expectedException = ExpectedException.none();\n+  @Mock\n+  SessionProperties sessionProperties;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\nindex 829c341762..6cacc8560b 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\n", "chunk": "@@ -61,7 +61,7 @@ public class ExplainExecutorTest {\n   @Rule\n   public ExpectedException expectedException = ExpectedException.none();\n   @Mock\n-  SessionProperties sessionProperties;\n+  private SessionProperties sessionProperties;\n \n   @Before\n   public void setup() {\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\nindex 6cacc8560b..829c341762 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\n", "chunk": "@@ -61,7 +61,7 @@ public class ExplainExecutorTest {\n   @Rule\n   public ExpectedException expectedException = ExpectedException.none();\n   @Mock\n-  private SessionProperties sessionProperties;\n+  SessionProperties sessionProperties;\n \n   @Before\n   public void setup() {\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\nindex 829c341762..4168594da3 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java\n", "chunk": "@@ -55,13 +56,14 @@ import org.mockito.junit.MockitoJUnitRunner;\n @RunWith(MockitoJUnitRunner.class)\n public class ExplainExecutorTest {\n \n+  private static final KafkaStreams.State STATE = KafkaStreams.State.RUNNING;\n   private static final KsqlHostInfo LOCAL_HOST = new KsqlHostInfo(\"host\", 8080);\n   @Rule\n   public final TemporaryEngine engine = new TemporaryEngine();\n   @Rule\n   public ExpectedException expectedException = ExpectedException.none();\n   @Mock\n-  SessionProperties sessionProperties;\n+  private SessionProperties sessionProperties;\n \n   @Before\n   public void setup() {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDQ2OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820469", "body": "nit: private", "bodyText": "nit: private", "bodyHTML": "<p dir=\"auto\">nit: private</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:54:53Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java", "diffHunk": "@@ -39,17 +41,39 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.Optional;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n+  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n+  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n+  @Mock\n+  SessionProperties sessionProperties;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex bea70e68a7..1d4a6c98e9 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -63,12 +63,13 @@ public class ListQueriesExecutorTest {\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n-  SessionProperties sessionProperties;\n-\n-  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  private SessionProperties sessionProperties;\n+  \n+  private KafkaStreamsStateCount kafkaStreamsStateCount;\n \n   @Before\n   public void setup() {\n+    // set to true so the tests don't perform the scatter gather by default\n     when(sessionProperties.getInternalRequest()).thenReturn(true);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n     kafkaStreamsStateCount = new KafkaStreamsStateCount();\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex 1d4a6c98e9..62a62ddf6c 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -63,14 +63,13 @@ public class ListQueriesExecutorTest {\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n-  private SessionProperties sessionProperties;\n-  \n-  private KafkaStreamsStateCount kafkaStreamsStateCount;\n+  SessionProperties sessionProperties;\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;\n \n   @Before\n   public void setup() {\n-    // set to true so the tests don't perform the scatter gather by default\n-    when(sessionProperties.getInternalRequest()).thenReturn(true);\n+    when(sessionProperties.getInternalRequest()).thenReturn(false);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n     kafkaStreamsStateCount = new KafkaStreamsStateCount();\n   }\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex 62a62ddf6c..bea70e68a7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -69,7 +69,7 @@ public class ListQueriesExecutorTest {\n \n   @Before\n   public void setup() {\n-    when(sessionProperties.getInternalRequest()).thenReturn(false);\n+    when(sessionProperties.getInternalRequest()).thenReturn(true);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n     kafkaStreamsStateCount = new KafkaStreamsStateCount();\n   }\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex bea70e68a7..d73f7d88d1 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -63,15 +62,16 @@ public class ListQueriesExecutorTest {\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n-  SessionProperties sessionProperties;\n-\n-  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  private SessionProperties sessionProperties;\n+  \n+  private QueryStateCount queryStateCount;\n \n   @Before\n   public void setup() {\n+    // set to true so the tests don't perform the scatter gather by default\n     when(sessionProperties.getInternalRequest()).thenReturn(true);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+    queryStateCount = new QueryStateCount();\n   }\n \n   @Test\n", "next_change": {"commit": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex d73f7d88d1..ef7283c643 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -56,22 +75,50 @@ import org.mockito.junit.MockitoJUnitRunner;\n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n-  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n-  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n-  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n+  private static final HostInfo REMOTE_HOST = new HostInfo(\"otherhost\", 1234);\n+  private static final HostInfo LOCAL_HOST = new HostInfo(\"HOST\", 444);\n+  private static final KsqlHostInfoEntity LOCAL_KSQL_HOST_INFO_ENTITY =\n+      new KsqlHostInfoEntity(LOCAL_HOST.host(), LOCAL_HOST.port());\n+  private static final KsqlHostInfoEntity REMOTE_KSQL_HOST_INFO_ENTITY =\n+      new KsqlHostInfoEntity(REMOTE_HOST.host(), REMOTE_HOST.port());\n+\n+  private static final KafkaStreams.State RUNNING_QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final KafkaStreams.State ERROR_QUERY_STATE = KafkaStreams.State.ERROR;\n+\n+  private static final Map<KsqlHostInfoEntity, String> LOCAL_KSQL_HOST_INFO_MAP =\n+      Collections.singletonMap(LOCAL_KSQL_HOST_INFO_ENTITY, RUNNING_QUERY_STATE.toString());\n+  \n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n   private SessionProperties sessionProperties;\n+  @Mock\n+  private RestResponse<KsqlEntityList> response;\n+  @Mock\n+  private ServiceContext serviceContext;\n+  @Mock\n+  private SimpleKsqlClient ksqlClient;\n+  @Mock\n+  private KsqlEntityList ksqlEntityList;\n+  @Mock\n+  private Queries remoteQueries;\n+  @Mock\n+  private QueryDescriptionList remoteQueryDescriptionList;\n   \n   private QueryStateCount queryStateCount;\n \n   @Before\n-  public void setup() {\n+  public void setup() throws MalformedURLException {\n     // set to true so the tests don't perform the scatter gather by default\n     when(sessionProperties.getInternalRequest()).thenReturn(true);\n-    when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n+    when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_KSQL_HOST_INFO_ENTITY.toKsqlHost());\n+    when(sessionProperties.getLocalUrl()).thenReturn(new URL(\"https://address\"));\n+\n     queryStateCount = new QueryStateCount();\n+\n+    when(ksqlClient.makeKsqlRequest(any(), any(), any())).thenReturn(response);\n+    when(response.isErroneous()).thenReturn(false);\n+    when(serviceContext.getKsqlClient()).thenReturn(ksqlClient);\n   }\n \n   @Test\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex d73f7d88d1..ef7283c643 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -79,7 +126,7 @@ public class ListQueriesExecutorTest {\n     // When\n     final Queries queries = (Queries) CustomExecutors.LIST_QUERIES.execute(\n         engine.configure(\"SHOW QUERIES;\"),\n-            mock(SessionProperties.class),\n+        mock(SessionProperties.class),\n         engine.getEngine(),\n         engine.getServiceContext()\n     ).orElseThrow(IllegalStateException::new);\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDczMA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820730", "body": "nit: private, and prefer mock to actual instance, as this decouples this test from `KafkaStreamsStateCount` implementation.", "bodyText": "nit: private, and prefer mock to actual instance, as this decouples this test from KafkaStreamsStateCount implementation.", "bodyHTML": "<p dir=\"auto\">nit: private, and prefer mock to actual instance, as this decouples this test from <code>KafkaStreamsStateCount</code> implementation.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:55:22Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java", "diffHunk": "@@ -39,17 +41,39 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.Optional;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n+  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n+  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n+  @Mock\n+  SessionProperties sessionProperties;\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkwMjI5MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401902291", "bodyText": "made it private, but I don't think this can be mocked. shouldListQueriesBasic test compares the state count object created in the output of ListQueriesExecutor with this variable and if it's a mock, it wouldn't be a match.", "author": "stevenpyzhang", "createdAt": "2020-04-01T20:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDczMA=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex bea70e68a7..1d4a6c98e9 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -63,12 +63,13 @@ public class ListQueriesExecutorTest {\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n-  SessionProperties sessionProperties;\n-\n-  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  private SessionProperties sessionProperties;\n+  \n+  private KafkaStreamsStateCount kafkaStreamsStateCount;\n \n   @Before\n   public void setup() {\n+    // set to true so the tests don't perform the scatter gather by default\n     when(sessionProperties.getInternalRequest()).thenReturn(true);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n     kafkaStreamsStateCount = new KafkaStreamsStateCount();\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex 1d4a6c98e9..62a62ddf6c 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -63,14 +63,13 @@ public class ListQueriesExecutorTest {\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n-  private SessionProperties sessionProperties;\n-  \n-  private KafkaStreamsStateCount kafkaStreamsStateCount;\n+  SessionProperties sessionProperties;\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;\n \n   @Before\n   public void setup() {\n-    // set to true so the tests don't perform the scatter gather by default\n-    when(sessionProperties.getInternalRequest()).thenReturn(true);\n+    when(sessionProperties.getInternalRequest()).thenReturn(false);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n     kafkaStreamsStateCount = new KafkaStreamsStateCount();\n   }\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex 62a62ddf6c..bea70e68a7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -69,7 +69,7 @@ public class ListQueriesExecutorTest {\n \n   @Before\n   public void setup() {\n-    when(sessionProperties.getInternalRequest()).thenReturn(false);\n+    when(sessionProperties.getInternalRequest()).thenReturn(true);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n     kafkaStreamsStateCount = new KafkaStreamsStateCount();\n   }\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex bea70e68a7..d73f7d88d1 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -63,15 +62,16 @@ public class ListQueriesExecutorTest {\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n-  SessionProperties sessionProperties;\n-\n-  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  private SessionProperties sessionProperties;\n+  \n+  private QueryStateCount queryStateCount;\n \n   @Before\n   public void setup() {\n+    // set to true so the tests don't perform the scatter gather by default\n     when(sessionProperties.getInternalRequest()).thenReturn(true);\n     when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+    queryStateCount = new QueryStateCount();\n   }\n \n   @Test\n", "next_change": {"commit": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex d73f7d88d1..ef7283c643 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -56,22 +75,50 @@ import org.mockito.junit.MockitoJUnitRunner;\n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n-  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n-  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n-  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n+  private static final HostInfo REMOTE_HOST = new HostInfo(\"otherhost\", 1234);\n+  private static final HostInfo LOCAL_HOST = new HostInfo(\"HOST\", 444);\n+  private static final KsqlHostInfoEntity LOCAL_KSQL_HOST_INFO_ENTITY =\n+      new KsqlHostInfoEntity(LOCAL_HOST.host(), LOCAL_HOST.port());\n+  private static final KsqlHostInfoEntity REMOTE_KSQL_HOST_INFO_ENTITY =\n+      new KsqlHostInfoEntity(REMOTE_HOST.host(), REMOTE_HOST.port());\n+\n+  private static final KafkaStreams.State RUNNING_QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final KafkaStreams.State ERROR_QUERY_STATE = KafkaStreams.State.ERROR;\n+\n+  private static final Map<KsqlHostInfoEntity, String> LOCAL_KSQL_HOST_INFO_MAP =\n+      Collections.singletonMap(LOCAL_KSQL_HOST_INFO_ENTITY, RUNNING_QUERY_STATE.toString());\n+  \n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n   @Mock\n   private SessionProperties sessionProperties;\n+  @Mock\n+  private RestResponse<KsqlEntityList> response;\n+  @Mock\n+  private ServiceContext serviceContext;\n+  @Mock\n+  private SimpleKsqlClient ksqlClient;\n+  @Mock\n+  private KsqlEntityList ksqlEntityList;\n+  @Mock\n+  private Queries remoteQueries;\n+  @Mock\n+  private QueryDescriptionList remoteQueryDescriptionList;\n   \n   private QueryStateCount queryStateCount;\n \n   @Before\n-  public void setup() {\n+  public void setup() throws MalformedURLException {\n     // set to true so the tests don't perform the scatter gather by default\n     when(sessionProperties.getInternalRequest()).thenReturn(true);\n-    when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_HOST.toKsqlHost());\n+    when(sessionProperties.getKsqlHostInfo()).thenReturn(LOCAL_KSQL_HOST_INFO_ENTITY.toKsqlHost());\n+    when(sessionProperties.getLocalUrl()).thenReturn(new URL(\"https://address\"));\n+\n     queryStateCount = new QueryStateCount();\n+\n+    when(ksqlClient.makeKsqlRequest(any(), any(), any())).thenReturn(response);\n+    when(response.isErroneous()).thenReturn(false);\n+    when(serviceContext.getKsqlClient()).thenReturn(ksqlClient);\n   }\n \n   @Test\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\nindex d73f7d88d1..ef7283c643 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java\n", "chunk": "@@ -79,7 +126,7 @@ public class ListQueriesExecutorTest {\n     // When\n     final Queries queries = (Queries) CustomExecutors.LIST_QUERIES.execute(\n         engine.configure(\"SHOW QUERIES;\"),\n-            mock(SessionProperties.class),\n+        mock(SessionProperties.class),\n         engine.getEngine(),\n         engine.getServiceContext()\n     ).orElseThrow(IllegalStateException::new);\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMzI1Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400823256", "body": "fyi: `!remoteHosts.isEmpty()` is often more efficient than `remoteHosts.size() != 0`.  The former only needs to check the first entry in the list. The latter may, depending on the collection implementation, need to iterate all entries to find the size.", "bodyText": "fyi: !remoteHosts.isEmpty() is often more efficient than remoteHosts.size() != 0.  The former only needs to check the first entry in the list. The latter may, depending on the collection implementation, need to iterate all entries to find the size.", "bodyHTML": "<p dir=\"auto\">fyi: <code>!remoteHosts.isEmpty()</code> is often more efficient than <code>remoteHosts.size() != 0</code>.  The former only needs to check the first entry in the list. The latter may, depending on the collection implementation, need to iterate all entries to find the size.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T10:59:47Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =\n+        queryDescriptions.stream().collect(\n+            Collectors.toMap(\n+                query -> query.getId().toString(),\n+                query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      if (remoteHosts.size() != 0) {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..f206c3c92d 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -176,13 +176,13 @@ public final class ListQueriesExecutor {\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      if (remoteHosts.size() != 0) {\n+      if (!remoteHosts.isEmpty()) {\n         final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n         final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n         for (HostInfo host : remoteHosts) {\n           futureQueryDescriptions.add(executorService.submit(() -> {\n             final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n+                .makeKsqlRequest(\n                     ServerUtil.buildRemoteUri(\n                         sessionProperties.getLocalUrl(),\n                         host.host(),\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex f206c3c92d..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -171,57 +166,54 @@ public final class ListQueriesExecutor {\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureQueryDescriptions.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n+          new ConcurrentLinkedQueue<>();\n+      futureQueryDescriptions.forEach(future -> {\n+        try {\n+          remoteQueryDescriptions.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-\n-        final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n-            new ConcurrentLinkedQueue<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToQueryDescription.put(queryId, q);\n-          }\n+      });\n+\n+      remoteQueryDescriptions.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+        if (queryToQueryDescription.containsKey(queryId)) {\n+          q.getKsqlHostQueryState()\n+              .forEach((host, state) ->\n+                  queryToQueryDescription\n+                      .get(queryId)\n+                      .getKsqlHostQueryState()\n+                      .put(host, state));\n+        } else {\n+          queryToQueryDescription.put(queryId, q);\n         }\n-      }\n+      });\n     }\n \n     return Optional.of(new QueryDescriptionList(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -166,54 +171,57 @@ public final class ListQueriesExecutor {\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n \n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureQueryDescriptions.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n-          new ConcurrentLinkedQueue<>();\n-      futureQueryDescriptions.forEach(future -> {\n-        try {\n-          remoteQueryDescriptions.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureQueryDescriptions.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n+          }));\n         }\n-      });\n-\n-      remoteQueryDescriptions.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-        if (queryToQueryDescription.containsKey(queryId)) {\n-          q.getKsqlHostQueryState()\n-              .forEach((host, state) ->\n-                  queryToQueryDescription\n-                      .get(queryId)\n-                      .getKsqlHostQueryState()\n-                      .put(host, state));\n-        } else {\n-          queryToQueryDescription.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n+                new ConcurrentLinkedQueue<>();\n+        futureQueryDescriptions.forEach(future -> {\n+          try {\n+            remoteQueryDescriptions.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (QueryDescription q : remoteQueryDescriptions) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+          if (queryToQueryDescription.containsKey(queryId)) {\n+            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+                q.getKsqlHostQueryState().entrySet()) {\n+              queryToQueryDescription\n+                  .get(queryId)\n+                  .getKsqlHostQueryState()\n+                  .put(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToQueryDescription.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new QueryDescriptionList(\n", "next_change": {"commit": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..2c9408b3c2 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -226,6 +234,6 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToQueryDescription.values())));\n+       queryToQueryDescription.values()));\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 2c9408b3c2..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -234,6 +231,6 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-       queryToQueryDescription.values()));\n+        queryToQueryDescription.values()));\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyNDE4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400824186", "body": "Why create it as a `List<QueryDescription>` only to convert to a `Map<String, QueryDescription>`? Why not just create as a map initially?\r\n\r\nAlso, why not make the map stronger typed, e.g. `Map<QueryId, QueryDescription>`?", "bodyText": "Why create it as a List<QueryDescription> only to convert to a Map<String, QueryDescription>? Why not just create as a map initially?\nAlso, why not make the map stronger typed, e.g. Map<QueryId, QueryDescription>?", "bodyHTML": "<p dir=\"auto\">Why create it as a <code>List&lt;QueryDescription&gt;</code> only to convert to a <code>Map&lt;String, QueryDescription&gt;</code>? Why not just create as a map initially?</p>\n<p dir=\"auto\">Also, why not make the map stronger typed, e.g. <code>Map&lt;QueryId, QueryDescription&gt;</code>?</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T11:01:36Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NjE4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402656187", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:36:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyNDE4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -164,10 +165,10 @@ public final class ListQueriesExecutor {\n               return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n             }).collect(Collectors.toList());\n \n-    final Map<String, QueryDescription> queryToQueryDescription =\n+    final Map<QueryId, QueryDescription> queryToQueryDescription =\n         queryDescriptions.stream().collect(\n             Collectors.toMap(\n-                query -> query.getId().toString(),\n+                query -> query.getId(),\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n", "next_change": {"commit": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..2c9408b3c2 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -168,7 +174,7 @@ public final class ListQueriesExecutor {\n     final Map<QueryId, QueryDescription> queryToQueryDescription =\n         queryDescriptions.stream().collect(\n             Collectors.toMap(\n-                query -> query.getId(),\n+                QueryDescription::getId,\n                 query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 2c9408b3c2..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -161,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                QueryDescription::getId,\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzMjkyNw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400832927", "body": "These executor services are not being shutdown, so they're a resource leak!", "bodyText": "These executor services are not being shutdown, so they're a resource leak!", "bodyHTML": "<p dir=\"auto\">These executor services are not being shutdown, so they're a resource leak!</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T11:18:20Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NjIzMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402656232", "bodyText": "shut down!", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzMjkyNw=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..f206c3c92d 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -95,13 +95,13 @@ public final class ListQueriesExecutor {\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n       \n-      if (remoteHosts.size() != 0) {\n+      if (!remoteHosts.isEmpty()) {\n         final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n         final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n         for (HostInfo host : remoteHosts) {\n           futureRunningQueries.add(executorService.submit(() -> {\n             final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n+                .makeKsqlRequest(\n                     ServerUtil.buildRemoteUri(\n                         sessionProperties.getLocalUrl(),\n                         host.host(),\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex f206c3c92d..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,57 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-            new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzNTQ5OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400835499", "body": "It may be sensible to add a timeout on this `get()` call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "bodyText": "It may be sensible to add a timeout on this get() call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "bodyHTML": "<p dir=\"auto\">It may be sensible to add a timeout on this <code>get()</code> call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T11:23:19Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..f206c3c92d 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -115,7 +115,7 @@ public final class ListQueriesExecutor {\n         }\n \n         final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n+            new ConcurrentLinkedQueue<>();\n         futureRunningQueries.forEach(future -> {\n           try {\n             remoteRunningQueries.addAll(future.get());\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex f206c3c92d..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,57 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-            new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzOTE4OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400839188", "body": "`.getResponse` throws unsupported operation on an error response!\r\n\r\nThis shouts \"Missing unit tests\" to me.  Can you add unit tests that:\r\n\r\na) return a failed `RestResponse`\r\nb) throw an exception from the `Future.get`.", "bodyText": ".getResponse throws unsupported operation on an error response!\nThis shouts \"Missing unit tests\" to me.  Can you add unit tests that:\na) return a failed RestResponse\nb) throw an exception from the Future.get.", "bodyHTML": "<p dir=\"auto\"><code>.getResponse</code> throws unsupported operation on an error response!</p>\n<p dir=\"auto\">This shouts \"Missing unit tests\" to me.  Can you add unit tests that:</p>\n<p dir=\"auto\">a) return a failed <code>RestResponse</code><br>\nb) throw an exception from the <code>Future.get</code>.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T11:30:13Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzI1NzI1MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r403257250", "bodyText": "added a lot more tests to ListQueriesExecutorTest", "author": "stevenpyzhang", "createdAt": "2020-04-03T19:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzOTE4OA=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..f206c3c92d 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -95,13 +95,13 @@ public final class ListQueriesExecutor {\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n       \n-      if (remoteHosts.size() != 0) {\n+      if (!remoteHosts.isEmpty()) {\n         final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n         final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n         for (HostInfo host : remoteHosts) {\n           futureRunningQueries.add(executorService.submit(() -> {\n             final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n+                .makeKsqlRequest(\n                     ServerUtil.buildRemoteUri(\n                         sessionProperties.getLocalUrl(),\n                         host.host(),\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex f206c3c92d..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,57 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-            new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NTkxNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400855915", "body": "nit: does not throw `InterruptedException`", "bodyText": "nit: does not throw InterruptedException", "bodyHTML": "<p dir=\"auto\">nit: does not throw <code>InterruptedException</code></p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:01:02Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+  private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP_0)\n+      .around(REST_APP_1);\n+\n+  @BeforeClass\n+  public static void setUpClass() throws InterruptedException {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -78,7 +74,7 @@ public class ShowQueriesMultiNodeFunctionalTest {\n       .around(REST_APP_1);\n \n   @BeforeClass\n-  public static void setUpClass() throws InterruptedException {\n+  public static void setUpClass() {\n     TEST_HARNESS.ensureTopics(2, PAGE_VIEW_TOPIC);\n     TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n     RestIntegrationTestUtil.createStream(REST_APP_0, PAGE_VIEWS_PROVIDER);\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 9a1472e0c7..2aa4bcc400 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -74,7 +78,7 @@ public class ShowQueriesMultiNodeFunctionalTest {\n       .around(REST_APP_1);\n \n   @BeforeClass\n-  public static void setUpClass() {\n+  public static void setUpClass() throws InterruptedException {\n     TEST_HARNESS.ensureTopics(2, PAGE_VIEW_TOPIC);\n     TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n     RestIntegrationTestUtil.createStream(REST_APP_0, PAGE_VIEWS_PROVIDER);\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -78,7 +74,7 @@ public class ShowQueriesMultiNodeFunctionalTest {\n       .around(REST_APP_1);\n \n   @BeforeClass\n-  public static void setUpClass() throws InterruptedException {\n+  public static void setUpClass() {\n     TEST_HARNESS.ensureTopics(2, PAGE_VIEW_TOPIC);\n     TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n     RestIntegrationTestUtil.createStream(REST_APP_0, PAGE_VIEWS_PROVIDER);\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -86,46 +82,79 @@ public class ShowQueriesMultiNodeFunctionalTest {\n         REST_APP_0,\n         \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n     );\n-    waitForClusterToBeDiscovered(REST_APP_0, 2);\n   }\n \n   @Test\n   public void shouldShowAllQueries() {\n-    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries;\"\n-    );\n+    // When:\n+    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n+    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n \n-    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n-    assertThat(allRunningQueries0.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n+    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n+  }\n \n-    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_1,\n+  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n         \"Show Queries;\"\n     );\n \n-    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n-    assertThat(allRunningQueries1.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    if (results.size() != 1) {\n+      return \"Expected 1 response, got \" + results.size();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof Queries)) {\n+      return \"Expected Queries, got \" + result;\n+    }\n+\n+    final List<RunningQuery> runningQueries = ((Queries) result)\n+        .getQueries();\n+\n+    if (runningQueries.size() != 1) {\n+      return \"Expected 1 running query, got \" + runningQueries.size();\n+    }\n+\n+    return runningQueries.get(0).getState().toString();\n   }\n \n   @Test\n   public void shouldShowAllQueriesExtended() {\n-    final List<KsqlEntity> clusterEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+    // When:\n+    final Supplier<Set<KsqlHostInfoEntity>> app0Response = () -> getShowQueriesExtendedResult(REST_APP_0);\n+    final Supplier<Set<KsqlHostInfoEntity>> app1Response = () -> getShowQueriesExtendedResult(REST_APP_1);\n \n-    final List<QueryDescription> clusterQueryDescriptions0 = ((QueryDescriptionList) clusterEntities0.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions0.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, containsInAnyOrder(host0, host1));\n+    assertThatEventually(\"App1\", app1Response, containsInAnyOrder(host0, host1));\n+  }\n \n-    final List<KsqlEntity> clusterEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+  private static Set<KsqlHostInfoEntity> getShowQueriesExtendedResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n+        \"Show Queries Extended;\"\n+    );\n+\n+    if (results.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof QueryDescriptionList)) {\n+      return Collections.emptySet();\n+    }\n+\n+    final List<QueryDescription> queryDescriptions = ((QueryDescriptionList) result)\n+        .getQueryDescriptions();\n \n-    final List<QueryDescription> clusterQueryDescriptions1 = ((QueryDescriptionList) clusterEntities1.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions1.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    if (queryDescriptions.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+    \n+    return queryDescriptions.get(0).getKsqlHostQueryState().keySet();\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}, {"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 9a1472e0c7..2aa4bcc400 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -82,79 +86,46 @@ public class ShowQueriesMultiNodeFunctionalTest {\n         REST_APP_0,\n         \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n     );\n+    waitForClusterToBeDiscovered(REST_APP_0, 2);\n   }\n \n   @Test\n   public void shouldShowAllQueries() {\n-    // When:\n-    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n-    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n-\n-    // Then:\n-    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n-    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n-  }\n-\n-  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n-    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n-        restApp,\n+    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n         \"Show Queries;\"\n     );\n \n-    if (results.size() != 1) {\n-      return \"Expected 1 response, got \" + results.size();\n-    }\n-\n-    final KsqlEntity result = results.get(0);\n+    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n+    assertThat(allRunningQueries0.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n \n-    if (!(result instanceof Queries)) {\n-      return \"Expected Queries, got \" + result;\n-    }\n-\n-    final List<RunningQuery> runningQueries = ((Queries) result)\n-        .getQueries();\n-\n-    if (runningQueries.size() != 1) {\n-      return \"Expected 1 running query, got \" + runningQueries.size();\n-    }\n+    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_1,\n+        \"Show Queries;\"\n+    );\n \n-    return runningQueries.get(0).getState().toString();\n+    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n+    assertThat(allRunningQueries1.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n   }\n \n   @Test\n   public void shouldShowAllQueriesExtended() {\n-    // When:\n-    final Supplier<Set<KsqlHostInfoEntity>> app0Response = () -> getShowQueriesExtendedResult(REST_APP_0);\n-    final Supplier<Set<KsqlHostInfoEntity>> app1Response = () -> getShowQueriesExtendedResult(REST_APP_1);\n-\n-    // Then:\n-    assertThatEventually(\"App0\", app0Response, containsInAnyOrder(host0, host1));\n-    assertThatEventually(\"App1\", app1Response, containsInAnyOrder(host0, host1));\n-  }\n-\n-  private static Set<KsqlHostInfoEntity> getShowQueriesExtendedResult(final TestKsqlRestApp restApp) {\n-    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n-        restApp,\n-        \"Show Queries Extended;\"\n-    );\n-\n-    if (results.size() != 1) {\n-      return Collections.emptySet();\n-    }\n-\n-    final KsqlEntity result = results.get(0);\n+    final List<KsqlEntity> clusterEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries Extended;\");\n \n-    if (!(result instanceof QueryDescriptionList)) {\n-      return Collections.emptySet();\n-    }\n+    final List<QueryDescription> clusterQueryDescriptions0 = ((QueryDescriptionList) clusterEntities0.get(0)).getQueryDescriptions();\n+    assertThat(clusterQueryDescriptions0.size(), equalTo(1));\n+    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n \n-    final List<QueryDescription> queryDescriptions = ((QueryDescriptionList) result)\n-        .getQueryDescriptions();\n+    final List<KsqlEntity> clusterEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries Extended;\");\n \n-    if (queryDescriptions.size() != 1) {\n-      return Collections.emptySet();\n-    }\n-    \n-    return queryDescriptions.get(0).getKsqlHostQueryState().keySet();\n+    final List<QueryDescription> clusterQueryDescriptions1 = ((QueryDescriptionList) clusterEntities1.get(0)).getQueryDescriptions();\n+    assertThat(clusterQueryDescriptions1.size(), equalTo(1));\n+    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -86,46 +82,79 @@ public class ShowQueriesMultiNodeFunctionalTest {\n         REST_APP_0,\n         \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n     );\n-    waitForClusterToBeDiscovered(REST_APP_0, 2);\n   }\n \n   @Test\n   public void shouldShowAllQueries() {\n-    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries;\"\n-    );\n+    // When:\n+    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n+    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n \n-    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n-    assertThat(allRunningQueries0.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n+    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n+  }\n \n-    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_1,\n+  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n         \"Show Queries;\"\n     );\n \n-    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n-    assertThat(allRunningQueries1.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    if (results.size() != 1) {\n+      return \"Expected 1 response, got \" + results.size();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof Queries)) {\n+      return \"Expected Queries, got \" + result;\n+    }\n+\n+    final List<RunningQuery> runningQueries = ((Queries) result)\n+        .getQueries();\n+\n+    if (runningQueries.size() != 1) {\n+      return \"Expected 1 running query, got \" + runningQueries.size();\n+    }\n+\n+    return runningQueries.get(0).getState().toString();\n   }\n \n   @Test\n   public void shouldShowAllQueriesExtended() {\n-    final List<KsqlEntity> clusterEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+    // When:\n+    final Supplier<Set<KsqlHostInfoEntity>> app0Response = () -> getShowQueriesExtendedResult(REST_APP_0);\n+    final Supplier<Set<KsqlHostInfoEntity>> app1Response = () -> getShowQueriesExtendedResult(REST_APP_1);\n \n-    final List<QueryDescription> clusterQueryDescriptions0 = ((QueryDescriptionList) clusterEntities0.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions0.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, containsInAnyOrder(host0, host1));\n+    assertThatEventually(\"App1\", app1Response, containsInAnyOrder(host0, host1));\n+  }\n \n-    final List<KsqlEntity> clusterEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+  private static Set<KsqlHostInfoEntity> getShowQueriesExtendedResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n+        \"Show Queries Extended;\"\n+    );\n+\n+    if (results.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof QueryDescriptionList)) {\n+      return Collections.emptySet();\n+    }\n+\n+    final List<QueryDescription> queryDescriptions = ((QueryDescriptionList) result)\n+        .getQueryDescriptions();\n \n-    final List<QueryDescription> clusterQueryDescriptions1 = ((QueryDescriptionList) clusterEntities1.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions1.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    if (queryDescriptions.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+    \n+    return queryDescriptions.get(0).getKsqlHostQueryState().keySet();\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NTY2MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400865661", "body": "I can replace this with a test that uses `assertThatEventually` which passes without any reliance on heartbeating:\r\n\r\n```java\r\n@Test\r\n  public void shouldShowAllQueries() {\r\n    // When:\r\n    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\r\n    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\r\n\r\n    // Then:\r\n    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\r\n    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\r\n  }\r\n\r\n  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\r\n    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\r\n        restApp,\r\n        \"Show Queries;\"\r\n    );\r\n\r\n    if (results.size() != 1) {\r\n      return \"Expected 1 response, got \" + results.size();\r\n    }\r\n\r\n    final KsqlEntity result = results.get(0);\r\n\r\n    if (!(result instanceof Queries)) {\r\n      return \"Expected Queries, got \" + result;\r\n    }\r\n\r\n    final List<RunningQuery> runningQueries = ((Queries) result)\r\n        .getQueries();\r\n\r\n    if (runningQueries.size() != 1) {\r\n      return \"Expected 1 running query, got \" + runningQueries.size();\r\n    }\r\n\r\n    return runningQueries.get(0).getState().toString();\r\n  }\r\n```\r\n\r\nSee if you can do the same for `shouldShowAllQueriesExtended`.", "bodyText": "I can replace this with a test that uses assertThatEventually which passes without any reliance on heartbeating:\n@Test\n  public void shouldShowAllQueries() {\n    // When:\n    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n\n    // Then:\n    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n  }\n\n  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n        restApp,\n        \"Show Queries;\"\n    );\n\n    if (results.size() != 1) {\n      return \"Expected 1 response, got \" + results.size();\n    }\n\n    final KsqlEntity result = results.get(0);\n\n    if (!(result instanceof Queries)) {\n      return \"Expected Queries, got \" + result;\n    }\n\n    final List<RunningQuery> runningQueries = ((Queries) result)\n        .getQueries();\n\n    if (runningQueries.size() != 1) {\n      return \"Expected 1 running query, got \" + runningQueries.size();\n    }\n\n    return runningQueries.get(0).getState().toString();\n  }\nSee if you can do the same for shouldShowAllQueriesExtended.", "bodyHTML": "<p dir=\"auto\">I can replace this with a test that uses <code>assertThatEventually</code> which passes without any reliance on heartbeating:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@Test\n  public void shouldShowAllQueries() {\n    // When:\n    final Supplier&lt;String&gt; app0Response = () -&gt; getShowQueriesResult(REST_APP_0);\n    final Supplier&lt;String&gt; app1Response = () -&gt; getShowQueriesResult(REST_APP_1);\n\n    // Then:\n    assertThatEventually(&quot;App0&quot;, app0Response, is(&quot;RUNNING:2&quot;));\n    assertThatEventually(&quot;App1&quot;, app1Response, is(&quot;RUNNING:2&quot;));\n  }\n\n  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n    final List&lt;KsqlEntity&gt; results = RestIntegrationTestUtil.makeKsqlRequest(\n        restApp,\n        &quot;Show Queries;&quot;\n    );\n\n    if (results.size() != 1) {\n      return &quot;Expected 1 response, got &quot; + results.size();\n    }\n\n    final KsqlEntity result = results.get(0);\n\n    if (!(result instanceof Queries)) {\n      return &quot;Expected Queries, got &quot; + result;\n    }\n\n    final List&lt;RunningQuery&gt; runningQueries = ((Queries) result)\n        .getQueries();\n\n    if (runningQueries.size() != 1) {\n      return &quot;Expected 1 running query, got &quot; + runningQueries.size();\n    }\n\n    return runningQueries.get(0).getState().toString();\n  }\"><pre><span class=\"pl-k\">@Test</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> shouldShowAllQueries() {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> When:</span>\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Supplier&lt;<span class=\"pl-smi\">String</span>&gt;</span> app0Response <span class=\"pl-k\">=</span> () <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> getShowQueriesResult(<span class=\"pl-c1\">REST_APP_0</span>);\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Supplier&lt;<span class=\"pl-smi\">String</span>&gt;</span> app1Response <span class=\"pl-k\">=</span> () <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> getShowQueriesResult(<span class=\"pl-c1\">REST_APP_1</span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Then:</span>\n    assertThatEventually(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>App0<span class=\"pl-pds\">\"</span></span>, app0Response, is(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>RUNNING:2<span class=\"pl-pds\">\"</span></span>));\n    assertThatEventually(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>App1<span class=\"pl-pds\">\"</span></span>, app1Response, is(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>RUNNING:2<span class=\"pl-pds\">\"</span></span>));\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-smi\">String</span> getShowQueriesResult(<span class=\"pl-k\">final</span> <span class=\"pl-smi\">TestKsqlRestApp</span> restApp) {\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> results <span class=\"pl-k\">=</span> <span class=\"pl-smi\">RestIntegrationTestUtil</span><span class=\"pl-k\">.</span>makeKsqlRequest(\n        restApp,\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Show Queries;<span class=\"pl-pds\">\"</span></span>\n    );\n\n    <span class=\"pl-k\">if</span> (results<span class=\"pl-k\">.</span>size() <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">1</span>) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Expected 1 response, got <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> results<span class=\"pl-k\">.</span>size();\n    }\n\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlEntity</span> result <span class=\"pl-k\">=</span> results<span class=\"pl-k\">.</span>get(<span class=\"pl-c1\">0</span>);\n\n    <span class=\"pl-k\">if</span> (<span class=\"pl-k\">!</span>(result <span class=\"pl-k\">instanceof</span> <span class=\"pl-smi\">Queries</span>)) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Expected Queries, got <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> result;\n    }\n\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">RunningQuery</span>&gt;</span> runningQueries <span class=\"pl-k\">=</span> ((<span class=\"pl-smi\">Queries</span>) result)\n        .getQueries();\n\n    <span class=\"pl-k\">if</span> (runningQueries<span class=\"pl-k\">.</span>size() <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">1</span>) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Expected 1 running query, got <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> runningQueries<span class=\"pl-k\">.</span>size();\n    }\n\n    <span class=\"pl-k\">return</span> runningQueries<span class=\"pl-k\">.</span>get(<span class=\"pl-c1\">0</span>)<span class=\"pl-k\">.</span>getState()<span class=\"pl-k\">.</span>toString();\n  }</pre></div>\n<p dir=\"auto\">See if you can do the same for <code>shouldShowAllQueriesExtended</code>.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:18:06Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+  private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP_0)\n+      .around(REST_APP_1);\n+\n+  @BeforeClass\n+  public static void setUpClass() throws InterruptedException {\n+    TEST_HARNESS.ensureTopics(2, PAGE_VIEW_TOPIC);\n+    TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n+    RestIntegrationTestUtil.createStream(REST_APP_0, PAGE_VIEWS_PROVIDER);\n+    RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n+    );\n+    waitForClusterToBeDiscovered(REST_APP_0, 2);\n+  }\n+\n+  @Test\n+  public void shouldShowAllQueries() {\n+    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries;\"\n+    );\n+\n+    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n+    assertThat(allRunningQueries0.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+\n+    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_1,\n+        \"Show Queries;\"\n+    );\n+\n+    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n+    assertThat(allRunningQueries1.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+  }", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2OTYzNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401969635", "bodyText": "changed shouldShowAllQueriesExtended to use asserThatEventually", "author": "stevenpyzhang", "createdAt": "2020-04-01T23:33:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NTY2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -86,46 +82,79 @@ public class ShowQueriesMultiNodeFunctionalTest {\n         REST_APP_0,\n         \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n     );\n-    waitForClusterToBeDiscovered(REST_APP_0, 2);\n   }\n \n   @Test\n   public void shouldShowAllQueries() {\n-    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries;\"\n-    );\n+    // When:\n+    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n+    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n \n-    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n-    assertThat(allRunningQueries0.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n+    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n+  }\n \n-    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_1,\n+  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n         \"Show Queries;\"\n     );\n \n-    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n-    assertThat(allRunningQueries1.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    if (results.size() != 1) {\n+      return \"Expected 1 response, got \" + results.size();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof Queries)) {\n+      return \"Expected Queries, got \" + result;\n+    }\n+\n+    final List<RunningQuery> runningQueries = ((Queries) result)\n+        .getQueries();\n+\n+    if (runningQueries.size() != 1) {\n+      return \"Expected 1 running query, got \" + runningQueries.size();\n+    }\n+\n+    return runningQueries.get(0).getState().toString();\n   }\n \n   @Test\n   public void shouldShowAllQueriesExtended() {\n-    final List<KsqlEntity> clusterEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+    // When:\n+    final Supplier<Set<KsqlHostInfoEntity>> app0Response = () -> getShowQueriesExtendedResult(REST_APP_0);\n+    final Supplier<Set<KsqlHostInfoEntity>> app1Response = () -> getShowQueriesExtendedResult(REST_APP_1);\n \n-    final List<QueryDescription> clusterQueryDescriptions0 = ((QueryDescriptionList) clusterEntities0.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions0.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, containsInAnyOrder(host0, host1));\n+    assertThatEventually(\"App1\", app1Response, containsInAnyOrder(host0, host1));\n+  }\n \n-    final List<KsqlEntity> clusterEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+  private static Set<KsqlHostInfoEntity> getShowQueriesExtendedResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n+        \"Show Queries Extended;\"\n+    );\n+\n+    if (results.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof QueryDescriptionList)) {\n+      return Collections.emptySet();\n+    }\n+\n+    final List<QueryDescription> queryDescriptions = ((QueryDescriptionList) result)\n+        .getQueryDescriptions();\n \n-    final List<QueryDescription> clusterQueryDescriptions1 = ((QueryDescriptionList) clusterEntities1.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions1.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    if (queryDescriptions.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+    \n+    return queryDescriptions.get(0).getKsqlHostQueryState().keySet();\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 9a1472e0c7..2aa4bcc400 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -82,79 +86,46 @@ public class ShowQueriesMultiNodeFunctionalTest {\n         REST_APP_0,\n         \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n     );\n+    waitForClusterToBeDiscovered(REST_APP_0, 2);\n   }\n \n   @Test\n   public void shouldShowAllQueries() {\n-    // When:\n-    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n-    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n-\n-    // Then:\n-    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n-    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n-  }\n-\n-  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n-    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n-        restApp,\n+    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n         \"Show Queries;\"\n     );\n \n-    if (results.size() != 1) {\n-      return \"Expected 1 response, got \" + results.size();\n-    }\n-\n-    final KsqlEntity result = results.get(0);\n+    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n+    assertThat(allRunningQueries0.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n \n-    if (!(result instanceof Queries)) {\n-      return \"Expected Queries, got \" + result;\n-    }\n-\n-    final List<RunningQuery> runningQueries = ((Queries) result)\n-        .getQueries();\n-\n-    if (runningQueries.size() != 1) {\n-      return \"Expected 1 running query, got \" + runningQueries.size();\n-    }\n+    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_1,\n+        \"Show Queries;\"\n+    );\n \n-    return runningQueries.get(0).getState().toString();\n+    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n+    assertThat(allRunningQueries1.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n   }\n \n   @Test\n   public void shouldShowAllQueriesExtended() {\n-    // When:\n-    final Supplier<Set<KsqlHostInfoEntity>> app0Response = () -> getShowQueriesExtendedResult(REST_APP_0);\n-    final Supplier<Set<KsqlHostInfoEntity>> app1Response = () -> getShowQueriesExtendedResult(REST_APP_1);\n-\n-    // Then:\n-    assertThatEventually(\"App0\", app0Response, containsInAnyOrder(host0, host1));\n-    assertThatEventually(\"App1\", app1Response, containsInAnyOrder(host0, host1));\n-  }\n-\n-  private static Set<KsqlHostInfoEntity> getShowQueriesExtendedResult(final TestKsqlRestApp restApp) {\n-    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n-        restApp,\n-        \"Show Queries Extended;\"\n-    );\n-\n-    if (results.size() != 1) {\n-      return Collections.emptySet();\n-    }\n-\n-    final KsqlEntity result = results.get(0);\n+    final List<KsqlEntity> clusterEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries Extended;\");\n \n-    if (!(result instanceof QueryDescriptionList)) {\n-      return Collections.emptySet();\n-    }\n+    final List<QueryDescription> clusterQueryDescriptions0 = ((QueryDescriptionList) clusterEntities0.get(0)).getQueryDescriptions();\n+    assertThat(clusterQueryDescriptions0.size(), equalTo(1));\n+    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n \n-    final List<QueryDescription> queryDescriptions = ((QueryDescriptionList) result)\n-        .getQueryDescriptions();\n+    final List<KsqlEntity> clusterEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries Extended;\");\n \n-    if (queryDescriptions.size() != 1) {\n-      return Collections.emptySet();\n-    }\n-    \n-    return queryDescriptions.get(0).getKsqlHostQueryState().keySet();\n+    final List<QueryDescription> clusterQueryDescriptions1 = ((QueryDescriptionList) clusterEntities1.get(0)).getQueryDescriptions();\n+    assertThat(clusterQueryDescriptions1.size(), equalTo(1));\n+    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\nindex 2aa4bcc400..9a1472e0c7 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java\n", "chunk": "@@ -86,46 +82,79 @@ public class ShowQueriesMultiNodeFunctionalTest {\n         REST_APP_0,\n         \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n     );\n-    waitForClusterToBeDiscovered(REST_APP_0, 2);\n   }\n \n   @Test\n   public void shouldShowAllQueries() {\n-    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries;\"\n-    );\n+    // When:\n+    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n+    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n \n-    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n-    assertThat(allRunningQueries0.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n+    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n+  }\n \n-    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_1,\n+  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n         \"Show Queries;\"\n     );\n \n-    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n-    assertThat(allRunningQueries1.size(), equalTo(1));\n-    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+    if (results.size() != 1) {\n+      return \"Expected 1 response, got \" + results.size();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof Queries)) {\n+      return \"Expected Queries, got \" + result;\n+    }\n+\n+    final List<RunningQuery> runningQueries = ((Queries) result)\n+        .getQueries();\n+\n+    if (runningQueries.size() != 1) {\n+      return \"Expected 1 running query, got \" + runningQueries.size();\n+    }\n+\n+    return runningQueries.get(0).getState().toString();\n   }\n \n   @Test\n   public void shouldShowAllQueriesExtended() {\n-    final List<KsqlEntity> clusterEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+    // When:\n+    final Supplier<Set<KsqlHostInfoEntity>> app0Response = () -> getShowQueriesExtendedResult(REST_APP_0);\n+    final Supplier<Set<KsqlHostInfoEntity>> app1Response = () -> getShowQueriesExtendedResult(REST_APP_1);\n \n-    final List<QueryDescription> clusterQueryDescriptions0 = ((QueryDescriptionList) clusterEntities0.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions0.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    // Then:\n+    assertThatEventually(\"App0\", app0Response, containsInAnyOrder(host0, host1));\n+    assertThatEventually(\"App1\", app1Response, containsInAnyOrder(host0, host1));\n+  }\n \n-    final List<KsqlEntity> clusterEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n-        REST_APP_0,\n-        \"Show Queries Extended;\");\n+  private static Set<KsqlHostInfoEntity> getShowQueriesExtendedResult(final TestKsqlRestApp restApp) {\n+    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n+        restApp,\n+        \"Show Queries Extended;\"\n+    );\n+\n+    if (results.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+\n+    final KsqlEntity result = results.get(0);\n+\n+    if (!(result instanceof QueryDescriptionList)) {\n+      return Collections.emptySet();\n+    }\n+\n+    final List<QueryDescription> queryDescriptions = ((QueryDescriptionList) result)\n+        .getQueryDescriptions();\n \n-    final List<QueryDescription> clusterQueryDescriptions1 = ((QueryDescriptionList) clusterEntities1.get(0)).getQueryDescriptions();\n-    assertThat(clusterQueryDescriptions1.size(), equalTo(1));\n-    assertThat(clusterQueryDescriptions0.get(0).getKsqlHostQueryState().keySet(), containsInAnyOrder(host0, host1));\n+    if (queryDescriptions.size() != 1) {\n+      return Collections.emptySet();\n+    }\n+    \n+    return queryDescriptions.get(0).getKsqlHostQueryState().keySet();\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NjcxMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400866712", "body": "There is a lot of code duplication in this class.  Let's break it down and see how we can remove this duplication!\r\n\r\nIt seems to me that this class needs to be able to:\r\n    - get the local node's running queries\r\n    - get the local node's extended query info\r\n    - scatter-gather either of the above requests to all nodes.\r\n\r\nAt the moment the scatter-gather code is duplicated: once for each of the type of info we need to get back. But the logic is the same!  Hence we should try to have only one copy of that logic.\r\n\r\nMy approach to this would to refactor the code so that there is a pair pf method to get the two different types of local info, a pair of methods to do the merging of the two different types and a single method for doing the scatter gather.\r\n\r\nIf we do all that, then we end up with something like:\r\n\r\n```java\r\npublic final class ListQueriesExecutor {\r\n\r\n  private static final Logger LOG = LoggerFactory.getLogger(ListQueriesExecutor.class);\r\n\r\n  private ListQueriesExecutor() {\r\n  }\r\n\r\n  public static Optional<KsqlEntity> execute(\r\n      final ConfiguredStatement<ListQueries> statement,\r\n      final SessionProperties sessionProperties,\r\n      final KsqlExecutionContext executionContext,\r\n      final ServiceContext serviceContext\r\n  ) {\r\n    final List<KsqlEntity> remoteResults =\r\n        scatterGather(statement, sessionProperties, executionContext, serviceContext);\r\n\r\n    return statement.getStatement().getShowExtended()\r\n        ? executeExtended(remoteResults, statement, sessionProperties, executionContext)\r\n        : executeSimple(remoteResults, statement, executionContext);\r\n  }\r\n\r\n  private static Optional<KsqlEntity> executeSimple(\r\n      final List<KsqlEntity> remoteResults,\r\n      final ConfiguredStatement<ListQueries> statement,\r\n      final KsqlExecutionContext executionContext\r\n  ) {\r\n    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\r\n\r\n    mergeSimple(remoteResults, runningQueries);\r\n\r\n    return Optional.of(new Queries(\r\n        statement.getStatementText(),\r\n        new ArrayList<>(runningQueries.values())));\r\n  }\r\n\r\n  private static Map<QueryId, RunningQuery> getLocalSimple(\r\n      final KsqlExecutionContext executionContext\r\n  ) {\r\n    return executionContext.getPersistentQueries()\r\n        .stream()\r\n        .map(q -> {\r\n          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\r\n          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\r\n          return new RunningQuery(\r\n              q.getStatementString(),\r\n              ImmutableSet.of(q.getSinkName().text()),\r\n              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\r\n              q.getQueryId(),\r\n              kafkaStreamsStateCount\r\n          );\r\n        }).collect(Collectors.toMap(RunningQuery::getId, Function.identity()));\r\n  }\r\n\r\n  private static void mergeSimple(\r\n      final List<KsqlEntity> remoteResults,\r\n      final Map<QueryId, RunningQuery> allResults\r\n  ) {\r\n    remoteResults.stream()\r\n        .map(Queries.class::cast)\r\n        .map(Queries::getQueries)\r\n        .flatMap(List::stream)\r\n        .forEach(rq ->\r\n            allResults.compute(rq.getId(), (id, existing) -> {\r\n              if (existing == null) {\r\n                return rq;\r\n              }\r\n\r\n              for (Entry<KafkaStreams.State, Integer> entry : rq.getState().getState().entrySet()) {\r\n                existing\r\n                    .getState()\r\n                    .updateStateCount(entry.getKey(), entry.getValue());\r\n              }\r\n\r\n              return existing;\r\n            })\r\n        );\r\n  }\r\n\r\n  private static Optional<KsqlEntity> executeExtended(\r\n      final List<KsqlEntity> remoteResults,\r\n      final ConfiguredStatement<ListQueries> statement,\r\n      final SessionProperties sessionProperties,\r\n      final KsqlExecutionContext executionContext\r\n  ) {\r\n    final Map<QueryId, QueryDescription> queryDescriptions =\r\n        getLocalExtended(sessionProperties, executionContext);\r\n\r\n    mergeExtended(remoteResults, queryDescriptions);\r\n\r\n    return Optional.of(new QueryDescriptionList(\r\n        statement.getStatementText(),\r\n        new ArrayList<>(queryDescriptions.values())));\r\n  }\r\n\r\n  private static Map<QueryId, QueryDescription> getLocalExtended(\r\n      final SessionProperties sessionProperties,\r\n      final KsqlExecutionContext executionContext\r\n  ) {\r\n    return executionContext.getPersistentQueries().stream()\r\n        .map(query -> {\r\n          final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\r\n          ksqlHostQueryState.put(\r\n              new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\r\n              query.getState());\r\n          return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\r\n        }).collect(Collectors.toMap(QueryDescription::getId, Function.identity()));\r\n  }\r\n\r\n  private static void mergeExtended(\r\n      final List<KsqlEntity> remoteResults,\r\n      final Map<QueryId, QueryDescription> allResults\r\n  ) {\r\n    remoteResults.stream()\r\n        .map(QueryDescriptionList.class::cast)\r\n        .map(QueryDescriptionList::getQueryDescriptions)\r\n        .flatMap(List::stream)\r\n        .forEach(qd ->\r\n            allResults.compute(qd.getId(), (id, existing) -> {\r\n              if (existing == null) {\r\n                return qd;\r\n              }\r\n\r\n              existing.getKsqlHostQueryState().putAll(qd.getKsqlHostQueryState());\r\n              return existing;\r\n            })\r\n        );\r\n  }\r\n\r\n  private static List<KsqlEntity> scatterGather(\r\n      final ConfiguredStatement<ListQueries> statement,\r\n      final SessionProperties sessionProperties,\r\n      final KsqlExecutionContext executionContext,\r\n      final ServiceContext serviceContext\r\n  ) {\r\n    if (sessionProperties.getInternalRequest()) {\r\n      return ImmutableList.of();\r\n    }\r\n\r\n    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\r\n        executionContext.getPersistentQueries(),\r\n        sessionProperties.getKsqlHostInfo()\r\n    );\r\n\r\n    if (remoteHosts.isEmpty()) {\r\n      return ImmutableList.of();\r\n    }\r\n\r\n    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\r\n\r\n    try {\r\n      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\r\n\r\n      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futures = new HashMap<>();\r\n      for (HostInfo host : remoteHosts) {\r\n        final Future<RestResponse<KsqlEntityList>> f = executorService.submit(() -> ksqlClient\r\n            .makeKsqlRequestWithRequestProperties(\r\n                ServerUtil.buildRemoteUri(\r\n                    sessionProperties.getLocalUrl(),\r\n                    host.host(),\r\n                    host.port()\r\n                ),\r\n                statement.getStatementText(),\r\n                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\r\n        );\r\n\r\n        futures.put(host, f);\r\n      }\r\n\r\n      // Todo: we should NOT ignore these failed hosts:  we should include this in the response.\r\n      final List<HostInfo> failedHosts = new ArrayList<>();\r\n      final List<KsqlEntity> results = new ArrayList<>();\r\n      for (final Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e : futures.entrySet()) {\r\n        try {\r\n          final RestResponse<KsqlEntityList> response = e.getValue().get();\r\n          if (response.isErroneous()) {\r\n            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\r\n                e.getKey(), response.getErrorMessage().getMessage());\r\n            failedHosts.add(e.getKey());\r\n          } else {\r\n            results.add(response.getResponse().get(0));\r\n          }\r\n        } catch (final Exception cause) {\r\n          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\r\n          failedHosts.add(e.getKey());\r\n        }\r\n      }\r\n\r\n      return results;\r\n    } finally {\r\n      executorService.shutdown();\r\n    }\r\n  }\r\n}\r\n```", "bodyText": "There is a lot of code duplication in this class.  Let's break it down and see how we can remove this duplication!\nIt seems to me that this class needs to be able to:\n- get the local node's running queries\n- get the local node's extended query info\n- scatter-gather either of the above requests to all nodes.\nAt the moment the scatter-gather code is duplicated: once for each of the type of info we need to get back. But the logic is the same!  Hence we should try to have only one copy of that logic.\nMy approach to this would to refactor the code so that there is a pair pf method to get the two different types of local info, a pair of methods to do the merging of the two different types and a single method for doing the scatter gather.\nIf we do all that, then we end up with something like:\npublic final class ListQueriesExecutor {\n\n  private static final Logger LOG = LoggerFactory.getLogger(ListQueriesExecutor.class);\n\n  private ListQueriesExecutor() {\n  }\n\n  public static Optional<KsqlEntity> execute(\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    final List<KsqlEntity> remoteResults =\n        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n\n    return statement.getStatement().getShowExtended()\n        ? executeExtended(remoteResults, statement, sessionProperties, executionContext)\n        : executeSimple(remoteResults, statement, executionContext);\n  }\n\n  private static Optional<KsqlEntity> executeSimple(\n      final List<KsqlEntity> remoteResults,\n      final ConfiguredStatement<ListQueries> statement,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n\n    mergeSimple(remoteResults, runningQueries);\n\n    return Optional.of(new Queries(\n        statement.getStatementText(),\n        new ArrayList<>(runningQueries.values())));\n  }\n\n  private static Map<QueryId, RunningQuery> getLocalSimple(\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries()\n        .stream()\n        .map(q -> {\n          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n          return new RunningQuery(\n              q.getStatementString(),\n              ImmutableSet.of(q.getSinkName().text()),\n              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n              q.getQueryId(),\n              kafkaStreamsStateCount\n          );\n        }).collect(Collectors.toMap(RunningQuery::getId, Function.identity()));\n  }\n\n  private static void mergeSimple(\n      final List<KsqlEntity> remoteResults,\n      final Map<QueryId, RunningQuery> allResults\n  ) {\n    remoteResults.stream()\n        .map(Queries.class::cast)\n        .map(Queries::getQueries)\n        .flatMap(List::stream)\n        .forEach(rq ->\n            allResults.compute(rq.getId(), (id, existing) -> {\n              if (existing == null) {\n                return rq;\n              }\n\n              for (Entry<KafkaStreams.State, Integer> entry : rq.getState().getState().entrySet()) {\n                existing\n                    .getState()\n                    .updateStateCount(entry.getKey(), entry.getValue());\n              }\n\n              return existing;\n            })\n        );\n  }\n\n  private static Optional<KsqlEntity> executeExtended(\n      final List<KsqlEntity> remoteResults,\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map<QueryId, QueryDescription> queryDescriptions =\n        getLocalExtended(sessionProperties, executionContext);\n\n    mergeExtended(remoteResults, queryDescriptions);\n\n    return Optional.of(new QueryDescriptionList(\n        statement.getStatementText(),\n        new ArrayList<>(queryDescriptions.values())));\n  }\n\n  private static Map<QueryId, QueryDescription> getLocalExtended(\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries().stream()\n        .map(query -> {\n          final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n          ksqlHostQueryState.put(\n              new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n              query.getState());\n          return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n        }).collect(Collectors.toMap(QueryDescription::getId, Function.identity()));\n  }\n\n  private static void mergeExtended(\n      final List<KsqlEntity> remoteResults,\n      final Map<QueryId, QueryDescription> allResults\n  ) {\n    remoteResults.stream()\n        .map(QueryDescriptionList.class::cast)\n        .map(QueryDescriptionList::getQueryDescriptions)\n        .flatMap(List::stream)\n        .forEach(qd ->\n            allResults.compute(qd.getId(), (id, existing) -> {\n              if (existing == null) {\n                return qd;\n              }\n\n              existing.getKsqlHostQueryState().putAll(qd.getKsqlHostQueryState());\n              return existing;\n            })\n        );\n  }\n\n  private static List<KsqlEntity> scatterGather(\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    if (sessionProperties.getInternalRequest()) {\n      return ImmutableList.of();\n    }\n\n    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n        executionContext.getPersistentQueries(),\n        sessionProperties.getKsqlHostInfo()\n    );\n\n    if (remoteHosts.isEmpty()) {\n      return ImmutableList.of();\n    }\n\n    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n\n    try {\n      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n\n      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futures = new HashMap<>();\n      for (HostInfo host : remoteHosts) {\n        final Future<RestResponse<KsqlEntityList>> f = executorService.submit(() -> ksqlClient\n            .makeKsqlRequestWithRequestProperties(\n                ServerUtil.buildRemoteUri(\n                    sessionProperties.getLocalUrl(),\n                    host.host(),\n                    host.port()\n                ),\n                statement.getStatementText(),\n                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n        );\n\n        futures.put(host, f);\n      }\n\n      // Todo: we should NOT ignore these failed hosts:  we should include this in the response.\n      final List<HostInfo> failedHosts = new ArrayList<>();\n      final List<KsqlEntity> results = new ArrayList<>();\n      for (final Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e : futures.entrySet()) {\n        try {\n          final RestResponse<KsqlEntityList> response = e.getValue().get();\n          if (response.isErroneous()) {\n            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n                e.getKey(), response.getErrorMessage().getMessage());\n            failedHosts.add(e.getKey());\n          } else {\n            results.add(response.getResponse().get(0));\n          }\n        } catch (final Exception cause) {\n          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n          failedHosts.add(e.getKey());\n        }\n      }\n\n      return results;\n    } finally {\n      executorService.shutdown();\n    }\n  }\n}", "bodyHTML": "<p dir=\"auto\">There is a lot of code duplication in this class.  Let's break it down and see how we can remove this duplication!</p>\n<p dir=\"auto\">It seems to me that this class needs to be able to:<br>\n- get the local node's running queries<br>\n- get the local node's extended query info<br>\n- scatter-gather either of the above requests to all nodes.</p>\n<p dir=\"auto\">At the moment the scatter-gather code is duplicated: once for each of the type of info we need to get back. But the logic is the same!  Hence we should try to have only one copy of that logic.</p>\n<p dir=\"auto\">My approach to this would to refactor the code so that there is a pair pf method to get the two different types of local info, a pair of methods to do the merging of the two different types and a single method for doing the scatter gather.</p>\n<p dir=\"auto\">If we do all that, then we end up with something like:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"public final class ListQueriesExecutor {\n\n  private static final Logger LOG = LoggerFactory.getLogger(ListQueriesExecutor.class);\n\n  private ListQueriesExecutor() {\n  }\n\n  public static Optional&lt;KsqlEntity&gt; execute(\n      final ConfiguredStatement&lt;ListQueries&gt; statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    final List&lt;KsqlEntity&gt; remoteResults =\n        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n\n    return statement.getStatement().getShowExtended()\n        ? executeExtended(remoteResults, statement, sessionProperties, executionContext)\n        : executeSimple(remoteResults, statement, executionContext);\n  }\n\n  private static Optional&lt;KsqlEntity&gt; executeSimple(\n      final List&lt;KsqlEntity&gt; remoteResults,\n      final ConfiguredStatement&lt;ListQueries&gt; statement,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map&lt;QueryId, RunningQuery&gt; runningQueries = getLocalSimple(executionContext);\n\n    mergeSimple(remoteResults, runningQueries);\n\n    return Optional.of(new Queries(\n        statement.getStatementText(),\n        new ArrayList&lt;&gt;(runningQueries.values())));\n  }\n\n  private static Map&lt;QueryId, RunningQuery&gt; getLocalSimple(\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries()\n        .stream()\n        .map(q -&gt; {\n          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n          return new RunningQuery(\n              q.getStatementString(),\n              ImmutableSet.of(q.getSinkName().text()),\n              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n              q.getQueryId(),\n              kafkaStreamsStateCount\n          );\n        }).collect(Collectors.toMap(RunningQuery::getId, Function.identity()));\n  }\n\n  private static void mergeSimple(\n      final List&lt;KsqlEntity&gt; remoteResults,\n      final Map&lt;QueryId, RunningQuery&gt; allResults\n  ) {\n    remoteResults.stream()\n        .map(Queries.class::cast)\n        .map(Queries::getQueries)\n        .flatMap(List::stream)\n        .forEach(rq -&gt;\n            allResults.compute(rq.getId(), (id, existing) -&gt; {\n              if (existing == null) {\n                return rq;\n              }\n\n              for (Entry&lt;KafkaStreams.State, Integer&gt; entry : rq.getState().getState().entrySet()) {\n                existing\n                    .getState()\n                    .updateStateCount(entry.getKey(), entry.getValue());\n              }\n\n              return existing;\n            })\n        );\n  }\n\n  private static Optional&lt;KsqlEntity&gt; executeExtended(\n      final List&lt;KsqlEntity&gt; remoteResults,\n      final ConfiguredStatement&lt;ListQueries&gt; statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map&lt;QueryId, QueryDescription&gt; queryDescriptions =\n        getLocalExtended(sessionProperties, executionContext);\n\n    mergeExtended(remoteResults, queryDescriptions);\n\n    return Optional.of(new QueryDescriptionList(\n        statement.getStatementText(),\n        new ArrayList&lt;&gt;(queryDescriptions.values())));\n  }\n\n  private static Map&lt;QueryId, QueryDescription&gt; getLocalExtended(\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries().stream()\n        .map(query -&gt; {\n          final HashMap&lt;KsqlHostInfoEntity, String&gt; ksqlHostQueryState = new HashMap&lt;&gt;();\n          ksqlHostQueryState.put(\n              new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n              query.getState());\n          return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n        }).collect(Collectors.toMap(QueryDescription::getId, Function.identity()));\n  }\n\n  private static void mergeExtended(\n      final List&lt;KsqlEntity&gt; remoteResults,\n      final Map&lt;QueryId, QueryDescription&gt; allResults\n  ) {\n    remoteResults.stream()\n        .map(QueryDescriptionList.class::cast)\n        .map(QueryDescriptionList::getQueryDescriptions)\n        .flatMap(List::stream)\n        .forEach(qd -&gt;\n            allResults.compute(qd.getId(), (id, existing) -&gt; {\n              if (existing == null) {\n                return qd;\n              }\n\n              existing.getKsqlHostQueryState().putAll(qd.getKsqlHostQueryState());\n              return existing;\n            })\n        );\n  }\n\n  private static List&lt;KsqlEntity&gt; scatterGather(\n      final ConfiguredStatement&lt;ListQueries&gt; statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    if (sessionProperties.getInternalRequest()) {\n      return ImmutableList.of();\n    }\n\n    final Set&lt;HostInfo&gt; remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n        executionContext.getPersistentQueries(),\n        sessionProperties.getKsqlHostInfo()\n    );\n\n    if (remoteHosts.isEmpty()) {\n      return ImmutableList.of();\n    }\n\n    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n\n    try {\n      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n\n      final Map&lt;HostInfo, Future&lt;RestResponse&lt;KsqlEntityList&gt;&gt;&gt; futures = new HashMap&lt;&gt;();\n      for (HostInfo host : remoteHosts) {\n        final Future&lt;RestResponse&lt;KsqlEntityList&gt;&gt; f = executorService.submit(() -&gt; ksqlClient\n            .makeKsqlRequestWithRequestProperties(\n                ServerUtil.buildRemoteUri(\n                    sessionProperties.getLocalUrl(),\n                    host.host(),\n                    host.port()\n                ),\n                statement.getStatementText(),\n                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n        );\n\n        futures.put(host, f);\n      }\n\n      // Todo: we should NOT ignore these failed hosts:  we should include this in the response.\n      final List&lt;HostInfo&gt; failedHosts = new ArrayList&lt;&gt;();\n      final List&lt;KsqlEntity&gt; results = new ArrayList&lt;&gt;();\n      for (final Entry&lt;HostInfo, Future&lt;RestResponse&lt;KsqlEntityList&gt;&gt;&gt; e : futures.entrySet()) {\n        try {\n          final RestResponse&lt;KsqlEntityList&gt; response = e.getValue().get();\n          if (response.isErroneous()) {\n            LOG.warn(&quot;Failed to retrieve query info from host. host: {}, cause: {}&quot;,\n                e.getKey(), response.getErrorMessage().getMessage());\n            failedHosts.add(e.getKey());\n          } else {\n            results.add(response.getResponse().get(0));\n          }\n        } catch (final Exception cause) {\n          LOG.warn(&quot;Failed to retrieve query info from host. host: &quot; + e.getKey(), cause);\n          failedHosts.add(e.getKey());\n        }\n      }\n\n      return results;\n    } finally {\n      executorService.shutdown();\n    }\n  }\n}\"><pre><span class=\"pl-k\">public</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\">class</span> <span class=\"pl-en\">ListQueriesExecutor</span> {\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">final</span> <span class=\"pl-smi\">Logger</span> <span class=\"pl-c1\">LOG</span> <span class=\"pl-k\">=</span> <span class=\"pl-smi\">LoggerFactory</span><span class=\"pl-k\">.</span>getLogger(<span class=\"pl-smi\">ListQueriesExecutor</span><span class=\"pl-k\">.</span>class);\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-en\">ListQueriesExecutor</span>() {\n  }\n\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">Optional&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-en\">execute</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">ConfiguredStatement&lt;<span class=\"pl-smi\">ListQueries</span>&gt;</span> <span class=\"pl-v\">statement</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">SessionProperties</span> <span class=\"pl-v\">sessionProperties</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlExecutionContext</span> <span class=\"pl-v\">executionContext</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">ServiceContext</span> <span class=\"pl-v\">serviceContext</span>\n  ) {\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> remoteResults <span class=\"pl-k\">=</span>\n        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n\n    <span class=\"pl-k\">return</span> statement<span class=\"pl-k\">.</span>getStatement()<span class=\"pl-k\">.</span>getShowExtended()\n        <span class=\"pl-k\">?</span> executeExtended(remoteResults, statement, sessionProperties, executionContext)\n        <span class=\"pl-k\">:</span> executeSimple(remoteResults, statement, executionContext);\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">Optional&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-en\">executeSimple</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-v\">remoteResults</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">ConfiguredStatement&lt;<span class=\"pl-smi\">ListQueries</span>&gt;</span> <span class=\"pl-v\">statement</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlExecutionContext</span> <span class=\"pl-v\">executionContext</span>\n  ) {\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">QueryId</span>, <span class=\"pl-smi\">RunningQuery</span>&gt;</span> runningQueries <span class=\"pl-k\">=</span> getLocalSimple(executionContext);\n\n    mergeSimple(remoteResults, runningQueries);\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-smi\">Optional</span><span class=\"pl-k\">.</span>of(<span class=\"pl-k\">new</span> <span class=\"pl-smi\">Queries</span>(\n        statement<span class=\"pl-k\">.</span>getStatementText(),\n        <span class=\"pl-k\">new</span> <span class=\"pl-k\">ArrayList&lt;&gt;</span>(runningQueries<span class=\"pl-k\">.</span>values())));\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">QueryId</span>, <span class=\"pl-smi\">RunningQuery</span>&gt;</span> <span class=\"pl-en\">getLocalSimple</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlExecutionContext</span> <span class=\"pl-v\">executionContext</span>\n  ) {\n    <span class=\"pl-k\">return</span> executionContext<span class=\"pl-k\">.</span>getPersistentQueries()\n        .stream()\n        .map(q <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {\n          <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> kafkaStreamsStateCount <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span>();\n          kafkaStreamsStateCount<span class=\"pl-k\">.</span>updateStateCount(q<span class=\"pl-k\">.</span>getState(), <span class=\"pl-c1\">1</span>);\n          <span class=\"pl-k\">return</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">RunningQuery</span>(\n              q<span class=\"pl-k\">.</span>getStatementString(),\n              <span class=\"pl-smi\">ImmutableSet</span><span class=\"pl-k\">.</span>of(q<span class=\"pl-k\">.</span>getSinkName()<span class=\"pl-k\">.</span>text()),\n              <span class=\"pl-smi\">ImmutableSet</span><span class=\"pl-k\">.</span>of(q<span class=\"pl-k\">.</span>getResultTopic()<span class=\"pl-k\">.</span>getKafkaTopicName()),\n              q<span class=\"pl-k\">.</span>getQueryId(),\n              kafkaStreamsStateCount\n          );\n        })<span class=\"pl-k\">.</span>collect(<span class=\"pl-smi\">Collectors</span><span class=\"pl-k\">.</span>toMap(<span class=\"pl-smi\">RunningQuery</span><span class=\"pl-k\">::</span>getId, <span class=\"pl-smi\">Function</span><span class=\"pl-k\">.</span>identity()));\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">mergeSimple</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-v\">remoteResults</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">QueryId</span>, <span class=\"pl-smi\">RunningQuery</span>&gt;</span> <span class=\"pl-v\">allResults</span>\n  ) {\n    remoteResults<span class=\"pl-k\">.</span>stream()\n        .map(<span class=\"pl-smi\">Queries</span><span class=\"pl-k\">.</span>class<span class=\"pl-k\">::</span>cast)\n        .map(<span class=\"pl-smi\">Queries</span><span class=\"pl-k\">::</span>getQueries)\n        .flatMap(<span class=\"pl-smi\">List</span><span class=\"pl-k\">::</span>stream)\n        .forEach(rq <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span>\n            allResults<span class=\"pl-k\">.</span>compute(rq<span class=\"pl-k\">.</span>getId(), (id, existing) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {\n              <span class=\"pl-k\">if</span> (existing <span class=\"pl-k\">==</span> <span class=\"pl-c1\">null</span>) {\n                <span class=\"pl-k\">return</span> rq;\n              }\n\n              <span class=\"pl-k\">for</span> (<span class=\"pl-k\">Entry&lt;<span class=\"pl-smi\">KafkaStreams</span>.</span><span class=\"pl-smi\">State</span>, <span class=\"pl-smi\">Integer</span><span class=\"pl-k\">&gt;</span> entry <span class=\"pl-k\">:</span> rq<span class=\"pl-k\">.</span>getState()<span class=\"pl-k\">.</span>getState()<span class=\"pl-k\">.</span>entrySet()) {\n                existing\n                    .getState()\n                    .updateStateCount(entry<span class=\"pl-k\">.</span>getKey(), entry<span class=\"pl-k\">.</span>getValue());\n              }\n\n              <span class=\"pl-k\">return</span> existing;\n            })\n        );\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">Optional&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-en\">executeExtended</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-v\">remoteResults</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">ConfiguredStatement&lt;<span class=\"pl-smi\">ListQueries</span>&gt;</span> <span class=\"pl-v\">statement</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">SessionProperties</span> <span class=\"pl-v\">sessionProperties</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlExecutionContext</span> <span class=\"pl-v\">executionContext</span>\n  ) {\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">QueryId</span>, <span class=\"pl-smi\">QueryDescription</span>&gt;</span> queryDescriptions <span class=\"pl-k\">=</span>\n        getLocalExtended(sessionProperties, executionContext);\n\n    mergeExtended(remoteResults, queryDescriptions);\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-smi\">Optional</span><span class=\"pl-k\">.</span>of(<span class=\"pl-k\">new</span> <span class=\"pl-smi\">QueryDescriptionList</span>(\n        statement<span class=\"pl-k\">.</span>getStatementText(),\n        <span class=\"pl-k\">new</span> <span class=\"pl-k\">ArrayList&lt;&gt;</span>(queryDescriptions<span class=\"pl-k\">.</span>values())));\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">QueryId</span>, <span class=\"pl-smi\">QueryDescription</span>&gt;</span> <span class=\"pl-en\">getLocalExtended</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">SessionProperties</span> <span class=\"pl-v\">sessionProperties</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlExecutionContext</span> <span class=\"pl-v\">executionContext</span>\n  ) {\n    <span class=\"pl-k\">return</span> executionContext<span class=\"pl-k\">.</span>getPersistentQueries()<span class=\"pl-k\">.</span>stream()\n        .map(query <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {\n          <span class=\"pl-k\">final</span> <span class=\"pl-k\">HashMap&lt;<span class=\"pl-smi\">KsqlHostInfoEntity</span>, <span class=\"pl-smi\">String</span>&gt;</span> ksqlHostQueryState <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;&gt;</span>();\n          ksqlHostQueryState<span class=\"pl-k\">.</span>put(\n              <span class=\"pl-k\">new</span> <span class=\"pl-smi\">KsqlHostInfoEntity</span>(sessionProperties<span class=\"pl-k\">.</span>getKsqlHostInfo()),\n              query<span class=\"pl-k\">.</span>getState());\n          <span class=\"pl-k\">return</span> <span class=\"pl-smi\">QueryDescriptionFactory</span><span class=\"pl-k\">.</span>forQueryMetadata(query, ksqlHostQueryState);\n        })<span class=\"pl-k\">.</span>collect(<span class=\"pl-smi\">Collectors</span><span class=\"pl-k\">.</span>toMap(<span class=\"pl-smi\">QueryDescription</span><span class=\"pl-k\">::</span>getId, <span class=\"pl-smi\">Function</span><span class=\"pl-k\">.</span>identity()));\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">mergeExtended</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-v\">remoteResults</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">QueryId</span>, <span class=\"pl-smi\">QueryDescription</span>&gt;</span> <span class=\"pl-v\">allResults</span>\n  ) {\n    remoteResults<span class=\"pl-k\">.</span>stream()\n        .map(<span class=\"pl-smi\">QueryDescriptionList</span><span class=\"pl-k\">.</span>class<span class=\"pl-k\">::</span>cast)\n        .map(<span class=\"pl-smi\">QueryDescriptionList</span><span class=\"pl-k\">::</span>getQueryDescriptions)\n        .flatMap(<span class=\"pl-smi\">List</span><span class=\"pl-k\">::</span>stream)\n        .forEach(qd <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span>\n            allResults<span class=\"pl-k\">.</span>compute(qd<span class=\"pl-k\">.</span>getId(), (id, existing) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {\n              <span class=\"pl-k\">if</span> (existing <span class=\"pl-k\">==</span> <span class=\"pl-c1\">null</span>) {\n                <span class=\"pl-k\">return</span> qd;\n              }\n\n              existing<span class=\"pl-k\">.</span>getKsqlHostQueryState()<span class=\"pl-k\">.</span>putAll(qd<span class=\"pl-k\">.</span>getKsqlHostQueryState());\n              <span class=\"pl-k\">return</span> existing;\n            })\n        );\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> <span class=\"pl-en\">scatterGather</span>(\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">ConfiguredStatement&lt;<span class=\"pl-smi\">ListQueries</span>&gt;</span> <span class=\"pl-v\">statement</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">SessionProperties</span> <span class=\"pl-v\">sessionProperties</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KsqlExecutionContext</span> <span class=\"pl-v\">executionContext</span>,\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">ServiceContext</span> <span class=\"pl-v\">serviceContext</span>\n  ) {\n    <span class=\"pl-k\">if</span> (sessionProperties<span class=\"pl-k\">.</span>getInternalRequest()) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-smi\">ImmutableList</span><span class=\"pl-k\">.</span>of();\n    }\n\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Set&lt;<span class=\"pl-smi\">HostInfo</span>&gt;</span> remoteHosts <span class=\"pl-k\">=</span> <span class=\"pl-smi\">DiscoverRemoteHostsUtil</span><span class=\"pl-k\">.</span>getRemoteHosts(\n        executionContext<span class=\"pl-k\">.</span>getPersistentQueries(),\n        sessionProperties<span class=\"pl-k\">.</span>getKsqlHostInfo()\n    );\n\n    <span class=\"pl-k\">if</span> (remoteHosts<span class=\"pl-k\">.</span>isEmpty()) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-smi\">ImmutableList</span><span class=\"pl-k\">.</span>of();\n    }\n\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">ExecutorService</span> executorService <span class=\"pl-k\">=</span> <span class=\"pl-smi\">Executors</span><span class=\"pl-k\">.</span>newFixedThreadPool(remoteHosts<span class=\"pl-k\">.</span>size());\n\n    <span class=\"pl-k\">try</span> {\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">SimpleKsqlClient</span> ksqlClient <span class=\"pl-k\">=</span> serviceContext<span class=\"pl-k\">.</span>getKsqlClient();\n\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">HostInfo</span>, <span class=\"pl-k\">Future&lt;<span class=\"pl-k\">RestResponse&lt;<span class=\"pl-smi\">KsqlEntityList</span>&gt;</span>&gt;</span>&gt;</span> futures <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;&gt;</span>();\n      <span class=\"pl-k\">for</span> (<span class=\"pl-smi\">HostInfo</span> host <span class=\"pl-k\">:</span> remoteHosts) {\n        <span class=\"pl-k\">final</span> <span class=\"pl-k\">Future&lt;<span class=\"pl-k\">RestResponse&lt;<span class=\"pl-smi\">KsqlEntityList</span>&gt;</span>&gt;</span> f <span class=\"pl-k\">=</span> executorService<span class=\"pl-k\">.</span>submit(() <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> ksqlClient\n            .makeKsqlRequestWithRequestProperties(\n                <span class=\"pl-smi\">ServerUtil</span><span class=\"pl-k\">.</span>buildRemoteUri(\n                    sessionProperties<span class=\"pl-k\">.</span>getLocalUrl(),\n                    host<span class=\"pl-k\">.</span>host(),\n                    host<span class=\"pl-k\">.</span>port()\n                ),\n                statement<span class=\"pl-k\">.</span>getStatementText(),\n                <span class=\"pl-smi\">Collections</span><span class=\"pl-k\">.</span>singletonMap(<span class=\"pl-smi\">KsqlRequestConfig</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>KSQL_REQUEST_INTERNAL_REQUEST</span>, <span class=\"pl-c1\">true</span>))\n        );\n\n        futures<span class=\"pl-k\">.</span>put(host, f);\n      }\n\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> Todo: we should NOT ignore these failed hosts:  we should include this in the response.</span>\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">HostInfo</span>&gt;</span> failedHosts <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">ArrayList&lt;&gt;</span>();\n      <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">KsqlEntity</span>&gt;</span> results <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">ArrayList&lt;&gt;</span>();\n      <span class=\"pl-k\">for</span> (<span class=\"pl-k\">final</span> <span class=\"pl-k\">Entry&lt;<span class=\"pl-smi\">HostInfo</span>, <span class=\"pl-k\">Future&lt;<span class=\"pl-k\">RestResponse&lt;<span class=\"pl-smi\">KsqlEntityList</span>&gt;</span>&gt;</span>&gt;</span> e <span class=\"pl-k\">:</span> futures<span class=\"pl-k\">.</span>entrySet()) {\n        <span class=\"pl-k\">try</span> {\n          <span class=\"pl-k\">final</span> <span class=\"pl-k\">RestResponse&lt;<span class=\"pl-smi\">KsqlEntityList</span>&gt;</span> response <span class=\"pl-k\">=</span> e<span class=\"pl-k\">.</span>getValue()<span class=\"pl-k\">.</span>get();\n          <span class=\"pl-k\">if</span> (response<span class=\"pl-k\">.</span>isErroneous()) {\n            <span class=\"pl-c1\">LOG</span><span class=\"pl-k\">.</span>warn(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Failed to retrieve query info from host. host: {}, cause: {}<span class=\"pl-pds\">\"</span></span>,\n                e<span class=\"pl-k\">.</span>getKey(), response<span class=\"pl-k\">.</span>getErrorMessage()<span class=\"pl-k\">.</span>getMessage());\n            failedHosts<span class=\"pl-k\">.</span>add(e<span class=\"pl-k\">.</span>getKey());\n          } <span class=\"pl-k\">else</span> {\n            results<span class=\"pl-k\">.</span>add(response<span class=\"pl-k\">.</span>getResponse()<span class=\"pl-k\">.</span>get(<span class=\"pl-c1\">0</span>));\n          }\n        } <span class=\"pl-k\">catch</span> (<span class=\"pl-k\">final</span> <span class=\"pl-smi\">Exception</span> cause) {\n          <span class=\"pl-c1\">LOG</span><span class=\"pl-k\">.</span>warn(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Failed to retrieve query info from host. host: <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> e<span class=\"pl-k\">.</span>getKey(), cause);\n          failedHosts<span class=\"pl-k\">.</span>add(e<span class=\"pl-k\">.</span>getKey());\n        }\n      }\n\n      <span class=\"pl-k\">return</span> results;\n    } <span class=\"pl-k\">finally</span> {\n      executorService<span class=\"pl-k\">.</span>shutdown();\n    }\n  }\n}</pre></div>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:19:35Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjc3NDYzMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402774632", "bodyText": "Thanks for the suggestion! I followed the outline and refactored the code.", "author": "stevenpyzhang", "createdAt": "2020-04-03T07:02:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NjcxMg=="}], "type": "inlineReview", "revised_code": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -61,171 +69,201 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return executeExtended(\n-          statement,\n-          sessionProperties,\n-          executionContext,\n-          serviceContext);\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n+\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n \n-    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n+        statement.getStatementText(),\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n         .stream()\n-        .map(q -> {\n-          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n-          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n-          return new RunningQuery(\n-              q.getStatementString(),\n-              ImmutableSet.of(q.getSinkName().text()),\n-              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-              q.getQueryId(),\n-              kafkaStreamsStateCount\n-          );\n-        }).collect(Collectors.toList());\n-\n-    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n-        Collectors.toMap(\n-            query -> query.getId().toString(),\n-            query -> query));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (remoteHosts.size() != 0) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n+                q.getStatementString(),\n+                ImmutableSet.of(q.getSinkName().text()),\n+                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+                q.getQueryId(),\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n+  }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n       final ConfiguredStatement<ListQueries> statement,\n       final SessionProperties sessionProperties,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<String, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId().toString(),\n-                query -> query));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (remoteHosts.size() != 0) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequestWithRequestProperties(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n-        }\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n \n-        final ConcurrentLinkedQueue<QueryDescription> remoteQueryDescriptions =\n-                new ConcurrentLinkedQueue<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        new ArrayList<>(queryToQueryDescription.values())));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2ODY0Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400868647", "body": "Rather than create the `KafkaStreamsStateCount` here, why not just pass `q.getState()` to the `RunningQuery` constructor and internally create the `KafkaStreamsStateCount` instance?  Thereby removing code duplication...", "bodyText": "Rather than create the KafkaStreamsStateCount here, why not just pass q.getState() to the RunningQuery constructor and internally create the KafkaStreamsStateCount instance?  Thereby removing code duplication...", "bodyHTML": "<p dir=\"auto\">Rather than create the <code>KafkaStreamsStateCount</code> here, why not just pass <code>q.getState()</code> to the <code>RunningQuery</code> constructor and internally create the <code>KafkaStreamsStateCount</code> instance?  Thereby removing code duplication...</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:22:29Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -73,20 +73,20 @@ public final class ListQueriesExecutor {\n     final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n         .stream()\n         .map(q -> {\n-          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n-          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          final QueryStateCount queryStateCount = new QueryStateCount();\n+          queryStateCount.updateStateCount(q.getState(), 1);\n           return new RunningQuery(\n               q.getStatementString(),\n               ImmutableSet.of(q.getSinkName().text()),\n               ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n               q.getQueryId(),\n-              kafkaStreamsStateCount\n+                  queryStateCount\n           );\n         }).collect(Collectors.toList());\n \n-    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+    final Map<QueryId, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n         Collectors.toMap(\n-            query -> query.getId().toString(),\n+            RunningQuery::getId,\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n", "next_change": {"commit": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..2c9408b3c2 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -72,17 +72,15 @@ public final class ListQueriesExecutor {\n \n     final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n         .stream()\n-        .map(q -> {\n-          final QueryStateCount queryStateCount = new QueryStateCount();\n-          queryStateCount.updateStateCount(q.getState(), 1);\n-          return new RunningQuery(\n+        .map(q -> new RunningQuery(\n               q.getStatementString(),\n               ImmutableSet.of(q.getSinkName().text()),\n               ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n               q.getQueryId(),\n-                  queryStateCount\n-          );\n-        }).collect(Collectors.toList());\n+              Optional.empty(),\n+              new QueryStateCount(\n+                  Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ).collect(Collectors.toList());\n \n     final Map<QueryId, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n         Collectors.toMap(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 2c9408b3c2..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -70,22 +71,21 @@ public final class ListQueriesExecutor {\n           serviceContext);\n     }\n \n-    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+    final Map<QueryId, RunningQuery> queryToRunningQuery = executionContext\n+        .getPersistentQueries()\n         .stream()\n-        .map(q -> new RunningQuery(\n-              q.getStatementString(),\n-              ImmutableSet.of(q.getSinkName().text()),\n-              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-              q.getQueryId(),\n-              Optional.empty(),\n-              new QueryStateCount(\n-                  Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n-        ).collect(Collectors.toList());\n-\n-    final Map<QueryId, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n-        Collectors.toMap(\n-            RunningQuery::getId,\n-            query -> query));\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n+                q.getStatementString(),\n+                ImmutableSet.of(q.getSinkName().text()),\n+                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+                q.getQueryId(),\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n+    \n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2OTEzNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400869136", "body": "No need for a concurrent collection type here. It's only being accessed by one thread...", "bodyText": "No need for a concurrent collection type here. It's only being accessed by one thread...", "bodyHTML": "<p dir=\"auto\">No need for a concurrent collection type here. It's only being accessed by one thread...</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:23:08Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..f206c3c92d 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -115,7 +115,7 @@ public final class ListQueriesExecutor {\n         }\n \n         final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-                new ConcurrentLinkedQueue<>();\n+            new ConcurrentLinkedQueue<>();\n         futureRunningQueries.forEach(future -> {\n           try {\n             remoteRunningQueries.addAll(future.get());\n", "next_change": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex f206c3c92d..7cdab1e532 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -90,57 +88,54 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n+      final Set<HostInfo> hosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n \n-        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-            new ConcurrentLinkedQueue<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final String queryId = q.getId().toString();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getState().getState().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getState()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n+      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+      hosts.forEach(host -> {\n+        futureRunningQueries.add(executorService.submit(() -> {\n+          final KsqlEntityList response = serviceContext.getKsqlClient()\n+              .makeKsqlRequestWithRequestProperties(\n+                  ServerUtil.buildRemoteUri(\n+                      sessionProperties.getLocalUrl(),\n+                      host.host(),\n+                      host.port()\n+                  ),\n+                  statement.getStatementText(),\n+                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+              .getResponse();\n+          return ((Queries) response.get(0)).getQueries();\n+        }));\n+      });\n+\n+      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+          new ConcurrentLinkedQueue<>();\n+      futureRunningQueries.forEach(future -> {\n+        try {\n+          remoteRunningQueries.addAll(future.get());\n+        } catch (final Exception e) {\n+          // If the future fails from a server, that result won't be included in the output\n         }\n-      }\n+      });\n+\n+      remoteRunningQueries.forEach(q -> {\n+        final String queryId = q.getId().toString();\n+\n+        // If the query has already been discovered, update the KafkaStreamsStateCount object\n+        if (queryToRunningQuery.containsKey(queryId)) {\n+          q.getState().getState()\n+              .forEach((state, count) ->\n+                  queryToRunningQuery\n+                      .get(queryId)\n+                      .getState()\n+                      .updateStateCount(state, count));\n+        } else {\n+          queryToRunningQuery.put(queryId, q);\n+        }\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 7cdab1e532..5605ff41bd 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,54 +90,57 @@ public final class ListQueriesExecutor {\n             query -> query));\n \n     if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> hosts =\n+      final Set<HostInfo> remoteHosts =\n           DiscoverRemoteHostsUtil.getRemoteHosts(\n               executionContext.getPersistentQueries(),\n               sessionProperties.getKsqlHostInfo());\n-\n-      final ExecutorService executorService = Executors.newFixedThreadPool(hosts.size());\n-      final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-      hosts.forEach(host -> {\n-        futureRunningQueries.add(executorService.submit(() -> {\n-          final KsqlEntityList response = serviceContext.getKsqlClient()\n-              .makeKsqlRequestWithRequestProperties(\n-                  ServerUtil.buildRemoteUri(\n-                      sessionProperties.getLocalUrl(),\n-                      host.host(),\n-                      host.port()\n-                  ),\n-                  statement.getStatementText(),\n-                  Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-              .getResponse();\n-          return ((Queries) response.get(0)).getQueries();\n-        }));\n-      });\n-\n-      final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n-          new ConcurrentLinkedQueue<>();\n-      futureRunningQueries.forEach(future -> {\n-        try {\n-          remoteRunningQueries.addAll(future.get());\n-        } catch (final Exception e) {\n-          // If the future fails from a server, that result won't be included in the output\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n         }\n-      });\n-\n-      remoteRunningQueries.forEach(q -> {\n-        final String queryId = q.getId().toString();\n-\n-        // If the query has already been discovered, update the KafkaStreamsStateCount object\n-        if (queryToRunningQuery.containsKey(queryId)) {\n-          q.getState().getState()\n-              .forEach((state, count) ->\n-                  queryToRunningQuery\n-                      .get(queryId)\n-                      .getState()\n-                      .updateStateCount(state, count));\n-        } else {\n-          queryToRunningQuery.put(queryId, q);\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n         }\n-      });\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 5605ff41bd..4bbf75e856 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -143,7 +144,7 @@ public final class ListQueriesExecutor {\n       }\n     }\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n         new ArrayList<>(queryToRunningQuery.values())));\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex 4bbf75e856..d577083f33 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -146,7 +146,15 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values())));\n+        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList()))));\n   }\n \n   private static Optional<KsqlEntity> executeExtended(\n", "next_change": {"commit": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex d577083f33..cd73be5653 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -163,21 +161,18 @@ public final class ListQueriesExecutor {\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final List<QueryDescription> queryDescriptions = \n-        executionContext.getPersistentQueries().stream()\n-            .map(query -> {\n-              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-              ksqlHostQueryState.put(\n-                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                  query.getState());\n-              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }).collect(Collectors.toList());\n-\n-    final Map<QueryId, QueryDescription> queryToQueryDescription =\n-        queryDescriptions.stream().collect(\n-            Collectors.toMap(\n-                query -> query.getId(),\n-                query -> query));\n+    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> {\n+                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+                ksqlHostQueryState.put(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState());\n+                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }));\n \n     if (!sessionProperties.getInternalRequest()) {\n       final Set<HostInfo> remoteHosts =\n", "next_change": {"commit": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex cd73be5653..37cb1e52ec 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -85,152 +116,154 @@ public final class ListQueriesExecutor {\n                 new QueryStateCount(\n                     Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n         ));\n-    \n+  }\n \n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-      \n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureRunningQueries.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((Queries) response.get(0)).getQueries();\n-          }));\n-        }\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n \n-        final ArrayList<RunningQuery> remoteRunningQueries =\n-            new ArrayList<>();\n-        futureRunningQueries.forEach(future -> {\n-          try {\n-            remoteRunningQueries.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (RunningQuery q : remoteRunningQueries) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, update the KafkaStreamsStateCount object\n-          if (queryToRunningQuery.containsKey(queryId)) {\n-            for (Map.Entry<KafkaStreams.State, Integer> entry :\n-                q.getStateCount().getStates().entrySet()) {\n-              queryToRunningQuery\n-                  .get(queryId)\n-                  .getStateCount()\n-                  .updateStateCount(entry.getKey(), entry.getValue());\n-            }\n-          } else {\n-            queryToRunningQuery.put(queryId, q);\n-          }\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n       }\n     }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n \n-    return Optional.of(new Queries(\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        new ArrayList<>(queryToRunningQuery.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList()))));\n+        new ArrayList<>(queryDescriptions.values())));\n   }\n \n-  private static Optional<KsqlEntity> executeExtended(\n-      final ConfiguredStatement<ListQueries> statement,\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n       final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n+      final KsqlExecutionContext executionContext\n   ) {\n-    final Map<QueryId, QueryDescription> queryToQueryDescription = executionContext\n+    return executionContext\n         .getPersistentQueries()\n         .stream()\n         .collect(Collectors.toMap(\n             PersistentQueryMetadata::getQueryId,\n-            query -> {\n-                final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n-                ksqlHostQueryState.put(\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n                     new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n-                    query.getState());\n-                return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n-            }));\n-\n-    if (!sessionProperties.getInternalRequest()) {\n-      final Set<HostInfo> remoteHosts =\n-          DiscoverRemoteHostsUtil.getRemoteHosts(\n-              executionContext.getPersistentQueries(),\n-              sessionProperties.getKsqlHostInfo());\n-\n-      if (!remoteHosts.isEmpty()) {\n-        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n-        final List<Future<List<QueryDescription>>> futureQueryDescriptions = new ArrayList<>();\n-        for (HostInfo host : remoteHosts) {\n-          futureQueryDescriptions.add(executorService.submit(() -> {\n-            final KsqlEntityList response = serviceContext.getKsqlClient()\n-                .makeKsqlRequest(\n-                    ServerUtil.buildRemoteUri(\n-                        sessionProperties.getLocalUrl(),\n-                        host.host(),\n-                        host.port()\n-                    ),\n-                    statement.getStatementText(),\n-                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n-                .getResponse();\n-            return ((QueryDescriptionList) response.get(0)).getQueryDescriptions();\n-          }));\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n         }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n \n-        final ArrayList<QueryDescription> remoteQueryDescriptions =\n-            new ArrayList<>();\n-        futureQueryDescriptions.forEach(future -> {\n-          try {\n-            remoteQueryDescriptions.addAll(future.get());\n-          } catch (final Exception e) {\n-            // If the future fails from a server, that result won't be included in the output\n-          }\n-        });\n-\n-        executorService.shutdown();\n-        for (QueryDescription q : remoteQueryDescriptions) {\n-          final QueryId queryId = q.getId();\n-\n-          // If the query has already been discovered, add to the ksqlQueryHostState mapping\n-          if (queryToQueryDescription.containsKey(queryId)) {\n-            for (Map.Entry<KsqlHostInfoEntity, String> entry :\n-                q.getKsqlHostQueryState().entrySet()) {\n-              queryToQueryDescription\n-                  .get(queryId)\n-                  .getKsqlHostQueryState()\n-                  .put(entry.getKey(), entry.getValue());\n-            }\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n           } else {\n-            queryToQueryDescription.put(queryId, q);\n+            results.add(response.getResponse().get(0));\n           }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n         }\n       }\n-    }\n \n-    return Optional.of(new QueryDescriptionList(\n-        statement.getStatementText(),\n-        queryToQueryDescription.values()));\n+      return results;\n+    } finally {\n+      executorService.shutdown();\n+    }\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400871606", "body": "Would be good to see tests added to cover when the passed map is NOT empty.", "bodyText": "Would be good to see tests added to cover when the passed map is NOT empty.", "bodyHTML": "<p dir=\"auto\">Would be good to see tests added to cover when the passed map is NOT empty.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:26:59Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/entity/QueryDescriptionFactoryTest.java", "diffHunk": "@@ -117,7 +117,7 @@ public void setUp() {\n         queryCloseCallback,\n         closeTimeout);\n \n-    transientQueryDescription = QueryDescriptionFactory.forQueryMetadata(transientQuery);\n+    transientQueryDescription = QueryDescriptionFactory.forQueryMetadata(transientQuery, Collections.emptyMap());", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NTM2OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401955369", "bodyText": "The passed map should always be empty for now since the only way forQueryMetadata() would be called on a transient query would be in ExplainExecutor.explainStatement() and the query isn't actually running at that point", "author": "stevenpyzhang", "createdAt": "2020-04-01T22:50:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NzYzMQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401957631", "bodyText": "after #4308 is completed, there should be tests with non-empty maps for transient queries", "author": "stevenpyzhang", "createdAt": "2020-04-01T22:56:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NjI4MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400876281", "body": "1. There's no need to parse APPLICATION_SERVER: you can just build it with known host & port.  \r\n2. please try and avoid subclassing HashMap just to add an entry.  Just using `ImmutableMap`.\r\n\r\n```java\r\nprivate static final String APPLICATION_HOST = \"localhost\";\r\n  private static final int APPLICATION_PORT = 9099;\r\n  private static final String APPLICATION_SERVER = \"http://\" + APPLICATION_HOST + \":\" + APPLICATION_PORT;\r\n\r\n...\r\n\r\n@Test\r\n  public void shouldShowQueriesExtended() {\r\n    // Given:\r\n    final Map<String, Object> overriddenProperties =\r\n        Collections.singletonMap(\"ksql.streams.auto.offset.reset\", \"earliest\");\r\n\r\n    final List<PersistentQueryMetadata> queryMetadata = createQueries(\r\n        \"CREATE STREAM test_describe_1 AS SELECT * FROM test_stream;\" +\r\n            \"CREATE STREAM test_describe_2 AS SELECT * FROM test_stream;\", overriddenProperties);\r\n\r\n    // When:\r\n    final QueryDescriptionList descriptionList = makeSingleRequest(\r\n        \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\r\n\r\n    // Then:\r\n    final Map<KsqlHostInfoEntity, String> queryHostState = ImmutableMap.of(\r\n        new KsqlHostInfoEntity(APPLICATION_HOST, APPLICATION_PORT),\r\n        \"CREATED\"\r\n    );\r\n\r\n    assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\r\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\r\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));\r\n  }\r\n```", "bodyText": "There's no need to parse APPLICATION_SERVER: you can just build it with known host & port.\nplease try and avoid subclassing HashMap just to add an entry.  Just using ImmutableMap.\n\nprivate static final String APPLICATION_HOST = \"localhost\";\n  private static final int APPLICATION_PORT = 9099;\n  private static final String APPLICATION_SERVER = \"http://\" + APPLICATION_HOST + \":\" + APPLICATION_PORT;\n\n...\n\n@Test\n  public void shouldShowQueriesExtended() {\n    // Given:\n    final Map<String, Object> overriddenProperties =\n        Collections.singletonMap(\"ksql.streams.auto.offset.reset\", \"earliest\");\n\n    final List<PersistentQueryMetadata> queryMetadata = createQueries(\n        \"CREATE STREAM test_describe_1 AS SELECT * FROM test_stream;\" +\n            \"CREATE STREAM test_describe_2 AS SELECT * FROM test_stream;\", overriddenProperties);\n\n    // When:\n    final QueryDescriptionList descriptionList = makeSingleRequest(\n        \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n\n    // Then:\n    final Map<KsqlHostInfoEntity, String> queryHostState = ImmutableMap.of(\n        new KsqlHostInfoEntity(APPLICATION_HOST, APPLICATION_PORT),\n        \"CREATED\"\n    );\n\n    assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));\n  }", "bodyHTML": "<ol dir=\"auto\">\n<li>There's no need to parse APPLICATION_SERVER: you can just build it with known host &amp; port.</li>\n<li>please try and avoid subclassing HashMap just to add an entry.  Just using <code>ImmutableMap</code>.</li>\n</ol>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"private static final String APPLICATION_HOST = &quot;localhost&quot;;\n  private static final int APPLICATION_PORT = 9099;\n  private static final String APPLICATION_SERVER = &quot;http://&quot; + APPLICATION_HOST + &quot;:&quot; + APPLICATION_PORT;\n\n...\n\n@Test\n  public void shouldShowQueriesExtended() {\n    // Given:\n    final Map&lt;String, Object&gt; overriddenProperties =\n        Collections.singletonMap(&quot;ksql.streams.auto.offset.reset&quot;, &quot;earliest&quot;);\n\n    final List&lt;PersistentQueryMetadata&gt; queryMetadata = createQueries(\n        &quot;CREATE STREAM test_describe_1 AS SELECT * FROM test_stream;&quot; +\n            &quot;CREATE STREAM test_describe_2 AS SELECT * FROM test_stream;&quot;, overriddenProperties);\n\n    // When:\n    final QueryDescriptionList descriptionList = makeSingleRequest(\n        &quot;SHOW QUERIES EXTENDED;&quot;, QueryDescriptionList.class);\n\n    // Then:\n    final Map&lt;KsqlHostInfoEntity, String&gt; queryHostState = ImmutableMap.of(\n        new KsqlHostInfoEntity(APPLICATION_HOST, APPLICATION_PORT),\n        &quot;CREATED&quot;\n    );\n\n    assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));\n  }\"><pre><span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">final</span> <span class=\"pl-smi\">String</span> <span class=\"pl-c1\">APPLICATION_HOST</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>localhost<span class=\"pl-pds\">\"</span></span>;\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\">int</span> <span class=\"pl-c1\">APPLICATION_PORT</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">9099</span>;\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">final</span> <span class=\"pl-smi\">String</span> <span class=\"pl-c1\">APPLICATION_SERVER</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>http://<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-c1\">APPLICATION_HOST</span> <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>:<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-c1\">APPLICATION_PORT</span>;\n\n<span class=\"pl-c1\">...</span>\n\n<span class=\"pl-k\">@Test</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> shouldShowQueriesExtended() {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Given:</span>\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, <span class=\"pl-smi\">Object</span>&gt;</span> overriddenProperties <span class=\"pl-k\">=</span>\n        <span class=\"pl-smi\">Collections</span><span class=\"pl-k\">.</span>singletonMap(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ksql.streams.auto.offset.reset<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>earliest<span class=\"pl-pds\">\"</span></span>);\n\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">PersistentQueryMetadata</span>&gt;</span> queryMetadata <span class=\"pl-k\">=</span> createQueries(\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CREATE STREAM test_describe_1 AS SELECT * FROM test_stream;<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span>\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CREATE STREAM test_describe_2 AS SELECT * FROM test_stream;<span class=\"pl-pds\">\"</span></span>, overriddenProperties);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> When:</span>\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">QueryDescriptionList</span> descriptionList <span class=\"pl-k\">=</span> makeSingleRequest(\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SHOW QUERIES EXTENDED;<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">QueryDescriptionList</span><span class=\"pl-k\">.</span>class);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Then:</span>\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">KsqlHostInfoEntity</span>, <span class=\"pl-smi\">String</span>&gt;</span> queryHostState <span class=\"pl-k\">=</span> <span class=\"pl-smi\">ImmutableMap</span><span class=\"pl-k\">.</span>of(\n        <span class=\"pl-k\">new</span> <span class=\"pl-smi\">KsqlHostInfoEntity</span>(<span class=\"pl-c1\">APPLICATION_HOST</span>, <span class=\"pl-c1\">APPLICATION_PORT</span>),\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CREATED<span class=\"pl-pds\">\"</span></span>\n    );\n\n    assertThat(descriptionList<span class=\"pl-k\">.</span>getQueryDescriptions(), containsInAnyOrder(\n        <span class=\"pl-smi\">QueryDescriptionFactory</span><span class=\"pl-k\">.</span>forQueryMetadata(queryMetadata<span class=\"pl-k\">.</span>get(<span class=\"pl-c1\">0</span>), queryHostState),\n        <span class=\"pl-smi\">QueryDescriptionFactory</span><span class=\"pl-k\">.</span>forQueryMetadata(queryMetadata<span class=\"pl-k\">.</span>get(<span class=\"pl-c1\">1</span>), queryHostState)));\n  }</pre></div>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:34:14Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java", "diffHunk": "@@ -539,10 +544,18 @@ public void shouldShowQueriesExtended() {\n     final QueryDescriptionList descriptionList = makeSingleRequest(\n         \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n \n+    final HostInfo hostInfo = ServerUtil.parseHostInfo(APPLICATION_SERVER);\n+    final HashMap<KsqlHostInfoEntity, String> queryHostState = \n+        new HashMap<KsqlHostInfoEntity, String>(){{ \n+          put(\n+              new KsqlHostInfoEntity(hostInfo.host(), hostInfo.port()),\n+              \"CREATED\"\n+          );\n+    }};\n     // Then:\n     assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n-        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0)),\n-        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1))));\n+        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n+        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\nindex 9a261070b5..320fbe6d50 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n", "chunk": "@@ -544,14 +548,8 @@ public class KsqlResourceTest {\n     final QueryDescriptionList descriptionList = makeSingleRequest(\n         \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n \n-    final HostInfo hostInfo = ServerUtil.parseHostInfo(APPLICATION_SERVER);\n-    final HashMap<KsqlHostInfoEntity, String> queryHostState = \n-        new HashMap<KsqlHostInfoEntity, String>(){{ \n-          put(\n-              new KsqlHostInfoEntity(hostInfo.host(), hostInfo.port()),\n-              \"CREATED\"\n-          );\n-    }};\n+    final Map<KsqlHostInfoEntity, String> queryHostState =\n+        ImmutableMap.of(new KsqlHostInfoEntity(APPLICATION_HOST, APPLICATION_PORT), \"CREATED\");\n     // Then:\n     assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n         QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NzExMw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400877113", "body": "The code would be a little cleaner If the `KafkaStreamsStateCount` constructor too the initial state, and used that to set that states count to `1`.  You could then inline the construction.\r\n\r\n```suggestion\r\n          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount(md.getState());", "bodyText": "The code would be a little cleaner If the KafkaStreamsStateCount constructor too the initial state, and used that to set that states count to 1.  You could then inline the construction.\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          \n          \n            \n                      kafkaStreamsStateCount.updateStateCount(md.getState(), 1);\n          \n          \n            \n                      final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount(md.getState());", "bodyHTML": "<p dir=\"auto\">The code would be a little cleaner If the <code>KafkaStreamsStateCount</code> constructor too the initial state, and used that to set that states count to <code>1</code>.  You could then inline the construction.</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">          <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> kafkaStreamsStateCount <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span>();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">          kafkaStreamsStateCount<span class=\"pl-k\">.</span>updateStateCount(md<span class=\"pl-k\">.</span>getState(), <span class=\"pl-c1\">1</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">          <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> kafkaStreamsStateCount <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span>(md<span class=\"pl-k\">.</span>getState());</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "big-andy-coates", "createdAt": "2020-03-31T12:35:40Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java", "diffHunk": "@@ -1981,14 +1994,17 @@ private PersistentQueryMetadata createQuery(\n \n     return createQueries(sql, overriddenProperties)\n         .stream()\n-        .map(md -> new RunningQuery(\n+        .map(md -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(md.getState(), 1);", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDI4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640285", "bodyText": "I think the introduction of this constructor public QueryStateCount(final Map<KafkaStreams.State, Integer> states) is sufficient for an initial state count", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:49:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NzExMw=="}], "type": "inlineReview", "revised_code": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\nindex 9a261070b5..320fbe6d50 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n", "chunk": "@@ -1995,14 +1993,14 @@ public class KsqlResourceTest {\n     return createQueries(sql, overriddenProperties)\n         .stream()\n         .map(md -> {\n-          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n-          kafkaStreamsStateCount.updateStateCount(md.getState(), 1);\n+          final QueryStateCount queryStateCount = new QueryStateCount();\n+          queryStateCount.updateStateCount(md.getState(), 1);\n           return new RunningQuery(\n             md.getStatementString(),\n             ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n             ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n             md.getQueryId(),\n-            kafkaStreamsStateCount\n+                  queryStateCount\n           );\n         }).collect(Collectors.toList());\n   }\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\nindex 320fbe6d50..744d8e2b46 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n", "chunk": "@@ -2000,8 +1997,8 @@ public class KsqlResourceTest {\n             ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n             ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n             md.getQueryId(),\n-                  queryStateCount\n-          );\n+            Optional.empty(),\n+            queryStateCount);\n         }).collect(Collectors.toList());\n   }\n \n", "next_change": {"commit": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\nindex 744d8e2b46..89f0cdaf36 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n", "chunk": "@@ -1989,17 +1990,15 @@ public class KsqlResourceTest {\n \n     return createQueries(sql, overriddenProperties)\n         .stream()\n-        .map(md -> {\n-          final QueryStateCount queryStateCount = new QueryStateCount();\n-          queryStateCount.updateStateCount(md.getState(), 1);\n-          return new RunningQuery(\n+        .map(md -> new RunningQuery(\n             md.getStatementString(),\n             ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n             ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n             md.getQueryId(),\n             Optional.empty(),\n-            queryStateCount);\n-        }).collect(Collectors.toList());\n+            new QueryStateCount(\n+                Collections.singletonMap(KafkaStreams.State.valueOf(md.getState()), 1)))\n+        ).collect(Collectors.toList());\n   }\n \n   private KsqlErrorMessage makeFailingRequest(final String ksql, final Code errorCode) {\n", "next_change": {"commit": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\nindex 89f0cdaf36..abdedfd1af 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n", "chunk": "@@ -1990,15 +1990,18 @@ public class KsqlResourceTest {\n \n     return createQueries(sql, overriddenProperties)\n         .stream()\n-        .map(md -> new RunningQuery(\n-            md.getStatementString(),\n-            ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n-            ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n-            md.getQueryId(),\n-            Optional.empty(),\n-            new QueryStateCount(\n-                Collections.singletonMap(KafkaStreams.State.valueOf(md.getState()), 1)))\n-        ).collect(Collectors.toList());\n+        .map(md -> {\n+            final QueryStateCount queryStateCount = new QueryStateCount(\n+                  Collections.singletonMap(KafkaStreams.State.valueOf(md.getState()), 1));\n+          return new RunningQuery(\n+              md.getStatementString(),\n+              ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n+              ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n+              md.getQueryId(),\n+              Optional.of(queryStateCount.toString()),\n+              queryStateCount);\n+            }\n+    ).collect(Collectors.toList());\n   }\n \n   private KsqlErrorMessage makeFailingRequest(final String ksql, final Code errorCode) {\n", "next_change": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\nindex abdedfd1af..bd4be631cd 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java\n", "chunk": "@@ -1990,17 +1990,13 @@ public class KsqlResourceTest {\n \n     return createQueries(sql, overriddenProperties)\n         .stream()\n-        .map(md -> {\n-            final QueryStateCount queryStateCount = new QueryStateCount(\n-                  Collections.singletonMap(KafkaStreams.State.valueOf(md.getState()), 1));\n-          return new RunningQuery(\n-              md.getStatementString(),\n-              ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n-              ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n-              md.getQueryId(),\n-              Optional.of(queryStateCount.toString()),\n-              queryStateCount);\n-            }\n+        .map(md -> new RunningQuery(\n+            md.getStatementString(),\n+            ImmutableSet.of(md.getSinkName().toString(FormatOptions.noEscape())),\n+            ImmutableSet.of(md.getResultTopic().getKafkaTopicName()),\n+            md.getQueryId(),\n+            new QueryStateCount(\n+                Collections.singletonMap(KafkaStreams.State.valueOf(md.getState()), 1)))\n     ).collect(Collectors.toList());\n   }\n \n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3ODU4OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400878589", "body": "Why not just inline this? i.e. make all the code that calls this just call the new version with the extra map param?\r\n\r\n(In case you're unaware IntelliJ can do this for you: with cursor on the function name, right click -> refactor -> inline method)", "bodyText": "Why not just inline this? i.e. make all the code that calls this just call the new version with the extra map param?\n(In case you're unaware IntelliJ can do this for you: with cursor on the function name, right click -> refactor -> inline method)", "bodyHTML": "<p dir=\"auto\">Why not just inline this? i.e. make all the code that calls this just call the new version with the extra map param?</p>\n<p dir=\"auto\">(In case you're unaware IntelliJ can do this for you: with cursor on the function name, right click -&gt; refactor -&gt; inline method)</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:37:53Z", "path": "ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java", "diffHunk": "@@ -138,23 +138,31 @@ public KsqlTarget properties(final Map<String, ?> properties) {\n \n   public RestResponse<KsqlEntityList> postKsqlRequest(\n       final String ksql,\n+      final Map<String, ?> requestProperties,\n       final Optional<Long> previousCommandSeqNum\n   ) {\n     return post(\n         KSQL_PATH,\n-        createKsqlRequest(ksql, Collections.emptyMap(), previousCommandSeqNum),\n+        createKsqlRequest(ksql, requestProperties, previousCommandSeqNum),\n         r -> deserialize(r.getBody(), KsqlEntityList.class)\n     );\n   }\n+  \n+  public RestResponse<KsqlEntityList> postKsqlRequest(", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NjQ1Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402656453", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:37:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3ODU4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "changed_code": [{"header": "diff --git a/ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java b/ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java\nindex 65109d91eb..25966775fa 100644\n--- a/ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java\n+++ b/ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java\n", "chunk": "@@ -147,13 +147,6 @@ public final class KsqlTarget {\n         r -> deserialize(r.getBody(), KsqlEntityList.class)\n     );\n   }\n-  \n-  public RestResponse<KsqlEntityList> postKsqlRequest(\n-      final String ksql,\n-      final Optional<Long> previousCommandSeqNum\n-  ) {\n-    return postKsqlRequest(ksql, Collections.emptyMap(), previousCommandSeqNum);\n-  }\n \n   public RestResponse<List<StreamedRow>> postQueryRequest(\n       final String ksql,\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg4NTQ2Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400885467", "body": "Would be nice to decouple this class from `KafkaStream.State`.  This enum is encapsulated by `QueryMetadata` deliberately.  If you would rather an enum that a String, (and I can understand you would), then add a new KSQL QueryState enum.   (This will probably be needed by @rodesai's work on query state anyway).\r\n\r\nAlso consider renaming this class to `QueryStateCounts`, which is less coupled to KS.", "bodyText": "Would be nice to decouple this class from KafkaStream.State.  This enum is encapsulated by QueryMetadata deliberately.  If you would rather an enum that a String, (and I can understand you would), then add a new KSQL QueryState enum.   (This will probably be needed by @rodesai's work on query state anyway).\nAlso consider renaming this class to QueryStateCounts, which is less coupled to KS.", "bodyHTML": "<p dir=\"auto\">Would be nice to decouple this class from <code>KafkaStream.State</code>.  This enum is encapsulated by <code>QueryMetadata</code> deliberately.  If you would rather an enum that a String, (and I can understand you would), then add a new KSQL QueryState enum.   (This will probably be needed by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/rodesai/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rodesai\">@rodesai</a>'s work on query state anyway).</p>\n<p dir=\"auto\">Also consider renaming this class to <code>QueryStateCounts</code>, which is less coupled to KS.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T12:48:57Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n+\n+  public KafkaStreamsStateCount() {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjcxOTkxMQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402719911", "bodyText": "Renamed the file, haven't gotten to the creating KSQL query state enums yet", "author": "stevenpyzhang", "createdAt": "2020-04-03T03:40:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg4NTQ2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex f9a742237e..2993d3a777 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -33,17 +35,17 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a EnumMap so toString() will always return the same string\n-  private final EnumMap<KafkaStreams.State, Integer> state;\n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnEnumMap();\n+    this.state = returnTreeMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n     final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n+    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n     for (String stateCount : parts) {\n       final String[] split = stateCount.split(\":\");\n       if (split.length != 2) {\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 2993d3a777..f9a742237e 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -35,17 +33,17 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a TreeMap so toString() will always return the same string\n-  private final TreeMap<KafkaStreams.State, Integer> state;\n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnTreeMap();\n+    this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n     final String [] parts = serializedPair.split(\",\");\n-    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n+    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n     for (String stateCount : parts) {\n       final String[] split = stateCount.split(\":\");\n       if (split.length != 2) {\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nsimilarity index 58%\nrename from ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nrename to ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nindex f9a742237e..64d6143d85 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\n", "chunk": "@@ -31,41 +33,27 @@ import org.apache.kafka.streams.KafkaStreams;\n  * across multiple servers. Used in {@link RunningQuery}.\n  */\n @JsonIgnoreProperties(ignoreUnknown = true)\n-public class KafkaStreamsStateCount {\n+public class QueryStateCount {\n   \n   // Use a EnumMap so toString() will always return the same string\n   private final EnumMap<KafkaStreams.State, Integer> state;\n \n-  public KafkaStreamsStateCount() {\n+  public QueryStateCount() {\n     this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n-  public KafkaStreamsStateCount(final String serializedPair) {\n-    final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n-    for (String stateCount : parts) {\n-      final String[] split = stateCount.split(\":\");\n-      if (split.length != 2) {\n-        throw new KsqlException(\n-            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair);\n-      }\n-\n-      final String currentState = split[0].trim();\n-\n-      try {\n-        final int count = Integer.parseInt(split[1]);\n-        deserializedKafkaStreamsStateCount.put(\n-            KafkaStreams.State.valueOf(currentState), count);\n-      } catch (final Exception e) {\n-        throw new KsqlException(\n-            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair, e);\n-      }\n-    }\n-\n-    this.state = deserializedKafkaStreamsStateCount;\n+  public QueryStateCount(final String serializedPair) {\n+    final Map<String, String> pairs =\n+        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n+    this.state = pairs.entrySet().stream().collect(\n+        Collectors.toMap(\n+            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n+            e -> Integer.parseInt(e.getValue()),\n+            (k1, k2) -> {\n+              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n+            },\n+            () -> new EnumMap<>(KafkaStreams.State.class)));\n   }\n \n   public void updateStateCount(final String state, final int change) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5MzgyOQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400893829", "body": "I'm a little confused by this class.  Why does it have all this code to convert to and from a string representation in the form `<state>: <count>, <state>: <count>`?  Why not just return this as a JSON Object?  The Jackson does all the heavy lifting for you!\r\n\r\n```json\r\n {\r\n     \"CREATED\": 1,\r\n     \"RUNNING\": 2\r\n}\r\n```\r\n\r\nThis can be achieved with:\r\n\r\n```java\r\n@JsonIgnoreProperties(ignoreUnknown = true)\r\npublic class KafkaStreamsStateCount {\r\n\r\n  private final Map<State, Integer> states;\r\n\r\n  public KafkaStreamsStateCount() {\r\n    this.states = new HashMap<>();\r\n  }\r\n\r\n  @SuppressWarnings(\"unused\") // Invoked by reflection\r\n  @JsonCreator\r\n  public KafkaStreamsStateCount(final Map<State, Integer> states) {\r\n    this.states = new HashMap<>(states);\r\n  }\r\n\r\n  public void updateStateCount(final String state, final int change) {\r\n    updateStateCount(KafkaStreams.State.valueOf(state), change);\r\n  }\r\n\r\n  public void updateStateCount(final KafkaStreams.State state, final int change) {\r\n    states.compute(state, (key, existing) ->\r\n        existing == null\r\n            ? change\r\n            : existing + change\r\n    );\r\n  }\r\n\r\n  @JsonValue\r\n  public Map<KafkaStreams.State, Integer> getState() {\r\n    return states;\r\n  }\r\n\r\n  @Override\r\n  public boolean equals(final Object o) {\r\n    if (this == o) {\r\n      return true;\r\n    }\r\n\r\n    if (o == null || getClass() != o.getClass()) {\r\n      return false;\r\n    }\r\n\r\n    final KafkaStreamsStateCount that = (KafkaStreamsStateCount) o;\r\n    return Objects.equals(states, that.states);\r\n  }\r\n\r\n  @Override\r\n  public int hashCode() {\r\n    return Objects.hash(states);\r\n  }\r\n}\r\n```", "bodyText": "I'm a little confused by this class.  Why does it have all this code to convert to and from a string representation in the form <state>: <count>, <state>: <count>?  Why not just return this as a JSON Object?  The Jackson does all the heavy lifting for you!\n {\n     \"CREATED\": 1,\n     \"RUNNING\": 2\n}\nThis can be achieved with:\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic class KafkaStreamsStateCount {\n\n  private final Map<State, Integer> states;\n\n  public KafkaStreamsStateCount() {\n    this.states = new HashMap<>();\n  }\n\n  @SuppressWarnings(\"unused\") // Invoked by reflection\n  @JsonCreator\n  public KafkaStreamsStateCount(final Map<State, Integer> states) {\n    this.states = new HashMap<>(states);\n  }\n\n  public void updateStateCount(final String state, final int change) {\n    updateStateCount(KafkaStreams.State.valueOf(state), change);\n  }\n\n  public void updateStateCount(final KafkaStreams.State state, final int change) {\n    states.compute(state, (key, existing) ->\n        existing == null\n            ? change\n            : existing + change\n    );\n  }\n\n  @JsonValue\n  public Map<KafkaStreams.State, Integer> getState() {\n    return states;\n  }\n\n  @Override\n  public boolean equals(final Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    final KafkaStreamsStateCount that = (KafkaStreamsStateCount) o;\n    return Objects.equals(states, that.states);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hash(states);\n  }\n}", "bodyHTML": "<p dir=\"auto\">I'm a little confused by this class.  Why does it have all this code to convert to and from a string representation in the form <code>&lt;state&gt;: &lt;count&gt;, &lt;state&gt;: &lt;count&gt;</code>?  Why not just return this as a JSON Object?  The Jackson does all the heavy lifting for you!</p>\n<div class=\"highlight highlight-source-json position-relative overflow-auto\" data-snippet-clipboard-copy-content=\" {\n     &quot;CREATED&quot;: 1,\n     &quot;RUNNING&quot;: 2\n}\"><pre> {\n     <span class=\"pl-ent\">\"CREATED\"</span>: <span class=\"pl-c1\">1</span>,\n     <span class=\"pl-ent\">\"RUNNING\"</span>: <span class=\"pl-c1\">2</span>\n}</pre></div>\n<p dir=\"auto\">This can be achieved with:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@JsonIgnoreProperties(ignoreUnknown = true)\npublic class KafkaStreamsStateCount {\n\n  private final Map&lt;State, Integer&gt; states;\n\n  public KafkaStreamsStateCount() {\n    this.states = new HashMap&lt;&gt;();\n  }\n\n  @SuppressWarnings(&quot;unused&quot;) // Invoked by reflection\n  @JsonCreator\n  public KafkaStreamsStateCount(final Map&lt;State, Integer&gt; states) {\n    this.states = new HashMap&lt;&gt;(states);\n  }\n\n  public void updateStateCount(final String state, final int change) {\n    updateStateCount(KafkaStreams.State.valueOf(state), change);\n  }\n\n  public void updateStateCount(final KafkaStreams.State state, final int change) {\n    states.compute(state, (key, existing) -&gt;\n        existing == null\n            ? change\n            : existing + change\n    );\n  }\n\n  @JsonValue\n  public Map&lt;KafkaStreams.State, Integer&gt; getState() {\n    return states;\n  }\n\n  @Override\n  public boolean equals(final Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    final KafkaStreamsStateCount that = (KafkaStreamsStateCount) o;\n    return Objects.equals(states, that.states);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hash(states);\n  }\n}\"><pre><span class=\"pl-k\">@JsonIgnoreProperties</span>(<span class=\"pl-c1\">ignoreUnknown</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">true</span>)\n<span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en\">KafkaStreamsStateCount</span> {\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">State</span>, <span class=\"pl-smi\">Integer</span>&gt;</span> states;\n\n  <span class=\"pl-k\">public</span> <span class=\"pl-en\">KafkaStreamsStateCount</span>() {\n    <span class=\"pl-c1\">this</span><span class=\"pl-k\">.</span>states <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;&gt;</span>();\n  }\n\n  <span class=\"pl-k\">@SuppressWarnings</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>unused<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-c\"><span class=\"pl-c\">//</span> Invoked by reflection</span>\n  <span class=\"pl-k\">@JsonCreator</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-en\">KafkaStreamsStateCount</span>(<span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">State</span>, <span class=\"pl-smi\">Integer</span>&gt;</span> <span class=\"pl-v\">states</span>) {\n    <span class=\"pl-c1\">this</span><span class=\"pl-k\">.</span>states <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;&gt;</span>(states);\n  }\n\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">updateStateCount</span>(<span class=\"pl-k\">final</span> <span class=\"pl-smi\">String</span> <span class=\"pl-v\">state</span>, <span class=\"pl-k\">final</span> <span class=\"pl-k\">int</span> <span class=\"pl-v\">change</span>) {\n    updateStateCount(<span class=\"pl-smi\">KafkaStreams</span><span class=\"pl-k\">.</span><span class=\"pl-smi\">State</span><span class=\"pl-k\">.</span>valueOf(state), change);\n  }\n\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">updateStateCount</span>(<span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreams</span>.<span class=\"pl-smi\">State</span> <span class=\"pl-v\">state</span>, <span class=\"pl-k\">final</span> <span class=\"pl-k\">int</span> <span class=\"pl-v\">change</span>) {\n    states<span class=\"pl-k\">.</span>compute(state, (key, existing) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span>\n        existing <span class=\"pl-k\">==</span> <span class=\"pl-c1\">null</span>\n            <span class=\"pl-k\">?</span> change\n            <span class=\"pl-k\">:</span> existing <span class=\"pl-k\">+</span> change\n    );\n  }\n\n  <span class=\"pl-k\">@JsonValue</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">KafkaStreams</span>.</span><span class=\"pl-smi\">State</span>, <span class=\"pl-smi\">Integer</span>&gt; <span class=\"pl-en\">getState</span>() {\n    <span class=\"pl-k\">return</span> states;\n  }\n\n  <span class=\"pl-k\">@Override</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">boolean</span> <span class=\"pl-en\">equals</span>(<span class=\"pl-k\">final</span> <span class=\"pl-smi\">Object</span> <span class=\"pl-v\">o</span>) {\n    <span class=\"pl-k\">if</span> (<span class=\"pl-c1\">this</span> <span class=\"pl-k\">==</span> o) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">true</span>;\n    }\n\n    <span class=\"pl-k\">if</span> (o <span class=\"pl-k\">==</span> <span class=\"pl-c1\">null</span> <span class=\"pl-k\">||</span> getClass() <span class=\"pl-k\">!=</span> o<span class=\"pl-k\">.</span>getClass()) {\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">false</span>;\n    }\n\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> that <span class=\"pl-k\">=</span> (<span class=\"pl-smi\">KafkaStreamsStateCount</span>) o;\n    <span class=\"pl-k\">return</span> <span class=\"pl-smi\">Objects</span><span class=\"pl-k\">.</span>equals(states, that<span class=\"pl-k\">.</span>states);\n  }\n\n  <span class=\"pl-k\">@Override</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">int</span> <span class=\"pl-en\">hashCode</span>() {\n    <span class=\"pl-k\">return</span> <span class=\"pl-smi\">Objects</span><span class=\"pl-k\">.</span>hash(states);\n  }\n}</pre></div>", "author": "big-andy-coates", "createdAt": "2020-03-31T13:01:29Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDg4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640885", "bodyText": "it's returned as a json object now, and the toString() representation is being used to populate the state field in the show queries output", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:50:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5MzgyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex f9a742237e..2993d3a777 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -33,17 +35,17 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a EnumMap so toString() will always return the same string\n-  private final EnumMap<KafkaStreams.State, Integer> state;\n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnEnumMap();\n+    this.state = returnTreeMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n     final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n+    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n     for (String stateCount : parts) {\n       final String[] split = stateCount.split(\":\");\n       if (split.length != 2) {\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nindex 2993d3a777..f9a742237e 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n", "chunk": "@@ -35,17 +33,17 @@ import org.apache.kafka.streams.KafkaStreams;\n @JsonIgnoreProperties(ignoreUnknown = true)\n public class KafkaStreamsStateCount {\n   \n-  // Use a TreeMap so toString() will always return the same string\n-  private final TreeMap<KafkaStreams.State, Integer> state;\n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n \n   public KafkaStreamsStateCount() {\n-    this.state = returnTreeMap();\n+    this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n   public KafkaStreamsStateCount(final String serializedPair) {\n     final String [] parts = serializedPair.split(\",\");\n-    final TreeMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnTreeMap();\n+    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n     for (String stateCount : parts) {\n       final String[] split = stateCount.split(\":\");\n       if (split.length != 2) {\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nsimilarity index 58%\nrename from ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\nrename to ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nindex f9a742237e..64d6143d85 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\n", "chunk": "@@ -31,41 +33,27 @@ import org.apache.kafka.streams.KafkaStreams;\n  * across multiple servers. Used in {@link RunningQuery}.\n  */\n @JsonIgnoreProperties(ignoreUnknown = true)\n-public class KafkaStreamsStateCount {\n+public class QueryStateCount {\n   \n   // Use a EnumMap so toString() will always return the same string\n   private final EnumMap<KafkaStreams.State, Integer> state;\n \n-  public KafkaStreamsStateCount() {\n+  public QueryStateCount() {\n     this.state = returnEnumMap();\n   }\n \n   @JsonCreator\n-  public KafkaStreamsStateCount(final String serializedPair) {\n-    final String [] parts = serializedPair.split(\",\");\n-    final EnumMap<KafkaStreams.State, Integer> deserializedKafkaStreamsStateCount = returnEnumMap();\n-    for (String stateCount : parts) {\n-      final String[] split = stateCount.split(\":\");\n-      if (split.length != 2) {\n-        throw new KsqlException(\n-            \"Invalid state count info. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair);\n-      }\n-\n-      final String currentState = split[0].trim();\n-\n-      try {\n-        final int count = Integer.parseInt(split[1]);\n-        deserializedKafkaStreamsStateCount.put(\n-            KafkaStreams.State.valueOf(currentState), count);\n-      } catch (final Exception e) {\n-        throw new KsqlException(\n-            \"Invalid count. Expected format: <KafkaStreams.State>:<count>, but was \"\n-                + serializedPair, e);\n-      }\n-    }\n-\n-    this.state = deserializedKafkaStreamsStateCount;\n+  public QueryStateCount(final String serializedPair) {\n+    final Map<String, String> pairs =\n+        Splitter.on(\",\").withKeyValueSeparator(\":\").split(serializedPair);\n+    this.state = pairs.entrySet().stream().collect(\n+        Collectors.toMap(\n+            e -> KafkaStreams.State.valueOf(e.getKey().trim()),\n+            e -> Integer.parseInt(e.getValue()),\n+            (k1, k2) -> {\n+              throw new IllegalArgumentException(\"Duplicate key \" + k2);\n+            },\n+            () -> new EnumMap<>(KafkaStreams.State.class)));\n   }\n \n   public void updateStateCount(final String state, final int change) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NjQ3NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400896474", "body": "Might be worth keeping the old state for a while as this will allow backwards compatibility for older CLI versions... i.e. \r\n\r\n```suggestion\r\n      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\r\n      @JsonProperty(\"stateCounts\") final KafkaStreamsStateCount stateCounts\r\n```\r\n\r\nand just populate the `state` string somehow, e.g. using the `stateCounts` string representation?  I *think* this would work as I think the old CLI just outputs this string as-is. Need to check though.", "bodyText": "Might be worth keeping the old state for a while as this will allow backwards compatibility for older CLI versions... i.e.\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  @JsonProperty(\"state\") final KafkaStreamsStateCount state\n          \n          \n            \n                  @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n          \n          \n            \n                  @JsonProperty(\"stateCounts\") final KafkaStreamsStateCount stateCounts\n          \n      \n    \n    \n  \n\nand just populate the state string somehow, e.g. using the stateCounts string representation?  I think this would work as I think the old CLI just outputs this string as-is. Need to check though.", "bodyHTML": "<p dir=\"auto\">Might be worth keeping the old state for a while as this will allow backwards compatibility for older CLI versions... i.e.</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">      <span class=\"pl-k\">@JsonProperty</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>state<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">final</span> <span class=\"pl-smi x x-first x-last\">KafkaStreamsStateCount</span> state</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">      <span class=\"pl-k\">@JsonProperty</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>state<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">final</span> <span class=\"pl-k\"><span class=\"x x-first\">Optional&lt;</span><span class=\"pl-smi x\">String</span><span class=\"x x-last\">&gt;</span></span> state<span class=\"x x-first\">, </span><span class=\"pl-c\"><span class=\"pl-c x\">//</span><span class=\"x x-last\"> Kept for backwards compatibility.</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">      <span class=\"pl-k\">@JsonProperty</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>stateCounts<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> stateCounts</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">and just populate the <code>state</code> string somehow, e.g. using the <code>stateCounts</code> string representation?  I <em>think</em> this would work as I think the old CLI just outputs this string as-is. Need to check though.</p>", "author": "big-andy-coates", "createdAt": "2020-03-31T13:05:15Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java", "diffHunk": "@@ -31,15 +30,15 @@\n   private final Set<String> sinks;\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n-  private final Optional<String> state;\n+  private final KafkaStreamsStateCount state;\n \n   @JsonCreator\n   public RunningQuery(\n       @JsonProperty(\"queryString\") final String queryString,\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state\n+      @JsonProperty(\"state\") final KafkaStreamsStateCount state", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDc5NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640795", "bodyText": "yea, I'm refactoring the output so that it'll be more backwards compatible here.", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NjQ3NA=="}], "type": "inlineReview", "revised_code": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex eed1ddfd67..e4c6c08b2d 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -30,7 +30,7 @@ public class RunningQuery {\n   private final Set<String> sinks;\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n-  private final KafkaStreamsStateCount state;\n+  private final QueryStateCount state;\n \n   @JsonCreator\n   public RunningQuery(\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex e4c6c08b2d..71463f025c 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -30,7 +31,8 @@ public class RunningQuery {\n   private final Set<String> sinks;\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n-  private final QueryStateCount state;\n+  private final Optional<String> state;\n+  private final QueryStateCount stateCount;\n \n   @JsonCreator\n   public RunningQuery(\n", "next_change": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex 71463f025c..baec888dd2 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -31,7 +31,6 @@ public class RunningQuery {\n   private final Set<String> sinks;\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n-  private final Optional<String> state;\n   private final QueryStateCount stateCount;\n \n   @JsonCreator\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex 71463f025c..baec888dd2 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -40,14 +39,12 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n       @JsonProperty(\"stateCount\") final QueryStateCount stateCount\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n     this.sinks = Objects.requireNonNull(sinks, \"sinks\");\n     this.id = Objects.requireNonNull(id, \"id\");\n-    this.state = Objects.requireNonNull(state, \"state\");\n     this.stateCount = Objects.requireNonNull(stateCount, \"stateCount\");\n   }\n \n", "next_change": null}]}}, {"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex e4c6c08b2d..71463f025c 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -38,13 +40,15 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final QueryStateCount state\n+      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n+      @JsonProperty(\"stateCount\") final QueryStateCount stateCount\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n     this.sinks = Objects.requireNonNull(sinks, \"sinks\");\n     this.id = Objects.requireNonNull(id, \"id\");\n     this.state = Objects.requireNonNull(state, \"state\");\n+    this.stateCount = Objects.requireNonNull(stateCount, \"stateCount\");\n   }\n \n   public String getQueryString() {\n", "next_change": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex 71463f025c..baec888dd2 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -40,14 +39,12 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n       @JsonProperty(\"stateCount\") final QueryStateCount stateCount\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n     this.sinks = Objects.requireNonNull(sinks, \"sinks\");\n     this.id = Objects.requireNonNull(id, \"id\");\n-    this.state = Objects.requireNonNull(state, \"state\");\n     this.stateCount = Objects.requireNonNull(stateCount, \"stateCount\");\n   }\n \n", "next_change": null}]}}]}}, {"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex eed1ddfd67..e4c6c08b2d 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -38,7 +38,7 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final KafkaStreamsStateCount state\n+      @JsonProperty(\"state\") final QueryStateCount state\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n", "next_change": {"commit": "41f17ebde495835e6e126d4203cc324e61ca58e3", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex e4c6c08b2d..71463f025c 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -38,13 +40,15 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final QueryStateCount state\n+      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n+      @JsonProperty(\"stateCount\") final QueryStateCount stateCount\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n     this.sinks = Objects.requireNonNull(sinks, \"sinks\");\n     this.id = Objects.requireNonNull(id, \"id\");\n     this.state = Objects.requireNonNull(state, \"state\");\n+    this.stateCount = Objects.requireNonNull(stateCount, \"stateCount\");\n   }\n \n   public String getQueryString() {\n", "next_change": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex 71463f025c..baec888dd2 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -40,14 +39,12 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n       @JsonProperty(\"stateCount\") final QueryStateCount stateCount\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n     this.sinks = Objects.requireNonNull(sinks, \"sinks\");\n     this.id = Objects.requireNonNull(id, \"id\");\n-    this.state = Objects.requireNonNull(state, \"state\");\n     this.stateCount = Objects.requireNonNull(stateCount, \"stateCount\");\n   }\n \n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NzIwOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400897208", "body": "With the changes I suggested to make this object serialize as a JSON object you can add tests such as:\r\n\r\n```java\r\n@Test\r\n  public void shouldRoundTripWhenEmpty() {\r\n    // When:\r\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\r\n\r\n    // Then:\r\n    assertThat(json, is(\"{}\"));\r\n  }\r\n\r\n  @Test\r\n  public void shouldRoundTripWhenNotEmpty() {\r\n    // Given:\r\n    kafkaStreamsStateCount.updateStateCount(State.RUNNING, 2);\r\n    kafkaStreamsStateCount.updateStateCount(State.CREATED, 10);\r\n\r\n    // When:\r\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\r\n\r\n    // Then:\r\n    assertThat(json, is(\"{\"\r\n        + \"\\\"CREATED\\\":10,\"\r\n        + \"\\\"RUNNING\\\":2\"\r\n        + \"}\"));\r\n  }\r\n\r\n  private static String assertDeserializedToSame(final KafkaStreamsStateCount original) {\r\n    try {\r\n      final String json = MAPPER.writeValueAsString(original);\r\n\r\n      final KafkaStreamsStateCount deserialized = MAPPER\r\n          .readValue(json, KafkaStreamsStateCount.class);\r\n\r\n      assertThat(deserialized, is(original));\r\n\r\n      return json;\r\n    } catch (Exception e) {\r\n      throw new AssertionError(\"Failed to round trip\", e);\r\n    }\r\n  }\r\n```", "bodyText": "With the changes I suggested to make this object serialize as a JSON object you can add tests such as:\n@Test\n  public void shouldRoundTripWhenEmpty() {\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(\"{}\"));\n  }\n\n  @Test\n  public void shouldRoundTripWhenNotEmpty() {\n    // Given:\n    kafkaStreamsStateCount.updateStateCount(State.RUNNING, 2);\n    kafkaStreamsStateCount.updateStateCount(State.CREATED, 10);\n\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(\"{\"\n        + \"\\\"CREATED\\\":10,\"\n        + \"\\\"RUNNING\\\":2\"\n        + \"}\"));\n  }\n\n  private static String assertDeserializedToSame(final KafkaStreamsStateCount original) {\n    try {\n      final String json = MAPPER.writeValueAsString(original);\n\n      final KafkaStreamsStateCount deserialized = MAPPER\n          .readValue(json, KafkaStreamsStateCount.class);\n\n      assertThat(deserialized, is(original));\n\n      return json;\n    } catch (Exception e) {\n      throw new AssertionError(\"Failed to round trip\", e);\n    }\n  }", "bodyHTML": "<p dir=\"auto\">With the changes I suggested to make this object serialize as a JSON object you can add tests such as:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@Test\n  public void shouldRoundTripWhenEmpty() {\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(&quot;{}&quot;));\n  }\n\n  @Test\n  public void shouldRoundTripWhenNotEmpty() {\n    // Given:\n    kafkaStreamsStateCount.updateStateCount(State.RUNNING, 2);\n    kafkaStreamsStateCount.updateStateCount(State.CREATED, 10);\n\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(&quot;{&quot;\n        + &quot;\\&quot;CREATED\\&quot;:10,&quot;\n        + &quot;\\&quot;RUNNING\\&quot;:2&quot;\n        + &quot;}&quot;));\n  }\n\n  private static String assertDeserializedToSame(final KafkaStreamsStateCount original) {\n    try {\n      final String json = MAPPER.writeValueAsString(original);\n\n      final KafkaStreamsStateCount deserialized = MAPPER\n          .readValue(json, KafkaStreamsStateCount.class);\n\n      assertThat(deserialized, is(original));\n\n      return json;\n    } catch (Exception e) {\n      throw new AssertionError(&quot;Failed to round trip&quot;, e);\n    }\n  }\"><pre><span class=\"pl-k\">@Test</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> shouldRoundTripWhenEmpty() {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> When:</span>\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">String</span> json <span class=\"pl-k\">=</span> assertDeserializedToSame(kafkaStreamsStateCount);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Then:</span>\n    assertThat(json, is(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>{}<span class=\"pl-pds\">\"</span></span>));\n  }\n\n  <span class=\"pl-k\">@Test</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> shouldRoundTripWhenNotEmpty() {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Given:</span>\n    kafkaStreamsStateCount<span class=\"pl-k\">.</span>updateStateCount(<span class=\"pl-smi\">State</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>RUNNING</span>, <span class=\"pl-c1\">2</span>);\n    kafkaStreamsStateCount<span class=\"pl-k\">.</span>updateStateCount(<span class=\"pl-smi\">State</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>CREATED</span>, <span class=\"pl-c1\">10</span>);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> When:</span>\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">String</span> json <span class=\"pl-k\">=</span> assertDeserializedToSame(kafkaStreamsStateCount);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Then:</span>\n    assertThat(json, is(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>{<span class=\"pl-pds\">\"</span></span>\n        <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\\"</span>CREATED<span class=\"pl-cce\">\\\"</span>:10,<span class=\"pl-pds\">\"</span></span>\n        <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\\"</span>RUNNING<span class=\"pl-cce\">\\\"</span>:2<span class=\"pl-pds\">\"</span></span>\n        <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>}<span class=\"pl-pds\">\"</span></span>));\n  }\n\n  <span class=\"pl-k\">private</span> <span class=\"pl-k\">static</span> <span class=\"pl-smi\">String</span> assertDeserializedToSame(<span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> original) {\n    <span class=\"pl-k\">try</span> {\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">String</span> json <span class=\"pl-k\">=</span> <span class=\"pl-c1\">MAPPER</span><span class=\"pl-k\">.</span>writeValueAsString(original);\n\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">KafkaStreamsStateCount</span> deserialized <span class=\"pl-k\">=</span> <span class=\"pl-c1\">MAPPER</span>\n          .readValue(json, <span class=\"pl-smi\">KafkaStreamsStateCount</span><span class=\"pl-k\">.</span>class);\n\n      assertThat(deserialized, is(original));\n\n      <span class=\"pl-k\">return</span> json;\n    } <span class=\"pl-k\">catch</span> (<span class=\"pl-smi\">Exception</span> e) {\n      <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">AssertionError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Failed to round trip<span class=\"pl-pds\">\"</span></span>, e);\n    }\n  }</pre></div>", "author": "big-andy-coates", "createdAt": "2020-03-31T13:06:22Z", "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.ksql.util.KsqlException;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.Map;\n+\n+@SuppressWarnings(\"SameParameterValue\")\n+public class KafkaStreamsStateCountTest {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDU0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640541", "bodyText": "added the tests", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:49:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NzIwOA=="}], "type": "inlineReview", "revised_code": {"commit": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nindex fea38ac4b0..5b9cb28abf 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n", "chunk": "@@ -23,6 +24,7 @@ import org.apache.kafka.streams.KafkaStreams;\n import org.junit.Before;\n import org.junit.Test;\n \n+import java.util.HashMap;\n import java.util.Map;\n \n @SuppressWarnings(\"SameParameterValue\")\n", "next_change": {"commit": "4957a5c4a3edab330671adb712176c6e37cbd7da", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nindex 5b9cb28abf..fea38ac4b0 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n", "chunk": "@@ -24,7 +23,6 @@ import org.apache.kafka.streams.KafkaStreams;\n import org.junit.Before;\n import org.junit.Test;\n \n-import java.util.HashMap;\n import java.util.Map;\n \n @SuppressWarnings(\"SameParameterValue\")\n", "next_change": {"commit": "653bc6806701e95d4493ff6bd261c220a095420c", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\nsimilarity index 54%\nrename from ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nrename to ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\nindex fea38ac4b0..50217f82b3 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\n", "chunk": "@@ -18,7 +18,6 @@ package io.confluent.ksql.rest.entity;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.is;\n \n-import io.confluent.ksql.util.KsqlException;\n import org.apache.kafka.streams.KafkaStreams;\n import org.junit.Before;\n import org.junit.Test;\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\nsimilarity index 54%\nrename from ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\nrename to ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\nindex fea38ac4b0..50217f82b3 100644\n--- a/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java\n+++ b/ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/QueryStateCountTest.java\n", "chunk": "@@ -26,62 +25,72 @@ import org.junit.Test;\n import java.util.Map;\n \n @SuppressWarnings(\"SameParameterValue\")\n-public class KafkaStreamsStateCountTest {\n+public class QueryStateCountTest {\n \n-  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  QueryStateCount queryStateCount;\n   \n   @Before\n   public void setup() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+    queryStateCount = new QueryStateCount();\n   }\n \n   @Test\n   public void shouldUpdateExistingStateCount() {\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    queryStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n     assertThat(\n-        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        queryStateCount.getState().get(KafkaStreams.State.RUNNING),\n         is(2));\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n+    queryStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n     assertThat(\n-        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        queryStateCount.getState().get(KafkaStreams.State.RUNNING),\n         is(6));\n   }\n \n   @Test\n   public void shouldToString() {\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    queryStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n     assertThat(\n-        kafkaStreamsStateCount.toString(),\n+        queryStateCount.toString(),\n         is(\"RUNNING:2\"));\n-    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n+    queryStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n     assertThat(\n-        kafkaStreamsStateCount.toString(),\n-        is(\"RUNNING:2, NOT_RUNNING:1\"));\n+        queryStateCount.toString(),\n+        is(\"RUNNING:2,NOT_RUNNING:1\"));\n   }\n \n   @Test\n   public void shouldConvertStringToKafkaStreamsStateCount() {\n+    // Given:\n     final String testString = \"REBALANCING:4, ERROR:1,    RUNNING:2\";\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(testString);\n-    final Map<KafkaStreams.State, Integer> state = kafkaStreamsStateCount.getState();\n+    \n+    // When:\n+    queryStateCount = new QueryStateCount(testString);\n+    \n+    // Then:\n+    final Map<KafkaStreams.State, Integer> state = queryStateCount.getState();\n     assertThat(state.get(KafkaStreams.State.REBALANCING), is(4));\n     assertThat(state.get(KafkaStreams.State.ERROR), is(1));\n     assertThat(state.get(KafkaStreams.State.RUNNING), is(2));\n-    assertThat(kafkaStreamsStateCount.toString(), is(\"REBALANCING:4, RUNNING:2, ERROR:1\"));\n+    assertThat(queryStateCount.toString(), is(\"REBALANCING:4,RUNNING:2,ERROR:1\"));\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidFormat() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:2:2\");\n+    queryStateCount = new QueryStateCount(\"RUNNING:2:2\");\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidCount() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"RUNNING:q\");\n+    queryStateCount = new QueryStateCount(\"RUNNING:q\");\n   }\n \n-  @Test(expected = KsqlException.class)\n+  @Test(expected = Exception.class)\n   public void shouldThrowExceptionIfInvalidState() {\n-    kafkaStreamsStateCount = new KafkaStreamsStateCount(\"other state:2\");\n+    queryStateCount = new QueryStateCount(\"other state:2\");\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void shouldThrowIllegalArgumentExceptionIfDuplicateState() {\n+    queryStateCount = new QueryStateCount(\"RUNNING:4,RUNNING:2,\");\n   }\n }\n\\ No newline at end of file\n", "next_change": null}]}}]}}]}}, {"oid": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "url": "https://github.com/confluentinc/ksql/commit/9abab589a7bfda4cc6a15271d0ea4807b974597f", "message": "addressing more comments", "committedDate": "2020-04-01T22:17:53Z", "type": "forcePushed"}, {"oid": "d4b8243ca0ae9157476193db226d7c0021976fb9", "url": "https://github.com/confluentinc/ksql/commit/d4b8243ca0ae9157476193db226d7c0021976fb9", "message": "addressing more comments", "committedDate": "2020-04-01T22:44:36Z", "type": "forcePushed"}, {"oid": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "url": "https://github.com/confluentinc/ksql/commit/a904008a542ae27a43a2fb5bd255a54ae00fcd55", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-04-02T17:35:34Z", "type": "commit"}, {"oid": "4957a5c4a3edab330671adb712176c6e37cbd7da", "url": "https://github.com/confluentinc/ksql/commit/4957a5c4a3edab330671adb712176c6e37cbd7da", "message": "address comments", "committedDate": "2020-04-02T17:35:34Z", "type": "commit"}, {"oid": "653bc6806701e95d4493ff6bd261c220a095420c", "url": "https://github.com/confluentinc/ksql/commit/653bc6806701e95d4493ff6bd261c220a095420c", "message": "addressing more comments", "committedDate": "2020-04-02T17:35:34Z", "type": "commit"}, {"oid": "41f17ebde495835e6e126d4203cc324e61ca58e3", "url": "https://github.com/confluentinc/ksql/commit/41f17ebde495835e6e126d4203cc324e61ca58e3", "message": "refactor for backwards-compatability", "committedDate": "2020-04-02T22:21:49Z", "type": "forcePushed"}, {"oid": "293e001f7a95180faa8acee22006e4dd023c41de", "url": "https://github.com/confluentinc/ksql/commit/293e001f7a95180faa8acee22006e4dd023c41de", "message": "refactor for backwards-compatability", "committedDate": "2020-04-02T22:28:05Z", "type": "forcePushed"}, {"oid": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "url": "https://github.com/confluentinc/ksql/commit/f8004d34f95b5a57a89361eac2935c8eff9a12c4", "message": "refactor for backwards-compatability", "committedDate": "2020-04-02T23:10:36Z", "type": "forcePushed"}, {"oid": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "url": "https://github.com/confluentinc/ksql/commit/2b52197e3af9f3516cbd30435da8dd389a85c7a3", "message": "refactor for backwards-compatability", "committedDate": "2020-04-03T00:45:24Z", "type": "commit"}, {"oid": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "url": "https://github.com/confluentinc/ksql/commit/2b52197e3af9f3516cbd30435da8dd389a85c7a3", "message": "refactor for backwards-compatability", "committedDate": "2020-04-03T00:45:24Z", "type": "forcePushed"}, {"oid": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "url": "https://github.com/confluentinc/ksql/commit/9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "message": "refactor ListQueriesExecutor", "committedDate": "2020-04-03T07:01:39Z", "type": "commit"}, {"oid": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "url": "https://github.com/confluentinc/ksql/commit/9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "message": "refactor ListQueriesExecutor", "committedDate": "2020-04-03T07:01:39Z", "type": "forcePushed"}, {"oid": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "url": "https://github.com/confluentinc/ksql/commit/2094b3f1ad442ed2642e50820ce0ab00bb969683", "message": "more unit tests", "committedDate": "2020-04-03T22:24:09Z", "type": "forcePushed"}, {"oid": "8c62c220495be00a406c5f0936fda64c140109a4", "url": "https://github.com/confluentinc/ksql/commit/8c62c220495be00a406c5f0936fda64c140109a4", "message": "more unit tests", "committedDate": "2020-04-03T22:44:50Z", "type": "forcePushed"}, {"oid": "27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "url": "https://github.com/confluentinc/ksql/commit/27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "message": "more unit tests", "committedDate": "2020-04-03T22:45:28Z", "type": "forcePushed"}, {"oid": "0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "url": "https://github.com/confluentinc/ksql/commit/0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "message": "more unit tests", "committedDate": "2020-04-06T16:45:24Z", "type": "forcePushed"}, {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3", "url": "https://github.com/confluentinc/ksql/commit/1825fd40b7926520ef42fd9c83174d83fec182f3", "message": "more unit tests", "committedDate": "2020-04-06T17:32:26Z", "type": "commit"}, {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3", "url": "https://github.com/confluentinc/ksql/commit/1825fd40b7926520ef42fd9c83174d83fec182f3", "message": "more unit tests", "committedDate": "2020-04-06T17:32:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzQwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733405", "body": "As per https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979, and note in summary, I don't think this should be swallowed.", "bodyText": "As per #4875 (comment), and note in summary, I don't think this should be swallowed.", "bodyHTML": "<p dir=\"auto\">As per <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"586545446\" data-permission-text=\"Title is private\" data-url=\"https://github.com/confluentinc/ksql/issues/4875\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/confluentinc/ksql/pull/4875/hovercard?comment_id=400814979&amp;comment_type=review_comment\" href=\"https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979\">#4875 (comment)</a>, and note in summary, I don't think this should be swallowed.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T11:22:55Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Error response from host. host: {}, cause: {}\",", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex a82549806f..3234890c20 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -263,7 +241,8 @@ public final class ListQueriesExecutor {\n       for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n           : futureResponses.entrySet()) {\n         try {\n-          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          final RestResponse<KsqlEntityList> response =\n+              e.getValue().get(TIMEOUT_SECONDS, TimeUnit.SECONDS);\n           if (response.isErroneous()) {\n             LOG.warn(\"Error response from host. host: {}, cause: {}\",\n                 e.getKey(), response.getErrorMessage().getMessage());\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzQzNA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733434", "body": "As per https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979, and note in summary, I don't think this should be swallowed.", "bodyText": "As per #4875 (comment), and note in summary, I don't think this should be swallowed.", "bodyHTML": "<p dir=\"auto\">As per <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"586545446\" data-permission-text=\"Title is private\" data-url=\"https://github.com/confluentinc/ksql/issues/4875\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/confluentinc/ksql/pull/4875/hovercard?comment_id=400814979&amp;comment_type=review_comment\" href=\"https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979\">#4875 (comment)</a>, and note in summary, I don't think this should be swallowed.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T11:22:59Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Error response from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n+          } else {\n+            results.add(response.getResponse().get(0));\n+          }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex a82549806f..3234890c20 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -263,7 +241,8 @@ public final class ListQueriesExecutor {\n       for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n           : futureResponses.entrySet()) {\n         try {\n-          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          final RestResponse<KsqlEntityList> response =\n+              e.getValue().get(TIMEOUT_SECONDS, TimeUnit.SECONDS);\n           if (response.isErroneous()) {\n             LOG.warn(\"Error response from host. host: {}, cause: {}\",\n                 e.getKey(), response.getErrorMessage().getMessage());\n", "next_change": null}, {"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex a82549806f..3234890c20 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -271,7 +250,8 @@ public final class ListQueriesExecutor {\n             results.add(response.getResponse().get(0));\n           }\n         } catch (final Exception cause) {\n-          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n+          LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n+              e.getKey(), cause.getMessage());\n         }\n       }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzk1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733957", "body": "As per https://github.com/confluentinc/ksql/pull/4875#discussion_r400835499:\r\n\r\n> It may be sensible to add a timeout on this `get()` call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "bodyText": "As per #4875 (comment):\n\nIt may be sensible to add a timeout on this get() call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "bodyHTML": "<p dir=\"auto\">As per <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"586545446\" data-permission-text=\"Title is private\" data-url=\"https://github.com/confluentinc/ksql/issues/4875\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/confluentinc/ksql/pull/4875/hovercard?comment_id=400835499&amp;comment_type=review_comment\" href=\"https://github.com/confluentinc/ksql/pull/4875#discussion_r400835499\">#4875 (comment)</a>:</p>\n<blockquote>\n<p dir=\"auto\">It may be sensible to add a timeout on this <code>get()</code> call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.</p>\n</blockquote>", "author": "big-andy-coates", "createdAt": "2020-04-07T11:23:58Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAzODEwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405038106", "bodyText": "added a timeout", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzk1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex a82549806f..3234890c20 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -263,7 +241,8 @@ public final class ListQueriesExecutor {\n       for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n           : futureResponses.entrySet()) {\n         try {\n-          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          final RestResponse<KsqlEntityList> response =\n+              e.getValue().get(TIMEOUT_SECONDS, TimeUnit.SECONDS);\n           if (response.isErroneous()) {\n             LOG.warn(\"Error response from host. host: {}, cause: {}\",\n                 e.getKey(), response.getErrorMessage().getMessage());\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNzQ2Mg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404737462", "body": "This creation of a new copy of each `RunningQuery` confused me at first. Then I realised you are probably doing this to set the legacy `state` field, right?   I've commented in `RunningQuery` explaining how you don't need to set `state` via the constructor - so this code to create new `RunningQuery`s can be removed.", "bodyText": "This creation of a new copy of each RunningQuery confused me at first. Then I realised you are probably doing this to set the legacy state field, right?   I've commented in RunningQuery explaining how you don't need to set state via the constructor - so this code to create new RunningQuerys can be removed.", "bodyHTML": "<p dir=\"auto\">This creation of a new copy of each <code>RunningQuery</code> confused me at first. Then I realised you are probably doing this to set the legacy <code>state</code> field, right?   I've commented in <code>RunningQuery</code> explaining how you don't need to set <code>state</code> via the constructor - so this code to create new <code>RunningQuery</code>s can be removed.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T11:30:24Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwMzI4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405003285", "bodyText": "got rid of it now", "author": "stevenpyzhang", "createdAt": "2020-04-07T17:55:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNzQ2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex a82549806f..3234890c20 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -88,15 +90,7 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new Queries(\n         statement.getStatementText(),\n-        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n-            runningQuery.getQueryString(),\n-            runningQuery.getSinks(),\n-            runningQuery.getSinkKafkaTopics(),\n-            runningQuery.getId(),\n-            Optional.of(runningQuery.getStateCount().toString()),\n-            runningQuery.getStateCount()\n-        ))\n-        .collect(Collectors.toList())));\n+        runningQueries.values()));\n   }\n \n   private static Map<QueryId, RunningQuery> getLocalSimple(\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MTYwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404741606", "body": "A cleaner way (my bad) would be to remove this param from the constructor but to still have the getter. For example:\r\n\r\n```java\r\n  public Optional<String> getState() {\r\n    return stateCount.getStates().isEmpty()\r\n        ? Optional.empty()\r\n        : Optional.of(stateCount.toString());\r\n  }\r\n```\r\n\r\n(You may even just be able to always return `Optional.of(stateCount.toString())`).\r\n\r\nI believe Jackson will then include `state` as a field in the json.  Though add a unit test for this.\r\n\r\nIf you're wondering how this can work, then remember we're keeping this field around for backwards compatibility and the old version of the CLI will have the old version of this class, which will still take `state` as a constructor param. Hence, all we need is the `state` in the Json. We don't need to be able to accept it as a constructor param any more.", "bodyText": "A cleaner way (my bad) would be to remove this param from the constructor but to still have the getter. For example:\n  public Optional<String> getState() {\n    return stateCount.getStates().isEmpty()\n        ? Optional.empty()\n        : Optional.of(stateCount.toString());\n  }\n(You may even just be able to always return Optional.of(stateCount.toString())).\nI believe Jackson will then include state as a field in the json.  Though add a unit test for this.\nIf you're wondering how this can work, then remember we're keeping this field around for backwards compatibility and the old version of the CLI will have the old version of this class, which will still take state as a constructor param. Hence, all we need is the state in the Json. We don't need to be able to accept it as a constructor param any more.", "bodyHTML": "<p dir=\"auto\">A cleaner way (my bad) would be to remove this param from the constructor but to still have the getter. For example:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  public Optional&lt;String&gt; getState() {\n    return stateCount.getStates().isEmpty()\n        ? Optional.empty()\n        : Optional.of(stateCount.toString());\n  }\"><pre>  <span class=\"pl-k\">public</span> <span class=\"pl-k\">Optional&lt;<span class=\"pl-smi\">String</span>&gt;</span> getState() {\n    <span class=\"pl-k\">return</span> stateCount<span class=\"pl-k\">.</span>getStates()<span class=\"pl-k\">.</span>isEmpty()\n        <span class=\"pl-k\">?</span> <span class=\"pl-smi\">Optional</span><span class=\"pl-k\">.</span>empty()\n        <span class=\"pl-k\">:</span> <span class=\"pl-smi\">Optional</span><span class=\"pl-k\">.</span>of(stateCount<span class=\"pl-k\">.</span>toString());\n  }</pre></div>\n<p dir=\"auto\">(You may even just be able to always return <code>Optional.of(stateCount.toString())</code>).</p>\n<p dir=\"auto\">I believe Jackson will then include <code>state</code> as a field in the json.  Though add a unit test for this.</p>\n<p dir=\"auto\">If you're wondering how this can work, then remember we're keeping this field around for backwards compatibility and the old version of the CLI will have the old version of this class, which will still take <code>state</code> as a constructor param. Hence, all we need is the <code>state</code> in the Json. We don't need to be able to accept it as a constructor param any more.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T11:38:22Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java", "diffHunk": "@@ -32,20 +32,23 @@\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n   private final Optional<String> state;\n+  private final QueryStateCount stateCount;\n \n   @JsonCreator\n   public RunningQuery(\n       @JsonProperty(\"queryString\") final String queryString,\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state\n+      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNDE4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405004186", "bodyText": "That makes sense.\nI had to fiddle around with it a bit, but it does work now.\n  @JsonProperty(\"state\")\n  public Optional<String> getState() {\n    return Optional.of(stateCount.toString());\n  }\n\nJust need to specify the @JsonProperty annotation on the getter to keep the field in the json output\nThe consoleTest basically tests the JSON output for RunningQuery so I didn't add any additional tests.", "author": "stevenpyzhang", "createdAt": "2020-04-07T17:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MTYwNg=="}], "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\nindex 313910e849..baec888dd2 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java\n", "chunk": "@@ -40,14 +39,12 @@ public class RunningQuery {\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n       @JsonProperty(\"stateCount\") final QueryStateCount stateCount\n   ) {\n     this.queryString = Objects.requireNonNull(queryString, \"queryString\");\n     this.sinkKafkaTopics = Objects.requireNonNull(sinkKafkaTopics, \"sinkKafkaTopics\");\n     this.sinks = Objects.requireNonNull(sinks, \"sinks\");\n     this.id = Objects.requireNonNull(id, \"id\");\n-    this.state = Objects.requireNonNull(state, \"state\");\n     this.stateCount = Objects.requireNonNull(stateCount, \"stateCount\");\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MzcxNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404743716", "body": "You can remove this code by following the same trick I've suggested for `RunningQuery` in `QueryDescription`.", "bodyText": "You can remove this code by following the same trick I've suggested for RunningQuery in QueryDescription.", "bodyHTML": "<p dir=\"auto\">You can remove this code by following the same trick I've suggested for <code>RunningQuery</code> in <code>QueryDescription</code>.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T11:42:30Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNDg0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405014841", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MzcxNg=="}], "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\nindex a82549806f..3234890c20 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java\n", "chunk": "@@ -159,21 +152,7 @@ public final class ListQueriesExecutor {\n \n     return Optional.of(new QueryDescriptionList(\n         statement.getStatementText(),\n-        queryDescriptions.values().stream().map(queryDescription -> \n-            new QueryDescription(\n-                queryDescription.getId(),\n-                queryDescription.getStatementText(),\n-                queryDescription.getWindowType(),\n-                queryDescription.getFields(),\n-                queryDescription.getSources(),\n-                queryDescription.getSinks(),\n-                queryDescription.getTopology(),\n-                queryDescription.getExecutionPlan(),\n-                queryDescription.getOverriddenProperties(),\n-                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n-                queryDescription.getKsqlHostQueryState()\n-            )\n-        ).collect(Collectors.toList())));\n+        queryDescriptions.values()));\n   }\n \n   private static Map<QueryId, QueryDescription> getLocalExtended(\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1Mjk3Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404752973", "body": "Exposes mutable state of object, i.e. breaks encapsulation. I think this should still ensure consistent ordering:\r\n\r\n```suggestion\r\n    return Collections.unmodifyableMap(ksqlHostQueryState);\r\n```\r\n\r\nIf not, then you can always just store a normal map in the field and return:\r\n\r\n```java\r\n  final Map<x, y> orderedMap = new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString))\r\n   orderedMap.putAll(ksqlHostQueryState);\r\nreturn orderedMap;\r\n```", "bodyText": "Exposes mutable state of object, i.e. breaks encapsulation. I think this should still ensure consistent ordering:\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return ksqlHostQueryState;\n          \n          \n            \n                return Collections.unmodifyableMap(ksqlHostQueryState);\n          \n      \n    \n    \n  \n\nIf not, then you can always just store a normal map in the field and return:\n  final Map<x, y> orderedMap = new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString))\n   orderedMap.putAll(ksqlHostQueryState);\nreturn orderedMap;", "bodyHTML": "<p dir=\"auto\">Exposes mutable state of object, i.e. breaks encapsulation. I think this should still ensure consistent ordering:</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">return</span> ksqlHostQueryState;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">return</span> <span class=\"pl-smi x x-first\">Collections</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">unmodifyableMap(</span>ksqlHostQueryState<span class=\"x x-first x-last\">)</span>;</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">If not, then you can always just store a normal map in the field and return:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  final Map&lt;x, y&gt; orderedMap = new TreeMap&lt;&gt;(Comparator.comparing(KsqlHostInfoEntity::toString))\n   orderedMap.putAll(ksqlHostQueryState);\nreturn orderedMap;\"><pre>  <span class=\"pl-k\">final</span> <span class=\"pl-k\">Map&lt;x, y&gt;</span> orderedMap <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">TreeMap&lt;&gt;</span>(<span class=\"pl-smi\">Comparator</span><span class=\"pl-k\">.</span>comparing(<span class=\"pl-smi\">KsqlHostInfoEntity</span><span class=\"pl-k\">::</span>toString))\n   orderedMap<span class=\"pl-k\">.</span>putAll(ksqlHostQueryState);\n<span class=\"pl-k\">return</span> orderedMap;</pre></div>", "author": "big-andy-coates", "createdAt": "2020-04-07T12:00:15Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -110,6 +121,10 @@ public String getExecutionPlan() {\n     return state;\n   }\n \n+  public Map<KsqlHostInfoEntity, String> getKsqlHostQueryState() {\n+    return ksqlHostQueryState;", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\nindex 5cd2ff232c..7b5496e3ae 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n", "chunk": "@@ -117,12 +111,18 @@ public class QueryDescription {\n     return overriddenProperties;\n   }\n \n+  // kept for backwards compatibility\n+  @JsonProperty(\"state\")\n   public Optional<String> getState() {\n-    return state;\n+    return Optional.of(ksqlHostQueryState.toString());\n   }\n \n-  public Map<KsqlHostInfoEntity, String> getKsqlHostQueryState() {\n-    return ksqlHostQueryState;\n+  public void updateKsqlHostQueryState(final KsqlHostInfoEntity host, final String state) {\n+    ksqlHostQueryState.put(host, state);\n+  }\n+\n+  public Map<KsqlHostInfoEntity, String> getKsqlHostQueryState() { \n+    return Collections.unmodifiableMap(ksqlHostQueryState);\n   }\n \n   // CHECKSTYLE_RULES.OFF: CyclomaticComplexity\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzE3NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753174", "body": "nit:\r\n\r\n```suggestion\r\n  private final Map<KsqlHostInfoEntity, String> ksqlHostQueryState;\r\n```\r\n\r\nIs sufficient, no?", "bodyText": "nit:\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;\n          \n          \n            \n              private final Map<KsqlHostInfoEntity, String> ksqlHostQueryState;\n          \n      \n    \n    \n  \n\nIs sufficient, no?", "bodyHTML": "<p dir=\"auto\">nit:</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">  <span class=\"pl-k\">private</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\"><span class=\"x x-first x-last\">TreeMap</span>&lt;<span class=\"pl-smi\">KsqlHostInfoEntity</span>, <span class=\"pl-smi\">String</span>&gt;</span> ksqlHostQueryState;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">  <span class=\"pl-k\">private</span> <span class=\"pl-k\">final</span> <span class=\"pl-k\"><span class=\"x x-first x-last\">Map</span>&lt;<span class=\"pl-smi\">KsqlHostInfoEntity</span>, <span class=\"pl-smi\">String</span>&gt;</span> ksqlHostQueryState;</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">Is sufficient, no?</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T12:00:40Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -42,7 +45,9 @@\n   private final String executionPlan;\n   private final Map<String, Object> overriddenProperties;\n   private final Optional<String> state;\n+  private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\nindex 5cd2ff232c..7b5496e3ae 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n", "chunk": "@@ -44,8 +44,7 @@ public class QueryDescription {\n   private final String topology;\n   private final String executionPlan;\n   private final Map<String, Object> overriddenProperties;\n-  private final Optional<String> state;\n-  private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;\n+  private final Map<KsqlHostInfoEntity, String> ksqlHostQueryState;\n \n   // CHECKSTYLE_RULES.OFF: ParameterNumberCheck\n   @SuppressWarnings(\"WeakerAccess\") // Invoked via reflection\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzgxMw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753813", "body": "Would be good to add a unit test to _test_ this is returning an ordered collection. (Or just JSON with ordered fields).", "bodyText": "Would be good to add a unit test to test this is returning an ordered collection. (Or just JSON with ordered fields).", "bodyHTML": "<p dir=\"auto\">Would be good to add a unit test to <em>test</em> this is returning an ordered collection. (Or just JSON with ordered fields).</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T12:01:56Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -68,6 +74,11 @@ public QueryDescription(\n     this.overriddenProperties = ImmutableMap.copyOf(Objects\n         .requireNonNull(overriddenProperties, \"overriddenProperties\"));\n     this.state = Objects.requireNonNull(state, \"state\");\n+    \n+    this.ksqlHostQueryState =\n+        new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString));\n+    this.ksqlHostQueryState\n+        .putAll(Objects.requireNonNull(ksqlHostQueryState, \"ksqlHostQueryState\"));", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAzOTI3Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405039277", "bodyText": "I actually only wanted an ordered set because some of the new tests I added weren't working because the toString() of this map would return different results, but those tests don't rely on the string representation anymore since the state field was removed from the constructor so order doesn't matter for now.", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzgxMw=="}], "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\nindex 5cd2ff232c..7b5496e3ae 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n", "chunk": "@@ -73,12 +71,8 @@ public class QueryDescription {\n     this.executionPlan = Objects.requireNonNull(executionPlan, \"executionPlan\");\n     this.overriddenProperties = ImmutableMap.copyOf(Objects\n         .requireNonNull(overriddenProperties, \"overriddenProperties\"));\n-    this.state = Objects.requireNonNull(state, \"state\");\n-    \n     this.ksqlHostQueryState =\n-        new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString));\n-    this.ksqlHostQueryState\n-        .putAll(Objects.requireNonNull(ksqlHostQueryState, \"ksqlHostQueryState\"));\n+        new HashMap<>(Objects.requireNonNull(ksqlHostQueryState, \"ksqlHostQueryState\"));\n   }\n \n   public QueryId getId() {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1Mzk5OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753998", "body": "Consider adding a unit test using `EqualsTester` if the class does not already have one.", "bodyText": "Consider adding a unit test using EqualsTester if the class does not already have one.", "bodyHTML": "<p dir=\"auto\">Consider adding a unit test using <code>EqualsTester</code> if the class does not already have one.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T12:02:17Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -130,7 +145,8 @@ public boolean equals(final Object o) {\n         && Objects.equals(sources, that.sources)\n         && Objects.equals(sinks, that.sinks)\n         && Objects.equals(overriddenProperties, that.overriddenProperties)\n-        && Objects.equals(state, that.state);\n+        && Objects.equals(state, that.state)\n+        && Objects.equals(ksqlHostQueryState, that.ksqlHostQueryState);", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\nindex 5cd2ff232c..7b5496e3ae 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java\n", "chunk": "@@ -145,7 +145,6 @@ public class QueryDescription {\n         && Objects.equals(sources, that.sources)\n         && Objects.equals(sinks, that.sinks)\n         && Objects.equals(overriddenProperties, that.overriddenProperties)\n-        && Objects.equals(state, that.state)\n         && Objects.equals(ksqlHostQueryState, that.ksqlHostQueryState);\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1NDQ5OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404754498", "body": "Breaks encapsulation by returning mutable object state.  As above, wrap in unmodifyableMap.", "bodyText": "Breaks encapsulation by returning mutable object state.  As above, wrap in unmodifyableMap.", "bodyHTML": "<p dir=\"auto\">Breaks encapsulation by returning mutable object state.  As above, wrap in unmodifyableMap.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T12:03:17Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import com.google.common.base.Joiner;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> states;\n+\n+  public QueryStateCount() {\n+    this.states = returnEnumMap();\n+  }\n+\n+  @SuppressWarnings(\"unused\") // Invoked by reflection\n+  @JsonCreator\n+  public QueryStateCount(final Map<KafkaStreams.State, Integer> states) {\n+    this.states = states.isEmpty() ? returnEnumMap() : new EnumMap<>(states);\n+  }\n+\n+  \n+  public void updateStateCount(final String state, final int change) {\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+  }\n+\n+  public void updateStateCount(final KafkaStreams.State state, final int change) {\n+    this.states.compute(state, (key, existing) ->\n+        existing == null\n+            ? change\n+            : existing + change);\n+    \n+  }\n+\n+  @JsonValue\n+  public Map<KafkaStreams.State, Integer> getStates() {\n+    return states;", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "changed_code": [{"header": "diff --git a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\nindex 265be73ff5..5c25de52c5 100644\n--- a/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\n+++ b/ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java\n", "chunk": "@@ -61,7 +62,7 @@ public class QueryStateCount {\n \n   @JsonValue\n   public Map<KafkaStreams.State, Integer> getStates() {\n-    return states;\n+    return Collections.unmodifiableMap(states);\n   }\n \n   @Override\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1NDc4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404754787", "body": "Add test using `EqualsTester`.", "bodyText": "Add test using EqualsTester.", "bodyHTML": "<p dir=\"auto\">Add test using <code>EqualsTester</code>.</p>", "author": "big-andy-coates", "createdAt": "2020-04-07T12:03:52Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import com.google.common.base.Joiner;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> states;\n+\n+  public QueryStateCount() {\n+    this.states = returnEnumMap();\n+  }\n+\n+  @SuppressWarnings(\"unused\") // Invoked by reflection\n+  @JsonCreator\n+  public QueryStateCount(final Map<KafkaStreams.State, Integer> states) {\n+    this.states = states.isEmpty() ? returnEnumMap() : new EnumMap<>(states);\n+  }\n+\n+  \n+  public void updateStateCount(final String state, final int change) {\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+  }\n+\n+  public void updateStateCount(final KafkaStreams.State state, final int change) {\n+    this.states.compute(state, (key, existing) ->\n+        existing == null\n+            ? change\n+            : existing + change);\n+    \n+  }\n+\n+  @JsonValue\n+  public Map<KafkaStreams.State, Integer> getStates() {\n+    return states;\n+  }\n+\n+  @Override\n+  public boolean equals(final Object o) {\n+    if (this == o) {\n+      return true;\n+    }\n+\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+\n+    final QueryStateCount that = (QueryStateCount) o;\n+    return Objects.equals(states, that.states);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(states);\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return Joiner.on(\",\").withKeyValueSeparator(\":\").join(this.states);\n+  }", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "url": "https://github.com/confluentinc/ksql/commit/9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "message": "last refactor", "committedDate": "2020-04-07T18:45:15Z", "type": "commit"}, {"oid": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "url": "https://github.com/confluentinc/ksql/commit/9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "message": "last refactor", "committedDate": "2020-04-07T18:45:15Z", "type": "forcePushed"}]}