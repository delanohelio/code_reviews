{"pr_number": 2494, "pr_title": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "pr_author": "zhuqi-lucas", "pr_createdAt": "2020-11-27T03:06:18Z", "pr_url": "https://github.com/apache/hadoop/pull/2494", "timeline": [{"oid": "cad6881da696a0fbc427f3dcb199e95ffc81804b", "url": "https://github.com/apache/hadoop/commit/cad6881da696a0fbc427f3dcb199e95ffc81804b", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-11-27T03:17:04Z", "type": "forcePushed"}, {"oid": "80388afb28c8d2b92fff95416bf0a0f76d9d202d", "url": "https://github.com/apache/hadoop/commit/80388afb28c8d2b92fff95416bf0a0f76d9d202d", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-01T05:40:57Z", "type": "commit"}, {"oid": "80388afb28c8d2b92fff95416bf0a0f76d9d202d", "url": "https://github.com/apache/hadoop/commit/80388afb28c8d2b92fff95416bf0a0f76d9d202d", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-01T05:40:57Z", "type": "forcePushed"}, {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8", "url": "https://github.com/apache/hadoop/commit/fb506a09bcf17d30468cb22231e710492168a1c8", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-01T14:25:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjUxMg==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533502512", "body": "Why remove this variable and add new within if-else block?", "bodyText": "Why remove this variable and add new within if-else block?", "bodyHTML": "<p dir=\"auto\">Why remove this variable and add new within if-else block?</p>", "author": "jiwq", "createdAt": "2020-12-01T15:29:41Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -531,11 +531,11 @@ private static boolean shouldSkipNodeSchedule(FiCaSchedulerNode node,\n \n   /**\n    * Schedule on all nodes by starting at a random point.\n+   * Schedule on all partitions by starting at a random partition\n+   * when multiNodePlacementEnabled is true.\n    * @param cs\n    */\n   static void schedule(CapacityScheduler cs) throws InterruptedException{\n-    // First randomize the start point\n-    int current = 0;", "originalCommit": "fb506a09bcf17d30468cb22231e710492168a1c8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTkxNg==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865916", "bodyText": "Fixed it.", "author": "zhuqi-lucas", "createdAt": "2020-12-02T03:07:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg0MQ==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533502841", "body": "```suggestion\r\n      // Get all partitions\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  //Get all partitions\n          \n          \n            \n                  // Get all partitions", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">      <span class=\"pl-c\"><span class=\"pl-c\">//</span>Get all partitions</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">      <span class=\"pl-c\"><span class=\"pl-c\">//</span><span class=\"x x-first x-last\"> </span>Get all partitions</span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "jiwq", "createdAt": "2020-12-01T15:30:03Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions", "originalCommit": "fb506a09bcf17d30468cb22231e710492168a1c8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTg3MQ==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865871", "bodyText": "Fixed it.", "author": "zhuqi-lucas", "createdAt": "2020-12-02T03:06:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwNjAyNg==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533506026", "body": "Due to `getCandiateNodeSet(String)` method maybe return null, so call `allocateContainersToNode` can cause NPE.", "bodyText": "Due to getCandiateNodeSet(String) method maybe return null, so call allocateContainersToNode can cause NPE.", "bodyHTML": "<p dir=\"auto\">Due to <code>getCandiateNodeSet(String)</code> method maybe return null, so call <code>allocateContainersToNode</code> can cause NPE.</p>", "author": "jiwq", "createdAt": "2020-12-01T15:34:09Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions\n+      List<String> partitions = cs.nodeTracker.getPartitions();\n+      int partitionSize = partitions.size();\n+      // First randomize the start point\n+      int start = random.nextInt(partitionSize);\n+      int current = 0;\n+      // Allocate containers of partition [start, end)\n+      for (String partititon : partitions) {\n+        if (current++ >= start) {\n+          cs.allocateContainersToNode(cs.getCandidateNodeSet(partititon),", "originalCommit": "fb506a09bcf17d30468cb22231e710492168a1c8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTc4Ng==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865786", "bodyText": "Fixed it.", "author": "zhuqi-lucas", "createdAt": "2020-12-02T03:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwNjAyNg=="}], "type": "inlineReview"}, {"oid": "c0f03143911fc5e0527304da8e8f05d9563748fe", "url": "https://github.com/apache/hadoop/commit/c0f03143911fc5e0527304da8e8f05d9563748fe", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-02T03:02:22Z", "type": "commit"}, {"oid": "c0f03143911fc5e0527304da8e8f05d9563748fe", "url": "https://github.com/apache/hadoop/commit/c0f03143911fc5e0527304da8e8f05d9563748fe", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-02T03:02:22Z", "type": "forcePushed"}]}