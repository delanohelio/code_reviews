{"pr_number": 1899, "pr_title": "HADOOP-16914 Adding Output Stream Counters in ABFS", "pr_createdAt": "2020-03-17T11:38:47Z", "pr_url": "https://github.com/apache/hadoop/pull/1899", "merge_commit": "459eb2ad6d5bc6b21462e728fb334c6e30e14c39", "timeline": [{"oid": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "url": "https://github.com/apache/hadoop/commit/20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "message": "Fixing issues", "committedDate": "2020-03-18T08:23:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyNzg5NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r394227894", "body": "Need help in simulating Bytes to fail to upload in this test to get some values for bytesUploadFailed counter.", "bodyText": "Need help in simulating Bytes to fail to upload in this test to get some values for bytesUploadFailed counter.", "bodyHTML": "<p dir=\"auto\">Need help in simulating Bytes to fail to upload in this test to get some values for bytesUploadFailed counter.</p>", "author": "mehakmeet", "createdAt": "2020-03-18T10:00:23Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -28,28 +26,38 @@ public ITestAbfsOutputStream() throws Exception {\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NjI0OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395756248", "bodyText": "I can't think of any. Maybe just have a unit test to take an AbfsOutputStreamsImpl and verify that when the method is called, the counter is updated.\n(Actually, mocking could simulate failure, ...)", "author": "steveloughran", "createdAt": "2020-03-20T16:34:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyNzg5NA=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n", "next_change": {"commit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 0c82a2c065e..6c29ef9dc06 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -36,9 +36,9 @@\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n-  private static int LARGE_OPERATIONS = 10;\n-  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n-  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n", "next_change": null}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -27,101 +50,121 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testBytesToUpload = \"bytes\";\n \n-    AbfsOutputStream outForSomeBytes = null;\n-    try {\n-      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-          statistics,\n-          true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n \n       //Test for zero bytes To upload\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for some bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForSomeBytes != null) {\n-        outForSomeBytes.close();\n-      }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n     }\n \n-    AbfsOutputStream outForLargeBytes = null;\n-    try {\n-      outForLargeBytes =\n-          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-              statistics\n-              , true, FsPermission.getDefault(),\n-              FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n \n-      int largeValue = 100000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for large bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\",\n           largeValue * (testBytesToUpload.getBytes().length),\n-          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForLargeBytes != null) {\n-        outForLargeBytes.close();\n-      }\n-    }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n \n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n   }\n \n   /**\n-   * Tests to check time spend on waiting for tasks to be complete on a\n+   * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n    *\n    * @throws IOException\n    */\n   @Test\n-  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n \n-    AbfsOutputStream out =\n-        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n-            statistics, true,\n-            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n \n   }\n \n   /**\n-   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -155,17 +158,18 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n           .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n       /*\n       Test for large random value of timeSpentWaitTask plus the time spent\n-      in previous test\n+      in previous test.\n        */\n-      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n     }\n \n   }\n \n   /**\n-   * Tests to check number of {@code shrinkWriteOperationQueue()}\n-   * calls.\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n    * shrink calls.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r394228752", "body": "any way around flush() to get queueShrink() calls after writing ?\r\nflush() is quite expensive as it takes some time even at 1000 calls to test.", "bodyText": "any way around flush() to get queueShrink() calls after writing ?\nflush() is quite expensive as it takes some time even at 1000 calls to test.", "bodyHTML": "<p dir=\"auto\">any way around flush() to get queueShrink() calls after writing ?<br>\nflush() is quite expensive as it takes some time even at 1000 calls to test.</p>", "author": "mehakmeet", "createdAt": "2020-03-18T10:01:47Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -133,58 +133,60 @@ public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path TEST_PATH = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n     AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n     abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     FileSystem.Statistics statistics = fs.getFsStatistics();\n     String testQueueShrink = \"testQueue\";\n \n-\n     AbfsOutputStream outForOneOp = null;\n \n     try {\n-      outForOneOp = (AbfsOutputStream) abfss.createFile(TEST_PATH, statistics,\n-        true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n \n       //Test for shrinking Queue zero time\n-      Assert.assertEquals(\"Mismatch in number of queueShrink() Calls\", 0,\n+      assertValues(\"number of queueShrink() Calls\", 0,\n           outForOneOp.getOutputStreamStatistics().queueShrink);\n \n       outForOneOp.write(testQueueShrink.getBytes());\n       // Queue is shrunk 2 times when outStream is flushed\n       outForOneOp.flush();\n \n       //Test for shrinking Queue 2 times\n-      Assert.assertEquals(\"Mismatch in number of queueShrink() Calls\", 2,\n+      assertValues(\"number of queueShrink() Calls\", 2,\n           outForOneOp.getOutputStreamStatistics().queueShrink);\n \n     } finally {\n-      if(outForOneOp != null){\n+      if (outForOneOp != null) {\n         outForOneOp.close();\n       }\n     }\n \n     AbfsOutputStream outForLargeOps = null;\n \n     try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(TEST_PATH,\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n           statistics, true,\n           FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n \n+      int largeValue = 1000;\n       //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n       // give 2000 QueueShrink calls\n-      for (int i = 0; i < 1000; i++) {\n+      for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         //Flush is quite expensive so 1000 calls only which takes 1 min+\n         outForLargeOps.flush();", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTIwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751202", "bodyText": "do you have to call it so many times?", "author": "steveloughran", "createdAt": "2020-03-20T16:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMTY5Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404611696", "bodyText": "You can call flush outside the for loop?", "author": "mukund-thakur", "createdAt": "2020-04-07T07:59:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTA1OTgwNg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405059806", "bodyText": "No I can't, basically calling flush after I write means the write task is done. This would trigger the shrinkWriteOperationQueue() method and we need to do it after each write to get 10 calls to shrinkWriteOperationQueue() .\nIf I flush after the loop, it would take all the write calls as 1 write operation and only 1 time the shrinkWriteOperationQueue() method is triggered.", "author": "mehakmeet", "createdAt": "2020-04-07T19:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -157,44 +192,29 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n \n       //Test for shrinking Queue 2 times\n       assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().queueShrink);\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n \n-    } finally {\n-      if (outForOneOp != null) {\n-        outForOneOp.close();\n-      }\n     }\n \n-    AbfsOutputStream outForLargeOps = null;\n-\n-    try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n-          statistics, true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n \n-      int largeValue = 1000;\n-      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n-      // give 2000 QueueShrink calls\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n-        //Flush is quite expensive so 1000 calls only which takes 1 min+\n         outForLargeOps.flush();\n       }\n \n-      //Test for 2000 queue shrink calls\n+      //Test for 20 queue shrink calls\n       assertValues(\"number of queueShrink() Calls\",\n           2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().queueShrink);\n-    } finally {\n-      if (outForLargeOps != null) {\n-        outForLargeOps.close();\n-      }\n+          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * Test to check number of {@code writeCurrentBufferToService()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -176,46 +180,52 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n \n-      //Test for shrinking Queue zero time\n-      assertValues(\"number of queueShrink() Calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outStream is flushed\n+      // Queue is shrunk 2 times when outputStream is flushed.\n       outForOneOp.flush();\n \n-      //Test for shrinking Queue 2 times\n-      assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n \n     try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n-\n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         outForLargeOps.flush();\n       }\n \n-      //Test for 20 queue shrink calls\n-      assertValues(\"number of queueShrink() Calls\",\n-          2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@code writeCurrentBufferToService()}\n-   * calls.\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n    * scenario.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMDI0Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r394230246", "body": "Need help on how to write tests for this counter.", "bodyText": "Need help on how to write tests for this counter.", "bodyHTML": "<p dir=\"auto\">Need help on how to write tests for this counter.</p>", "author": "mehakmeet", "createdAt": "2020-03-18T10:04:18Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTYwMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749601", "bodyText": "I don't see any easy way except to assert that it is > 0", "author": "steveloughran", "createdAt": "2020-03-20T16:24:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMDI0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTc2Mw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749763", "bodyText": "Also, \"time spent\"", "author": "steveloughran", "createdAt": "2020-03-20T16:24:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMDI0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -27,101 +50,121 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testBytesToUpload = \"bytes\";\n \n-    AbfsOutputStream outForSomeBytes = null;\n-    try {\n-      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-          statistics,\n-          true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n \n       //Test for zero bytes To upload\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for some bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForSomeBytes != null) {\n-        outForSomeBytes.close();\n-      }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n     }\n \n-    AbfsOutputStream outForLargeBytes = null;\n-    try {\n-      outForLargeBytes =\n-          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-              statistics\n-              , true, FsPermission.getDefault(),\n-              FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n \n-      int largeValue = 100000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for large bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\",\n           largeValue * (testBytesToUpload.getBytes().length),\n-          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForLargeBytes != null) {\n-        outForLargeBytes.close();\n-      }\n-    }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n \n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n   }\n \n   /**\n-   * Tests to check time spend on waiting for tasks to be complete on a\n+   * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n    *\n    * @throws IOException\n    */\n   @Test\n-  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n \n-    AbfsOutputStream out =\n-        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n-            statistics, true,\n-            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n \n   }\n \n   /**\n-   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -155,17 +158,18 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n           .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n       /*\n       Test for large random value of timeSpentWaitTask plus the time spent\n-      in previous test\n+      in previous test.\n        */\n-      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n     }\n \n   }\n \n   /**\n-   * Tests to check number of {@code shrinkWriteOperationQueue()}\n-   * calls.\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n    * shrink calls.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MzU1MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395743551", "body": "this is input stream; presumably it's come in from somewhere else", "bodyText": "this is input stream; presumably it's come in from somewhere else", "bodyHTML": "<p dir=\"auto\">this is input stream; presumably it's come in from somewhere else</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:14:20Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java", "diffHunk": "@@ -101,6 +101,7 @@ public synchronized int read(final byte[] b, final int off, final int len) throw\n     int currentLen = len;\n     int lastReadBytes;\n     int totalReadBytes = 0;\n+    incrementReadOps();", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjIzMDE1Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r396230156", "bodyText": "this is from the master PR(#1881)", "author": "mehakmeet", "createdAt": "2020-03-23T06:13:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MzU1MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MzkyMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395743922", "body": "move down to under ElasticByteBufferPool", "bodyText": "move down to under ElasticByteBufferPool", "bodyHTML": "<p dir=\"auto\">move down to under ElasticByteBufferPool</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:15:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -36,20 +36,25 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n+import org.apache.hadoop.fs.FileSystem.Statistics;", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6e5cf8b5fd3..1bd17193594 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -36,10 +36,10 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n-import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.io.ElasticByteBufferPool;\n+import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.FSExceptionMessages;\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 1bd17193594..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -44,7 +46,6 @@\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n \n-import static org.apache.hadoop.io.IOUtils.LOG;\n import static org.apache.hadoop.io.IOUtils.wrapException;\n \n /**\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6974db92557..dff5897ea38 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -46,6 +44,7 @@\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n \n+import static org.apache.hadoop.io.IOUtils.LOG;\n import static org.apache.hadoop.io.IOUtils.wrapException;\n \n /**\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex dff5897ea38..c55d5a2cc5f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -44,7 +46,6 @@\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n \n-import static org.apache.hadoop.io.IOUtils.LOG;\n import static org.apache.hadoop.io.IOUtils.wrapException;\n \n /**\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NDQ3NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395744474", "body": "add both new fields at the bottom of the other fields, e.g Line 85, and keep togeher. ", "bodyText": "add both new fields at the bottom of the other fields, e.g Line 85, and keep togeher.", "bodyHTML": "<p dir=\"auto\">add both new fields at the bottom of the other fields, e.g Line 85, and keep togeher.</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:15:55Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -36,20 +36,25 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n+import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.io.ElasticByteBufferPool;\n import org.apache.hadoop.fs.FSExceptionMessages;\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n \n+import static org.apache.hadoop.io.IOUtils.LOG;\n import static org.apache.hadoop.io.IOUtils.wrapException;\n \n /**\n  * The BlobFsOutputStream for Rest AbfsClient.\n  */\n public class AbfsOutputStream extends OutputStream implements Syncable, StreamCapabilities {\n+", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6e5cf8b5fd3..1bd17193594 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -52,9 +52,7 @@\n  */\n public class AbfsOutputStream extends OutputStream implements Syncable, StreamCapabilities {\n \n-  private final AbfsOutputStreamStatisticsImpl outputStreamStatistics;\n   private final AbfsClient client;\n-  private final Statistics statistics;\n   private final String path;\n   private long position;\n   private boolean closed;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NTI0OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395745249", "body": "prefer a more detailed description like uploadFailed(long). It's recording that an upload failed and the number of bytes", "bodyText": "prefer a more detailed description like uploadFailed(long). It's recording that an upload failed and the number of bytes", "bodyHTML": "<p dir=\"auto\">prefer a more detailed description like uploadFailed(long). It's recording that an upload failed and the number of bytes</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:17:15Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Number of bytes uploaded Successfully.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  void bytesUploadedSuccessfully(long bytes);\n+\n+  /**\n+   * Number of bytes failed to upload.\n+   *\n+   * @param bytes number of bytes that failed to upload\n+   */\n+  void bytesFailed(long bytes);", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex cb6b9b7074a..e21628623f6 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -16,18 +34,18 @@\n   void bytesToUpload(long bytes);\n \n   /**\n-   * Number of bytes uploaded Successfully.\n+   * Records a successful upload and the number of bytes uploaded.\n    *\n    * @param bytes number of bytes that were successfully uploaded\n    */\n-  void bytesUploadedSuccessfully(long bytes);\n+  void uploadSuccessful(long bytes);\n \n   /**\n-   * Number of bytes failed to upload.\n+   * Records that upload is failed and the number of bytes.\n    *\n    * @param bytes number of bytes that failed to upload\n    */\n-  void bytesFailed(long bytes);\n+  void uploadFailed(long bytes);\n \n   /**\n    * Time spent in waiting for tasks to be completed in the blocking Queue.\n", "next_change": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex e21628623f6..cbd70ceaa8f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -29,40 +29,41 @@\n   /**\n    * Number of bytes to be uploaded.\n    *\n-   * @param bytes number of bytes to upload\n+   * @param bytes number of bytes to upload.\n    */\n   void bytesToUpload(long bytes);\n \n   /**\n    * Records a successful upload and the number of bytes uploaded.\n    *\n-   * @param bytes number of bytes that were successfully uploaded\n+   * @param bytes number of bytes that were successfully uploaded.\n    */\n   void uploadSuccessful(long bytes);\n \n   /**\n    * Records that upload is failed and the number of bytes.\n    *\n-   * @param bytes number of bytes that failed to upload\n+   * @param bytes number of bytes that failed to upload.\n    */\n   void uploadFailed(long bytes);\n \n   /**\n    * Time spent in waiting for tasks to be completed in the blocking Queue.\n    *\n-   * @param start millisecond at which the wait for task to be complete begins\n-   * @param end   millisecond at which the wait is completed for the task\n+   * @param start millisecond at which the wait for task to be complete begins.\n+   * @param end   millisecond at which the wait is completed for the task.\n    */\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code shrinkWriteOperationQueue()}\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n   void queueShrinked();\n \n   /**\n-   * Number of times {@code writeCurrentBufferToService(boolean, boolean)}\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n    * method was called.\n    */\n   void writeCurrentBuffer();\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex cbd70ceaa8f..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -59,7 +59,7 @@\n    * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n-  void queueShrinked();\n+  void queueShrunk();\n \n   /**\n    * Number of times\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex c9fe0dd4552..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,18 +56,20 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times task queue is shrunk.\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n+   * method was called.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times buffer is written to the service after a write operation.\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n+   * method was called.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a string of all AbfsOutputStream statistics and their\n-   * values.\n+   * Method to form a String of all AbfsOutputStream counters and their values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NjAxMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395746011", "body": "MUST NOT use @link to private/package-private/protected methods. Javadoc will fail", "bodyText": "MUST NOT use @link to private/package-private/protected methods. Javadoc will fail", "bodyHTML": "<p dir=\"auto\">MUST NOT use <a class=\"user-mention\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/link/hovercard\" href=\"https://github.com/link\">@link</a> to private/package-private/protected methods. Javadoc will fail</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:18:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;\n+  public volatile long bytesUploadSuccessful;\n+  public volatile long bytesUploadFailed;\n+  public volatile long timeSpendOnTaskWait;\n+  public volatile long queueShrink;\n+  public volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded only when bytes passed are positive.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  @Override\n+  public void bytesUploadedSuccessfully(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Number of bytes that weren't uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spend for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -32,38 +50,42 @@ public void bytesToUpload(long bytes) {\n     }\n   }\n \n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n   @Override\n-  public void bytesUploadedSuccessfully(long bytes) {\n+  public void uploadSuccessful(long bytes) {\n     if (bytes > 0) {\n       bytesUploadSuccessful += bytes;\n     }\n   }\n \n   /**\n-   * Number of bytes that weren't uploaded.\n+   * Upload failed and the number of bytes.\n    *\n    * @param bytes negative values are ignored\n    */\n   @Override\n-  public void bytesFailed(long bytes) {\n+  public void uploadFailed(long bytes) {\n     if (bytes > 0) {\n       bytesUploadFailed += bytes;\n     }\n   }\n \n   /**\n-   * Time spend for waiting a task to be completed.\n+   * Time spent for waiting a task to be completed.\n    *\n-   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param startTime on calling {@code waitForTaskToComplete()}\n    * @param endTime   on method completing\n    */\n   @Override\n-  public void timeSpendTaskWait(long startTime, long endTime) {\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n     timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n-   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.\n+   * Number of calls to {@code shrinkWriteOperationQueue()}.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -85,7 +102,10 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   }\n \n   /**\n-   * Number of calls to {@code shrinkWriteOperationQueue()}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,12 +110,12 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   /**\n    * {@inheritDoc}\n    *\n-   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * Records the number of times AbfsOutputStream try to remove the completed\n    * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n-  public void queueShrinked() {\n-    queueShrink++;\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n   }\n \n   /**\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 6c06cf0e35b..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -103,14 +104,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpentOnTaskWait += endTime - startTime;\n+    timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation task queue.\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -93,7 +113,10 @@ public void queueShrinked() {\n   }\n \n   /**\n-   * Number of calls to {@code writeCurrentBufferToService(boolean, boolean)}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream writes the buffer to the\n+   * service via the AbfsClient and appends the buffer to the service.\n    */\n   @Override\n   public void writeCurrentBuffer() {\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NjI1Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395746252", "body": "see above comment about javadocs", "bodyText": "see above comment about javadocs", "bodyHTML": "<p dir=\"auto\">see above comment about javadocs</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:18:52Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;\n+  public volatile long bytesUploadSuccessful;\n+  public volatile long bytesUploadFailed;\n+  public volatile long timeSpendOnTaskWait;\n+  public volatile long queueShrink;\n+  public volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded only when bytes passed are positive.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  @Override\n+  public void bytesUploadedSuccessfully(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Number of bytes that weren't uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spend for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param endTime   on method completing\n+   */\n+  @Override\n+  public void timeSpendTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -32,38 +50,42 @@ public void bytesToUpload(long bytes) {\n     }\n   }\n \n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n   @Override\n-  public void bytesUploadedSuccessfully(long bytes) {\n+  public void uploadSuccessful(long bytes) {\n     if (bytes > 0) {\n       bytesUploadSuccessful += bytes;\n     }\n   }\n \n   /**\n-   * Number of bytes that weren't uploaded.\n+   * Upload failed and the number of bytes.\n    *\n    * @param bytes negative values are ignored\n    */\n   @Override\n-  public void bytesFailed(long bytes) {\n+  public void uploadFailed(long bytes) {\n     if (bytes > 0) {\n       bytesUploadFailed += bytes;\n     }\n   }\n \n   /**\n-   * Time spend for waiting a task to be completed.\n+   * Time spent for waiting a task to be completed.\n    *\n-   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param startTime on calling {@code waitForTaskToComplete()}\n    * @param endTime   on method completing\n    */\n   @Override\n-  public void timeSpendTaskWait(long startTime, long endTime) {\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n     timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n-   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.\n+   * Number of calls to {@code shrinkWriteOperationQueue()}.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -85,7 +102,10 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   }\n \n   /**\n-   * Number of calls to {@code shrinkWriteOperationQueue()}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,12 +110,12 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   /**\n    * {@inheritDoc}\n    *\n-   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * Records the number of times AbfsOutputStream try to remove the completed\n    * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n-  public void queueShrinked() {\n-    queueShrink++;\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n   }\n \n   /**\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 6c06cf0e35b..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -103,14 +104,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpentOnTaskWait += endTime - startTime;\n+    timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation task queue.\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -93,7 +113,10 @@ public void queueShrinked() {\n   }\n \n   /**\n-   * Number of calls to {@code writeCurrentBufferToService(boolean, boolean)}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream writes the buffer to the\n+   * service via the AbfsClient and appends the buffer to the service.\n    */\n   @Override\n   public void writeCurrentBuffer() {\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NjMwMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395746300", "body": "see above comment about javadocs", "bodyText": "see above comment about javadocs", "bodyHTML": "<p dir=\"auto\">see above comment about javadocs</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:18:57Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;\n+  public volatile long bytesUploadSuccessful;\n+  public volatile long bytesUploadFailed;\n+  public volatile long timeSpendOnTaskWait;\n+  public volatile long queueShrink;\n+  public volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded only when bytes passed are positive.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  @Override\n+  public void bytesUploadedSuccessfully(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Number of bytes that weren't uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spend for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param endTime   on method completing\n+   */\n+  @Override\n+  public void timeSpendTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.\n+   */\n+  @Override\n+  public void queueShrinked() {\n+    queueShrink++;\n+  }\n+\n+  /**\n+   * Number of calls to {@link AbfsOutputStream#writeCurrentBufferToService()}.", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -32,38 +50,42 @@ public void bytesToUpload(long bytes) {\n     }\n   }\n \n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n   @Override\n-  public void bytesUploadedSuccessfully(long bytes) {\n+  public void uploadSuccessful(long bytes) {\n     if (bytes > 0) {\n       bytesUploadSuccessful += bytes;\n     }\n   }\n \n   /**\n-   * Number of bytes that weren't uploaded.\n+   * Upload failed and the number of bytes.\n    *\n    * @param bytes negative values are ignored\n    */\n   @Override\n-  public void bytesFailed(long bytes) {\n+  public void uploadFailed(long bytes) {\n     if (bytes > 0) {\n       bytesUploadFailed += bytes;\n     }\n   }\n \n   /**\n-   * Time spend for waiting a task to be completed.\n+   * Time spent for waiting a task to be completed.\n    *\n-   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param startTime on calling {@code waitForTaskToComplete()}\n    * @param endTime   on method completing\n    */\n   @Override\n-  public void timeSpendTaskWait(long startTime, long endTime) {\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n     timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n-   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.\n+   * Number of calls to {@code shrinkWriteOperationQueue()}.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -85,7 +102,10 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   }\n \n   /**\n-   * Number of calls to {@code shrinkWriteOperationQueue()}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,12 +110,12 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   /**\n    * {@inheritDoc}\n    *\n-   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * Records the number of times AbfsOutputStream try to remove the completed\n    * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n-  public void queueShrinked() {\n-    queueShrink++;\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n   }\n \n   /**\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 6c06cf0e35b..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -103,14 +104,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpentOnTaskWait += endTime - startTime;\n+    timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation task queue.\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -93,7 +113,10 @@ public void queueShrinked() {\n   }\n \n   /**\n-   * Number of calls to {@code writeCurrentBufferToService(boolean, boolean)}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream writes the buffer to the\n+   * service via the AbfsClient and appends the buffer to the service.\n    */\n   @Override\n   public void writeCurrentBuffer() {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -71,13 +93,37 @@ public void queueShrinked() {\n   }\n \n   /**\n-   * Number of calls to {@link AbfsOutputStream#writeCurrentBufferToService()}.\n+   * Number of calls to {@code writeCurrentBufferToService(boolean, boolean)}.\n    */\n   @Override\n   public void writeCurrentBuffer() {\n     writeCurrentBufferOperations++;\n   }\n \n+  public long getBytesToUpload() {\n+    return bytesToUpload;\n+  }\n+\n+  public long getBytesUploadSuccessful() {\n+    return bytesUploadSuccessful;\n+  }\n+\n+  public long getBytesUploadFailed() {\n+    return bytesUploadFailed;\n+  }\n+\n+  public long getTimeSpendOnTaskWait() {\n+    return timeSpendOnTaskWait;\n+  }\n+\n+  public long getQueueShrink() {\n+    return queueShrink;\n+  }\n+\n+  public long getWriteCurrentBufferOperations() {\n+    return writeCurrentBufferOperations;\n+  }\n+\n   /**\n    * String to show AbfsOutputStream statistics values in AbfsOutputStream.\n    *\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -132,15 +160,15 @@ public long getWriteCurrentBufferOperations() {\n   @Override public String toString() {\n     final StringBuilder outputStreamStats = new StringBuilder(\n         \"OutputStream Statistics{\");\n-    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);\n-    outputStreamStats.append(\", BYTES_UPLOAD_SUCCESSFUL=\")\n+    outputStreamStats.append(\", bytes_upload=\").append(bytesToUpload);\n+    outputStreamStats.append(\", bytes_upload_successfully=\")\n         .append(bytesUploadSuccessful);\n-    outputStreamStats.append(\", BYTES_UPLOAD_FAILED=\")\n+    outputStreamStats.append(\", bytes_upload_failed=\")\n         .append(bytesUploadFailed);\n-    outputStreamStats.append(\", TIME_SPEND_WAIT_TASK=\")\n-        .append(timeSpendOnTaskWait);\n-    outputStreamStats.append(\", QUEUE_SHRINK=\").append(queueShrink);\n-    outputStreamStats.append(\", WRITE_CURRENT_BUFFER=\")\n+    outputStreamStats.append(\", time_spent_task_wait=\")\n+        .append(timeSpentOnTaskWait);\n+    outputStreamStats.append(\", queue_shrunk_ops=\").append(queueShrunkOps);\n+    outputStreamStats.append(\", write_current_buffer_ops=\")\n         .append(writeCurrentBufferOperations);\n     outputStreamStats.append(\"}\");\n     return outputStreamStats.toString();\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -160,15 +161,15 @@ public long getWriteCurrentBufferOperations() {\n   @Override public String toString() {\n     final StringBuilder outputStreamStats = new StringBuilder(\n         \"OutputStream Statistics{\");\n-    outputStreamStats.append(\", bytes_upload=\").append(bytesToUpload);\n-    outputStreamStats.append(\", bytes_upload_successfully=\")\n+    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);\n+    outputStreamStats.append(\", BYTES_UPLOAD_SUCCESSFUL=\")\n         .append(bytesUploadSuccessful);\n-    outputStreamStats.append(\", bytes_upload_failed=\")\n+    outputStreamStats.append(\", BYTES_UPLOAD_FAILED=\")\n         .append(bytesUploadFailed);\n-    outputStreamStats.append(\", time_spent_task_wait=\")\n-        .append(timeSpentOnTaskWait);\n-    outputStreamStats.append(\", queue_shrunk_ops=\").append(queueShrunkOps);\n-    outputStreamStats.append(\", write_current_buffer_ops=\")\n+    outputStreamStats.append(\", TIME_SPEND_WAIT_TASK=\")\n+        .append(timeSpendOnTaskWait);\n+    outputStreamStats.append(\", QUEUE_SHRINK=\").append(queueShrunkOps);\n+    outputStreamStats.append(\", WRITE_CURRENT_BUFFER=\")\n         .append(writeCurrentBufferOperations);\n     outputStreamStats.append(\"}\");\n     return outputStreamStats.toString();\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -161,15 +160,15 @@ public long getWriteCurrentBufferOperations() {\n   @Override public String toString() {\n     final StringBuilder outputStreamStats = new StringBuilder(\n         \"OutputStream Statistics{\");\n-    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);\n-    outputStreamStats.append(\", BYTES_UPLOAD_SUCCESSFUL=\")\n+    outputStreamStats.append(\", bytes_upload=\").append(bytesToUpload);\n+    outputStreamStats.append(\", bytes_upload_successfully=\")\n         .append(bytesUploadSuccessful);\n-    outputStreamStats.append(\", BYTES_UPLOAD_FAILED=\")\n+    outputStreamStats.append(\", bytes_upload_failed=\")\n         .append(bytesUploadFailed);\n-    outputStreamStats.append(\", TIME_SPEND_WAIT_TASK=\")\n-        .append(timeSpendOnTaskWait);\n-    outputStreamStats.append(\", QUEUE_SHRINK=\").append(queueShrunkOps);\n-    outputStreamStats.append(\", WRITE_CURRENT_BUFFER=\")\n+    outputStreamStats.append(\", time_spent_task_wait=\")\n+        .append(timeSpentOnTaskWait);\n+    outputStreamStats.append(\", queue_shrunk_ops=\").append(queueShrunkOps);\n+    outputStreamStats.append(\", write_current_buffer_ops=\")\n         .append(writeCurrentBufferOperations);\n     outputStreamStats.append(\"}\");\n     return outputStreamStats.toString();\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0ODMwNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395748307", "body": "1. MUST use { } in all if () clauses.\n2. If there's a mismatch, use AssertEquals and include the pos where the problem occurred\n\nImagine: \"A remote test run failed -what information should be in the test report to begin debugging this?\"", "bodyText": "MUST use { } in all if () clauses.\nIf there's a mismatch, use AssertEquals and include the pos where the problem occurred\n\nImagine: \"A remote test run failed -what information should be in the test report to begin debugging this?\"", "bodyHTML": "<ol dir=\"auto\">\n<li>MUST use { } in all if () clauses.</li>\n<li>If there's a mismatch, use AssertEquals and include the pos where the problem occurred</li>\n</ol>\n<p dir=\"auto\">Imagine: \"A remote test run failed -what information should be in the test report to begin debugging this?\"</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:22:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java", "diffHunk": "@@ -67,4 +77,46 @@ public void nameThread() {\n   protected int getTestTimeoutMillis() {\n     return TEST_TIMEOUT;\n   }\n+\n+  /**\n+   * Describe a test in the logs.\n+   *\n+   * @param text text to print\n+   * @param args arguments to format in the printing\n+   */\n+  protected void describe(String text, Object... args) {\n+    LOG.info(\"\\n\\n{}: {}\\n\",\n+        methodName.getMethodName(),\n+        String.format(text, args));\n+  }\n+\n+  /**\n+   * Validate Contents written on a file in Abfs.\n+   *\n+   * @param fs                AzureBlobFileSystem\n+   * @param path              Path of the file\n+   * @param originalByteArray original byte array\n+   * @return if content is validated true else, false\n+   * @throws IOException\n+   */\n+  protected boolean validateContent(AzureBlobFileSystem fs, Path path,\n+      byte[] originalByteArray)\n+      throws IOException {\n+    FSDataInputStream in = fs.open(path);\n+\n+    int pos = 0;\n+    int lenOfOriginalByteArray = originalByteArray.length;\n+    byte valueOfContentAtPos = (byte) in.read();\n+\n+    while (valueOfContentAtPos != -1 && pos < lenOfOriginalByteArray) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java\nindex f6805fb88c4..0485422871e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java\n", "chunk": "@@ -102,21 +102,28 @@ protected void describe(String text, Object... args) {\n   protected boolean validateContent(AzureBlobFileSystem fs, Path path,\n       byte[] originalByteArray)\n       throws IOException {\n-    FSDataInputStream in = fs.open(path);\n-\n     int pos = 0;\n     int lenOfOriginalByteArray = originalByteArray.length;\n-    byte valueOfContentAtPos = (byte) in.read();\n \n-    while (valueOfContentAtPos != -1 && pos < lenOfOriginalByteArray) {\n-      if (originalByteArray[pos] != valueOfContentAtPos)\n+    try (FSDataInputStream in = fs.open(path)) {\n+      byte valueOfContentAtPos = (byte) in.read();\n+\n+      while (valueOfContentAtPos != -1 && pos < lenOfOriginalByteArray) {\n+        if (originalByteArray[pos] != valueOfContentAtPos) {\n+          assertEquals(\"Mismatch in content validation at position {}\", pos,\n+              originalByteArray[pos], valueOfContentAtPos);\n+          return false;\n+        }\n+        valueOfContentAtPos = (byte) in.read();\n+        pos++;\n+      }\n+      if (valueOfContentAtPos != -1) {\n+        assertEquals(\"Expected end of file\", -1, valueOfContentAtPos);\n         return false;\n-      valueOfContentAtPos = (byte) in.read();\n-      pos++;\n+      }\n+      return true;\n     }\n-    if (valueOfContentAtPos != -1)\n-      return false;\n-    return true;\n+\n   }\n \n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTAyMw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749023", "body": "IOUtils.closeQuietly(LOG, ...), or try-with-resources", "bodyText": "IOUtils.closeQuietly(LOG, ...), or try-with-resources", "bodyHTML": "<p dir=\"auto\">IOUtils.closeQuietly(LOG, ...), or try-with-resources</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:23:14Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -27,101 +50,121 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testBytesToUpload = \"bytes\";\n \n-    AbfsOutputStream outForSomeBytes = null;\n-    try {\n-      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-          statistics,\n-          true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n \n       //Test for zero bytes To upload\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for some bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForSomeBytes != null) {\n-        outForSomeBytes.close();\n-      }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n     }\n \n-    AbfsOutputStream outForLargeBytes = null;\n-    try {\n-      outForLargeBytes =\n-          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-              statistics\n-              , true, FsPermission.getDefault(),\n-              FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n \n-      int largeValue = 100000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for large bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\",\n           largeValue * (testBytesToUpload.getBytes().length),\n-          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForLargeBytes != null) {\n-        outForLargeBytes.close();\n-      }\n-    }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n \n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n   }\n \n   /**\n-   * Tests to check time spend on waiting for tasks to be complete on a\n+   * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n    *\n    * @throws IOException\n    */\n   @Test\n-  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n \n-    AbfsOutputStream out =\n-        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n-            statistics, true,\n-            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n \n   }\n \n   /**\n-   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -155,17 +158,18 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n           .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n       /*\n       Test for large random value of timeSpentWaitTask plus the time spent\n-      in previous test\n+      in previous test.\n        */\n-      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n     }\n \n   }\n \n   /**\n-   * Tests to check number of {@code shrinkWriteOperationQueue()}\n-   * calls.\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n    * shrink calls.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTIxMw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749213", "body": "same", "bodyText": "same", "bodyHTML": "<p dir=\"auto\">same</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:23:31Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -27,101 +50,121 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testBytesToUpload = \"bytes\";\n \n-    AbfsOutputStream outForSomeBytes = null;\n-    try {\n-      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-          statistics,\n-          true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n \n       //Test for zero bytes To upload\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for some bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForSomeBytes != null) {\n-        outForSomeBytes.close();\n-      }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n     }\n \n-    AbfsOutputStream outForLargeBytes = null;\n-    try {\n-      outForLargeBytes =\n-          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-              statistics\n-              , true, FsPermission.getDefault(),\n-              FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n \n-      int largeValue = 100000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for large bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\",\n           largeValue * (testBytesToUpload.getBytes().length),\n-          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForLargeBytes != null) {\n-        outForLargeBytes.close();\n-      }\n-    }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n \n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n   }\n \n   /**\n-   * Tests to check time spend on waiting for tasks to be complete on a\n+   * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n    *\n    * @throws IOException\n    */\n   @Test\n-  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n \n-    AbfsOutputStream out =\n-        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n-            statistics, true,\n-            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n \n   }\n \n   /**\n-   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -155,17 +158,18 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n           .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n       /*\n       Test for large random value of timeSpentWaitTask plus the time spent\n-      in previous test\n+      in previous test.\n        */\n-      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n     }\n \n   }\n \n   /**\n-   * Tests to check number of {@code shrinkWriteOperationQueue()}\n-   * calls.\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n    * shrink calls.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MDAxMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395750011", "body": "will need to be closed", "bodyText": "will need to be closed", "bodyHTML": "<p dir=\"auto\">will need to be closed</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:24:50Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -27,101 +50,121 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testBytesToUpload = \"bytes\";\n \n-    AbfsOutputStream outForSomeBytes = null;\n-    try {\n-      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-          statistics,\n-          true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n \n       //Test for zero bytes To upload\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for some bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForSomeBytes != null) {\n-        outForSomeBytes.close();\n-      }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n     }\n \n-    AbfsOutputStream outForLargeBytes = null;\n-    try {\n-      outForLargeBytes =\n-          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-              statistics\n-              , true, FsPermission.getDefault(),\n-              FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n \n-      int largeValue = 100000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for large bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\",\n           largeValue * (testBytesToUpload.getBytes().length),\n-          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForLargeBytes != null) {\n-        outForLargeBytes.close();\n-      }\n-    }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n \n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n   }\n \n   /**\n-   * Tests to check time spend on waiting for tasks to be complete on a\n+   * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n    *\n    * @throws IOException\n    */\n   @Test\n-  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n \n-    AbfsOutputStream out =\n-        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n-            statistics, true,\n-            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n \n   }\n \n   /**\n-   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -155,17 +158,18 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n           .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n       /*\n       Test for large random value of timeSpentWaitTask plus the time spent\n-      in previous test\n+      in previous test.\n        */\n-      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n     }\n \n   }\n \n   /**\n-   * Tests to check number of {@code shrinkWriteOperationQueue()}\n-   * calls.\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n    * shrink calls.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MDQwMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395750400", "body": "try-with-resources or IOUtils.closeQuietly", "bodyText": "try-with-resources or IOUtils.closeQuietly", "bodyHTML": "<p dir=\"auto\">try-with-resources or IOUtils.closeQuietly</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:25:28Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -157,44 +192,29 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n \n       //Test for shrinking Queue 2 times\n       assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().queueShrink);\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n \n-    } finally {\n-      if (outForOneOp != null) {\n-        outForOneOp.close();\n-      }\n     }\n \n-    AbfsOutputStream outForLargeOps = null;\n-\n-    try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n-          statistics, true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n \n-      int largeValue = 1000;\n-      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n-      // give 2000 QueueShrink calls\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n-        //Flush is quite expensive so 1000 calls only which takes 1 min+\n         outForLargeOps.flush();\n       }\n \n-      //Test for 2000 queue shrink calls\n+      //Test for 20 queue shrink calls\n       assertValues(\"number of queueShrink() Calls\",\n           2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().queueShrink);\n-    } finally {\n-      if (outForLargeOps != null) {\n-        outForLargeOps.close();\n-      }\n+          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * Test to check number of {@code writeCurrentBufferToService()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -176,46 +180,52 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n \n-      //Test for shrinking Queue zero time\n-      assertValues(\"number of queueShrink() Calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outStream is flushed\n+      // Queue is shrunk 2 times when outputStream is flushed.\n       outForOneOp.flush();\n \n-      //Test for shrinking Queue 2 times\n-      assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n \n     try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n-\n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         outForLargeOps.flush();\n       }\n \n-      //Test for 20 queue shrink calls\n-      assertValues(\"number of queueShrink() Calls\",\n-          2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@code writeCurrentBufferToService()}\n-   * calls.\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n    * scenario.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MDk2Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395750967", "body": "you are calling createFile() enough in these tests it makes sense to factor out into it own method", "bodyText": "you are calling createFile() enough in these tests it makes sense to factor out into it own method", "bodyHTML": "<p dir=\"auto\">you are calling createFile() enough in these tests it makes sense to factor out into it own method</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:26:14Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -157,44 +192,29 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n \n       //Test for shrinking Queue 2 times\n       assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().queueShrink);\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n \n-    } finally {\n-      if (outForOneOp != null) {\n-        outForOneOp.close();\n-      }\n     }\n \n-    AbfsOutputStream outForLargeOps = null;\n-\n-    try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n-          statistics, true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n \n-      int largeValue = 1000;\n-      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n-      // give 2000 QueueShrink calls\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n-        //Flush is quite expensive so 1000 calls only which takes 1 min+\n         outForLargeOps.flush();\n       }\n \n-      //Test for 2000 queue shrink calls\n+      //Test for 20 queue shrink calls\n       assertValues(\"number of queueShrink() Calls\",\n           2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().queueShrink);\n-    } finally {\n-      if (outForLargeOps != null) {\n-        outForLargeOps.close();\n-      }\n+          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * Test to check number of {@code writeCurrentBufferToService()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -176,46 +180,52 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n \n-      //Test for shrinking Queue zero time\n-      assertValues(\"number of queueShrink() Calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outStream is flushed\n+      // Queue is shrunk 2 times when outputStream is flushed.\n       outForOneOp.flush();\n \n-      //Test for shrinking Queue 2 times\n-      assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n \n     try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n-\n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         outForLargeOps.flush();\n       }\n \n-      //Test for 20 queue shrink calls\n-      assertValues(\"number of queueShrink() Calls\",\n-          2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@code writeCurrentBufferToService()}\n-   * calls.\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n    * scenario.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTQ3MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751470", "body": "@code", "bodyText": "@code", "bodyHTML": "<p dir=\"auto\"><a class=\"user-mention\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/code/hovercard\" href=\"https://github.com/code\">@code</a></p>", "author": "steveloughran", "createdAt": "2020-03-20T16:27:00Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n+          statistics, true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 1000;\n+      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n+      // give 2000 QueueShrink calls\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        //Flush is quite expensive so 1000 calls only which takes 1 min+\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 2000 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().queueShrink);\n+    } finally {\n+      if (outForLargeOps != null) {\n+        outForLargeOps.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@codes writeCurrentBufferToService()}", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -157,44 +192,29 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n \n       //Test for shrinking Queue 2 times\n       assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().queueShrink);\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n \n-    } finally {\n-      if (outForOneOp != null) {\n-        outForOneOp.close();\n-      }\n     }\n \n-    AbfsOutputStream outForLargeOps = null;\n-\n-    try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n-          statistics, true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n \n-      int largeValue = 1000;\n-      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n-      // give 2000 QueueShrink calls\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n-        //Flush is quite expensive so 1000 calls only which takes 1 min+\n         outForLargeOps.flush();\n       }\n \n-      //Test for 2000 queue shrink calls\n+      //Test for 20 queue shrink calls\n       assertValues(\"number of queueShrink() Calls\",\n           2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().queueShrink);\n-    } finally {\n-      if (outForLargeOps != null) {\n-        outForLargeOps.close();\n-      }\n+          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * Test to check number of {@code writeCurrentBufferToService()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -176,46 +180,52 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n \n-      //Test for shrinking Queue zero time\n-      assertValues(\"number of queueShrink() Calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outStream is flushed\n+      // Queue is shrunk 2 times when outputStream is flushed.\n       outForOneOp.flush();\n \n-      //Test for shrinking Queue 2 times\n-      assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n \n     try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n-\n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         outForLargeOps.flush();\n       }\n \n-      //Test for 20 queue shrink calls\n-      assertValues(\"number of queueShrink() Calls\",\n-          2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@code writeCurrentBufferToService()}\n-   * calls.\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n    * scenario.\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTc1MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751750", "body": "try-with-resources or IOUtils.closeQuietly", "bodyText": "try-with-resources or IOUtils.closeQuietly", "bodyHTML": "<p dir=\"auto\">try-with-resources or IOUtils.closeQuietly</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:27:22Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n+          statistics, true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 1000;\n+      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n+      // give 2000 QueueShrink calls\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        //Flush is quite expensive so 1000 calls only which takes 1 min+\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 2000 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().queueShrink);\n+    } finally {\n+      if (outForLargeOps != null) {\n+        outForLargeOps.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testWriteBuffer = \"Buffer\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -207,61 +227,58 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n     describe(\"Testing writeCurrentBufferToService() calls\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testWriteBuffer = \"Buffer\";\n \n-    AbfsOutputStream outForOneOp = null;\n-\n-    try {\n-      outForOneOp =\n-          (AbfsOutputStream) abfss.createFile(writeBufferFilePath, statistics,\n-              true,\n-              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n \n       //Test for zero time writing Buffer to service\n       assertValues(\"number writeCurrentBufferToService() calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n \n       outForOneOp.write(testWriteBuffer.getBytes());\n       outForOneOp.flush();\n \n       //Test for one time writeCurrentBuffer() call\n       assertValues(\"number writeCurrentBufferToService() calls\", 1,\n-          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n-    } finally {\n-      if (outForOneOp != null) {\n-        outForOneOp.close();\n-      }\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n     }\n \n-    AbfsOutputStream outForLargeOps = null;\n-    try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(writeBufferFilePath,\n-          statistics, true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n \n-      int largeValue = 1000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testWriteBuffer.getBytes());\n-\n-        //Flush is quite expensive so taking 1000 calls only which takes 1-3\n-        // min per test\n         outForLargeOps.flush();\n       }\n-      //Test for 1000 writeBufferOperations\n+      //Test for 10 writeBufferOperations\n       assertValues(\"number of writeCurrentBufferToService() calls\", largeValue,\n           outForLargeOps\n-              .getOutputStreamStatistics().writeCurrentBufferOperations);\n-    } finally {\n-      if (outForLargeOps != null) {\n-        outForLargeOps.close();\n-      }\n+              .getOutputStreamStatistics().getWriteCurrentBufferOperations());\n     }\n \n   }\n \n+  /**\n+   * Generic create File and setting OutputStreamFlush to false.\n+   *\n+   * @param fs   AzureBlobFileSystem that is initialised in the test\n+   * @param path Path of the file to be created\n+   * @return AbfsOutputStream for writing\n+   * @throws AzureBlobFileSystemException\n+   */\n+  private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n+      Path path) throws AzureBlobFileSystemException {\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+\n+    return (AbfsOutputStream) abfss.createFile(path, fs.getFsStatistics(),\n+        true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+  }\n+\n   /**\n    * Generic assert method.\n    *\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -279,16 +293,4 @@ private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n         true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n   }\n \n-  /**\n-   * Generic assert method.\n-   *\n-   * @param operation     operation being asserted\n-   * @param expectedValue value that is expected\n-   * @param actualValue   value that is actual\n-   */\n-  private void assertValues(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n-  }\n-\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTg3MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751870", "body": "try-with-resources or IOUtils.closeQuietly", "bodyText": "try-with-resources or IOUtils.closeQuietly", "bodyHTML": "<p dir=\"auto\">try-with-resources or IOUtils.closeQuietly</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:27:35Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n+          statistics, true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 1000;\n+      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n+      // give 2000 QueueShrink calls\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        //Flush is quite expensive so 1000 calls only which takes 1 min+\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 2000 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().queueShrink);\n+    } finally {\n+      if (outForLargeOps != null) {\n+        outForLargeOps.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testWriteBuffer = \"Buffer\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(writeBufferFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero time writing Buffer to service\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n+\n+      outForOneOp.write(testWriteBuffer.getBytes());\n+      outForOneOp.flush();\n+\n+      //Test for one time writeCurrentBuffer() call\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+    try {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -207,61 +227,58 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n     describe(\"Testing writeCurrentBufferToService() calls\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testWriteBuffer = \"Buffer\";\n \n-    AbfsOutputStream outForOneOp = null;\n-\n-    try {\n-      outForOneOp =\n-          (AbfsOutputStream) abfss.createFile(writeBufferFilePath, statistics,\n-              true,\n-              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n \n       //Test for zero time writing Buffer to service\n       assertValues(\"number writeCurrentBufferToService() calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n \n       outForOneOp.write(testWriteBuffer.getBytes());\n       outForOneOp.flush();\n \n       //Test for one time writeCurrentBuffer() call\n       assertValues(\"number writeCurrentBufferToService() calls\", 1,\n-          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n-    } finally {\n-      if (outForOneOp != null) {\n-        outForOneOp.close();\n-      }\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n     }\n \n-    AbfsOutputStream outForLargeOps = null;\n-    try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(writeBufferFilePath,\n-          statistics, true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n \n-      int largeValue = 1000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testWriteBuffer.getBytes());\n-\n-        //Flush is quite expensive so taking 1000 calls only which takes 1-3\n-        // min per test\n         outForLargeOps.flush();\n       }\n-      //Test for 1000 writeBufferOperations\n+      //Test for 10 writeBufferOperations\n       assertValues(\"number of writeCurrentBufferToService() calls\", largeValue,\n           outForLargeOps\n-              .getOutputStreamStatistics().writeCurrentBufferOperations);\n-    } finally {\n-      if (outForLargeOps != null) {\n-        outForLargeOps.close();\n-      }\n+              .getOutputStreamStatistics().getWriteCurrentBufferOperations());\n     }\n \n   }\n \n+  /**\n+   * Generic create File and setting OutputStreamFlush to false.\n+   *\n+   * @param fs   AzureBlobFileSystem that is initialised in the test\n+   * @param path Path of the file to be created\n+   * @return AbfsOutputStream for writing\n+   * @throws AzureBlobFileSystemException\n+   */\n+  private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n+      Path path) throws AzureBlobFileSystemException {\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+\n+    return (AbfsOutputStream) abfss.createFile(path, fs.getFsStatistics(),\n+        true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+  }\n+\n   /**\n    * Generic assert method.\n    *\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 65%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 0c82a2c065e..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -279,16 +293,4 @@ private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n         true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n   }\n \n-  /**\n-   * Generic assert method.\n-   *\n-   * @param operation     operation being asserted\n-   * @param expectedValue value that is expected\n-   * @param actualValue   value that is actual\n-   */\n-  private void assertValues(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n-  }\n-\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MjYwOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395752609", "body": "This is sounds like a slow test.\n\n1. Use smaller values than 1000, e.g. \"10\"\n2. make the value a constant used across all tests. ", "bodyText": "This is sounds like a slow test.\n\nUse smaller values than 1000, e.g. \"10\"\nmake the value a constant used across all tests.", "bodyHTML": "<p dir=\"auto\">This is sounds like a slow test.</p>\n<ol dir=\"auto\">\n<li>Use smaller values than 1000, e.g. \"10\"</li>\n<li>make the value a constant used across all tests.</li>\n</ol>", "author": "steveloughran", "createdAt": "2020-03-20T16:28:41Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n", "next_change": {"commit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 0c82a2c065e..6c29ef9dc06 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n", "chunk": "@@ -36,9 +36,9 @@\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n-  private static int LARGE_OPERATIONS = 10;\n-  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n-  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1Mjk0Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395752947", "body": "not needed", "bodyText": "not needed", "bodyHTML": "<p dir=\"auto\">not needed</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:29:12Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg4NDg2MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r396884860", "bodyText": "I think constructor is needed to handle Exception ?", "author": "mehakmeet", "createdAt": "2020-03-24T03:34:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1Mjk0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -18,13 +18,15 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import org.junit.Assert;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.FSDataInputStream;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n \n /**\n  * Test Abfs Stream.\n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -34,6 +36,11 @@\n   public ITestAbfsStreamStatistics() throws Exception {\n   }\n \n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ITestAbfsStreamStatistics.class);\n+\n+  private static final int LARGE_NUMBER_OF_OPS = 999999;\n+\n   /***\n    * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n    * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MzIwNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395753205", "body": "IOUtils.closeQuietly", "bodyText": "IOUtils.closeQuietly", "bodyHTML": "<p dir=\"auto\">IOUtils.closeQuietly</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:29:38Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -68,24 +75,29 @@ public void testAbfsStreamOps() throws Exception {\n       //Test for a single write operation\n       assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n \n+      //Flushing output stream to see content to read\n+      outForOneOperation.hflush();\n       inForOneOperation = fs.open(smallOperationsFile);\n-      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+      statistics.reset();\n+      int result = inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n           testReadWriteOps.getBytes().length);\n \n-      //Test for a single read operation\n-      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+      LOG.info(\"Result of Read operation : {}\", result);\n+      /*\n+      Testing if 2 read_ops value is coming after reading full content from a\n+      file (3 if anything to read from Buffer too).\n+      Reason: read() call gives read_ops=1,\n+      reading from AbfsClient(http GET) gives read_ops=2.\n+       */\n+      assertReadWriteOps(\"read\", 2, statistics.getReadOps());\n \n     } finally {\n-      if (inForOneOperation != null) {\n-        inForOneOperation.close();\n-      }\n-      if (outForOneOperation != null) {\n-        outForOneOperation.close();\n-      }\n+      IOUtils.cleanupWithLogger(LOG, inForOneOperation,\n+          outForOneOperation);\n     }\n \n     //Validating if content is being written in the smallOperationsFile\n-    Assert.assertTrue(\"Mismatch in content validation\",\n+    assertTrue(\"Mismatch in content validation\",\n         validateContent(fs, smallOperationsFile,\n             testReadWriteOps.getBytes()));\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MzQ0Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395753442", "body": "once validateContent raises exceptions, you don't need to wrap in an assert", "bodyText": "once validateContent raises exceptions, you don't need to wrap in an assert", "bodyHTML": "<p dir=\"auto\">once validateContent raises exceptions, you don't need to wrap in an assert</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:29:59Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {\n+        inForOneOperation.close();\n+      }\n+      if (outForOneOperation != null) {\n+        outForOneOperation.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in the smallOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -68,24 +75,29 @@ public void testAbfsStreamOps() throws Exception {\n       //Test for a single write operation\n       assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n \n+      //Flushing output stream to see content to read\n+      outForOneOperation.hflush();\n       inForOneOperation = fs.open(smallOperationsFile);\n-      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+      statistics.reset();\n+      int result = inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n           testReadWriteOps.getBytes().length);\n \n-      //Test for a single read operation\n-      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+      LOG.info(\"Result of Read operation : {}\", result);\n+      /*\n+      Testing if 2 read_ops value is coming after reading full content from a\n+      file (3 if anything to read from Buffer too).\n+      Reason: read() call gives read_ops=1,\n+      reading from AbfsClient(http GET) gives read_ops=2.\n+       */\n+      assertReadWriteOps(\"read\", 2, statistics.getReadOps());\n \n     } finally {\n-      if (inForOneOperation != null) {\n-        inForOneOperation.close();\n-      }\n-      if (outForOneOperation != null) {\n-        outForOneOperation.close();\n-      }\n+      IOUtils.cleanupWithLogger(LOG, inForOneOperation,\n+          outForOneOperation);\n     }\n \n     //Validating if content is being written in the smallOperationsFile\n-    Assert.assertTrue(\"Mismatch in content validation\",\n+    assertTrue(\"Mismatch in content validation\",\n         validateContent(fs, smallOperationsFile,\n             testReadWriteOps.getBytes()));\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MzgyMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395753822", "body": "IOUtils.closeQuietly", "bodyText": "IOUtils.closeQuietly", "bodyHTML": "<p dir=\"auto\">IOUtils.closeQuietly</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:30:33Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {\n+        inForOneOperation.close();\n+      }\n+      if (outForOneOperation != null) {\n+        outForOneOperation.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in the smallOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",\n+        validateContent(fs, smallOperationsFile,\n+            testReadWriteOps.getBytes()));\n+\n+    FSDataOutputStream outForLargeOperations = null;\n+    FSDataInputStream inForLargeOperations = null;\n+    StringBuilder largeOperationsValidationString = new StringBuilder();\n+    try {\n+      outForLargeOperations = fs.create(largeOperationsFile);\n+      statistics.reset();\n+      int largeValue = 1000000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOperations.write(testReadWriteOps.getBytes());\n+\n+        //Creating the String for content Validation\n+        largeOperationsValidationString.append(testReadWriteOps);\n+      }\n+\n+      //Test for 1000000 write operations\n+      assertReadWriteOps(\"write\", largeValue, statistics.getWriteOps());\n+\n+      inForLargeOperations = fs.open(largeOperationsFile);\n+      for (int i = 0; i < largeValue; i++)\n+        inForLargeOperations\n+            .read(testReadWriteOps.getBytes(), 0,\n+                testReadWriteOps.getBytes().length);\n+\n+      //Test for 1000000 read operations\n+      assertReadWriteOps(\"read\", largeValue, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForLargeOperations != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -95,37 +107,35 @@ public void testAbfsStreamOps() throws Exception {\n     try {\n       outForLargeOperations = fs.create(largeOperationsFile);\n       statistics.reset();\n-      int largeValue = 1000000;\n+      int largeValue = LARGE_NUMBER_OF_OPS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOperations.write(testReadWriteOps.getBytes());\n \n         //Creating the String for content Validation\n         largeOperationsValidationString.append(testReadWriteOps);\n       }\n+      LOG.info(\"Number of bytes of Large data written: {}\",\n+          largeOperationsValidationString.toString().getBytes().length);\n \n       //Test for 1000000 write operations\n       assertReadWriteOps(\"write\", largeValue, statistics.getWriteOps());\n \n       inForLargeOperations = fs.open(largeOperationsFile);\n-      for (int i = 0; i < largeValue; i++)\n+      for (int i = 0; i < largeValue; i++) {\n         inForLargeOperations\n             .read(testReadWriteOps.getBytes(), 0,\n                 testReadWriteOps.getBytes().length);\n+      }\n \n       //Test for 1000000 read operations\n       assertReadWriteOps(\"read\", largeValue, statistics.getReadOps());\n \n     } finally {\n-      if (inForLargeOperations != null) {\n-        inForLargeOperations.close();\n-      }\n-      if (outForLargeOperations != null) {\n-        outForLargeOperations.close();\n-      }\n+      IOUtils.cleanupWithLogger(LOG, inForLargeOperations,\n+          outForLargeOperations);\n     }\n-\n     //Validating if content is being written in largeOperationsFile\n-    Assert.assertTrue(\"Mismatch in content validation\",\n+    assertTrue(\"Mismatch in content validation\",\n         validateContent(fs, largeOperationsFile,\n             largeOperationsValidationString.toString().getBytes()));\n \n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex b749f496bbf..e057c022e63 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,18 +140,4 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n-\n-  /**\n-   * Generic method to assert both Read an write operations.\n-   *\n-   * @param operation     what operation is being asserted\n-   * @param expectedValue value which is expected\n-   * @param actualValue   value which is actual\n-   */\n-\n-  private void assertReadWriteOps(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n-        actualValue);\n-  }\n }\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex e057c022e63..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,4 +140,18 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n+\n+  /**\n+   * Generic method to assert both Read an write operations.\n+   *\n+   * @param operation     what operation is being asserted\n+   * @param expectedValue value which is expected\n+   * @param actualValue   value which is actual\n+   */\n+\n+  private void assertReadWriteOps(String operation, long expectedValue,\n+      long actualValue) {\n+    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n+        actualValue);\n+  }\n }\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex b749f496bbf..e057c022e63 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,18 +140,4 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n-\n-  /**\n-   * Generic method to assert both Read an write operations.\n-   *\n-   * @param operation     what operation is being asserted\n-   * @param expectedValue value which is expected\n-   * @param actualValue   value which is actual\n-   */\n-\n-  private void assertReadWriteOps(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n-        actualValue);\n-  }\n }\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex e057c022e63..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,4 +140,18 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n+\n+  /**\n+   * Generic method to assert both Read an write operations.\n+   *\n+   * @param operation     what operation is being asserted\n+   * @param expectedValue value which is expected\n+   * @param actualValue   value which is actual\n+   */\n+\n+  private void assertReadWriteOps(String operation, long expectedValue,\n+      long actualValue) {\n+    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n+        actualValue);\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NDEwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395754102", "body": "again, superflous with validateContent raising exceptions", "bodyText": "again, superflous with validateContent raising exceptions", "bodyHTML": "<p dir=\"auto\">again, superflous with validateContent raising exceptions</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:31:01Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {\n+        inForOneOperation.close();\n+      }\n+      if (outForOneOperation != null) {\n+        outForOneOperation.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in the smallOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",\n+        validateContent(fs, smallOperationsFile,\n+            testReadWriteOps.getBytes()));\n+\n+    FSDataOutputStream outForLargeOperations = null;\n+    FSDataInputStream inForLargeOperations = null;\n+    StringBuilder largeOperationsValidationString = new StringBuilder();\n+    try {\n+      outForLargeOperations = fs.create(largeOperationsFile);\n+      statistics.reset();\n+      int largeValue = 1000000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOperations.write(testReadWriteOps.getBytes());\n+\n+        //Creating the String for content Validation\n+        largeOperationsValidationString.append(testReadWriteOps);\n+      }\n+\n+      //Test for 1000000 write operations\n+      assertReadWriteOps(\"write\", largeValue, statistics.getWriteOps());\n+\n+      inForLargeOperations = fs.open(largeOperationsFile);\n+      for (int i = 0; i < largeValue; i++)\n+        inForLargeOperations\n+            .read(testReadWriteOps.getBytes(), 0,\n+                testReadWriteOps.getBytes().length);\n+\n+      //Test for 1000000 read operations\n+      assertReadWriteOps(\"read\", largeValue, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForLargeOperations != null) {\n+        inForLargeOperations.close();\n+      }\n+      if (outForLargeOperations != null) {\n+        outForLargeOperations.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in largeOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -95,37 +107,35 @@ public void testAbfsStreamOps() throws Exception {\n     try {\n       outForLargeOperations = fs.create(largeOperationsFile);\n       statistics.reset();\n-      int largeValue = 1000000;\n+      int largeValue = LARGE_NUMBER_OF_OPS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeOperations.write(testReadWriteOps.getBytes());\n \n         //Creating the String for content Validation\n         largeOperationsValidationString.append(testReadWriteOps);\n       }\n+      LOG.info(\"Number of bytes of Large data written: {}\",\n+          largeOperationsValidationString.toString().getBytes().length);\n \n       //Test for 1000000 write operations\n       assertReadWriteOps(\"write\", largeValue, statistics.getWriteOps());\n \n       inForLargeOperations = fs.open(largeOperationsFile);\n-      for (int i = 0; i < largeValue; i++)\n+      for (int i = 0; i < largeValue; i++) {\n         inForLargeOperations\n             .read(testReadWriteOps.getBytes(), 0,\n                 testReadWriteOps.getBytes().length);\n+      }\n \n       //Test for 1000000 read operations\n       assertReadWriteOps(\"read\", largeValue, statistics.getReadOps());\n \n     } finally {\n-      if (inForLargeOperations != null) {\n-        inForLargeOperations.close();\n-      }\n-      if (outForLargeOperations != null) {\n-        outForLargeOperations.close();\n-      }\n+      IOUtils.cleanupWithLogger(LOG, inForLargeOperations,\n+          outForLargeOperations);\n     }\n-\n     //Validating if content is being written in largeOperationsFile\n-    Assert.assertTrue(\"Mismatch in content validation\",\n+    assertTrue(\"Mismatch in content validation\",\n         validateContent(fs, largeOperationsFile,\n             largeOperationsValidationString.toString().getBytes()));\n \n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex b749f496bbf..e057c022e63 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,18 +140,4 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n-\n-  /**\n-   * Generic method to assert both Read an write operations.\n-   *\n-   * @param operation     what operation is being asserted\n-   * @param expectedValue value which is expected\n-   * @param actualValue   value which is actual\n-   */\n-\n-  private void assertReadWriteOps(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n-        actualValue);\n-  }\n }\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex e057c022e63..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,4 +140,18 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n+\n+  /**\n+   * Generic method to assert both Read an write operations.\n+   *\n+   * @param operation     what operation is being asserted\n+   * @param expectedValue value which is expected\n+   * @param actualValue   value which is actual\n+   */\n+\n+  private void assertReadWriteOps(String operation, long expectedValue,\n+      long actualValue) {\n+    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n+        actualValue);\n+  }\n }\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex b749f496bbf..e057c022e63 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,18 +140,4 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n-\n-  /**\n-   * Generic method to assert both Read an write operations.\n-   *\n-   * @param operation     what operation is being asserted\n-   * @param expectedValue value which is expected\n-   * @param actualValue   value which is actual\n-   */\n-\n-  private void assertReadWriteOps(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n-        actualValue);\n-  }\n }\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex e057c022e63..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n", "chunk": "@@ -140,4 +140,18 @@ reading from AbfsClient(http GET) gives read_ops=2.\n             largeOperationsValidationString.toString().getBytes()));\n \n   }\n+\n+  /**\n+   * Generic method to assert both Read an write operations.\n+   *\n+   * @param operation     what operation is being asserted\n+   * @param expectedValue value which is expected\n+   * @param actualValue   value which is actual\n+   */\n+\n+  private void assertReadWriteOps(String operation, long expectedValue,\n+      long actualValue) {\n+    assertEquals(\"Mismatch in \" + operation + \" operations\", expectedValue,\n+        actualValue);\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NDUxOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395754519", "body": "add a .close(), even if the original code didn't. Always good to improve a test", "bodyText": "add a .close(), even if the original code didn't. Always good to improve a test", "bodyHTML": "<p dir=\"auto\">add a .close(), even if the original code didn't. Always good to improve a test</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:31:42Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java", "diffHunk": "@@ -143,7 +143,7 @@ public void testBlobDataReader() throws Exception {\n \n     // TEST WRITE FILE\n     try {\n-      abfsStore.openFileForWrite(EXISTED_FILE_PATH, true);\n+      abfsStore.openFileForWrite(EXISTED_FILE_PATH, fs.getFsStatistics(), true);", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java\nindex 5016609676d..e517f685784 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java\n", "chunk": "@@ -146,6 +151,8 @@ public void testBlobDataReader() throws Exception {\n       abfsStore.openFileForWrite(EXISTED_FILE_PATH, fs.getFsStatistics(), true);\n     } catch (AbfsRestOperationException e) {\n       assertEquals(AzureServiceErrorCode.AUTHORIZATION_PERMISSION_MISS_MATCH, e.getErrorCode());\n+    } finally {\n+      IOUtils.cleanupWithLogger(LOG, abfsStore);\n     }\n \n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NTM4MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395755381", "body": "let's make these private and have getters", "bodyText": "let's make these private and have getters", "bodyHTML": "<p dir=\"auto\">let's make these private and have getters</p>", "author": "steveloughran", "createdAt": "2020-03-20T16:33:05Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -9,19 +27,19 @@\n  * data.\n  *\n  * WriteCurrentBufferOperations - Number of times\n- * {@codes writeCurrentBufferToService()} calls were made.\n+ * {@code writeCurrentBufferToService()} calls were made.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n-  public volatile long bytesToUpload;\n-  public volatile long bytesUploadSuccessful;\n-  public volatile long bytesUploadFailed;\n-  public volatile long timeSpendOnTaskWait;\n-  public volatile long queueShrink;\n-  public volatile long writeCurrentBufferOperations;\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n \n   /**\n-   * Number of bytes uploaded only when bytes passed are positive.\n+   * Number of bytes uploaded.\n    *\n    * @param bytes negative values are ignored\n    */\n", "next_change": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -39,9 +42,10 @@\n   private volatile long writeCurrentBufferOperations;\n \n   /**\n-   * Number of bytes uploaded.\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n    *\n-   * @param bytes negative values are ignored\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -19,33 +19,37 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n-\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n   /**\n-   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n-   * Blocking Queue in AbfsOutputStream.\n-   *\n-   * queueShrink - Number of times Blocking Queue was shrunk after writing\n-   * data.\n-   *\n-   * WriteCurrentBufferOperations - Number of times the current buffer which\n-   * was written has been forwarded to the service.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n+   */\n+  private long timeSpentOnTaskWait;\n+  /**\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n-  private volatile long bytesToUpload;\n-  private volatile long bytesUploadSuccessful;\n-  private volatile long bytesUploadFailed;\n-  private volatile long timeSpendOnTaskWait;\n-  private volatile long queueShrink;\n-  private volatile long writeCurrentBufferOperations;\n+  private long writeCurrentBufferOperations;\n \n   /**\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}]}}]}}, {"oid": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "url": "https://github.com/apache/hadoop/commit/0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "message": "HADOOP-16914. Fixing review comments", "committedDate": "2020-04-01T10:20:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NTE3Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402095177", "body": "explain more", "bodyText": "explain more", "bodyHTML": "<p dir=\"auto\">explain more</p>", "author": "mehakmeet", "createdAt": "2020-04-02T07:07:42Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Records a successful upload and the number of bytes uploaded.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  void uploadSuccessful(long bytes);\n+\n+  /**\n+   * Records that upload is failed and the number of bytes.\n+   *\n+   * @param bytes number of bytes that failed to upload\n+   */\n+  void uploadFailed(long bytes);\n+\n+  /**\n+   * Time spent in waiting for tasks to be completed in the blocking Queue.", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex e21628623f6..cbd70ceaa8f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -29,40 +29,41 @@\n   /**\n    * Number of bytes to be uploaded.\n    *\n-   * @param bytes number of bytes to upload\n+   * @param bytes number of bytes to upload.\n    */\n   void bytesToUpload(long bytes);\n \n   /**\n    * Records a successful upload and the number of bytes uploaded.\n    *\n-   * @param bytes number of bytes that were successfully uploaded\n+   * @param bytes number of bytes that were successfully uploaded.\n    */\n   void uploadSuccessful(long bytes);\n \n   /**\n    * Records that upload is failed and the number of bytes.\n    *\n-   * @param bytes number of bytes that failed to upload\n+   * @param bytes number of bytes that failed to upload.\n    */\n   void uploadFailed(long bytes);\n \n   /**\n    * Time spent in waiting for tasks to be completed in the blocking Queue.\n    *\n-   * @param start millisecond at which the wait for task to be complete begins\n-   * @param end   millisecond at which the wait is completed for the task\n+   * @param start millisecond at which the wait for task to be complete begins.\n+   * @param end   millisecond at which the wait is completed for the task.\n    */\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code shrinkWriteOperationQueue()}\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n   void queueShrinked();\n \n   /**\n-   * Number of times {@code writeCurrentBufferToService(boolean, boolean)}\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n    * method was called.\n    */\n   void writeCurrentBuffer();\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex cbd70ceaa8f..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -59,7 +59,7 @@\n    * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n-  void queueShrinked();\n+  void queueShrunk();\n \n   /**\n    * Number of times\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex c9fe0dd4552..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,18 +56,20 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times task queue is shrunk.\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n+   * method was called.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times buffer is written to the service after a write operation.\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n+   * method was called.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a string of all AbfsOutputStream statistics and their\n-   * values.\n+   * Method to form a String of all AbfsOutputStream counters and their values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NTQxNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402095417", "body": "this java doc above variable name", "bodyText": "this java doc above variable name", "bodyHTML": "<p dir=\"auto\">this java doc above variable name</p>", "author": "mehakmeet", "createdAt": "2020-04-02T07:08:12Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -20,17 +20,20 @@\n \n /**\n  * OutputStream Statistics Implementation for Abfs.\n- * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n- * Blocking Queue in AbfsOutputStream.\n- *\n- * queueShrink - Number of times Blocking Queue was shrunk after writing\n- * data.\n- *\n- * WriteCurrentBufferOperations - Number of times\n- * {@code writeCurrentBufferToService()} calls were made.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -23,22 +23,28 @@\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n-\n-  /**\n-   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n-   * Blocking Queue in AbfsOutputStream.\n-   *\n-   * queueShrink - Number of times Blocking Queue was shrunk after writing\n-   * data.\n-   *\n-   * WriteCurrentBufferOperations - Number of times the current buffer which\n-   * was written has been forwarded to the service.\n-   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n   private volatile long timeSpendOnTaskWait;\n-  private volatile long queueShrink;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private volatile long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n   private volatile long writeCurrentBufferOperations;\n \n   /**\n", "next_change": {"commit": "a667ab0820443fde451225be1f628f7f451005da", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 6c06cf0e35b..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -45,7 +45,7 @@\n    * Data store by\n    * AbfsResOperation.\n    */\n-  private volatile long writeCurrentBufferOperations;\n+  private long writeCurrentBufferOperations;\n \n   /**\n    * Records the need to upload bytes and increments the total bytes that\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3MDkyMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402070920", "body": "We should be defining here using the interface not concrete class and initialising it in constructor with concrete class implementation. That whole point of using interface is we can change add the new implementation in future and change the the implementation to be used in constructor using some configuration. Right @steveloughran?", "bodyText": "We should be defining here using the interface not concrete class and initialising it in constructor with concrete class implementation. That whole point of using interface is we can change add the new implementation in future and change the the implementation to be used in constructor using some configuration. Right @steveloughran?", "bodyHTML": "<p dir=\"auto\">We should be defining here using the interface not concrete class and initialising it in constructor with concrete class implementation. That whole point of using interface is we can change add the new implementation in future and change the the implementation to be used in constructor using some configuration. Right <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/steveloughran/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/steveloughran\">@steveloughran</a>?</p>", "author": "mukund-thakur", "createdAt": "2020-04-02T06:07:07Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -80,6 +82,7 @@\n           = new ElasticByteBufferPool();\n \n   private final Statistics statistics;\n+  private final AbfsOutputStreamStatisticsImpl outputStreamStatistics;", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA2MDIxNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404060217", "bodyText": "yes. Use the interface in reference/args and pass the instance in", "author": "steveloughran", "createdAt": "2020-04-06T12:43:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3MDkyMA=="}], "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 1bd17193594..64a0aaa783c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -82,7 +82,7 @@\n           = new ElasticByteBufferPool();\n \n   private final Statistics statistics;\n-  private final AbfsOutputStreamStatisticsImpl outputStreamStatistics;\n+  private final AbfsOutputStreamStatistics outputStreamStatistics;\n \n   public AbfsOutputStream(\n       final AbfsClient client,\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 64a0aaa783c..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -84,6 +85,9 @@\n   private final Statistics statistics;\n   private final AbfsOutputStreamStatistics outputStreamStatistics;\n \n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(AbfsOutputStream.class);\n+\n   public AbfsOutputStream(\n       final AbfsClient client,\n       final Statistics statistics,\n", "next_change": {"commit": "f0543e1bd0d994b6f284c825fffffe92ddd06218", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6974db92557..3863752ec04 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -89,23 +89,22 @@\n       LoggerFactory.getLogger(AbfsOutputStream.class);\n \n   public AbfsOutputStream(\n-      final AbfsClient client,\n-      final Statistics statistics,\n-      final String path,\n-      final long position,\n-      final int bufferSize,\n-      final boolean supportFlush,\n-      final boolean disableOutputStreamFlush) {\n+          final AbfsClient client,\n+          final Statistics statistics,\n+          final String path,\n+          final long position,\n+          AbfsOutputStreamContext abfsOutputStreamContext) {\n     this.client = client;\n     this.statistics = statistics;\n     this.path = path;\n     this.position = position;\n     this.closed = false;\n-    this.supportFlush = supportFlush;\n-    this.disableOutputStreamFlush = disableOutputStreamFlush;\n+    this.supportFlush = abfsOutputStreamContext.isEnableFlush();\n+    this.disableOutputStreamFlush = abfsOutputStreamContext\n+            .isDisableOutputStreamFlush();\n     this.lastError = null;\n     this.lastFlushOffset = 0;\n-    this.bufferSize = bufferSize;\n+    this.bufferSize = abfsOutputStreamContext.getWriteBufferSize();\n     this.buffer = byteBufferPool.getBuffer(false, bufferSize).array();\n     this.bufferIndex = 0;\n     this.writeOperations = new ConcurrentLinkedDeque<>();\n", "next_change": {"commit": "424bb884bd9e96b3893075bcd8ef4158f4f8187b", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 3863752ec04..4297b18651b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -108,7 +108,7 @@ public AbfsOutputStream(\n     this.buffer = byteBufferPool.getBuffer(false, bufferSize).array();\n     this.bufferIndex = 0;\n     this.writeOperations = new ConcurrentLinkedDeque<>();\n-    this.outputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+    this.outputStreamStatistics = abfsOutputStreamContext.getStreamStatistics();\n \n     this.maxConcurrentRequestCount = 4 * Runtime.getRuntime().availableProcessors();\n \n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3MzE2Mw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402073163", "body": "Add trailing . in the end for all java docs.", "bodyText": "Add trailing . in the end for all java docs.", "bodyHTML": "<p dir=\"auto\">Add trailing . in the end for all java docs.</p>", "author": "mukund-thakur", "createdAt": "2020-04-02T06:13:22Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex e21628623f6..cbd70ceaa8f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -29,40 +29,41 @@\n   /**\n    * Number of bytes to be uploaded.\n    *\n-   * @param bytes number of bytes to upload\n+   * @param bytes number of bytes to upload.\n    */\n   void bytesToUpload(long bytes);\n \n   /**\n    * Records a successful upload and the number of bytes uploaded.\n    *\n-   * @param bytes number of bytes that were successfully uploaded\n+   * @param bytes number of bytes that were successfully uploaded.\n    */\n   void uploadSuccessful(long bytes);\n \n   /**\n    * Records that upload is failed and the number of bytes.\n    *\n-   * @param bytes number of bytes that failed to upload\n+   * @param bytes number of bytes that failed to upload.\n    */\n   void uploadFailed(long bytes);\n \n   /**\n    * Time spent in waiting for tasks to be completed in the blocking Queue.\n    *\n-   * @param start millisecond at which the wait for task to be complete begins\n-   * @param end   millisecond at which the wait is completed for the task\n+   * @param start millisecond at which the wait for task to be complete begins.\n+   * @param end   millisecond at which the wait is completed for the task.\n    */\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code shrinkWriteOperationQueue()}\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n   void queueShrinked();\n \n   /**\n-   * Number of times {@code writeCurrentBufferToService(boolean, boolean)}\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n    * method was called.\n    */\n   void writeCurrentBuffer();\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex cbd70ceaa8f..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -59,7 +59,7 @@\n    * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n-  void queueShrinked();\n+  void queueShrunk();\n \n   /**\n    * Number of times\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex c9fe0dd4552..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,18 +56,20 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times task queue is shrunk.\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n+   * method was called.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times buffer is written to the service after a write operation.\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n+   * method was called.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a string of all AbfsOutputStream statistics and their\n-   * values.\n+   * Method to form a String of all AbfsOutputStream counters and their values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3NTc4NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402075785", "body": "Write full method in javadoc like AbfsOutputStream#waitForTaskToComplete() otherwise people will have to figure out where this method actually is.", "bodyText": "Write full method in javadoc like AbfsOutputStream#waitForTaskToComplete() otherwise people will have to figure out where this method actually is.", "bodyHTML": "<p dir=\"auto\">Write full method in javadoc like AbfsOutputStream#waitForTaskToComplete() otherwise people will have to figure out where this method actually is.</p>", "author": "mukund-thakur", "createdAt": "2020-04-02T06:21:04Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload failed and the number of bytes.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spent for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@code waitForTaskToComplete()}", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -74,10 +80,21 @@ public void uploadFailed(long bytes) {\n   }\n \n   /**\n-   * Time spent for waiting a task to be completed.\n+   * {@inheritDoc}\n+   *\n+   * Records the total time spent waiting for a task.\n+   * When the thread executor has a task\n+   * queue{@link java.util.concurrent.BlockingQueue} of size greater than or equal to 2\n+   * times the maxConcurrentRequestCounts then, it waits for a task in that\n+   * queue to finish, then do the next task in the queue.\n    *\n-   * @param startTime on calling {@code waitForTaskToComplete()}\n-   * @param endTime   on method completing\n+   * This time spent while waiting for the task to be completed is being\n+   * recorded in this counter.\n+   *\n+   * @param startTime time(in milliseconds) before the wait for task to be\n+   *                  completed is begin.\n+   * @param endTime   time(in milliseconds) after the wait for the task to be\n+   *                  completed is done.\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -98,18 +103,18 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n-   * Records the number of time AbfsOutputStream Try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * Records the number of times AbfsOutputStream try to remove the completed\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n-  public void queueShrinked() {\n-    queueShrink++;\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n   }\n \n   /**\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -103,14 +104,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpentOnTaskWait += endTime - startTime;\n+    timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation task queue.\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3NjU4NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402076584", "body": "What is the task here? Please explain. This is for all javadocs. There is no harm in writing more lines :P", "bodyText": "What is the task here? Please explain. This is for all javadocs. There is no harm in writing more lines :P", "bodyHTML": "<p dir=\"auto\">What is the task here? Please explain. This is for all javadocs. There is no harm in writing more lines :P</p>", "author": "mukund-thakur", "createdAt": "2020-04-02T06:23:09Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload failed and the number of bytes.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spent for waiting a task to be completed.", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -74,10 +80,21 @@ public void uploadFailed(long bytes) {\n   }\n \n   /**\n-   * Time spent for waiting a task to be completed.\n+   * {@inheritDoc}\n+   *\n+   * Records the total time spent waiting for a task.\n+   * When the thread executor has a task\n+   * queue{@link java.util.concurrent.BlockingQueue} of size greater than or equal to 2\n+   * times the maxConcurrentRequestCounts then, it waits for a task in that\n+   * queue to finish, then do the next task in the queue.\n    *\n-   * @param startTime on calling {@code waitForTaskToComplete()}\n-   * @param endTime   on method completing\n+   * This time spent while waiting for the task to be completed is being\n+   * recorded in this counter.\n+   *\n+   * @param startTime time(in milliseconds) before the wait for task to be\n+   *                  completed is begin.\n+   * @param endTime   time(in milliseconds) after the wait for the task to be\n+   *                  completed is done.\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -98,18 +103,18 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n-   * Records the number of time AbfsOutputStream Try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * Records the number of times AbfsOutputStream try to remove the completed\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n-  public void queueShrinked() {\n-    queueShrink++;\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n   }\n \n   /**\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -103,14 +104,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpentOnTaskWait += endTime - startTime;\n+    timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation task queue.\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": null}]}}]}}]}}]}, "revised_code_in_main": null, "commits_in_main": [{"oid": "459eb2ad6d5bc6b21462e728fb334c6e30e14c39", "message": "Merge commit", "committedDate": null}, {"oid": "0a6ddfa145b788c834098b9169ea880eec2b5b82", "committedDate": "2021-01-12 15:48:09 +0000", "message": "HADOOP-17272. ABFS Streams to support IOStatistics API (#2604)"}, {"oid": "52c024cc3aac2571e60e69c7f8b620299aad8e27", "committedDate": "2021-09-15 22:27:28 +0100", "message": "HADOOP-17195. OutOfMemory error while performing hdfs CopyFromLocal to ABFS (#3406)"}, {"oid": "10f3abeae76863222f59ce6b80c508100d07fcfd", "committedDate": "2021-09-15 22:27:49 +0100", "message": "Revert \"HADOOP-17195. OutOfMemory error while performing hdfs CopyFromLocal to ABFS (#3406)\" (#3443)"}, {"oid": "acffe203b8128989a1cde872dc5576c810e5a0f0", "committedDate": "2021-09-21 12:48:06 +0100", "message": "HADOOP-17195. ABFS: OutOfMemory error while uploading huge files (#3446)"}, {"oid": "79e5a7f3e3f798b5000d14f4f74f0d942ba682cf", "committedDate": "2021-10-14 17:43:32 +0900", "message": "HADOOP-17962. Replace Guava VisibleForTesting by Hadoop's own annotation in hadoop-tools modules (#3540)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3Njg5OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402076899", "body": "Once again which queue. How is this metrics important??", "bodyText": "Once again which queue. How is this metrics important??", "bodyHTML": "<p dir=\"auto\">Once again which queue. How is this metrics important??</p>", "author": "mukund-thakur", "createdAt": "2020-04-02T06:23:58Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload failed and the number of bytes.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spent for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@code waitForTaskToComplete()}\n+   * @param endTime   on method completing\n+   */\n+  @Override\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * Number of calls to {@code shrinkWriteOperationQueue()}.\n+   */\n+  @Override\n+  public void queueShrinked() {", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU5MTM3MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404591370", "bodyText": "How is this metrics important??", "author": "mukund-thakur", "createdAt": "2020-04-07T07:24:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3Njg5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU5MTYyNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404591627", "bodyText": "typo in times, small t in try.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:25:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3Njg5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -85,7 +102,10 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   }\n \n   /**\n-   * Number of calls to {@code shrinkWriteOperationQueue()}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrinked() {\n", "next_change": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,12 +110,12 @@ public void timeSpentTaskWait(long startTime, long endTime) {\n   /**\n    * {@inheritDoc}\n    *\n-   * Records the number of time AbfsOutputStream Try to remove the completed\n+   * Records the number of times AbfsOutputStream try to remove the completed\n    * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n-  public void queueShrinked() {\n-    queueShrink++;\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n   }\n \n   /**\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 6c06cf0e35b..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -103,14 +104,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpentOnTaskWait += endTime - startTime;\n+    timeSpendOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation task queue.\n+   * write operations from the beginning of write operation FIFO queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -104,14 +103,14 @@ public void uploadFailed(long bytes) {\n    */\n   @Override\n   public void timeSpentTaskWait(long startTime, long endTime) {\n-    timeSpendOnTaskWait += endTime - startTime;\n+    timeSpentOnTaskWait += endTime - startTime;\n   }\n \n   /**\n    * {@inheritDoc}\n    *\n    * Records the number of times AbfsOutputStream try to remove the completed\n-   * write operations from the beginning of write operation FIFO queue.\n+   * write operations from the beginning of write operation task queue.\n    */\n   @Override\n   public void queueShrunk() {\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -93,7 +113,10 @@ public void queueShrinked() {\n   }\n \n   /**\n-   * Number of calls to {@code writeCurrentBufferToService(boolean, boolean)}.\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream writes the buffer to the\n+   * service via the AbfsClient and appends the buffer to the service.\n    */\n   @Override\n   public void writeCurrentBuffer() {\n", "next_change": null}]}}, {"oid": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "url": "https://github.com/apache/hadoop/commit/c8c660884cb509c835e6e4941acdddfabad2d2fe", "message": "HADOOP-16914. Java Docs", "committedDate": "2020-04-06T11:51:23Z", "type": "forcePushed"}, {"oid": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "url": "https://github.com/apache/hadoop/commit/2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "message": "HADOOP-16914. Java Docs", "committedDate": "2020-04-06T12:03:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU2Mzc3OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404563779", "body": "Change name to ITestAbfsOutputStreamStatictics.", "bodyText": "Change name to ITestAbfsOutputStreamStatictics.", "bodyHTML": "<p dir=\"auto\">Change name to ITestAbfsOutputStreamStatictics.</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T06:26:41Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NzA2Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404587067", "bodyText": "Move the constructor down after the class variables.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:17:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU2Mzc3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NjE5NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404586195", "body": "use path(methodName.getMethodName());. The current code won't create your files under test directory so the cleanup might miss cleaning up them during teardown.", "bodyText": "use path(methodName.getMethodName());. The current code won't create your files under test directory so the cleanup might miss cleaning up them during teardown.", "bodyHTML": "<p dir=\"auto\">use path(methodName.getMethodName());. The current code won't create your files under test directory so the cleanup might miss cleaning up them during teardown.</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:15:25Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwNjAwNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404606007", "bodyText": "Create a new protected method in the base clase to get methode name using\nmethodName.getMethodName()", "author": "mukund-thakur", "createdAt": "2020-04-07T07:49:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NjE5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -49,65 +50,67 @@ public ITestAbfsOutputStream() throws Exception {\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n         uploadBytesFilePath)\n     ) {\n \n-      //Test for zero bytes To upload\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n-      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+      abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for bytes to upload\n+      //Test for bytes to upload.\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          abfsOutputStreamStatistics.getBytesToUpload());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n-      //Test for successful bytes uploaded\n+      //Test for successful bytes uploaded.\n       assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n-          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n-      //Populating random value for bytesFailed\n+      //Populating random value for bytesFailed.\n       int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n-      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      //Test for bytes failed to upload\n+      abfsOutputStreamStatisticsForUploadBytes.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n       assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-          abfsOutputStreamStatistics.getBytesUploadFailed());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadFailed());\n \n     }\n \n     try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n         uploadBytesFilePath)) {\n \n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for bytes to upload\n+      //Test for bytes to upload.\n       assertValues(\"bytes to upload\",\n-          largeValue * (testBytesToUpload.getBytes().length),\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesToUpload());\n \n-      //Test for successful bytes uploaded\n+      //Test for successful bytes uploaded.\n       assertValues(\"successful bytes uploaded\",\n-          largeValue * (testBytesToUpload.getBytes().length),\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesUploadSuccessful());\n \n-      //Populating random values for bytesFailed\n+      //Populating random values for bytesFailed.\n       int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n       abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      //Test for bytes failed to upload\n+      //Test for bytes failed to upload.\n       assertValues(\"bytes failed to upload\", randomBytesFailed,\n           abfsOutputStreamStatistics.getBytesUploadFailed());\n     }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4ODQxNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404588417", "body": "extract in variable utForSomeBytes.getOutputStreamStatistics(). like it is done at L65.", "bodyText": "extract in variable utForSomeBytes.getOutputStreamStatistics(). like it is done at L65.", "bodyHTML": "<p dir=\"auto\">extract in variable utForSomeBytes.getOutputStreamStatistics(). like it is done at L65.</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:19:27Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -49,65 +50,67 @@ public ITestAbfsOutputStream() throws Exception {\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n         uploadBytesFilePath)\n     ) {\n \n-      //Test for zero bytes To upload\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n-      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+      abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for bytes to upload\n+      //Test for bytes to upload.\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          abfsOutputStreamStatistics.getBytesToUpload());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n-      //Test for successful bytes uploaded\n+      //Test for successful bytes uploaded.\n       assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n-          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n-      //Populating random value for bytesFailed\n+      //Populating random value for bytesFailed.\n       int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n-      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      //Test for bytes failed to upload\n+      abfsOutputStreamStatisticsForUploadBytes.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n       assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-          abfsOutputStreamStatistics.getBytesUploadFailed());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadFailed());\n \n     }\n \n     try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n         uploadBytesFilePath)) {\n \n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for bytes to upload\n+      //Test for bytes to upload.\n       assertValues(\"bytes to upload\",\n-          largeValue * (testBytesToUpload.getBytes().length),\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesToUpload());\n \n-      //Test for successful bytes uploaded\n+      //Test for successful bytes uploaded.\n       assertValues(\"successful bytes uploaded\",\n-          largeValue * (testBytesToUpload.getBytes().length),\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesUploadSuccessful());\n \n-      //Populating random values for bytesFailed\n+      //Populating random values for bytesFailed.\n       int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n       abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      //Test for bytes failed to upload\n+      //Test for bytes failed to upload.\n       assertValues(\"bytes failed to upload\", randomBytesFailed,\n           abfsOutputStreamStatistics.getBytesUploadFailed());\n     }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4OTAxMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404589011", "body": "Same method was present in earlier patch. Move to base class and reuse.", "bodyText": "Same method was present in earlier patch. Move to base class and reuse.", "bodyHTML": "<p dir=\"auto\">Same method was present in earlier patch. Move to base class and reuse.</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:20:31Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testQueueShrink = \"testQueue\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 20 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@code writeCurrentBufferToService()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testWriteBuffer = \"Buffer\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      //Test for zero time writing Buffer to service\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n+\n+      outForOneOp.write(testWriteBuffer.getBytes());\n+      outForOneOp.flush();\n+\n+      //Test for one time writeCurrentBuffer() call\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testWriteBuffer.getBytes());\n+        outForLargeOps.flush();\n+      }\n+      //Test for 10 writeBufferOperations\n+      assertValues(\"number of writeCurrentBufferToService() calls\", largeValue,\n+          outForLargeOps\n+              .getOutputStreamStatistics().getWriteCurrentBufferOperations());\n+    }\n+\n+  }\n+\n+  /**\n+   * Generic create File and setting OutputStreamFlush to false.\n+   *\n+   * @param fs   AzureBlobFileSystem that is initialised in the test\n+   * @param path Path of the file to be created\n+   * @return AbfsOutputStream for writing\n+   * @throws AzureBlobFileSystemException\n+   */\n+  private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n+      Path path) throws AzureBlobFileSystemException {\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+\n+    return (AbfsOutputStream) abfss.createFile(path, fs.getFsStatistics(),\n+        true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+  }\n+\n+  /**\n+   * Generic assert method.\n+   *\n+   * @param operation     operation being asserted\n+   * @param expectedValue value that is expected\n+   * @param actualValue   value that is actual\n+   */", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -279,16 +293,4 @@ private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n         true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n   }\n \n-  /**\n-   * Generic assert method.\n-   *\n-   * @param operation     operation being asserted\n-   * @param expectedValue value that is expected\n-   * @param actualValue   value that is actual\n-   */\n-  private void assertValues(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n-  }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4OTc3OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404589778", "body": "Move the java doc to corresponding variables.", "bodyText": "Move the java doc to corresponding variables.", "bodyHTML": "<p dir=\"auto\">Move the java doc to corresponding variables.</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:22:01Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -23,22 +23,28 @@\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n-\n-  /**\n-   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n-   * Blocking Queue in AbfsOutputStream.\n-   *\n-   * queueShrink - Number of times Blocking Queue was shrunk after writing\n-   * data.\n-   *\n-   * WriteCurrentBufferOperations - Number of times the current buffer which\n-   * was written has been forwarded to the service.\n-   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n   private volatile long timeSpendOnTaskWait;\n-  private volatile long queueShrink;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private volatile long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n   private volatile long writeCurrentBufferOperations;\n \n   /**\n", "next_change": {"commit": "a667ab0820443fde451225be1f628f7f451005da", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 6c06cf0e35b..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -45,7 +45,7 @@\n    * Data store by\n    * AbfsResOperation.\n    */\n-  private volatile long writeCurrentBufferOperations;\n+  private long writeCurrentBufferOperations;\n \n   /**\n    * Records the need to upload bytes and increments the total bytes that\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMDU5Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404600592", "body": "Should go down after if clause?", "bodyText": "Should go down after if clause?", "bodyHTML": "<p dir=\"auto\">Should go down after if clause?</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:40:15Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -294,19 +299,23 @@ private synchronized void flushInternalAsync() throws IOException {\n   }\n \n   private synchronized void writeCurrentBufferToService() throws IOException {\n+    outputStreamStatistics.writeCurrentBuffer();", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjg0NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405022845", "bodyText": "yes, let's do that", "author": "steveloughran", "createdAt": "2020-04-07T18:27:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMDU5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ee15980ca78..b5467de06b7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -299,10 +301,10 @@ private synchronized void flushInternalAsync() throws IOException {\n   }\n \n   private synchronized void writeCurrentBufferToService() throws IOException {\n-    outputStreamStatistics.writeCurrentBuffer();\n     if (bufferIndex == 0) {\n       return;\n     }\n+    outputStreamStatistics.writeCurrentBuffer();\n \n     final byte[] bytes = buffer;\n     final int bytesLength = bufferIndex;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMTA4NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404601085", "body": "I don't understand the benifits of capturing this metric?", "bodyText": "I don't understand the benifits of capturing this metric?", "bodyHTML": "<p dir=\"auto\">I don't understand the benifits of capturing this metric?</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:41:07Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -384,6 +398,7 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    outputStreamStatistics.queueShrinked();", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMzI5NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405023294", "bodyText": "it would also be \"queueShrunk\" as a name", "author": "steveloughran", "createdAt": "2020-04-07T18:28:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMTA4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTA2MTM1OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405061359", "bodyText": "It is an expensive method. So, I thought it would benefit in knowing how many times it's being called after some write operations.\nSorry for the spelling mistake.", "author": "mehakmeet", "createdAt": "2020-04-07T19:33:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMTA4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ee15980ca78..b5467de06b7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -398,7 +400,7 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrinked();\n+    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex b5467de06b7..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -400,12 +404,13 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n+        // Incrementing statistics to indicate queue has been shrunk.\n+        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6974db92557..dff5897ea38 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -404,13 +399,12 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n-        // Incrementing statistics to indicate queue has been shrunk.\n-        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex dff5897ea38..a47c31ad125 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -399,12 +403,13 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n+        // Incrementing statistics to indicate queue has been shrunk.\n+        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwNDk4OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404604989", "body": "Use LARGE_OPERATIONS directly. Why to create a new variable.", "bodyText": "Use LARGE_OPERATIONS directly. Why to create a new variable.", "bodyHTML": "<p dir=\"auto\">Use LARGE_OPERATIONS directly. Why to create a new variable.</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:48:07Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -49,65 +50,67 @@ public ITestAbfsOutputStream() throws Exception {\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n         uploadBytesFilePath)\n     ) {\n \n-      //Test for zero bytes To upload\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n-      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+      abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for bytes to upload\n+      //Test for bytes to upload.\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          abfsOutputStreamStatistics.getBytesToUpload());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n-      //Test for successful bytes uploaded\n+      //Test for successful bytes uploaded.\n       assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n-          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n-      //Populating random value for bytesFailed\n+      //Populating random value for bytesFailed.\n       int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n-      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      //Test for bytes failed to upload\n+      abfsOutputStreamStatisticsForUploadBytes.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n       assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-          abfsOutputStreamStatistics.getBytesUploadFailed());\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadFailed());\n \n     }\n \n     try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n         uploadBytesFilePath)) {\n \n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for bytes to upload\n+      //Test for bytes to upload.\n       assertValues(\"bytes to upload\",\n-          largeValue * (testBytesToUpload.getBytes().length),\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesToUpload());\n \n-      //Test for successful bytes uploaded\n+      //Test for successful bytes uploaded.\n       assertValues(\"successful bytes uploaded\",\n-          largeValue * (testBytesToUpload.getBytes().length),\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesUploadSuccessful());\n \n-      //Populating random values for bytesFailed\n+      //Populating random values for bytesFailed.\n       int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n       abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      //Test for bytes failed to upload\n+      //Test for bytes failed to upload.\n       assertValues(\"bytes failed to upload\", randomBytesFailed,\n           abfsOutputStreamStatistics.getBytesUploadFailed());\n     }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwNTYyOA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404605628", "body": "same use path(getMethodName())", "bodyText": "same use path(getMethodName())", "bodyHTML": "<p dir=\"auto\">same use path(getMethodName())</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:49:06Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -123,14 +126,14 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path timeSpendFilePath = path(getMethodName());\n \n     try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           out.getOutputStreamStatistics();\n \n-      //Test for initial value of timeSpentWaitTask\n+      //Test for initial value of timeSpentWaitTask.\n       assertValues(\"Time spent on waiting tasks\", 0,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwODI5OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404608299", "body": "Looks like this an UT. Should move under UT folder. Create a new class TestAbfsOutputStreamStatictics and write all UT's there. You don't even have to create a file there. What do you say @steveloughran?", "bodyText": "Looks like this an UT. Should move under UT folder. Create a new class TestAbfsOutputStreamStatictics and write all UT's there. You don't even have to create a file there. What do you say @steveloughran?", "bodyHTML": "<p dir=\"auto\">Looks like this an UT. Should move under UT folder. Create a new class TestAbfsOutputStreamStatictics and write all UT's there. You don't even have to create a file there. What do you say <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/steveloughran/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/steveloughran\">@steveloughran</a>?</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T07:53:35Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -142,8 +145,8 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n       int smallDiff = smallRandomEndTime - smallRandomStartTime;\n       abfsOutputStreamStatistics\n           .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n-      //Test for small random value of timeSpentWaitTask\n-      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+      //Test for small random value of timeSpentWaitTask.\n+      assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n           abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n \n       int largeRandomStartTime =\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxODY1MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404618650", "body": "I can see you are disabling flush in createAbfsOutputStream(). Then why are you expecting double the actual values?", "bodyText": "I can see you are disabling flush in createAbfsOutputStream(). Then why are you expecting double the actual values?", "bodyHTML": "<p dir=\"auto\">I can see you are disabling flush in createAbfsOutputStream(). Then why are you expecting double the actual values?</p>", "author": "mukund-thakur", "createdAt": "2020-04-07T08:10:56Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testQueueShrink = \"testQueue\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+    }\n+", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNzAwNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404807005", "bodyText": "I am setting disableOutputStreamFlush to false, which implies flush is enabled.", "author": "mehakmeet", "createdAt": "2020-04-07T13:26:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxODY1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwOTYyMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405109621", "bodyText": "I had a mistake in the comments of that method so, that is why you could've assumed it to be disabling flush. Sorry for that.", "author": "mehakmeet", "createdAt": "2020-04-07T21:00:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxODY1MA=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -176,46 +180,52 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n \n-      //Test for shrinking Queue zero time\n-      assertValues(\"number of queueShrink() Calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outStream is flushed\n+      // Queue is shrunk 2 times when outputStream is flushed.\n       outForOneOp.flush();\n \n-      //Test for shrinking Queue 2 times\n-      assertValues(\"number of queueShrink() Calls\", 2,\n-          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n \n     try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n         queueShrinkFilePath)) {\n-\n-      int largeValue = LARGE_OPERATIONS;\n-      for (int i = 0; i < largeValue; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         outForLargeOps.flush();\n       }\n \n-      //Test for 20 queue shrink calls\n-      assertValues(\"number of queueShrink() Calls\",\n-          2 * largeValue,\n-          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n     }\n \n   }\n \n   /**\n-   * Test to check number of {@code writeCurrentBufferToService()}\n-   * calls.\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write() to simulate the\n    * scenario.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjYxMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405022610", "body": "let's guard this with a LOG.isDebugEnabled(), because that toString() operation is doing enough work. Or, use `this` as the argument and have SLF4J Call this.toString() only if it is printing the log entry", "bodyText": "let's guard this with a LOG.isDebugEnabled(), because that toString() operation is doing enough work. Or, use this as the argument and have SLF4J Call this.toString() only if it is printing the log entry", "bodyHTML": "<p dir=\"auto\">let's guard this with a LOG.isDebugEnabled(), because that toString() operation is doing enough work. Or, use <code>this</code> as the argument and have SLF4J Call this.toString() only if it is printing the log entry</p>", "author": "steveloughran", "createdAt": "2020-04-07T18:27:16Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -279,6 +283,7 @@ public synchronized void close() throws IOException {\n         threadExecutor.shutdownNow();\n       }\n     }\n+    LOG.debug(\"Closing AbfsOutputStream \", toString());", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ee15980ca78..b5467de06b7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -283,7 +283,9 @@ public synchronized void close() throws IOException {\n         threadExecutor.shutdownNow();\n       }\n     }\n-    LOG.debug(\"Closing AbfsOutputStream \", toString());\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Closing AbfsOutputStream \", toString());\n+    }\n   }\n \n   private synchronized void flushInternal(boolean isClose) throws IOException {\n", "next_change": null}]}}, {"oid": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "url": "https://github.com/apache/hadoop/commit/7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "message": "HADOOP-16914. Fixing comments and tests", "committedDate": "2020-04-07T20:47:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwNjQ1Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405106456", "body": "*disableOutputStreamFlush", "bodyText": "*disableOutputStreamFlush", "bodyHTML": "<p dir=\"auto\">*disableOutputStreamFlush</p>", "author": "mehakmeet", "createdAt": "2020-04-07T20:54:21Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,296 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = path(getMethodName());\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n+      assertValues(\"bytes to upload\", 0,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed.\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatisticsForUploadBytes.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed.\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = path(getMethodName());\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask.\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask.\n+      assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test.\n+       */\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = path(getMethodName());\n+    String testQueueShrink = \"testQueue\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outputStream is flushed.\n+      outForOneOp.flush();\n+\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        outForLargeOps.flush();\n+      }\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = path(getMethodName());\n+    String testWriteBuffer = \"Buffer\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for zero time writing Buffer to service.\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n+          abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n+\n+      outForOneOp.write(testWriteBuffer.getBytes());\n+      outForOneOp.flush();\n+\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for one time writeCurrentBuffer() call.\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+          abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeOps.write(testWriteBuffer.getBytes());\n+        outForLargeOps.flush();\n+      }\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+      //Test for 10 writeBufferOperations.\n+      assertValues(\"number of writeCurrentBufferToService() calls\",\n+          LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n+    }\n+\n+  }\n+\n+  /**\n+   * Generic create File and setting OutputStreamFlush to false.", "originalCommit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8d86c63f4053d4843323ff58341f2f2a78676625", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex d36a5441304..c24e1412384 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -276,21 +231,4 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n \n   }\n \n-  /**\n-   * Generic create File and setting OutputStreamFlush to false.\n-   *\n-   * @param fs   AzureBlobFileSystem that is initialised in the test.\n-   * @param path Path of the file to be created.\n-   * @return AbfsOutputStream for writing.\n-   * @throws AzureBlobFileSystemException\n-   */\n-  private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n-      Path path) throws AzureBlobFileSystemException {\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n-\n-    return (AbfsOutputStream) abfss.createFile(path, fs.getFsStatistics(),\n-        true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n-  }\n-\n }\n", "next_change": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex c24e1412384..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -207,28 +188,30 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n \n       abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n \n-      //Test for one time writeCurrentBuffer() call.\n-      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+      //Test for one time writing buffer to service.\n+      assertEquals(\"Mismatch in write current buffer operations\", 1,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n \n     try (\n         AbfsOutputStream outForLargeOps = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            writeBufferFilePath)) {\n+            fs, writeBufferFilePath)) {\n \n-      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+      /*\n+       * Need to flush each time after we write to actually write the data\n+       * into the data store and thus, get the writeCurrentBufferToService()\n+       * method triggered and increment the statistic.\n+       */\n+      for (int i = 0; i < OPERATIONS; i++) {\n         outForLargeOps.write(testWriteBuffer.getBytes());\n         outForLargeOps.flush();\n       }\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForLargeOps.getOutputStreamStatistics();\n-      //Test for 10 writeBufferOperations.\n-      assertValues(\"number of writeCurrentBufferToService() calls\",\n-          LARGE_OPERATIONS,\n+      //Test for 10 times writing buffer to service.\n+      assertEquals(\"Mismatch in write current buffer operations\",\n+          OPERATIONS,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n-\n   }\n-\n }\n", "next_change": {"commit": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex bda95cbc814..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -207,11 +207,23 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n         outForLargeOps.flush();\n       }\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForLargeOps.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForLargeOps);\n       //Test for 10 times writing buffer to service.\n       assertEquals(\"Mismatch in write current buffer operations\",\n           OPERATIONS,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n   }\n+\n+  /**\n+   * Method to get the AbfsOutputStream statistics.\n+   *\n+   * @param out AbfsOutputStream whose statistics is needed.\n+   * @return AbfsOutputStream statistics implementation class to get the\n+   * values of the counters.\n+   */\n+  private static AbfsOutputStreamStatisticsImpl getAbfsOutputStreamStatistics(\n+      AbfsOutputStream out) {\n+    return (AbfsOutputStreamStatisticsImpl) out.getOutputStreamStatistics();\n+  }\n }\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 09cbfde1beb..a41aeef3022 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -137,93 +152,82 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n      */\n     try (\n         AbfsOutputStream outForLargeOps = createAbfsOutputStreamWithFlushEnabled(\n-            fs, queueShrinkFilePath)) {\n-      for (int i = 0; i < OPERATIONS; i++) {\n+            fs,\n+            queueShrinkFilePath)) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         outForLargeOps.flush();\n       }\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          getAbfsOutputStreamStatistics(outForLargeOps);\n+          outForLargeOps.getOutputStreamStatistics();\n+\n       /*\n-       * After a write operation is done, it is in a task queue where it is\n-       * removed. Hence, to get the correct expected value we get the size of\n-       * the task queue from AbfsOutputStream and subtract it with total\n-       * write operations done to get the number of queue shrinks done.\n-       *\n+       * After each write operation we trigger the shrinkWriteOperationQueue\n+       * () method 2 times. Hence, after running the write operations 10\n+       * times inside the loop. We expect 20(2 * number_of_operations)\n+       * shrinkWriteOperationQueue() calls.\n        */\n-      assertEquals(\"Mismatch in queue shrunk operations\",\n-          OPERATIONS - outForLargeOps.getWriteOperationsSize(),\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n           abfsOutputStreamStatistics.getQueueShrunkOps());\n     }\n \n   }\n \n   /**\n-   * Tests to check correct values of write current buffer operations done by\n-   * AbfsOutputStream.\n-   *\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n    * After writing data, AbfsOutputStream doesn't upload data till flush() is\n    * called. Hence, flush() calls were made after write().\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamWriteBuffer() throws IOException {\n-    describe(\"Testing write current buffer operations by AbfsOutputStream\");\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path writeBufferFilePath = path(getMethodName());\n     String testWriteBuffer = \"Buffer\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStreamWithFlushEnabled(\n-        fs, writeBufferFilePath)) {\n+        fs,\n+        writeBufferFilePath)) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          getAbfsOutputStreamStatistics(outForOneOp);\n+          outForOneOp.getOutputStreamStatistics();\n \n-      //Test for zero time writing buffer to service.\n-      assertEquals(\"Mismatch in write current buffer operations\", 0,\n+      //Test for zero time writing Buffer to service.\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n \n       outForOneOp.write(testWriteBuffer.getBytes());\n       outForOneOp.flush();\n \n-      abfsOutputStreamStatistics = getAbfsOutputStreamStatistics(outForOneOp);\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n \n-      //Test for one time writing buffer to service.\n-      assertEquals(\"Mismatch in write current buffer operations\", 1,\n+      //Test for one time writeCurrentBuffer() call.\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n \n     try (\n         AbfsOutputStream outForLargeOps = createAbfsOutputStreamWithFlushEnabled(\n-            fs, writeBufferFilePath)) {\n+            fs,\n+            writeBufferFilePath)) {\n \n-      /*\n-       * Need to flush each time after we write to actually write the data\n-       * into the data store and thus, get the writeCurrentBufferToService()\n-       * method triggered and increment the statistic.\n-       */\n-      for (int i = 0; i < OPERATIONS; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeOps.write(testWriteBuffer.getBytes());\n         outForLargeOps.flush();\n       }\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          getAbfsOutputStreamStatistics(outForLargeOps);\n-      //Test for 10 times writing buffer to service.\n-      assertEquals(\"Mismatch in write current buffer operations\",\n-          OPERATIONS,\n+          outForLargeOps.getOutputStreamStatistics();\n+      //Test for 10 writeBufferOperations.\n+      assertValues(\"number of writeCurrentBufferToService() calls\",\n+          LARGE_OPERATIONS,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n-  }\n \n-  /**\n-   * Method to get the AbfsOutputStream statistics.\n-   *\n-   * @param out AbfsOutputStream whose statistics is needed.\n-   * @return AbfsOutputStream statistics implementation class to get the\n-   * values of the counters.\n-   */\n-  private static AbfsOutputStreamStatisticsImpl getAbfsOutputStreamStatistics(\n-      AbfsOutputStream out) {\n-    return (AbfsOutputStreamStatisticsImpl) out.getOutputStreamStatistics();\n   }\n+\n }\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -206,28 +197,30 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n \n       abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n \n-      //Test for one time writeCurrentBuffer() call.\n-      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+      //Test for one time writing buffer to service.\n+      assertEquals(\"Mismatch in write current buffer operations\", 1,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n \n     try (\n         AbfsOutputStream outForLargeOps = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            writeBufferFilePath)) {\n+            fs, writeBufferFilePath)) {\n \n-      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+      /*\n+       * Need to flush each time after we write to actually write the data\n+       * into the data store and thus, get the writeCurrentBufferToService()\n+       * method triggered and increment the statistic.\n+       */\n+      for (int i = 0; i < OPERATIONS; i++) {\n         outForLargeOps.write(testWriteBuffer.getBytes());\n         outForLargeOps.flush();\n       }\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForLargeOps.getOutputStreamStatistics();\n-      //Test for 10 writeBufferOperations.\n-      assertValues(\"number of writeCurrentBufferToService() calls\",\n-          LARGE_OPERATIONS,\n+      //Test for 10 times writing buffer to service.\n+      assertEquals(\"Mismatch in write current buffer operations\",\n+          OPERATIONS,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n-\n   }\n-\n }\n", "next_change": {"commit": "f98a76c746e68fce59593841e881387f7dd74b0d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex cd706dfbbfe..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -216,11 +207,23 @@ public void testAbfsOutputStreamWriteBuffer() throws IOException {\n         outForLargeOps.flush();\n       }\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForLargeOps.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForLargeOps);\n       //Test for 10 times writing buffer to service.\n       assertEquals(\"Mismatch in write current buffer operations\",\n           OPERATIONS,\n           abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n     }\n   }\n+\n+  /**\n+   * Method to get the AbfsOutputStream statistics.\n+   *\n+   * @param out AbfsOutputStream whose statistics is needed.\n+   * @return AbfsOutputStream statistics implementation class to get the\n+   * values of the counters.\n+   */\n+  private static AbfsOutputStreamStatisticsImpl getAbfsOutputStreamStatistics(\n+      AbfsOutputStream out) {\n+    return (AbfsOutputStreamStatisticsImpl) out.getOutputStreamStatistics();\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"oid": "8d86c63f4053d4843323ff58341f2f2a78676625", "url": "https://github.com/apache/hadoop/commit/8d86c63f4053d4843323ff58341f2f2a78676625", "message": "HADOOP-16914. Fixing comments and tests", "committedDate": "2020-04-08T17:39:23Z", "type": "forcePushed"}, {"oid": "09d0deab572c8ddf34bba64b25437949380356bc", "url": "https://github.com/apache/hadoop/commit/09d0deab572c8ddf34bba64b25437949380356bc", "message": "HADOOP-16914 AbfsOutputStream Counter\n\nChange-Id: Ie976f23c6c3e2f5cf9167794357cfc669a232c80", "committedDate": "2020-04-09T06:43:22Z", "type": "forcePushed"}, {"oid": "a667ab0820443fde451225be1f628f7f451005da", "url": "https://github.com/apache/hadoop/commit/a667ab0820443fde451225be1f628f7f451005da", "message": "HADOOP-16914 AbfsOutputStream Counter\n\nChange-Id: Ie976f23c6c3e2f5cf9167794357cfc669a232c80", "committedDate": "2020-04-14T12:27:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE1NDgxOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408154819", "body": "typo.. Remove first word bytes.", "bodyText": "typo.. Remove first word bytes.", "bodyHTML": "<p dir=\"auto\">typo.. Remove first word bytes.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T13:54:41Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload.\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Records a successful upload and the number of bytes uploaded.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded.\n+   */\n+  void uploadSuccessful(long bytes);\n+\n+  /**\n+   * Records that upload is failed and the number of bytes.\n+   *\n+   * @param bytes number of bytes that failed to upload.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4NTM3Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408485372", "bodyText": "that is the name of the param, description follows. It would be color coded in an IDE.", "author": "mehakmeet", "createdAt": "2020-04-14T23:02:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE1NDgxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -48,7 +48,7 @@\n   void uploadFailed(long bytes);\n \n   /**\n-   * Time spent in waiting for tasks to be completed in the blocking Queue.\n+   * Time spent in waiting for tasks to be completed in the blocking queue.\n    *\n    * @param start millisecond at which the wait for task to be complete begins.\n    * @param end   millisecond at which the wait is completed for the task.\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex c9fe0dd4552..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -48,7 +48,7 @@\n   void uploadFailed(long bytes);\n \n   /**\n-   * Time spent in waiting for tasks to be completed in the blocking queue.\n+   * Time spent in waiting for tasks to be completed in the blocking Queue.\n    *\n    * @param start millisecond at which the wait for task to be complete begins.\n    * @param end   millisecond at which the wait is completed for the task.\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -48,7 +48,7 @@\n   void uploadFailed(long bytes);\n \n   /**\n-   * Time spent in waiting for tasks to be completed in the blocking Queue.\n+   * Time spent in waiting for tasks to be completed in the blocking queue.\n    *\n    * @param start millisecond at which the wait for task to be complete begins.\n    * @param end   millisecond at which the wait is completed for the task.\n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex c9fe0dd4552..9bdfbda91fe 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,18 +56,20 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times task queue is shrunk.\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n+   * method was called.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times buffer is written to the service after a write operation.\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n+   * method was called.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a string of all AbfsOutputStream statistics and their\n-   * values.\n+   * Method to form a String of all AbfsOutputStream counters and their values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n", "chunk": "@@ -56,20 +56,18 @@\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n-   * method was called.\n+   * Number of times task queue is shrunk.\n    */\n   void queueShrunk();\n \n   /**\n-   * Number of times\n-   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n-   * method was called.\n+   * Number of times buffer is written to the service after a write operation.\n    */\n   void writeCurrentBuffer();\n \n   /**\n-   * Method to form a String of all AbfsOutputStream counters and their values.\n+   * Method to form a string of all AbfsOutputStream statistics and their\n+   * values.\n    *\n    * @return AbfsOutputStream statistics.\n    */\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE1NDkxOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408154919", "body": "typo.. Remove first word bytes.", "bodyText": "typo.. Remove first word bytes.", "bodyHTML": "<p dir=\"auto\">typo.. Remove first word bytes.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T13:54:48Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload.\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Records a successful upload and the number of bytes uploaded.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODQwNA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178404", "body": "A better test would to be call multiple times and see if the summation is working fine rather that resetting the stats?", "bodyText": "A better test would to be call multiple times and see if the summation is working fine rather that resetting the stats?", "bodyHTML": "<p dir=\"auto\">A better test would to be call multiple times and see if the summation is working fine rather that resetting the stats?</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T14:25:25Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ5NjA0OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408496049", "bodyText": "I can use the previous value(L61) and see if it's being summed by removing the reset?", "author": "mehakmeet", "createdAt": "2020-04-14T23:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODQwNA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -27,67 +26,73 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit Tests for AbfsOutputStream Statistics.\n+ * Unit tests for AbfsOutputStream statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check number of bytes failed to upload in\n+   * {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertValues(\"number fo bytes failed to upload\", 0,\n+    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Initializing again to reset the statistics.\n+    //Reset statistics for the next test.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    //Populating large random values for bytesFailed.\n-    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    /*\n+     * Entering multiple random values for bytesFailed to check correct\n+     * summation of values.\n+     */\n+    int expectedBytesFailed = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      expectedBytesFailed += randomBytesFailed;\n+    }\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    describe(\"Testing time Spent on waiting for task to be completed in \"\n+        + \"AbfsOutputStream\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -26,73 +27,67 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit tests for AbfsOutputStream statistics.\n+ * Unit Tests for AbfsOutputStream Statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n-  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check number of bytes failed to upload in\n-   * {@link AbfsOutputStream}.\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n+    assertValues(\"number fo bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\",\n-        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Reset statistics for the next test.\n+    //Initializing again to reset the statistics.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    /*\n-     * Entering multiple random values for bytesFailed to check correct\n-     * summation of values.\n-     */\n-    int expectedBytesFailed = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      expectedBytesFailed += randomBytesFailed;\n-    }\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\",\n-        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing time Spent on waiting for task to be completed in \"\n-        + \"AbfsOutputStream\");\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -27,67 +26,73 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit Tests for AbfsOutputStream Statistics.\n+ * Unit tests for AbfsOutputStream statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check number of bytes failed to upload in\n+   * {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertValues(\"number fo bytes failed to upload\", 0,\n+    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Initializing again to reset the statistics.\n+    //Reset statistics for the next test.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    //Populating large random values for bytesFailed.\n-    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    /*\n+     * Entering multiple random values for bytesFailed to check correct\n+     * summation of values.\n+     */\n+    int expectedBytesFailed = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      expectedBytesFailed += randomBytesFailed;\n+    }\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    describe(\"Testing time Spent on waiting for task to be completed in \"\n+        + \"AbfsOutputStream\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODkxMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178910", "body": "Indentation.", "bodyText": "Indentation.", "bodyHTML": "<p dir=\"auto\">Indentation.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T14:26:03Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,77 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue random times.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     *\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations and\n+     * checking summation.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..292ed644580 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -175,5 +175,4 @@ public void testAbfsOutputStreamQueueShrink() {\n         randomQueueValues * OPERATIONS,\n         abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n-\n }\n", "next_change": {"commit": "51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 292ed644580..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -161,15 +161,13 @@ public void testAbfsOutputStreamQueueShrink() {\n     /*\n      * Entering random values for queueShrunkOps and checking the correctness\n      * of summation for the statistic.\n-     *\n      */\n     int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n     for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n       abfsOutputStreamStatistics.queueShrunk();\n     }\n     /*\n-     * Test for random times incrementing queue shrunk operations and\n-     * checking summation.\n+     * Test for random times incrementing queue shrunk operations.\n      */\n     assertEquals(\"Mismatch in queue shrunk operations\",\n         randomQueueValues * OPERATIONS,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 58f00233710..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -103,74 +98,23 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering multiple values for timeSpentTaskWait() to check the\n-     * summation is happening correctly. Also calculating the expected result.\n-     */\n-    int expectedRandomDiff = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      int largeRandomStartTime =\n-          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-          + largeRandomStartTime;\n-      abfsOutputStreamStatistics\n-          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n-    }\n-\n-    /*\n-     * Test to check correct value of timeSpentTaskWait after multiple\n-     * random values are passed in it.\n-     */\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        expectedRandomDiff,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n   }\n \n-  /**\n-   * Unit Tests to check correct values of queue shrunk operations in\n-   * AbfsOutputStream.\n-   *\n-   */\n-  @Test\n-  public void testAbfsOutputStreamQueueShrink() {\n-    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n-\n-    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-        new AbfsOutputStreamStatisticsImpl();\n-\n-    //Test for shrinking queue zero time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    abfsOutputStreamStatistics.queueShrunk();\n-\n-    //Test for shrinking queue 1 time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering random values for queueShrunkOps and checking the correctness\n-     * of summation for the statistic.\n-     */\n-    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n-      abfsOutputStreamStatistics.queueShrunk();\n-    }\n-    /*\n-     * Test for random times incrementing queue shrunk operations.\n-     */\n-    assertEquals(\"Mismatch in queue shrunk operations\",\n-        randomQueueValues * OPERATIONS,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-  }\n-}\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,33 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-  }\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-}\n\\ No newline at end of file\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+}\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex ca082cf7042..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -132,4 +132,45 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n         expectedRandomDiff,\n         abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n   }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue 1 time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTMzMw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179333", "body": "same as comment on L68.", "bodyText": "same as comment on L68.", "bodyHTML": "<p dir=\"auto\">same as comment on L68.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T14:26:38Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4Njc1Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408486756", "bodyText": "actually in this test I am testing the summation, by expecting a summed value of test at L101 in test at L115. Should I do something similar for above tests(L68) ? or should I do multiple summations using loops ?", "author": "mehakmeet", "createdAt": "2020-04-14T23:06:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTMzMw=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,77 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue random times.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     *\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations and\n+     * checking summation.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..292ed644580 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -175,5 +175,4 @@ public void testAbfsOutputStreamQueueShrink() {\n         randomQueueValues * OPERATIONS,\n         abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n-\n }\n", "next_change": {"commit": "51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 292ed644580..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -161,15 +161,13 @@ public void testAbfsOutputStreamQueueShrink() {\n     /*\n      * Entering random values for queueShrunkOps and checking the correctness\n      * of summation for the statistic.\n-     *\n      */\n     int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n     for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n       abfsOutputStreamStatistics.queueShrunk();\n     }\n     /*\n-     * Test for random times incrementing queue shrunk operations and\n-     * checking summation.\n+     * Test for random times incrementing queue shrunk operations.\n      */\n     assertEquals(\"Mismatch in queue shrunk operations\",\n         randomQueueValues * OPERATIONS,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 58f00233710..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -103,74 +98,23 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering multiple values for timeSpentTaskWait() to check the\n-     * summation is happening correctly. Also calculating the expected result.\n-     */\n-    int expectedRandomDiff = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      int largeRandomStartTime =\n-          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-          + largeRandomStartTime;\n-      abfsOutputStreamStatistics\n-          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n-    }\n-\n-    /*\n-     * Test to check correct value of timeSpentTaskWait after multiple\n-     * random values are passed in it.\n-     */\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        expectedRandomDiff,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n   }\n \n-  /**\n-   * Unit Tests to check correct values of queue shrunk operations in\n-   * AbfsOutputStream.\n-   *\n-   */\n-  @Test\n-  public void testAbfsOutputStreamQueueShrink() {\n-    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n-\n-    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-        new AbfsOutputStreamStatisticsImpl();\n-\n-    //Test for shrinking queue zero time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    abfsOutputStreamStatistics.queueShrunk();\n-\n-    //Test for shrinking queue 1 time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering random values for queueShrunkOps and checking the correctness\n-     * of summation for the statistic.\n-     */\n-    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n-      abfsOutputStreamStatistics.queueShrunk();\n-    }\n-    /*\n-     * Test for random times incrementing queue shrunk operations.\n-     */\n-    assertEquals(\"Mismatch in queue shrunk operations\",\n-        randomQueueValues * OPERATIONS,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-  }\n-}\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,33 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-  }\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-}\n\\ No newline at end of file\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+}\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex ca082cf7042..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -132,4 +132,45 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n         expectedRandomDiff,\n         abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n   }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue 1 time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4MTAwOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408181009", "body": "remove bytes.", "bodyText": "remove bytes.", "bodyHTML": "<p dir=\"auto\">remove bytes.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T14:28:44Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n+  private long writeCurrentBufferOperations;\n+\n+  /**\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n+   *\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3MjEwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408172102", "body": "just create your own static LOG", "bodyText": "just create your own static LOG", "bodyHTML": "<p dir=\"auto\">just create your own static LOG</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:17:16Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -279,6 +283,9 @@ public synchronized void close() throws IOException {\n         threadExecutor.shutdownNow();\n       }\n     }\n+    if (LOG.isDebugEnabled()) {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3MzgzMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408173830", "body": "remember that discussion we had about volatile vs long and you concluded that we could shut yetus up by going non volatile?\r\nIn #1820 I've moved s3a input stream stats to volatile so that the IOStatistics gets the latest values without blocking...and then turned off findbugs warnings (or at least, I'm trying to)", "bodyText": "remember that discussion we had about volatile vs long and you concluded that we could shut yetus up by going non volatile?\nIn #1820 I've moved s3a input stream stats to volatile so that the IOStatistics gets the latest values without blocking...and then turned off findbugs warnings (or at least, I'm trying to)", "bodyHTML": "<p dir=\"auto\">remember that discussion we had about volatile vs long and you concluded that we could shut yetus up by going non volatile?<br>\nIn <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"555819456\" data-permission-text=\"Title is private\" data-url=\"https://github.com/apache/hadoop/issues/1820\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/apache/hadoop/pull/1820/hovercard\" href=\"https://github.com/apache/hadoop/pull/1820\">#1820</a> I've moved s3a input stream stats to volatile so that the IOStatistics gets the latest values without blocking...and then turned off findbugs warnings (or at least, I'm trying to)</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:19:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY4MTk2Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408681962", "bodyText": "I thought we concluded that AbfsInputStream and AbfsOutputStream uses synchronized for thread safety and we don't need either volatile or AtomicLong for the counters.\nShould I use volatile and suppress the warnings ?", "author": "mehakmeet", "createdAt": "2020-04-15T08:49:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3MzgzMA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream statistics implementation for Abfs.\n+ * OutputStream Statistics Implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDMyNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408174325", "body": "not needed; just cut it", "bodyText": "not needed; just cut it", "bodyHTML": "<p dir=\"auto\">not needed; just cut it</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:20:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4NzcxNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408487715", "bodyText": "Think I need to handle Exception for this Test, and don't know any way other than making a constructor and doing so.", "author": "mehakmeet", "createdAt": "2020-04-14T23:09:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDMyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ3MjA5MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r411472091", "bodyText": "test suites can throw exceptions, but the constructor shouldn't have to. But if you want to keep it, then go ahead and keep it. It's not important", "author": "steveloughran", "createdAt": "2020-04-20T15:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDMyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -31,34 +31,31 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int LARGE_OPERATIONS = 10;\n+  private static final int OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)\n+            fs, uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertValues(\"bytes to upload\", 0,\n+      assertEquals(\"Mismatch in bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n", "next_change": {"commit": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex bda95cbc814..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -52,7 +52,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n-          outForSomeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForSomeBytes);\n \n       //Test for zero bytes To upload.\n       assertEquals(\"Mismatch in bytes to upload\", 0,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 09cbfde1beb..a41aeef3022 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -31,45 +31,47 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int OPERATIONS = 10;\n+  private static final int LARGE_OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs, uploadBytesFilePath)\n+            fs,\n+            uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertEquals(\"Mismatch in bytes to upload\", 0,\n+      assertValues(\"bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n       abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertEquals(\"Mismatch in bytes to upload\",\n-          testBytesToUpload.getBytes().length,\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertEquals(\"Mismatch in successful bytes uploaded\",\n+      assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -67,11 +64,12 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+      assertEquals(\"Mismatch in bytes to upload\",\n+          testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertValues(\"successful bytes uploaded\",\n+      assertEquals(\"Mismatch in successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -79,10 +77,9 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n \n     try (\n         AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)) {\n+            fs, uploadBytesFilePath)) {\n \n-      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+      for (int i = 0; i < OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n", "next_change": {"commit": "f98a76c746e68fce59593841e881387f7dd74b0d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex cd706dfbbfe..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -84,7 +84,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForLargeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForLargeBytes);\n \n       //Test for bytes to upload.\n       assertEquals(\"Mismatch in bytes to upload\",\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex bda95cbc814..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -61,7 +61,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n       abfsOutputStreamStatisticsForUploadBytes =\n-          outForSomeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForSomeBytes);\n \n       //Test for bytes to upload.\n       assertEquals(\"Mismatch in bytes to upload\",\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 09cbfde1beb..a41aeef3022 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -31,45 +31,47 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int OPERATIONS = 10;\n+  private static final int LARGE_OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs, uploadBytesFilePath)\n+            fs,\n+            uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertEquals(\"Mismatch in bytes to upload\", 0,\n+      assertValues(\"bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n       abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertEquals(\"Mismatch in bytes to upload\",\n-          testBytesToUpload.getBytes().length,\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertEquals(\"Mismatch in successful bytes uploaded\",\n+      assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -67,11 +64,12 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+      assertEquals(\"Mismatch in bytes to upload\",\n+          testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertValues(\"successful bytes uploaded\",\n+      assertEquals(\"Mismatch in successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -79,10 +77,9 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n \n     try (\n         AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)) {\n+            fs, uploadBytesFilePath)) {\n \n-      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+      for (int i = 0; i < OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n", "next_change": {"commit": "f98a76c746e68fce59593841e881387f7dd74b0d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex cd706dfbbfe..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -84,7 +84,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForLargeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForLargeBytes);\n \n       //Test for bytes to upload.\n       assertEquals(\"Mismatch in bytes to upload\",\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDg5OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408174898", "body": "nit: pull up to previous line", "bodyText": "nit: pull up to previous line", "bodyHTML": "<p dir=\"auto\">nit: pull up to previous line</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:20:53Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = path(getMethodName());\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (\n+        AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n+            fs,\n+            uploadBytesFilePath)\n+    ) {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -31,34 +31,31 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int LARGE_OPERATIONS = 10;\n+  private static final int OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)\n+            fs, uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertValues(\"bytes to upload\", 0,\n+      assertEquals(\"Mismatch in bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n", "next_change": {"commit": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex bda95cbc814..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -52,7 +52,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n-          outForSomeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForSomeBytes);\n \n       //Test for zero bytes To upload.\n       assertEquals(\"Mismatch in bytes to upload\", 0,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 09cbfde1beb..a41aeef3022 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -31,45 +31,47 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int OPERATIONS = 10;\n+  private static final int LARGE_OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs, uploadBytesFilePath)\n+            fs,\n+            uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertEquals(\"Mismatch in bytes to upload\", 0,\n+      assertValues(\"bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n       abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertEquals(\"Mismatch in bytes to upload\",\n-          testBytesToUpload.getBytes().length,\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertEquals(\"Mismatch in successful bytes uploaded\",\n+      assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -67,11 +64,12 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+      assertEquals(\"Mismatch in bytes to upload\",\n+          testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertValues(\"successful bytes uploaded\",\n+      assertEquals(\"Mismatch in successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -79,10 +77,9 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n \n     try (\n         AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)) {\n+            fs, uploadBytesFilePath)) {\n \n-      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+      for (int i = 0; i < OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n", "next_change": {"commit": "f98a76c746e68fce59593841e881387f7dd74b0d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex cd706dfbbfe..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -84,7 +84,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForLargeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForLargeBytes);\n \n       //Test for bytes to upload.\n       assertEquals(\"Mismatch in bytes to upload\",\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex bda95cbc814..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -61,7 +61,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n       abfsOutputStreamStatisticsForUploadBytes =\n-          outForSomeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForSomeBytes);\n \n       //Test for bytes to upload.\n       assertEquals(\"Mismatch in bytes to upload\",\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 09cbfde1beb..a41aeef3022 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -31,45 +31,47 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int OPERATIONS = 10;\n+  private static final int LARGE_OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs, uploadBytesFilePath)\n+            fs,\n+            uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertEquals(\"Mismatch in bytes to upload\", 0,\n+      assertValues(\"bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n       abfsOutputStreamStatisticsForUploadBytes =\n-          getAbfsOutputStreamStatistics(outForSomeBytes);\n+          outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertEquals(\"Mismatch in bytes to upload\",\n-          testBytesToUpload.getBytes().length,\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertEquals(\"Mismatch in successful bytes uploaded\",\n+      assertValues(\"successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -67,11 +64,12 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+      assertEquals(\"Mismatch in bytes to upload\",\n+          testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertValues(\"successful bytes uploaded\",\n+      assertEquals(\"Mismatch in successful bytes uploaded\",\n           testBytesToUpload.getBytes().length,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -79,10 +77,9 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n \n     try (\n         AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)) {\n+            fs, uploadBytesFilePath)) {\n \n-      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+      for (int i = 0; i < OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n", "next_change": {"commit": "f98a76c746e68fce59593841e881387f7dd74b0d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex cd706dfbbfe..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -84,7 +84,7 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForLargeBytes.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForLargeBytes);\n \n       //Test for bytes to upload.\n       assertEquals(\"Mismatch in bytes to upload\",\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NTM2NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408175364", "body": "nit: just cut these lines from the javadoc. Nice to see the rest of the detail", "bodyText": "nit: just cut these lines from the javadoc. Nice to see the rest of the detail", "bodyHTML": "<p dir=\"auto\">nit: just cut these lines from the javadoc. Nice to see the rest of the detail</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:21:28Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = path(getMethodName());\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (\n+        AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n+            fs,\n+            uploadBytesFilePath)\n+    ) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n+      assertValues(\"bytes to upload\", 0,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n+\n+    }\n+\n+    try (\n+        AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n+            fs,\n+            uploadBytesFilePath)) {\n+\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+    }\n+  }\n+\n+  /**\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNzYzNA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408627634", "bodyText": "So, the throws comments from all the javadoc in the tests, right ?", "author": "mehakmeet", "createdAt": "2020-04-15T07:13:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NTM2NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -90,53 +87,41 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n           outForLargeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertValues(\"bytes to upload\",\n-          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+      assertEquals(\"Mismatch in bytes to upload\",\n+          OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertValues(\"successful bytes uploaded\",\n-          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+      assertEquals(\"Mismatch in successful bytes uploaded\",\n+          OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesUploadSuccessful());\n \n     }\n   }\n \n   /**\n-   * Tests to check number of {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n-   * After writing data, AbfsOutputStream doesn't upload the data until\n-   * Flushed. Hence, flush() method is called after write() to test Queue\n-   * shrink calls.\n+   * Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n    *\n-   * @throws IOException\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * flushed. Hence, flush() method is called after write() to test queue\n+   * shrink operations.\n    */\n   @Test\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n-    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStreamWithFlushEnabled(\n-        fs,\n-        queueShrinkFilePath)) {\n+        fs, queueShrinkFilePath)) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForOneOp.getOutputStreamStatistics();\n \n-      //Test for shrinking Queue zero time.\n-      assertValues(\"Queue shrunk operations\", 0,\n-          abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-      outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outputStream is flushed.\n-      outForOneOp.flush();\n-\n-      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n-\n-      //Test for shrinking Queue 2 times.\n-      assertValues(\"Queue shrunk operations\", 2,\n+      //Test for shrinking queue zero time.\n+      assertEquals(\"Mismatch in queue shrunk operations\", 0,\n           abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n", "next_change": {"commit": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex bda95cbc814..09cbfde1beb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -118,7 +118,7 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n         fs, queueShrinkFilePath)) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          outForOneOp.getOutputStreamStatistics();\n+          getAbfsOutputStreamStatistics(outForOneOp);\n \n       //Test for shrinking queue zero time.\n       assertEquals(\"Mismatch in queue shrunk operations\", 0,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 09cbfde1beb..a41aeef3022 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -77,51 +79,64 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n \n     try (\n         AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs, uploadBytesFilePath)) {\n+            fs,\n+            uploadBytesFilePath)) {\n \n-      for (int i = 0; i < OPERATIONS; i++) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          getAbfsOutputStreamStatistics(outForLargeBytes);\n+          outForLargeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertEquals(\"Mismatch in bytes to upload\",\n-          OPERATIONS * (testBytesToUpload.getBytes().length),\n+      assertValues(\"bytes to upload\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertEquals(\"Mismatch in successful bytes uploaded\",\n-          OPERATIONS * (testBytesToUpload.getBytes().length),\n+      assertValues(\"successful bytes uploaded\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesUploadSuccessful());\n \n     }\n   }\n \n   /**\n-   * Tests to check correct values of queue shrunk operations in\n-   * AbfsOutputStream.\n-   *\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n-   * flushed. Hence, flush() method is called after write() to test queue\n-   * shrink operations.\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n-    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStreamWithFlushEnabled(\n-        fs, queueShrinkFilePath)) {\n+        fs,\n+        queueShrinkFilePath)) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-          getAbfsOutputStreamStatistics(outForOneOp);\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outputStream is flushed.\n+      outForOneOp.flush();\n \n-      //Test for shrinking queue zero time.\n-      assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n           abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..cd706dfbbfe 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -90,53 +87,51 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n           outForLargeBytes.getOutputStreamStatistics();\n \n       //Test for bytes to upload.\n-      assertValues(\"bytes to upload\",\n-          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+      assertEquals(\"Mismatch in bytes to upload\",\n+          OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesToUpload());\n \n       //Test for successful bytes uploaded.\n-      assertValues(\"successful bytes uploaded\",\n-          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+      assertEquals(\"Mismatch in successful bytes uploaded\",\n+          OPERATIONS * (testBytesToUpload.getBytes().length),\n           abfsOutputStreamStatistics.getBytesUploadSuccessful());\n \n     }\n   }\n \n   /**\n-   * Tests to check number of {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n-   * After writing data, AbfsOutputStream doesn't upload the data until\n-   * Flushed. Hence, flush() method is called after write() to test Queue\n-   * shrink calls.\n+   * Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n    *\n-   * @throws IOException\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * flushed. Hence, flush() method is called after write() to test queue\n+   * shrink operations.\n    */\n   @Test\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n-    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path queueShrinkFilePath = path(getMethodName());\n     String testQueueShrink = \"testQueue\";\n \n     try (AbfsOutputStream outForOneOp = createAbfsOutputStreamWithFlushEnabled(\n-        fs,\n-        queueShrinkFilePath)) {\n+        fs, queueShrinkFilePath)) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForOneOp.getOutputStreamStatistics();\n \n       //Test for shrinking Queue zero time.\n-      assertValues(\"Queue shrunk operations\", 0,\n+      assertEquals(\"Mismatch in queue shrunk operations\", 0,\n           abfsOutputStreamStatistics.getQueueShrunkOps());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n-      // Queue is shrunk 2 times when outputStream is flushed.\n+      //Queue is shrunk 2 times when outputStream is flushed.\n       outForOneOp.flush();\n \n       abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n \n       //Test for shrinking Queue 2 times.\n-      assertValues(\"Queue shrunk operations\", 2,\n+      assertEquals(\"Mismatch in queue shrunk operations\", 2,\n           abfsOutputStreamStatistics.getQueueShrunkOps());\n \n     }\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex cd706dfbbfe..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -120,20 +120,10 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n           outForOneOp.getOutputStreamStatistics();\n \n-      //Test for shrinking Queue zero time.\n+      //Test for shrinking queue zero time.\n       assertEquals(\"Mismatch in queue shrunk operations\", 0,\n           abfsOutputStreamStatistics.getQueueShrunkOps());\n \n-      outForOneOp.write(testQueueShrink.getBytes());\n-      //Queue is shrunk 2 times when outputStream is flushed.\n-      outForOneOp.flush();\n-\n-      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n-\n-      //Test for shrinking Queue 2 times.\n-      assertEquals(\"Mismatch in queue shrunk operations\", 2,\n-          abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n     }\n \n     /*\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408176558", "body": "why is this being cast rather than returned as is?", "bodyText": "why is this being cast rather than returned as is?", "bodyHTML": "<p dir=\"auto\">why is this being cast rather than returned as is?</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:22:57Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -436,4 +453,28 @@ private void waitForTaskToComplete() throws IOException {\n   public synchronized void waitForPendingUploads() throws IOException {\n     waitForTaskToComplete();\n   }\n+\n+  /**\n+   * Getter method for AbfsOutputStream Statistics.\n+   *\n+   * @return statistics for AbfsOutputStream.\n+   */\n+  @VisibleForTesting\n+  public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ5Mjk5NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408492995", "bodyText": "I think it expects to return AbfsOutputStreamStatisticsImpl, and if we return just AbfsOutputStreamStatistics, it would give rise to incompatible types error.", "author": "mehakmeet", "createdAt": "2020-04-14T23:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY4MDg1Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408680852", "bodyText": "I could cast in the tests where this is called, but I thought it would easier to cast here than casting there as there would be many calls to this method.", "author": "mehakmeet", "createdAt": "2020-04-15T08:47:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ3NDU0NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r411474545", "bodyText": "this would be coding into the implementation/semi-public API something only relevant for testing -and make it very hard to ever change to a different implementation.\nJust add some static method in the test suite\nAbfsOutputStreamStatisticsImp getStreamStatistics(AbfsOutputStream)\n\nand you could do the casting in just one place.", "author": "steveloughran", "createdAt": "2020-04-20T15:31:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex b5467de06b7..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -455,7 +460,7 @@ public synchronized void waitForPendingUploads() throws IOException {\n   }\n \n   /**\n-   * Getter method for AbfsOutputStream Statistics.\n+   * Getter method for AbfsOutputStream statistics.\n    *\n    * @return statistics for AbfsOutputStream.\n    */\n", "next_change": {"commit": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6974db92557..ade80a9cbd2 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -465,8 +465,8 @@ public synchronized void waitForPendingUploads() throws IOException {\n    * @return statistics for AbfsOutputStream.\n    */\n   @VisibleForTesting\n-  public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n-    return (AbfsOutputStreamStatisticsImpl) outputStreamStatistics;\n+  public AbfsOutputStreamStatistics getOutputStreamStatistics() {\n+    return outputStreamStatistics;\n   }\n \n   /**\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ade80a9cbd2..dff5897ea38 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -460,27 +454,17 @@ public synchronized void waitForPendingUploads() throws IOException {\n   }\n \n   /**\n-   * Getter method for AbfsOutputStream statistics.\n+   * Getter method for AbfsOutputStream Statistics.\n    *\n    * @return statistics for AbfsOutputStream.\n    */\n   @VisibleForTesting\n-  public AbfsOutputStreamStatistics getOutputStreamStatistics() {\n-    return outputStreamStatistics;\n-  }\n-\n-  /**\n-   * Getter to get the size of the task queue.\n-   *\n-   * @return the number of writeOperations in AbfsOutputStream.\n-   */\n-  @VisibleForTesting\n-  public int getWriteOperationsSize() {\n-    return writeOperations.size();\n+  public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n+    return (AbfsOutputStreamStatisticsImpl) outputStreamStatistics;\n   }\n \n   /**\n-   * Appending AbfsOutputStream statistics to base toString().\n+   * Appending AbfsOutputStream Statistics to base toString().\n    *\n    * @return String with AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex dff5897ea38..c55d5a2cc5f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -464,7 +468,7 @@ public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n   }\n \n   /**\n-   * Appending AbfsOutputStream Statistics to base toString().\n+   * Appending AbfsOutputStream statistics to base toString().\n    *\n    * @return String with AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex c55d5a2cc5f..a47c31ad125 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -467,6 +468,16 @@ public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n     return (AbfsOutputStreamStatisticsImpl) outputStreamStatistics;\n   }\n \n+  /**\n+   * Getter to get the size of the task queue.\n+   *\n+   * @return the number of writeOperations in AbfsOutputStream.\n+   */\n+  @VisibleForTesting\n+  public int getWriteOperationsSize() {\n+    return writeOperations.size();\n+  }\n+\n   /**\n    * Appending AbfsOutputStream statistics to base toString().\n    *\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex b5467de06b7..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -465,7 +470,17 @@ public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n   }\n \n   /**\n-   * Appending AbfsOutputStream Statistics to base toString().\n+   * Getter to get the size of the task queue.\n+   *\n+   * @return the number of writeOperations in AbfsOutputStream.\n+   */\n+  @VisibleForTesting\n+  public int getWriteOperationsSize() {\n+    return writeOperations.size();\n+  }\n+\n+  /**\n+   * Appending AbfsOutputStream statistics to base toString().\n    *\n    * @return String with AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6974db92557..dff5897ea38 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -470,17 +464,7 @@ public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n   }\n \n   /**\n-   * Getter to get the size of the task queue.\n-   *\n-   * @return the number of writeOperations in AbfsOutputStream.\n-   */\n-  @VisibleForTesting\n-  public int getWriteOperationsSize() {\n-    return writeOperations.size();\n-  }\n-\n-  /**\n-   * Appending AbfsOutputStream statistics to base toString().\n+   * Appending AbfsOutputStream Statistics to base toString().\n    *\n    * @return String with AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex dff5897ea38..c55d5a2cc5f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -464,7 +468,7 @@ public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n   }\n \n   /**\n-   * Appending AbfsOutputStream Statistics to base toString().\n+   * Appending AbfsOutputStream statistics to base toString().\n    *\n    * @return String with AbfsOutputStream statistics.\n    */\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex c55d5a2cc5f..a47c31ad125 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -467,6 +468,16 @@ public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {\n     return (AbfsOutputStreamStatisticsImpl) outputStreamStatistics;\n   }\n \n+  /**\n+   * Getter to get the size of the task queue.\n+   *\n+   * @return the number of writeOperations in AbfsOutputStream.\n+   */\n+  @VisibleForTesting\n+  public int getWriteOperationsSize() {\n+    return writeOperations.size();\n+  }\n+\n   /**\n    * Appending AbfsOutputStream statistics to base toString().\n    *\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NzkzMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408177932", "body": "too vague a name and no obvious difference with assertEquals. \r\n\r\nPropose:\r\n*  leave existing test alone, \r\nand then one of\r\n* use Junit assertEquals()\r\n* or Assertions.assertThat(object).describedAs().equals().\r\n", "bodyText": "too vague a name and no obvious difference with assertEquals.\nPropose:\n\nleave existing test alone,\nand then one of\nuse Junit assertEquals()\nor Assertions.assertThat(object).describedAs().equals().", "bodyHTML": "<p dir=\"auto\">too vague a name and no obvious difference with assertEquals.</p>\n<p dir=\"auto\">Propose:</p>\n<ul dir=\"auto\">\n<li>leave existing test alone,<br>\nand then one of</li>\n<li>use Junit assertEquals()</li>\n<li>or Assertions.assertThat(object).describedAs().equals().</li>\n</ul>", "author": "steveloughran", "createdAt": "2020-04-14T14:24:44Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java", "diffHunk": "@@ -383,4 +391,34 @@ protected AbfsDelegationTokenManager getDelegationTokenManager()\n       throws IOException {\n     return getFileSystem().getDelegationTokenManager();\n   }\n+\n+  /**\n+   * Generic assert method.\n+   *\n+   * @param operation     operation being asserted.\n+   * @param expectedValue value that is expected.\n+   * @param actualValue   value that is actual.\n+   */\n+  protected void assertValues(String operation, long expectedValue,", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\nindex dab9b91e01f..4d9fc5cae73 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n", "chunk": "@@ -392,18 +392,6 @@ protected AbfsDelegationTokenManager getDelegationTokenManager()\n     return getFileSystem().getDelegationTokenManager();\n   }\n \n-  /**\n-   * Generic assert method.\n-   *\n-   * @param operation     operation being asserted.\n-   * @param expectedValue value that is expected.\n-   * @param actualValue   value that is actual.\n-   */\n-  protected void assertValues(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n-  }\n-\n   /**\n    * Generic create File and enabling AbfsOutputStream Flush.\n    *\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\nindex 4d9fc5cae73..dab9b91e01f 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n", "chunk": "@@ -392,6 +392,18 @@ protected AbfsDelegationTokenManager getDelegationTokenManager()\n     return getFileSystem().getDelegationTokenManager();\n   }\n \n+  /**\n+   * Generic assert method.\n+   *\n+   * @param operation     operation being asserted.\n+   * @param expectedValue value that is expected.\n+   * @param actualValue   value that is actual.\n+   */\n+  protected void assertValues(String operation, long expectedValue,\n+      long actualValue) {\n+    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n+  }\n+\n   /**\n    * Generic create File and enabling AbfsOutputStream Flush.\n    *\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\nindex dab9b91e01f..4d9fc5cae73 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n", "chunk": "@@ -392,18 +392,6 @@ protected AbfsDelegationTokenManager getDelegationTokenManager()\n     return getFileSystem().getDelegationTokenManager();\n   }\n \n-  /**\n-   * Generic assert method.\n-   *\n-   * @param operation     operation being asserted.\n-   * @param expectedValue value that is expected.\n-   * @param actualValue   value that is actual.\n-   */\n-  protected void assertValues(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n-  }\n-\n   /**\n    * Generic create File and enabling AbfsOutputStream Flush.\n    *\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODE5OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178198", "body": "nit: typo", "bodyText": "nit: typo", "bodyHTML": "<p dir=\"auto\">nit: typo</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:25:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -27,67 +26,73 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit Tests for AbfsOutputStream Statistics.\n+ * Unit tests for AbfsOutputStream statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check number of bytes failed to upload in\n+   * {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertValues(\"number fo bytes failed to upload\", 0,\n+    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Initializing again to reset the statistics.\n+    //Reset statistics for the next test.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    //Populating large random values for bytesFailed.\n-    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    /*\n+     * Entering multiple random values for bytesFailed to check correct\n+     * summation of values.\n+     */\n+    int expectedBytesFailed = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      expectedBytesFailed += randomBytesFailed;\n+    }\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    describe(\"Testing time Spent on waiting for task to be completed in \"\n+        + \"AbfsOutputStream\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -26,73 +27,67 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit tests for AbfsOutputStream statistics.\n+ * Unit Tests for AbfsOutputStream Statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n-  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check number of bytes failed to upload in\n-   * {@link AbfsOutputStream}.\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n+    assertValues(\"number fo bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\",\n-        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Reset statistics for the next test.\n+    //Initializing again to reset the statistics.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    /*\n-     * Entering multiple random values for bytesFailed to check correct\n-     * summation of values.\n-     */\n-    int expectedBytesFailed = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      expectedBytesFailed += randomBytesFailed;\n-    }\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\",\n-        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing time Spent on waiting for task to be completed in \"\n-        + \"AbfsOutputStream\");\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -27,67 +26,73 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit Tests for AbfsOutputStream Statistics.\n+ * Unit tests for AbfsOutputStream statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check number of bytes failed to upload in\n+   * {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertValues(\"number fo bytes failed to upload\", 0,\n+    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Initializing again to reset the statistics.\n+    //Reset statistics for the next test.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    //Populating large random values for bytesFailed.\n-    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    /*\n+     * Entering multiple random values for bytesFailed to check correct\n+     * summation of values.\n+     */\n+    int expectedBytesFailed = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      expectedBytesFailed += randomBytesFailed;\n+    }\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    describe(\"Testing time Spent on waiting for task to be completed in \"\n+        + \"AbfsOutputStream\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODMxMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178312", "body": "typo", "bodyText": "typo", "bodyHTML": "<p dir=\"auto\">typo</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:25:18Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -27,67 +26,73 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit Tests for AbfsOutputStream Statistics.\n+ * Unit tests for AbfsOutputStream statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check number of bytes failed to upload in\n+   * {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertValues(\"number fo bytes failed to upload\", 0,\n+    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Initializing again to reset the statistics.\n+    //Reset statistics for the next test.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    //Populating large random values for bytesFailed.\n-    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    /*\n+     * Entering multiple random values for bytesFailed to check correct\n+     * summation of values.\n+     */\n+    int expectedBytesFailed = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      expectedBytesFailed += randomBytesFailed;\n+    }\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    describe(\"Testing time Spent on waiting for task to be completed in \"\n+        + \"AbfsOutputStream\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -26,73 +27,67 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit tests for AbfsOutputStream statistics.\n+ * Unit Tests for AbfsOutputStream Statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n-  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check number of bytes failed to upload in\n-   * {@link AbfsOutputStream}.\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n+    assertValues(\"number fo bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\",\n-        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Reset statistics for the next test.\n+    //Initializing again to reset the statistics.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    /*\n-     * Entering multiple random values for bytesFailed to check correct\n-     * summation of values.\n-     */\n-    int expectedBytesFailed = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n-      expectedBytesFailed += randomBytesFailed;\n-    }\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertEquals(\"Mismatch in number of bytes failed to upload\",\n-        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing time Spent on waiting for task to be completed in \"\n-        + \"AbfsOutputStream\");\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -27,67 +26,73 @@\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n \n /**\n- * Unit Tests for AbfsOutputStream Statistics.\n+ * Unit tests for AbfsOutputStream statistics.\n  */\n public class TestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n \n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+  private static final int OPERATIONS = 10;\n \n   public TestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check number of bytes failed to upload in\n+   * {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamBytesFailed() {\n-    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+    describe(\"Testing number of bytes failed during upload in AbfsOutputSteam\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for zero bytes uploaded.\n-    assertValues(\"number fo bytes failed to upload\", 0,\n+    assertEquals(\"Mismatch in number of bytes failed to upload\", 0,\n         abfsOutputStreamStatistics.getBytesUploadFailed());\n \n     //Populating small random value for bytesFailed.\n     int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n     abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        randomBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n \n-    //Initializing again to reset the statistics.\n+    //Reset statistics for the next test.\n     abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-    //Populating large random values for bytesFailed.\n-    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    /*\n+     * Entering multiple random values for bytesFailed to check correct\n+     * summation of values.\n+     */\n+    int expectedBytesFailed = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      expectedBytesFailed += randomBytesFailed;\n+    }\n     //Test for bytes failed to upload.\n-    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n-        abfsOutputStreamStatistics.getBytesUploadFailed());\n+    assertEquals(\"Mismatch in number of bytes failed to upload\",\n+        expectedBytesFailed, abfsOutputStreamStatistics.getBytesUploadFailed());\n   }\n \n   /**\n    * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n    */\n   @Test\n   public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n-    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    describe(\"Testing time Spent on waiting for task to be completed in \"\n+        + \"AbfsOutputStream\");\n \n     AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n         new AbfsOutputStreamStatisticsImpl();\n \n     //Test for initial value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n \n     int smallRandomStartTime =\n         new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODQ5OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178498", "body": "nit: newline", "bodyText": "nit: newline", "bodyHTML": "<p dir=\"auto\">nit: newline</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:25:32Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+  }\n+\n+}", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,77 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue random times.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     *\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations and\n+     * checking summation.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..292ed644580 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -175,5 +175,4 @@ public void testAbfsOutputStreamQueueShrink() {\n         randomQueueValues * OPERATIONS,\n         abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n-\n }\n", "next_change": {"commit": "51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 292ed644580..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -161,15 +161,13 @@ public void testAbfsOutputStreamQueueShrink() {\n     /*\n      * Entering random values for queueShrunkOps and checking the correctness\n      * of summation for the statistic.\n-     *\n      */\n     int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n     for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n       abfsOutputStreamStatistics.queueShrunk();\n     }\n     /*\n-     * Test for random times incrementing queue shrunk operations and\n-     * checking summation.\n+     * Test for random times incrementing queue shrunk operations.\n      */\n     assertEquals(\"Mismatch in queue shrunk operations\",\n         randomQueueValues * OPERATIONS,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 58f00233710..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -103,74 +98,23 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering multiple values for timeSpentTaskWait() to check the\n-     * summation is happening correctly. Also calculating the expected result.\n-     */\n-    int expectedRandomDiff = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      int largeRandomStartTime =\n-          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-          + largeRandomStartTime;\n-      abfsOutputStreamStatistics\n-          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n-    }\n-\n-    /*\n-     * Test to check correct value of timeSpentTaskWait after multiple\n-     * random values are passed in it.\n-     */\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        expectedRandomDiff,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n   }\n \n-  /**\n-   * Unit Tests to check correct values of queue shrunk operations in\n-   * AbfsOutputStream.\n-   *\n-   */\n-  @Test\n-  public void testAbfsOutputStreamQueueShrink() {\n-    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n-\n-    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-        new AbfsOutputStreamStatisticsImpl();\n-\n-    //Test for shrinking queue zero time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    abfsOutputStreamStatistics.queueShrunk();\n-\n-    //Test for shrinking queue 1 time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering random values for queueShrunkOps and checking the correctness\n-     * of summation for the statistic.\n-     */\n-    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n-      abfsOutputStreamStatistics.queueShrunk();\n-    }\n-    /*\n-     * Test for random times incrementing queue shrunk operations.\n-     */\n-    assertEquals(\"Mismatch in queue shrunk operations\",\n-        randomQueueValues * OPERATIONS,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-  }\n-}\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,33 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-  }\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-}\n\\ No newline at end of file\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+}\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex ca082cf7042..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -132,4 +132,45 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n         expectedRandomDiff,\n         abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n   }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue 1 time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTA5MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179091", "body": "don't think we need capitals here", "bodyText": "don't think we need capitals here", "bodyHTML": "<p dir=\"auto\">don't think we need capitals here</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:26:17Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n+  private long writeCurrentBufferOperations;\n+\n+  /**\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n+   *\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes successfully uploaded through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded. Negative\n+   *              bytes are ignored.\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes failed to upload through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes failed to upload. Negative bytes are ignored.\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * Records the total time spent waiting for a task.\n+   * When the thread executor has a task\n+   * queue{@link java.util.concurrent.BlockingQueue} of size greater than or equal to 2\n+   * times the maxConcurrentRequestCounts then, it waits for a task in that\n+   * queue to finish, then do the next task in the queue.\n+   *\n+   * This time spent while waiting for the task to be completed is being\n+   * recorded in this counter.\n+   *\n+   * @param startTime time(in milliseconds) before the wait for task to be\n+   *                  completed is begin.\n+   * @param endTime   time(in milliseconds) after the wait for the task to be\n+   *                  completed is done.\n+   */\n+  @Override\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream try to remove the completed\n+   * write operations from the beginning of write operation FIFO queue.\n+   */\n+  @Override\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream writes the buffer to the\n+   * service via the AbfsClient and appends the buffer to the service.\n+   */\n+  @Override\n+  public void writeCurrentBuffer() {\n+    writeCurrentBufferOperations++;\n+  }\n+\n+  public long getBytesToUpload() {\n+    return bytesToUpload;\n+  }\n+\n+  public long getBytesUploadSuccessful() {\n+    return bytesUploadSuccessful;\n+  }\n+\n+  public long getBytesUploadFailed() {\n+    return bytesUploadFailed;\n+  }\n+\n+  public long getTimeSpendOnTaskWait() {\n+    return timeSpendOnTaskWait;\n+  }\n+\n+  public long getQueueShrunkOps() {\n+    return queueShrunkOps;\n+  }\n+\n+  public long getWriteCurrentBufferOperations() {\n+    return writeCurrentBufferOperations;\n+  }\n+\n+  /**\n+   * String to show AbfsOutputStream statistics values in AbfsOutputStream.\n+   *\n+   * @return String with AbfsOutputStream statistics.\n+   */\n+  @Override public String toString() {\n+    final StringBuilder outputStreamStats = new StringBuilder(\n+        \"OutputStream Statistics{\");\n+    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -161,15 +160,15 @@ public long getWriteCurrentBufferOperations() {\n   @Override public String toString() {\n     final StringBuilder outputStreamStats = new StringBuilder(\n         \"OutputStream Statistics{\");\n-    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);\n-    outputStreamStats.append(\", BYTES_UPLOAD_SUCCESSFUL=\")\n+    outputStreamStats.append(\", bytes_upload=\").append(bytesToUpload);\n+    outputStreamStats.append(\", bytes_upload_successfully=\")\n         .append(bytesUploadSuccessful);\n-    outputStreamStats.append(\", BYTES_UPLOAD_FAILED=\")\n+    outputStreamStats.append(\", bytes_upload_failed=\")\n         .append(bytesUploadFailed);\n-    outputStreamStats.append(\", TIME_SPEND_WAIT_TASK=\")\n-        .append(timeSpendOnTaskWait);\n-    outputStreamStats.append(\", QUEUE_SHRINK=\").append(queueShrunkOps);\n-    outputStreamStats.append(\", WRITE_CURRENT_BUFFER=\")\n+    outputStreamStats.append(\", time_spent_task_wait=\")\n+        .append(timeSpentOnTaskWait);\n+    outputStreamStats.append(\", queue_shrunk_ops=\").append(queueShrunkOps);\n+    outputStreamStats.append(\", write_current_buffer_ops=\")\n         .append(writeCurrentBufferOperations);\n     outputStreamStats.append(\"}\");\n     return outputStreamStats.toString();\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -160,15 +161,15 @@ public long getWriteCurrentBufferOperations() {\n   @Override public String toString() {\n     final StringBuilder outputStreamStats = new StringBuilder(\n         \"OutputStream Statistics{\");\n-    outputStreamStats.append(\", bytes_upload=\").append(bytesToUpload);\n-    outputStreamStats.append(\", bytes_upload_successfully=\")\n+    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);\n+    outputStreamStats.append(\", BYTES_UPLOAD_SUCCESSFUL=\")\n         .append(bytesUploadSuccessful);\n-    outputStreamStats.append(\", bytes_upload_failed=\")\n+    outputStreamStats.append(\", BYTES_UPLOAD_FAILED=\")\n         .append(bytesUploadFailed);\n-    outputStreamStats.append(\", time_spent_task_wait=\")\n-        .append(timeSpentOnTaskWait);\n-    outputStreamStats.append(\", queue_shrunk_ops=\").append(queueShrunkOps);\n-    outputStreamStats.append(\", write_current_buffer_ops=\")\n+    outputStreamStats.append(\", TIME_SPEND_WAIT_TASK=\")\n+        .append(timeSpendOnTaskWait);\n+    outputStreamStats.append(\", QUEUE_SHRINK=\").append(queueShrunkOps);\n+    outputStreamStats.append(\", WRITE_CURRENT_BUFFER=\")\n         .append(writeCurrentBufferOperations);\n     outputStreamStats.append(\"}\");\n     return outputStreamStats.toString();\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -161,15 +160,15 @@ public long getWriteCurrentBufferOperations() {\n   @Override public String toString() {\n     final StringBuilder outputStreamStats = new StringBuilder(\n         \"OutputStream Statistics{\");\n-    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);\n-    outputStreamStats.append(\", BYTES_UPLOAD_SUCCESSFUL=\")\n+    outputStreamStats.append(\", bytes_upload=\").append(bytesToUpload);\n+    outputStreamStats.append(\", bytes_upload_successfully=\")\n         .append(bytesUploadSuccessful);\n-    outputStreamStats.append(\", BYTES_UPLOAD_FAILED=\")\n+    outputStreamStats.append(\", bytes_upload_failed=\")\n         .append(bytesUploadFailed);\n-    outputStreamStats.append(\", TIME_SPEND_WAIT_TASK=\")\n-        .append(timeSpendOnTaskWait);\n-    outputStreamStats.append(\", QUEUE_SHRINK=\").append(queueShrunkOps);\n-    outputStreamStats.append(\", WRITE_CURRENT_BUFFER=\")\n+    outputStreamStats.append(\", time_spent_task_wait=\")\n+        .append(timeSpentOnTaskWait);\n+    outputStreamStats.append(\", queue_shrunk_ops=\").append(queueShrunkOps);\n+    outputStreamStats.append(\", write_current_buffer_ops=\")\n         .append(writeCurrentBufferOperations);\n     outputStreamStats.append(\"}\");\n     return outputStreamStats.toString();\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTU5Mw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179593", "body": "timeSpent", "bodyText": "timeSpent", "bodyHTML": "<p dir=\"auto\">timeSpent</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:26:58Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTczNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179735", "body": "typo", "bodyText": "typo", "bodyHTML": "<p dir=\"auto\">typo</p>", "author": "steveloughran", "createdAt": "2020-04-14T14:27:09Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,21 +27,23 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * Counter to get the total time spent while waiting for tasks to complete\n-   * in the blocking queue inside the thread executor.\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n    */\n-  private long timeSpentOnTaskWait;\n+  private long timeSpendOnTaskWait;\n   /**\n-   * Counter to get the total number of queue shrink operations done {@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n-   * remove the write operations which were successfully done by\n-   * AbfsOutputStream from the task queue.\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * Counter to get the total number of times the current buffer is written\n-   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the data store by AbfsRestOperation.\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -27,23 +27,21 @@\n   private long bytesUploadSuccessful;\n   private long bytesUploadFailed;\n   /**\n-   * counter to get the total time spent while waiting for tasks to complete\n-   * in the Blocking queue inside the thread executor.\n+   * Counter to get the total time spent while waiting for tasks to complete\n+   * in the blocking queue inside the thread executor.\n    */\n-  private long timeSpendOnTaskWait;\n+  private long timeSpentOnTaskWait;\n   /**\n-   * counter to get the total number of queue shrink operations done{@code\n-   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n-   * AbfsOutputStream to remove the write operations which were successfully\n-   * done by AbfsOutputStream from the Blocking Queue.\n+   * Counter to get the total number of queue shrink operations done {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by AbfsOutputStream to\n+   * remove the write operations which were successfully done by\n+   * AbfsOutputStream from the task queue.\n    */\n   private long queueShrunkOps;\n   /**\n-   * counter to get the total number of times the current buffer is written\n-   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n-   * AbfsClient and appended to the\n-   * Data store by\n-   * AbfsResOperation.\n+   * Counter to get the total number of times the current buffer is written\n+   * to the service {@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the data store by AbfsRestOperation.\n    */\n   private long writeCurrentBufferOperations;\n \n", "next_change": null}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}, {"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex cd5a29e217c..17b1f50c582 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -49,7 +51,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes total bytes to upload. Negative bytes are ignored.\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n", "chunk": "@@ -51,7 +49,7 @@\n    * Records the need to upload bytes and increments the total bytes that\n    * needs to be uploaded.\n    *\n-   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   * @param bytes total bytes to upload. Negative bytes are ignored.\n    */\n   @Override\n   public void bytesToUpload(long bytes) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4MTU2OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408181568", "body": "Remove bytes.", "bodyText": "Remove bytes.", "bodyHTML": "<p dir=\"auto\">Remove bytes.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T14:29:23Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n+  private long writeCurrentBufferOperations;\n+\n+  /**\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n+   *\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes successfully uploaded through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded. Negative\n+   *              bytes are ignored.\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes failed to upload through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes failed to upload. Negative bytes are ignored.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODI3NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408188275", "body": "No new line at the end. I think this will cause checkstyle issue.", "bodyText": "No new line at the end. I think this will cause checkstyle issue.", "bodyHTML": "<p dir=\"auto\">No new line at the end. I think this will cause checkstyle issue.</p>", "author": "mukund-thakur", "createdAt": "2020-04-14T14:38:04Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+  }\n+\n+}", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,77 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue random times.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     *\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations and\n+     * checking summation.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 9a76c2e27e6..292ed644580 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -175,5 +175,4 @@ public void testAbfsOutputStreamQueueShrink() {\n         randomQueueValues * OPERATIONS,\n         abfsOutputStreamStatistics.getQueueShrunkOps());\n   }\n-\n }\n", "next_change": {"commit": "51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 292ed644580..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -161,15 +161,13 @@ public void testAbfsOutputStreamQueueShrink() {\n     /*\n      * Entering random values for queueShrunkOps and checking the correctness\n      * of summation for the statistic.\n-     *\n      */\n     int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n     for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n       abfsOutputStreamStatistics.queueShrunk();\n     }\n     /*\n-     * Test for random times incrementing queue shrunk operations and\n-     * checking summation.\n+     * Test for random times incrementing queue shrunk operations.\n      */\n     assertEquals(\"Mismatch in queue shrunk operations\",\n         randomQueueValues * OPERATIONS,\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 58f00233710..7d313b0e46b 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -103,74 +98,23 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering multiple values for timeSpentTaskWait() to check the\n-     * summation is happening correctly. Also calculating the expected result.\n-     */\n-    int expectedRandomDiff = 0;\n-    for (int i = 0; i < OPERATIONS; i++) {\n-      int largeRandomStartTime =\n-          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-          + largeRandomStartTime;\n-      abfsOutputStreamStatistics\n-          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n-    }\n-\n-    /*\n-     * Test to check correct value of timeSpentTaskWait after multiple\n-     * random values are passed in it.\n-     */\n-    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n-        expectedRandomDiff,\n-        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n   }\n \n-  /**\n-   * Unit Tests to check correct values of queue shrunk operations in\n-   * AbfsOutputStream.\n-   *\n-   */\n-  @Test\n-  public void testAbfsOutputStreamQueueShrink() {\n-    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n-\n-    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n-        new AbfsOutputStreamStatisticsImpl();\n-\n-    //Test for shrinking queue zero time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    abfsOutputStreamStatistics.queueShrunk();\n-\n-    //Test for shrinking queue 1 time.\n-    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-\n-    //Reset statistics for the next test.\n-    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n-\n-    /*\n-     * Entering random values for queueShrunkOps and checking the correctness\n-     * of summation for the statistic.\n-     */\n-    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n-      abfsOutputStreamStatistics.queueShrunk();\n-    }\n-    /*\n-     * Test for random times incrementing queue shrunk operations.\n-     */\n-    assertEquals(\"Mismatch in queue shrunk operations\",\n-        randomQueueValues * OPERATIONS,\n-        abfsOutputStreamStatistics.getQueueShrunkOps());\n-  }\n-}\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..ca082cf7042 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -98,23 +103,33 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n     abfsOutputStreamStatistics\n         .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n     //Test for small random value of timeSpentWaitTask.\n-    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-\n-    int largeRandomStartTime =\n-        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n-    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n-        + largeRandomStartTime;\n-    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n-    abfsOutputStreamStatistics\n-        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n-      /*\n-      Test for large random value of timeSpentWaitTask plus the time spent\n-      waiting in previous test.\n-       */\n-    assertValues(\"Time spend on waiting for tasks to complete\",\n-        smallDiff + randomDiff,\n-        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n-  }\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        smallDiff, abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n \n-}\n\\ No newline at end of file\n+    /*\n+     * Entering multiple values for timeSpentTaskWait() to check the\n+     * summation is happening correctly. Also calculating the expected result.\n+     */\n+    int expectedRandomDiff = 0;\n+    for (int i = 0; i < OPERATIONS; i++) {\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      expectedRandomDiff += largeRandomEndTime - largeRandomStartTime;\n+    }\n+\n+    /*\n+     * Test to check correct value of timeSpentTaskWait after multiple\n+     * random values are passed in it.\n+     */\n+    assertEquals(\"Mismatch in time spent on waiting for tasks to complete\",\n+        expectedRandomDiff,\n+        abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n+  }\n+}\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex ca082cf7042..58f00233710 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n", "chunk": "@@ -132,4 +132,45 @@ public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n         expectedRandomDiff,\n         abfsOutputStreamStatistics.getTimeSpentOnTaskWait());\n   }\n+\n+  /**\n+   * Unit Tests to check correct values of queue shrunk operations in\n+   * AbfsOutputStream.\n+   *\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() {\n+    describe(\"Testing queue shrink operations by AbfsOutputStream\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for shrinking queue zero time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 0,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    abfsOutputStreamStatistics.queueShrunk();\n+\n+    //Test for shrinking queue 1 time.\n+    assertEquals(\"Mismatch in queue shrunk operations\", 1,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    //Reset statistics for the next test.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    /*\n+     * Entering random values for queueShrunkOps and checking the correctness\n+     * of summation for the statistic.\n+     */\n+    int randomQueueValues = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    for (int i = 0; i < randomQueueValues * OPERATIONS; i++) {\n+      abfsOutputStreamStatistics.queueShrunk();\n+    }\n+    /*\n+     * Test for random times incrementing queue shrunk operations.\n+     */\n+    assertEquals(\"Mismatch in queue shrunk operations\",\n+        randomQueueValues * OPERATIONS,\n+        abfsOutputStreamStatistics.getQueueShrunkOps());\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODk5MjE4OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408992189", "body": "Queue is not actually getting shrunk here, rather inside the while loop. I'll change this and the respective tests.", "bodyText": "Queue is not actually getting shrunk here, rather inside the while loop. I'll change this and the respective tests.", "bodyHTML": "<p dir=\"auto\">Queue is not actually getting shrunk here, rather inside the while loop. I'll change this and the respective tests.</p>", "author": "mehakmeet", "createdAt": "2020-04-15T16:56:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -384,6 +400,7 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    outputStreamStatistics.queueShrunk();", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex b5467de06b7..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -400,12 +404,13 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n+        // Incrementing statistics to indicate queue has been shrunk.\n+        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n", "next_change": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6974db92557..dff5897ea38 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -404,13 +399,12 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n-        // Incrementing statistics to indicate queue has been shrunk.\n-        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n", "next_change": {"commit": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex dff5897ea38..a47c31ad125 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n", "chunk": "@@ -399,12 +403,13 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n+        // Incrementing statistics to indicate queue has been shrunk.\n+        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n", "next_change": null}]}}]}}]}}, {"oid": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "url": "https://github.com/apache/hadoop/commit/e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-16T08:22:06Z", "type": "forcePushed"}, {"oid": "490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "url": "https://github.com/apache/hadoop/commit/490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-16T09:02:06Z", "type": "forcePushed"}, {"oid": "51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "url": "https://github.com/apache/hadoop/commit/51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-16T09:56:49Z", "type": "forcePushed"}, {"oid": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "url": "https://github.com/apache/hadoop/commit/01880f57c1ed21e208bb1c17330ac7b613c8b990", "message": "HADOOP-16914. fixing review comments", "committedDate": "2020-04-21T06:12:43Z", "type": "forcePushed"}, {"oid": "f0543e1bd0d994b6f284c825fffffe92ddd06218", "url": "https://github.com/apache/hadoop/commit/f0543e1bd0d994b6f284c825fffffe92ddd06218", "message": "HADOOP-16914. fixing review comments", "committedDate": "2020-04-22T07:03:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzcwODkwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r413708902", "body": "needs to go in with the org.apache block", "bodyText": "needs to go in with the org.apache block", "bodyHTML": "<p dir=\"auto\">needs to go in with the org.apache block</p>", "author": "steveloughran", "createdAt": "2020-04-23T10:42:15Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -51,6 +51,7 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import com.google.common.base.Strings;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;", "originalCommit": "73c4c69fec5a6ac3b19db1619e1e83c9354e24ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "changed_code": [{"header": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex 18e85ce99e5..6b194a41de2 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n", "chunk": "@@ -51,7 +51,6 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import com.google.common.base.Strings;\n-import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n", "next_change": null}]}}, {"oid": "745c377d1a0c57c845ce18298b999566379079a1", "url": "https://github.com/apache/hadoop/commit/745c377d1a0c57c845ce18298b999566379079a1", "message": "HADOOP-16914 AbfsOutputStream Counter\n\nChange-Id: Ie976f23c6c3e2f5cf9167794357cfc669a232c80", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "url": "https://github.com/apache/hadoop/commit/fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "message": "HADOOP-16914. review comments", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "url": "https://github.com/apache/hadoop/commit/b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "f98a76c746e68fce59593841e881387f7dd74b0d", "url": "https://github.com/apache/hadoop/commit/f98a76c746e68fce59593841e881387f7dd74b0d", "message": "HADOOP-16914. fixing review comments", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "424bb884bd9e96b3893075bcd8ef4158f4f8187b", "url": "https://github.com/apache/hadoop/commit/424bb884bd9e96b3893075bcd8ef4158f4f8187b", "message": "HADOOP-16914. Passing statistics through abfsOutputStreamContext", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "424bb884bd9e96b3893075bcd8ef4158f4f8187b", "url": "https://github.com/apache/hadoop/commit/424bb884bd9e96b3893075bcd8ef4158f4f8187b", "message": "HADOOP-16914. Passing statistics through abfsOutputStreamContext", "committedDate": "2020-04-23T10:47:46Z", "type": "forcePushed"}]}