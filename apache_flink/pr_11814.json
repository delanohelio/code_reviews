{"pr_number": 11814, "pr_title": "[FLINK-17218][tests] Adding recoverable failures and correctness chec\u2026", "pr_author": "AHeise", "pr_createdAt": "2020-04-20T06:27:47Z", "pr_url": "https://github.com/apache/flink/pull/11814", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwMjYzMA==", "url": "https://github.com/apache/flink/pull/11814#discussion_r415202630", "body": "Thanks for finding this bug!\r\n\r\nI think the root cause was the state inconsistency among `{leftOverLimit, leftOverStart}` with `leftOverData`. During `#clear()` we only reset `leftOverData` as null, but now reset the derived `{leftOverLimit, leftOverStart}` from `leftOverData`. So we have to check the condition only by `leftOverData` here. Another option is also to reset `{leftOverLimit, leftOverStart}` during `#clear()` to keep all consistency.", "bodyText": "Thanks for finding this bug!\nI think the root cause was the state inconsistency among {leftOverLimit, leftOverStart} with leftOverData. During #clear() we only reset leftOverData as null, but now reset the derived {leftOverLimit, leftOverStart} from leftOverData. So we have to check the condition only by leftOverData here. Another option is also to reset {leftOverLimit, leftOverStart} during #clear() to keep all consistency.", "bodyHTML": "<p dir=\"auto\">Thanks for finding this bug!</p>\n<p dir=\"auto\">I think the root cause was the state inconsistency among <code>{leftOverLimit, leftOverStart}</code> with <code>leftOverData</code>. During <code>#clear()</code> we only reset <code>leftOverData</code> as null, but now reset the derived <code>{leftOverLimit, leftOverStart}</code> from <code>leftOverData</code>. So we have to check the condition only by <code>leftOverData</code> here. Another option is also to reset <code>{leftOverLimit, leftOverStart}</code> during <code>#clear()</code> to keep all consistency.</p>", "author": "zhijiangW", "createdAt": "2020-04-26T03:26:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/serialization/SpillingAdaptiveSpanningRecordDeserializer.java", "diffHunk": "@@ -597,12 +597,12 @@ private void addNextChunkFromMemorySegment(MemorySegment segment, int offset, in\n \t\t\t\tthrow new UnsupportedOperationException(\"Unaligned checkpoint currently do not support spilled \" +\n \t\t\t\t\t\"records.\");\n \t\t\t} else if (recordLength != -1) {\n-\t\t\t\tint leftOverSize = leftOverLimit - leftOverStart;\n+\t\t\t\tint leftOverSize = leftOverData != null ? leftOverLimit - leftOverStart : 0;", "originalCommit": "42653324e6245cf58b547928f0b90d151fcf8f48", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTMwNzQ5OA==", "url": "https://github.com/apache/flink/pull/11814#discussion_r425307498", "body": "https://github.com/apache/flink/pull/8693 will add extra `notifyCheckpointAborted` that we could use here. I guess it's a race which PR is going to be merged first.", "bodyText": "#8693 will add extra notifyCheckpointAborted that we could use here. I guess it's a race which PR is going to be merged first.", "bodyHTML": "<p dir=\"auto\"><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"454679975\" data-permission-text=\"Title is private\" data-url=\"https://github.com/apache/flink/issues/8693\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/apache/flink/pull/8693/hovercard\" href=\"https://github.com/apache/flink/pull/8693\">#8693</a> will add extra <code>notifyCheckpointAborted</code> that we could use here. I guess it's a race which PR is going to be merged first.</p>", "author": "pnowojski", "createdAt": "2020-05-14T17:24:14Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -189,6 +188,7 @@ private void cleanup(\n \t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n \t\t\tException ex) throws Exception {\n \n+\t\tchannelStateWriter.abort(metadata.getCheckpointId(), ex);", "originalCommit": "2e688933309bb8c7476facd2b7e6a52da74ede67", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTMwNzc5OQ==", "url": "https://github.com/apache/flink/pull/11814#discussion_r425307799", "body": "nit: I guess it's no longer `notifyCheckpointComplete`, but `finishedWriting(...)`?", "bodyText": "nit: I guess it's no longer notifyCheckpointComplete, but finishedWriting(...)?", "bodyHTML": "<p dir=\"auto\">nit: I guess it's no longer <code>notifyCheckpointComplete</code>, but <code>finishedWriting(...)</code>?</p>", "author": "pnowojski", "createdAt": "2020-05-14T17:24:47Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -240,7 +240,8 @@ private void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snaps\n \t\tfinal Future<?> channelWrittenFuture;\n \t\tif (unalignedCheckpointEnabled) {\n \t\t\tChannelStateWriteResult writeResult = channelStateWriter.getWriteResult(metadata.getCheckpointId());\n-\t\t\tchannelWrittenFuture = writeResult.getJointFuture();\n+\t\t\tchannelWrittenFuture = writeResult.getJointFuture()\n+\t\t\t\t.whenComplete((dummy, ex) -> channelStateWriter.notifyCheckpointComplete(metadata.getCheckpointId()));", "originalCommit": "2e688933309bb8c7476facd2b7e6a52da74ede67", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTY1OTQwNQ==", "url": "https://github.com/apache/flink/pull/11814#discussion_r425659405", "bodyText": "I called it stop now (symmetric to start).", "author": "AHeise", "createdAt": "2020-05-15T08:52:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTMwNzc5OQ=="}], "type": "inlineReview"}, {"oid": "29aed91c6b7319398eb972ad51bd581e9f2e8ea8", "url": "https://github.com/apache/flink/commit/29aed91c6b7319398eb972ad51bd581e9f2e8ea8", "message": "[FLINK-17218][checkpointing] Ensuring that ChannelStateWriter aborts previous checkpoints before a new checkpoint is started.", "committedDate": "2020-05-15T08:54:02Z", "type": "commit"}, {"oid": "9ee814ce07ebc6054d06eaaa587f76a8e2bf51f8", "url": "https://github.com/apache/flink/commit/9ee814ce07ebc6054d06eaaa587f76a8e2bf51f8", "message": "[FLINK-17218][checkpointing] Cleaning up ChannelStateWriter state after all data has been written and after sync checkpoint failure.", "committedDate": "2020-05-15T08:54:02Z", "type": "commit"}, {"oid": "bd4011ecc3dc8bb29d4d365dcb00f0b7505b6832", "url": "https://github.com/apache/flink/commit/bd4011ecc3dc8bb29d4d365dcb00f0b7505b6832", "message": "[FLINK-17218][tests] Adding recoverable failures and correctness checks to UnalignedCheckpointITCase.", "committedDate": "2020-05-15T08:54:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTczNDA3OQ==", "url": "https://github.com/apache/flink/pull/11814#discussion_r425734079", "body": "I guess the below `Preconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);` might be invalid if we remove the old ones here?", "bodyText": "I guess the below Preconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints); might be invalid if we remove the old ones here?", "bodyHTML": "<p dir=\"auto\">I guess the below <code>Preconditions.checkState(results.size() &lt; maxCheckpoints, \"results.size() &gt; maxCheckpoints\", results.size(), maxCheckpoints);</code> might be invalid if we remove the old ones here?</p>", "author": "zhijiangW", "createdAt": "2020-05-15T11:17:38Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -91,6 +91,7 @@ public ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver)\n \n \t@Override\n \tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tresults.keySet().forEach(oldCheckpointId -> abort(oldCheckpointId, new Exception(\"Starting new checkpoint \" + checkpointId)));", "originalCommit": "bd4011ecc3dc8bb29d4d365dcb00f0b7505b6832", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk0MTU2OQ==", "url": "https://github.com/apache/flink/pull/11814#discussion_r425941569", "bodyText": "You are right that it's probably not needed. However, it's an inexpensive check that verifies the highlighted line.\nI'd keep the check for now.", "author": "AHeise", "createdAt": "2020-05-15T17:19:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTczNDA3OQ=="}], "type": "inlineReview"}]}