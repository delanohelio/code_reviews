{"pr_number": 13845, "pr_title": "[FLINK-19801] Adding virtual channels for rescaling unaligned checkpoints.", "pr_author": "AHeise", "pr_createdAt": "2020-10-29T15:28:43Z", "pr_url": "https://github.com/apache/flink/pull/13845", "merge_commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzI4Mg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163282", "body": "Here, `selector.getSubtaskIndex()` is expected to be **this** subtask old index, right? This is correct for the input channel state recovered on **this** subtask.\r\nBut, when the upstream sends its subpartition recovered data, it uses its own oldSubtaskIndex.", "bodyText": "Here, selector.getSubtaskIndex() is expected to be this subtask old index, right? This is correct for the input channel state recovered on this subtask.\nBut, when the upstream sends its subpartition recovered data, it uses its own oldSubtaskIndex.", "bodyHTML": "<p dir=\"auto\">Here, <code>selector.getSubtaskIndex()</code> is expected to be <strong>this</strong> subtask old index, right? This is correct for the input channel state recovered on <strong>this</strong> subtask.<br>\nBut, when the upstream sends its subpartition recovered data, it uses its own oldSubtaskIndex.</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:38:09Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyOTUxNg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519229516", "bodyText": "Yes that's mostly correct. That's why on subpartition recovery, the information subtask <=> subpartition index is swapped. Please note that I also renamed the fields of VirtualChannelSelector (inputSubtaskIndex and inputChannelIndex) to make it clearer.\n\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n\nsubpartitionInfo.getSubPartitionIdx() is set as the inputSubtaskIndex and oldSubtaskIndex is inputChannelIndex.", "author": "AHeise", "createdAt": "2020-11-07T22:51:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzI4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzQ1Mg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163452", "body": "nit: rename to `subtaskToDemultiplexer` to make the meaning of `Integer` clear?", "bodyText": "nit: rename to subtaskToDemultiplexer to make the meaning of Integer clear?", "bodyHTML": "<p dir=\"auto\">nit: rename to <code>subtaskToDemultiplexer</code> to make the meaning of <code>Integer</code> clear?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:39:59Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzcxNg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163716", "body": "Make it static?\r\nThis method is called from the constructor and refers to a field. This makes it error-prone because the field may not be initialized. ", "bodyText": "Make it static?\nThis method is called from the constructor and refers to a field. This makes it error-prone because the field may not be initialized.", "bodyHTML": "<p dir=\"auto\">Make it static?<br>\nThis method is called from the constructor and refers to a field. This makes it error-prone because the field may not be initialized.</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:43:36Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyODM1OQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519228359", "bodyText": "I inlined it in ctor. It's using an instance field and is called from SubtaskDemultplexer, so I don't see a good way to make it static.", "author": "AHeise", "createdAt": "2020-11-07T22:38:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzcxNg=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzgxMA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163810", "body": "Shouldn't we check here that the new watermark is higher than the old one?", "bodyText": "Shouldn't we check here that the new watermark is higher than the old one?", "bodyHTML": "<p dir=\"auto\">Shouldn't we check here that the new watermark is higher than the old one?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:44:28Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyODE4Mg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519228182", "bodyText": "There should not be any harm to write out the same watermark twice. (in fact most standard implementation of watermark emitter do not guarantee strict monotony). Performance impact should be rather small but we could optimize later.", "author": "AHeise", "createdAt": "2020-11-07T22:36:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MzgxMA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzg4MA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163880", "body": "```suggestion\r\n\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(StreamStatus::isActive)) {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n          \n          \n            \n            \t\t\t\t\tif (streamStatuses.values().stream().anyMatch(StreamStatus::isActive)) {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t\t<span class=\"pl-k\">if</span> (streamStatuses<span class=\"pl-k\">.</span>values()<span class=\"pl-k\">.</span>stream()<span class=\"pl-k\">.</span>anyMatch(<span class=\"x x-first\">s </span><span class=\"pl-k x\">-</span><span class=\"pl-k x\">&gt;</span><span class=\"x\"> s</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">equals(</span><span class=\"pl-smi\">StreamStatus</span><span class=\"pl-c1\"><span class=\"pl-k x x-first\">.</span><span class=\"x\">ACTIVE</span></span><span class=\"x x-last\">)</span>)) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t\t<span class=\"pl-k\">if</span> (streamStatuses<span class=\"pl-k\">.</span>values()<span class=\"pl-k\">.</span>stream()<span class=\"pl-k\">.</span>anyMatch(<span class=\"pl-smi\">StreamStatus</span><span class=\"pl-k x x-first\">::</span><span class=\"x x-last\">isActive</span>)) {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "rkhachatryan", "createdAt": "2020-11-07T10:45:01Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzk4Nw==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519163987", "body": "Is it intentional that filter is only applied to records?\r\nCan't watermarks be misinterpreted then?", "bodyText": "Is it intentional that filter is only applied to records?\nCan't watermarks be misinterpreted then?", "bodyHTML": "<p dir=\"auto\">Is it intentional that filter is only applied to records?<br>\nCan't watermarks be misinterpreted then?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:46:32Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNjU0OA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519226548", "bodyText": "The filter (ChannelSelector/Partitioner) can only deal with StreamRecord. Watermarks are interpreted differently. I'll add a comment.", "author": "AHeise", "createdAt": "2020-11-07T22:19:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2Mzk4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDYxMQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519164611", "body": "This delegate is shared across all the channels, but this is the only place where it's used.\r\nI think it's a bit risky. Why not create it in this method (`createFilter`)?", "bodyText": "This delegate is shared across all the channels, but this is the only place where it's used.\nI think it's a bit risky. Why not create it in this method (createFilter)?", "bodyHTML": "<p dir=\"auto\">This delegate is shared across all the channels, but this is the only place where it's used.<br>\nI think it's a bit risky. Why not create it in this method (<code>createFilter</code>)?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:54:17Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n+\t\t}\n+\t\treturn streamRecord -> {\n+\t\t\tdelegate.setInstance(streamRecord);", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNjkwMw==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519226903", "bodyText": "Since it's only used for the specific call inside the same thread it should be safe. However, it's cheap enough to create for each filter and it's probably much easier to reason about, so I changed it as you suggested.", "author": "AHeise", "createdAt": "2020-11-07T22:23:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDYxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDk0OQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519164949", "body": "Shouldn't it be old DOP (not `UPPER_BOUND_MAX_PARALLELISM`)?", "bodyText": "Shouldn't it be old DOP (not UPPER_BOUND_MAX_PARALLELISM)?", "bodyHTML": "<p dir=\"auto\">Shouldn't it be old DOP (not <code>UPPER_BOUND_MAX_PARALLELISM</code>)?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T10:57:18Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {\n+\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n+\n+\tvoid setNextBuffer(Buffer buffer) throws IOException;\n+\n+\tvoid select(VirtualChannelSelector event);\n+\n+\t@Override\n+\tvoid close();\n+}\n+\n+class NoDataDemultiplexer implements Demultiplexer {\n+\tprivate final InputChannelInfo channelInfo;\n+\n+\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n+\t\tthis.channelInfo = channelInfo;\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) {\n+\t\tthrow getException();\n+\t}\n+\n+\t@Override\n+\tpublic void select(VirtualChannelSelector event) {\n+\t\tthrow getException();\n+\t}\n+\n+\tprivate IllegalStateException getException() {\n+\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t}\n+}\n+\n+/**\n+ * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n+ */\n+class DemultiplexParameters {\n+\tfinal IOManager ioManager;\n+\tfinal InflightDataRescalingDescriptor channelMapping;\n+\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n+\tfinal SerializationDelegate<StreamRecord> delegate;\n+\tfinal int numberOfChannels;\n+\tfinal int subtaskIndex;\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tDemultiplexParameters(\n+\t\t\tTypeSerializer<?> inputSerializer,\n+\t\t\tIOManager ioManager,\n+\t\t\tInflightDataRescalingDescriptor channelMapping,\n+\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n+\t\t\tint numberOfChannels,\n+\t\t\tint subtaskIndex) {\n+\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n+\t\tthis.ioManager = ioManager;\n+\t\tthis.channelMapping = channelMapping;\n+\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n+\t\tthis.numberOfChannels = numberOfChannels;\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on subtask-level.\n+ *\n+ * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n+ * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n+ * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n+ *\n+ * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n+ * statuses of the (nested) virtual channels.\n+ */\n+class SubtaskDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n+\n+\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n+\n+\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n+\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n+\n+\tprivate VirtualChannelSelector currentSelector;\n+\n+\tprivate ChannelDemultiplexer selectedSubtask;\n+\n+\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n+\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n+\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n+\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n+\t\tselectedSubtask = defaultSelection.getValue();\n+\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n+\t\t\tselectedSubtask.selectedChannelIndex);\n+\n+\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n+\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n+\t\tgetChannelSelectors().forEach(selector -> {\n+\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n+\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tcurrentSelector = selector;\n+\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n+\t\tif (selectedSubtask == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t\tselectedSubtask.select(selector);\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedSubtask.setNextBuffer(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n+\n+\t\t\t// special handling of watermarks and stream status\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isWatermark()) {\n+\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n+\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n+\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n+\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n+\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n+\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n+\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n+\t\t\t\t\t\tcontinue;\n+\t\t\t\t\t}\n+\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n+\t\t\t\t} else if (element.isStreamStatus()) {\n+\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n+\t\t\t\t\t// summarize statuses across all virtual channels\n+\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n+\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n+\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is only re-executed for suppressed watermark\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void close() {\n+\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n+\t}\n+\n+\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n+\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n+\t\tif (oldSubtaskIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n+\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n+\t\tif (oldChannelIndexes.length == 0) {\n+\t\t\treturn new NoDataDemultiplexer(info);\n+\t\t}\n+\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n+\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tFunction.identity(),\n+\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n+\t\t\t));\n+\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"SubtaskDemultiplexer{\" +\n+\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n+\t\t\t'}';\n+\t}\n+}\n+\n+/**\n+ * Demultiplexes buffers on channel-level.\n+ *\n+ * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n+ * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n+ * with the respective old channels.\n+ *\n+ * <p>For all non-unique mappings of new channels to old channels (see\n+ * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n+ * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n+ * be processed at a different subtask.\n+ */\n+class ChannelDemultiplexer implements Demultiplexer {\n+\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n+\n+\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n+\n+\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n+\n+\tprivate final int subtaskIndex;\n+\n+\t@Nullable\n+\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n+\n+\tint selectedChannelIndex;\n+\n+\tChannelDemultiplexer(\n+\t\t\tint subtaskIndex,\n+\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tthis.subtaskIndex = subtaskIndex;\n+\t\tthis.filters = oldChannelsWithFilters;\n+\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n+\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n+\t\t\trecordDeserializersForChannels.put(oldChannel,\n+\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n+\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n+\t\t}\n+\n+\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n+\t\t\tselectedChannel = firstEntry.getValue();\n+\t\t\tselectedChannelIndex = firstEntry.getKey();\n+\t\t});\n+\t}\n+\n+\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n+\t\treturn recordDeserializersForChannels.keySet().stream()\n+\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n+\t}\n+\n+\t@Override\n+\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n+\t\tdo {\n+\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n+\n+\t\t\tif (result.isBufferConsumed()) {\n+\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n+\t\t\t}\n+\t\t\tif (result.isFullRecord()) {\n+\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n+\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn result;\n+\t\t\t// loop is re-executed for filtered full records.\n+\t\t} while (true);\n+\t}\n+\n+\tpublic void select(VirtualChannelSelector selector) {\n+\t\tselectedChannelIndex = selector.getChannelIndex();\n+\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n+\t\tif (selectedChannel == null) {\n+\t\t\tthrow new IllegalStateException(\n+\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n+\t\tselectedChannel.setNextBuffer(buffer);\n+\t}\n+\n+\tpublic void close() {\n+\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n+\t\t\trecordDeserializersForChannels.values()) {\n+\t\t\t// recycle buffers and clear the deserializer.\n+\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n+\t\t\tif (buffer != null && !buffer.isRecycled()) {\n+\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t}\n+\t\t\tdeserializer.clear();\n+\t\t}\n+\t}\n+\n+\tstatic ChannelDemultiplexer forChannel(\n+\t\t\tint subtaskIndex,\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tint totalChannels) {\n+\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n+\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n+\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n+\n+\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n+\t\t\tArrays.stream(oldChannels).boxed()\n+\t\t\t\t.collect(Collectors.toMap(\n+\t\t\t\t\tFunction.identity(),\n+\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n+\n+\t\treturn new ChannelDemultiplexer(\n+\t\t\tsubtaskIndex,\n+\t\t\toldChannelsWithFilters,\n+\t\t\tparameters,\n+\t\t\ttotalChannels);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> getFilterForChannel(\n+\t\t\tInputChannelInfo channelInfo,\n+\t\t\tDemultiplexParameters parameters,\n+\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n+\t\t\tInteger oldChannel) {\n+\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n+\t\t\tNO_FILTER :\n+\t\t\tcreateFilter(channelInfo, parameters);\n+\t}\n+\n+\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n+\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n+\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n+\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n+\t\tpartitioner.setup(parameters.numberOfChannels);\n+\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n+\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNzQxMg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519227412", "bodyText": "Don't ask me who came up with the great method names, but configure is only used to set the max parallelism of KeyGroupStreamPartitioner. Only the method setup is used to set the real parallelism but must be the new DOP here.", "author": "AHeise", "createdAt": "2020-11-07T22:29:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NDk0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTMyOQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519165329", "body": "Can't we use just `Map<InputChannelInfo, Demultiplexer>` instead of this map and `channelDemultiplexers` array?", "bodyText": "Can't we use just Map<InputChannelInfo, Demultiplexer> instead of this map and channelDemultiplexers array?", "bodyHTML": "<p dir=\"auto\">Can't we use just <code>Map&lt;InputChannelInfo, Demultiplexer&gt;</code> instead of this map and <code>channelDemultiplexers</code> array?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:02:00Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n+\n+\tprivate final CheckpointedInputGate checkpointedInputGate;\n+\n+\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n+\n+\tprivate final Demultiplexer[] channelDemultiplexers;\n+\n+\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n+\tprivate final StatusWatermarkValve statusWatermarkValve;\n+\n+\tprivate final int inputIndex;\n+\n+\tprivate final Map<InputChannelInfo, Integer> channelIndexes;", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNzg3Nw==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519227877", "bodyText": "StatusWatermarkValve operators on indexes, so we need this indirection. We should probably refactor that (it's the same in StreamTaskNetworkInput).", "author": "AHeise", "createdAt": "2020-11-07T22:33:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTMyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 3794274cf8c..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,283 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-\n-import static org.apache.flink.util.Preconditions.checkNotNull;\n-import static org.apache.flink.util.Preconditions.checkState;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases.\n- * <ul>\n- *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n- * relevant to keyed exchanges).\n- * </ul>\n- * In both cases, records from multiple old channels are received over one new physical channel, which need to\n- * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n- * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n- * virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n-\n-\tprivate final CheckpointedInputGate checkpointedInputGate;\n-\n-\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n-\n-\tprivate final Demultiplexer[] channelDemultiplexers;\n-\n-\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n-\tprivate final StatusWatermarkValve statusWatermarkValve;\n-\n-\tprivate final int inputIndex;\n-\n-\tprivate final Map<InputChannelInfo, Integer> channelIndexes;\n-\n-\tprivate final TypeSerializer<?> inputSerializer;\n-\tprivate final IOManager ioManager;\n-\n-\t@Nullable\n-\tprivate Demultiplexer currentChannelDemultiplexer = null;\n-\tprivate int lastChannel;\n-\n-\tprivate RescalingStreamTaskNetworkInput(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\tthis.checkpointedInputGate = checkpointedInputGate;\n-\t\tthis.inputSerializer = inputSerializer;\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.deserializationDelegate = new NonReusingDeserializationDelegate<>(\n-\t\t\tnew StreamElementSerializer<>(inputSerializer));\n-\n-\t\tthis.statusWatermarkValve = checkNotNull(statusWatermarkValve);\n-\t\tthis.inputIndex = inputIndex;\n-\t\tthis.channelIndexes = getChannelIndexes(checkpointedInputGate);\n-\n-\t\tMap<Integer, StreamPartitioner<?>> partitionerCache = new HashMap<>();\n-\t\tfinal DemultiplexParameters parameters = new DemultiplexParameters(\n-\t\t\tinputSerializer,\n-\t\t\tioManager,\n-\t\t\tinflightDataRescalingDescriptor,\n-\t\t\tgateIndex -> partitionerCache.computeIfAbsent(gateIndex, inputPartitionerRetriever),\n-\t\t\tchannelIndexes.size(),\n-\t\t\tsubtaskIndex);\n-\t\tthis.channelDemultiplexers = this.checkpointedInputGate.getChannelInfos().stream()\n-\t\t\t.map(channelInfo -> SubtaskDemultiplexer.forChannel(channelInfo, parameters))\n-\t\t\t.toArray(Demultiplexer[]::new);\n-\t}\n-\n-\t@Override\n-\tpublic StreamTaskInput<T> finishRecovery() {\n-\t\tclose();\n-\t\treturn new StreamTaskNetworkInput<>(checkpointedInputGate, inputSerializer, ioManager, statusWatermarkValve, inputIndex);\n-\t}\n-\n-\tprivate static Map<InputChannelInfo, Integer> getChannelIndexes(CheckpointedInputGate checkpointedInputGate) {\n-\t\tint index = 0;\n-\t\tList<InputChannelInfo> channelInfos = checkpointedInputGate.getChannelInfos();\n-\t\tMap<InputChannelInfo, Integer> channelIndexes = new HashMap<>(channelInfos.size());\n-\t\tfor (InputChannelInfo channelInfo : channelInfos) {\n-\t\t\tchannelIndexes.put(channelInfo, index++);\n-\t\t}\n-\t\treturn channelIndexes;\n-\t}\n-\n-\t/**\n-\t * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput} depending on {@link InflightDataRescalingDescriptor}.\n-\t */\n-\tpublic static <T> StreamTaskInput<T> of(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\treturn rescalingDescriptorinflightDataRescalingDescriptor.equals(InflightDataRescalingDescriptor.NO_RESCALE) ?\n-\t\t\tnew StreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex) :\n-\t\t\tnew RescalingStreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex,\n-\t\t\t\trescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\t\tinputPartitionerRetriever,\n-\t\t\t\tsubtaskIndex);\n-\t}\n-\n-\t@Override\n-\tpublic InputStatus emitNext(DataOutput<T> output) throws Exception {\n-\n-\t\twhile (true) {\n-\t\t\t// get the stream element from the deserializer\n-\t\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\t\tDeserializationResult result = currentChannelDemultiplexer.getNextRecord(deserializationDelegate);\n-\n-\t\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\t\tcurrentChannelDemultiplexer = null;\n-\t\t\t\t}\n-\n-\t\t\t\tif (result.isFullRecord()) {\n-\t\t\t\t\tprocessElement(deserializationDelegate.getInstance(), output);\n-\t\t\t\t\treturn InputStatus.MORE_AVAILABLE;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\tOptional<BufferOrEvent> bufferOrEvent = checkpointedInputGate.pollNext();\n-\t\t\tif (bufferOrEvent.isPresent()) {\n-\t\t\t\t// return to the mailbox after receiving a checkpoint barrier to avoid processing of\n-\t\t\t\t// data after the barrier before checkpoint is performed for unaligned checkpoint mode\n-\t\t\t\tif (bufferOrEvent.get().isBuffer()) {\n-\t\t\t\t\tprocessBuffer(bufferOrEvent.get());\n-\t\t\t\t} else {\n-\t\t\t\t\treturn processEvent(bufferOrEvent.get());\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tif (checkpointedInputGate.isFinished()) {\n-\t\t\t\t\tcheckState(checkpointedInputGate.getAvailableFuture().isDone(), \"Finished BarrierHandler should be available\");\n-\t\t\t\t\treturn InputStatus.END_OF_INPUT;\n-\t\t\t\t}\n-\t\t\t\treturn InputStatus.NOTHING_AVAILABLE;\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tprivate void processElement(StreamElement recordOrMark, DataOutput<T> output) throws Exception {\n-\t\tif (recordOrMark.isRecord()){\n-\t\t\toutput.emitRecord(recordOrMark.asRecord());\n-\t\t} else if (recordOrMark.isWatermark()) {\n-\t\t\tstatusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), lastChannel, output);\n-\t\t} else if (recordOrMark.isLatencyMarker()) {\n-\t\t\toutput.emitLatencyMarker(recordOrMark.asLatencyMarker());\n-\t\t} else if (recordOrMark.isStreamStatus()) {\n-\t\t\tstatusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), lastChannel, output);\n-\t\t} else {\n-\t\t\tthrow new UnsupportedOperationException(\"Unknown type of StreamElement\");\n-\t\t}\n-\t}\n-\n-\tprivate InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-\t\t// Event received\n-\t\tfinal AbstractEvent event = bufferOrEvent.getEvent();\n-\t\tif (event instanceof VirtualChannelSelector) {\n-\t\t\tint channel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\t\tcheckState(channel != StreamTaskInput.UNSPECIFIED);\n-\t\t\tthis.channelDemultiplexers[channel].select((VirtualChannelSelector) event);\n-\t\t} else if (event.getClass() == EndOfPartitionEvent.class) {\n-\t\t\t// release the record deserializer immediately,\n-\t\t\t// which is very valuable in case of bounded stream\n-\t\t\treleaseDeserializer(channelIndexes.get(bufferOrEvent.getChannelInfo()));\n-\t\t} else if (event.getClass() == EndOfChannelStateEvent.class) {\n-\t\t\treturn InputStatus.END_OF_RECOVERY;\n-\t\t}\n-\t\treturn InputStatus.MORE_AVAILABLE;\n-\t}\n-\n-\tprivate void processBuffer(BufferOrEvent bufferOrEvent) throws IOException {\n-\t\tlastChannel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\tcheckState(lastChannel != StreamTaskInput.UNSPECIFIED);\n-\t\tcurrentChannelDemultiplexer = this.channelDemultiplexers[lastChannel];\n-\t\tcheckState(\n-\t\t\tcurrentChannelDemultiplexer != null,\n-\t\t\t\"currentRecordDeserializer has already been released\");\n-\n-\t\tcurrentChannelDemultiplexer.setNextBuffer(bufferOrEvent.getBuffer());\n-\t}\n-\n-\t@Override\n-\tpublic int getInputIndex() {\n-\t\treturn inputIndex;\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<?> getAvailableFuture() {\n-\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\treturn AVAILABLE;\n-\t\t}\n-\t\treturn checkpointedInputGate.getAvailableFuture();\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<Void> prepareSnapshot(ChannelStateWriter channelStateWriter, long checkpointId) {\n-\t\tthrow new IllegalStateException(\"Tasks with inputs should not start checkpointing during recovery (rejected in CheckpointedInputGate).\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t\t// release the deserializers . this part should not ever fail\n-\t\tfor (int channelIndex = 0; channelIndex < channelDemultiplexers.length; channelIndex++) {\n-\t\t\treleaseDeserializer(channelIndex);\n-\t\t}\n-\t}\n-\n-\tprivate void releaseDeserializer(int channelIndex) {\n-\t\tDemultiplexer demultiplexer = channelDemultiplexers[channelIndex];\n-\t\tif (demultiplexer != null) {\n-\t\t\tdemultiplexer.close();\n-\n-\t\t\tchannelDemultiplexers[channelIndex] = null;\n-\t\t}\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 3794274cf8c..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,283 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-\n-import static org.apache.flink.util.Preconditions.checkNotNull;\n-import static org.apache.flink.util.Preconditions.checkState;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases.\n- * <ul>\n- *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n- * relevant to keyed exchanges).\n- * </ul>\n- * In both cases, records from multiple old channels are received over one new physical channel, which need to\n- * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n- * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n- * virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n-\n-\tprivate final CheckpointedInputGate checkpointedInputGate;\n-\n-\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n-\n-\tprivate final Demultiplexer[] channelDemultiplexers;\n-\n-\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n-\tprivate final StatusWatermarkValve statusWatermarkValve;\n-\n-\tprivate final int inputIndex;\n-\n-\tprivate final Map<InputChannelInfo, Integer> channelIndexes;\n-\n-\tprivate final TypeSerializer<?> inputSerializer;\n-\tprivate final IOManager ioManager;\n-\n-\t@Nullable\n-\tprivate Demultiplexer currentChannelDemultiplexer = null;\n-\tprivate int lastChannel;\n-\n-\tprivate RescalingStreamTaskNetworkInput(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\tthis.checkpointedInputGate = checkpointedInputGate;\n-\t\tthis.inputSerializer = inputSerializer;\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.deserializationDelegate = new NonReusingDeserializationDelegate<>(\n-\t\t\tnew StreamElementSerializer<>(inputSerializer));\n-\n-\t\tthis.statusWatermarkValve = checkNotNull(statusWatermarkValve);\n-\t\tthis.inputIndex = inputIndex;\n-\t\tthis.channelIndexes = getChannelIndexes(checkpointedInputGate);\n-\n-\t\tMap<Integer, StreamPartitioner<?>> partitionerCache = new HashMap<>();\n-\t\tfinal DemultiplexParameters parameters = new DemultiplexParameters(\n-\t\t\tinputSerializer,\n-\t\t\tioManager,\n-\t\t\tinflightDataRescalingDescriptor,\n-\t\t\tgateIndex -> partitionerCache.computeIfAbsent(gateIndex, inputPartitionerRetriever),\n-\t\t\tchannelIndexes.size(),\n-\t\t\tsubtaskIndex);\n-\t\tthis.channelDemultiplexers = this.checkpointedInputGate.getChannelInfos().stream()\n-\t\t\t.map(channelInfo -> SubtaskDemultiplexer.forChannel(channelInfo, parameters))\n-\t\t\t.toArray(Demultiplexer[]::new);\n-\t}\n-\n-\t@Override\n-\tpublic StreamTaskInput<T> finishRecovery() {\n-\t\tclose();\n-\t\treturn new StreamTaskNetworkInput<>(checkpointedInputGate, inputSerializer, ioManager, statusWatermarkValve, inputIndex);\n-\t}\n-\n-\tprivate static Map<InputChannelInfo, Integer> getChannelIndexes(CheckpointedInputGate checkpointedInputGate) {\n-\t\tint index = 0;\n-\t\tList<InputChannelInfo> channelInfos = checkpointedInputGate.getChannelInfos();\n-\t\tMap<InputChannelInfo, Integer> channelIndexes = new HashMap<>(channelInfos.size());\n-\t\tfor (InputChannelInfo channelInfo : channelInfos) {\n-\t\t\tchannelIndexes.put(channelInfo, index++);\n-\t\t}\n-\t\treturn channelIndexes;\n-\t}\n-\n-\t/**\n-\t * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput} depending on {@link InflightDataRescalingDescriptor}.\n-\t */\n-\tpublic static <T> StreamTaskInput<T> of(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\treturn rescalingDescriptorinflightDataRescalingDescriptor.equals(InflightDataRescalingDescriptor.NO_RESCALE) ?\n-\t\t\tnew StreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex) :\n-\t\t\tnew RescalingStreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex,\n-\t\t\t\trescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\t\tinputPartitionerRetriever,\n-\t\t\t\tsubtaskIndex);\n-\t}\n-\n-\t@Override\n-\tpublic InputStatus emitNext(DataOutput<T> output) throws Exception {\n-\n-\t\twhile (true) {\n-\t\t\t// get the stream element from the deserializer\n-\t\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\t\tDeserializationResult result = currentChannelDemultiplexer.getNextRecord(deserializationDelegate);\n-\n-\t\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\t\tcurrentChannelDemultiplexer = null;\n-\t\t\t\t}\n-\n-\t\t\t\tif (result.isFullRecord()) {\n-\t\t\t\t\tprocessElement(deserializationDelegate.getInstance(), output);\n-\t\t\t\t\treturn InputStatus.MORE_AVAILABLE;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\tOptional<BufferOrEvent> bufferOrEvent = checkpointedInputGate.pollNext();\n-\t\t\tif (bufferOrEvent.isPresent()) {\n-\t\t\t\t// return to the mailbox after receiving a checkpoint barrier to avoid processing of\n-\t\t\t\t// data after the barrier before checkpoint is performed for unaligned checkpoint mode\n-\t\t\t\tif (bufferOrEvent.get().isBuffer()) {\n-\t\t\t\t\tprocessBuffer(bufferOrEvent.get());\n-\t\t\t\t} else {\n-\t\t\t\t\treturn processEvent(bufferOrEvent.get());\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tif (checkpointedInputGate.isFinished()) {\n-\t\t\t\t\tcheckState(checkpointedInputGate.getAvailableFuture().isDone(), \"Finished BarrierHandler should be available\");\n-\t\t\t\t\treturn InputStatus.END_OF_INPUT;\n-\t\t\t\t}\n-\t\t\t\treturn InputStatus.NOTHING_AVAILABLE;\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tprivate void processElement(StreamElement recordOrMark, DataOutput<T> output) throws Exception {\n-\t\tif (recordOrMark.isRecord()){\n-\t\t\toutput.emitRecord(recordOrMark.asRecord());\n-\t\t} else if (recordOrMark.isWatermark()) {\n-\t\t\tstatusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), lastChannel, output);\n-\t\t} else if (recordOrMark.isLatencyMarker()) {\n-\t\t\toutput.emitLatencyMarker(recordOrMark.asLatencyMarker());\n-\t\t} else if (recordOrMark.isStreamStatus()) {\n-\t\t\tstatusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), lastChannel, output);\n-\t\t} else {\n-\t\t\tthrow new UnsupportedOperationException(\"Unknown type of StreamElement\");\n-\t\t}\n-\t}\n-\n-\tprivate InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-\t\t// Event received\n-\t\tfinal AbstractEvent event = bufferOrEvent.getEvent();\n-\t\tif (event instanceof VirtualChannelSelector) {\n-\t\t\tint channel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\t\tcheckState(channel != StreamTaskInput.UNSPECIFIED);\n-\t\t\tthis.channelDemultiplexers[channel].select((VirtualChannelSelector) event);\n-\t\t} else if (event.getClass() == EndOfPartitionEvent.class) {\n-\t\t\t// release the record deserializer immediately,\n-\t\t\t// which is very valuable in case of bounded stream\n-\t\t\treleaseDeserializer(channelIndexes.get(bufferOrEvent.getChannelInfo()));\n-\t\t} else if (event.getClass() == EndOfChannelStateEvent.class) {\n-\t\t\treturn InputStatus.END_OF_RECOVERY;\n-\t\t}\n-\t\treturn InputStatus.MORE_AVAILABLE;\n-\t}\n-\n-\tprivate void processBuffer(BufferOrEvent bufferOrEvent) throws IOException {\n-\t\tlastChannel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\tcheckState(lastChannel != StreamTaskInput.UNSPECIFIED);\n-\t\tcurrentChannelDemultiplexer = this.channelDemultiplexers[lastChannel];\n-\t\tcheckState(\n-\t\t\tcurrentChannelDemultiplexer != null,\n-\t\t\t\"currentRecordDeserializer has already been released\");\n-\n-\t\tcurrentChannelDemultiplexer.setNextBuffer(bufferOrEvent.getBuffer());\n-\t}\n-\n-\t@Override\n-\tpublic int getInputIndex() {\n-\t\treturn inputIndex;\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<?> getAvailableFuture() {\n-\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\treturn AVAILABLE;\n-\t\t}\n-\t\treturn checkpointedInputGate.getAvailableFuture();\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<Void> prepareSnapshot(ChannelStateWriter channelStateWriter, long checkpointId) {\n-\t\tthrow new IllegalStateException(\"Tasks with inputs should not start checkpointing during recovery (rejected in CheckpointedInputGate).\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t\t// release the deserializers . this part should not ever fail\n-\t\tfor (int channelIndex = 0; channelIndex < channelDemultiplexers.length; channelIndex++) {\n-\t\t\treleaseDeserializer(channelIndex);\n-\t\t}\n-\t}\n-\n-\tprivate void releaseDeserializer(int channelIndex) {\n-\t\tDemultiplexer demultiplexer = channelDemultiplexers[channelIndex];\n-\t\tif (demultiplexer != null) {\n-\t\t\tdemultiplexer.close();\n-\n-\t\t\tchannelDemultiplexers[channelIndex] = null;\n-\t\t}\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTQ2NA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519165464", "body": "According to javadoc above, it's a type of `RecordDeserializer`, just not explicitly implementing it.\r\nSo the name `DemultiplexingRecordDeserializer` would make more sense to me.", "bodyText": "According to javadoc above, it's a type of RecordDeserializer, just not explicitly implementing it.\nSo the name DemultiplexingRecordDeserializer would make more sense to me.", "bodyHTML": "<p dir=\"auto\">According to javadoc above, it's a type of <code>RecordDeserializer</code>, just not explicitly implementing it.<br>\nSo the name <code>DemultiplexingRecordDeserializer</code> would make more sense to me.</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:03:51Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java", "diffHunk": "@@ -0,0 +1,402 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n+ * non-recovery hotpath, this interface is not extending RecordDeserializer.\n+ */\n+interface Demultiplexer extends AutoCloseable {", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyODY3Mg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519228672", "bodyText": "Good idea. Would it be okay to keep the implementation names as is to avoid super-long names?", "author": "AHeise", "createdAt": "2020-11-07T22:41:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2NTQ2NA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\ndeleted file mode 100644\nindex df6d5a5e04d..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/Demultiplexer.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;\n-import org.apache.flink.streaming.api.watermark.Watermark;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Iterables;\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-\n-/**\n- * {@link RecordDeserializer}-like interface for recovery. To avoid additional virtual method calls on the\n- * non-recovery hotpath, this interface is not extending RecordDeserializer.\n- */\n-interface Demultiplexer extends AutoCloseable {\n-\tRecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException;\n-\n-\tvoid setNextBuffer(Buffer buffer) throws IOException;\n-\n-\tvoid select(VirtualChannelSelector event);\n-\n-\t@Override\n-\tvoid close();\n-}\n-\n-class NoDataDemultiplexer implements Demultiplexer {\n-\tprivate final InputChannelInfo channelInfo;\n-\n-\tpublic NoDataDemultiplexer(InputChannelInfo channelInfo) {\n-\t\tthis.channelInfo = channelInfo;\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) {\n-\t\tthrow getException();\n-\t}\n-\n-\t@Override\n-\tpublic void select(VirtualChannelSelector event) {\n-\t\tthrow getException();\n-\t}\n-\n-\tprivate IllegalStateException getException() {\n-\t\treturn new IllegalStateException(channelInfo + \" should not receive any data/events during recovery\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t}\n-}\n-\n-/**\n- * Parameter structure to pass all relevant information to the factory methods of @{@link Demultiplexer}.\n- */\n-class DemultiplexParameters {\n-\tfinal IOManager ioManager;\n-\tfinal InflightDataRescalingDescriptor channelMapping;\n-\tfinal Function<Integer, StreamPartitioner<?>> gatePartitionerRetriever;\n-\tfinal SerializationDelegate<StreamRecord> delegate;\n-\tfinal int numberOfChannels;\n-\tfinal int subtaskIndex;\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tDemultiplexParameters(\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tInflightDataRescalingDescriptor channelMapping,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> gatePartitionerRetriever,\n-\t\t\tint numberOfChannels,\n-\t\t\tint subtaskIndex) {\n-\t\tdelegate = new SerializationDelegate<>((TypeSerializer<StreamRecord>) inputSerializer);\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.gatePartitionerRetriever = gatePartitionerRetriever;\n-\t\tthis.numberOfChannels = numberOfChannels;\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on subtask-level.\n- *\n- * <p>Example: If the current task has been downscaled from 2 to 1. Then the only new subtask needs to handle data\n- * originating from old subtasks 0 and 1. In this case, {@link #demultiplexersForSubtasks} contains\n- * {@code 0->ChannelDemultiplexer0, 1->ChannelDemultiplexer1}.\n- *\n- * <p>Since this the outer demultiplexing layer, it is also responsible for summarizing watermark and stream\n- * statuses of the (nested) virtual channels.\n- */\n-class SubtaskDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks;\n-\n-\t/** Keep track of the last emitted watermark for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, Watermark> lastWatermarks;\n-\n-\t/** Keep track of the last emitted stream status for all (nested) virtual channels. */\n-\tprivate final Map<VirtualChannelSelector, StreamStatus> streamStatuses;\n-\n-\tprivate VirtualChannelSelector currentSelector;\n-\n-\tprivate ChannelDemultiplexer selectedSubtask;\n-\n-\tpublic SubtaskDemultiplexer(Map<Integer, ChannelDemultiplexer> demultiplexersForSubtasks, int totalChannels) {\n-\t\tthis.demultiplexersForSubtasks = demultiplexersForSubtasks;\n-\t\tfinal Map.Entry<Integer, ChannelDemultiplexer> defaultSelection =\n-\t\t\tIterables.get(demultiplexersForSubtasks.entrySet(), 0);\n-\t\tselectedSubtask = defaultSelection.getValue();\n-\t\tcurrentSelector = new VirtualChannelSelector(defaultSelection.getKey(),\n-\t\t\tselectedSubtask.selectedChannelIndex);\n-\n-\t\t// initialize watermarks and streamStatuses for all nested virtual channels\n-\t\tthis.lastWatermarks = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tthis.streamStatuses = Maps.newHashMapWithExpectedSize(totalChannels);\n-\t\tgetChannelSelectors().forEach(selector -> {\n-\t\t\tlastWatermarks.put(selector, Watermark.UNINITIALIZED);\n-\t\t\tstreamStatuses.put(selector, StreamStatus.ACTIVE);\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn demultiplexersForSubtasks.values().stream().flatMap(ChannelDemultiplexer::getChannelSelectors);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tcurrentSelector = selector;\n-\t\tselectedSubtask = demultiplexersForSubtasks.get(selector.getSubtaskIndex());\n-\t\tif (selectedSubtask == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t\tselectedSubtask.select(selector);\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedSubtask.setNextBuffer(buffer);\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tRecordDeserializer.DeserializationResult result = selectedSubtask.getNextRecord(deserializationDelegate);\n-\n-\t\t\t// special handling of watermarks and stream status\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isWatermark()) {\n-\t\t\t\t\t// basically, do not emit a watermark if not all virtual channel are past it\n-\t\t\t\t\tlastWatermarks.put(currentSelector, element.asWatermark());\n-\t\t\t\t\tfinal Watermark minWatermark = lastWatermarks.values().stream()\n-\t\t\t\t\t\t.min(Comparator.comparing(Watermark::getTimestamp))\n-\t\t\t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Should always have a min watermark\"));\n-\t\t\t\t\t// at least one virtual channel has no watermark, so don't emit any watermark yet\n-\t\t\t\t\tif (minWatermark.equals(Watermark.UNINITIALIZED)) {\n-\t\t\t\t\t\tcontinue;\n-\t\t\t\t\t}\n-\t\t\t\t\tdeserializationDelegate.setInstance(minWatermark);\n-\t\t\t\t} else if (element.isStreamStatus()) {\n-\t\t\t\t\tstreamStatuses.put(currentSelector, element.asStreamStatus());\n-\t\t\t\t\t// summarize statuses across all virtual channels\n-\t\t\t\t\t// duplicate statuses are filtered in StatusWatermarkValve\n-\t\t\t\t\tif (streamStatuses.values().stream().anyMatch(s -> s.equals(StreamStatus.ACTIVE))) {\n-\t\t\t\t\t\tdeserializationDelegate.setInstance(StreamStatus.ACTIVE);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is only re-executed for suppressed watermark\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void close() {\n-\t\tdemultiplexersForSubtasks.values().forEach(Demultiplexer::close);\n-\t}\n-\n-\tstatic Demultiplexer forChannel(InputChannelInfo info, DemultiplexParameters parameters) {\n-\t\tfinal int[] oldSubtaskIndexes = parameters.channelMapping.getOldSubtaskIndexes(parameters.subtaskIndex);\n-\t\tif (oldSubtaskIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tfinal int[] oldChannelIndexes = parameters.channelMapping.getChannelMapping(info.getGateIdx())\n-\t\t\t.getOldChannelIndexes(info.getInputChannelIdx());\n-\t\tif (oldChannelIndexes.length == 0) {\n-\t\t\treturn new NoDataDemultiplexer(info);\n-\t\t}\n-\t\tint totalChannels = oldSubtaskIndexes.length * oldChannelIndexes.length;\n-\t\tMap<Integer, ChannelDemultiplexer> demultiplexersForSubtasks = Arrays.stream(oldSubtaskIndexes).boxed()\n-\t\t\t.collect(Collectors.toMap(\n-\t\t\t\tFunction.identity(),\n-\t\t\t\toldSubtaskIndex -> ChannelDemultiplexer.forChannel(oldSubtaskIndex, info, parameters, totalChannels)\n-\t\t\t));\n-\t\treturn new SubtaskDemultiplexer(demultiplexersForSubtasks, totalChannels);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"SubtaskDemultiplexer{\" +\n-\t\t\t\"demultiplexersForSubtasks=\" + demultiplexersForSubtasks +\n-\t\t\t'}';\n-\t}\n-}\n-\n-/**\n- * Demultiplexes buffers on channel-level.\n- *\n- * <p>Example: If the upstream task has been downscaled from 2 to 1. Then, old channels 0 and 1 are both\n- * processed over new channel 0. So this channel demultiplexer has two {@link #recordDeserializersForChannels} associated\n- * with the respective old channels.\n- *\n- * <p>For all non-unique mappings of new channels to old channels (see\n- * {@link org.apache.flink.runtime.io.network.api.writer.SubtaskStateMapper} for more details), a filter\n- * verifies if the restored record should be indeed processed by this subtask or if it should be filtered out and\n- * be processed at a different subtask.\n- */\n-class ChannelDemultiplexer implements Demultiplexer {\n-\tprivate final Map<Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> recordDeserializersForChannels;\n-\n-\tprivate static final Predicate<StreamRecord> NO_FILTER = record -> true;\n-\n-\tprivate final Map<Integer, Predicate<StreamRecord>> filters;\n-\n-\tprivate final int subtaskIndex;\n-\n-\t@Nullable\n-\tprivate RecordDeserializer<DeserializationDelegate<StreamElement>> selectedChannel;\n-\n-\tint selectedChannelIndex;\n-\n-\tChannelDemultiplexer(\n-\t\t\tint subtaskIndex,\n-\t\t\tMap<Integer, Predicate<StreamRecord>> oldChannelsWithFilters,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.filters = oldChannelsWithFilters;\n-\t\trecordDeserializersForChannels = Maps.newHashMapWithExpectedSize(oldChannelsWithFilters.size());\n-\t\tfor (final Integer oldChannel : oldChannelsWithFilters.keySet()) {\n-\t\t\trecordDeserializersForChannels.put(oldChannel,\n-\t\t\t\tnew SpillingAdaptiveSpanningRecordDeserializer<>(parameters.ioManager.getSpillingDirectoriesPaths(),\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING / totalChannels,\n-\t\t\t\t\tSpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE / totalChannels));\n-\t\t}\n-\n-\t\trecordDeserializersForChannels.entrySet().stream().findFirst().ifPresent(firstEntry -> {\n-\t\t\tselectedChannel = firstEntry.getValue();\n-\t\t\tselectedChannelIndex = firstEntry.getKey();\n-\t\t});\n-\t}\n-\n-\tpublic Stream<VirtualChannelSelector> getChannelSelectors() {\n-\t\treturn recordDeserializersForChannels.keySet().stream()\n-\t\t\t.map(channelIndex -> new VirtualChannelSelector(subtaskIndex, channelIndex));\n-\t}\n-\n-\t@Override\n-\tpublic RecordDeserializer.DeserializationResult getNextRecord(DeserializationDelegate<StreamElement> deserializationDelegate) throws IOException {\n-\t\tdo {\n-\t\t\tfinal RecordDeserializer.DeserializationResult result = selectedChannel.getNextRecord(deserializationDelegate);\n-\n-\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\tselectedChannel.getCurrentBuffer().recycleBuffer();\n-\t\t\t}\n-\t\t\tif (result.isFullRecord()) {\n-\t\t\t\tfinal StreamElement element = deserializationDelegate.getInstance();\n-\t\t\t\tif (element.isRecord() && !filters.get(selectedChannelIndex).test(element.asRecord())) {\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\treturn result;\n-\t\t\t// loop is re-executed for filtered full records.\n-\t\t} while (true);\n-\t}\n-\n-\tpublic void select(VirtualChannelSelector selector) {\n-\t\tselectedChannelIndex = selector.getChannelIndex();\n-\t\tselectedChannel = recordDeserializersForChannels.get(selectedChannelIndex);\n-\t\tif (selectedChannel == null) {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot select \" + selector + \"; known channels are \" + getChannelSelectors().collect(Collectors.toList()));\n-\t\t}\n-\t}\n-\n-\t@Override\n-\tpublic void setNextBuffer(Buffer buffer) throws IOException {\n-\t\tselectedChannel.setNextBuffer(buffer);\n-\t}\n-\n-\tpublic void close() {\n-\t\tfor (RecordDeserializer<DeserializationDelegate<StreamElement>> deserializer :\n-\t\t\trecordDeserializersForChannels.values()) {\n-\t\t\t// recycle buffers and clear the deserializer.\n-\t\t\tBuffer buffer = deserializer.getCurrentBuffer();\n-\t\t\tif (buffer != null && !buffer.isRecycled()) {\n-\t\t\t\tbuffer.recycleBuffer();\n-\t\t\t}\n-\t\t\tdeserializer.clear();\n-\t\t}\n-\t}\n-\n-\tstatic ChannelDemultiplexer forChannel(\n-\t\t\tint subtaskIndex,\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tint totalChannels) {\n-\t\tfinal InflightDataRescalingDescriptor mapping = parameters.channelMapping;\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping =\n-\t\t\tmapping.getChannelMapping(channelInfo.getGateIdx());\n-\t\tfinal int[] oldChannels = rescaledChannelsMapping.getOldChannelIndexes(channelInfo.getInputChannelIdx());\n-\n-\t\tfinal Map<Integer, Predicate<StreamRecord>> oldChannelsWithFilters =\n-\t\t\tArrays.stream(oldChannels).boxed()\n-\t\t\t\t.collect(Collectors.toMap(\n-\t\t\t\t\tFunction.identity(),\n-\t\t\t\t\toldChannel -> getFilterForChannel(channelInfo, parameters, rescaledChannelsMapping, oldChannel)));\n-\n-\t\treturn new ChannelDemultiplexer(\n-\t\t\tsubtaskIndex,\n-\t\t\toldChannelsWithFilters,\n-\t\t\tparameters,\n-\t\t\ttotalChannels);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> getFilterForChannel(\n-\t\t\tInputChannelInfo channelInfo,\n-\t\t\tDemultiplexParameters parameters,\n-\t\t\tRescaledChannelsMapping rescaledChannelsMapping,\n-\t\t\tInteger oldChannel) {\n-\t\treturn rescaledChannelsMapping.getNewChannelIndexes(oldChannel).length <= 1 ?\n-\t\t\tNO_FILTER :\n-\t\t\tcreateFilter(channelInfo, parameters);\n-\t}\n-\n-\tprivate static Predicate<StreamRecord> createFilter(InputChannelInfo channelInfo, DemultiplexParameters parameters) {\n-\t\tfinal StreamPartitioner partitioner = parameters.gatePartitionerRetriever.apply(channelInfo.getGateIdx());\n-\t\tfinal int inputChannelIdx = channelInfo.getInputChannelIdx();\n-\t\tfinal SerializationDelegate<StreamRecord> delegate = parameters.delegate;\n-\t\tpartitioner.setup(parameters.numberOfChannels);\n-\t\tif (partitioner instanceof ConfigurableStreamPartitioner) {\n-\t\t\t((ConfigurableStreamPartitioner) partitioner).configure(KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM);\n-\t\t}\n-\t\treturn streamRecord -> {\n-\t\t\tdelegate.setInstance(streamRecord);\n-\t\t\treturn partitioner.selectChannel(delegate) == inputChannelIdx;\n-\t\t};\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"ChannelDemultiplexer{\" +\n-\t\t\t\"channels=\" + getChannelSelectors().map(VirtualChannelSelector::getChannelIndex).collect(Collectors.toList()) +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODY0NA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519168644", "body": "This class duplicates `StreamTaskNetworkInput` by most part (the same with much less extent goes to `Demultiplexer`). \r\nI guess the motivation not to reuse was performance, right?\r\nHow big was the impact?", "bodyText": "This class duplicates StreamTaskNetworkInput by most part (the same with much less extent goes to Demultiplexer).\nI guess the motivation not to reuse was performance, right?\nHow big was the impact?", "bodyHTML": "<p dir=\"auto\">This class duplicates <code>StreamTaskNetworkInput</code> by most part (the same with much less extent goes to <code>Demultiplexer</code>).<br>\nI guess the motivation not to reuse was performance, right?<br>\nHow big was the impact?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:40:52Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases.\n+ * <ul>\n+ *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n+ * relevant to keyed exchanges).\n+ * </ul>\n+ * In both cases, records from multiple old channels are received over one new physical channel, which need to\n+ * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n+ * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n+ * virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyOTA1MA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519229050", "bodyText": "The main motivation was to avoid a secondary implementations of RecordDeserializer as that would translate to virtual calls in the regular StreamTaskNetworkInput. I have not measured the impact but it was a major concern of @pnowojski .\nNow, it would be very well possible to subclass StreamTaskNetworkInput or extract a common super class. However, because recordDeserializers is of a different type without common ancestor (for CHA), it's hard to generalize.\nI had hoped for some input on how to solve it.", "author": "AHeise", "createdAt": "2020-11-07T22:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODY0NA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 3794274cf8c..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,283 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-\n-import static org.apache.flink.util.Preconditions.checkNotNull;\n-import static org.apache.flink.util.Preconditions.checkState;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases.\n- * <ul>\n- *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n- * relevant to keyed exchanges).\n- * </ul>\n- * In both cases, records from multiple old channels are received over one new physical channel, which need to\n- * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n- * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n- * virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n-\n-\tprivate final CheckpointedInputGate checkpointedInputGate;\n-\n-\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n-\n-\tprivate final Demultiplexer[] channelDemultiplexers;\n-\n-\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n-\tprivate final StatusWatermarkValve statusWatermarkValve;\n-\n-\tprivate final int inputIndex;\n-\n-\tprivate final Map<InputChannelInfo, Integer> channelIndexes;\n-\n-\tprivate final TypeSerializer<?> inputSerializer;\n-\tprivate final IOManager ioManager;\n-\n-\t@Nullable\n-\tprivate Demultiplexer currentChannelDemultiplexer = null;\n-\tprivate int lastChannel;\n-\n-\tprivate RescalingStreamTaskNetworkInput(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\tthis.checkpointedInputGate = checkpointedInputGate;\n-\t\tthis.inputSerializer = inputSerializer;\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.deserializationDelegate = new NonReusingDeserializationDelegate<>(\n-\t\t\tnew StreamElementSerializer<>(inputSerializer));\n-\n-\t\tthis.statusWatermarkValve = checkNotNull(statusWatermarkValve);\n-\t\tthis.inputIndex = inputIndex;\n-\t\tthis.channelIndexes = getChannelIndexes(checkpointedInputGate);\n-\n-\t\tMap<Integer, StreamPartitioner<?>> partitionerCache = new HashMap<>();\n-\t\tfinal DemultiplexParameters parameters = new DemultiplexParameters(\n-\t\t\tinputSerializer,\n-\t\t\tioManager,\n-\t\t\tinflightDataRescalingDescriptor,\n-\t\t\tgateIndex -> partitionerCache.computeIfAbsent(gateIndex, inputPartitionerRetriever),\n-\t\t\tchannelIndexes.size(),\n-\t\t\tsubtaskIndex);\n-\t\tthis.channelDemultiplexers = this.checkpointedInputGate.getChannelInfos().stream()\n-\t\t\t.map(channelInfo -> SubtaskDemultiplexer.forChannel(channelInfo, parameters))\n-\t\t\t.toArray(Demultiplexer[]::new);\n-\t}\n-\n-\t@Override\n-\tpublic StreamTaskInput<T> finishRecovery() {\n-\t\tclose();\n-\t\treturn new StreamTaskNetworkInput<>(checkpointedInputGate, inputSerializer, ioManager, statusWatermarkValve, inputIndex);\n-\t}\n-\n-\tprivate static Map<InputChannelInfo, Integer> getChannelIndexes(CheckpointedInputGate checkpointedInputGate) {\n-\t\tint index = 0;\n-\t\tList<InputChannelInfo> channelInfos = checkpointedInputGate.getChannelInfos();\n-\t\tMap<InputChannelInfo, Integer> channelIndexes = new HashMap<>(channelInfos.size());\n-\t\tfor (InputChannelInfo channelInfo : channelInfos) {\n-\t\t\tchannelIndexes.put(channelInfo, index++);\n-\t\t}\n-\t\treturn channelIndexes;\n-\t}\n-\n-\t/**\n-\t * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput} depending on {@link InflightDataRescalingDescriptor}.\n-\t */\n-\tpublic static <T> StreamTaskInput<T> of(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\treturn rescalingDescriptorinflightDataRescalingDescriptor.equals(InflightDataRescalingDescriptor.NO_RESCALE) ?\n-\t\t\tnew StreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex) :\n-\t\t\tnew RescalingStreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex,\n-\t\t\t\trescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\t\tinputPartitionerRetriever,\n-\t\t\t\tsubtaskIndex);\n-\t}\n-\n-\t@Override\n-\tpublic InputStatus emitNext(DataOutput<T> output) throws Exception {\n-\n-\t\twhile (true) {\n-\t\t\t// get the stream element from the deserializer\n-\t\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\t\tDeserializationResult result = currentChannelDemultiplexer.getNextRecord(deserializationDelegate);\n-\n-\t\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\t\tcurrentChannelDemultiplexer = null;\n-\t\t\t\t}\n-\n-\t\t\t\tif (result.isFullRecord()) {\n-\t\t\t\t\tprocessElement(deserializationDelegate.getInstance(), output);\n-\t\t\t\t\treturn InputStatus.MORE_AVAILABLE;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\tOptional<BufferOrEvent> bufferOrEvent = checkpointedInputGate.pollNext();\n-\t\t\tif (bufferOrEvent.isPresent()) {\n-\t\t\t\t// return to the mailbox after receiving a checkpoint barrier to avoid processing of\n-\t\t\t\t// data after the barrier before checkpoint is performed for unaligned checkpoint mode\n-\t\t\t\tif (bufferOrEvent.get().isBuffer()) {\n-\t\t\t\t\tprocessBuffer(bufferOrEvent.get());\n-\t\t\t\t} else {\n-\t\t\t\t\treturn processEvent(bufferOrEvent.get());\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tif (checkpointedInputGate.isFinished()) {\n-\t\t\t\t\tcheckState(checkpointedInputGate.getAvailableFuture().isDone(), \"Finished BarrierHandler should be available\");\n-\t\t\t\t\treturn InputStatus.END_OF_INPUT;\n-\t\t\t\t}\n-\t\t\t\treturn InputStatus.NOTHING_AVAILABLE;\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tprivate void processElement(StreamElement recordOrMark, DataOutput<T> output) throws Exception {\n-\t\tif (recordOrMark.isRecord()){\n-\t\t\toutput.emitRecord(recordOrMark.asRecord());\n-\t\t} else if (recordOrMark.isWatermark()) {\n-\t\t\tstatusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), lastChannel, output);\n-\t\t} else if (recordOrMark.isLatencyMarker()) {\n-\t\t\toutput.emitLatencyMarker(recordOrMark.asLatencyMarker());\n-\t\t} else if (recordOrMark.isStreamStatus()) {\n-\t\t\tstatusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), lastChannel, output);\n-\t\t} else {\n-\t\t\tthrow new UnsupportedOperationException(\"Unknown type of StreamElement\");\n-\t\t}\n-\t}\n-\n-\tprivate InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-\t\t// Event received\n-\t\tfinal AbstractEvent event = bufferOrEvent.getEvent();\n-\t\tif (event instanceof VirtualChannelSelector) {\n-\t\t\tint channel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\t\tcheckState(channel != StreamTaskInput.UNSPECIFIED);\n-\t\t\tthis.channelDemultiplexers[channel].select((VirtualChannelSelector) event);\n-\t\t} else if (event.getClass() == EndOfPartitionEvent.class) {\n-\t\t\t// release the record deserializer immediately,\n-\t\t\t// which is very valuable in case of bounded stream\n-\t\t\treleaseDeserializer(channelIndexes.get(bufferOrEvent.getChannelInfo()));\n-\t\t} else if (event.getClass() == EndOfChannelStateEvent.class) {\n-\t\t\treturn InputStatus.END_OF_RECOVERY;\n-\t\t}\n-\t\treturn InputStatus.MORE_AVAILABLE;\n-\t}\n-\n-\tprivate void processBuffer(BufferOrEvent bufferOrEvent) throws IOException {\n-\t\tlastChannel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\tcheckState(lastChannel != StreamTaskInput.UNSPECIFIED);\n-\t\tcurrentChannelDemultiplexer = this.channelDemultiplexers[lastChannel];\n-\t\tcheckState(\n-\t\t\tcurrentChannelDemultiplexer != null,\n-\t\t\t\"currentRecordDeserializer has already been released\");\n-\n-\t\tcurrentChannelDemultiplexer.setNextBuffer(bufferOrEvent.getBuffer());\n-\t}\n-\n-\t@Override\n-\tpublic int getInputIndex() {\n-\t\treturn inputIndex;\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<?> getAvailableFuture() {\n-\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\treturn AVAILABLE;\n-\t\t}\n-\t\treturn checkpointedInputGate.getAvailableFuture();\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<Void> prepareSnapshot(ChannelStateWriter channelStateWriter, long checkpointId) {\n-\t\tthrow new IllegalStateException(\"Tasks with inputs should not start checkpointing during recovery (rejected in CheckpointedInputGate).\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t\t// release the deserializers . this part should not ever fail\n-\t\tfor (int channelIndex = 0; channelIndex < channelDemultiplexers.length; channelIndex++) {\n-\t\t\treleaseDeserializer(channelIndex);\n-\t\t}\n-\t}\n-\n-\tprivate void releaseDeserializer(int channelIndex) {\n-\t\tDemultiplexer demultiplexer = channelDemultiplexers[channelIndex];\n-\t\tif (demultiplexer != null) {\n-\t\t\tdemultiplexer.close();\n-\n-\t\t\tchannelDemultiplexers[channelIndex] = null;\n-\t\t}\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 3794274cf8c..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,283 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer.DeserializationResult;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-\n-import static org.apache.flink.util.Preconditions.checkNotNull;\n-import static org.apache.flink.util.Preconditions.checkState;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases.\n- * <ul>\n- *     <li> Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *     <li> The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly\n- * relevant to keyed exchanges).\n- * </ul>\n- * In both cases, records from multiple old channels are received over one new physical channel, which need to\n- * demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is the cross product of\n- * channels. So if two subtasks are collapsed and two channels overlap from the output side, there is a total of 4\n- * virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T> implements RecoverableStreamTaskInput<T> {\n-\n-\tprivate final CheckpointedInputGate checkpointedInputGate;\n-\n-\tprivate final DeserializationDelegate<StreamElement> deserializationDelegate;\n-\n-\tprivate final Demultiplexer[] channelDemultiplexers;\n-\n-\t/** Valve that controls how watermarks and stream statuses are forwarded. */\n-\tprivate final StatusWatermarkValve statusWatermarkValve;\n-\n-\tprivate final int inputIndex;\n-\n-\tprivate final Map<InputChannelInfo, Integer> channelIndexes;\n-\n-\tprivate final TypeSerializer<?> inputSerializer;\n-\tprivate final IOManager ioManager;\n-\n-\t@Nullable\n-\tprivate Demultiplexer currentChannelDemultiplexer = null;\n-\tprivate int lastChannel;\n-\n-\tprivate RescalingStreamTaskNetworkInput(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\tthis.checkpointedInputGate = checkpointedInputGate;\n-\t\tthis.inputSerializer = inputSerializer;\n-\t\tthis.ioManager = ioManager;\n-\t\tthis.deserializationDelegate = new NonReusingDeserializationDelegate<>(\n-\t\t\tnew StreamElementSerializer<>(inputSerializer));\n-\n-\t\tthis.statusWatermarkValve = checkNotNull(statusWatermarkValve);\n-\t\tthis.inputIndex = inputIndex;\n-\t\tthis.channelIndexes = getChannelIndexes(checkpointedInputGate);\n-\n-\t\tMap<Integer, StreamPartitioner<?>> partitionerCache = new HashMap<>();\n-\t\tfinal DemultiplexParameters parameters = new DemultiplexParameters(\n-\t\t\tinputSerializer,\n-\t\t\tioManager,\n-\t\t\tinflightDataRescalingDescriptor,\n-\t\t\tgateIndex -> partitionerCache.computeIfAbsent(gateIndex, inputPartitionerRetriever),\n-\t\t\tchannelIndexes.size(),\n-\t\t\tsubtaskIndex);\n-\t\tthis.channelDemultiplexers = this.checkpointedInputGate.getChannelInfos().stream()\n-\t\t\t.map(channelInfo -> SubtaskDemultiplexer.forChannel(channelInfo, parameters))\n-\t\t\t.toArray(Demultiplexer[]::new);\n-\t}\n-\n-\t@Override\n-\tpublic StreamTaskInput<T> finishRecovery() {\n-\t\tclose();\n-\t\treturn new StreamTaskNetworkInput<>(checkpointedInputGate, inputSerializer, ioManager, statusWatermarkValve, inputIndex);\n-\t}\n-\n-\tprivate static Map<InputChannelInfo, Integer> getChannelIndexes(CheckpointedInputGate checkpointedInputGate) {\n-\t\tint index = 0;\n-\t\tList<InputChannelInfo> channelInfos = checkpointedInputGate.getChannelInfos();\n-\t\tMap<InputChannelInfo, Integer> channelIndexes = new HashMap<>(channelInfos.size());\n-\t\tfor (InputChannelInfo channelInfo : channelInfos) {\n-\t\t\tchannelIndexes.put(channelInfo, index++);\n-\t\t}\n-\t\treturn channelIndexes;\n-\t}\n-\n-\t/**\n-\t * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput} depending on {@link InflightDataRescalingDescriptor}.\n-\t */\n-\tpublic static <T> StreamTaskInput<T> of(\n-\t\t\tCheckpointedInputGate checkpointedInputGate,\n-\t\t\tTypeSerializer<?> inputSerializer,\n-\t\t\tIOManager ioManager,\n-\t\t\tStatusWatermarkValve statusWatermarkValve,\n-\t\t\tint inputIndex,\n-\t\t\tInflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\tFunction<Integer, StreamPartitioner<?>> inputPartitionerRetriever,\n-\t\t\tint subtaskIndex) {\n-\t\treturn rescalingDescriptorinflightDataRescalingDescriptor.equals(InflightDataRescalingDescriptor.NO_RESCALE) ?\n-\t\t\tnew StreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex) :\n-\t\t\tnew RescalingStreamTaskNetworkInput<>(\n-\t\t\t\tcheckpointedInputGate,\n-\t\t\t\tinputSerializer,\n-\t\t\t\tioManager,\n-\t\t\t\tstatusWatermarkValve,\n-\t\t\t\tinputIndex,\n-\t\t\t\trescalingDescriptorinflightDataRescalingDescriptor,\n-\t\t\t\tinputPartitionerRetriever,\n-\t\t\t\tsubtaskIndex);\n-\t}\n-\n-\t@Override\n-\tpublic InputStatus emitNext(DataOutput<T> output) throws Exception {\n-\n-\t\twhile (true) {\n-\t\t\t// get the stream element from the deserializer\n-\t\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\t\tDeserializationResult result = currentChannelDemultiplexer.getNextRecord(deserializationDelegate);\n-\n-\t\t\t\tif (result.isBufferConsumed()) {\n-\t\t\t\t\tcurrentChannelDemultiplexer = null;\n-\t\t\t\t}\n-\n-\t\t\t\tif (result.isFullRecord()) {\n-\t\t\t\t\tprocessElement(deserializationDelegate.getInstance(), output);\n-\t\t\t\t\treturn InputStatus.MORE_AVAILABLE;\n-\t\t\t\t}\n-\t\t\t}\n-\n-\t\t\tOptional<BufferOrEvent> bufferOrEvent = checkpointedInputGate.pollNext();\n-\t\t\tif (bufferOrEvent.isPresent()) {\n-\t\t\t\t// return to the mailbox after receiving a checkpoint barrier to avoid processing of\n-\t\t\t\t// data after the barrier before checkpoint is performed for unaligned checkpoint mode\n-\t\t\t\tif (bufferOrEvent.get().isBuffer()) {\n-\t\t\t\t\tprocessBuffer(bufferOrEvent.get());\n-\t\t\t\t} else {\n-\t\t\t\t\treturn processEvent(bufferOrEvent.get());\n-\t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tif (checkpointedInputGate.isFinished()) {\n-\t\t\t\t\tcheckState(checkpointedInputGate.getAvailableFuture().isDone(), \"Finished BarrierHandler should be available\");\n-\t\t\t\t\treturn InputStatus.END_OF_INPUT;\n-\t\t\t\t}\n-\t\t\t\treturn InputStatus.NOTHING_AVAILABLE;\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tprivate void processElement(StreamElement recordOrMark, DataOutput<T> output) throws Exception {\n-\t\tif (recordOrMark.isRecord()){\n-\t\t\toutput.emitRecord(recordOrMark.asRecord());\n-\t\t} else if (recordOrMark.isWatermark()) {\n-\t\t\tstatusWatermarkValve.inputWatermark(recordOrMark.asWatermark(), lastChannel, output);\n-\t\t} else if (recordOrMark.isLatencyMarker()) {\n-\t\t\toutput.emitLatencyMarker(recordOrMark.asLatencyMarker());\n-\t\t} else if (recordOrMark.isStreamStatus()) {\n-\t\t\tstatusWatermarkValve.inputStreamStatus(recordOrMark.asStreamStatus(), lastChannel, output);\n-\t\t} else {\n-\t\t\tthrow new UnsupportedOperationException(\"Unknown type of StreamElement\");\n-\t\t}\n-\t}\n-\n-\tprivate InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-\t\t// Event received\n-\t\tfinal AbstractEvent event = bufferOrEvent.getEvent();\n-\t\tif (event instanceof VirtualChannelSelector) {\n-\t\t\tint channel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\t\tcheckState(channel != StreamTaskInput.UNSPECIFIED);\n-\t\t\tthis.channelDemultiplexers[channel].select((VirtualChannelSelector) event);\n-\t\t} else if (event.getClass() == EndOfPartitionEvent.class) {\n-\t\t\t// release the record deserializer immediately,\n-\t\t\t// which is very valuable in case of bounded stream\n-\t\t\treleaseDeserializer(channelIndexes.get(bufferOrEvent.getChannelInfo()));\n-\t\t} else if (event.getClass() == EndOfChannelStateEvent.class) {\n-\t\t\treturn InputStatus.END_OF_RECOVERY;\n-\t\t}\n-\t\treturn InputStatus.MORE_AVAILABLE;\n-\t}\n-\n-\tprivate void processBuffer(BufferOrEvent bufferOrEvent) throws IOException {\n-\t\tlastChannel = channelIndexes.get(bufferOrEvent.getChannelInfo());\n-\t\tcheckState(lastChannel != StreamTaskInput.UNSPECIFIED);\n-\t\tcurrentChannelDemultiplexer = this.channelDemultiplexers[lastChannel];\n-\t\tcheckState(\n-\t\t\tcurrentChannelDemultiplexer != null,\n-\t\t\t\"currentRecordDeserializer has already been released\");\n-\n-\t\tcurrentChannelDemultiplexer.setNextBuffer(bufferOrEvent.getBuffer());\n-\t}\n-\n-\t@Override\n-\tpublic int getInputIndex() {\n-\t\treturn inputIndex;\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<?> getAvailableFuture() {\n-\t\tif (currentChannelDemultiplexer != null) {\n-\t\t\treturn AVAILABLE;\n-\t\t}\n-\t\treturn checkpointedInputGate.getAvailableFuture();\n-\t}\n-\n-\t@Override\n-\tpublic CompletableFuture<Void> prepareSnapshot(ChannelStateWriter channelStateWriter, long checkpointId) {\n-\t\tthrow new IllegalStateException(\"Tasks with inputs should not start checkpointing during recovery (rejected in CheckpointedInputGate).\");\n-\t}\n-\n-\t@Override\n-\tpublic void close() {\n-\t\t// release the deserializers . this part should not ever fail\n-\t\tfor (int channelIndex = 0; channelIndex < channelDemultiplexers.length; channelIndex++) {\n-\t\t\treleaseDeserializer(channelIndex);\n-\t\t}\n-\t}\n-\n-\tprivate void releaseDeserializer(int channelIndex) {\n-\t\tDemultiplexer demultiplexer = channelDemultiplexers[channelIndex];\n-\t\tif (demultiplexer != null) {\n-\t\t\tdemultiplexer.close();\n-\n-\t\t\tchannelDemultiplexers[channelIndex] = null;\n-\t\t}\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2ODk4OA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519168988", "body": "nit: if `channels` is empty then a more informative error message would be helpful", "bodyText": "nit: if channels is empty then a more informative error message would be helpful", "bodyHTML": "<p dir=\"auto\">nit: if <code>channels</code> is empty then a more informative error message would be helpful</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:44:44Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -18,183 +18,139 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.api.java.tuple.Tuple2;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;\n import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.logger.NetworkActionsLogger;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultPartition;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultSubpartition;\n-import org.apache.flink.runtime.io.network.partition.consumer.InputChannel;\n import org.apache.flink.runtime.io.network.partition.consumer.InputGate;\n import org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.stream.Collectors;\n \n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+        this.inputGates = inputGates;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        RecoveredInputChannel channel = getChannel(channelInfo);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+        if (buffer.readableBytes() > 0) {\n+            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n+        } else {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(InputChannelInfo info) {\n+        return (RecoveredInputChannel)\n+                inputGates[info.getGateIdx()].getChannel(info.getInputChannelIdx());\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+        this.writers = writers;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        BufferBuilder bufferBuilder =\n+                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        bufferBuilderAndConsumer.f0.finish();\n+        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+            NetworkActionsLogger.traceRecover(\n+                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                    bufferBuilderAndConsumer.f1,\n+                    subpartitionInfo);\n+            boolean added =\n+                    getSubpartition(subpartitionInfo)\n+                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n+            if (!added) {\n+                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            }\n+        } else {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n+        if (writer instanceof CheckpointedResultPartition) {\n+            return ((CheckpointedResultPartition) writer)\n+                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n+        } else {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -45,156 +43,217 @@ import java.util.stream.Collectors;\n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n+        this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        // request the buffer from any mapped channel as they all will receive the same buffer\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n+        try {\n+            if (buffer.readableBytes() > 0) {\n+                for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                    channel.onRecoveredStateBuffer(\n+                            EventSerializer.toBuffer(\n+                                    new SubtaskConnectionDescriptor(\n+                                            oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                    false));\n+                    channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+                }\n+            }\n+        } finally {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n+        final InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n+        if (!(inputChannel instanceof RecoveredInputChannel)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n+        }\n+        return (RecoveredInputChannel) inputChannel;\n+    }\n+\n+    private List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n+        return rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n+    }\n+\n+    private List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getGateIdx(), idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<RecoveredInputChannel> channels =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getInputChannelIdx()))\n+                        .mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n+                        .collect(Collectors.toList());\n+        if (channels.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getGateIdx()));\n+        }\n+        return channels;\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n+        this.writers = writers;\n+        this.channelMapping = channelMapping;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        // request the buffer from any mapped subpartition as they all will receive the same buffer\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            int oldSubtaskIndex,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n+                }\n+            }\n+        } finally {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            int partitionIndex, int subPartitionIdx) {\n+        ResultPartitionWriter writer = writers[partitionIndex];\n+        if (!(writer instanceof CheckpointedResultPartition)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> getMappedChannels(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getPartitionIdx(),\n+                        idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<CheckpointedResultSubpartition> subpartitions =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))\n+                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+                        .collect(Collectors.toList());\n+        if (subpartitions.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getPartitionIdx()));\n+        }\n+        return subpartitions;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTA3Mg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169072", "body": "nit: move to top?", "bodyText": "nit: move to top?", "bodyHTML": "<p dir=\"auto\">nit: move to top?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:45:43Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyOTA4Mw==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519229083", "bodyText": "I'll remove the whole commit; it's just for debugging tests.", "author": "AHeise", "createdAt": "2020-11-07T22:46:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTA3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -18,183 +18,139 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.api.java.tuple.Tuple2;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;\n import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.logger.NetworkActionsLogger;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultPartition;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultSubpartition;\n-import org.apache.flink.runtime.io.network.partition.consumer.InputChannel;\n import org.apache.flink.runtime.io.network.partition.consumer.InputGate;\n import org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.stream.Collectors;\n \n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+        this.inputGates = inputGates;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        RecoveredInputChannel channel = getChannel(channelInfo);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+        if (buffer.readableBytes() > 0) {\n+            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n+        } else {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(InputChannelInfo info) {\n+        return (RecoveredInputChannel)\n+                inputGates[info.getGateIdx()].getChannel(info.getInputChannelIdx());\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+        this.writers = writers;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        BufferBuilder bufferBuilder =\n+                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        bufferBuilderAndConsumer.f0.finish();\n+        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+            NetworkActionsLogger.traceRecover(\n+                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                    bufferBuilderAndConsumer.f1,\n+                    subpartitionInfo);\n+            boolean added =\n+                    getSubpartition(subpartitionInfo)\n+                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n+            if (!added) {\n+                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            }\n+        } else {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n+        if (writer instanceof CheckpointedResultPartition) {\n+            return ((CheckpointedResultPartition) writer)\n+                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n+        } else {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -45,156 +43,217 @@ import java.util.stream.Collectors;\n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n+        this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        // request the buffer from any mapped channel as they all will receive the same buffer\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n+        try {\n+            if (buffer.readableBytes() > 0) {\n+                for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                    channel.onRecoveredStateBuffer(\n+                            EventSerializer.toBuffer(\n+                                    new SubtaskConnectionDescriptor(\n+                                            oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                    false));\n+                    channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+                }\n+            }\n+        } finally {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n+        final InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n+        if (!(inputChannel instanceof RecoveredInputChannel)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n+        }\n+        return (RecoveredInputChannel) inputChannel;\n+    }\n+\n+    private List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n+        return rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n+    }\n+\n+    private List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getGateIdx(), idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<RecoveredInputChannel> channels =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getInputChannelIdx()))\n+                        .mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n+                        .collect(Collectors.toList());\n+        if (channels.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getGateIdx()));\n+        }\n+        return channels;\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n+        this.writers = writers;\n+        this.channelMapping = channelMapping;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        // request the buffer from any mapped subpartition as they all will receive the same buffer\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            int oldSubtaskIndex,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n+                }\n+            }\n+        } finally {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            int partitionIndex, int subPartitionIdx) {\n+        ResultPartitionWriter writer = writers[partitionIndex];\n+        if (!(writer instanceof CheckpointedResultPartition)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> getMappedChannels(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getPartitionIdx(),\n+                        idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<CheckpointedResultSubpartition> subpartitions =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))\n+                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+                        .collect(Collectors.toList());\n+        if (subpartitions.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getPartitionIdx()));\n+        }\n+        return subpartitions;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTEyMg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169122", "body": "I think the log level should be debug here.", "bodyText": "I think the log level should be debug here.", "bodyHTML": "<p dir=\"auto\">I think the log level should be debug here.</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:46:19Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+\t}\n+\n+\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n+\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+\t}\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n+\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n+\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n+\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+\t\t\t.collect(Collectors.toList());\n+\n+\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNTk5Mg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519225992", "bodyText": "I'll remove the whole commit; it's just for debugging tests.", "author": "AHeise", "createdAt": "2020-11-07T22:14:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTEyMg=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -18,183 +18,139 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.api.java.tuple.Tuple2;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;\n import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.logger.NetworkActionsLogger;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultPartition;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultSubpartition;\n-import org.apache.flink.runtime.io.network.partition.consumer.InputChannel;\n import org.apache.flink.runtime.io.network.partition.consumer.InputGate;\n import org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.stream.Collectors;\n \n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+        this.inputGates = inputGates;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        RecoveredInputChannel channel = getChannel(channelInfo);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+        if (buffer.readableBytes() > 0) {\n+            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n+        } else {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(InputChannelInfo info) {\n+        return (RecoveredInputChannel)\n+                inputGates[info.getGateIdx()].getChannel(info.getInputChannelIdx());\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+        this.writers = writers;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        BufferBuilder bufferBuilder =\n+                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        bufferBuilderAndConsumer.f0.finish();\n+        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+            NetworkActionsLogger.traceRecover(\n+                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                    bufferBuilderAndConsumer.f1,\n+                    subpartitionInfo);\n+            boolean added =\n+                    getSubpartition(subpartitionInfo)\n+                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n+            if (!added) {\n+                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            }\n+        } else {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n+        if (writer instanceof CheckpointedResultPartition) {\n+            return ((CheckpointedResultPartition) writer)\n+                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n+        } else {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -45,156 +43,217 @@ import java.util.stream.Collectors;\n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n+        this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        // request the buffer from any mapped channel as they all will receive the same buffer\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n+        try {\n+            if (buffer.readableBytes() > 0) {\n+                for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                    channel.onRecoveredStateBuffer(\n+                            EventSerializer.toBuffer(\n+                                    new SubtaskConnectionDescriptor(\n+                                            oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                    false));\n+                    channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+                }\n+            }\n+        } finally {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n+        final InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n+        if (!(inputChannel instanceof RecoveredInputChannel)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n+        }\n+        return (RecoveredInputChannel) inputChannel;\n+    }\n+\n+    private List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n+        return rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n+    }\n+\n+    private List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getGateIdx(), idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<RecoveredInputChannel> channels =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getInputChannelIdx()))\n+                        .mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n+                        .collect(Collectors.toList());\n+        if (channels.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getGateIdx()));\n+        }\n+        return channels;\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n+        this.writers = writers;\n+        this.channelMapping = channelMapping;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        // request the buffer from any mapped subpartition as they all will receive the same buffer\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            int oldSubtaskIndex,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n+                }\n+            }\n+        } finally {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            int partitionIndex, int subPartitionIdx) {\n+        ResultPartitionWriter writer = writers[partitionIndex];\n+        if (!(writer instanceof CheckpointedResultPartition)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> getMappedChannels(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getPartitionIdx(),\n+                        idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<CheckpointedResultSubpartition> subpartitions =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))\n+                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+                        .collect(Collectors.toList());\n+        if (subpartitions.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getPartitionIdx()));\n+        }\n+        return subpartitions;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTMwMA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169300", "body": "Is it guaranteed that new subpartitions include all needed old subpartitions?\r\nI think in case of downscaling of the downstream, the new upstream will less subpartitions than the old one.\r\nWDYT?\r\n", "bodyText": "Is it guaranteed that new subpartitions include all needed old subpartitions?\nI think in case of downscaling of the downstream, the new upstream will less subpartitions than the old one.\nWDYT?", "bodyHTML": "<p dir=\"auto\">Is it guaranteed that new subpartitions include all needed old subpartitions?<br>\nI think in case of downscaling of the downstream, the new upstream will less subpartitions than the old one.<br>\nWDYT?</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:49:09Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -88,38 +127,66 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n \tprivate final ResultPartitionWriter[] writers;\n \tprivate final boolean notifyAndBlockOnCompletion;\n \n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+\tprivate final InflightDataRescalingDescriptor channelMapping;\n+\n+\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n+\n+\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n \t\tthis.writers = writers;\n+\t\tthis.channelMapping = channelMapping;\n \t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n \t}\n \n \t@Override\n \tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tBufferBuilder bufferBuilder = getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n \t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n \t}\n \n \t@Override\n-\tpublic void recover(ResultSubpartitionInfo subpartitionInfo, Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n+\tpublic void recover(\n+\t\t\tResultSubpartitionInfo subpartitionInfo,\n+\t\t\tint oldSubtaskIndex,\n+\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n \t\tbufferBuilderAndConsumer.f0.finish();\n \t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tboolean added = getSubpartition(subpartitionInfo).add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-\t\t\tif (!added) {\n-\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n+\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n+\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n+\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+\t\t\t\tif (!added) {\n+\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+\t\t\t\t}\n \t\t\t}\n-\t\t} else {\n-\t\t\tbufferBuilderAndConsumer.f1.close();\n \t\t}\n+\t\tbufferBuilderAndConsumer.f1.close();\n \t}\n \n-\tprivate CheckpointedResultSubpartition getSubpartition(ResultSubpartitionInfo subpartitionInfo) {\n-\t\tResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-\t\t} else {\n-\t\t\tthrow new IllegalStateException(\n-\t\t\t\t\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n+\t\tResultPartitionWriter writer = writers[partitionIndex];\n+\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n+\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n \t\t}\n+\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNTk0NA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519225944", "bodyText": "In the event of downscaling on input side, the state on output side is exactly recovered by the upstream subtasks that produced it.\nHowever, as you pointed out, there might be fewer subpartitions. In this case the SubtaskStateMapper of the input side will create a mapping that is also set to the InflightDataRescalingDescriptor of the output side in the rescaledChannelsMappings part.\nSo the sequential reader recovers a buffer with old SubpartitionInfo and the mapping is used to find all new channels to which to send the buffer. At this point, the mapping guarantees that all old channels are remapped to new channels.\nFor example, consider the following downscaling of a key range on input side.\n3 partitions: [0; 43) [43; 87) [87; 128)\n2 partitions: [0; 64) [64; 128)\nmapping: 0->[0; 1]; 1->[1;2] (new to old)\nreverse mapping used in sequential reader: 0->[0]; 1->[0;1]; 2->[1] (old to new)\n\nWhen a buffer from subpartition 1 is recovered (from 3 partitions), it needs to be send to subpartition 0 and 1. Similarly, if a buffer from subpartition 2 is recovered, it needs to be send to subpartition 1.", "author": "AHeise", "createdAt": "2020-11-07T22:13:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTMwMA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -18,183 +18,139 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.api.java.tuple.Tuple2;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.RescaledChannelsMapping;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;\n import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.logger.NetworkActionsLogger;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultPartition;\n import org.apache.flink.runtime.io.network.partition.CheckpointedResultSubpartition;\n-import org.apache.flink.runtime.io.network.partition.consumer.InputChannel;\n import org.apache.flink.runtime.io.network.partition.consumer.InputGate;\n import org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.stream.Collectors;\n \n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+        this.inputGates = inputGates;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        RecoveredInputChannel channel = getChannel(channelInfo);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+        if (buffer.readableBytes() > 0) {\n+            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n+        } else {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(InputChannelInfo info) {\n+        return (RecoveredInputChannel)\n+                inputGates[info.getGateIdx()].getChannel(info.getInputChannelIdx());\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+        this.writers = writers;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        BufferBuilder bufferBuilder =\n+                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        bufferBuilderAndConsumer.f0.finish();\n+        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+            NetworkActionsLogger.traceRecover(\n+                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                    bufferBuilderAndConsumer.f1,\n+                    subpartitionInfo);\n+            boolean added =\n+                    getSubpartition(subpartitionInfo)\n+                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n+            if (!added) {\n+                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            }\n+        } else {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n+        if (writer instanceof CheckpointedResultPartition) {\n+            return ((CheckpointedResultPartition) writer)\n+                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n+        } else {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 7346c3499e1..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -45,156 +43,217 @@ import java.util.stream.Collectors;\n import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n \n interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n-\tclass BufferWithContext<Context> {\n-\t\tfinal ChannelStateByteBuffer buffer;\n-\t\tfinal Context context;\n+    class BufferWithContext<Context> {\n+        final ChannelStateByteBuffer buffer;\n+        final Context context;\n \n-\t\tBufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n-\t\t\tthis.buffer = buffer;\n-\t\t\tthis.context = context;\n-\t\t}\n-\t}\n+        BufferWithContext(ChannelStateByteBuffer buffer, Context context) {\n+            this.buffer = buffer;\n+            this.context = context;\n+        }\n+    }\n \n-\tBufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n+    BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-\tvoid recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n-class InputChannelRecoveredStateHandler implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n-\tprivate final InputGate[] inputGates;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels = new HashMap<>();\n-\n-\tInputChannelRecoveredStateHandler(InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.inputGates = inputGates;\n-\t\tthis.channelMapping = channelMapping;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo) throws IOException, InterruptedException {\n-\t\tRecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n-\t\tBuffer buffer = channel.requestBufferBlocking();\n-\t\treturn new BufferWithContext<>(wrap(buffer), buffer);\n-\t}\n-\n-\t@Override\n-\tpublic void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer) throws IOException {\n-\t\tif (buffer.readableBytes() > 0) {\n-\t\t\tfor (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-\t\t\t\tchannel.onRecoveredStateBuffer(EventSerializer.toBuffer(new VirtualChannelSelector(oldSubtaskIndex, channelInfo.getInputChannelIdx()), false));\n-\t\t\t\tchannel.onRecoveredStateBuffer(buffer.retainBuffer());\n-\t\t\t}\n-\t\t}\n-\t\tbuffer.recycleBuffer();\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\t// note that we need to finish all RecoveredInputChannels, not just those with state\n-\t\tfor (final InputGate inputGate : inputGates) {\n-\t\t\tinputGate.finishReadRecoveredState();\n-\t\t}\n-\t}\n-\n-\tprivate RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n-\t\tfinal InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n-\t\tif (!(inputChannel instanceof RecoveredInputChannel)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n-\t\t}\n-\t\treturn (RecoveredInputChannel) inputChannel;\n-\t}\n-\n-\tprivate List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(InputChannelRecoveredStateHandler.class);\n-\tprivate List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getGateIdx());\n-\t\tfinal List<RecoveredInputChannel> channels = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getInputChannelIdx()))\n-\t\t\t.mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n-\t\t\t.collect(Collectors.toList());\n-\t\tLOG.info(\"input#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tchannels.stream().map(RecoveredInputChannel::getChannelInfo).collect(Collectors.toList()));\n-\t\treturn channels;\n-\t}\n+class InputChannelRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n+    private final InputGate[] inputGates;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n+        this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n+            throws IOException, InterruptedException {\n+        // request the buffer from any mapped channel as they all will receive the same buffer\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n+        Buffer buffer = channel.requestBufferBlocking();\n+        return new BufferWithContext<>(wrap(buffer), buffer);\n+    }\n+\n+    @Override\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n+        try {\n+            if (buffer.readableBytes() > 0) {\n+                for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                    channel.onRecoveredStateBuffer(\n+                            EventSerializer.toBuffer(\n+                                    new SubtaskConnectionDescriptor(\n+                                            oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                    false));\n+                    channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+                }\n+            }\n+        } finally {\n+            buffer.recycleBuffer();\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        // note that we need to finish all RecoveredInputChannels, not just those with state\n+        for (final InputGate inputGate : inputGates) {\n+            inputGate.finishReadRecoveredState();\n+        }\n+    }\n+\n+    private RecoveredInputChannel getChannel(int gateIndex, int subPartitionIndex) {\n+        final InputChannel inputChannel = inputGates[gateIndex].getChannel(subPartitionIndex);\n+        if (!(inputChannel instanceof RecoveredInputChannel)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-recovered input channel: \" + inputChannel);\n+        }\n+        return (RecoveredInputChannel) inputChannel;\n+    }\n+\n+    private List<RecoveredInputChannel> getMappedChannels(InputChannelInfo channelInfo) {\n+        return rescaledChannels.computeIfAbsent(channelInfo, this::calculateMapping);\n+    }\n+\n+    private List<RecoveredInputChannel> calculateMapping(InputChannelInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getGateIdx(), idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<RecoveredInputChannel> channels =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getInputChannelIdx()))\n+                        .mapToObj(newChannelIndex -> getChannel(info.getGateIdx(), newChannelIndex))\n+                        .collect(Collectors.toList());\n+        if (channels.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getGateIdx()));\n+        }\n+        return channels;\n+    }\n }\n \n-class ResultSubpartitionRecoveredStateHandler implements RecoveredChannelStateHandler<ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n-\n-\tprivate final ResultPartitionWriter[] writers;\n-\tprivate final boolean notifyAndBlockOnCompletion;\n-\n-\tprivate final InflightDataRescalingDescriptor channelMapping;\n-\n-\tprivate final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>> rescaledChannels = new HashMap<>();\n-\n-\tResultSubpartitionRecoveredStateHandler(ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion, InflightDataRescalingDescriptor channelMapping) {\n-\t\tthis.writers = writers;\n-\t\tthis.channelMapping = channelMapping;\n-\t\tthis.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n-\t}\n-\n-\t@Override\n-\tpublic BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\tBufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-\t\treturn new BufferWithContext<>(wrap(bufferBuilder), Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n-\t}\n-\n-\t@Override\n-\tpublic void recover(\n-\t\t\tResultSubpartitionInfo subpartitionInfo,\n-\t\t\tint oldSubtaskIndex,\n-\t\t\tTuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer) throws IOException {\n-\t\tbufferBuilderAndConsumer.f0.finish();\n-\t\tif (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-\t\t\tfinal List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-\t\t\tfor (final CheckpointedResultSubpartition channel : channels) {\n-\t\t\t\t// channel selector is created from the downstream's point of view: the subtask of downstream = subpartition index of recovered buffer\n-\t\t\t\tfinal VirtualChannelSelector channelSelector = new VirtualChannelSelector(subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-\t\t\t\tchannel.add(EventSerializer.toBufferConsumer(channelSelector, false), Integer.MIN_VALUE);\n-\t\t\t\tboolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-\t\t\t\tif (!added) {\n-\t\t\t\t\tthrow new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\tbufferBuilderAndConsumer.f1.close();\n-\t}\n-\n-\tprivate CheckpointedResultSubpartition getSubpartition(int partitionIndex, int subPartitionIdx) {\n-\t\tResultPartitionWriter writer = writers[partitionIndex];\n-\t\tif (!(writer instanceof CheckpointedResultPartition)) {\n-\t\t\tthrow new IllegalStateException(\"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-\t\t}\n-\t\treturn ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-\t}\n-\n-\tprivate List<CheckpointedResultSubpartition> getMappedChannels(ResultSubpartitionInfo subpartitionInfo) {\n-\t\treturn rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-\t}\n-\n-\tprivate static final Logger LOG = LoggerFactory.getLogger(ResultSubpartitionRecoveredStateHandler.class);\n-\tprivate List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-\t\tfinal RescaledChannelsMapping rescaledChannelsMapping = channelMapping.getChannelMapping(info.getPartitionIdx());\n-\t\tfinal List<CheckpointedResultSubpartition> subpartitions = Arrays.stream(rescaledChannelsMapping.getNewChannelIndexes(info.getSubPartitionIdx()))\n-\t\t\t.mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-\t\t\t.collect(Collectors.toList());\n-\n-\t\tLOG.info(\"output#calculateMapping for {} using {}: {}\", info, rescaledChannelsMapping,\n-\t\t\tsubpartitions.stream().map(CheckpointedResultSubpartition::getSubpartitionInfo).collect(Collectors.toList()));\n-\t\treturn subpartitions;\n-\t}\n-\n-\t@Override\n-\tpublic void close() throws IOException {\n-\t\tfor (ResultPartitionWriter writer : writers) {\n-\t\t\tif (writer instanceof CheckpointedResultPartition) {\n-\t\t\t\t((CheckpointedResultPartition) writer).finishReadRecoveredState(notifyAndBlockOnCompletion);\n-\t\t\t}\n-\t\t}\n-\t}\n+class ResultSubpartitionRecoveredStateHandler\n+        implements RecoveredChannelStateHandler<\n+                ResultSubpartitionInfo, Tuple2<BufferBuilder, BufferConsumer>> {\n+\n+    private final ResultPartitionWriter[] writers;\n+    private final boolean notifyAndBlockOnCompletion;\n+\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    ResultSubpartitionRecoveredStateHandler(\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n+        this.writers = writers;\n+        this.channelMapping = channelMapping;\n+        this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n+    }\n+\n+    @Override\n+    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n+            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        // request the buffer from any mapped subpartition as they all will receive the same buffer\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n+        return new BufferWithContext<>(\n+                wrap(bufferBuilder),\n+                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+    }\n+\n+    @Override\n+    public void recover(\n+            ResultSubpartitionInfo subpartitionInfo,\n+            int oldSubtaskIndex,\n+            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            throws IOException {\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n+                }\n+            }\n+        } finally {\n+            bufferBuilderAndConsumer.f1.close();\n+        }\n+    }\n+\n+    private CheckpointedResultSubpartition getSubpartition(\n+            int partitionIndex, int subPartitionIdx) {\n+        ResultPartitionWriter writer = writers[partitionIndex];\n+        if (!(writer instanceof CheckpointedResultPartition)) {\n+            throw new IllegalStateException(\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n+        }\n+        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> getMappedChannels(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getPartitionIdx(),\n+                        idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<CheckpointedResultSubpartition> subpartitions =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))\n+                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+                        .collect(Collectors.toList());\n+        if (subpartitions.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getPartitionIdx()));\n+        }\n+        return subpartitions;\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+        for (ResultPartitionWriter writer : writers) {\n+            if (writer instanceof CheckpointedResultPartition) {\n+                ((CheckpointedResultPartition) writer)\n+                        .finishReadRecoveredState(notifyAndBlockOnCompletion);\n+            }\n+        }\n+    }\n }\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTYyOA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519169628", "body": "The meaning of these fields is a bit ambiguous to me\r\n- both: is it upstream or downstream?\r\n- channelIndex: is it subPartition or inputChannel?\r\n\r\nSome javadoc would be helpful.", "bodyText": "The meaning of these fields is a bit ambiguous to me\n\nboth: is it upstream or downstream?\nchannelIndex: is it subPartition or inputChannel?\n\nSome javadoc would be helpful.", "bodyHTML": "<p dir=\"auto\">The meaning of these fields is a bit ambiguous to me</p>\n<ul dir=\"auto\">\n<li>both: is it upstream or downstream?</li>\n<li>channelIndex: is it subPartition or inputChannel?</li>\n</ul>\n<p dir=\"auto\">Some javadoc would be helpful.</p>", "author": "rkhachatryan", "createdAt": "2020-11-07T11:52:17Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/**\n+ * An event that is used to demultiplex virtual channels over the same physical channel.\n+ */\n+public final class VirtualChannelSelector extends RuntimeEvent {\n+\n+\tprivate final int subtaskIndex;\n+\tprivate final int channelIndex;", "originalCommit": "215a25d83260a048877bdf8462a06473676efb8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTIyNDQ5Ng==", "url": "https://github.com/apache/flink/pull/13845#discussion_r519224496", "bodyText": "I changed it to the following to clarify that it's always meant to be from the perspective of the input side (where demultiplexing is happening).\n/**\n * An event that is used to demultiplex virtual channels over the same physical channel. The information is to be interpreted from\n * the point of view of the downstream node.\n */\npublic final class VirtualChannelSelector extends RuntimeEvent {\n\n\tprivate final int inputSubtaskIndex;\n\tprivate final int inputChannelIndex;", "author": "AHeise", "createdAt": "2020-11-07T21:59:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2OTYyOA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\ndeleted file mode 100644\nindex 78b17dac7d4..00000000000\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\n+++ /dev/null\n", "chunk": "@@ -1,88 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.runtime.io.network.api;\n-\n-import org.apache.flink.core.memory.DataInputView;\n-import org.apache.flink.core.memory.DataOutputView;\n-import org.apache.flink.runtime.event.RuntimeEvent;\n-\n-import java.util.Objects;\n-\n-/**\n- * An event that is used to demultiplex virtual channels over the same physical channel.\n- */\n-public final class VirtualChannelSelector extends RuntimeEvent {\n-\n-\tprivate final int subtaskIndex;\n-\tprivate final int channelIndex;\n-\n-\tpublic VirtualChannelSelector(int subtaskIndex, int channelIndex) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.channelIndex = channelIndex;\n-\t}\n-\n-\t// ------------------------------------------------------------------------\n-\t// Serialization\n-\t// ------------------------------------------------------------------------\n-\n-\t@Override\n-\tpublic void write(DataOutputView out) {\n-\t\tthrow new UnsupportedOperationException(\"This method should never be called\");\n-\t}\n-\n-\t@Override\n-\tpublic void read(DataInputView in) {\n-\t\tthrow new UnsupportedOperationException(\"This method should never be called\");\n-\t}\n-\n-\t// ------------------------------------------------------------------------\n-\n-\tpublic int getSubtaskIndex() {\n-\t\treturn subtaskIndex;\n-\t}\n-\n-\tpublic int getChannelIndex() {\n-\t\treturn channelIndex;\n-\t}\n-\n-\t@Override\n-\tpublic boolean equals(Object o) {\n-\t\tif (this == o) {\n-\t\t\treturn true;\n-\t\t}\n-\t\tif (o == null || getClass() != o.getClass()) {\n-\t\t\treturn false;\n-\t\t}\n-\t\tfinal VirtualChannelSelector that = (VirtualChannelSelector) o;\n-\t\treturn subtaskIndex == that.subtaskIndex &&\n-\t\t\tchannelIndex == that.channelIndex;\n-\t}\n-\n-\t@Override\n-\tpublic int hashCode() {\n-\t\treturn Objects.hash(subtaskIndex, channelIndex);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"VirtualChannelSelector{\" +\n-\t\t\t\"taskIndex=\" + subtaskIndex +\n-\t\t\t\", channelIndex=\" + channelIndex +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\ndeleted file mode 100644\nindex 78b17dac7d4..00000000000\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\n+++ /dev/null\n", "chunk": "@@ -1,88 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.runtime.io.network.api;\n-\n-import org.apache.flink.core.memory.DataInputView;\n-import org.apache.flink.core.memory.DataOutputView;\n-import org.apache.flink.runtime.event.RuntimeEvent;\n-\n-import java.util.Objects;\n-\n-/**\n- * An event that is used to demultiplex virtual channels over the same physical channel.\n- */\n-public final class VirtualChannelSelector extends RuntimeEvent {\n-\n-\tprivate final int subtaskIndex;\n-\tprivate final int channelIndex;\n-\n-\tpublic VirtualChannelSelector(int subtaskIndex, int channelIndex) {\n-\t\tthis.subtaskIndex = subtaskIndex;\n-\t\tthis.channelIndex = channelIndex;\n-\t}\n-\n-\t// ------------------------------------------------------------------------\n-\t// Serialization\n-\t// ------------------------------------------------------------------------\n-\n-\t@Override\n-\tpublic void write(DataOutputView out) {\n-\t\tthrow new UnsupportedOperationException(\"This method should never be called\");\n-\t}\n-\n-\t@Override\n-\tpublic void read(DataInputView in) {\n-\t\tthrow new UnsupportedOperationException(\"This method should never be called\");\n-\t}\n-\n-\t// ------------------------------------------------------------------------\n-\n-\tpublic int getSubtaskIndex() {\n-\t\treturn subtaskIndex;\n-\t}\n-\n-\tpublic int getChannelIndex() {\n-\t\treturn channelIndex;\n-\t}\n-\n-\t@Override\n-\tpublic boolean equals(Object o) {\n-\t\tif (this == o) {\n-\t\t\treturn true;\n-\t\t}\n-\t\tif (o == null || getClass() != o.getClass()) {\n-\t\t\treturn false;\n-\t\t}\n-\t\tfinal VirtualChannelSelector that = (VirtualChannelSelector) o;\n-\t\treturn subtaskIndex == that.subtaskIndex &&\n-\t\t\tchannelIndex == that.channelIndex;\n-\t}\n-\n-\t@Override\n-\tpublic int hashCode() {\n-\t\treturn Objects.hash(subtaskIndex, channelIndex);\n-\t}\n-\n-\t@Override\n-\tpublic String toString() {\n-\t\treturn \"VirtualChannelSelector{\" +\n-\t\t\t\"taskIndex=\" + subtaskIndex +\n-\t\t\t\", channelIndex=\" + channelIndex +\n-\t\t\t'}';\n-\t}\n-}\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583489658", "body": "I'm wondering whether it's possible that the record will be discarded because the partitioner always chooses the \"other\" subtask?\r\n\r\nFor example, in an up-scaling from 1 to 2 scenario with RoundRobin partitioner:\r\n1. let subtask0.rrPartitioner.nextChannelToSendTo = 0\r\nselectChannel returns 1 - filtered out\r\n2. let subtask1.rrPartitioner.nextChannelToSendTo = 1 (some record was already processed)\r\nselectChannel returns 0 - filtered out", "bodyText": "I'm wondering whether it's possible that the record will be discarded because the partitioner always chooses the \"other\" subtask?\nFor example, in an up-scaling from 1 to 2 scenario with RoundRobin partitioner:\n\nlet subtask0.rrPartitioner.nextChannelToSendTo = 0\nselectChannel returns 1 - filtered out\nlet subtask1.rrPartitioner.nextChannelToSendTo = 1 (some record was already processed)\nselectChannel returns 0 - filtered out", "bodyHTML": "<p dir=\"auto\">I'm wondering whether it's possible that the record will be discarded because the partitioner always chooses the \"other\" subtask?</p>\n<p dir=\"auto\">For example, in an up-scaling from 1 to 2 scenario with RoundRobin partitioner:</p>\n<ol dir=\"auto\">\n<li>let subtask0.rrPartitioner.nextChannelToSendTo = 0<br>\nselectChannel returns 1 - filtered out</li>\n<li>let subtask1.rrPartitioner.nextChannelToSendTo = 1 (some record was already processed)<br>\nselectChannel returns 0 - filtered out</li>\n</ol>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:10:47Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI1ODgxNQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r587258815", "bodyText": "That is a viable concern that I also had. In general, as long as the partitioner is deterministic, it shouldn't happen though:\n\nThe filter is only applied for ambiguous channels. That is, the same data on upstream and downstream is sent to multiple subtasks.\nThe respective channel under filter sees the same buffers in the same order on all subtasks.\nIf the partitioner is deterministic, then all filters of the ambiguous channel have the same state on all subtasks.\nThe partitioner should only yield exactly one channel per replicated record across the subtasks.\n\nNote that Flink's non-deterministic partitioner (ShufflePartitioner) is not ambiguous. Custom partitioners are not supported for that reason unless forced and we should clearly add this reason to the docs.", "author": "AHeise", "createdAt": "2021-03-04T08:33:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODMxNzYyOQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r588317629", "bodyText": "The respective channel under filter sees the same buffers in the same order on all subtasks.\n\nCould you explain why is it the case? E.g. if we upscale form 2 to 3?", "author": "rkhachatryan", "createdAt": "2021-03-05T14:03:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MTMwMTc0Ng==", "url": "https://github.com/apache/flink/pull/13845#discussion_r591301746", "bodyText": "I was assuming that each partitioner is used at most by one filter and that in turn is uniquely associated with exactly one virtual channel. Upon reinspection, it turned out that the partitioner cache inside the RecordFilterFactory actually violated that assumption and it turns out that you are correct.\nCurrently, the filter is only used for keyed exchanges and blinks hash partitioner where the partitioners are stateless. However, that may not be true in the future and it also doesn't necessarily hold for custom partitioners when they are forced.\nHowever, since the retrieval of the partitioner is rather costly for one input tasks, I retained the cache and instead rely on a proper StreamPartitioner#copy implementation. Note that indeed quite a few of these implementations are a bit whacky (returning this although the partitioner is stateful), but none of that applies to the partitioner that produce ambiguous channels, so I left as is for now.", "author": "AHeise", "createdAt": "2021-03-10T10:02:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MTM2ODMyNg==", "url": "https://github.com/apache/flink/pull/13845#discussion_r591368326", "bodyText": "I'm afraid we can't rely on KeyGroupStreamPartitioner.copy (actually all except Shuffle return this):\n    public StreamPartitioner<T> copy() {\n        return this;\n    }\n\nedit:  KeyGroupStreamPartitioner uses SubtaskStateMapper.RANGE which is ambiguous", "author": "rkhachatryan", "createdAt": "2021-03-10T11:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MTQwNjAyNQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r591406025", "bodyText": "Discussed offline:\n\nRebalancePartitioner is stateful but uses non-ambiguous SubtaskStateMapper.ROUND_ROBIN\nKeyGroupStreamPartitioner uses ambiguous SubtaskStateMapper.RANGE but is stateless", "author": "rkhachatryan", "createdAt": "2021-03-10T11:48:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ4OTY1OA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java\ndeleted file mode 100644\nindex a0f805f27b5..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java\n+++ /dev/null\n", "chunk": "@@ -1,64 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io.recovery;\n-\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n-import org.apache.flink.runtime.plugable.SerializationDelegate;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-\n-import java.util.function.Predicate;\n-\n-/**\n- * Filters records for ambiguous channel mappings.\n- *\n- * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n- * the output side on te upstream node needs to be replicated to both channels. This filter then\n- * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n- * records.\n- *\n- * @param <T>\n- */\n-class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n-    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n-\n-    private final SerializationDelegate<StreamRecord<T>> delegate;\n-\n-    private final int subtaskIndex;\n-\n-    public RecordFilter(\n-            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n-            TypeSerializer<T> inputSerializer,\n-            int subtaskIndex) {\n-        this.partitioner = partitioner;\n-        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n-        this.subtaskIndex = subtaskIndex;\n-    }\n-\n-    public static <T> Predicate<StreamRecord<T>> all() {\n-        return record -> true;\n-    }\n-\n-    @Override\n-    public boolean test(StreamRecord<T> streamRecord) {\n-        delegate.setInstance(streamRecord);\n-        // check if record would have arrived at this subtask if it had been partitioned upstream\n-        return partitioner.selectChannel(delegate) == subtaskIndex;\n-    }\n-}\n", "next_change": {"commit": "9232f328fcb33993f49e2a182b700111a890784a", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java\nnew file mode 100644\nindex 00000000000..a0f805f27b5\n--- /dev/null\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RecordFilter.java\n", "chunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;\n+import org.apache.flink.runtime.plugable.SerializationDelegate;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElementSerializer;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+\n+import java.util.function.Predicate;\n+\n+/**\n+ * Filters records for ambiguous channel mappings.\n+ *\n+ * <p>For example, when the downstream node of a keyed exchange is scaled from 1 to 2, the state of\n+ * the output side on te upstream node needs to be replicated to both channels. This filter then\n+ * checks the deserialized records on both downstream subtasks and filters out the irrelevant\n+ * records.\n+ *\n+ * @param <T>\n+ */\n+class RecordFilter<T> implements Predicate<StreamRecord<T>> {\n+    private final ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner;\n+\n+    private final SerializationDelegate<StreamRecord<T>> delegate;\n+\n+    private final int subtaskIndex;\n+\n+    public RecordFilter(\n+            ChannelSelector<SerializationDelegate<StreamRecord<T>>> partitioner,\n+            TypeSerializer<T> inputSerializer,\n+            int subtaskIndex) {\n+        this.partitioner = partitioner;\n+        delegate = new SerializationDelegate<>(new StreamElementSerializer(inputSerializer));\n+        this.subtaskIndex = subtaskIndex;\n+    }\n+\n+    public static <T> Predicate<StreamRecord<T>> all() {\n+        return record -> true;\n+    }\n+\n+    @Override\n+    public boolean test(StreamRecord<T> streamRecord) {\n+        delegate.setInstance(streamRecord);\n+        // check if record would have arrived at this subtask if it had been partitioned upstream\n+        return partitioner.selectChannel(delegate) == subtaskIndex;\n+    }\n+}\n", "next_change": null}]}}]}, "revised_code_in_main": null, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MDQyMA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583490420", "body": "Should it be in `finally`?", "bodyText": "Should it be in finally?", "bodyHTML": "<p dir=\"auto\">Should it be in <code>finally</code>?</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:11:55Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -45,32 +55,46 @@\n \n     BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-    void recover(Info info, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n class InputChannelRecoveredStateHandler\n         implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n     private final InputGate[] inputGates;\n \n-    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n         this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n     }\n \n     @Override\n     public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n             throws IOException, InterruptedException {\n-        RecoveredInputChannel channel = getChannel(channelInfo);\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n         Buffer buffer = channel.requestBufferBlocking();\n         return new BufferWithContext<>(wrap(buffer), buffer);\n     }\n \n     @Override\n-    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n         if (buffer.readableBytes() > 0) {\n-            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n-        } else {\n-            buffer.recycleBuffer();\n+            for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                channel.onRecoveredStateBuffer(\n+                        EventSerializer.toBuffer(\n+                                new VirtualChannelSelector(\n+                                        oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                false));\n+                channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+            }\n         }\n+        buffer.recycleBuffer();", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 5a21759c6b7..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -55,46 +45,32 @@ interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n \n     BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n+    void recover(Info info, Context context) throws IOException;\n }\n \n class InputChannelRecoveredStateHandler\n         implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n     private final InputGate[] inputGates;\n \n-    private final InflightDataRescalingDescriptor channelMapping;\n-\n-    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n-            new HashMap<>();\n-\n-    InputChannelRecoveredStateHandler(\n-            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n+    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n         this.inputGates = inputGates;\n-        this.channelMapping = channelMapping;\n     }\n \n     @Override\n     public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n             throws IOException, InterruptedException {\n-        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n+        RecoveredInputChannel channel = getChannel(channelInfo);\n         Buffer buffer = channel.requestBufferBlocking();\n         return new BufferWithContext<>(wrap(buffer), buffer);\n     }\n \n     @Override\n-    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n-            throws IOException {\n+    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n         if (buffer.readableBytes() > 0) {\n-            for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-                channel.onRecoveredStateBuffer(\n-                        EventSerializer.toBuffer(\n-                                new VirtualChannelSelector(\n-                                        oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n-                                false));\n-                channel.onRecoveredStateBuffer(buffer.retainBuffer());\n-            }\n+            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n+        } else {\n+            buffer.recycleBuffer();\n         }\n-        buffer.recycleBuffer();\n     }\n \n     @Override\n", "next_change": {"commit": "6771250a1599f99d21a0f00f45cf43e478e81f4b", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex a3076219b68..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -45,30 +55,49 @@ interface RecoveredChannelStateHandler<Info, Context> extends AutoCloseable {\n \n     BufferWithContext<Context> getBuffer(Info info) throws IOException, InterruptedException;\n \n-    void recover(Info info, Context context) throws IOException;\n+    void recover(Info info, int oldSubtaskIndex, Context context) throws IOException;\n }\n \n class InputChannelRecoveredStateHandler\n         implements RecoveredChannelStateHandler<InputChannelInfo, Buffer> {\n     private final InputGate[] inputGates;\n \n-    InputChannelRecoveredStateHandler(InputGate[] inputGates) {\n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<InputChannelInfo, List<RecoveredInputChannel>> rescaledChannels =\n+            new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n+    InputChannelRecoveredStateHandler(\n+            InputGate[] inputGates, InflightDataRescalingDescriptor channelMapping) {\n         this.inputGates = inputGates;\n+        this.channelMapping = channelMapping;\n     }\n \n     @Override\n     public BufferWithContext<Buffer> getBuffer(InputChannelInfo channelInfo)\n             throws IOException, InterruptedException {\n-        RecoveredInputChannel channel = getChannel(channelInfo);\n+        // request the buffer from any mapped channel as they all will receive the same buffer\n+        RecoveredInputChannel channel = getMappedChannels(channelInfo).get(0);\n         Buffer buffer = channel.requestBufferBlocking();\n         return new BufferWithContext<>(wrap(buffer), buffer);\n     }\n \n     @Override\n-    public void recover(InputChannelInfo channelInfo, Buffer buffer) {\n-        if (buffer.readableBytes() > 0) {\n-            getChannel(channelInfo).onRecoveredStateBuffer(buffer);\n-        } else {\n+    public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n+            throws IOException {\n+        try {\n+            if (buffer.readableBytes() > 0) {\n+                for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                    channel.onRecoveredStateBuffer(\n+                            EventSerializer.toBuffer(\n+                                    new SubtaskConnectionDescriptor(\n+                                            oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                    false));\n+                    channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+                }\n+            }\n+        } finally {\n             buffer.recycleBuffer();\n         }\n     }\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 5a21759c6b7..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -84,17 +86,20 @@ class InputChannelRecoveredStateHandler\n     @Override\n     public void recover(InputChannelInfo channelInfo, int oldSubtaskIndex, Buffer buffer)\n             throws IOException {\n-        if (buffer.readableBytes() > 0) {\n-            for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n-                channel.onRecoveredStateBuffer(\n-                        EventSerializer.toBuffer(\n-                                new VirtualChannelSelector(\n-                                        oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n-                                false));\n-                channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+        try {\n+            if (buffer.readableBytes() > 0) {\n+                for (final RecoveredInputChannel channel : getMappedChannels(channelInfo)) {\n+                    channel.onRecoveredStateBuffer(\n+                            EventSerializer.toBuffer(\n+                                    new SubtaskConnectionDescriptor(\n+                                            oldSubtaskIndex, channelInfo.getInputChannelIdx()),\n+                                    false));\n+                    channel.onRecoveredStateBuffer(buffer.retainBuffer());\n+                }\n             }\n+        } finally {\n+            buffer.recycleBuffer();\n         }\n-        buffer.recycleBuffer();\n     }\n \n     @Override\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MDc2MQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583490761", "body": "Should it be in `finally`?", "bodyText": "Should it be in finally?", "bodyHTML": "<p dir=\"auto\">Should it be in <code>finally</code>?</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:12:29Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -121,27 +181,59 @@ public void recover(\n                     \"ResultSubpartitionRecoveredStateHandler#recover\",\n                     bufferBuilderAndConsumer.f1,\n                     subpartitionInfo);\n-            boolean added =\n-                    getSubpartition(subpartitionInfo)\n-                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-            if (!added) {\n-                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+            final List<CheckpointedResultSubpartition> channels =\n+                    getMappedChannels(subpartitionInfo);\n+            for (final CheckpointedResultSubpartition channel : channels) {\n+                // channel selector is created from the downstream's point of view: the subtask of\n+                // downstream = subpartition index of recovered buffer\n+                final VirtualChannelSelector channelSelector =\n+                        new VirtualChannelSelector(\n+                                subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                channel.add(\n+                        EventSerializer.toBufferConsumer(channelSelector, false),\n+                        Integer.MIN_VALUE);\n+                boolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                if (!added) {\n+                    throw new IOException(\n+                            \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                }\n             }\n-        } else {\n-            bufferBuilderAndConsumer.f1.close();\n         }\n+        bufferBuilderAndConsumer.f1.close();", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 5a21759c6b7..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -181,59 +121,27 @@ class ResultSubpartitionRecoveredStateHandler\n                     \"ResultSubpartitionRecoveredStateHandler#recover\",\n                     bufferBuilderAndConsumer.f1,\n                     subpartitionInfo);\n-            final List<CheckpointedResultSubpartition> channels =\n-                    getMappedChannels(subpartitionInfo);\n-            for (final CheckpointedResultSubpartition channel : channels) {\n-                // channel selector is created from the downstream's point of view: the subtask of\n-                // downstream = subpartition index of recovered buffer\n-                final VirtualChannelSelector channelSelector =\n-                        new VirtualChannelSelector(\n-                                subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-                channel.add(\n-                        EventSerializer.toBufferConsumer(channelSelector, false),\n-                        Integer.MIN_VALUE);\n-                boolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-                if (!added) {\n-                    throw new IOException(\n-                            \"Buffer consumer couldn't be added to ResultSubpartition\");\n-                }\n+            boolean added =\n+                    getSubpartition(subpartitionInfo)\n+                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n+            if (!added) {\n+                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n             }\n+        } else {\n+            bufferBuilderAndConsumer.f1.close();\n         }\n-        bufferBuilderAndConsumer.f1.close();\n     }\n \n     private CheckpointedResultSubpartition getSubpartition(\n-            int partitionIndex, int subPartitionIdx) {\n-        ResultPartitionWriter writer = writers[partitionIndex];\n-        if (!(writer instanceof CheckpointedResultPartition)) {\n-            throw new IllegalStateException(\n-                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n-        }\n-        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n-    }\n-\n-    private List<CheckpointedResultSubpartition> getMappedChannels(\n             ResultSubpartitionInfo subpartitionInfo) {\n-        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n-    }\n-\n-    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n-        final RescaledChannelsMapping rescaledChannelsMapping =\n-                channelMapping.getChannelMapping(info.getPartitionIdx());\n-        final List<CheckpointedResultSubpartition> subpartitions =\n-                Arrays.stream(\n-                                rescaledChannelsMapping.getNewChannelIndexes(\n-                                        info.getSubPartitionIdx()))\n-                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n-                        .collect(Collectors.toList());\n-        if (subpartitions.isEmpty()) {\n+        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n+        if (writer instanceof CheckpointedResultPartition) {\n+            return ((CheckpointedResultPartition) writer)\n+                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n+        } else {\n             throw new IllegalStateException(\n-                    \"Recovered a buffer from old \"\n-                            + info\n-                            + \" that has no mapping in \"\n-                            + rescaledChannelsMapping);\n+                    \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n         }\n-        return subpartitions;\n     }\n \n     @Override\n", "next_change": {"commit": "6771250a1599f99d21a0f00f45cf43e478e81f4b", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex a3076219b68..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -113,35 +178,73 @@ class ResultSubpartitionRecoveredStateHandler\n     @Override\n     public void recover(\n             ResultSubpartitionInfo subpartitionInfo,\n+            int oldSubtaskIndex,\n             Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n             throws IOException {\n-        bufferBuilderAndConsumer.f0.finish();\n-        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-            NetworkActionsLogger.traceRecover(\n-                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n-                    bufferBuilderAndConsumer.f1,\n-                    subpartitionInfo);\n-            boolean added =\n-                    getSubpartition(subpartitionInfo)\n-                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-            if (!added) {\n-                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n+                }\n             }\n-        } else {\n+        } finally {\n             bufferBuilderAndConsumer.f1.close();\n         }\n     }\n \n     private CheckpointedResultSubpartition getSubpartition(\n-            ResultSubpartitionInfo subpartitionInfo) {\n-        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-        if (writer instanceof CheckpointedResultPartition) {\n-            return ((CheckpointedResultPartition) writer)\n-                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-        } else {\n+            int partitionIndex, int subPartitionIdx) {\n+        ResultPartitionWriter writer = writers[partitionIndex];\n+        if (!(writer instanceof CheckpointedResultPartition)) {\n             throw new IllegalStateException(\n                     \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n         }\n+        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> getMappedChannels(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getPartitionIdx(),\n+                        idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<CheckpointedResultSubpartition> subpartitions =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))\n+                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+                        .collect(Collectors.toList());\n+        if (subpartitions.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getPartitionIdx()));\n+        }\n+        return subpartitions;\n     }\n \n     @Override\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 5a21759c6b7..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -175,31 +181,36 @@ class ResultSubpartitionRecoveredStateHandler\n             int oldSubtaskIndex,\n             Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n             throws IOException {\n-        bufferBuilderAndConsumer.f0.finish();\n-        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-            NetworkActionsLogger.traceRecover(\n-                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n-                    bufferBuilderAndConsumer.f1,\n-                    subpartitionInfo);\n-            final List<CheckpointedResultSubpartition> channels =\n-                    getMappedChannels(subpartitionInfo);\n-            for (final CheckpointedResultSubpartition channel : channels) {\n-                // channel selector is created from the downstream's point of view: the subtask of\n-                // downstream = subpartition index of recovered buffer\n-                final VirtualChannelSelector channelSelector =\n-                        new VirtualChannelSelector(\n-                                subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-                channel.add(\n-                        EventSerializer.toBufferConsumer(channelSelector, false),\n-                        Integer.MIN_VALUE);\n-                boolean added = channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-                if (!added) {\n-                    throw new IOException(\n-                            \"Buffer consumer couldn't be added to ResultSubpartition\");\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n                 }\n             }\n+        } finally {\n+            bufferBuilderAndConsumer.f1.close();\n         }\n-        bufferBuilderAndConsumer.f1.close();\n     }\n \n     private CheckpointedResultSubpartition getSubpartition(\n", "next_change": {"commit": "2293362f0a144f47e182039c26c0d7047f87232a", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 86894c9f86f..d8a2baa2610 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -165,51 +176,39 @@ class ResultSubpartitionRecoveredStateHandler\n     }\n \n     @Override\n-    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n-            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+    public BufferWithContext<BufferBuilder> getBuffer(ResultSubpartitionInfo subpartitionInfo)\n+            throws IOException, InterruptedException {\n         // request the buffer from any mapped subpartition as they all will receive the same buffer\n         final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n         BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-        return new BufferWithContext<>(\n-                wrap(bufferBuilder),\n-                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+        return new BufferWithContext<>(wrap(bufferBuilder), bufferBuilder);\n     }\n \n     @Override\n     public void recover(\n             ResultSubpartitionInfo subpartitionInfo,\n             int oldSubtaskIndex,\n-            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            BufferWithContext<BufferBuilder> bufferWithContext)\n             throws IOException {\n-        try {\n-            bufferBuilderAndConsumer.f0.finish();\n-            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-                NetworkActionsLogger.traceRecover(\n-                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n-                        bufferBuilderAndConsumer.f1,\n-                        subpartitionInfo);\n-                final List<CheckpointedResultSubpartition> channels =\n-                        getMappedChannels(subpartitionInfo);\n-                for (final CheckpointedResultSubpartition channel : channels) {\n-                    // channel selector is created from the downstream's point of view: the subtask\n-                    // of\n-                    // downstream = subpartition index of recovered buffer\n-                    final SubtaskConnectionDescriptor channelSelector =\n-                            new SubtaskConnectionDescriptor(\n-                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-                    channel.add(\n-                            EventSerializer.toBufferConsumer(channelSelector, false),\n-                            Integer.MIN_VALUE);\n-                    boolean added =\n-                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-                    if (!added) {\n-                        throw new IOException(\n-                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+        try (BufferBuilder bufferBuilder = bufferWithContext.context) {\n+            try (BufferConsumer bufferConsumer =\n+                    bufferBuilder.createBufferConsumerFromBeginning()) {\n+                bufferBuilder.finish();\n+                if (bufferConsumer.isDataAvailable()) {\n+                    final List<CheckpointedResultSubpartition> channels =\n+                            getMappedChannels(subpartitionInfo);\n+                    for (final CheckpointedResultSubpartition channel : channels) {\n+                        // channel selector is created from the downstream's point of view: the\n+                        // subtask of downstream = subpartition index of recovered buffer\n+                        final SubtaskConnectionDescriptor channelSelector =\n+                                new SubtaskConnectionDescriptor(\n+                                        subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                        channel.addRecovered(\n+                                EventSerializer.toBufferConsumer(channelSelector, false));\n+                        channel.addRecovered(bufferConsumer.copy());\n                     }\n                 }\n             }\n-        } finally {\n-            bufferBuilderAndConsumer.f1.close();\n         }\n     }\n \n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5MTgyMA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583491820", "body": "I guess `get(0)` is used here because the actual subpartition that we use to request a buffer from doesn't matter.\r\nIf so, could you please add a comment in the code?", "bodyText": "I guess get(0) is used here because the actual subpartition that we use to request a buffer from doesn't matter.\nIf so, could you please add a comment in the code?", "bodyHTML": "<p dir=\"auto\">I guess <code>get(0)</code> is used here because the actual subpartition that we use to request a buffer from doesn't matter.<br>\nIf so, could you please add a comment in the code?</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:14:09Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java", "diffHunk": "@@ -94,17 +145,25 @@ private RecoveredInputChannel getChannel(InputChannelInfo info) {\n     private final ResultPartitionWriter[] writers;\n     private final boolean notifyAndBlockOnCompletion;\n \n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+\n     ResultSubpartitionRecoveredStateHandler(\n-            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n         this.writers = writers;\n+        this.channelMapping = channelMapping;\n         this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n     }\n \n     @Override\n     public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n             ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-        BufferBuilder bufferBuilder =\n-                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 5a21759c6b7..a3076219b68 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -145,25 +94,17 @@ class ResultSubpartitionRecoveredStateHandler\n     private final ResultPartitionWriter[] writers;\n     private final boolean notifyAndBlockOnCompletion;\n \n-    private final InflightDataRescalingDescriptor channelMapping;\n-\n-    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n-            rescaledChannels = new HashMap<>();\n-\n     ResultSubpartitionRecoveredStateHandler(\n-            ResultPartitionWriter[] writers,\n-            boolean notifyAndBlockOnCompletion,\n-            InflightDataRescalingDescriptor channelMapping) {\n+            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n         this.writers = writers;\n-        this.channelMapping = channelMapping;\n         this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n     }\n \n     @Override\n     public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n             ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n-        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n+        BufferBuilder bufferBuilder =\n+                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n         return new BufferWithContext<>(\n                 wrap(bufferBuilder),\n                 Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n", "next_change": {"commit": "6771250a1599f99d21a0f00f45cf43e478e81f4b", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex a3076219b68..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -94,17 +149,27 @@ class ResultSubpartitionRecoveredStateHandler\n     private final ResultPartitionWriter[] writers;\n     private final boolean notifyAndBlockOnCompletion;\n \n+    private final InflightDataRescalingDescriptor channelMapping;\n+\n+    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>\n+            rescaledChannels = new HashMap<>();\n+    private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();\n+\n     ResultSubpartitionRecoveredStateHandler(\n-            ResultPartitionWriter[] writers, boolean notifyAndBlockOnCompletion) {\n+            ResultPartitionWriter[] writers,\n+            boolean notifyAndBlockOnCompletion,\n+            InflightDataRescalingDescriptor channelMapping) {\n         this.writers = writers;\n+        this.channelMapping = channelMapping;\n         this.notifyAndBlockOnCompletion = notifyAndBlockOnCompletion;\n     }\n \n     @Override\n     public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n             ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n-        BufferBuilder bufferBuilder =\n-                getSubpartition(subpartitionInfo).requestBufferBuilderBlocking();\n+        // request the buffer from any mapped subpartition as they all will receive the same buffer\n+        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n+        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n         return new BufferWithContext<>(\n                 wrap(bufferBuilder),\n                 Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n", "next_change": null}, {"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex a3076219b68..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -113,35 +178,73 @@ class ResultSubpartitionRecoveredStateHandler\n     @Override\n     public void recover(\n             ResultSubpartitionInfo subpartitionInfo,\n+            int oldSubtaskIndex,\n             Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n             throws IOException {\n-        bufferBuilderAndConsumer.f0.finish();\n-        if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-            NetworkActionsLogger.traceRecover(\n-                    \"ResultSubpartitionRecoveredStateHandler#recover\",\n-                    bufferBuilderAndConsumer.f1,\n-                    subpartitionInfo);\n-            boolean added =\n-                    getSubpartition(subpartitionInfo)\n-                            .add(bufferBuilderAndConsumer.f1, Integer.MIN_VALUE);\n-            if (!added) {\n-                throw new IOException(\"Buffer consumer couldn't be added to ResultSubpartition\");\n+        try {\n+            bufferBuilderAndConsumer.f0.finish();\n+            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n+                NetworkActionsLogger.traceRecover(\n+                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n+                        bufferBuilderAndConsumer.f1,\n+                        subpartitionInfo);\n+                final List<CheckpointedResultSubpartition> channels =\n+                        getMappedChannels(subpartitionInfo);\n+                for (final CheckpointedResultSubpartition channel : channels) {\n+                    // channel selector is created from the downstream's point of view: the subtask\n+                    // of\n+                    // downstream = subpartition index of recovered buffer\n+                    final SubtaskConnectionDescriptor channelSelector =\n+                            new SubtaskConnectionDescriptor(\n+                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                    channel.add(\n+                            EventSerializer.toBufferConsumer(channelSelector, false),\n+                            Integer.MIN_VALUE);\n+                    boolean added =\n+                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n+                    if (!added) {\n+                        throw new IOException(\n+                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+                    }\n+                }\n             }\n-        } else {\n+        } finally {\n             bufferBuilderAndConsumer.f1.close();\n         }\n     }\n \n     private CheckpointedResultSubpartition getSubpartition(\n-            ResultSubpartitionInfo subpartitionInfo) {\n-        ResultPartitionWriter writer = writers[subpartitionInfo.getPartitionIdx()];\n-        if (writer instanceof CheckpointedResultPartition) {\n-            return ((CheckpointedResultPartition) writer)\n-                    .getCheckpointedSubpartition(subpartitionInfo.getSubPartitionIdx());\n-        } else {\n+            int partitionIndex, int subPartitionIdx) {\n+        ResultPartitionWriter writer = writers[partitionIndex];\n+        if (!(writer instanceof CheckpointedResultPartition)) {\n             throw new IllegalStateException(\n                     \"Cannot restore state to a non-checkpointable partition type: \" + writer);\n         }\n+        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> getMappedChannels(\n+            ResultSubpartitionInfo subpartitionInfo) {\n+        return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);\n+    }\n+\n+    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {\n+        final RescaleMappings oldToNewMapping =\n+                oldToNewMappings.computeIfAbsent(\n+                        info.getPartitionIdx(),\n+                        idx -> channelMapping.getChannelMapping(idx).invert());\n+        final List<CheckpointedResultSubpartition> subpartitions =\n+                Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))\n+                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))\n+                        .collect(Collectors.toList());\n+        if (subpartitions.isEmpty()) {\n+            throw new IllegalStateException(\n+                    \"Recovered a buffer from old \"\n+                            + info\n+                            + \" that has no mapping in \"\n+                            + channelMapping.getChannelMapping(info.getPartitionIdx()));\n+        }\n+        return subpartitions;\n     }\n \n     @Override\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 5a21759c6b7..86894c9f86f 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -162,6 +167,7 @@ class ResultSubpartitionRecoveredStateHandler\n     @Override\n     public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n             ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+        // request the buffer from any mapped subpartition as they all will receive the same buffer\n         final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n         BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n         return new BufferWithContext<>(\n", "next_change": {"commit": "2293362f0a144f47e182039c26c0d7047f87232a", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\nindex 86894c9f86f..d8a2baa2610 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java\n", "chunk": "@@ -165,51 +176,39 @@ class ResultSubpartitionRecoveredStateHandler\n     }\n \n     @Override\n-    public BufferWithContext<Tuple2<BufferBuilder, BufferConsumer>> getBuffer(\n-            ResultSubpartitionInfo subpartitionInfo) throws IOException, InterruptedException {\n+    public BufferWithContext<BufferBuilder> getBuffer(ResultSubpartitionInfo subpartitionInfo)\n+            throws IOException, InterruptedException {\n         // request the buffer from any mapped subpartition as they all will receive the same buffer\n         final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);\n         BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();\n-        return new BufferWithContext<>(\n-                wrap(bufferBuilder),\n-                Tuple2.of(bufferBuilder, bufferBuilder.createBufferConsumer()));\n+        return new BufferWithContext<>(wrap(bufferBuilder), bufferBuilder);\n     }\n \n     @Override\n     public void recover(\n             ResultSubpartitionInfo subpartitionInfo,\n             int oldSubtaskIndex,\n-            Tuple2<BufferBuilder, BufferConsumer> bufferBuilderAndConsumer)\n+            BufferWithContext<BufferBuilder> bufferWithContext)\n             throws IOException {\n-        try {\n-            bufferBuilderAndConsumer.f0.finish();\n-            if (bufferBuilderAndConsumer.f1.isDataAvailable()) {\n-                NetworkActionsLogger.traceRecover(\n-                        \"ResultSubpartitionRecoveredStateHandler#recover\",\n-                        bufferBuilderAndConsumer.f1,\n-                        subpartitionInfo);\n-                final List<CheckpointedResultSubpartition> channels =\n-                        getMappedChannels(subpartitionInfo);\n-                for (final CheckpointedResultSubpartition channel : channels) {\n-                    // channel selector is created from the downstream's point of view: the subtask\n-                    // of\n-                    // downstream = subpartition index of recovered buffer\n-                    final SubtaskConnectionDescriptor channelSelector =\n-                            new SubtaskConnectionDescriptor(\n-                                    subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n-                    channel.add(\n-                            EventSerializer.toBufferConsumer(channelSelector, false),\n-                            Integer.MIN_VALUE);\n-                    boolean added =\n-                            channel.add(bufferBuilderAndConsumer.f1.copy(), Integer.MIN_VALUE);\n-                    if (!added) {\n-                        throw new IOException(\n-                                \"Buffer consumer couldn't be added to ResultSubpartition\");\n+        try (BufferBuilder bufferBuilder = bufferWithContext.context) {\n+            try (BufferConsumer bufferConsumer =\n+                    bufferBuilder.createBufferConsumerFromBeginning()) {\n+                bufferBuilder.finish();\n+                if (bufferConsumer.isDataAvailable()) {\n+                    final List<CheckpointedResultSubpartition> channels =\n+                            getMappedChannels(subpartitionInfo);\n+                    for (final CheckpointedResultSubpartition channel : channels) {\n+                        // channel selector is created from the downstream's point of view: the\n+                        // subtask of downstream = subpartition index of recovered buffer\n+                        final SubtaskConnectionDescriptor channelSelector =\n+                                new SubtaskConnectionDescriptor(\n+                                        subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);\n+                        channel.addRecovered(\n+                                EventSerializer.toBufferConsumer(channelSelector, false));\n+                        channel.addRecovered(bufferConsumer.copy());\n                     }\n                 }\n             }\n-        } finally {\n-            bufferBuilderAndConsumer.f1.close();\n         }\n     }\n \n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "72cec554c4a78e656ad8f462372444f77eb6a801", "committedDate": "2021-04-29 17:13:44 +0200", "message": "[FLINK-22232][network] Add task name to output recovery tracing."}, {"oid": "2293362f0a144f47e182039c26c0d7047f87232a", "committedDate": "2021-06-04 13:51:32 +0200", "message": "[FLINK-22376][runtime] RecoveredChannelStateHandler requires the ownership of the input Buffer"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583498113", "body": "nit: To me `SubtaskConnectionDescriptor` would be more informative. But that's a matter of taste so please ignore if you prefer `VirtualChannelSelector`.\r\n\r\nnit: virtual/physical channels in javadoc are confusing to me. How about channels before/after re-scaling? For example:\r\nAn event sent over a channel **after re-scaling** to signal what channel was used **before re-scaling** for the data being sent.", "bodyText": "nit: To me SubtaskConnectionDescriptor would be more informative. But that's a matter of taste so please ignore if you prefer VirtualChannelSelector.\nnit: virtual/physical channels in javadoc are confusing to me. How about channels before/after re-scaling? For example:\nAn event sent over a channel after re-scaling to signal what channel was used before re-scaling for the data being sent.", "bodyHTML": "<p dir=\"auto\">nit: To me <code>SubtaskConnectionDescriptor</code> would be more informative. But that's a matter of taste so please ignore if you prefer <code>VirtualChannelSelector</code>.</p>\n<p dir=\"auto\">nit: virtual/physical channels in javadoc are confusing to me. How about channels before/after re-scaling? For example:<br>\nAn event sent over a channel <strong>after re-scaling</strong> to signal what channel was used <strong>before re-scaling</strong> for the data being sent.</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:23:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.io.network.api;\n+\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+import org.apache.flink.runtime.event.RuntimeEvent;\n+\n+import java.util.Objects;\n+\n+/** An event that is used to demultiplex virtual channels over the same physical channel. */\n+public final class VirtualChannelSelector extends RuntimeEvent {", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI3NjgwNQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r587276805", "bodyText": "Yes, you are right. When I started I was still using channel indexes but at some point I changed it. Please check if the javadoc is more informative to you now.", "author": "AHeise", "createdAt": "2021-03-04T08:54:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODMxOTYzNA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r588319634", "bodyText": "Yes, looks good, thanks!", "author": "rkhachatryan", "createdAt": "2021-03-05T14:06:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5ODExMw=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\ndeleted file mode 100644\nindex bab2138ce0b..00000000000\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\n+++ /dev/null\n", "chunk": "@@ -1,88 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.runtime.io.network.api;\n-\n-import org.apache.flink.core.memory.DataInputView;\n-import org.apache.flink.core.memory.DataOutputView;\n-import org.apache.flink.runtime.event.RuntimeEvent;\n-\n-import java.util.Objects;\n-\n-/** An event that is used to demultiplex virtual channels over the same physical channel. */\n-public final class VirtualChannelSelector extends RuntimeEvent {\n-\n-    private final int inputSubtaskIndex;\n-    private final int outputSubtaskIndex;\n-\n-    public VirtualChannelSelector(int inputSubtaskIndex, int outputSubtaskIndex) {\n-        this.inputSubtaskIndex = inputSubtaskIndex;\n-        this.outputSubtaskIndex = outputSubtaskIndex;\n-    }\n-\n-    // ------------------------------------------------------------------------\n-    // Serialization\n-    // ------------------------------------------------------------------------\n-\n-    @Override\n-    public void write(DataOutputView out) {\n-        throw new UnsupportedOperationException(\"This method should never be called\");\n-    }\n-\n-    @Override\n-    public void read(DataInputView in) {\n-        throw new UnsupportedOperationException(\"This method should never be called\");\n-    }\n-\n-    // ------------------------------------------------------------------------\n-\n-    public int getInputSubtaskIndex() {\n-        return inputSubtaskIndex;\n-    }\n-\n-    public int getOutputSubtaskIndex() {\n-        return outputSubtaskIndex;\n-    }\n-\n-    @Override\n-    public boolean equals(Object o) {\n-        if (this == o) {\n-            return true;\n-        }\n-        if (o == null || getClass() != o.getClass()) {\n-            return false;\n-        }\n-        final VirtualChannelSelector that = (VirtualChannelSelector) o;\n-        return inputSubtaskIndex == that.inputSubtaskIndex\n-                && outputSubtaskIndex == that.outputSubtaskIndex;\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return Objects.hash(inputSubtaskIndex, outputSubtaskIndex);\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return \"VirtualChannelSelector{\"\n-                + \"inputSubtaskIndex=\"\n-                + inputSubtaskIndex\n-                + \", inputChannelIndex=\"\n-                + outputSubtaskIndex\n-                + '}';\n-    }\n-}\n", "next_change": null}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/SubtaskConnectionDescriptor.java\nsimilarity index 76%\nrename from flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\nrename to flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/SubtaskConnectionDescriptor.java\nindex bab2138ce0b..b46d5f29585 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/VirtualChannelSelector.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/SubtaskConnectionDescriptor.java\n", "chunk": "@@ -23,13 +23,20 @@ import org.apache.flink.runtime.event.RuntimeEvent;\n \n import java.util.Objects;\n \n-/** An event that is used to demultiplex virtual channels over the same physical channel. */\n-public final class VirtualChannelSelector extends RuntimeEvent {\n+/**\n+ * An event that is used to (de)multiplex old channels over the same new channel.\n+ *\n+ * <p>During unaligned checkpoint recovery, if there is a rescaling, channels from the previous run\n+ * may not be available anymore for restoring the data. In that case, the data of several old\n+ * channels is sent over the same new channel through multiplexing. Each buffer is following this\n+ * {@code SubtaskConnectionDescriptor} such that the receiver can demultiplex them.\n+ */\n+public final class SubtaskConnectionDescriptor extends RuntimeEvent {\n \n     private final int inputSubtaskIndex;\n     private final int outputSubtaskIndex;\n \n-    public VirtualChannelSelector(int inputSubtaskIndex, int outputSubtaskIndex) {\n+    public SubtaskConnectionDescriptor(int inputSubtaskIndex, int outputSubtaskIndex) {\n         this.inputSubtaskIndex = inputSubtaskIndex;\n         this.outputSubtaskIndex = outputSubtaskIndex;\n     }\n", "next_change": null}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzQ5OTU2Ng==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583499566", "body": "How about moving this (and other) static methods to a dedicated factory class?\r\nTo me the responsibility of this class would be more clear.", "bodyText": "How about moving this (and other) static methods to a dedicated factory class?\nTo me the responsibility of this class would be more clear.", "bodyHTML": "<p dir=\"auto\">How about moving this (and other) static methods to a dedicated factory class?<br>\nTo me the responsibility of this class would be more clear.</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:26:09Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 0fe60f4f02a..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,280 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io.recovery;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.TaskInfo;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.CheckpointException;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-\n-import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases. *\n- *\n- * <ul>\n- *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n- *       channels (mostly relevant to keyed exchanges).\n- * </ul>\n- *\n- * <p>In both cases, records from multiple old channels are received over one new physical channel,\n- * which need to demultiplex the record to correctly restore spanning records (similar to how\n- * StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n- * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n- * output side, there is a total of 4 virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T>\n-        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n-        implements RecoverableStreamTaskInput<T> {\n-\n-    private static final Logger LOG =\n-            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n-    private final IOManager ioManager;\n-\n-    private RescalingStreamTaskNetworkInput(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        super(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                statusWatermarkValve,\n-                inputIndex,\n-                getRecordDeserializers(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        inflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo));\n-        this.ioManager = ioManager;\n-\n-        LOG.info(\n-                \"Created demultiplexer for input {} from {}\",\n-                inputIndex,\n-                inflightDataRescalingDescriptor);\n-    }\n-\n-    private static <T>\n-            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n-                    CheckpointedInputGate checkpointedInputGate,\n-                    TypeSerializer<T> inputSerializer,\n-                    IOManager ioManager,\n-                    InflightDataRescalingDescriptor rescalingDescriptor,\n-                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                    TaskInfo taskInfo) {\n-\n-        RecordFilterFactory<T> recordFilterFactory =\n-                new RecordFilterFactory<>(\n-                        taskInfo.getIndexOfThisSubtask(),\n-                        inputSerializer,\n-                        taskInfo.getNumberOfParallelSubtasks(),\n-                        gatePartitioners,\n-                        taskInfo.getMaxNumberOfParallelSubtasks());\n-        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n-        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n-                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n-        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n-            deserializers.put(\n-                    channelInfo,\n-                    DemultiplexingRecordDeserializer.create(\n-                            channelInfo,\n-                            rescalingDescriptor,\n-                            deserializerFactory,\n-                            recordFilterFactory));\n-        }\n-        return deserializers;\n-    }\n-\n-    @Override\n-    public StreamTaskInput<T> finishRecovery() throws IOException {\n-        close();\n-        return new StreamTaskNetworkInput<>(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                ioManager,\n-                statusWatermarkValve,\n-                inputIndex);\n-    }\n-\n-    /**\n-     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n-     * depending on {@link InflightDataRescalingDescriptor}.\n-     */\n-    public static <T> StreamTaskInput<T> create(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n-                        InflightDataRescalingDescriptor.NO_RESCALE)\n-                ? new StreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex)\n-                : new RescalingStreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex,\n-                        rescalingDescriptorinflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo);\n-    }\n-\n-    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n-            InputChannelInfo channelInfo) {\n-        final DemultiplexingRecordDeserializer<T> deserialier =\n-                recordDeserializers.get(channelInfo);\n-        if (!deserialier.hasMappings()) {\n-            throw new IllegalStateException(\n-                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n-        }\n-        return deserialier;\n-    }\n-\n-    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-        // Event received\n-        final AbstractEvent event = bufferOrEvent.getEvent();\n-        if (event instanceof VirtualChannelSelector) {\n-            getActiveSerializer(bufferOrEvent.getChannelInfo())\n-                    .select((VirtualChannelSelector) event);\n-            return InputStatus.MORE_AVAILABLE;\n-        }\n-        return super.processEvent(bufferOrEvent);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> prepareSnapshot(\n-            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n-        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n-    }\n-\n-    static class RecordFilterFactory<T>\n-            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n-        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n-        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n-        private final TypeSerializer<T> inputSerializer;\n-        private final int numberOfChannels;\n-        private int subtaskIndex;\n-        private int maxParallelism;\n-\n-        public RecordFilterFactory(\n-                int subtaskIndex,\n-                TypeSerializer<T> inputSerializer,\n-                int numberOfChannels,\n-                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                int maxParallelism) {\n-            this.gatePartitioners = gatePartitioners;\n-            this.inputSerializer = inputSerializer;\n-            this.numberOfChannels = numberOfChannels;\n-            this.subtaskIndex = subtaskIndex;\n-            this.maxParallelism = maxParallelism;\n-        }\n-\n-        @Override\n-        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n-            return new RecordFilter<>(\n-                    partitionerCache.computeIfAbsent(\n-                            channelInfo.getGateIdx(), this::createPartitioner),\n-                    inputSerializer,\n-                    subtaskIndex);\n-        }\n-\n-        private StreamPartitioner<T> createPartitioner(Integer index) {\n-            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n-            partitioner.setup(numberOfChannels);\n-            if (partitioner instanceof ConfigurableStreamPartitioner) {\n-                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n-            }\n-            return partitioner;\n-        }\n-    }\n-\n-    static class DeserializerFactory\n-            implements Function<\n-                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n-        private final IOManager ioManager;\n-\n-        public DeserializerFactory(IOManager ioManager) {\n-            this.ioManager = ioManager;\n-        }\n-\n-        @Override\n-        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n-                Integer totalChannels) {\n-            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n-                    ioManager.getSpillingDirectoriesPaths(),\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n-                            / totalChannels,\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n-                            / totalChannels);\n-        }\n-    }\n-}\n", "next_change": {"commit": "9232f328fcb33993f49e2a182b700111a890784a", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nnew file mode 100644\nindex 00000000000..99e57aed0ba\n--- /dev/null\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.SubtaskConnectionDescriptor;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    public RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        checkState(\n+                !recordDeserializers.values().stream()\n+                        .anyMatch(DemultiplexingRecordDeserializer::hasPartialData),\n+                \"Not all data has been fully consumed\");\n+\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                super.getActiveSerializer(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof SubtaskConnectionDescriptor) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((SubtaskConnectionDescriptor) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    /**\n+     * Creates a filter for records of ambiguous channels (channels that are restored to multiple\n+     * subtasks). The filter ensure that each record is exactly restored once.\n+     *\n+     * <p>Filters must not be shared across different virtual channels to ensure that the state is\n+     * in-sync across different subtasks.\n+     */\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private final int subtaskIndex;\n+        private final int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            // retrieving the partitioner for one input task is rather costly so cache them all\n+            final StreamPartitioner<T> partitioner =\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner);\n+            // use a copy of partitioner to ensure that the filter of ambiguous virtual channels\n+            // have the same state across several subtasks\n+            return new RecordFilter<>(partitioner.copy(), inputSerializer, subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }\n+    }\n+}\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nindex 0fe60f4f02a..99e57aed0ba 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -156,42 +162,10 @@ public final class RescalingStreamTaskNetworkInput<T>\n                 inputIndex);\n     }\n \n-    /**\n-     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n-     * depending on {@link InflightDataRescalingDescriptor}.\n-     */\n-    public static <T> StreamTaskInput<T> create(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n-                        InflightDataRescalingDescriptor.NO_RESCALE)\n-                ? new StreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex)\n-                : new RescalingStreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex,\n-                        rescalingDescriptorinflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo);\n-    }\n-\n     protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n             InputChannelInfo channelInfo) {\n         final DemultiplexingRecordDeserializer<T> deserialier =\n-                recordDeserializers.get(channelInfo);\n+                super.getActiveSerializer(channelInfo);\n         if (!deserialier.hasMappings()) {\n             throw new IllegalStateException(\n                     \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n", "next_change": {"commit": "684d56ebce83c9bf69a3bd070a8a0aefd3b380ff", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nindex 99e57aed0ba..16d0872b512 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -173,13 +173,13 @@ public final class RescalingStreamTaskNetworkInput<T>\n         return deserialier;\n     }\n \n-    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+    protected DataInputStatus processEvent(BufferOrEvent bufferOrEvent) {\n         // Event received\n         final AbstractEvent event = bufferOrEvent.getEvent();\n         if (event instanceof SubtaskConnectionDescriptor) {\n             getActiveSerializer(bufferOrEvent.getChannelInfo())\n                     .select((SubtaskConnectionDescriptor) event);\n-            return InputStatus.MORE_AVAILABLE;\n+            return DataInputStatus.MORE_AVAILABLE;\n         }\n         return super.processEvent(bufferOrEvent);\n     }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "edac2adb9523adcb69e1dacc5fd4ea8f63480175", "committedDate": "2021-07-26 09:56:45 +0200", "message": "[FLINK-23329][build] Bump flink-shaded to 14.0"}, {"oid": "684d56ebce83c9bf69a3bd070a8a0aefd3b380ff", "committedDate": "2021-07-26 12:58:47 +0200", "message": "[FLINK-23474] Extract internal version of InputStatus"}, {"oid": "474808d5833398247aa27a5544abf09d6bd17ee4", "committedDate": "2021-08-16 19:05:54 +0200", "message": "[FLINK-23767][streaming] Rename StreamStatus to WatermarkStatus."}, {"oid": "f6c7c30118ef26f98a7d422831fa8047f1fd9f98", "committedDate": "2023-01-27 09:34:31 +0800", "message": "[FLINK-30709][runtime] NetworkInput#emitNext() should push records to DataOutput within a while loop"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMDI1OA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583500258", "body": "nit: `super.getActiveSerializer(channelInfo);`", "bodyText": "nit: super.getActiveSerializer(channelInfo);", "bodyHTML": "<p dir=\"auto\">nit: <code>super.getActiveSerializer(channelInfo);</code></p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:27:15Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 0fe60f4f02a..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,280 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io.recovery;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.TaskInfo;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.CheckpointException;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-\n-import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases. *\n- *\n- * <ul>\n- *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n- *       channels (mostly relevant to keyed exchanges).\n- * </ul>\n- *\n- * <p>In both cases, records from multiple old channels are received over one new physical channel,\n- * which need to demultiplex the record to correctly restore spanning records (similar to how\n- * StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n- * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n- * output side, there is a total of 4 virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T>\n-        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n-        implements RecoverableStreamTaskInput<T> {\n-\n-    private static final Logger LOG =\n-            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n-    private final IOManager ioManager;\n-\n-    private RescalingStreamTaskNetworkInput(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        super(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                statusWatermarkValve,\n-                inputIndex,\n-                getRecordDeserializers(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        inflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo));\n-        this.ioManager = ioManager;\n-\n-        LOG.info(\n-                \"Created demultiplexer for input {} from {}\",\n-                inputIndex,\n-                inflightDataRescalingDescriptor);\n-    }\n-\n-    private static <T>\n-            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n-                    CheckpointedInputGate checkpointedInputGate,\n-                    TypeSerializer<T> inputSerializer,\n-                    IOManager ioManager,\n-                    InflightDataRescalingDescriptor rescalingDescriptor,\n-                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                    TaskInfo taskInfo) {\n-\n-        RecordFilterFactory<T> recordFilterFactory =\n-                new RecordFilterFactory<>(\n-                        taskInfo.getIndexOfThisSubtask(),\n-                        inputSerializer,\n-                        taskInfo.getNumberOfParallelSubtasks(),\n-                        gatePartitioners,\n-                        taskInfo.getMaxNumberOfParallelSubtasks());\n-        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n-        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n-                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n-        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n-            deserializers.put(\n-                    channelInfo,\n-                    DemultiplexingRecordDeserializer.create(\n-                            channelInfo,\n-                            rescalingDescriptor,\n-                            deserializerFactory,\n-                            recordFilterFactory));\n-        }\n-        return deserializers;\n-    }\n-\n-    @Override\n-    public StreamTaskInput<T> finishRecovery() throws IOException {\n-        close();\n-        return new StreamTaskNetworkInput<>(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                ioManager,\n-                statusWatermarkValve,\n-                inputIndex);\n-    }\n-\n-    /**\n-     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n-     * depending on {@link InflightDataRescalingDescriptor}.\n-     */\n-    public static <T> StreamTaskInput<T> create(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n-                        InflightDataRescalingDescriptor.NO_RESCALE)\n-                ? new StreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex)\n-                : new RescalingStreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex,\n-                        rescalingDescriptorinflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo);\n-    }\n-\n-    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n-            InputChannelInfo channelInfo) {\n-        final DemultiplexingRecordDeserializer<T> deserialier =\n-                recordDeserializers.get(channelInfo);\n-        if (!deserialier.hasMappings()) {\n-            throw new IllegalStateException(\n-                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n-        }\n-        return deserialier;\n-    }\n-\n-    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-        // Event received\n-        final AbstractEvent event = bufferOrEvent.getEvent();\n-        if (event instanceof VirtualChannelSelector) {\n-            getActiveSerializer(bufferOrEvent.getChannelInfo())\n-                    .select((VirtualChannelSelector) event);\n-            return InputStatus.MORE_AVAILABLE;\n-        }\n-        return super.processEvent(bufferOrEvent);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> prepareSnapshot(\n-            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n-        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n-    }\n-\n-    static class RecordFilterFactory<T>\n-            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n-        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n-        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n-        private final TypeSerializer<T> inputSerializer;\n-        private final int numberOfChannels;\n-        private int subtaskIndex;\n-        private int maxParallelism;\n-\n-        public RecordFilterFactory(\n-                int subtaskIndex,\n-                TypeSerializer<T> inputSerializer,\n-                int numberOfChannels,\n-                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                int maxParallelism) {\n-            this.gatePartitioners = gatePartitioners;\n-            this.inputSerializer = inputSerializer;\n-            this.numberOfChannels = numberOfChannels;\n-            this.subtaskIndex = subtaskIndex;\n-            this.maxParallelism = maxParallelism;\n-        }\n-\n-        @Override\n-        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n-            return new RecordFilter<>(\n-                    partitionerCache.computeIfAbsent(\n-                            channelInfo.getGateIdx(), this::createPartitioner),\n-                    inputSerializer,\n-                    subtaskIndex);\n-        }\n-\n-        private StreamPartitioner<T> createPartitioner(Integer index) {\n-            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n-            partitioner.setup(numberOfChannels);\n-            if (partitioner instanceof ConfigurableStreamPartitioner) {\n-                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n-            }\n-            return partitioner;\n-        }\n-    }\n-\n-    static class DeserializerFactory\n-            implements Function<\n-                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n-        private final IOManager ioManager;\n-\n-        public DeserializerFactory(IOManager ioManager) {\n-            this.ioManager = ioManager;\n-        }\n-\n-        @Override\n-        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n-                Integer totalChannels) {\n-            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n-                    ioManager.getSpillingDirectoriesPaths(),\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n-                            / totalChannels,\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n-                            / totalChannels);\n-        }\n-    }\n-}\n", "next_change": {"commit": "9232f328fcb33993f49e2a182b700111a890784a", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nnew file mode 100644\nindex 00000000000..99e57aed0ba\n--- /dev/null\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.SubtaskConnectionDescriptor;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    public RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        checkState(\n+                !recordDeserializers.values().stream()\n+                        .anyMatch(DemultiplexingRecordDeserializer::hasPartialData),\n+                \"Not all data has been fully consumed\");\n+\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                super.getActiveSerializer(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof SubtaskConnectionDescriptor) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((SubtaskConnectionDescriptor) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    /**\n+     * Creates a filter for records of ambiguous channels (channels that are restored to multiple\n+     * subtasks). The filter ensure that each record is exactly restored once.\n+     *\n+     * <p>Filters must not be shared across different virtual channels to ensure that the state is\n+     * in-sync across different subtasks.\n+     */\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private final int subtaskIndex;\n+        private final int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            // retrieving the partitioner for one input task is rather costly so cache them all\n+            final StreamPartitioner<T> partitioner =\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner);\n+            // use a copy of partitioner to ensure that the filter of ambiguous virtual channels\n+            // have the same state across several subtasks\n+            return new RecordFilter<>(partitioner.copy(), inputSerializer, subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }\n+    }\n+}\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nindex 0fe60f4f02a..99e57aed0ba 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -156,42 +162,10 @@ public final class RescalingStreamTaskNetworkInput<T>\n                 inputIndex);\n     }\n \n-    /**\n-     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n-     * depending on {@link InflightDataRescalingDescriptor}.\n-     */\n-    public static <T> StreamTaskInput<T> create(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n-                        InflightDataRescalingDescriptor.NO_RESCALE)\n-                ? new StreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex)\n-                : new RescalingStreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex,\n-                        rescalingDescriptorinflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo);\n-    }\n-\n     protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n             InputChannelInfo channelInfo) {\n         final DemultiplexingRecordDeserializer<T> deserialier =\n-                recordDeserializers.get(channelInfo);\n+                super.getActiveSerializer(channelInfo);\n         if (!deserialier.hasMappings()) {\n             throw new IllegalStateException(\n                     \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n", "next_change": {"commit": "684d56ebce83c9bf69a3bd070a8a0aefd3b380ff", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nindex 99e57aed0ba..16d0872b512 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -173,13 +173,13 @@ public final class RescalingStreamTaskNetworkInput<T>\n         return deserialier;\n     }\n \n-    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+    protected DataInputStatus processEvent(BufferOrEvent bufferOrEvent) {\n         // Event received\n         final AbstractEvent event = bufferOrEvent.getEvent();\n         if (event instanceof SubtaskConnectionDescriptor) {\n             getActiveSerializer(bufferOrEvent.getChannelInfo())\n                     .select((SubtaskConnectionDescriptor) event);\n-            return InputStatus.MORE_AVAILABLE;\n+            return DataInputStatus.MORE_AVAILABLE;\n         }\n         return super.processEvent(bufferOrEvent);\n     }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "edac2adb9523adcb69e1dacc5fd4ea8f63480175", "committedDate": "2021-07-26 09:56:45 +0200", "message": "[FLINK-23329][build] Bump flink-shaded to 14.0"}, {"oid": "684d56ebce83c9bf69a3bd070a8a0aefd3b380ff", "committedDate": "2021-07-26 12:58:47 +0200", "message": "[FLINK-23474] Extract internal version of InputStatus"}, {"oid": "474808d5833398247aa27a5544abf09d6bd17ee4", "committedDate": "2021-08-16 19:05:54 +0200", "message": "[FLINK-23767][streaming] Rename StreamStatus to WatermarkStatus."}, {"oid": "f6c7c30118ef26f98a7d422831fa8047f1fd9f98", "committedDate": "2023-01-27 09:34:31 +0800", "message": "[FLINK-30709][runtime] NetworkInput#emitNext() should push records to DataOutput within a while loop"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMjEzNA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583502134", "body": "If the defaults in `SpillingAdaptiveSpanningRecordDeserializer` are decreased then we can get 0 here with high enough DoP.\r\nShould we add `Math.max(some_minimum, ....)` ?", "bodyText": "If the defaults in SpillingAdaptiveSpanningRecordDeserializer are decreased then we can get 0 here with high enough DoP.\nShould we add Math.max(some_minimum, ....) ?", "bodyHTML": "<p dir=\"auto\">If the defaults in <code>SpillingAdaptiveSpanningRecordDeserializer</code> are decreased then we can get 0 here with high enough DoP.<br>\nShould we add <code>Math.max(some_minimum, ....)</code> ?</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T09:30:06Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    /**\n+     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n+     * depending on {@link InflightDataRescalingDescriptor}.\n+     */\n+    public static <T> StreamTaskInput<T> create(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n+                        InflightDataRescalingDescriptor.NO_RESCALE)\n+                ? new StreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex)\n+                : new RescalingStreamTaskNetworkInput<>(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        statusWatermarkValve,\n+                        inputIndex,\n+                        rescalingDescriptorinflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                recordDeserializers.get(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof VirtualChannelSelector) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((VirtualChannelSelector) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private int subtaskIndex;\n+        private int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            return new RecordFilter<>(\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner),\n+                    inputSerializer,\n+                    subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI3OTE0MA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r587279140", "bodyText": "Good catch. I added some minimum (probably up to debate).", "author": "AHeise", "createdAt": "2021-03-04T08:57:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUwMjEzNA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 0fe60f4f02a..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,280 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io.recovery;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.TaskInfo;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.CheckpointException;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-\n-import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases. *\n- *\n- * <ul>\n- *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n- *       channels (mostly relevant to keyed exchanges).\n- * </ul>\n- *\n- * <p>In both cases, records from multiple old channels are received over one new physical channel,\n- * which need to demultiplex the record to correctly restore spanning records (similar to how\n- * StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n- * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n- * output side, there is a total of 4 virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T>\n-        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n-        implements RecoverableStreamTaskInput<T> {\n-\n-    private static final Logger LOG =\n-            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n-    private final IOManager ioManager;\n-\n-    private RescalingStreamTaskNetworkInput(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        super(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                statusWatermarkValve,\n-                inputIndex,\n-                getRecordDeserializers(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        inflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo));\n-        this.ioManager = ioManager;\n-\n-        LOG.info(\n-                \"Created demultiplexer for input {} from {}\",\n-                inputIndex,\n-                inflightDataRescalingDescriptor);\n-    }\n-\n-    private static <T>\n-            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n-                    CheckpointedInputGate checkpointedInputGate,\n-                    TypeSerializer<T> inputSerializer,\n-                    IOManager ioManager,\n-                    InflightDataRescalingDescriptor rescalingDescriptor,\n-                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                    TaskInfo taskInfo) {\n-\n-        RecordFilterFactory<T> recordFilterFactory =\n-                new RecordFilterFactory<>(\n-                        taskInfo.getIndexOfThisSubtask(),\n-                        inputSerializer,\n-                        taskInfo.getNumberOfParallelSubtasks(),\n-                        gatePartitioners,\n-                        taskInfo.getMaxNumberOfParallelSubtasks());\n-        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n-        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n-                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n-        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n-            deserializers.put(\n-                    channelInfo,\n-                    DemultiplexingRecordDeserializer.create(\n-                            channelInfo,\n-                            rescalingDescriptor,\n-                            deserializerFactory,\n-                            recordFilterFactory));\n-        }\n-        return deserializers;\n-    }\n-\n-    @Override\n-    public StreamTaskInput<T> finishRecovery() throws IOException {\n-        close();\n-        return new StreamTaskNetworkInput<>(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                ioManager,\n-                statusWatermarkValve,\n-                inputIndex);\n-    }\n-\n-    /**\n-     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n-     * depending on {@link InflightDataRescalingDescriptor}.\n-     */\n-    public static <T> StreamTaskInput<T> create(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n-                        InflightDataRescalingDescriptor.NO_RESCALE)\n-                ? new StreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex)\n-                : new RescalingStreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex,\n-                        rescalingDescriptorinflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo);\n-    }\n-\n-    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n-            InputChannelInfo channelInfo) {\n-        final DemultiplexingRecordDeserializer<T> deserialier =\n-                recordDeserializers.get(channelInfo);\n-        if (!deserialier.hasMappings()) {\n-            throw new IllegalStateException(\n-                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n-        }\n-        return deserialier;\n-    }\n-\n-    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-        // Event received\n-        final AbstractEvent event = bufferOrEvent.getEvent();\n-        if (event instanceof VirtualChannelSelector) {\n-            getActiveSerializer(bufferOrEvent.getChannelInfo())\n-                    .select((VirtualChannelSelector) event);\n-            return InputStatus.MORE_AVAILABLE;\n-        }\n-        return super.processEvent(bufferOrEvent);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> prepareSnapshot(\n-            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n-        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n-    }\n-\n-    static class RecordFilterFactory<T>\n-            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n-        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n-        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n-        private final TypeSerializer<T> inputSerializer;\n-        private final int numberOfChannels;\n-        private int subtaskIndex;\n-        private int maxParallelism;\n-\n-        public RecordFilterFactory(\n-                int subtaskIndex,\n-                TypeSerializer<T> inputSerializer,\n-                int numberOfChannels,\n-                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                int maxParallelism) {\n-            this.gatePartitioners = gatePartitioners;\n-            this.inputSerializer = inputSerializer;\n-            this.numberOfChannels = numberOfChannels;\n-            this.subtaskIndex = subtaskIndex;\n-            this.maxParallelism = maxParallelism;\n-        }\n-\n-        @Override\n-        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n-            return new RecordFilter<>(\n-                    partitionerCache.computeIfAbsent(\n-                            channelInfo.getGateIdx(), this::createPartitioner),\n-                    inputSerializer,\n-                    subtaskIndex);\n-        }\n-\n-        private StreamPartitioner<T> createPartitioner(Integer index) {\n-            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n-            partitioner.setup(numberOfChannels);\n-            if (partitioner instanceof ConfigurableStreamPartitioner) {\n-                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n-            }\n-            return partitioner;\n-        }\n-    }\n-\n-    static class DeserializerFactory\n-            implements Function<\n-                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n-        private final IOManager ioManager;\n-\n-        public DeserializerFactory(IOManager ioManager) {\n-            this.ioManager = ioManager;\n-        }\n-\n-        @Override\n-        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n-                Integer totalChannels) {\n-            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n-                    ioManager.getSpillingDirectoriesPaths(),\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n-                            / totalChannels,\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n-                            / totalChannels);\n-        }\n-    }\n-}\n", "next_change": {"commit": "9232f328fcb33993f49e2a182b700111a890784a", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nnew file mode 100644\nindex 00000000000..99e57aed0ba\n--- /dev/null\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.SubtaskConnectionDescriptor;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    public RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        checkState(\n+                !recordDeserializers.values().stream()\n+                        .anyMatch(DemultiplexingRecordDeserializer::hasPartialData),\n+                \"Not all data has been fully consumed\");\n+\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                super.getActiveSerializer(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof SubtaskConnectionDescriptor) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((SubtaskConnectionDescriptor) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    /**\n+     * Creates a filter for records of ambiguous channels (channels that are restored to multiple\n+     * subtasks). The filter ensure that each record is exactly restored once.\n+     *\n+     * <p>Filters must not be shared across different virtual channels to ensure that the state is\n+     * in-sync across different subtasks.\n+     */\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private final int subtaskIndex;\n+        private final int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            // retrieving the partitioner for one input task is rather costly so cache them all\n+            final StreamPartitioner<T> partitioner =\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner);\n+            // use a copy of partitioner to ensure that the filter of ambiguous virtual channels\n+            // have the same state across several subtasks\n+            return new RecordFilter<>(partitioner.copy(), inputSerializer, subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }\n+    }\n+}\n", "next_change": null}]}}]}, "revised_code_in_main": null, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "edac2adb9523adcb69e1dacc5fd4ea8f63480175", "committedDate": "2021-07-26 09:56:45 +0200", "message": "[FLINK-23329][build] Bump flink-shaded to 14.0"}, {"oid": "684d56ebce83c9bf69a3bd070a8a0aefd3b380ff", "committedDate": "2021-07-26 12:58:47 +0200", "message": "[FLINK-23474] Extract internal version of InputStatus"}, {"oid": "474808d5833398247aa27a5544abf09d6bd17ee4", "committedDate": "2021-08-16 19:05:54 +0200", "message": "[FLINK-23767][streaming] Rename StreamStatus to WatermarkStatus."}, {"oid": "f6c7c30118ef26f98a7d422831fa8047f1fd9f98", "committedDate": "2023-01-27 09:34:31 +0800", "message": "[FLINK-30709][runtime] NetworkInput#emitNext() should push records to DataOutput within a while loop"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUyOTk5OA==", "url": "https://github.com/apache/flink/pull/13845#discussion_r583529998", "body": "Do we need to make sure that all the buffers in deserializers are consumed?", "bodyText": "Do we need to make sure that all the buffers in deserializers are consumed?", "bodyHTML": "<p dir=\"auto\">Do we need to make sure that all the buffers in deserializers are consumed?</p>", "author": "rkhachatryan", "createdAt": "2021-02-26T10:15:40Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    private RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        close();", "originalCommit": "bd18dbb4154a033a55320c2740e2499ac7d63ff9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzI4NzA3MQ==", "url": "https://github.com/apache/flink/pull/13845#discussion_r587287071", "bodyText": "Yes good idea.", "author": "AHeise", "createdAt": "2021-03-04T09:08:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MzUyOTk5OA=="}], "type": "inlineReview", "revised_code": {"commit": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\ndeleted file mode 100644\nindex 0fe60f4f02a..00000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ /dev/null\n", "chunk": "@@ -1,280 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.runtime.io.recovery;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.api.common.TaskInfo;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.io.InputStatus;\n-import org.apache.flink.runtime.checkpoint.CheckpointException;\n-import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n-import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n-import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n-import org.apache.flink.runtime.event.AbstractEvent;\n-import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n-import org.apache.flink.runtime.io.network.api.VirtualChannelSelector;\n-import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n-import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n-import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n-import org.apache.flink.runtime.plugable.DeserializationDelegate;\n-import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n-import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n-import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n-import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n-import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n-import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n-import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.function.Function;\n-import java.util.function.Predicate;\n-\n-import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n-\n-/**\n- * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n- *\n- * <p>The demultiplexing works in two dimensions for the following cases. *\n- *\n- * <ul>\n- *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n- *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n- *       channels (mostly relevant to keyed exchanges).\n- * </ul>\n- *\n- * <p>In both cases, records from multiple old channels are received over one new physical channel,\n- * which need to demultiplex the record to correctly restore spanning records (similar to how\n- * StreamTaskNetworkInput works).\n- *\n- * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n- * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n- * output side, there is a total of 4 virtual channels.\n- */\n-@Internal\n-public final class RescalingStreamTaskNetworkInput<T>\n-        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n-        implements RecoverableStreamTaskInput<T> {\n-\n-    private static final Logger LOG =\n-            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n-    private final IOManager ioManager;\n-\n-    private RescalingStreamTaskNetworkInput(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        super(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                statusWatermarkValve,\n-                inputIndex,\n-                getRecordDeserializers(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        inflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo));\n-        this.ioManager = ioManager;\n-\n-        LOG.info(\n-                \"Created demultiplexer for input {} from {}\",\n-                inputIndex,\n-                inflightDataRescalingDescriptor);\n-    }\n-\n-    private static <T>\n-            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n-                    CheckpointedInputGate checkpointedInputGate,\n-                    TypeSerializer<T> inputSerializer,\n-                    IOManager ioManager,\n-                    InflightDataRescalingDescriptor rescalingDescriptor,\n-                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                    TaskInfo taskInfo) {\n-\n-        RecordFilterFactory<T> recordFilterFactory =\n-                new RecordFilterFactory<>(\n-                        taskInfo.getIndexOfThisSubtask(),\n-                        inputSerializer,\n-                        taskInfo.getNumberOfParallelSubtasks(),\n-                        gatePartitioners,\n-                        taskInfo.getMaxNumberOfParallelSubtasks());\n-        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n-        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n-                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n-        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n-            deserializers.put(\n-                    channelInfo,\n-                    DemultiplexingRecordDeserializer.create(\n-                            channelInfo,\n-                            rescalingDescriptor,\n-                            deserializerFactory,\n-                            recordFilterFactory));\n-        }\n-        return deserializers;\n-    }\n-\n-    @Override\n-    public StreamTaskInput<T> finishRecovery() throws IOException {\n-        close();\n-        return new StreamTaskNetworkInput<>(\n-                checkpointedInputGate,\n-                inputSerializer,\n-                ioManager,\n-                statusWatermarkValve,\n-                inputIndex);\n-    }\n-\n-    /**\n-     * Factory method for {@link StreamTaskNetworkInput} or {@link RescalingStreamTaskNetworkInput}\n-     * depending on {@link InflightDataRescalingDescriptor}.\n-     */\n-    public static <T> StreamTaskInput<T> create(\n-            CheckpointedInputGate checkpointedInputGate,\n-            TypeSerializer<T> inputSerializer,\n-            IOManager ioManager,\n-            StatusWatermarkValve statusWatermarkValve,\n-            int inputIndex,\n-            InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n-            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-            TaskInfo taskInfo) {\n-        return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n-                        InflightDataRescalingDescriptor.NO_RESCALE)\n-                ? new StreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex)\n-                : new RescalingStreamTaskNetworkInput<>(\n-                        checkpointedInputGate,\n-                        inputSerializer,\n-                        ioManager,\n-                        statusWatermarkValve,\n-                        inputIndex,\n-                        rescalingDescriptorinflightDataRescalingDescriptor,\n-                        gatePartitioners,\n-                        taskInfo);\n-    }\n-\n-    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n-            InputChannelInfo channelInfo) {\n-        final DemultiplexingRecordDeserializer<T> deserialier =\n-                recordDeserializers.get(channelInfo);\n-        if (!deserialier.hasMappings()) {\n-            throw new IllegalStateException(\n-                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n-        }\n-        return deserialier;\n-    }\n-\n-    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n-        // Event received\n-        final AbstractEvent event = bufferOrEvent.getEvent();\n-        if (event instanceof VirtualChannelSelector) {\n-            getActiveSerializer(bufferOrEvent.getChannelInfo())\n-                    .select((VirtualChannelSelector) event);\n-            return InputStatus.MORE_AVAILABLE;\n-        }\n-        return super.processEvent(bufferOrEvent);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> prepareSnapshot(\n-            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n-        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n-    }\n-\n-    static class RecordFilterFactory<T>\n-            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n-        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n-        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n-        private final TypeSerializer<T> inputSerializer;\n-        private final int numberOfChannels;\n-        private int subtaskIndex;\n-        private int maxParallelism;\n-\n-        public RecordFilterFactory(\n-                int subtaskIndex,\n-                TypeSerializer<T> inputSerializer,\n-                int numberOfChannels,\n-                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n-                int maxParallelism) {\n-            this.gatePartitioners = gatePartitioners;\n-            this.inputSerializer = inputSerializer;\n-            this.numberOfChannels = numberOfChannels;\n-            this.subtaskIndex = subtaskIndex;\n-            this.maxParallelism = maxParallelism;\n-        }\n-\n-        @Override\n-        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n-            return new RecordFilter<>(\n-                    partitionerCache.computeIfAbsent(\n-                            channelInfo.getGateIdx(), this::createPartitioner),\n-                    inputSerializer,\n-                    subtaskIndex);\n-        }\n-\n-        private StreamPartitioner<T> createPartitioner(Integer index) {\n-            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n-            partitioner.setup(numberOfChannels);\n-            if (partitioner instanceof ConfigurableStreamPartitioner) {\n-                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n-            }\n-            return partitioner;\n-        }\n-    }\n-\n-    static class DeserializerFactory\n-            implements Function<\n-                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n-        private final IOManager ioManager;\n-\n-        public DeserializerFactory(IOManager ioManager) {\n-            this.ioManager = ioManager;\n-        }\n-\n-        @Override\n-        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n-                Integer totalChannels) {\n-            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n-                    ioManager.getSpillingDirectoriesPaths(),\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n-                            / totalChannels,\n-                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n-                            / totalChannels);\n-        }\n-    }\n-}\n", "next_change": {"commit": "9232f328fcb33993f49e2a182b700111a890784a", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nnew file mode 100644\nindex 00000000000..99e57aed0ba\n--- /dev/null\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.io.recovery;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.TaskInfo;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.io.InputStatus;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.event.AbstractEvent;\n+import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n+import org.apache.flink.runtime.io.network.api.SubtaskConnectionDescriptor;\n+import org.apache.flink.runtime.io.network.api.serialization.RecordDeserializer;\n+import org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer;\n+import org.apache.flink.runtime.io.network.partition.consumer.BufferOrEvent;\n+import org.apache.flink.runtime.plugable.DeserializationDelegate;\n+import org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.RecoverableStreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskInput;\n+import org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput;\n+import org.apache.flink.streaming.runtime.io.checkpointing.CheckpointedInputGate;\n+import org.apache.flink.streaming.runtime.partitioner.ConfigurableStreamPartitioner;\n+import org.apache.flink.streaming.runtime.partitioner.StreamPartitioner;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamElement;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.Maps;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+\n+import static org.apache.flink.runtime.checkpoint.CheckpointFailureReason.CHECKPOINT_DECLINED_TASK_NOT_READY;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A {@link StreamTaskNetworkInput} implementation that demultiplexes virtual channels.\n+ *\n+ * <p>The demultiplexing works in two dimensions for the following cases. *\n+ *\n+ * <ul>\n+ *   <li>Subtasks of the current operator have been collapsed in a round-robin fashion.\n+ *   <li>The connected output operator has been rescaled (up and down!) and there is an overlap of\n+ *       channels (mostly relevant to keyed exchanges).\n+ * </ul>\n+ *\n+ * <p>In both cases, records from multiple old channels are received over one new physical channel,\n+ * which need to demultiplex the record to correctly restore spanning records (similar to how\n+ * StreamTaskNetworkInput works).\n+ *\n+ * <p>Note that when both cases occur at the same time (downscaling of several operators), there is\n+ * the cross product of channels. So if two subtasks are collapsed and two channels overlap from the\n+ * output side, there is a total of 4 virtual channels.\n+ */\n+@Internal\n+public final class RescalingStreamTaskNetworkInput<T>\n+        extends AbstractStreamTaskNetworkInput<T, DemultiplexingRecordDeserializer<T>>\n+        implements RecoverableStreamTaskInput<T> {\n+\n+    private static final Logger LOG =\n+            LoggerFactory.getLogger(RescalingStreamTaskNetworkInput.class);\n+    private final IOManager ioManager;\n+\n+    public RescalingStreamTaskNetworkInput(\n+            CheckpointedInputGate checkpointedInputGate,\n+            TypeSerializer<T> inputSerializer,\n+            IOManager ioManager,\n+            StatusWatermarkValve statusWatermarkValve,\n+            int inputIndex,\n+            InflightDataRescalingDescriptor inflightDataRescalingDescriptor,\n+            Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+            TaskInfo taskInfo) {\n+        super(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                statusWatermarkValve,\n+                inputIndex,\n+                getRecordDeserializers(\n+                        checkpointedInputGate,\n+                        inputSerializer,\n+                        ioManager,\n+                        inflightDataRescalingDescriptor,\n+                        gatePartitioners,\n+                        taskInfo));\n+        this.ioManager = ioManager;\n+\n+        LOG.info(\n+                \"Created demultiplexer for input {} from {}\",\n+                inputIndex,\n+                inflightDataRescalingDescriptor);\n+    }\n+\n+    private static <T>\n+            Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> getRecordDeserializers(\n+                    CheckpointedInputGate checkpointedInputGate,\n+                    TypeSerializer<T> inputSerializer,\n+                    IOManager ioManager,\n+                    InflightDataRescalingDescriptor rescalingDescriptor,\n+                    Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                    TaskInfo taskInfo) {\n+\n+        RecordFilterFactory<T> recordFilterFactory =\n+                new RecordFilterFactory<>(\n+                        taskInfo.getIndexOfThisSubtask(),\n+                        inputSerializer,\n+                        taskInfo.getNumberOfParallelSubtasks(),\n+                        gatePartitioners,\n+                        taskInfo.getMaxNumberOfParallelSubtasks());\n+        final DeserializerFactory deserializerFactory = new DeserializerFactory(ioManager);\n+        Map<InputChannelInfo, DemultiplexingRecordDeserializer<T>> deserializers =\n+                Maps.newHashMapWithExpectedSize(checkpointedInputGate.getChannelInfos().size());\n+        for (InputChannelInfo channelInfo : checkpointedInputGate.getChannelInfos()) {\n+            deserializers.put(\n+                    channelInfo,\n+                    DemultiplexingRecordDeserializer.create(\n+                            channelInfo,\n+                            rescalingDescriptor,\n+                            deserializerFactory,\n+                            recordFilterFactory));\n+        }\n+        return deserializers;\n+    }\n+\n+    @Override\n+    public StreamTaskInput<T> finishRecovery() throws IOException {\n+        checkState(\n+                !recordDeserializers.values().stream()\n+                        .anyMatch(DemultiplexingRecordDeserializer::hasPartialData),\n+                \"Not all data has been fully consumed\");\n+\n+        close();\n+        return new StreamTaskNetworkInput<>(\n+                checkpointedInputGate,\n+                inputSerializer,\n+                ioManager,\n+                statusWatermarkValve,\n+                inputIndex);\n+    }\n+\n+    protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n+            InputChannelInfo channelInfo) {\n+        final DemultiplexingRecordDeserializer<T> deserialier =\n+                super.getActiveSerializer(channelInfo);\n+        if (!deserialier.hasMappings()) {\n+            throw new IllegalStateException(\n+                    \"Channel \" + channelInfo + \" should not receive data during recovery.\");\n+        }\n+        return deserialier;\n+    }\n+\n+    protected InputStatus processEvent(BufferOrEvent bufferOrEvent) {\n+        // Event received\n+        final AbstractEvent event = bufferOrEvent.getEvent();\n+        if (event instanceof SubtaskConnectionDescriptor) {\n+            getActiveSerializer(bufferOrEvent.getChannelInfo())\n+                    .select((SubtaskConnectionDescriptor) event);\n+            return InputStatus.MORE_AVAILABLE;\n+        }\n+        return super.processEvent(bufferOrEvent);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> prepareSnapshot(\n+            ChannelStateWriter channelStateWriter, long checkpointId) throws CheckpointException {\n+        throw new CheckpointException(CHECKPOINT_DECLINED_TASK_NOT_READY);\n+    }\n+\n+    /**\n+     * Creates a filter for records of ambiguous channels (channels that are restored to multiple\n+     * subtasks). The filter ensure that each record is exactly restored once.\n+     *\n+     * <p>Filters must not be shared across different virtual channels to ensure that the state is\n+     * in-sync across different subtasks.\n+     */\n+    static class RecordFilterFactory<T>\n+            implements Function<InputChannelInfo, Predicate<StreamRecord<T>>> {\n+        private final Map<Integer, StreamPartitioner<T>> partitionerCache = new HashMap<>(1);\n+        private final Function<Integer, StreamPartitioner<?>> gatePartitioners;\n+        private final TypeSerializer<T> inputSerializer;\n+        private final int numberOfChannels;\n+        private final int subtaskIndex;\n+        private final int maxParallelism;\n+\n+        public RecordFilterFactory(\n+                int subtaskIndex,\n+                TypeSerializer<T> inputSerializer,\n+                int numberOfChannels,\n+                Function<Integer, StreamPartitioner<?>> gatePartitioners,\n+                int maxParallelism) {\n+            this.gatePartitioners = gatePartitioners;\n+            this.inputSerializer = inputSerializer;\n+            this.numberOfChannels = numberOfChannels;\n+            this.subtaskIndex = subtaskIndex;\n+            this.maxParallelism = maxParallelism;\n+        }\n+\n+        @Override\n+        public Predicate<StreamRecord<T>> apply(InputChannelInfo channelInfo) {\n+            // retrieving the partitioner for one input task is rather costly so cache them all\n+            final StreamPartitioner<T> partitioner =\n+                    partitionerCache.computeIfAbsent(\n+                            channelInfo.getGateIdx(), this::createPartitioner);\n+            // use a copy of partitioner to ensure that the filter of ambiguous virtual channels\n+            // have the same state across several subtasks\n+            return new RecordFilter<>(partitioner.copy(), inputSerializer, subtaskIndex);\n+        }\n+\n+        private StreamPartitioner<T> createPartitioner(Integer index) {\n+            StreamPartitioner<T> partitioner = (StreamPartitioner<T>) gatePartitioners.apply(index);\n+            partitioner.setup(numberOfChannels);\n+            if (partitioner instanceof ConfigurableStreamPartitioner) {\n+                ((ConfigurableStreamPartitioner) partitioner).configure(maxParallelism);\n+            }\n+            return partitioner;\n+        }\n+    }\n+\n+    static class DeserializerFactory\n+            implements Function<\n+                    Integer, RecordDeserializer<DeserializationDelegate<StreamElement>>> {\n+        private final IOManager ioManager;\n+\n+        public DeserializerFactory(IOManager ioManager) {\n+            this.ioManager = ioManager;\n+        }\n+\n+        @Override\n+        public RecordDeserializer<DeserializationDelegate<StreamElement>> apply(\n+                Integer totalChannels) {\n+            return new SpillingAdaptiveSpanningRecordDeserializer<>(\n+                    ioManager.getSpillingDirectoriesPaths(),\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_THRESHOLD_FOR_SPILLING\n+                            / totalChannels,\n+                    SpillingAdaptiveSpanningRecordDeserializer.DEFAULT_FILE_BUFFER_SIZE\n+                            / totalChannels);\n+        }\n+    }\n+}\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nindex 0fe60f4f02a..99e57aed0ba 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -147,6 +148,11 @@ public final class RescalingStreamTaskNetworkInput<T>\n \n     @Override\n     public StreamTaskInput<T> finishRecovery() throws IOException {\n+        checkState(\n+                !recordDeserializers.values().stream()\n+                        .anyMatch(DemultiplexingRecordDeserializer::hasPartialData),\n+                \"Not all data has been fully consumed\");\n+\n         close();\n         return new StreamTaskNetworkInput<>(\n                 checkpointedInputGate,\n", "next_change": {"commit": "f6c7c30118ef26f98a7d422831fa8047f1fd9f98", "changed_code": [{"header": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\nindex 99e57aed0ba..b95dded940e 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/io/recovery/RescalingStreamTaskNetworkInput.java\n", "chunk": "@@ -159,7 +162,8 @@ public final class RescalingStreamTaskNetworkInput<T>\n                 inputSerializer,\n                 ioManager,\n                 statusWatermarkValve,\n-                inputIndex);\n+                inputIndex,\n+                canEmitBatchOfRecords);\n     }\n \n     protected DemultiplexingRecordDeserializer<T> getActiveSerializer(\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "b4c57c056ecc54bb1a8d04e6d4222639036dccfa", "message": "Merge commit", "committedDate": null}, {"oid": "edac2adb9523adcb69e1dacc5fd4ea8f63480175", "committedDate": "2021-07-26 09:56:45 +0200", "message": "[FLINK-23329][build] Bump flink-shaded to 14.0"}, {"oid": "684d56ebce83c9bf69a3bd070a8a0aefd3b380ff", "committedDate": "2021-07-26 12:58:47 +0200", "message": "[FLINK-23474] Extract internal version of InputStatus"}, {"oid": "474808d5833398247aa27a5544abf09d6bd17ee4", "committedDate": "2021-08-16 19:05:54 +0200", "message": "[FLINK-23767][streaming] Rename StreamStatus to WatermarkStatus."}, {"oid": "f6c7c30118ef26f98a7d422831fa8047f1fd9f98", "committedDate": "2023-01-27 09:34:31 +0800", "message": "[FLINK-30709][runtime] NetworkInput#emitNext() should push records to DataOutput within a while loop"}]}, {"oid": "c9a9c58c6731f711c468c9114bb113d321dfdf5e", "url": "https://github.com/apache/flink/commit/c9a9c58c6731f711c468c9114bb113d321dfdf5e", "message": "[hotfix][checkpoint] Ensure buffers are recycled on released RecoveredInputChannel.", "committedDate": "2021-03-10T09:55:38Z", "type": "commit"}, {"oid": "12f0d0a3450a3569de598b2fdf85fd7b848874e8", "url": "https://github.com/apache/flink/commit/12f0d0a3450a3569de598b2fdf85fd7b848874e8", "message": "[hotfix][network] Incomplete cleanup of buffer pools does no longer leak other resources.", "committedDate": "2021-03-10T09:55:38Z", "type": "commit"}, {"oid": "d179e7c37f82a69676598f28e3215fc0f7fa1534", "url": "https://github.com/apache/flink/commit/d179e7c37f82a69676598f28e3215fc0f7fa1534", "message": "[FLINK-19801][checkpoint] Using lazy initialization of aux structure while creating InflightDataRescalingDescriptor.\n\nFor rescaling unaligned checkpoints, rescaling descriptors need to be calculated. However, for larger setups, it can take a while to calculate mappings and thus it should be avoided for all aligned checkpoints, interchanges without data, and for trivial setup (simple upscaling of shuffles).\n\nThere were some optimizations already in the code but it relied on determining the simple cases in advance, which is quite complicated and fell short in two regards. In certain cases, such as channels that or filled only on either upstream or downstream, it was too aggressive and lead to wrong results. Further, some optimization opportunities were left out.\n\nThis commit also generalizes RescaledChannelMapping to RescaleMappings to be additionally used for subtask mappings.\n\nIn this refactoring, the calculation of most aux structure is lazy to simplify the detection of the cases. Accordingly, most calculations are moved inside TaskStateAssignment and properly encapsulated.", "committedDate": "2021-03-10T09:55:38Z", "type": "commit"}, {"oid": "4c151a52db75a274dff347ece2ac3f0d40930527", "url": "https://github.com/apache/flink/commit/4c151a52db75a274dff347ece2ac3f0d40930527", "message": "[FLINK-19801][checkpoint] Expose rescale descriptors in TaskStateManager and add ambiguity of subtasks + max parallelism.\n\nThe descriptors will be used during unspilling and in the StreamTaskNetworkInput to create virtual channels.", "committedDate": "2021-03-10T09:55:39Z", "type": "commit"}, {"oid": "5e7f35553bc89148575902086d43a1bc26b2a0d2", "url": "https://github.com/apache/flink/commit/5e7f35553bc89148575902086d43a1bc26b2a0d2", "message": "[FLINK-19801][streaming] Adding Watermark#UNINITIALIZED.\n\nThis special watermark can be used to reflect the state of an subtask/gate/channel that hasn't received a watermark yet. It will be used in later rescaling recovery commits.", "committedDate": "2021-03-10T09:55:39Z", "type": "commit"}, {"oid": "1f91e195d306f134a7d5d07c77ff1e28a0fc29e2", "url": "https://github.com/apache/flink/commit/1f91e195d306f134a7d5d07c77ff1e28a0fc29e2", "message": "[FLINK-19801][network] Simplify RecordDeserializer interface.\n\nRecordDeserializer is now fully responsible for the buffer that it has been given.", "committedDate": "2021-03-10T09:55:39Z", "type": "commit"}, {"oid": "56f73d129685256228406bd9036dfb34fb9589d0", "url": "https://github.com/apache/flink/commit/56f73d129685256228406bd9036dfb34fb9589d0", "message": "[FLINK-19801][task] Extract AbstractStreamTaskNetworkInput from StreamTaskNetworkInput.\n\nAbstractStreamTaskNetworkInput will become the base of RescalingStreamTaskNetworkInput in the next commit.", "committedDate": "2021-03-10T09:55:39Z", "type": "commit"}, {"oid": "f417d58448fb9236db4e3be9f36c5f40011a2c9a", "url": "https://github.com/apache/flink/commit/f417d58448fb9236db4e3be9f36c5f40011a2c9a", "message": "[FLINK-19801][checkpoint] StreamTaskInput#prepareSnapshot throws CheckpointException to allow declining checkpoints.", "committedDate": "2021-03-10T09:55:40Z", "type": "commit"}, {"oid": "9232f328fcb33993f49e2a182b700111a890784a", "url": "https://github.com/apache/flink/commit/9232f328fcb33993f49e2a182b700111a890784a", "message": "[FLINK-19801][task] Implement virtual channel demultiplexing in RecoveringStreamTaskNetworkInput.\n\nThe demultiplexing works in two dimensions for the following cases.\n* Subtasks of the current operator have been collapsed in a round-robin fashion.\n* The connected output operator has been rescaled (up and down!) and there is an overlap of channels (mostly relevant to keyed exchanges).\nIn both cases, records from multiple old channels are received over one new physical channel, which need to demultiplex the record to correctly restore spanning records (similar to how StreamTaskNetworkInput works).\n\nFor performance reasons, the virtual demultiplexing logic is implemented separately from StreamTaskNetworkInput, such that on after recovery, the network input is replaced with the non-recovery counter-part in all StreamInputProcessors.", "committedDate": "2021-03-10T09:55:40Z", "type": "commit"}, {"oid": "6771250a1599f99d21a0f00f45cf43e478e81f4b", "url": "https://github.com/apache/flink/commit/6771250a1599f99d21a0f00f45cf43e478e81f4b", "message": "[FLINK-19801][checkpoint] Recover data with virtual channels.\n\nThis commit adds virtual channel support to SequentialChannelStateReader. The reader now replicates data on input and output side according to the InflightDataRescalingDescriptor and adds VirtualChannelSelector events before buffers.", "committedDate": "2021-03-10T09:55:41Z", "type": "commit"}, {"oid": "32d65ea98d6fee63a6042ad3525de645f6ea4385", "url": "https://github.com/apache/flink/commit/32d65ea98d6fee63a6042ad3525de645f6ea4385", "message": "[FLINK-19801][checkpoint/tests] Enable rescaling of unaligned checkpoints.", "committedDate": "2021-03-10T09:55:41Z", "type": "commit"}, {"oid": "328e51b44db76cdd71dfa533c96967cb742b8d53", "url": "https://github.com/apache/flink/commit/328e51b44db76cdd71dfa533c96967cb742b8d53", "message": "[FLINK-19801][tests] Adding rescaling IT for unaligned checkpoints.", "committedDate": "2021-03-11T06:57:10Z", "type": "commit"}]}