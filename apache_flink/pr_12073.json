{"pr_number": 12073, "pr_title": " [FLINK-17735][streaming] Add specialized collecting iterator", "pr_author": "tsreaper", "pr_createdAt": "2020-05-11T07:20:41Z", "pr_url": "https://github.com/apache/flink/pull/12073", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwODEzMg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426208132", "body": "rename to `jobTerminated`", "bodyText": "rename to jobTerminated", "bodyHTML": "<p dir=\"auto\">rename to <code>jobTerminated</code></p>", "author": "KurtYoung", "createdAt": "2020-05-17T01:56:47Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTEzNg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209136", "body": "doesn't see any tests relying on this method", "bodyText": "doesn't see any tests relying on this method", "bodyHTML": "<p dir=\"auto\">doesn't see any tests relying on this method</p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:16:24Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTIxMw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209213", "body": "init `closed` variable", "bodyText": "init closed variable", "bodyHTML": "<p dir=\"auto\">init <code>closed</code> variable</p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:17:52Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTIzMw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209233", "body": "add `@Nullable`", "bodyText": "add @Nullable", "bodyHTML": "<p dir=\"auto\">add <code>@Nullable</code></p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:18:19Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTI2Mw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209263", "body": "use another field to save `CoordinationRequestGateway`, can save some casting in the future", "bodyText": "use another field to save CoordinationRequestGateway, can save some casting in the future", "bodyHTML": "<p dir=\"auto\">use another field to save <code>CoordinationRequestGateway</code>, can save some casting in the future</p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:19:18Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTM0MA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209340", "body": "how about `userVisibleHead`", "bodyText": "how about userVisibleHead", "bodyHTML": "<p dir=\"auto\">how about <code>userVisibleHead</code></p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:20:24Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDMxMQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210311", "body": "I don't think we should eat this exception, we should throw this out to show something is going wrong", "bodyText": "I don't think we should eat this exception, we should throw this out to show something is going wrong", "bodyHTML": "<p dir=\"auto\">I don't think we should eat this exception, we should throw this out to show something is going wrong</p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:38:25Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMTY5Mg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426221692", "bodyText": "I would prefer to throw it out", "author": "KurtYoung", "createdAt": "2020-05-17T06:09:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDMxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDUxOQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210519", "body": "when will `responseLastCheckpointedOffset < lastCheckpointedOffset`(I can understand when they are equal), and what would you do with this situation?", "bodyText": "when will responseLastCheckpointedOffset < lastCheckpointedOffset(I can understand when they are equal), and what would you do with this situation?", "bodyHTML": "<p dir=\"auto\">when will <code>responseLastCheckpointedOffset &lt; lastCheckpointedOffset</code>(I can understand when they are equal), and what would you do with this situation?</p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:42:16Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tLOG.warn(\"An exception occurs when deserializing query results. Some results might be lost.\", e);\n+\t\t\t\tresults = Collections.emptyList();\n+\t\t\t}\n+\n+\t\t\tif (responseLastCheckpointedOffset > lastCheckpointedOffset) {", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxNjg4OA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426216888", "bodyText": "It is impossible for responseLastCheckpointedOffset to be smaller than lastCheckpointedOffset, offsets are always non-decreasing.", "author": "tsreaper", "createdAt": "2020-05-17T04:46:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDUxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDYzMQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210631", "body": "We need some document about these variables and ResultBuffer, I'm quite confused now even if I know the algorithm...", "bodyText": "We need some document about these variables and ResultBuffer, I'm quite confused now even if I know the algorithm...", "bodyHTML": "<p dir=\"auto\">We need some document about these variables and ResultBuffer, I'm quite confused now even if I know the algorithm...</p>", "author": "KurtYoung", "createdAt": "2020-05-17T02:44:32Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "01b3b026dc70c49c81b727cadb53b339bab5fbaf", "url": "https://github.com/apache/flink/commit/01b3b026dc70c49c81b727cadb53b339bab5fbaf", "message": "[FLINK-14807][table] Add specialized collecting iterator to Blink planner", "committedDate": "2020-05-17T05:02:55Z", "type": "commit"}, {"oid": "9874962514e28a3e6ee9e796244cf2a04a84bfbf", "url": "https://github.com/apache/flink/commit/9874962514e28a3e6ee9e796244cf2a04a84bfbf", "message": "[fix] Simplify implementation of collect iterator into a memory-based one and refactor test to use this iterator", "committedDate": "2020-05-17T05:02:55Z", "type": "commit"}, {"oid": "2880b1268705e2e671f17208cc723da6f4ab32bf", "url": "https://github.com/apache/flink/commit/2880b1268705e2e671f17208cc723da6f4ab32bf", "message": "[fix] Fix checkstyle and connection issue in collect sink and coordinator", "committedDate": "2020-05-17T05:02:55Z", "type": "commit"}, {"oid": "e7e982893093d13dd679bc0504d892fdc0fb6b63", "url": "https://github.com/apache/flink/commit/e7e982893093d13dd679bc0504d892fdc0fb6b63", "message": "[fix] Add socket timeout to coordinator", "committedDate": "2020-05-17T05:04:07Z", "type": "commit"}, {"oid": "176a38394a1c0e69167dc151f66959ac84258db5", "url": "https://github.com/apache/flink/commit/176a38394a1c0e69167dc151f66959ac84258db5", "message": "[fix] Change statement order in collect result fetcher for easier understanding", "committedDate": "2020-05-17T05:04:07Z", "type": "commit"}, {"oid": "579236dbe523ccc71e62f4f9becdf0937d3b1bf4", "url": "https://github.com/apache/flink/commit/579236dbe523ccc71e62f4f9becdf0937d3b1bf4", "message": "[fix] Fix kurt's comments", "committedDate": "2020-05-17T05:04:07Z", "type": "commit"}, {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29", "url": "https://github.com/apache/flink/commit/4ad199a9f0a8db9ce82493af6e180af602774e29", "message": "[fix] Fix checkstyle", "committedDate": "2020-05-17T05:30:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzUxMQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223511", "body": "```suggestion\r\n\t\t\t\tlong requestOffset = buffer.offset;\r\n\t\t\t\tCollectCoordinationResponse<T> response;\r\n\t\t\t\ttry {\r\n\t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\r\n\t\t\t\t\tsleepBeforeRetry();\r\n\t\t\t\t\tcontinue;\r\n\t\t\t\t}\r\n\t\t\t\t// the response will contain data (if any) starting exactly from requested offset\r\n\t\t\t\tbuffer.dealWithResponse(response, requestOffset);\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\tCollectCoordinationResponse<T> response;\n          \n          \n            \n            \t\t\t\ttry {\n          \n          \n            \n            \t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n          \n          \n            \n            \t\t\t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n          \n          \n            \n            \t\t\t\t\tsleepBeforeRetry();\n          \n          \n            \n            \t\t\t\t\tcontinue;\n          \n          \n            \n            \t\t\t\t}\n          \n          \n            \n            \t\t\t\tbuffer.dealWithResponse(response);\n          \n          \n            \n            \t\t\t\tlong requestOffset = buffer.offset;\n          \n          \n            \n            \t\t\t\tCollectCoordinationResponse<T> response;\n          \n          \n            \n            \t\t\t\ttry {\n          \n          \n            \n            \t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\n          \n          \n            \n            \t\t\t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n          \n          \n            \n            \t\t\t\t\tsleepBeforeRetry();\n          \n          \n            \n            \t\t\t\t\tcontinue;\n          \n          \n            \n            \t\t\t\t}\n          \n          \n            \n            \t\t\t\t// the response will contain data (if any) starting exactly from requested offset\n          \n          \n            \n            \t\t\t\tbuffer.dealWithResponse(response, requestOffset);", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t<span class=\"pl-k\">CollectCoordinationResponse&lt;<span class=\"pl-smi\">T</span>&gt;</span> response;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t<span class=\"pl-k\">try</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t\tresponse <span class=\"pl-k\">=</span> sendRequest(buffer<span class=\"pl-k\">.</span>version, buffer<span class=\"pl-k\">.</span>offset);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t} <span class=\"pl-k\">catch</span> (<span class=\"pl-smi\">Exception</span> e) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t\t<span class=\"pl-c1\">LOG</span><span class=\"pl-k\">.</span>warn(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>An exception occurs when fetching query results<span class=\"pl-pds\">\"</span></span>, e);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t\tsleepBeforeRetry();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t\t<span class=\"pl-k\">continue</span>;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\t}</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t\t\t\tbuffer<span class=\"pl-k\">.</span>dealWithResponse(response);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t<span class=\"pl-k\">long</span> requestOffset <span class=\"pl-k\">=</span> buffer<span class=\"pl-k\">.</span>offset;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t<span class=\"pl-k\">CollectCoordinationResponse&lt;<span class=\"pl-smi\">T</span>&gt;</span> response;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t<span class=\"pl-k\">try</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t\tresponse <span class=\"pl-k\">=</span> sendRequest(buffer<span class=\"pl-k\">.</span>version, requestOffset);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t} <span class=\"pl-k\">catch</span> (<span class=\"pl-smi\">Exception</span> e) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t\t<span class=\"pl-c1\">LOG</span><span class=\"pl-k\">.</span>warn(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>An exception occurs when fetching query results<span class=\"pl-pds\">\"</span></span>, e);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t\tsleepBeforeRetry();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t\t<span class=\"pl-k\">continue</span>;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t}</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> the response will contain data (if any) starting exactly from requested offset</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t\t\t\tbuffer<span class=\"pl-k\">.</span>dealWithResponse(response, requestOffset);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "KurtYoung", "createdAt": "2020-05-17T06:32:41Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzYwNQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223605", "body": "delete this method", "bodyText": "delete this method", "bodyHTML": "<p dir=\"auto\">delete this method</p>", "author": "KurtYoung", "createdAt": "2020-05-17T06:33:30Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzc0MQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223741", "body": "add a sanity check that `responseLastCheckpointedOffset` is less than offset. \r\nand also checks that this buffer still contains data starting from `responseLastCheckpointedOffset`", "bodyText": "add a sanity check that responseLastCheckpointedOffset is less than offset.\nand also checks that this buffer still contains data starting from responseLastCheckpointedOffset", "bodyHTML": "<p dir=\"auto\">add a sanity check that <code>responseLastCheckpointedOffset</code> is less than offset.<br>\nand also checks that this buffer still contains data starting from <code>responseLastCheckpointedOffset</code></p>", "author": "KurtYoung", "createdAt": "2020-05-17T06:35:13Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyOTU5Nw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426229597", "bodyText": "\"less than offset\" should be \"less than or equal to offset\", because sink may have restarted before client fetches more results.", "author": "tsreaper", "createdAt": "2020-05-17T07:46:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzc0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDE0Mg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426224142", "body": "what about if `responseOffset + results.size()` still less than offset, which means you get a fully duplicated data?", "bodyText": "what about if responseOffset + results.size() still less than offset, which means you get a fully duplicated data?", "bodyHTML": "<p dir=\"auto\">what about if <code>responseOffset + results.size()</code> still less than offset, which means you get a fully duplicated data?</p>", "author": "KurtYoung", "createdAt": "2020-05-17T06:40:19Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {\n+\t\t\t\t\tbuffer.removeLast();\n+\t\t\t\t}\n+\t\t\t\tversion = responseVersion;\n+\t\t\t\toffset = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\t// we now check if more results can be seen by the user\n+\t\t\tif (responseLastCheckpointedOffset > userVisibleTail) {\n+\t\t\t\t// lastCheckpointedOffset increases, this means that more results have been\n+\t\t\t\t// checkpointed, and we can give these results to the user\n+\t\t\t\tuserVisibleTail = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\tif (!results.isEmpty()) {\n+\t\t\t\t// response contains some data, add them to buffer\n+\t\t\t\tint addStart = (int) (offset - responseOffset);\n+\t\t\t\tList<T> addedResults = results.subList(addStart, results.size());", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNzcxMg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426227712", "bodyText": "This is impossible. Because if this happens then the sink must have restarted, and we must have gone back to the last checkpointed offset. But I'll add a sanity check here.", "author": "tsreaper", "createdAt": "2020-05-17T07:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDYxNw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426224617", "body": "also check the gateway", "bodyText": "also check the gateway", "bodyHTML": "<p dir=\"auto\">also check the gateway</p>", "author": "KurtYoung", "createdAt": "2020-05-17T06:46:29Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTAwOQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225009", "body": "```suggestion\r\n\tprivate Tuple2<Long, CollectCoordinationResponse<T>> getAccumulatorResults() {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n          \n          \n            \n            \tprivate Tuple2<Long, CollectCoordinationResponse<T>> getAccumulatorResults() {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">\t<span class=\"pl-k\">private</span> <span class=\"pl-k\">Tuple2&lt;<span class=\"pl-smi\">Long</span>, <span class=\"pl-smi\">CollectCoordinationResponse</span>&gt;</span> getAccumulatorResults() {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">\t<span class=\"pl-k\">private</span> <span class=\"pl-k\">Tuple2&lt;<span class=\"pl-smi\">Long</span>, <span class=\"pl-k\">CollectCoordinationResponse<span class=\"x x-first\">&lt;</span><span class=\"pl-smi x\">T</span><span class=\"x x-last\">&gt;</span></span>&gt;</span> getAccumulatorResults() {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "KurtYoung", "createdAt": "2020-05-17T06:51:33Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTY4NA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225684", "body": "throw IOException istead", "bodyText": "throw IOException istead", "bodyHTML": "<p dir=\"auto\">throw IOException istead</p>", "author": "KurtYoung", "createdAt": "2020-05-17T07:00:11Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTgwMA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225800", "body": "should let user know this is a abnormal case, throw an exception?", "bodyText": "should let user know this is a abnormal case, throw an exception?", "bodyHTML": "<p dir=\"auto\">should let user know this is a abnormal case, throw an exception?</p>", "author": "KurtYoung", "createdAt": "2020-05-17T07:01:19Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNjIxMw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426226213", "body": "Before we throw any exception, we should also try to cancel the job", "bodyText": "Before we throw any exception, we should also try to cancel the job", "bodyHTML": "<p dir=\"auto\">Before we throw any exception, we should also try to cancel the job</p>", "author": "KurtYoung", "createdAt": "2020-05-17T07:06:45Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNjY4Ng==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426226686", "body": "change this to `do {} while`, maybe we can reuse these statements with line 110 - line 117?", "bodyText": "change this to do {} while, maybe we can reuse these statements with line 110 - line 117?", "bodyHTML": "<p dir=\"auto\">change this to <code>do {} while</code>, maybe we can reuse these statements with line 110 - line 117?</p>", "author": "KurtYoung", "createdAt": "2020-05-17T07:12:41Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cc45779cd014b587a2fbed2393683ff4fe73a38b", "url": "https://github.com/apache/flink/commit/cc45779cd014b587a2fbed2393683ff4fe73a38b", "message": "[fix] Fix kurt's comments", "committedDate": "2020-05-17T08:21:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI0ODA4Mg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426248082", "body": "how about throw IOException instead?", "bodyText": "how about throw IOException instead?", "bodyHTML": "<p dir=\"auto\">how about throw IOException instead?</p>", "author": "KurtYoung", "createdAt": "2020-05-17T11:08:21Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,358 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\t// this is only an insurance,\n+\t\t// it's the user's responsibility to close the iterator if he does not need it anymore\n+\t\tRuntime.getRuntime().addShutdownHook(new Thread(this::close));\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// this is to avoid sleeping before first try\n+\t\tboolean beforeFirstTry = true;\n+\t\tdo {\n+\t\t\tT res = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// we still have user-visible results, just use them\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else if (!beforeFirstTry) {\n+\t\t\t\t// no results but job is still running, sleep before retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t\tbeforeFirstTry = false;\n+\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\ttry {\n+\t\t\t\t\tTuple2<Long, CollectCoordinationResponse<T>> accResults = getAccumulatorResults();\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(", "originalCommit": "cc45779cd014b587a2fbed2393683ff4fe73a38b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI0ODE2Nw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426248167", "body": "ditto", "bodyText": "ditto", "bodyHTML": "<p dir=\"auto\">ditto</p>", "author": "KurtYoung", "createdAt": "2020-05-17T11:09:23Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,358 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\t// this is only an insurance,\n+\t\t// it's the user's responsibility to close the iterator if he does not need it anymore\n+\t\tRuntime.getRuntime().addShutdownHook(new Thread(this::close));\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// this is to avoid sleeping before first try\n+\t\tboolean beforeFirstTry = true;\n+\t\tdo {\n+\t\t\tT res = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// we still have user-visible results, just use them\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else if (!beforeFirstTry) {\n+\t\t\t\t// no results but job is still running, sleep before retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t\tbeforeFirstTry = false;\n+\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\ttry {\n+\t\t\t\t\tTuple2<Long, CollectCoordinationResponse<T>> accResults = getAccumulatorResults();\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(\n+\t\t\t\t\t\t\"Failed to deal with final accumulator results, final batch of results are lost\", e);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tlong requestOffset = buffer.offset;\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\t// the response will contain data (if any) starting exactly from requested offset\n+\t\t\t\ttry {\n+\t\t\t\t\tbuffer.dealWithResponse(response, requestOffset);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(\"Failed to deal with response from sink\", e);", "originalCommit": "cc45779cd014b587a2fbed2393683ff4fe73a38b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "db16ab869545c73c16e0a3bec6c4482cb3331619", "url": "https://github.com/apache/flink/commit/db16ab869545c73c16e0a3bec6c4482cb3331619", "message": "[fix] Fix kurt's comments", "committedDate": "2020-05-17T11:38:17Z", "type": "commit"}, {"oid": "41d3524e0ba410d80f17f86206191b146d34e460", "url": "https://github.com/apache/flink/commit/41d3524e0ba410d80f17f86206191b146d34e460", "message": "[fix] Remove close insurance as they might throw unwanted exceptions when stopping JVM", "committedDate": "2020-05-17T12:25:23Z", "type": "commit"}]}