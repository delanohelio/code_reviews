{"pr_number": 11515, "pr_title": "[FLINK-16744][task] implement channel state persistence for unaligned checkpoints", "pr_author": "rkhachatryan", "pr_createdAt": "2020-03-25T22:31:45Z", "pr_url": "https://github.com/apache/flink/pull/11515", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkyNzM4Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404927386", "body": "Uniform the argument form as `writeInput`? `Buffer...` or `Buffer[]`", "bodyText": "Uniform the argument form as writeInput? Buffer... or Buffer[]", "bodyHTML": "<p dir=\"auto\">Uniform the argument form as <code>writeInput</code>? <code>Buffer...</code> or <code>Buffer[]</code></p>", "author": "zhijiangW", "createdAt": "2020-04-07T16:02:22Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMjAyOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404932029", "body": "Are there any problems if `checkpointStream.close()` causes exception to not execute the below `dataStream.close()`?", "bodyText": "Are there any problems if checkpointStream.close() causes exception to not execute the below dataStream.close()?", "bodyHTML": "<p dir=\"auto\">Are there any problems if <code>checkpointStream.close()</code> causes exception to not execute the below <code>dataStream.close()</code>?</p>", "author": "zhijiangW", "createdAt": "2020-04-07T16:08:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean allInputsReceived = false;\n+\tprivate boolean allOutputsReceived = false;\n+\tprivate final RunnableWithException onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(\n+\t\t\tstartCheckpointItem.getCheckpointId(),\n+\t\t\tstartCheckpointItem.getTargetResult(),\n+\t\t\tstreamFactory.createCheckpointStateOutputStream(EXCLUSIVE),\n+\t\t\tserializer,\n+\t\t\tonComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnableWithException onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\twrite(inputChannelOffsets, info, flinkBuffers, !allInputsReceived);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers, !allOutputsReceived);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers, boolean precondition) throws Exception {\n+\t\ttry {\n+\t\t\tif (result.isDone()) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\trunWithChecks(() -> {\n+\t\t\t\tcheckState(precondition);\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t});\n+\t\t} finally {\n+\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", allOutputsReceived);\n+\t\tcomplete(!allInputsReceived, () -> allInputsReceived = true);\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", allInputsReceived);\n+\t\tcomplete(!allOutputsReceived, () -> allOutputsReceived = true);\n+\t}\n+\n+\tprivate void complete(boolean precondition, RunnableWithException complete) throws Exception {\n+\t\tif (result.isDone()) {\n+\t\t\t// likely after abort - only need to set the flag run onComplete callback\n+\t\t\tdoComplete(precondition, complete, onComplete);\n+\t\t} else {\n+\t\t\trunWithChecks(() -> doComplete(precondition, complete, onComplete, this::finishWriteAndResult));\n+\t\t}\n+\t}\n+\n+\tprivate void finishWriteAndResult() throws IOException {\n+\t\tdataStream.flush();\n+\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t}\n+\n+\tprivate void doComplete(boolean precondition, RunnableWithException complete, RunnableWithException... callbacks) throws Exception {\n+\t\tPreconditions.checkArgument(precondition);\n+\t\tcomplete.run();\n+\t\tif (allInputsReceived && allOutputsReceived) {\n+\t\t\tfor (RunnableWithException callback : callbacks) {\n+\t\t\t\tcallback.run();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\t\tCompletableFuture<Collection<H>> future,\n+\t\t\tMap<I, List<Long>> offsets,\n+\t\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tcheckState(!result.isDone(), \"result is already completed\", result);\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tfail(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tpublic void fail(Throwable e) throws Exception {\n+\t\tresult.fail(e);\n+\t\tcheckpointStream.close();\n+\t\tdataStream.close();", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwOTE1Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405109157", "bodyText": "Yes, but in that case closing of dataStream doesn't matter.", "author": "rkhachatryan", "createdAt": "2020-04-07T20:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkzMjAyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2NzI4Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404967282", "body": "nit: adjust the description because we only return the size of state in bytes now.", "bodyText": "nit: adjust the description because we only return the size of state in bytes now.", "bodyHTML": "<p dir=\"auto\">nit: adjust the description because we only return the size of state in bytes now.</p>", "author": "zhijiangW", "createdAt": "2020-04-07T16:59:22Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\tint readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\t/**\n+\t * Read up to <code>bytesToRead</code> bytes into this buffer from the given {@link InputStream}.\n+\t * @return     the total number of bytes read into this buffer.\n+\t */\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate final ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\tint left = bytesToRead;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn bytesToRead - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, bufferBuilder.getWritableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\tprivate int written = 0;\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\tfinal int bytesRead = input.read(bytes, written, bytes.length - written);\n+\t\t\t\twritten += bytesRead;\n+\t\t\t\treturn bytesRead;\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes());\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404991842", "body": "Also not sure if we should add suppression for non-standard warnings (e.g. unchecked). Everyone has different settings and the code might be very cluttered if everyone adds these suppressions. And then there is the warning for unused suppressions, which turns it into a recursive mess.", "bodyText": "Also not sure if we should add suppression for non-standard warnings (e.g. unchecked). Everyone has different settings and the code might be very cluttered if everyone adds these suppressions. And then there is the warning for unused suppressions, which turns it into a recursive mess.", "bodyHTML": "<p dir=\"auto\">Also not sure if we should add suppression for non-standard warnings (e.g. unchecked). Everyone has different settings and the code might be very cluttered if everyone adds these suppressions. And then there is the warning for unused suppressions, which turns it into a recursive mess.</p>", "author": "AHeise", "createdAt": "2020-04-07T17:37:17Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Once all data is read, this class can't be used anymore.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate final Queue<Long> offsets;\n+\tprivate int remainingBytes = -1;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.getOrCreate(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incRef();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclosed = true;\n+\t\t\tstream.decRef();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (remainingBytes <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, remainingBytes);\n+\t\t\tremainingBytes -= bytesRead;\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn remainingBytes > 0 || !offsets.isEmpty();\n+\t}\n+\n+\t@SuppressWarnings(\"ConstantConditions\")", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyNzM3Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405427372", "bodyText": "SuppressWarnings is a compiler annotation so it can be ignored by humans.\nCompiler warnings, on the other hand, are intended for humans and shouldn't be ignored.\nTherefore useless warnings produce clutter and unsupported SuppressWarnings not.", "author": "rkhachatryan", "createdAt": "2020-04-08T10:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQzNjI1Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405436252", "bodyText": "My main point was that the specific warning is not a standard java compiler, but coming from IntelliJ and depends on your settings (I don't see this warning).\nIf I enable warning for unused suppression, I get a compiler warning for your suppression and I don't want to argue which settings are inherently better.\nSo I suggest to not suppress \"ConstantConditions\", but only standard suppressions like \"unchecked\".", "author": "AHeise", "createdAt": "2020-04-08T10:54:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5MTg0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5NjYwNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404996605", "body": "nit: initialize field directly? (not sure what the default is, just pointing out)", "bodyText": "nit: initialize field directly? (not sure what the default is, just pointing out)", "bodyHTML": "<p dir=\"auto\">nit: initialize field directly? (not sure what the default is, just pointing out)</p>", "author": "AHeise", "createdAt": "2020-04-07T17:44:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5NzE0MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404997140", "body": "nit: add string message (containing checkpoint id for easier debugging).", "bodyText": "nit: add string message (containing checkpoint id for easier debugging).", "bodyHTML": "<p dir=\"auto\">nit: add string message (containing checkpoint id for easier debugging).</p>", "author": "AHeise", "createdAt": "2020-04-07T17:45:48Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();\n+\t\tthis.streamFactoryResolver = streamFactoryResolver;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\t@Override\n+\tpublic void dispatch(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\ttry {\n+\t\t\tdispatchInternal(request);\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tprivate void dispatchInternal(ChannelStateWriteRequest request) throws Exception {\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.getCheckpointId()));", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5ODEwNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404998104", "body": "nit: forEach is not saving anything on for-loop and the latter is usually easier to read for java guys.", "bodyText": "nit: forEach is not saving anything on for-loop and the latter is usually easier to read for java guys.", "bodyHTML": "<p dir=\"auto\">nit: forEach is not saving anything on for-loop and the latter is usually easier to read for java guys.</p>", "author": "AHeise", "createdAt": "2020-04-07T17:47:24Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcherImpl.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestDispatcherImpl implements ChannelStateWriteRequestDispatcher {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestDispatcherImpl.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryResolver;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestDispatcherImpl(CheckpointStorageWorkerView streamFactoryResolver, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>();\n+\t\tthis.streamFactoryResolver = streamFactoryResolver;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\t@Override\n+\tpublic void dispatch(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\ttry {\n+\t\t\tdispatchInternal(request);\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow e;\n+\t\t}\n+\t}\n+\n+\tprivate void dispatchInternal(ChannelStateWriteRequest request) throws Exception {\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.getCheckpointId()));\n+\t\t\twriters.put(request.getCheckpointId(), buildWriter((CheckpointStartRequest) request));\n+\t\t} else if (request instanceof CheckpointInProgressRequest) {\n+\t\t\tChannelStateCheckpointWriter writer = writers.get(request.getCheckpointId());\n+\t\t\tCheckpointInProgressRequest req = (CheckpointInProgressRequest) request;\n+\t\t\tif (writer == null) {\n+\t\t\t\treq.onWriterMissing();\n+\t\t\t} else {\n+\t\t\t\treq.execute(writer);\n+\t\t\t}\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"unknown request type: \" + request);\n+\t\t}\n+\t}\n+\n+\tprivate ChannelStateCheckpointWriter buildWriter(CheckpointStartRequest request) throws Exception {\n+\t\treturn new ChannelStateCheckpointWriter(\n+\t\t\trequest,\n+\t\t\tstreamFactoryResolver.resolveCheckpointStorageLocation(request.getCheckpointId(), request.getLocationReference()),\n+\t\t\tserializer,\n+\t\t\t() -> writers.remove(request.getCheckpointId()));\n+\t}\n+\n+\t@Override\n+\tpublic void close(Throwable cause) {\n+\t\twriters.values().forEach(writer -> {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTEwMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404999103", "body": "`close` is a strange name for something that belongs to the exception handling. Why not call it `fail` like in the writer?", "bodyText": "close is a strange name for something that belongs to the exception handling. Why not call it fail like in the writer?", "bodyHTML": "<p dir=\"auto\"><code>close</code> is a strange name for something that belongs to the exception handling. Why not call it <code>fail</code> like in the writer?</p>", "author": "AHeise", "createdAt": "2020-04-07T17:48:53Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestDispatcher.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+interface ChannelStateWriteRequestDispatcher {\n+\n+\tvoid dispatch(ChannelStateWriteRequest request) throws Exception;\n+\n+\tvoid close(Throwable cause);", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk5OTQ0MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404999440", "body": "nit: you don't use empty lines on other classes.", "bodyText": "nit: you don't use empty lines on other classes.", "bodyHTML": "<p dir=\"auto\">nit: you don't use empty lines on other classes.</p>", "author": "AHeise", "createdAt": "2020-04-07T17:49:31Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutor.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import java.io.Closeable;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s potentially asynchronously. An exception thrown during the execution\n+ * should be re-thrown on any next call.\n+ */\n+interface ChannelStateWriteRequestExecutor extends Closeable {\n+\n+\t/**\n+\t * @throws IllegalStateException if called more than once or after {@link #close()}\n+\t */\n+\tvoid start() throws IllegalStateException;\n+\n+\t/**\n+\t * Send {@link ChannelStateWriteRequest} to this worker. If this method throws an exception then client must\n+\t * {@link ChannelStateWriteRequest#cancel cancel} it.\n+\t * @throws IllegalStateException if worker is not running\n+\t * @throws Exception if any exception occurred during processing this or other items previously\n+\t */\n+\tvoid submit(ChannelStateWriteRequest r) throws Exception;\n+\n+\t/**\n+\t * Send {@link ChannelStateWriteRequest} to this worker to be processed first. If this method throws an exception then client must\n+\t * {@link ChannelStateWriteRequest#cancel cancel} it.\n+\t * @throws IllegalStateException if worker is not running\n+\t * @throws Exception if any exception occurred during processing this or other items previously\n+\t */\n+\tvoid submitPriority(ChannelStateWriteRequest r) throws Exception;\n+", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNjMyNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405006327", "body": "Is there a particular reason to bound the optionally-bouded `LinkedBlockingDeque`? In the end, we are most likely limited by the number of buffers anyways and I'd argue that the overhead of your data structures is minimal compared to them.", "bodyText": "Is there a particular reason to bound the optionally-bouded LinkedBlockingDeque? In the end, we are most likely limited by the number of buffers anyways and I'd argue that the overhead of your data structures is minimal compared to them.", "bodyHTML": "<p dir=\"auto\">Is there a particular reason to bound the optionally-bouded <code>LinkedBlockingDeque</code>? In the end, we are most likely limited by the number of buffers anyways and I'd argue that the overhead of your data structures is minimal compared to them.</p>", "author": "AHeise", "createdAt": "2020-04-07T18:00:22Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTExOTg5MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405119890", "bodyText": "If the same buffer can be enqueued multiple times, then this overhead can be significant.\nIt can happen because of a bug or (probably) with multiple checkpoints in-flight but without incremental checkpointing.\nIn such cases we can:\n\nthrow an exception (current behavior)\nblock\nallow to proceed (possibly exhausting memory / gc)\n\n(and no limit means Integer.MAX_VALUE, so it's just a higher limit)", "author": "rkhachatryan", "createdAt": "2020-04-07T21:20:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNjMyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwODY1OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405008659", "body": "Since we encountered a hard error in Flink, there is no way to proceed and I'd probably also switch `checkArgument` to `checkState`.", "bodyText": "Since we encountered a hard error in Flink, there is no way to proceed and I'd probably also switch checkArgument to checkState.", "bodyHTML": "<p dir=\"auto\">Since we encountered a hard error in Flink, there is no way to proceed and I'd probably also switch <code>checkArgument</code> to <code>checkState</code>.</p>", "author": "AHeise", "createdAt": "2020-04-07T18:03:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tresults.clear();\n+\t\texecutor.close();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request, boolean atTheFront) {\n+\t\t// state check and previous errors check are performed inside the worker\n+\t\ttry {\n+\t\t\tif (atTheFront) {\n+\t\t\t\texecutor.submitPriority(request);\n+\t\t\t} else {\n+\t\t\t\texecutor.submit(request);\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\trequest.cancel(e);\n+\t\t\tthrow new RuntimeException(\"unable to send request to worker\", e);\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {\n+\t\tif (data == null) {\n+\t\t\treturn new Buffer[0];\n+\t\t}\n+\t\ttry {\n+\t\t\tfor (Buffer buffer : data) {\n+\t\t\t\tPreconditions.checkArgument(buffer.isBuffer());", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQzNDY4Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405434683", "bodyText": "The class itself (and its \"downstream\" classes) is still operable. It shouldn't know that it's clients aren't able to deal with this exception.", "author": "rkhachatryan", "createdAt": "2020-04-08T10:51:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwODY1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwOTg4Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405009883", "body": "See my previous comment on suppressions.", "bodyText": "See my previous comment on suppressions.", "bodyHTML": "<p dir=\"auto\">See my previous comment on suppressions.</p>", "author": "AHeise", "createdAt": "2020-04-07T18:05:59Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDYzMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405010630", "body": "Now this should be a real suppression ;)", "bodyText": "Now this should be a real suppression ;)", "bodyHTML": "<p dir=\"auto\">Now this should be a real suppression ;)</p>", "author": "AHeise", "createdAt": "2020-04-07T18:07:16Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDg0OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405010848", "body": "you should decide on empty line or not?", "bodyText": "you should decide on empty line or not?", "bodyHTML": "<p dir=\"auto\">you should decide on empty line or not?</p>", "author": "AHeise", "createdAt": "2020-04-07T18:07:37Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {\n+\t\t//noinspection unchecked\n+\t\treturn handles.stream().filter(clazz::isInstance).map(h -> (C) h).collect(Collectors.toList());\n+\t}\n+\n+\tprivate static int sizeOfBytes(Map<?, byte[]> map) {\n+\t\treturn map.values().stream().mapToInt(d -> d.length).sum();\n+\t}\n+\n+\tprivate <K> Map<K, Buffer> wrapWithBuffers(Map<K, byte[]> icMap) {\n+\t\treturn icMap.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> wrapWithBuffer(e.getValue())));\n+\t}\n+\n+\tprivate static Buffer wrapWithBuffer(byte[] data) {\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(data.length, null), FreeingBufferRecycler.INSTANCE);\n+\t\tbuffer.writeBytes(data);\n+\t\treturn buffer;\n+\t}\n+", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQzNzMxMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405437313", "bodyText": "I don't think it makes a big difference. If it would, it should be in the Flink formatting guidelines and checkstyle config.", "author": "rkhachatryan", "createdAt": "2020-04-08T10:56:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMDg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxMjM1Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405012353", "body": "Usually, we don't want to push TODOs into master, but I can see that it has some value. On the other hand, it should be quite easy to find when actually adding unaligned checkpoints.", "bodyText": "Usually, we don't want to push TODOs into master, but I can see that it has some value. On the other hand, it should be quite easy to find when actually adding unaligned checkpoints.", "bodyHTML": "<p dir=\"auto\">Usually, we don't want to push TODOs into master, but I can see that it has some value. On the other hand, it should be quite easy to find when actually adding unaligned checkpoints.</p>", "author": "AHeise", "createdAt": "2020-04-07T18:10:09Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -277,7 +277,8 @@ protected StreamTask(\n \t\t\tgetCancelables(),\n \t\t\tgetAsyncOperationsThreadPool(),\n \t\t\tgetEnvironment(),\n-\t\t\tthis);\n+\t\t\tthis,\n+\t\t\tfalse); // todo: pass true if unaligned checkpoints enabled", "originalCommit": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNTkwMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405015903", "body": "This looks a bit suspicious. Do we actually need a dedicated `open` or could we `open` it in the constructor already. Maybe it would allow us to have more final fields?", "bodyText": "This looks a bit suspicious. Do we actually need a dedicated open or could we open it in the constructor already. Maybe it would allow us to have more final fields?", "bodyHTML": "<p dir=\"auto\">This looks a bit suspicious. Do we actually need a dedicated <code>open</code> or could we <code>open</code> it in the constructor already. Maybe it would allow us to have more final fields?</p>", "author": "AHeise", "createdAt": "2020-04-07T18:16:14Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -55,20 +68,33 @@\n \t\t\tCloseableRegistry closeableRegistry,\n \t\t\tExecutorService executorService,\n \t\t\tEnvironment env,\n-\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n \t\tthis.actionExecutor = actionExecutor;\n+\t\tthis.channelStateWriter = sendChannelState ? openChannelStateWriter() : ChannelStateWriter.NO_OP;\n+\t\tthis.closeableRegistry.registerCloseable(this);\n+\t}\n+\n+\tprivate ChannelStateWriterImpl openChannelStateWriter() {\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(this.checkpointStorage);\n+\t\twriter.open();", "originalCommit": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEyMzUxMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405123512", "bodyText": "It starts a thread and it doesn't affect fields.", "author": "rkhachatryan", "createdAt": "2020-04-07T21:27:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNTkwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI0ODAxNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405248014", "body": "nit: too long line", "bodyText": "nit: too long line", "bodyHTML": "<p dir=\"auto\">nit: too long line</p>", "author": "zhijiangW", "createdAt": "2020-04-08T04:14:10Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI1NjU1Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405256556", "body": "I have three concerns with the `cancel`: \r\n\r\n- In `CheckpointStartRequest#cancel`, the `targetResult.fail(cause)` would be executed. For the case of `CheckpointInProgressRequest`, do we also need to complete the future with failure?\r\n\r\n- `#cancel` is only valid to perform before executing `#execute` method because of the limitation of state condition, although `#cancel` is still triggered while performing `#execute` to cause any exceptions. Is it considered by design?\r\n\r\n- I guess the introduction of `state` was mainly for voiding cancelling multiple times, because `#execute` can not be called more than once in practice. If so, maybe it is not necessary to bring in so many state values, only need one `isCancelled` state.\r\n\r\n", "bodyText": "I have three concerns with the cancel:\n\n\nIn CheckpointStartRequest#cancel, the targetResult.fail(cause) would be executed. For the case of CheckpointInProgressRequest, do we also need to complete the future with failure?\n\n\n#cancel is only valid to perform before executing #execute method because of the limitation of state condition, although #cancel is still triggered while performing #execute to cause any exceptions. Is it considered by design?\n\n\nI guess the introduction of state was mainly for voiding cancelling multiple times, because #execute can not be called more than once in practice. If so, maybe it is not necessary to bring in so many state values, only need one isCancelled state.", "bodyHTML": "<p dir=\"auto\">I have three concerns with the <code>cancel</code>:</p>\n<ul dir=\"auto\">\n<li>\n<p dir=\"auto\">In <code>CheckpointStartRequest#cancel</code>, the <code>targetResult.fail(cause)</code> would be executed. For the case of <code>CheckpointInProgressRequest</code>, do we also need to complete the future with failure?</p>\n</li>\n<li>\n<p dir=\"auto\"><code>#cancel</code> is only valid to perform before executing <code>#execute</code> method because of the limitation of state condition, although <code>#cancel</code> is still triggered while performing <code>#execute</code> to cause any exceptions. Is it considered by design?</p>\n</li>\n<li>\n<p dir=\"auto\">I guess the introduction of <code>state</code> was mainly for voiding cancelling multiple times, because <code>#execute</code> can not be called more than once in practice. If so, maybe it is not necessary to bring in so many state values, only need one <code>isCancelled</code> state.</p>\n</li>\n</ul>", "author": "zhijiangW", "createdAt": "2020-04-08T04:50:44Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+\n+interface ChannelStateWriteRequest {\n+\tlong getCheckpointId();\n+\n+\tvoid cancel(Throwable cause);\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeInput\", checkpointId, ChannelStateCheckpointWriter::completeInput, false);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(\"completeOutput\", checkpointId, ChannelStateCheckpointWriter::completeOutput, false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeInput\", checkpointId, writer -> writer.writeInput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(\"writeOutput\", checkpointId, writer -> writer.writeOutput(info, flinkBuffers), recycle(flinkBuffers), false);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest start(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\treturn new CheckpointStartRequest(checkpointId, targetResult, locationReference);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest abort(long checkpointId, Throwable cause) {\n+\t\treturn new CheckpointInProgressRequest(\"abort\", checkpointId, writer -> writer.fail(cause), true);\n+\t}\n+\n+\tstatic Consumer<Throwable> recycle(Buffer[] flinkBuffers) {\n+\t\treturn unused -> {\n+\t\t\tfor (Buffer b : flinkBuffers) {\n+\t\t\t\tb.recycleBuffer();\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+final class CheckpointStartRequest implements ChannelStateWriteRequest {\n+\tprivate final ChannelStateWriteResult targetResult;\n+\tprivate final CheckpointStorageLocationReference locationReference;\n+\tprivate final long checkpointId;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\tChannelStateWriteResult getTargetResult() {\n+\t\treturn targetResult;\n+\t}\n+\n+\tpublic CheckpointStorageLocationReference getLocationReference() {\n+\t\treturn locationReference;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\ttargetResult.fail(cause);\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn \"start \" + checkpointId;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest implements ChannelStateWriteRequest {\n+\tprivate final ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\tprivate final Consumer<Throwable> discardAction;\n+\tprivate final long checkpointId;\n+\tprivate final String name;\n+\tprivate final boolean ignoreMissingWriter;\n+\tprivate final AtomicReference<CheckpointInProgressRequestState> state = new AtomicReference<>(CheckpointInProgressRequestState.NEW);\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, boolean ignoreMissingWriter) {\n+\t\tthis(name, checkpointId, action, unused -> {\n+\t\t}, ignoreMissingWriter);\n+\t}\n+\n+\tCheckpointInProgressRequest(String name, long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action, Consumer<Throwable> discardAction, boolean ignoreMissingWriter) {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.action = action;\n+\t\tthis.discardAction = discardAction;\n+\t\tthis.name = name;\n+\t\tthis.ignoreMissingWriter = ignoreMissingWriter;\n+\t}\n+\n+\t@Override\n+\tpublic long getCheckpointId() {\n+\t\treturn checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic void cancel(Throwable cause) {\n+\t\tif (state.compareAndSet(CheckpointInProgressRequestState.NEW, CheckpointInProgressRequestState.CANCELLED)) {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxMjQ5Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405612493", "bodyText": "In case of CheckpointStartRequest it \"owns\" the result future (ChannelStateCheckpointWriter wasn't yet created for it). In other cases ChannelStateCheckpointWriter owns the future.\n\n\nThis is a bug. Fixed it.\n\n\nwith just volatile isCanceled it's possible for two thread to cancel it simultaneously", "author": "rkhachatryan", "createdAt": "2020-04-08T15:28:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI1NjU1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI2MjcyNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405262725", "body": "If the thread is still alive, do we also need to `Thread.currentThread().interrupt()`?", "bodyText": "If the thread is still alive, do we also need to Thread.currentThread().interrupt()?", "bodyHTML": "<p dir=\"auto\">If the thread is still alive, do we also need to <code>Thread.currentThread().interrupt()</code>?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T05:15:48Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\twasClosed = true;\n+\t\twhile (thread.isAlive()) {\n+\t\t\tthread.interrupt();\n+\t\t\ttry {\n+\t\t\t\tthread.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!thread.isAlive()) {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ0ODcwMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405448703", "bodyText": "This will cause join to exit immediately (because the interrupt flag is set) and the loop will be essentially busy waiting.", "author": "rkhachatryan", "createdAt": "2020-04-08T11:19:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI2MjcyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI3MDI4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405270284", "body": "can we judge this condition only by `thread.isAlive()`? In some other cases if thread was ended not via `#close()` method by accident, it seems still make sense for the caller to make the decision.", "bodyText": "can we judge this condition only by thread.isAlive()? In some other cases if thread was ended not via #close() method by accident, it seems still make sense for the caller to make the decision.", "bodyHTML": "<p dir=\"auto\">can we judge this condition only by <code>thread.isAlive()</code>? In some other cases if thread was ended not via <code>#close()</code> method by accident, it seems still make sense for the caller to make the decision.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T05:43:06Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImpl.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.BlockingDeque;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+/**\n+ * Executes {@link ChannelStateWriteRequest}s in a separate thread. Any exception occurred during execution causes this\n+ * thread to stop and the exception to be re-thrown on any subsequent call.\n+ */\n+@ThreadSafe\n+class ChannelStateWriteRequestExecutorImpl implements ChannelStateWriteRequestExecutor {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestExecutorImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10_000;\n+\n+\tprivate final ChannelStateWriteRequestDispatcher dispatcher;\n+\tprivate final BlockingDeque<ChannelStateWriteRequest> deque;\n+\tprivate final Thread thread;\n+\tprivate volatile Exception thrown = null;\n+\tprivate volatile boolean wasClosed = false;\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher) {\n+\t\tthis(dispatcher, new LinkedBlockingDeque<>(DEFAULT_HANDOVER_CAPACITY));\n+\t}\n+\n+\tChannelStateWriteRequestExecutorImpl(ChannelStateWriteRequestDispatcher dispatcher, BlockingDeque<ChannelStateWriteRequest> deque) {\n+\t\tthis.dispatcher = dispatcher;\n+\t\tthis.deque = deque;\n+\t\tthis.thread = new Thread(this::run);\n+\t\tthis.thread.setDaemon(true);\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid run() {\n+\t\ttry {\n+\t\t\tloop();\n+\t\t} catch (Exception ex) {\n+\t\t\tthrown = ex;\n+\t\t} finally {\n+\t\t\tcleanupRequests();\n+\t\t\tdispatcher.close(thrown == null ? new CancellationException() : thrown);\n+\t\t}\n+\t\tLOG.debug(\"loop terminated\");\n+\t}\n+\n+\tprivate void loop() throws Exception {\n+\t\twhile (isActive()) {\n+\t\t\ttry {\n+\t\t\t\tdispatcher.dispatch(deque.take());\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (isActive()) {\n+\t\t\t\t\tLOG.debug(\"interrupted while waiting for a request (continue waiting)\", e);\n+\t\t\t\t} else {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void cleanupRequests() {\n+\t\tThrowable cause = thrown == null ? new CancellationException() : thrown;\n+\t\tList<ChannelStateWriteRequest> drained = new ArrayList<>();\n+\t\tdeque.drainTo(drained);\n+\t\tLOG.info(\"discarding {} drained requests\", drained.size());\n+\t\tfor (ChannelStateWriteRequest request : drained) {\n+\t\t\trequest.cancel(cause);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void start() throws IllegalStateException {\n+\t\tthis.thread.start();\n+\t}\n+\n+\t@Override\n+\tpublic void submit(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.add(request));\n+\t}\n+\n+\t@Override\n+\tpublic void submitPriority(ChannelStateWriteRequest request) throws Exception {\n+\t\tsubmitInternal(request, () -> deque.addFirst(request));\n+\t}\n+\n+\tprivate void submitInternal(ChannelStateWriteRequest request, RunnableWithException action) throws Exception {\n+\t\ttry {\n+\t\t\taction.run();\n+\t\t} catch (Exception ex) {\n+\t\t\trequest.cancel(ex);\n+\t\t\tthrow ex;\n+\t\t}\n+\t\tensureRunning();\n+\t}\n+\n+\tprivate void ensureRunning() throws Exception {\n+\t\t// this check should be performed *at least after* enqueuing a request\n+\t\t// checking before is not enough because (check + enqueue) is not atomic\n+\t\tif (!isActive()) {\n+\t\t\tcleanupRequests();\n+\t\t\tthrow ExceptionUtils.firstOrSuppressed(new IllegalStateException(\"not running\"), thrown);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isActive() {\n+\t\treturn !wasClosed && thread.isAlive();", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ1MDk2OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405450968", "bodyText": "This method is used inside loop and ensureRunning.\nIn loop it actually wasClosed that matters (so it's possible to exit loop).\nIn ensureRunning we could use only thread.isAlive; but there is no guarantee when it will return false after wasClosed was set.", "author": "rkhachatryan", "createdAt": "2020-04-08T11:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI3MDI4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI4NDg4Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405284887", "body": "This can be done only via `SubtaskCheckpointCoordinatorImpl#close`, but i do not see `StreamTask` or other places will call `SubtaskCheckpointCoordinatorImpl#close` from the current codes. What is the consideration for this?", "bodyText": "This can be done only via SubtaskCheckpointCoordinatorImpl#close, but i do not see StreamTask or other places will call SubtaskCheckpointCoordinatorImpl#close from the current codes. What is the consideration for this?", "bodyHTML": "<p dir=\"auto\">This can be done only via <code>SubtaskCheckpointCoordinatorImpl#close</code>, but i do not see <code>StreamTask</code> or other places will call <code>SubtaskCheckpointCoordinatorImpl#close</code> from the current codes. What is the consideration for this?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T06:24:29Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has by default\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ * Thread-safety: this class is thread-safe when used with a thread-safe {@link ChannelStateWriteRequestExecutor executor}\n+ * (e.g. default {@link ChannelStateWriteRequestExecutorImpl}.\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate final ChannelStateWriteRequestExecutor executor;\n+\tprivate final ConcurrentMap<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver) {\n+\t\tthis(streamFactoryResolver, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link ChannelStateSerializerImpl default} {@link ChannelStateSerializer},\n+\t * and a {@link ChannelStateWriteRequestExecutorImpl}.\n+\t *\n+\t * @param maxCheckpoints        maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t * @param streamFactoryResolver a factory to obtain output stream factory for a given checkpoint\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryResolver, int maxCheckpoints) {\n+\t\tthis(\n+\t\t\tnew ConcurrentHashMap<>(maxCheckpoints),\n+\t\t\tnew ChannelStateWriteRequestExecutorImpl(new ChannelStateWriteRequestDispatcherImpl(streamFactoryResolver, new ChannelStateSerializerImpl())),\n+\t\t\tmaxCheckpoints\n+\t\t);\n+\t}\n+\n+\tChannelStateWriterImpl(ConcurrentMap<Long, ChannelStateWriteResult> results, ChannelStateWriteRequestExecutor executor, int maxCheckpoints) {\n+\t\tthis.results = results;\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.executor = executor;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkState(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()), false);\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId), false);\n+\t}\n+\n+\t@Override\n+\tpublic void abort(long checkpointId, Throwable cause) {\n+\t\tLOG.debug(\"abort, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), true); // abort already started\n+\t\tenqueue(ChannelStateWriteRequest.abort(checkpointId, cause), false); // abort enqueued but not started\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\texecutor.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ1NjAxMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405456013", "bodyText": "SubtaskCheckpointCoordinatorImpl is registered with CloseableRegistry in its constructor (which in turn is closed by StreamTask).", "author": "rkhachatryan", "createdAt": "2020-04-08T11:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI4NDg4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI5NDE4Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405294182", "body": "nit: irrelevant change, better to have spaces", "bodyText": "nit: irrelevant change, better to have spaces", "bodyHTML": "<p dir=\"auto\">nit: irrelevant change, better to have spaces</p>", "author": "zhijiangW", "createdAt": "2020-04-08T06:48:19Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -1057,7 +1062,7 @@ else if (current == ExecutionState.RUNNING) {\n \t\t\t\t\t\t// case the canceling could not continue\n \n \t\t\t\t\t\t// The canceller calls cancel and interrupts the executing thread once\n-\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this :: closeNetworkResources, invokable, executingThread, taskNameWithSubtask);\n+\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this::closeNetworkResources, invokable, executingThread, taskNameWithSubtask);", "originalCommit": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTI5ODgwNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405298804", "body": "Do we have the tests coverage for this new introduced caching function in the commit `[FLINK-16744][task] send channel state handles to JM`?", "bodyText": "Do we have the tests coverage for this new introduced caching function in the commit [FLINK-16744][task] send channel state handles to JM?", "bodyHTML": "<p dir=\"auto\">Do we have the tests coverage for this new introduced caching function in the commit <code>[FLINK-16744][task] send channel state handles to JM</code>?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T06:58:44Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -188,6 +221,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(\n+\t\t\t\tchannelStateWriteResult\n+\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t.thenApply(SnapshotResult::of));\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(\n+\t\t\t\tchannelStateWriteResult\n+\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t.thenApply(SnapshotResult::of));\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws IOException {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {", "originalCommit": "bdb06fc00a0da1e0c3df87383de8ebb0a28b1ef3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwMzcwMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405303703", "body": "it is not suggested putting multiple arguments in one line. split line for every argument", "bodyText": "it is not suggested putting multiple arguments in one line. split line for every argument", "bodyHTML": "<p dir=\"auto\">it is not suggested putting multiple arguments in one line. split line for every argument</p>", "author": "zhijiangW", "createdAt": "2020-04-08T07:09:22Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,", "originalCommit": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405304470", "body": "I guess the condition `checkpointOptions.getCheckpointType() == CHECKPOINT` should be consistent with `sendChannelState` in constructor?", "bodyText": "I guess the condition checkpointOptions.getCheckpointType() == CHECKPOINT should be consistent with sendChannelState in constructor?", "bodyHTML": "<p dir=\"auto\">I guess the condition <code>checkpointOptions.getCheckpointType() == CHECKPOINT</code> should be consistent with <code>sendChannelState</code> in constructor?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T07:11:03Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?", "originalCommit": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ2MjczMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405462733", "bodyText": "No,\n\nsendChannelState is set on startup and never changes and means \"unaligned checkpoints enabled\".\ncheckpointOptions.getCheckpointType() varies from call to call", "author": "rkhachatryan", "createdAt": "2020-04-08T11:47:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY3NjMzMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405676332", "bodyText": "that is right", "author": "zhijiangW", "createdAt": "2020-04-08T17:01:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNDQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNTQ1Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405305452", "body": "nit: reduce indentation?", "bodyText": "nit: reduce indentation?", "bodyHTML": "<p dir=\"auto\">nit: reduce indentation?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T07:13:04Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :", "originalCommit": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNjQ1MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405306450", "body": "If `buildOperatorSnapshotFutures` encounters exception, the clear will not be executed, should place within `finally`?", "bodyText": "If buildOperatorSnapshotFutures encounters exception, the clear will not be executed, should place within finally?", "bodyHTML": "<p dir=\"auto\">If <code>buildOperatorSnapshotFutures</code> encounters exception, the clear will not be executed, should place within <code>finally</code>?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T07:15:09Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -130,95 +130,108 @@ public void checkpointState(\n \n \t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n \t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n+\t\toperatorChain.prepareSnapshotPreBarrier(metadata.getCheckpointId());\n \n \t\t// Step (2): Send the checkpoint barrier downstream\n-\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\tcheckpointId,\n-\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\tcheckpointOptions);\n+\t\toperatorChain.broadcastCheckpointBarrier(metadata.getCheckpointId(), metadata.getTimestamp(), options);\n \n-\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t//           impact progress of the streaming topology\n+\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not impact progress of the streaming topology\n \n-\t\tlong startSyncPartNano = System.nanoTime();\n-\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n-\t\tChannelStateWriteResult channelStateWriteResult =\n-\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n-\t\t\t\tChannelStateWriteResult.EMPTY;\n+\t\tMap<OperatorID, OperatorSnapshotFutures> snapshotFutures = new HashMap<>(operatorChain.getNumberOfOperators());\n \t\ttry {\n-\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\toperatorSnapshotsInProgress.put(\n-\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n-\t\t\t\t\tbuildOperatorSnapshotFutures(\n-\t\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\t\toperatorChain,\n-\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n-\t\t\t\t\t\tisCanceled,\n-\t\t\t\t\t\tchannelStateWriteResult)\n-\t\t\t\t);\n-\t\t\t}\n-\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());\n+\t\t\ttakeSnapshotSync(snapshotFutures, metadata, metrics, options, operatorChain, isCanceled);\n+\t\t\tfinishAndReportAsync(snapshotFutures, metadata, metrics);\n+\t\t} catch (Exception ex) {\n+\t\t\tcleanup(snapshotFutures, metadata, metrics, options, ex);\n+\t\t}\n+\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n-\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n-\t\t\t}\n+\tprivate void cleanup(\n+\t\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n+\t\t\tCheckpointMetaData metadata,\n+\t\t\tCheckpointMetrics metrics, CheckpointOptions options,\n+\t\t\tException ex) throws Exception {\n \n-\t\t\tlong startAsyncPartNano = System.nanoTime();\n-\n-\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n-\n-\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n-\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n-\t\t\t\toperatorSnapshotsInProgress,\n-\t\t\t\tcheckpointMetaData,\n-\t\t\t\tcheckpointMetrics,\n-\t\t\t\tstartAsyncPartNano,\n-\t\t\t\ttaskName,\n-\t\t\t\tcloseableRegistry,\n-\t\t\t\tenv,\n-\t\t\t\tasyncExceptionHandler));\n-\n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n-\t\t} catch (Exception ex) {\n-\t\t\t// Cleanup to release resources\n-\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n-\t\t\t\tif (null != operatorSnapshotResult) {\n-\t\t\t\t\ttry {\n-\t\t\t\t\t\toperatorSnapshotResult.cancel();\n-\t\t\t\t\t} catch (Exception e) {\n-\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n-\t\t\t\t\t}\n+\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\tif (operatorSnapshotResult != null) {\n+\t\t\t\ttry {\n+\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n \t\t\t\t}\n \t\t\t}\n+\t\t}\n \n-\t\t\tif (LOG.isDebugEnabled()) {\n-\t\t\t\tLOG.debug(\n-\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n-\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n-\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n-\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n-\t\t\t}\n+\t\tif (LOG.isDebugEnabled()) {\n+\t\t\tLOG.debug(\n+\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\ttaskName, metadata.getCheckpointId(),\n+\t\t\t\tmetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\tmetrics.getSyncDurationMillis());\n+\t\t}\n \n-\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n-\t\t\t\t// so that the task fails.\n-\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n-\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n-\t\t\t\tthrow ex;\n-\t\t\t} else {\n-\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n-\t\t\t}\n+\t\tif (options.getCheckpointType().isSynchronous()) {\n+\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t// so that the task fails.\n+\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\tthrow ex;\n+\t\t} else {\n+\t\t\tenv.declineCheckpoint(metadata.getCheckpointId(), ex);\n+\t\t}\n+\t}\n+\n+\tprivate void finishAndReportAsync(Map<OperatorID, OperatorSnapshotFutures> snapshotFutures, CheckpointMetaData metadata, CheckpointMetrics metrics) {\n+\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\tsnapshotFutures,\n+\t\t\tmetadata,\n+\t\t\tmetrics,\n+\t\t\tSystem.nanoTime(),\n+\t\t\ttaskName,\n+\t\t\tcloseableRegistry,\n+\t\t\tenv,\n+\t\t\tasyncExceptionHandler));\n+\t}\n+\n+\tprivate void takeSnapshotSync(\n+\t\tMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress, CheckpointMetaData checkpointMetaData,\n+\t\tCheckpointMetrics checkpointMetrics, CheckpointOptions checkpointOptions,\n+\t\tOperatorChain<?, ?> operatorChain,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\n+\t\tlong checkpointId = checkpointMetaData.getCheckpointId();\n+\t\tlong started = System.nanoTime();\n+\n+\t\tChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n+\t\t\t\t\t\t\t\tchannelStateWriter.getWriteResult(checkpointId) :\n+\t\t\t\t\t\t\t\tChannelStateWriteResult.EMPTY;\n+\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(checkpointId, checkpointOptions.getTargetLocation());\n+\n+\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\toperatorChain,\n+\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\tisCanceled,\n+\t\t\t\t\tchannelStateWriteResult,\n+\t\t\t\t\tstorage));\n \t\t}\n+\n+\t\tcheckpointStorage.clearCacheFor(checkpointId);", "originalCommit": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ2MzY1Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405463652", "bodyText": "Yes, will fix this.", "author": "rkhachatryan", "createdAt": "2020-04-08T11:48:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMwNjQ1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMxNzkwOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405317909", "body": "it is better to also verify the `ChannelStateWriteResult#isDone` when complete both input and output.", "bodyText": "it is better to also verify the ChannelStateWriteResult#isDone when complete both input and output.", "bodyHTML": "<p dir=\"auto\">it is better to also verify the <code>ChannelStateWriteResult#isDone</code> when complete both input and output.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T07:37:16Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriterTest.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory.MemoryCheckpointOutputStream;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateCheckpointWriter} test.\n+ */\n+public class ChannelStateCheckpointWriterTest {\n+\tprivate static final RunnableWithException NO_OP_RUNNABLE = () -> {\n+\t};\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testRecyclingBuffers() throws Exception {\n+\t\tChannelStateCheckpointWriter writer = createWriter(new ChannelStateWriteResult());\n+\t\tNetworkBuffer buffer = new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(10, null), FreeingBufferRecycler.INSTANCE);\n+\t\twriter.writeInput(new InputChannelInfo(1, 2), buffer);\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test\n+\tpublic void testFlush() throws Exception {\n+\t\tclass FlushRecorder extends DataOutputStream {\n+\t\t\tprivate boolean flushed = false;\n+\n+\t\t\tprivate FlushRecorder() {\n+\t\t\t\tsuper(new ByteArrayOutputStream());\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void flush() throws IOException {\n+\t\t\t\tflushed = true;\n+\t\t\t\tsuper.flush();\n+\t\t\t}\n+\t\t}\n+\n+\t\tFlushRecorder dataStream = new FlushRecorder();\n+\t\tfinal ChannelStateCheckpointWriter writer = new ChannelStateCheckpointWriter(\n+\t\t\t1L,\n+\t\t\tnew ChannelStateWriteResult(),\n+\t\t\tnew ChannelStateSerializerImpl(),\n+\t\t\tNO_OP_RUNNABLE,\n+\t\t\tnew MemoryCheckpointOutputStream(42),\n+\t\t\tdataStream\n+\t\t);\n+\n+\t\twriter.completeInput();\n+\t\twriter.completeOutput();\n+\n+\t\tassertTrue(dataStream.flushed);", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ2ODEyOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405468128", "bodyText": "There are already tests that check that result is completed.\nHowever, they are on a higher level, so I added a separate test here too.", "author": "rkhachatryan", "createdAt": "2020-04-08T11:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMxNzkwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMyODM4Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405328387", "body": "All the below tests are for the  `ChannelStateReader#readInput`, not sure whether we also need to cover the code path for `ChannelStateReader#readOutput`.", "bodyText": "All the below tests are for the  ChannelStateReader#readInput, not sure whether we also need to cover the code path for ChannelStateReader#readOutput.", "bodyHTML": "<p dir=\"auto\">All the below tests are for the  <code>ChannelStateReader#readInput</code>, not sure whether we also need to cover the code path for <code>ChannelStateReader#readOutput</code>.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T07:55:44Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ3NjY0OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405476649", "bodyText": "I don't think it's necessary because they mostly use the same code paths.\nReading into a BufferBuilder is tested separately.", "author": "rkhachatryan", "createdAt": "2020-04-08T12:12:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMyODM4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQwODQzNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405408437", "body": "I have not seen any tests covering the resource release for the reader. If possible, it is better to further verify the internal `RefCountingFSDataInputStream` is dereferenced and closed when no more data.  Then we can confirm no resource leak. ", "bodyText": "I have not seen any tests covering the resource release for the reader. If possible, it is better to further verify the internal RefCountingFSDataInputStream is dereferenced and closed when no more data.  Then we can confirm no resource leak.", "bodyHTML": "<p dir=\"auto\">I have not seen any tests covering the resource release for the reader. If possible, it is better to further verify the internal <code>RefCountingFSDataInputStream</code> is dereferenced and closed when no more data.  Then we can confirm no resource leak.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T10:03:59Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {\n+\n+\tprivate static final InputChannelInfo CHANNEL = new InputChannelInfo(1, 2);\n+\tprivate static final byte[] DATA = generateData(10);\n+\tprivate ChannelStateReaderImpl reader;\n+\n+\t@Before\n+\tpublic void init() {\n+\t\treader = getReader(CHANNEL, DATA);\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws Exception {\n+\t\treader.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testDifferentBufferSizes() throws Exception {\n+\t\tfor (int bufferSize = 1; bufferSize < 2 * DATA.length; bufferSize++) {\n+\t\t\ttry (ChannelStateReaderImpl reader = getReader(CHANNEL, DATA)) { // re-create reader to re-read the same channel\n+\t\t\t\treadAndVerify(bufferSize, CHANNEL, DATA, reader);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testWithOffsets() throws IOException {\n+\t\tMap<InputChannelStateHandle, byte[]> handlesAndBytes = generateHandlesWithBytes(10, 20);\n+\t\tChannelStateReader reader = new ChannelStateReaderImpl(taskStateSnapshot(handlesAndBytes.keySet()), new ChannelStateSerializerImpl());\n+\t\tfor (Map.Entry<InputChannelStateHandle, byte[]> e : handlesAndBytes.entrySet()) {\n+\t\t\treadAndVerify(42, e.getKey().getInfo(), e.getValue(), reader);\n+\t\t}\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadOnlyOnce() throws IOException {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyMDU3Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405420576", "body": "close the stream at the end?", "bodyText": "close the stream at the end?", "bodyHTML": "<p dir=\"auto\">close the stream at the end?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T10:25:05Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerImplTest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.BufferConsumer;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Random;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+\n+/**\n+ * {@link ChannelStateSerializerImpl} test.\n+ */\n+public class ChannelStateSerializerImplTest {\n+\n+\tprivate final Random random = new Random();\n+\n+\t@Test\n+\tpublic void testWriteRead() throws IOException {\n+\t\tint bufSize = 10;\n+\t\tint[] numBuffersToWriteAtOnce = {0, 1, 2, 3};\n+\t\tbyte[] data = getData(bufSize);\n+\t\tChannelStateSerializer s = new ChannelStateSerializerImpl();\n+\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n+\t\tDataOutputStream out = new DataOutputStream(baos);", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyNTEwMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405425100", "body": "nit: this can be reused in other places, like `ChannelStateSerializerImplTest#getData(int len)`, `ChannelStateSerializerTest#randomBytes`", "bodyText": "nit: this can be reused in other places, like ChannelStateSerializerImplTest#getData(int len), ChannelStateSerializerTest#randomBytes", "bodyHTML": "<p dir=\"auto\">nit: this can be reused in other places, like <code>ChannelStateSerializerImplTest#getData(int len)</code>, <code>ChannelStateSerializerTest#randomBytes</code></p>", "author": "zhijiangW", "createdAt": "2020-04-08T10:33:19Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImplTest.java", "diffHunk": "@@ -0,0 +1,205 @@\n+package org.apache.flink.runtime.checkpoint.channel;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.memory.ByteStreamStateHandle;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+import static java.util.Collections.singletonList;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * {@link ChannelStateReaderImpl} test.\n+ */\n+public class ChannelStateReaderImplTest {\n+\n+\tprivate static final InputChannelInfo CHANNEL = new InputChannelInfo(1, 2);\n+\tprivate static final byte[] DATA = generateData(10);\n+\tprivate ChannelStateReaderImpl reader;\n+\n+\t@Before\n+\tpublic void init() {\n+\t\treader = getReader(CHANNEL, DATA);\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws Exception {\n+\t\treader.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testDifferentBufferSizes() throws Exception {\n+\t\tfor (int bufferSize = 1; bufferSize < 2 * DATA.length; bufferSize++) {\n+\t\t\ttry (ChannelStateReaderImpl reader = getReader(CHANNEL, DATA)) { // re-create reader to re-read the same channel\n+\t\t\t\treadAndVerify(bufferSize, CHANNEL, DATA, reader);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testWithOffsets() throws IOException {\n+\t\tMap<InputChannelStateHandle, byte[]> handlesAndBytes = generateHandlesWithBytes(10, 20);\n+\t\tChannelStateReader reader = new ChannelStateReaderImpl(taskStateSnapshot(handlesAndBytes.keySet()), new ChannelStateSerializerImpl());\n+\t\tfor (Map.Entry<InputChannelStateHandle, byte[]> e : handlesAndBytes.entrySet()) {\n+\t\t\treadAndVerify(42, e.getKey().getInfo(), e.getValue(), reader);\n+\t\t}\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadOnlyOnce() throws IOException {\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t}\n+\n+\t@Test(expected = Exception.class)\n+\tpublic void testReadClosed() throws Exception {\n+\t\treader.close();\n+\t\treader.readInputData(CHANNEL, getBuffer(DATA.length));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testReadWrongChannelState() throws IOException {\n+\t\tInputChannelInfo wrongChannel = new InputChannelInfo(CHANNEL.getGateIdx() + 1, CHANNEL.getInputChannelIdx() + 1);\n+\t\treader.readInputData(wrongChannel, getBuffer(DATA.length));\n+\t}\n+\n+\tprivate TaskStateSnapshot taskStateSnapshot(Collection<InputChannelStateHandle> inputChannelStateHandles) {\n+\t\treturn new TaskStateSnapshot(Collections.singletonMap(\n+\t\t\tnew OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(inputChannelStateHandles),\n+\t\t\t\tStateObjectCollection.empty()\n+\t\t\t)));\n+\t}\n+\n+\tprivate static byte[] generateData(int len) {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQyODMwMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405428301", "body": "This class can be merged with `ChannelStateSerializerImplTest`, because they are all aiming for testing the `ChannelStateSerializerImpl` actually, for wrapping `BufferBuilder`, `Buffer`, and `bytes[]` separately in different tests.", "bodyText": "This class can be merged with ChannelStateSerializerImplTest, because they are all aiming for testing the ChannelStateSerializerImpl actually, for wrapping BufferBuilder, Buffer, and bytes[] separately in different tests.", "bodyHTML": "<p dir=\"auto\">This class can be merged with <code>ChannelStateSerializerImplTest</code>, because they are all aiming for testing the <code>ChannelStateSerializerImpl</code> actually, for wrapping <code>BufferBuilder</code>, <code>Buffer</code>, and <code>bytes[]</code> separately in different tests.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T10:39:32Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializerTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.MemorySegmentFactory;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.Random;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * ChannelStateSerializerTest.\n+ */\n+public class ChannelStateSerializerTest {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ5MjA3MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405492070", "body": "eventBuf.recycleBuffer()", "bodyText": "eventBuf.recycleBuffer()", "bodyHTML": "<p dir=\"auto\">eventBuf.recycleBuffer()</p>", "author": "zhijiangW", "createdAt": "2020-04-08T12:39:18Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTU4Nzg0OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405587848", "bodyText": "I used HeapMemorySegment in tests so buffers are freed when the method finishes at the latest.\nrecycleBuffer() would just make them eligible for GC a couple of instructions earlier.", "author": "rkhachatryan", "createdAt": "2020-04-08T14:55:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ5MjA3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405517754", "body": "The worker should start after created, otherwise even though we do not call close via `WorkerClosingDeque`, it can still encounter exception as did in `testSubmitFailure`.", "bodyText": "The worker should start after created, otherwise even though we do not call close via WorkerClosingDeque, it can still encounter exception as did in testSubmitFailure.", "bodyHTML": "<p dir=\"auto\">The worker should start after created, otherwise even though we do not call close via <code>WorkerClosingDeque</code>, it can still encounter exception as did in <code>testSubmitFailure</code>.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T13:18:56Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwMDg1Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405600852", "bodyText": "I didn't get your point here, can you please explain what do you mean?", "author": "rkhachatryan", "createdAt": "2020-04-08T15:12:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY3NTAzOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405675039", "bodyText": "I mean it is better to add worker.start(), then it is easy to distinguish the conditions with below testSubmitFailure. testSubmitFailure is to test the impact without starting, and testCloseAfterSubmit is to test the impact withe explicit close after starting.", "author": "zhijiangW", "createdAt": "2020-04-08T16:59:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUxNzc1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwNDY1Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405604653", "body": "I am not quite clear what is this test motivation for. When the dispatcher throws exception, it would terminate the internal thread inside `ChannelStateWriteRequestExecutorImpl`. And when the `worker#close`, it should throw exception actually, i think we should verify the exception is same with `testException`", "bodyText": "I am not quite clear what is this test motivation for. When the dispatcher throws exception, it would terminate the internal thread inside ChannelStateWriteRequestExecutorImpl. And when the worker#close, it should throw exception actually, i think we should verify the exception is same with testException", "bodyHTML": "<p dir=\"auto\">I am not quite clear what is this test motivation for. When the dispatcher throws exception, it would terminate the internal thread inside <code>ChannelStateWriteRequestExecutorImpl</code>. And when the <code>worker#close</code>, it should throw exception actually, i think we should verify the exception is same with <code>testException</code></p>", "author": "zhijiangW", "createdAt": "2020-04-08T15:18:02Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestExecutorImplTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.LinkedBlockingDeque;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequestDispatcher.NO_OP;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriteRequestExecutorImpl} test.\n+ */\n+public class ChannelStateWriteRequestExecutorImplTest {\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmit() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testCloseAfterSubmitPriority() throws Exception {\n+\t\ttestCloseAfterSubmit(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submit);\n+\t}\n+\n+\t@Test\n+\tpublic void testSubmitPriorityFailure() throws Exception {\n+\t\ttestSubmitFailure(ChannelStateWriteRequestExecutor::submitPriority);\n+\t}\n+\n+\tprivate void testCloseAfterSubmit(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> requestFun) throws Exception {\n+\t\tWorkerClosingDeque closingDeque = new WorkerClosingDeque();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(NO_OP, closingDeque);\n+\t\tclosingDeque.setWorker(worker);\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\trequestFun.accept(worker, request);\n+\t\tassertTrue(closingDeque.isEmpty());\n+\t\tassertFalse(request.isCancelled());\n+\t}\n+\n+\tprivate void testSubmitFailure(BiConsumerWithException<ChannelStateWriteRequestExecutor, ChannelStateWriteRequest, Exception> submitAction) throws Exception {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry {\n+\t\t\tsubmitAction.accept(new ChannelStateWriteRequestExecutorImpl(NO_OP, deque), request);\n+\t\t} catch (IllegalStateException e) {\n+\t\t\t// expected: executor not started;\n+\t\t\treturn;\n+\t\t} finally {\n+\t\t\tassertTrue(request.cancelled);\n+\t\t\tassertTrue(deque.isEmpty());\n+\t\t}\n+\t\tthrow new RuntimeException(\"expected exception not thrown\");\n+\t}\n+\n+\t@Test\n+\t@SuppressWarnings(\"CallToThreadRun\")\n+\tpublic void testCleanup() throws IOException {\n+\t\tTestWriteRequest request = new TestWriteRequest();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\tdeque.add(request);\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque);\n+\n+\t\tworker.close();\n+\t\tworker.run();\n+\n+\t\tassertTrue(requestProcessor.isStopped());\n+\t\tassertTrue(deque.isEmpty());\n+\t\tassertTrue(request.isCancelled());\n+\t}\n+\n+\t@Test\n+\tpublic void testIgnoresInterruptsWhileRunning() throws Exception {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {\n+\t\t\tworker.start();\n+\t\t\tworker.getThread().interrupt();\n+\t\t\tworker.submit(new TestWriteRequest());\n+\t\t\tworker.getThread().interrupt();\n+\t\t\twhile (!deque.isEmpty()) {\n+\t\t\t\tThread.sleep(100);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testCanBeClosed() throws IOException {\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher();\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor)) {\n+\t\t\tworker.start();\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testRecordsException() throws Exception {\n+\t\tTestException testException = new TestException();\n+\t\tTestRequestDispatcher requestProcessor = new TestRequestDispatcher() {\n+\t\t\t@Override\n+\t\t\tpublic void dispatch(ChannelStateWriteRequest request) {\n+\t\t\t\tthrow testException;\n+\t\t\t}\n+\t\t};\n+\t\tLinkedBlockingDeque<ChannelStateWriteRequest> deque = new LinkedBlockingDeque<>(Arrays.asList(new TestWriteRequest()));\n+\t\ttry (ChannelStateWriteRequestExecutorImpl worker = new ChannelStateWriteRequestExecutorImpl(requestProcessor, deque)) {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNTExMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405635113", "bodyText": "Right.\nFixed, thanks for pointing this out", "author": "rkhachatryan", "createdAt": "2020-04-08T15:59:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYwNDY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxOTg2NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405619864", "body": "I guess it is not determined results? When the writer#close, then it relies on `ChannelStateWriteRequestExecutorImpl#cleanupRequests` to cancel the start request to complete the result. But if the start request was already taken away from the queue by internal thread before, then we can not take it from queue to cancel. Or I missed something else?", "bodyText": "I guess it is not determined results? When the writer#close, then it relies on ChannelStateWriteRequestExecutorImpl#cleanupRequests to cancel the start request to complete the result. But if the start request was already taken away from the queue by internal thread before, then we can not take it from queue to cancel. Or I missed something else?", "bodyHTML": "<p dir=\"auto\">I guess it is not determined results? When the writer#close, then it relies on <code>ChannelStateWriteRequestExecutorImpl#cleanupRequests</code> to cancel the start request to complete the result. But if the start request was already taken away from the queue by internal thread before, then we can not take it from queue to cancel. Or I missed something else?</p>", "author": "zhijiangW", "createdAt": "2020-04-08T15:38:11Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAwNzkxMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r406007910", "bodyText": "The result shoud be competed by ChannelStateWriterImpl.close() which is not affected by any other threads.", "author": "rkhachatryan", "createdAt": "2020-04-09T07:28:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYxOTg2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYyMDg3OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405620878", "body": "indentation formatting", "bodyText": "indentation formatting", "bodyHTML": "<p dir=\"auto\">indentation formatting</p>", "author": "zhijiangW", "createdAt": "2020-04-08T15:39:36Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());\n+\t\t}\n+\t\tassertTrue(buffer.isRecycled());\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testNoAddDataAfterFinished() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(\n+\t\t\twriter -> {\n+\t\t\t\tcallStart(writer);\n+\t\t\t\tcallFinish(writer);\n+\t\t\t\tcallAddInputData(writer);\n+\t\t\t}\n+\t\t));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddDataNotStarted() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(writer -> callAddInputData(writer)));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testFinishNotStarted() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(this::callFinish));\n+\t}\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testRethrowOnClose() throws Exception {\n+\t\tunwrappingError(IllegalArgumentException.class, () -> runWithSyncWorker(\n+\t\t\twriter -> {\n+\t\t\t\ttry {\n+\t\t\t\t\tcallFinish(writer);\n+\t\t\t\t} catch (IllegalArgumentException e) {\n+\t\t\t\t\t// ignore here - should rethrow in close\n+\t\t\t\t}\n+\t\t\t}\n+\t\t));\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testRethrowOnNextCall() throws Exception {\n+\t\tSyncChannelStateWriteRequestExecutor worker = new SyncChannelStateWriteRequestExecutor();\n+\t\tChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), worker, 5);\n+\t\twriter.open();\n+\t\tworker.setThrown(new TestException());\n+\t\tunwrappingError(TestException.class, () -> callStart(writer));\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testLimit() throws IOException {\n+\t\tint maxCheckpoints = 3;\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(), maxCheckpoints)) {\n+\t\t\twriter.open();\n+\t\t\tfor (int i = 0; i < maxCheckpoints; i++) {\n+\t\t\t\twriter.start(i, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t\t}\n+\t\t\twriter.start(maxCheckpoints, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t}\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testStartNotOpened() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory())) {\n+\t\t\t\tcallStart(writer);\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testNoStartAfterClose() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\tChannelStateWriterImpl writer = openWriter();\n+\t\t\twriter.close();\n+\t\t\twriter.start(42, CheckpointOptions.forCheckpointWithDefaultLocation());\n+\t\t});\n+\t}\n+\n+\t@Test(expected = IllegalStateException.class)\n+\tpublic void testNoAddDataAfterClose() throws Exception {\n+\t\tunwrappingError(IllegalStateException.class, () -> {\n+\t\t\tChannelStateWriterImpl writer = openWriter();\n+\t\t\tcallStart(writer);\n+\t\t\twriter.close();\n+\t\t\tcallAddInputData(writer);\n+\t\t});\n+\t}\n+\n+\tprivate static <T extends Throwable> void unwrappingError(Class<T> clazz, RunnableWithException r) throws Exception {\n+\t\ttry {\n+\t\t\tr.run();\n+\t\t} catch (Exception e) {\n+\t\t\tthrow findThrowable(e, clazz).map(te -> (Exception) te).orElse(e);\n+\t\t}\n+\t}\n+\n+\tprivate NetworkBuffer getBuffer() {\n+\t\treturn new NetworkBuffer(HeapMemorySegment.FACTORY.allocateUnpooledSegment(123, null), FreeingBufferRecycler.INSTANCE);\n+\t}\n+\n+\tprivate ChannelStateWriteRequestExecutor failingWorker() {\n+\t\treturn new ChannelStateWriteRequestExecutor() {\n+\t\t\t@Override\n+\t\t\tpublic void close() {\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void submit(ChannelStateWriteRequest e) {\n+\t\t\t\tthrow new TestException();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void submitPriority(ChannelStateWriteRequest e) {\n+\t\t\t\tthrow new TestException();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic void start() throws IllegalStateException {\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate void runWithSyncWorker(Consumer<ChannelStateWriter> writerConsumer) throws Exception {\n+\t\trunWithSyncWorker((channelStateWriter, syncChannelStateWriterWorker) -> writerConsumer.accept(channelStateWriter));\n+\t}\n+\n+\tprivate void runWithSyncWorker(BiConsumerWithException<ChannelStateWriter, SyncChannelStateWriteRequestExecutor, Exception> testFn) throws Exception {\n+\t\ttry (\n+\t\t\t\tSyncChannelStateWriteRequestExecutor worker = new SyncChannelStateWriteRequestExecutor();", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNDY0Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405634642", "body": "seems unstable results? After `callAddInputData`, if the enqueued buffer is already dispatched to be executed by internal thread, then the buffer should be recycled when this assert calls. Although this probability is very small, but in theory it is not stable and easily fragile.  ", "bodyText": "seems unstable results? After callAddInputData, if the enqueued buffer is already dispatched to be executed by internal thread, then the buffer should be recycled when this assert calls. Although this probability is very small, but in theory it is not stable and easily fragile.", "bodyHTML": "<p dir=\"auto\">seems unstable results? After <code>callAddInputData</code>, if the enqueued buffer is already dispatched to be executed by internal thread, then the buffer should be recycled when this assert calls. Although this probability is very small, but in theory it is not stable and easily fragile.</p>", "author": "zhijiangW", "createdAt": "2020-04-08T15:58:43Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImplTest.java", "diffHunk": "@@ -0,0 +1,320 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.util.function.BiConsumerWithException;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.runtime.state.ChannelPersistenceITCase.getStreamFactoryFactory;\n+import static org.apache.flink.util.ExceptionUtils.findThrowable;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * {@link ChannelStateWriterImpl} lifecycle tests.\n+ */\n+public class ChannelStateWriterImplTest {\n+\tprivate static final long CHECKPOINT_ID = 42L;\n+\n+\t@Test(expected = IllegalArgumentException.class)\n+\tpublic void testAddEventBuffer() {\n+\t\tNetworkBuffer dataBuf = getBuffer();\n+\t\tNetworkBuffer eventBuf = getBuffer();\n+\t\teventBuf.tagAsEvent();\n+\t\tChannelStateWriterImpl writer = openWriter();\n+\t\tcallStart(writer);\n+\t\ttry {\n+\t\t\twriter.addInputData(CHECKPOINT_ID, new InputChannelInfo(1, 1), 1, eventBuf, dataBuf);\n+\t\t} finally {\n+\t\t\tassertTrue(dataBuf.isRecycled());\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testResultCompletion() throws IOException {\n+\t\tChannelStateWriteResult result;\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tresult = writer.getWriteResult(CHECKPOINT_ID);\n+\t\t\tassertFalse(result.resultSubpartitionStateHandles.isDone());\n+\t\t\tassertFalse(result.inputChannelStateHandles.isDone());\n+\t\t}\n+\t\tassertTrue(result.inputChannelStateHandles.isDone());\n+\t\tassertTrue(result.resultSubpartitionStateHandles.isDone());\n+\t}\n+\n+\t@Test\n+\tpublic void testAbort() throws Exception {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\trunWithSyncWorker((writer, worker) -> {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tcallAbort(writer);\n+\t\t\tworker.processAllRequests();\n+\t\t\tassertTrue(writer.getWriteResult(CHECKPOINT_ID).isDone());\n+\t\t\tassertTrue(buffer.isRecycled());\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testAbortIgnoresMissing() throws Exception {\n+\t\trunWithSyncWorker(this::callAbort);\n+\t}\n+\n+\t@Test(expected = TestException.class)\n+\tpublic void testBuffersRecycledOnError() throws Exception {\n+\t\tunwrappingError(TestException.class, () -> {\n+\t\t\tNetworkBuffer buffer = getBuffer();\n+\t\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(new ConcurrentHashMap<>(), failingWorker(), 5)) {\n+\t\t\t\twriter.open();\n+\t\t\t\tcallAddInputData(writer, buffer);\n+\t\t\t} finally {\n+\t\t\t\tassertTrue(buffer.isRecycled());\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\t@Test\n+\tpublic void testBuffersRecycledOnClose() throws IOException {\n+\t\tNetworkBuffer buffer = getBuffer();\n+\t\ttry (ChannelStateWriterImpl writer = openWriter()) {\n+\t\t\tcallStart(writer);\n+\t\t\tcallAddInputData(writer, buffer);\n+\t\t\tassertFalse(buffer.isRecycled());", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAxMDc5MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r406010791", "bodyText": "You're right, fixed it.", "author": "rkhachatryan", "createdAt": "2020-04-09T07:33:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTYzNDY0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY1NDgyMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405654821", "body": "unused method", "bodyText": "unused method", "bodyHTML": "<p dir=\"auto\">unused method</p>", "author": "zhijiangW", "createdAt": "2020-04-08T16:28:43Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/ChannelPersistenceITCase.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.state;\n+\n+import org.apache.flink.core.memory.HeapMemorySegment;\n+import org.apache.flink.core.memory.MemorySegment;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReaderImpl;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n+import org.apache.flink.runtime.checkpoint.channel.InputChannelInfo;\n+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;\n+import org.apache.flink.runtime.io.network.buffer.NetworkBuffer;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.memory.NonPersistentMetadataCheckpointStorageLocation;\n+import org.apache.flink.util.function.BiFunctionWithException;\n+\n+import org.junit.Test;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.SEQUENCE_NUMBER_UNKNOWN;\n+import static org.apache.flink.util.Preconditions.checkState;\n+import static org.junit.Assert.assertArrayEquals;\n+\n+/**\n+ * ChannelPersistenceITCase.\n+ */\n+public class ChannelPersistenceITCase {\n+\tprivate static final Random RANDOM = new Random(System.currentTimeMillis());\n+\n+\t@Test\n+\tpublic void testReadWritten() throws Exception {\n+\t\tlong checkpointId = 1L;\n+\n+\t\tInputChannelInfo inputChannelInfo = new InputChannelInfo(2, 3);\n+\t\tbyte[] inputChannelInfoData = randomBytes(1024);\n+\n+\t\tResultSubpartitionInfo resultSubpartitionInfo = new ResultSubpartitionInfo(4, 5);\n+\t\tbyte[] resultSubpartitionInfoData = randomBytes(1024);\n+\n+\t\tChannelStateWriteResult handles = write(\n+\t\t\tcheckpointId,\n+\t\t\tsingletonMap(inputChannelInfo, inputChannelInfoData),\n+\t\t\tsingletonMap(resultSubpartitionInfo, resultSubpartitionInfoData)\n+\t\t);\n+\n+\t\tassertArrayEquals(inputChannelInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tinputChannelInfoData.length,\n+\t\t\t(reader, mem) -> reader.readInputData(inputChannelInfo, new NetworkBuffer(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\n+\t\tassertArrayEquals(resultSubpartitionInfoData, read(\n+\t\t\ttoTaskStateSnapshot(handles),\n+\t\t\tresultSubpartitionInfoData.length,\n+\t\t\t(reader, mem) -> reader.readOutputData(resultSubpartitionInfo, new BufferBuilder(mem, FreeingBufferRecycler.INSTANCE))\n+\t\t));\n+\t}\n+\n+\tprivate byte[] randomBytes(int size) {\n+\t\tbyte[] bytes = new byte[size];\n+\t\tRANDOM.nextBytes(bytes);\n+\t\treturn bytes;\n+\t}\n+\n+\tprivate ChannelStateWriteResult write(long checkpointId, Map<InputChannelInfo, byte[]> icMap, Map<ResultSubpartitionInfo, byte[]> rsMap) throws Exception {\n+\t\tint maxStateSize = sizeOfBytes(icMap) + sizeOfBytes(rsMap) + Long.BYTES * 2;\n+\t\tMap<InputChannelInfo, Buffer> icBuffers = wrapWithBuffers(icMap);\n+\t\tMap<ResultSubpartitionInfo, Buffer> rsBuffers = wrapWithBuffers(rsMap);\n+\t\ttry (ChannelStateWriterImpl writer = new ChannelStateWriterImpl(getStreamFactoryFactory(maxStateSize))) {\n+\t\t\twriter.open();\n+\t\t\twriter.start(checkpointId, new CheckpointOptions(CHECKPOINT, new CheckpointStorageLocationReference(\"poly\".getBytes())));\n+\t\t\tfor (Map.Entry<InputChannelInfo, Buffer> e : icBuffers.entrySet()) {\n+\t\t\t\twriter.addInputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishInput(checkpointId);\n+\t\t\tfor (Map.Entry<ResultSubpartitionInfo, Buffer> e : rsBuffers.entrySet()) {\n+\t\t\t\twriter.addOutputData(checkpointId, e.getKey(), SEQUENCE_NUMBER_UNKNOWN, e.getValue());\n+\t\t\t}\n+\t\t\twriter.finishOutput(checkpointId);\n+\t\t\tChannelStateWriteResult result = writer.getWriteResult(checkpointId);\n+\t\t\tresult.getResultSubpartitionStateHandles().join(); // prevent abnormal complete in close\n+\t\t\treturn result;\n+\t\t}\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory() {\n+\t\treturn getStreamFactoryFactory(42);\n+\t}\n+\n+\tpublic static CheckpointStorageWorkerView getStreamFactoryFactory(int maxStateSize) {\n+\t\treturn new CheckpointStorageWorkerView() {\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\t\treturn new NonPersistentMetadataCheckpointStorageLocation(maxStateSize);\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream createTaskOwnedStateStream() {\n+\t\t\t\tthrow new UnsupportedOperationException();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tprivate byte[] read(TaskStateSnapshot taskStateSnapshot, int size, BiFunctionWithException<ChannelStateReader, MemorySegment, ReadResult, Exception> readFn) throws Exception {\n+\t\tbyte[] dst = new byte[size];\n+\t\tHeapMemorySegment mem = HeapMemorySegment.FACTORY.wrap(dst);\n+\t\ttry {\n+\t\t\tcheckState(NO_MORE_DATA == readFn.apply(new ChannelStateReaderImpl(taskStateSnapshot), mem));\n+\t\t} finally {\n+\t\t\tmem.free();\n+\t\t}\n+\t\treturn dst;\n+\t}\n+\n+\tprivate TaskStateSnapshot toTaskStateSnapshot(ChannelStateWriteResult t) throws Exception {\n+\t\treturn new TaskStateSnapshot(singletonMap(new OperatorID(),\n+\t\t\tnew OperatorSubtaskState(\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tStateObjectCollection.empty(),\n+\t\t\t\tnew StateObjectCollection<>(t.getInputChannelStateHandles().get()),\n+\t\t\t\tnew StateObjectCollection<>(t.getResultSubpartitionStateHandles().get())\n+\t\t\t)\n+\t\t));\n+\t}\n+\n+\tprivate <C> List<C> collect(Collection<StateObject> handles, Class<C> clazz) {", "originalCommit": "45d9acbac249340422dc39bc56ff3aeba49182aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "393d1c7c6cf588828fa53b4b0bc8f4ef35078625", "url": "https://github.com/apache/flink/commit/393d1c7c6cf588828fa53b4b0bc8f4ef35078625", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity", "committedDate": "2020-04-08T20:14:33Z", "type": "forcePushed"}, {"oid": "72c7b7dd1776d318c09beb6a16836dd7eeff74e8", "url": "https://github.com/apache/flink/commit/72c7b7dd1776d318c09beb6a16836dd7eeff74e8", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity", "committedDate": "2020-04-08T22:31:17Z", "type": "forcePushed"}, {"oid": "120e5440141b365c890ea402941ad5f74cebe08e", "url": "https://github.com/apache/flink/commit/120e5440141b365c890ea402941ad5f74cebe08e", "message": "[FLINK-16744][task][hotfix] Finalize StreamTask methods used during construction\n\nMotivation: prevent access to uninitialized descendant state from\nStreamTask constructor which otherwise leads to NPE", "committedDate": "2020-04-09T07:43:28Z", "type": "commit"}, {"oid": "51f87a7f28e67c5af1f2e500e4364957957fe591", "url": "https://github.com/apache/flink/commit/51f87a7f28e67c5af1f2e500e4364957957fe591", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity", "committedDate": "2020-04-09T07:43:29Z", "type": "forcePushed"}, {"oid": "5001eeaf884a9dea356c1fcbb936564c67764fc8", "url": "https://github.com/apache/flink/commit/5001eeaf884a9dea356c1fcbb936564c67764fc8", "message": "[FLINK-16744][task][refactor] Extract SubtaskCheckpointCoordinator\n\nMotivation:\n1. move checkpoint-related responsibilities out of StreamTask\n2. ability to cache checkpoint storage locations for unaligned checkpoints", "committedDate": "2020-04-09T18:37:24Z", "type": "commit"}, {"oid": "db44a10215580e6ad0dd28b769a8d8c3f2b409a3", "url": "https://github.com/apache/flink/commit/db44a10215580e6ad0dd28b769a8d8c3f2b409a3", "message": "[FLINK-16744][task] Send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint", "committedDate": "2020-04-09T18:37:24Z", "type": "commit"}, {"oid": "4ed4c52e78481c53e9c9348232a489430c3d6f2c", "url": "https://github.com/apache/flink/commit/4ed4c52e78481c53e9c9348232a489430c3d6f2c", "message": "[FLINK-16744][task][test][hotfix] Fix formatting\n\nRemove extra newline in TestTaskStateManager", "committedDate": "2020-04-09T18:37:24Z", "type": "commit"}, {"oid": "8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "url": "https://github.com/apache/flink/commit/8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity", "committedDate": "2020-04-09T18:37:24Z", "type": "commit"}, {"oid": "c3618403513b13e3941e199e0fddb335131a8f35", "url": "https://github.com/apache/flink/commit/c3618403513b13e3941e199e0fddb335131a8f35", "message": "[FLINK-16744][task] Split finish() in ChannelStateWriter\n\nSplit finish() in ChannelStateWriter into finishIn and finishOut to ease client usage", "committedDate": "2020-04-09T18:37:38Z", "type": "commit"}, {"oid": "a5b7e1f68058e8342ef20f068b33192f65cdefd4", "url": "https://github.com/apache/flink/commit/a5b7e1f68058e8342ef20f068b33192f65cdefd4", "message": "[FLINK-16744][task] Implement channel state reading and writing for unaligned checkpoints", "committedDate": "2020-04-09T18:37:24Z", "type": "commit"}, {"oid": "8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "url": "https://github.com/apache/flink/commit/8492dd04cdb1712069f6d1c1abf39acbae60aaa2", "message": "[FLINK-16744][task][hotfix] Refactor SubtaskCheckpointCoordinatorImpl\n\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity", "committedDate": "2020-04-09T18:37:24Z", "type": "forcePushed"}, {"oid": "22e12ad32ac71e45f7c40fd08ad0cc4498664613", "url": "https://github.com/apache/flink/commit/22e12ad32ac71e45f7c40fd08ad0cc4498664613", "message": "[FLINK-16744][task] send channel state handles to JM\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint", "committedDate": "2020-03-25T23:06:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r398400971", "body": "Could we avoid this class by binding the life-cycle of a `FSDataInputStream` to `ChannelStateReaderImpl` instead of `ChannelStateStreamReader`. Then only `ChannelStateReader#close` would close the input stream and we don't need to keep track. ", "bodyText": "Could we avoid this class by binding the life-cycle of a FSDataInputStream to ChannelStateReaderImpl instead of ChannelStateStreamReader. Then only ChannelStateReader#close would close the input stream and we don't need to keep track.", "bodyHTML": "<p dir=\"auto\">Could we avoid this class by binding the life-cycle of a <code>FSDataInputStream</code> to <code>ChannelStateReaderImpl</code> instead of <code>ChannelStateStreamReader</code>. Then only <code>ChannelStateReader#close</code> would close the input stream and we don't need to keep track.</p>", "author": "AHeise", "createdAt": "2020-03-26T08:45:28Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {", "originalCommit": "5f5ca2f608caeb6d87a0697aca5da75880a1b844", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0MTc3NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r399141774", "bodyText": "Having FSDataInputStreams managed by ChannelStateReaderImpl is simpler but have these drawbacks:\n\nclients should coordinate their calls to close() (these are for or in and out channels); even if possible, I don't think it worth to couple them together\n(slight) increase of ChannelStateReaderImpl complexity", "author": "rkhachatryan", "createdAt": "2020-03-27T09:40:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk1MTI4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400951284", "bodyText": "I'm also fine with either way. Just wanted to point out how we could avoid some code.", "author": "AHeise", "createdAt": "2020-03-31T14:19:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMDk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r398402875", "body": "\ud83d\udc4d for pulling that out. Should it actually be `TaskCheckpointCoordinator` since it's bound to a `StreamTask`? Or do you consider `StreamTask` to be a misnomer that should be `StreamSubtask` (not proposing to change that, just want to understand the rational)?", "bodyText": "\ud83d\udc4d for pulling that out. Should it actually be TaskCheckpointCoordinator since it's bound to a StreamTask? Or do you consider StreamTask to be a misnomer that should be StreamSubtask (not proposing to change that, just want to understand the rational)?", "bodyHTML": "<p dir=\"auto\"><g-emoji class=\"g-emoji\" alias=\"+1\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png\">\ud83d\udc4d</g-emoji> for pulling that out. Should it actually be <code>TaskCheckpointCoordinator</code> since it's bound to a <code>StreamTask</code>? Or do you consider <code>StreamTask</code> to be a misnomer that should be <code>StreamSubtask</code> (not proposing to change that, just want to understand the rational)?</p>", "author": "AHeise", "createdAt": "2020-03-26T08:48:53Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a task. Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {", "originalCommit": "8f0c3d0c6c3fd55bf7b417c11de319b863fbe6c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0NzI2OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r399147269", "bodyText": "Yes, I think both Task and StreamTask are named inconsistently with higher-level terminology, where we have Tasks with their Subtasks.\nI'm not sure which should be changed though or which one should be used here :)\nThanks.", "author": "rkhachatryan", "createdAt": "2020-03-27T09:50:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEyMjMwNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400122305", "bodyText": "Okay makes sense. Maybe add comment/documentation that this corresponds to StreamTask?", "author": "AHeise", "createdAt": "2020-03-30T11:35:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwMjg3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r398409092", "body": "Probably needs some reference counting here after splitting finish into finishInput and finishOutput.", "bodyText": "Probably needs some reference counting here after splitting finish into finishInput and finishOutput.", "bodyHTML": "<p dir=\"auto\">Probably needs some reference counting here after splitting finish into finishInput and finishOutput.</p>", "author": "AHeise", "createdAt": "2020-03-26T08:59:08Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessHandoverLoop implements Runnable {\n+\t\tprivate final Map<Long, ChannelStateWriteTask> tasks = new HashMap<>(maxCheckpoints);\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\tcleanup(thrown);\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\tprocessItem(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tprivate void processItem(ChannelStateWriteItem item) throws Exception {\n+\t\t\tif (item instanceof StartCheckpointItem) {\n+\t\t\t\ttasks.put(item.checkpointId, new ChannelStateWriteTask((StartCheckpointItem) item, streamFactory, serializer)); // tasks is limited indirectly by results max size\n+\t\t\t} else if (item instanceof InputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((InputDataItem) item);\n+\t\t\t} else if (item instanceof OutputDataItem) {\n+\t\t\t\ttasks.get(item.checkpointId).write((OutputDataItem) item);\n+\t\t\t} else if (item instanceof FinishInputCheckpointItem) {\n+\t\t\t\ttasks.get(item.checkpointId).completeInput(() -> tasks.remove(item.checkpointId));", "originalCommit": "5f5ca2f608caeb6d87a0697aca5da75880a1b844", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE1MDI4MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r399150280", "bodyText": "finishIn/Out split is handled by having inputCompleted and outputCompleted fields inside ChannelStateWriteTask.\nDo you think it's not enough and we need to add ref counters?", "author": "rkhachatryan", "createdAt": "2020-03-27T09:55:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMyMTUxOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r399321518", "bodyText": "I meant that you are removing the task from tasks on the first of FinishInput/OutputItem and you probably will miss it if the other half is not finished.", "author": "AHeise", "createdAt": "2020-03-27T14:51:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUzNTM1OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r399535359", "bodyText": "Got it. No, this is a runnable which is executed only when both input and output are finished.\nAs it confuses not only me :) I'll change it a bit:\n\nmake Runnable onComplete field in WriteTask (pass it to constructor)\ncompleteInput / Output won't have any arguments\n\nWDYT?", "author": "rkhachatryan", "createdAt": "2020-03-27T21:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEyMzA2OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400123068", "bodyText": "Sounds good to me.", "author": "AHeise", "createdAt": "2020-03-30T11:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwOTA5Mg=="}], "type": "inlineReview"}, {"oid": "8665adbc70e1591e8729b9434f522892860e633b", "url": "https://github.com/apache/flink/commit/8665adbc70e1591e8729b9434f522892860e633b", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint", "committedDate": "2020-03-29T21:25:12Z", "type": "forcePushed"}, {"oid": "d3a26446f1c9d62e2572fa440accf95cb2d8596f", "url": "https://github.com/apache/flink/commit/d3a26446f1c9d62e2572fa440accf95cb2d8596f", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint", "committedDate": "2020-03-30T09:43:00Z", "type": "forcePushed"}, {"oid": "85c5d0044d8c8c53abc57e4e24383505462a48ae", "url": "https://github.com/apache/flink/commit/85c5d0044d8c8c53abc57e4e24383505462a48ae", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint", "committedDate": "2020-03-30T19:32:17Z", "type": "forcePushed"}, {"oid": "da674cafad1c62dde92588b94b8d44ab699b8280", "url": "https://github.com/apache/flink/commit/da674cafad1c62dde92588b94b8d44ab699b8280", "message": "[FLINK-16744][task] send channel state handles to JM\n\n1. add channel state writer to SubtaskCheckpointCoordinator\n2. add handles to the reported snapshot\n3. cache checkpoint locations to prevent multiple streams\nper checkpoint. With unaligned checkpoints, checkpoint\ncan be initiated from several places which can result\n(without cache) in multiple streams/files for a single\ncheckpoint", "committedDate": "2020-03-30T21:35:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMDM1NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400930355", "body": "why is this line still necessary?", "bodyText": "why is this line still necessary?", "bodyHTML": "<p dir=\"auto\">why is this line still necessary?</p>", "author": "AHeise", "createdAt": "2020-03-31T13:52:08Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());", "originalCommit": "05c60654476141e8c0cb224d725cea99c85e7b15", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc1NDcxNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401754717", "bodyText": "Removing mockito here (addressed the comment below).", "author": "rkhachatryan", "createdAt": "2020-04-01T16:39:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMDM1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzMTMwOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400931309", "body": "Couldn't you just override the method on the `MockableStreamTask` to get rid of mockito?", "bodyText": "Couldn't you just override the method on the MockableStreamTask to get rid of mockito?", "bodyHTML": "<p dir=\"auto\">Couldn't you just override the method on the <code>MockableStreamTask</code> to get rid of mockito?</p>", "author": "AHeise", "createdAt": "2020-03-31T13:53:20Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);\n \t\t\t\tEnvironment env = mock(Environment.class);\n-\t\t\t\twhen(task.getEnvironment()).thenReturn(env);\n+\t\t\t\twhen(task.getEnvironment()).thenReturn(new MockEnvironmentBuilder().build());\n \t\t\t\twhen(env.getMemoryManager()).thenReturn(memoryManager);", "originalCommit": "05c60654476141e8c0cb224d725cea99c85e7b15", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNDE1Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400934156", "body": "nit: indent", "bodyText": "nit: indent", "bodyHTML": "<p dir=\"auto\">nit: indent</p>", "author": "AHeise", "createdAt": "2020-03-31T13:56:47Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n+\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final String taskName;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\tprivate final ExecutorService executorService;\n+\tprivate final Environment env;\n+\tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\n+\tSubtaskCheckpointCoordinatorImpl(\n+\t\tCheckpointStorageWorkerView checkpointStorage,", "originalCommit": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNDYzOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400934639", "body": "nit: indent", "bodyText": "nit: indent", "bodyHTML": "<p dir=\"auto\">nit: indent</p>", "author": "AHeise", "createdAt": "2020-03-31T13:57:24Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,", "originalCommit": "ae7bd9f04b94f8c4810b3321df7729b11affeee4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzNTM1Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400935357", "body": "nit: indent", "bodyText": "nit: indent", "bodyHTML": "<p dir=\"auto\">nit: indent</p>", "author": "AHeise", "createdAt": "2020-03-31T13:58:19Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\tCompletableFuture<Collection<H>> future,", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400939338", "body": "Is that method used in later commits? Seems unused except in the implementor.", "bodyText": "Is that method used in later commits? Seems unused except in the implementor.", "bodyHTML": "<p dir=\"auto\">Is that method used in later commits? Seems unused except in the implementor.</p>", "author": "AHeise", "createdAt": "2020-03-31T14:03:37Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc2MTMwNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401761307", "bodyText": "Yes, it is used, in the same commit (probably, I've reordered changes in the last update).", "author": "rkhachatryan", "createdAt": "2020-04-01T16:49:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMDgyNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402400824", "bodyText": "I guess we can remove this explicit method actually, because it is only used inside `#wrap() method and would not be called by outsides.  See dad865f#r402400614", "author": "zhijiangW", "createdAt": "2020-04-02T15:23:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjg0NTQ1Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402845457", "bodyText": "Removed it, thanks.", "author": "rkhachatryan", "createdAt": "2020-04-03T08:45:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDkzOTMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NDM2OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400944368", "body": "looks okay. anything particular to check?", "bodyText": "looks okay. anything particular to check?", "bodyHTML": "<p dir=\"auto\">looks okay. anything particular to check?</p>", "author": "AHeise", "createdAt": "2020-03-31T14:10:10Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc2NDkxMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401764913", "bodyText": "I wanted to make sure that it's not required to update reader index here.", "author": "rkhachatryan", "createdAt": "2020-04-01T16:54:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NDM2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400945812", "body": "Could we avoid creating the DIS adhoc? You need to read header anyways, so why not always create a DIS and pass it everywhere?", "bodyText": "Could we avoid creating the DIS adhoc? You need to read header anyways, so why not always create a DIS and pass it everywhere?", "bodyHTML": "<p dir=\"auto\">Could we avoid creating the DIS adhoc? You need to read header anyways, so why not always create a DIS and pass it everywhere?</p>", "author": "AHeise", "createdAt": "2020-03-31T14:12:10Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn written < bytes.length;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bytes.length - written;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn input.read(bytes, written, writableBytes());\n+\t\t\t}\n+\t\t};\n+\t}\n+}\n+\n+class ChannelStateSerializerImpl implements ChannelStateSerializer, ChannelStateDeserializer {\n+\tprivate static final int LEN_SIZE = Integer.BYTES;\n+\tprivate static final int SERIALIZATION_VERSION = 0;\n+\n+\t@Override\n+\tpublic void writeHeader(DataOutputStream dataStream) throws IOException {\n+\t\tdataStream.writeInt(SERIALIZATION_VERSION);\n+\t}\n+\n+\t@Override\n+\tpublic void writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException {\n+\t\tstream.writeInt(getSize(flinkBuffers));\n+\t\tfor (Buffer buffer : flinkBuffers) {\n+\t\t\tByteBuf nettyByteBuf = buffer.asByteBuf();\n+\t\t\tnettyByteBuf.getBytes(nettyByteBuf.readerIndex(), stream, nettyByteBuf.readableBytes()); // todo: review me\n+\t\t}\n+\t}\n+\n+\tprivate int getSize(Buffer[] buffers) {\n+\t\tint len = 0;\n+\t\tfor (Buffer buffer : buffers) {\n+\t\t\tlen = addExact(len, buffer.readableBytes());\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t@Override\n+\tpublic void readHeader(InputStream stream) throws IOException {\n+\t\tint version = readInt(stream);\n+\t\tPreconditions.checkArgument(version == SERIALIZATION_VERSION, \"unsupported version: \" + version);\n+\t}\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\t@Override\n+\tpublic Tuple2<Integer, Integer> readLength(InputStream stream) throws IOException {\n+\t\tint len = readInt(stream);\n+\t\tPreconditions.checkArgument(len >= 0, \"negative state size\");\n+\t\treturn Tuple2.of(len, LEN_SIZE);\n+\t}\n+\n+\t@Override\n+\tpublic int readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException {\n+\t\treturn buffer.writeBytes(stream, bytes);\n+\t}\n+\n+\tprivate static int readInt(InputStream stream) throws IOException {\n+\t\treturn new DataInputStream(stream).readInt();", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc3Mjg1NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401772855", "bodyText": "It's doesn't do anything except creating this object and this object doesn't escape the method. So I don't think there is any performance issue here (given this is IO on recovery).\nAlternatively, I'd just replicate DataInputStream.readInt logic.\nI'd like to avoid an extra field just to get readInt method.\nWDYT?", "author": "rkhachatryan", "createdAt": "2020-04-01T17:06:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjkwNDQ5OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402904498", "bodyText": "I was more thinking to always wrap InputStream in DIS and change the signatures accordingly. Then it would be the same number of fields.\nIf that is not doable, then please leave as is, don't have a custom readInt.", "author": "AHeise", "createdAt": "2020-04-03T10:17:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NTgxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0NjkxNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400946915", "body": "Not a big fan of leaving inspection settings in code. If everyone does it with different IDEs/settings, it will become quickly a mess.", "bodyText": "Not a big fan of leaving inspection settings in code. If everyone does it with different IDEs/settings, it will become quickly a mess.", "bodyHTML": "<p dir=\"auto\">Not a big fan of leaving inspection settings in code. If everyone does it with different IDEs/settings, it will become quickly a mess.</p>", "author": "AHeise", "createdAt": "2020-03-31T14:13:34Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {\n+\t\t\t\tadvanceOffset();\n+\t\t\t}\n+\t\t\tint bytesRead = serializer.readData(stream, buffer, rem);\n+\t\t\trem -= bytesRead;\n+\t\t\tpos = addExact(pos, bytesRead);\n+\t\t}\n+\t}\n+\n+\tprivate boolean haveMoreData() {\n+\t\treturn rem > 0 || !offsets.isEmpty();\n+\t}\n+\n+\tprivate void advanceOffset() throws IOException {\n+\t\t//noinspection ConstantConditions", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0ODMzNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400948335", "body": "Add a factory for start for symmetry? Or move the factories to `InProgress`?", "bodyText": "Add a factory for start for symmetry? Or move the factories to InProgress?", "bodyHTML": "<p dir=\"auto\">Add a factory for start for symmetry? Or move the factories to <code>InProgress</code>?</p>", "author": "AHeise", "createdAt": "2020-03-31T14:15:25Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk0OTg4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400949884", "body": "Rename to `fail`?", "bodyText": "Rename to fail?", "bodyHTML": "<p dir=\"auto\">Rename to <code>fail</code>?</p>", "author": "AHeise", "createdAt": "2020-03-31T14:17:25Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid processRequest(ChannelStateWriteRequest request) throws Exception {\n+\t\tLOG.debug(\"process {}\", request);\n+\t\tif (request instanceof CheckpointStartRequest) {\n+\t\t\tPreconditions.checkState(!writers.containsKey(request.checkpointId));\n+\t\t\twriters.put(request.checkpointId, buildWriter((CheckpointStartRequest) request));\n+\t\t} else if (request instanceof CheckpointInProgressRequest) {\n+\t\t\tPreconditions.checkState(writers.containsKey(request.checkpointId), \"writer not found for checkpoint id \" + request.checkpointId);\n+\t\t\twriters.get(request.checkpointId).process((CheckpointInProgressRequest) request);\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"unknown request type: \" + request);\n+\t\t}\n+\t}\n+\n+\tprivate ChannelStateCheckpointWriter buildWriter(CheckpointStartRequest request) throws Exception {\n+\t\treturn new ChannelStateCheckpointWriter(\n+\t\t\trequest,\n+\t\t\tstreamFactoryFactory.resolveCheckpointStorageLocation(request.checkpointId, request.locationReference),\n+\t\t\tserializer,\n+\t\t\t() -> writers.remove(request.checkpointId));\n+\t}\n+\n+\tvoid cleanup(Throwable e) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODAzOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400968039", "body": "nit: space", "bodyText": "nit: space", "bodyHTML": "<p dir=\"auto\">nit: space</p>", "author": "AHeise", "createdAt": "2020-03-31T14:40:25Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -1057,7 +1062,7 @@ else if (current == ExecutionState.RUNNING) {\n \t\t\t\t\t\t// case the canceling could not continue\n \n \t\t\t\t\t\t// The canceller calls cancel and interrupts the executing thread once\n-\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this :: closeNetworkResources, invokable, executingThread, taskNameWithSubtask);\n+\t\t\t\t\t\tRunnable canceler = new TaskCanceler(LOG, this ::closeResources, invokable, executingThread, taskNameWithSubtask);", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400968509", "body": "move to subtask commit", "bodyText": "move to subtask commit", "bodyHTML": "<p dir=\"auto\">move to subtask commit</p>", "author": "AHeise", "createdAt": "2020-03-31T14:40:59Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc3OTIwNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401779207", "bodyText": "Can you please explain what do you mean?", "author": "rkhachatryan", "createdAt": "2020-04-01T17:16:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUxODQ1Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402518452", "bodyText": "These lines fix what has been added to a previous commit, where you added subtask. So squash the hunk into that commit.", "author": "AHeise", "createdAt": "2020-04-02T18:18:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODUwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2OTg5NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400969895", "body": "Also cleared on abort?", "bodyText": "Also cleared on abort?", "bodyHTML": "<p dir=\"auto\">Also cleared on abort?</p>", "author": "AHeise", "createdAt": "2020-03-31T14:42:44Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc4MTU4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401781584", "bodyText": "Good point!", "author": "rkhachatryan", "createdAt": "2020-04-01T17:20:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2OTg5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk3MjU4Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r400972586", "body": "weird format.", "bodyText": "weird format.", "bodyHTML": "<p dir=\"auto\">weird format.</p>", "author": "AHeise", "createdAt": "2020-03-31T14:46:05Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTU5MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401339591", "body": "I did not get the point why we need this change and it seems unrelated to this PR. If the motivation is for avoiding stuck long time during `await()`, but it already has `timeoutPerTest` for ending the test after timeout.\r\n\r\nIf we want to refactor some previous tests, it should be a `hotfix` commit if minor and give some descriptions in commit message for better understanding the motivation.", "bodyText": "I did not get the point why we need this change and it seems unrelated to this PR. If the motivation is for avoiding stuck long time during await(), but it already has timeoutPerTest for ending the test after timeout.\nIf we want to refactor some previous tests, it should be a hotfix commit if minor and give some descriptions in commit message for better understanding the motivation.", "bodyHTML": "<p dir=\"auto\">I did not get the point why we need this change and it seems unrelated to this PR. If the motivation is for avoiding stuck long time during <code>await()</code>, but it already has <code>timeoutPerTest</code> for ending the test after timeout.</p>\n<p dir=\"auto\">If we want to refactor some previous tests, it should be a <code>hotfix</code> commit if minor and give some descriptions in commit message for better understanding the motivation.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T03:45:44Z", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -82,7 +84,7 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\tfinal Thread executionThread = srcTaskTestHarness.invoke();\n \t\tfinal StreamTask<Long, ?> srcTask = srcTaskTestHarness.getTask();\n \n-\t\tready.await();\n+\t\twaitForLatchSetByTask(ready, srcTaskTestHarness);", "originalCommit": "86d660018a3166d1cbab1e70619004d352b2bffc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTc5NTU1Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401795556", "bodyText": "At some point, this test was failing with a timeout\nbut It was unclear why do I get this timeout.\nI'll update the commit message to includehotfix and motivation.\nRemoving the commit as it seems not necessary now.", "author": "rkhachatryan", "createdAt": "2020-04-01T17:43:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTU5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MjAxNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401342017", "body": "I guess we can merge the following `while` and `if` logics into this `while` to avoid judging `srcTask.isRunning()` three times separately, and make the logics more close with each other.", "bodyText": "I guess we can merge the following while and if logics into this while to avoid judging srcTask.isRunning() three times separately, and make the logics more close with each other.", "bodyHTML": "<p dir=\"auto\">I guess we can merge the following <code>while</code> and <code>if</code> logics into this <code>while</code> to avoid judging <code>srcTask.isRunning()</code> three times separately, and make the logics more close with each other.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T03:56:16Z", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/SourceTaskTerminationTest.java", "diffHunk": "@@ -122,6 +124,26 @@ private void stopWithSavepointStreamTaskTestHelper(final boolean withMaxWatermar\n \t\texecutionThread.join();\n \t}\n \n+\tprivate void waitForLatchSetByTask(OneShotLatch latch, StreamTaskTestHarness<?> srcTaskTestHarness) throws Exception {\n+\t\tfinal StreamTask<?, ?> srcTask = srcTaskTestHarness.getTask();\n+\t\tfinal Thread executionThread = srcTaskTestHarness.taskThread;\n+\t\twhile (executionThread.isAlive() && srcTask.isRunning()) {", "originalCommit": "86d660018a3166d1cbab1e70619004d352b2bffc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401343534", "body": "nit: unrelated change for this commit motivation", "bodyText": "nit: unrelated change for this commit motivation", "bodyHTML": "<p dir=\"auto\">nit: unrelated change for this commit motivation</p>", "author": "zhijiangW", "createdAt": "2020-04-01T04:03:03Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java", "diffHunk": "@@ -335,7 +335,7 @@ public void acknowledgeCheckpoint(long checkpointId, CheckpointMetrics checkpoin\n \n \t@Override\n \tpublic void declineCheckpoint(long checkpointId, Throwable cause) {\n-\t\tthrow new UnsupportedOperationException();\n+\t\tthrow new UnsupportedOperationException(cause);", "originalCommit": "05c60654476141e8c0cb224d725cea99c85e7b15", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzMTc4Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401831783", "bodyText": "Agree, but I don't think this change deserves its own commit.", "author": "rkhachatryan", "createdAt": "2020-04-01T18:44:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQzMDk5Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402430996", "bodyText": "Based on my experience, any unrelated tiny changes should be submitted as hotfix commit instead, such as typo, indentation formatting, etc.\nBut I guess there are no explicit guidelines for it, so feel free to do it or not.", "author": "zhijiangW", "createdAt": "2020-04-02T16:05:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzUzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0MzkyMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401343922", "body": "nit: unrelated change", "bodyText": "nit: unrelated change", "bodyHTML": "<p dir=\"auto\">nit: unrelated change</p>", "author": "zhijiangW", "createdAt": "2020-04-01T04:04:30Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -64,7 +66,6 @@\n  * Test for {@link BufferDataOverWindowOperator}.\n  */\n public class BufferDataOverWindowOperatorTest {\n-", "originalCommit": "05c60654476141e8c0cb224d725cea99c85e7b15", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0NTU0Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401345542", "body": "TBH i did not get the point why this class change is related to the commit motivation. \r\nIf it is necessary, can we use `MockStreamTaskBuilder` to build `MockStreamTask` instead, to avoid construct `MockableStreamTask`. Besides that, it is not suggested to use `mock` in unit tests.", "bodyText": "TBH i did not get the point why this class change is related to the commit motivation.\nIf it is necessary, can we use MockStreamTaskBuilder to build MockStreamTask instead, to avoid construct MockableStreamTask. Besides that, it is not suggested to use mock in unit tests.", "bodyHTML": "<p dir=\"auto\">TBH i did not get the point why this class change is related to the commit motivation.<br>\nIf it is necessary, can we use <code>MockStreamTaskBuilder</code> to build <code>MockStreamTask</code> instead, to avoid construct <code>MockableStreamTask</code>. Besides that, it is not suggested to use <code>mock</code> in unit tests.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T04:11:24Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -205,9 +206,19 @@ public StreamConfig getOperatorConfig() {\n \n \t\t\t@Override\n \t\t\tpublic StreamTask<?, ?> getContainingTask() {\n-\t\t\t\tStreamTask task = mock(StreamTask.class);\n+\t\t\t\tclass MockableStreamTask extends StreamTask<Object, StreamOperator<Object>> implements EnvironmentSupport {\n+\t\t\t\t\tMockableStreamTask() throws Exception {\n+\t\t\t\t\t\tsuper(new MockEnvironmentBuilder().build());\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tprotected void init() {\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\tStreamTask<?, ?> task = mock(MockableStreamTask.class);", "originalCommit": "05c60654476141e8c0cb224d725cea99c85e7b15", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzNzg2OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401837869", "bodyText": "After making final some methods of StreamTask this test broke because mockito wasn't able now to override them.\nEventually, I removed mockito from here.", "author": "rkhachatryan", "createdAt": "2020-04-01T18:54:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0NTU0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401349817", "body": "I guess the motivation for defining `final` for related parent methods is from constructing `SubtaskCheckpointCoordinatorImpl` in `StreamTask` constructor. If so, we need also define final for `AbstractInvokable#getEnvironment` because it is also accessed while constructing `SubtaskCheckpointCoordinatorImpl`.\r\n\r\nActually we can avoid using getter while constructing `SubtaskCheckpointCoordinatorImpl` to use specific arguments instead. Anyway i think it is meaningful to define `final` for some methods if we confirm they should not be override by subclasses. But the requirement should not be from constructing `SubtaskCheckpointCoordinatorImpl`, and we should review all the methods in `AbstractInvokable` and `StreamTask` to make this thing completely. ", "bodyText": "I guess the motivation for defining final for related parent methods is from constructing SubtaskCheckpointCoordinatorImpl in StreamTask constructor. If so, we need also define final for AbstractInvokable#getEnvironment because it is also accessed while constructing SubtaskCheckpointCoordinatorImpl.\nActually we can avoid using getter while constructing SubtaskCheckpointCoordinatorImpl to use specific arguments instead. Anyway i think it is meaningful to define final for some methods if we confirm they should not be override by subclasses. But the requirement should not be from constructing SubtaskCheckpointCoordinatorImpl, and we should review all the methods in AbstractInvokable and StreamTask to make this thing completely.", "bodyHTML": "<p dir=\"auto\">I guess the motivation for defining <code>final</code> for related parent methods is from constructing <code>SubtaskCheckpointCoordinatorImpl</code> in <code>StreamTask</code> constructor. If so, we need also define final for <code>AbstractInvokable#getEnvironment</code> because it is also accessed while constructing <code>SubtaskCheckpointCoordinatorImpl</code>.</p>\n<p dir=\"auto\">Actually we can avoid using getter while constructing <code>SubtaskCheckpointCoordinatorImpl</code> to use specific arguments instead. Anyway i think it is meaningful to define <code>final</code> for some methods if we confirm they should not be override by subclasses. But the requirement should not be from constructing <code>SubtaskCheckpointCoordinatorImpl</code>, and we should review all the methods in <code>AbstractInvokable</code> and <code>StreamTask</code> to make this thing completely.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T04:30:10Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -651,7 +651,7 @@ boolean isSerializingTimestamps() {\n \t * Gets the name of the task, in the form \"taskname (2/5)\".\n \t * @return The name of the task.\n \t */\n-\tpublic String getName() {\n+\tpublic final String getName() {", "originalCommit": "05c60654476141e8c0cb224d725cea99c85e7b15", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0Njg0MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401846841", "bodyText": "Right, the motivation is the use of this method in constructor.\nThanks for pointing out about getEnvironment (it was modified made final too but then reverted accidentally while fixing tests).\nI did consider the alternative of using specific values in constructor, but then we can get inconsistency between values used in constructor with ones in getters. So using getters here and declaring them final I think is a lesser evil.\nRegarding the contract of AbstractInvokable and StreamTask, I don't think these methods are extension points (as opposed to processInput for example), and therefore shouldn't be overridden.", "author": "rkhachatryan", "createdAt": "2020-04-01T19:10:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4MjI0Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403482247", "bodyText": "Yes, i agree with your consideration for inconsistency between values used in constructor with ones in getters.\nRegarding the AbstractInvokable and StreamTask, you misunderstood my previous comment. I mean that there might still have other methods inside parent AbstractInvokable and StreamTask,  which should not be overridden by subclasses, so it should also be defined as final as you already did in this PR. Now we only consider the requirements from SubtaskCheckpointCoordinatorImpl to handle the related methods. But from a more general motivation, we might need to go through all the necessary methods to limit them as final to make this story complete. But it is up to you whether to touch more things in this PR.", "author": "zhijiangW", "createdAt": "2020-04-04T15:26:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM0OTgxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MjA5NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401352094", "body": "nit: we can get `environment` directly from argument instead of `getEnvironment()`, also for `getAsyncOperationsThreadPool()`", "bodyText": "nit: we can get environment directly from argument instead of getEnvironment(), also for getAsyncOperationsThreadPool()", "bodyHTML": "<p dir=\"auto\">nit: we can get <code>environment</code> directly from argument instead of <code>getEnvironment()</code>, also for <code>getAsyncOperationsThreadPool()</code></p>", "author": "zhijiangW", "createdAt": "2020-04-01T04:40:10Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -271,7 +269,14 @@ protected StreamTask(\n \t\t\tnew ExecutorThreadFactory(\"AsyncOperations\", uncaughtExceptionHandler));\n \n \t\tthis.stateBackend = createStateBackend();\n-\t\tthis.checkpointStorage = stateBackend.createCheckpointStorage(getEnvironment().getJobID());\n+\n+\t\tthis.subtaskCheckpointCoordinator = new SubtaskCheckpointCoordinatorImpl(\n+\t\t\tstateBackend.createCheckpointStorage(getEnvironment().getJobID()),", "originalCommit": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0NzM4Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401847382", "bodyText": "replied in the comment above\n(this would bring inconsistency with values from getters)", "author": "rkhachatryan", "createdAt": "2020-04-01T19:11:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MjA5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1MzA1MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401353051", "body": "nit: split the arguments into every line, seem too long.", "bodyText": "nit: split the arguments into every line, seem too long.", "bodyHTML": "<p dir=\"auto\">nit: split the arguments into every line, seem too long.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T04:44:28Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java", "diffHunk": "@@ -772,38 +777,18 @@ private boolean performCheckpoint(\n \t\tLOG.debug(\"Starting checkpoint ({}) {} on task {}\",\n \t\t\tcheckpointMetaData.getCheckpointId(), checkpointOptions.getCheckpointType(), getName());\n \n-\t\tfinal long checkpointId = checkpointMetaData.getCheckpointId();\n-\n \t\tif (isRunning) {\n \t\t\tactionExecutor.runThrowing(() -> {\n \n \t\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n-\t\t\t\t\tsetSynchronousSavepointId(checkpointId);\n+\t\t\t\t\tsetSynchronousSavepointId(checkpointMetaData.getCheckpointId());\n \n \t\t\t\t\tif (advanceToEndOfTime) {\n \t\t\t\t\t\tadvanceToEndOfEventTime();\n \t\t\t\t\t}\n \t\t\t\t}\n \n-\t\t\t\t// All of the following steps happen as an atomic step from the perspective of barriers and\n-\t\t\t\t// records/watermarks/timers/callbacks.\n-\t\t\t\t// We generally try to emit the checkpoint barrier as soon as possible to not affect downstream\n-\t\t\t\t// checkpoint alignments\n-\n-\t\t\t\t// Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.\n-\t\t\t\t//           The pre-barrier work should be nothing or minimal in the common case.\n-\t\t\t\toperatorChain.prepareSnapshotPreBarrier(checkpointId);\n-\n-\t\t\t\t// Step (2): Send the checkpoint barrier downstream\n-\t\t\t\toperatorChain.broadcastCheckpointBarrier(\n-\t\t\t\t\t\tcheckpointId,\n-\t\t\t\t\t\tcheckpointMetaData.getTimestamp(),\n-\t\t\t\t\t\tcheckpointOptions);\n-\n-\t\t\t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n-\t\t\t\t//           impact progress of the streaming topology\n-\t\t\t\tcheckpointState(checkpointMetaData, checkpointOptions, checkpointMetrics);\n-\n+\t\t\t\tsubtaskCheckpointCoordinator.checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics, operatorChain, this::isCanceled);", "originalCommit": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTMwMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401359301", "body": "I do not find any usages in this PR. Do you expect which component might use this getter future?", "bodyText": "I do not find any usages in this PR. Do you expect which component might use this getter future?", "bodyHTML": "<p dir=\"auto\">I do not find any usages in this PR. Do you expect which component might use this getter future?</p>", "author": "zhijiangW", "createdAt": "2020-04-01T05:11:23Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinator.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+\n+import java.util.function.Supplier;\n+\n+/**\n+ * Coordinates checkpointing-related work for a subtask (i.e. {@link org.apache.flink.runtime.taskmanager.Task Task} and\n+ * {@link StreamTask}). Responsibilities:\n+ * <ol>\n+ * <li>build a snapshot (invokable)</li>\n+ * <li>report snapshot to the JobManager</li>\n+ * <li>maintain storage locations</li>\n+ * </ol>\n+ */\n+@Internal\n+interface SubtaskCheckpointCoordinator {\n+\n+\tChannelStateWriter getChannelStateWriter();", "originalCommit": "c3387596c1f3e4ed6e6cbeb586cefb59bc9f2e67", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg0OTc1Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401849753", "bodyText": "Yes, this is supposed to be used to \"spill\" buffers while checkpointing in Unaligned mode (#11507).", "author": "rkhachatryan", "createdAt": "2020-04-01T19:15:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTMwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM1OTk5Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401359992", "body": "nit: better to extract a separate method for the following operation, otherwise this method seems too long for not easy tracing the steps.", "bodyText": "nit: better to extract a separate method for the following operation, otherwise this method seems too long for not easy tracing the steps.", "bodyHTML": "<p dir=\"auto\">nit: better to extract a separate method for the following operation, otherwise this method seems too long for not easy tracing the steps.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T05:14:10Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();", "originalCommit": "ae7bd9f04b94f8c4810b3321df7729b11affeee4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401360730", "body": "nit: also `checkNotNull` for `checkpointMetaData` and `operatorChain`, and i think they can be done with the commit `[FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator`", "bodyText": "nit: also checkNotNull for checkpointMetaData and operatorChain, and i think they can be done with the commit [FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator", "bodyHTML": "<p dir=\"auto\">nit: also <code>checkNotNull</code> for <code>checkpointMetaData</code> and <code>operatorChain</code>, and i think they can be done with the commit <code>[FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator</code></p>", "author": "zhijiangW", "createdAt": "2020-04-01T05:17:05Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -65,6 +75,8 @@ public void checkpointState(\n \t\t\tCheckpointMetrics checkpointMetrics,\n \t\t\tOperatorChain<?, ?> operatorChain,\n \t\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\tcheckNotNull(checkpointOptions);", "originalCommit": "ae7bd9f04b94f8c4810b3321df7729b11affeee4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg3OTEzNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401879137", "bodyText": "Both of these fields are unreferenced a few lines below. Do you think it makes sense to add this check at the beginning too?", "author": "rkhachatryan", "createdAt": "2020-04-01T20:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcxNzU0NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403717544", "bodyText": "When I checked the commit \"[FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator\",  the arguments of CheckpointMetaData, CheckpointOptions and operatorChain are already referenced in below lines, so i suggested checkNotNull for them in that commit.", "author": "zhijiangW", "createdAt": "2020-04-05T15:30:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkwODQ3Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404908472", "bodyText": "When checking the commit \"[FLINK-16744][task][refactor] inline CheckpointingOperation\", we only checkNotNull for checkpointOptions and checkpointMetrics.  But from the commit \"[FLINK-16744][task][refactor] extract SubtaskCheckpointCoordinator\" when this method is firstly introduced,  we did not checkNotNull for other arguments which are actually referenced in that commit, so the criteria seems inconsistent.", "author": "zhijiangW", "createdAt": "2020-04-07T15:37:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MDczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2Mjk2NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401362965", "body": "nit: better to split line for every argument", "bodyText": "nit: better to split line for every argument", "bodyHTML": "<p dir=\"auto\">nit: better to split line for every argument</p>", "author": "zhijiangW", "createdAt": "2020-04-01T05:25:51Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),", "originalCommit": "ae7bd9f04b94f8c4810b3321df7729b11affeee4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2NDAwOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401364009", "body": "I see this log occur twice with the same arguments only different message, and this log actually seems a bit long to impact the normal logics review. I am not sure whether it is worth extracting a separate method for only passing different message in two usages.", "bodyText": "I see this log occur twice with the same arguments only different message, and this log actually seems a bit long to impact the normal logics review. I am not sure whether it is worth extracting a separate method for only passing different message in two usages.", "bodyHTML": "<p dir=\"auto\">I see this log occur twice with the same arguments only different message, and this log actually seems a bit long to impact the normal logics review. I am not sure whether it is worth extracting a separate method for only passing different message in two usages.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T05:30:04Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(", "originalCommit": "ae7bd9f04b94f8c4810b3321df7729b11affeee4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NTMzOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401955339", "bodyText": "I refactored a bit SubtaskCheckpointCoordinatorImpl while addressing one of the issues below and these messages ended up one after another; so removed one.", "author": "rkhachatryan", "createdAt": "2020-04-01T22:50:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2NDAwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2ODQ3MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401368470", "body": "nit: maybe `warn` instead of `info` and give some custom message to indicate which process causes the exception.", "bodyText": "nit: maybe warn instead of info and give some custom message to indicate which process causes the exception.", "bodyHTML": "<p dir=\"auto\">nit: maybe <code>warn</code> instead of <code>info</code> and give some custom message to indicate which process causes the exception.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T05:45:29Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -89,17 +101,98 @@ public void checkpointState(\n \t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\tcheckpointOptions.getTargetLocation());\n \n-\t\tCheckpointingOperation.execute(\n-\t\t\tcheckpointMetaData,\n-\t\t\tcheckpointOptions,\n-\t\t\tcheckpointMetrics,\n-\t\t\tstorage,\n-\t\t\toperatorChain,\n-\t\t\ttaskName,\n-\t\t\tcloseableRegistry,\n-\t\t\texecutorService,\n-\t\t\tenv,\n-\t\t\tasyncExceptionHandler,\n-\t\t\tisCanceled);\n+\t\tlong startSyncPartNano = System.nanoTime();\n+\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\ttry {\n+\t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n+\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n+\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\t\t\top,\n+\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\tstorage,\n+\t\t\t\t\tisCanceled);\n+\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\"Finished synchronous checkpoints for checkpoint {} on task {}\",\n+\t\t\t\t\tcheckpointMetaData.getCheckpointId(), taskName);\n+\t\t\t}\n+\n+\t\t\tlong startAsyncPartNano = System.nanoTime();\n+\n+\t\t\tcheckpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000);\n+\n+\t\t\t// we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit\n+\t\t\texecutorService.execute(new AsyncCheckpointRunnable(\n+\t\t\t\toperatorSnapshotsInProgress,\n+\t\t\t\tcheckpointMetaData,\n+\t\t\t\tcheckpointMetrics,\n+\t\t\t\tstartAsyncPartNano,\n+\t\t\t\ttaskName,\n+\t\t\t\tcloseableRegistry,\n+\t\t\t\tenv,\n+\t\t\t\tasyncExceptionHandler));\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - finished synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\t\t} catch (Exception ex) {\n+\t\t\t// Cleanup to release resources\n+\t\t\tfor (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {\n+\t\t\t\tif (null != operatorSnapshotResult) {\n+\t\t\t\t\ttry {\n+\t\t\t\t\t\toperatorSnapshotResult.cancel();\n+\t\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\t\tLOG.warn(\"Could not properly cancel an operator snapshot result.\", e);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (LOG.isDebugEnabled()) {\n+\t\t\t\tLOG.debug(\n+\t\t\t\t\t\"{} - did NOT finish synchronous part of checkpoint {}. Alignment duration: {} ms, snapshot duration {} ms\",\n+\t\t\t\t\ttaskName, checkpointMetaData.getCheckpointId(),\n+\t\t\t\t\tcheckpointMetrics.getAlignmentDurationNanos() / 1_000_000,\n+\t\t\t\t\tcheckpointMetrics.getSyncDurationMillis());\n+\t\t\t}\n+\n+\t\t\tif (checkpointOptions.getCheckpointType().isSynchronous()) {\n+\t\t\t\t// in the case of a synchronous checkpoint, we always rethrow the exception,\n+\t\t\t\t// so that the task fails.\n+\t\t\t\t// this is because the intention is always to stop the job after this checkpointing\n+\t\t\t\t// operation, and without the failure, the task would go back to normal execution.\n+\t\t\t\tthrow ex;\n+\t\t\t} else {\n+\t\t\t\tenv.declineCheckpoint(checkpointMetaData.getCheckpointId(), ex);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\tStreamOperator<?> op,\n+\t\tCheckpointMetaData checkpointMetaData,\n+\t\tCheckpointOptions checkpointOptions,\n+\t\tCheckpointStreamFactory storageLocation,\n+\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\t\ttry {\n+\t\t\treturn op.snapshotState(\n+\t\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\t\tcheckpointMetaData.getTimestamp(),\n+\t\t\t\tcheckpointOptions,\n+\t\t\t\tstorageLocation);\n+\t\t}\n+\t\tcatch (Exception ex) {\n+\t\t\tif (!isCanceled.get()) {\n+\t\t\t\tLOG.info(ex.getMessage(), ex);", "originalCommit": "ae7bd9f04b94f8c4810b3321df7729b11affeee4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg4NTIzMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401885233", "bodyText": "This change was introduced by another commit into CheckpointingOperation which I merged with SubtaskCheckpointCoordinatorImpl.\nAs I see from StreamOperatorStateHandler.snapshotState, the message is built like this:\nString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" + operatorName + \".\";\n\nWhich I think provides enough details.\nNot sure, why do we log (info) and re-throw it, but I'd like not to address it in this PR.", "author": "rkhachatryan", "createdAt": "2020-04-01T20:20:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2ODQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxMTU5MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401411590", "body": "nit: indentation alignment", "bodyText": "nit: indentation alignment", "bodyHTML": "<p dir=\"auto\">nit: indentation alignment</p>", "author": "zhijiangW", "createdAt": "2020-04-01T07:35:17Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder,\n+\t\t\t@Nonnull ChannelStateReader channelStateReader) {\n+\t\t\tthis.jobId = jobId;", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNjc0OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401416749", "body": "nit: also make this argument separate line", "bodyText": "nit: also make this argument separate line", "bodyHTML": "<p dir=\"auto\">nit: also make this argument separate line</p>", "author": "zhijiangW", "createdAt": "2020-04-01T07:44:33Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401417233", "body": "only need private atm", "bodyText": "only need private atm", "bodyHTML": "<p dir=\"auto\">only need private atm</p>", "author": "zhijiangW", "createdAt": "2020-04-01T07:45:25Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskStateManagerImpl.java", "diffHunk": "@@ -68,18 +70,36 @@\n \t/** The checkpoint responder through which this manager can report to the job manager. */\n \tprivate final CheckpointResponder checkpointResponder;\n \n+\tprivate final ChannelStateReader channelStateReader;\n+\n \tpublic TaskStateManagerImpl(\n-\t\t@Nonnull JobID jobId,\n-\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n-\t\t@Nonnull TaskLocalStateStore localStateStore,\n-\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n-\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\t\t@Nonnull JobID jobId,\n+\t\t\t@Nonnull ExecutionAttemptID executionAttemptID,\n+\t\t\t@Nonnull TaskLocalStateStore localStateStore,\n+\t\t\t@Nullable JobManagerTaskRestore jobManagerTaskRestore,\n+\t\t\t@Nonnull CheckpointResponder checkpointResponder) {\n+\t\tthis(jobId,\n+\t\t\texecutionAttemptID,\n+\t\t\tlocalStateStore,\n+\t\t\tjobManagerTaskRestore,\n+\t\t\tcheckpointResponder,\n+\t\t\tnew ChannelStateReaderImpl(jobManagerTaskRestore == null ? new TaskStateSnapshot() : jobManagerTaskRestore.getTaskStateSnapshot())\n+\t\t);\n+\t}\n \n-\t\tthis.jobId = jobId;\n+\tTaskStateManagerImpl(", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg4Njg3Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401886877", "bodyText": "It could be used in tests.", "author": "rkhachatryan", "createdAt": "2020-04-01T20:23:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQzNDE4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402434184", "bodyText": "@VisibleForTesting", "author": "zhijiangW", "createdAt": "2020-04-02T16:09:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjg1NzkyMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402857921", "bodyText": "There is nothing wrong with using this constructor in production code too.", "author": "rkhachatryan", "createdAt": "2020-04-03T08:59:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NDIxNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403484216", "bodyText": "Yes, I agree with your point to some extent. I think the key concern is how we define the access modifier based on two considerations.\n\n\nBased on current demands: if so, it should be private ATM, and then further extend it  by demands if necessary future.\n\n\nBased on future considerations: if so, it can be defined as package public now, even public.  But it is hard to say whether it is alway fitting the expectation, then it might seem unnecessary for long time. If taking this option, we might even remove @VisibleForTesting annotation for previous usages, because any constructors might have the possibility to be used in core codes future.\n\n\nAnyway, I can accept both options and do not think it is a big issue. Just share some thoughts, feel free to take for your favor. :)", "author": "zhijiangW", "createdAt": "2020-04-04T15:44:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQxNzIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401423000", "body": "The precious consideration of closing network resources early is done by canceler thread, which would throw exception while task thread interacts with buffer operation to make task exit ASAP. If we add the state manager close here, does it have the same effect to throw any exceptions while interacting with task thread?", "bodyText": "The precious consideration of closing network resources early is done by canceler thread, which would throw exception while task thread interacts with buffer operation to make task exit ASAP. If we add the state manager close here, does it have the same effect to throw any exceptions while interacting with task thread?", "bodyHTML": "<p dir=\"auto\">The precious consideration of closing network resources early is done by canceler thread, which would throw exception while task thread interacts with buffer operation to make task exit ASAP. If we add the state manager close here, does it have the same effect to throw any exceptions while interacting with task thread?</p>", "author": "zhijiangW", "createdAt": "2020-04-01T07:56:06Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -914,6 +914,11 @@ private void closeNetworkResources() {\n \t\t\t\tLOG.error(\"Failed to release input gate for task {}.\", taskNameWithSubtask, t);\n \t\t\t}\n \t\t}\n+\t\ttry {\n+\t\t\ttaskStateManager.close();", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5MjA4Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401892083", "bodyText": "I don't fully understand your concerns, could you explain what are they?\nOn close, taskStateManager will close all opened input streams (without waiting for the task thread).", "author": "rkhachatryan", "createdAt": "2020-04-01T20:33:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQzNzQ3NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402437475", "bodyText": "The previous closeNetworkResources can be used in two scenarios, one is for task exit in finally region, another is used by canceler thread before task exiting. The motivation to close network resource by canceler thread is to release the buffers ASAP, then the task thread can cause exception while interacting with buffer to make it exit early.\nIf the close of taskStateManager does not have the effect to make task thread exit early, then it should not be called by canceler thread, and it only needs to be called in task thread finally region.", "author": "zhijiangW", "createdAt": "2020-04-02T16:14:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA1MzY4Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403053686", "bodyText": "Thanks for the explanation.\nI will move taskStateManager.close() to releaseResources() which is called from doRun and not task canceller.", "author": "rkhachatryan", "createdAt": "2020-04-03T14:40:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzAwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyMzE1MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401423151", "body": "also adjust the respective javadoc", "bodyText": "also adjust the respective javadoc", "bodyHTML": "<p dir=\"auto\">also adjust the respective javadoc</p>", "author": "zhijiangW", "createdAt": "2020-04-01T07:56:22Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java", "diffHunk": "@@ -889,14 +889,14 @@ private void releaseNetworkResources() {\n \t\t\t}\n \t\t}\n \n-\t\tcloseNetworkResources();\n+\t\tcloseResources();\n \t}\n \n \t/**\n \t * There are two scenarios to close the network resources. One is from {@link TaskCanceler} to early", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401425192", "body": "unrelated change", "bodyText": "unrelated change", "bodyHTML": "<p dir=\"auto\">unrelated change</p>", "author": "zhijiangW", "createdAt": "2020-04-01T07:59:49Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/state/TestTaskStateManager.java", "diffHunk": "@@ -94,7 +95,6 @@ public void reportTaskStateSnapshots(\n \t\t@Nullable TaskStateSnapshot acknowledgedState,\n \t\t@Nullable TaskStateSnapshot localState) {\n \n-", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5NTU0MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401895541", "bodyText": "Do you mean it should go to a separate commit or PR?\nI'd rather choose a cleaner git/PR history.", "author": "rkhachatryan", "createdAt": "2020-04-01T20:39:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQ0MjAwMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402442003", "bodyText": "To be strict, any unrelated formatting change should be a separate hotfix commit, not need a separate PR, can commit separately in this PR.\nBecause I was also told the same issue multiple times by other committers when submitting PR in the early period. So I just mention it, it is not mandatory from my side. :)", "author": "zhijiangW", "createdAt": "2020-04-02T16:21:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA2NDYzNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403064635", "bodyText": "I understand. Extracted into a separate commit.", "author": "rkhachatryan", "createdAt": "2020-04-03T14:55:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNTE5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQyNjUwMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401426501", "body": "nit: @Nullable", "bodyText": "nit: @nullable", "bodyHTML": "<p dir=\"auto\">nit: <a class=\"user-mention\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/nullable/hovercard\" href=\"https://github.com/nullable\">@nullable</a></p>", "author": "zhijiangW", "createdAt": "2020-04-01T08:02:25Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/OperatorChain.java", "diffHunk": "@@ -544,6 +544,10 @@ private void linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorW\n \t\t\tcontainingTask.getMailboxExecutorFactory().createExecutor(operatorConfig.getChainIndex()));\n \t}\n \n+\tStreamOperator<?> getTailOperator() {", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQzNDY2NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401434664", "body": "should register `this` after it is constructed completely? ", "bodyText": "should register this after it is constructed completely?", "bodyHTML": "<p dir=\"auto\">should register <code>this</code> after it is constructed completely?</p>", "author": "zhijiangW", "createdAt": "2020-04-01T08:16:40Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -21,53 +21,79 @@\n import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.checkpoint.StateObjectCollection;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriterImpl;\n import org.apache.flink.runtime.execution.Environment;\n import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.SnapshotResult;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.util.WrappingRuntimeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.io.IOException;\n import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.function.Supplier;\n \n+import static org.apache.flink.runtime.checkpoint.CheckpointType.CHECKPOINT;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n \n class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n \n-\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final CachingCheckpointStorageWorkerView checkpointStorage;\n \tprivate final String taskName;\n \tprivate final CloseableRegistry closeableRegistry;\n \tprivate final ExecutorService executorService;\n \tprivate final Environment env;\n \tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final ChannelStateWriter channelStateWriter;\n \n \tSubtaskCheckpointCoordinatorImpl(\n-\t\tCheckpointStorageWorkerView checkpointStorage,\n-\t\tString taskName,\n-\t\tCloseableRegistry closeableRegistry,\n-\t\tExecutorService executorService,\n-\t\tEnvironment env,\n-\t\tAsyncExceptionHandler asyncExceptionHandler) {\n-\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler,\n+\t\t\tboolean sendChannelState) throws IOException {\n+\t\tthis.checkpointStorage = new CachingCheckpointStorageWorkerView(checkNotNull(checkpointStorage));\n \t\tthis.taskName = checkNotNull(taskName);\n \t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n \t\tthis.executorService = checkNotNull(executorService);\n \t\tthis.env = checkNotNull(env);\n \t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.closeableRegistry.registerCloseable(this);", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5NjY1NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401896655", "bodyText": "Agree, will move to the end of the constructor.", "author": "rkhachatryan", "createdAt": "2020-04-01T20:42:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTQzNDY2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401505507", "body": "The proper javadoc format for class should be \r\n/**\r\n*\r\n**/", "bodyText": "The proper javadoc format for class should be\n/**\n*\n**/", "bodyHTML": "<p dir=\"auto\">The proper javadoc format for class should be<br>\n/**<br>\n*<br>\n**/</p>", "author": "zhijiangW", "createdAt": "2020-04-01T10:13:22Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5OTEzNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401899136", "bodyText": "This is not a javadoc but rather description of SubtaskCheckpointCoordinatorImpl inner workings. I can make it javadoc if you prefer though.", "author": "rkhachatryan", "createdAt": "2020-04-01T20:46:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NDUzMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403484530", "bodyText": "I am not forcing that, it is up to you. Only saw that most of descriptions for class scope prefers to using above, and // is almost used in inline codes, /** */ is for class fields.", "author": "zhijiangW", "createdAt": "2020-04-04T15:48:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwNTUwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUwODc1NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401508754", "body": "maybe better formatting as follow\r\n```\r\nChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\r\n\t\t\tchannelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\r\n\t\t\tChannelStateWriteResult.EMPTY;\r\n```", "bodyText": "maybe better formatting as follow\nChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n\t\t\tchannelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n\t\t\tChannelStateWriteResult.EMPTY;", "bodyHTML": "<p dir=\"auto\">maybe better formatting as follow</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"ChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n\t\t\tchannelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n\t\t\tChannelStateWriteResult.EMPTY;\n\"><pre><code>ChannelStateWriteResult channelStateWriteResult = checkpointOptions.getCheckpointType() == CHECKPOINT ?\n\t\t\tchannelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n\t\t\tChannelStateWriteResult.EMPTY;\n</code></pre></div>", "author": "zhijiangW", "createdAt": "2020-04-01T10:19:02Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUxOTA0Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401519043", "body": "should we add some `TODO` before `getWriteResult`, otherwise it seems hard to understand from this commit that we actually have not written anything before get the result.", "bodyText": "should we add some TODO before getWriteResult, otherwise it seems hard to understand from this commit that we actually have not written anything before get the result.", "bodyHTML": "<p dir=\"auto\">should we add some <code>TODO</code> before <code>getWriteResult</code>, otherwise it seems hard to understand from this commit that we actually have not written anything before get the result.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T10:37:38Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkwMTUyMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401901521", "bodyText": "There is todo in StreamTask near SubtaskCheckpointCoordinatorImpl constructor:\nfalse); // todo: pass true if unaligned checkpoints enabled\n\n(I expect the exact type of this option could change)", "author": "rkhachatryan", "createdAt": "2020-04-01T20:51:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUxOTA0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401526771", "body": "`WrappingRuntimeException` is used for wrapping non-runtime exceptions? I guess this should belong to runtime exception. Another option without wrapping exception is not using lambda way to throw `IOException` explicitly in the method `resolveCheckpointStorageLocation`", "bodyText": "WrappingRuntimeException is used for wrapping non-runtime exceptions? I guess this should belong to runtime exception. Another option without wrapping exception is not using lambda way to throw IOException explicitly in the method resolveCheckpointStorageLocation", "bodyHTML": "<p dir=\"auto\"><code>WrappingRuntimeException</code> is used for wrapping non-runtime exceptions? I guess this should belong to runtime exception. Another option without wrapping exception is not using lambda way to throw <code>IOException</code> explicitly in the method <code>resolveCheckpointStorageLocation</code></p>", "author": "zhijiangW", "createdAt": "2020-04-01T10:52:28Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -175,6 +203,77 @@ public void checkpointState(\n \t\t}\n \t}\n \n+\tprivate OperatorSnapshotFutures buildOperatorSnapshotFutures(\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tOperatorChain<?, ?> operatorChain,\n+\t\t\tStreamOperator<?> op,\n+\t\t\tSupplier<Boolean> isCanceled,\n+\t\t\tChannelStateWriteResult channelStateWriteResult) throws Exception {\n+\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n+\t\t\tcheckpointMetaData.getCheckpointId(),\n+\t\t\tcheckpointOptions.getTargetLocation());\n+\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n+\t\t\top,\n+\t\t\tcheckpointMetaData,\n+\t\t\tcheckpointOptions,\n+\t\t\tstorage,\n+\t\t\tisCanceled);\n+\t\tif (op == operatorChain.getHeadOperator()) {\n+\t\t\tsnapshotInProgress.setInputChannelStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getInputChannelStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\tif (op == operatorChain.getTailOperator()) {\n+\t\t\tsnapshotInProgress.setResultSubpartitionStateFuture(channelStateWriteResult\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.getResultSubpartitionStateHandles()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(StateObjectCollection::new)\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.thenApply(SnapshotResult::of)\n+\t\t\t);\n+\t\t}\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tchannelStateWriter.close();\n+\t}\n+\n+\t// Caches checkpoint output stream factories to prevent multiple output stream per checkpoint.\n+\t// This could result from requesting output stream by different entities (this and channelStateWriter)\n+\t// We can't just pass a stream to the channelStateWriter because it can receive checkpoint call earlier than this class\n+\t// in some unaligned checkpoints scenarios\n+\tprivate static class CachingCheckpointStorageWorkerView implements CheckpointStorageWorkerView {\n+\t\tprivate final Map<Long, CheckpointStreamFactory> cache = new ConcurrentHashMap<>();\n+\t\tprivate final CheckpointStorageWorkerView delegate;\n+\n+\t\tprivate CachingCheckpointStorageWorkerView(CheckpointStorageWorkerView delegate) {\n+\t\t\tthis.delegate = delegate;\n+\t\t}\n+\n+\t\tvoid clearCacheFor(long checkpointId) {\n+\t\t\tcache.remove(checkpointId);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic CheckpointStreamFactory resolveCheckpointStorageLocation(long checkpointId, CheckpointStorageLocationReference reference) {\n+\t\t\treturn cache.computeIfAbsent(checkpointId, id -> {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn delegate.resolveCheckpointStorageLocation(checkpointId, reference);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tthrow new WrappingRuntimeException(e);", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkwMjk1MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401902951", "bodyText": "Yes, I think this is the very purpose of WrappingRuntimeException:\n/**\n * A runtime exception that is explicitly used to wrap non-runtime exceptions.\n\nOr did I misunderstand something?", "author": "rkhachatryan", "createdAt": "2020-04-01T20:54:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyMTU0NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403721544", "bodyText": "Sorry for misleading. Some concerns are the same as #11515 (comment), and another tiny concern is why not use FlinkRuntimeException directly? I have not found any special purpose for WrappingRuntimeException.", "author": "zhijiangW", "createdAt": "2020-04-05T16:05:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0ODY2NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404748665", "bodyText": "Replaced with FlinkRuntimeException.", "author": "rkhachatryan", "createdAt": "2020-04-07T11:52:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUyNjc3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTUzMDU2Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r401530563", "body": "nit: I prefer to extracting `checkpointStorage.resolveCheckpointStorageLocation` from `buildOperatorSnapshotFutures` and put it before `for` loop, then it is easy to trace both the creation and clear actions in the same page.", "bodyText": "nit: I prefer to extracting checkpointStorage.resolveCheckpointStorageLocation from buildOperatorSnapshotFutures and put it before for loop, then it is easy to trace both the creation and clear actions in the same page.", "bodyHTML": "<p dir=\"auto\">nit: I prefer to extracting <code>checkpointStorage.resolveCheckpointStorageLocation</code> from <code>buildOperatorSnapshotFutures</code> and put it before <code>for</code> loop, then it is easy to trace both the creation and clear actions in the same page.</p>", "author": "zhijiangW", "createdAt": "2020-04-01T10:59:52Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -97,24 +123,26 @@ public void checkpointState(\n \t\t// Step (3): Take the state snapshot. This should be largely asynchronous, to not\n \t\t//           impact progress of the streaming topology\n \n-\t\tCheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(\n-\t\t\tcheckpointMetaData.getCheckpointId(),\n-\t\t\tcheckpointOptions.getTargetLocation());\n-\n \t\tlong startSyncPartNano = System.nanoTime();\n \n \t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress = new HashMap<>(operatorChain.getNumberOfOperators());\n+\t\tChannelStateWriteResult channelStateWriteResult =\n+\t\t\tcheckpointOptions.getCheckpointType() == CHECKPOINT ? channelStateWriter.getWriteResult(checkpointMetaData.getCheckpointId()) :\n+\t\t\t\tChannelStateWriteResult.EMPTY;\n \t\ttry {\n \t\t\tfor (StreamOperatorWrapper<?, ?> operatorWrapper : operatorChain.getAllOperators(true)) {\n-\t\t\t\tStreamOperator<?> op = operatorWrapper.getStreamOperator();\n-\t\t\t\tOperatorSnapshotFutures snapshotInProgress = checkpointStreamOperator(\n-\t\t\t\t\top,\n-\t\t\t\t\tcheckpointMetaData,\n-\t\t\t\t\tcheckpointOptions,\n-\t\t\t\t\tstorage,\n-\t\t\t\t\tisCanceled);\n-\t\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n+\t\t\t\toperatorSnapshotsInProgress.put(\n+\t\t\t\t\toperatorWrapper.getStreamOperator().getOperatorID(),\n+\t\t\t\t\tbuildOperatorSnapshotFutures(\n+\t\t\t\t\t\tcheckpointMetaData,\n+\t\t\t\t\t\tcheckpointOptions,\n+\t\t\t\t\t\toperatorChain,\n+\t\t\t\t\t\toperatorWrapper.getStreamOperator(),\n+\t\t\t\t\t\tisCanceled,\n+\t\t\t\t\t\tchannelStateWriteResult)\n+\t\t\t\t);\n \t\t\t}\n+\t\t\tcheckpointStorage.clearCacheFor(checkpointMetaData.getCheckpointId());", "originalCommit": "da674cafad1c62dde92588b94b8d44ab699b8280", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402028615", "body": " weird naming `streamFactoryFactory`", "bodyText": "weird naming streamFactoryFactory", "bodyHTML": "<p dir=\"auto\">weird naming <code>streamFactoryFactory</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:15:19Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIzMjI0NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402232244", "bodyText": "Agree, but it serves its purpose: make it clear what it is (at least clear to me); while checkpointStorageWorkerView wouldn't tell me much.\nDo you have any better names?", "author": "rkhachatryan", "createdAt": "2020-04-02T11:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQ1MDcyOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402450729", "bodyText": "Yes, I can guess your previous motivation to name this. But I guess it might easy bring confusing for others at first glance.\nIn general the variable naming should be consistent with class naming. But I also do not like the naming of CheckpointStorageWorkerView because it is hard to get the real semantic. So the root cause might be refactoring the class name in a hotfix commit, but i am not forcing it.\nActually  CheckpointStorageWorkerView has two purposes, if only considering the builder for factory, might be streamFactoryBuilder/Resolver.", "author": "zhijiangW", "createdAt": "2020-04-02T16:34:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA2NzIxMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403067210", "bodyText": "Renamed to streamFactoryResolver.", "author": "rkhachatryan", "createdAt": "2020-04-03T14:59:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyODYxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTM3NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402029374", "body": "I guess it is not always using  `DEFAULT_MAX_CHECKPOINTS`, the `maxCheckpoints` can still be set explicitly, e.g. in tests.", "bodyText": "I guess it is not always using  DEFAULT_MAX_CHECKPOINTS, the maxCheckpoints can still be set explicitly, e.g. in tests.", "bodyHTML": "<p dir=\"auto\">I guess it is not always using  <code>DEFAULT_MAX_CHECKPOINTS</code>, the <code>maxCheckpoints</code> can still be set explicitly, e.g. in tests.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:18:17Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIzODUwNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402238506", "bodyText": "Right, thanks. Updating the javadoc.", "author": "rkhachatryan", "createdAt": "2020-04-02T11:22:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTM3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402029849", "body": "it can be private ATM", "bodyText": "it can be private ATM", "bodyHTML": "<p dir=\"auto\">it can be private ATM</p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:20:08Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI0MDEzNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402240135", "bodyText": "It could be used in tests.", "author": "rkhachatryan", "createdAt": "2020-04-02T11:25:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyMTI4Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402421283", "bodyText": "If so, maybe add @VisibleForTesting", "author": "zhijiangW", "createdAt": "2020-04-02T15:51:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyOTg0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDE4Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402030187", "body": "Is it probably to pass different implementations of `ChannelStateSerializer` future?", "bodyText": "Is it probably to pass different implementations of ChannelStateSerializer future?", "bodyHTML": "<p dir=\"auto\">Is it probably to pass different implementations of <code>ChannelStateSerializer</code> future?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:21:44Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI0MTU3Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402241577", "bodyText": "Yes, I considered to pass a no-op implementation for tests.", "author": "rkhachatryan", "createdAt": "2020-04-02T11:28:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDE4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMDg5Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402030897", "body": "nit: better to also describe other arguments for consistent.", "bodyText": "nit: better to also describe other arguments for consistent.", "bodyHTML": "<p dir=\"auto\">nit: better to also describe other arguments for consistent.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:24:51Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMzk0MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402033941", "body": "nit: `maxCheckpoints` is not necessary to pass. \r\nweird naming `streamFactoryFactory`. \r\nAnother option is to construct `ChannelStateWriteRequestProcessor` inside constructor of `ChannelStateWriterImpl` and pass it directly into `ProcessRequestsLoop`", "bodyText": "nit: maxCheckpoints is not necessary to pass.\nweird naming streamFactoryFactory.\nAnother option is to construct ChannelStateWriteRequestProcessor inside constructor of ChannelStateWriterImpl and pass it directly into ProcessRequestsLoop", "bodyHTML": "<p dir=\"auto\">nit: <code>maxCheckpoints</code> is not necessary to pass.<br>\nweird naming <code>streamFactoryFactory</code>.<br>\nAnother option is to construct <code>ChannelStateWriteRequestProcessor</code> inside constructor of <code>ChannelStateWriterImpl</code> and pass it directly into <code>ProcessRequestsLoop</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:37:53Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402038720", "body": "nit: IMO better to place this class after constructor, not mixed among the class fields.", "bodyText": "nit: IMO better to place this class after constructor, not mixed among the class fields.", "bodyHTML": "<p dir=\"auto\">nit: IMO better to place this class after constructor, not mixed among the class fields.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T03:59:00Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MDg2OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402250869", "bodyText": "Placing it after constructor confuses me.\nWDYT about bottom of the file?", "author": "rkhachatryan", "createdAt": "2020-04-02T11:47:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyMDMxNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402420317", "bodyText": "Not mandatory. In general I found many internal class were placed at the bottom. For me, this class is placed among the class fields to break them down, then it is not convenient to directly overview all the class fields.", "author": "zhijiangW", "createdAt": "2020-04-02T15:50:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzODcyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402039744", "body": "I am wondering  it might bring potential problems to use `BlockingQueue` with bounded size. The IO operations might be stuck sometimes in bad scenarios, then the request in the queue can not be consumed in time. Therefore it would block all the operations of `#addInputData`, especially the `#addInputData` might be triggered by multiple netty threads, to impact the network throughput. How about using unbounded queue if the memory overhead is not obvious?", "bodyText": "I am wondering  it might bring potential problems to use BlockingQueue with bounded size. The IO operations might be stuck sometimes in bad scenarios, then the request in the queue can not be consumed in time. Therefore it would block all the operations of #addInputData, especially the #addInputData might be triggered by multiple netty threads, to impact the network throughput. How about using unbounded queue if the memory overhead is not obvious?", "bodyHTML": "<p dir=\"auto\">I am wondering  it might bring potential problems to use <code>BlockingQueue</code> with bounded size. The IO operations might be stuck sometimes in bad scenarios, then the request in the queue can not be consumed in time. Therefore it would block all the operations of <code>#addInputData</code>, especially the <code>#addInputData</code> might be triggered by multiple netty threads, to impact the network throughput. How about using unbounded queue if the memory overhead is not obvious?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T04:03:30Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NjYzNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402266636", "bodyText": "Interesting question. The usual arguments for bounded queues like protecting against memory exhaustion don't work that well here. The reasons are that the queue essentially holds references to larger memory regions and atm we can only have a single in-flight checkpoint.\nHowever,\n\nwe may have multiple references to the same region (when we remove the single-checkpoint limit and don't have incremental checkpointing yet or it doesn't help here)\nthese are different memory regions (heap and likely non-heap)\n\nWith an unbounded queue, the task could run out of memory and it would be much harder to figure it out.\nSo I'd stick with bounded queue but lift its default size.\nWDYT?", "author": "rkhachatryan", "createdAt": "2020-04-02T12:16:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NzI5OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403487299", "bodyText": "Thanks for sharing your thoughts. Actually I only thought of the benefits of resource limitation for bounded queue before.\nDo you concerning that the network buffer to be exhausted or run out of memory by unbounded queue I f I understand correctly? If so, I guess this hurt might be less worse than blocking the netty thread for two reasons:\n\n\nIf one netty thread is blocked, it might block multiple input channels receiving following data, then it might even delay the barrier alignment, based on the truth that one netty thread wouold serve for multiple input channels data transport.\n\n\nIf one netty thread is blocked, it does not alway mean that the left buffer memory can be better used by other channels. For exclusive buffers per-channel, it can only be used by current blocked netty thread for receiving data. For floating buffers among all the channels, if they were already requested away by the current blocked netty thread, they can not returned back to be used by other active netty threads. It can only avoid requesting more floating buffers by current blocked netty thread, but it is not determined behavior.\n\n\nSo if there are no concerns for additional memory overhead caused by unbounded queue and it is also easy to adjust, then i prefer to unblocking option. Otherwise we can lift the default size for bounded size and further convert to unbounded queue if finding serious problems in production future. But I am not quite sure whether the blocking impact can be easily found in practice.", "author": "zhijiangW", "createdAt": "2020-04-04T16:15:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1OTg2Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404359862", "bodyText": "I agree, blocking the netty thread is a bad idea for a bug-free and maybe backpressured scenarios.\nBut even with unbounded queue I think we need to check the size of the queue (and throw exception when exceeded); so that in case of a bug it can be  detected easier.\nIn that case, bounded vs unbounded becomes just an implementation detail (and I found it easier to use bounded currently).", "author": "rkhachatryan", "createdAt": "2020-04-06T20:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMzYyNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404603624", "bodyText": "If it is easier for using bounded atm, i am also fine with setting enough capacity for the queue, then we can assume that it would never block netty thread with this large capacity.", "author": "zhijiangW", "createdAt": "2020-04-07T07:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzOTc0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402045285", "body": "Give some javadoc to explain why we do not support event data?", "bodyText": "Give some javadoc to explain why we do not support event data?", "bodyHTML": "<p dir=\"auto\">Give some javadoc to explain why we do not support event data?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T04:29:39Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace\n+\t\t}\n+\t}\n+\n+\tprivate static Buffer[] checkBufferType(Buffer... data) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2OTQ0Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402269447", "bodyText": "The limitation itself is documented on the interface level.\nThe reasons behind it are too high-level for this class IMO.", "author": "rkhachatryan", "createdAt": "2020-04-02T12:21:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyNDE3Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402424172", "bodyText": "That is fine for me if it is documented in some places", "author": "zhijiangW", "createdAt": "2020-04-02T15:55:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTI4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA0NTk2MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402045961", "body": "should check both `isRunning && asyncWriter.isAlive()` as did in `#start()`", "bodyText": "should check both isRunning && asyncWriter.isAlive() as did in #start()", "bodyHTML": "<p dir=\"auto\">should check both <code>isRunning &amp;&amp; asyncWriter.isAlive()</code> as did in <code>#start()</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T04:32:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402050562", "body": "I do not think `RuntimeException` is a good way unless necessary. Although it seems simple to not announce exceptions explicitly in related methods, it might mislead the upper caller to think all the interactions with `ChannelStateWriter` would not cause any exceptions. Then the caller might lose the chance to handle exceptions in elegant way.\r\n\r\nAlso the `RuntimeException` seems have a more widely concept, I guess it probably should be `IOException` for writer to give more sense.", "bodyText": "I do not think RuntimeException is a good way unless necessary. Although it seems simple to not announce exceptions explicitly in related methods, it might mislead the upper caller to think all the interactions with ChannelStateWriter would not cause any exceptions. Then the caller might lose the chance to handle exceptions in elegant way.\nAlso the RuntimeException seems have a more widely concept, I guess it probably should be IOException for writer to give more sense.", "bodyHTML": "<p dir=\"auto\">I do not think <code>RuntimeException</code> is a good way unless necessary. Although it seems simple to not announce exceptions explicitly in related methods, it might mislead the upper caller to think all the interactions with <code>ChannelStateWriter</code> would not cause any exceptions. Then the caller might lose the chance to handle exceptions in elegant way.</p>\n<p dir=\"auto\">Also the <code>RuntimeException</code> seems have a more widely concept, I guess it probably should be <code>IOException</code> for writer to give more sense.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T04:53:14Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {\n+\t\tif (thrown != null) {\n+\t\t\tthrow new RuntimeException(thrown); // wrap to record current stack-trace", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3OTk4MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402279980", "bodyText": "I don't see how the client could recover from any exception thrown by this class. Especially given that:\n\nthese exceptions can come from previous calls\nthe idiomatic way to handle errors in Flink (as I see it) is to fail and recover the whole job\n\nAlso, it can be any exception, not only IOException.\nSo there is no point to declare (likely forcing the client to wrap it or declare too).", "author": "rkhachatryan", "createdAt": "2020-04-02T12:38:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyMDk4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403720984", "bodyText": "Yes, I agree that any exceptions should fail the task and result in restarting the whole job.\nMy previous concern was that it may be better to announce the specific exceptions explicitly for the called methods, to make the caller have the possibility to handle the exception in elegant way.\nE.g. If the internal called methods without explicit exception:\n#method1() {\naction 1: request some resources\naction 2: call some methods without exception\naction 3: release resources\n}\nE.g. If the internal called methods with explicit exception\n#method1() {\naction 1: request some resources\ntry{\naction 2: call some methods without exception\n} finally {\naction 3: release resources\n}\n}\nFor the first example, it might cause resource leak for the caller if is not ware of the exception.\nI guess all the related exceptions for these methods should be IOException and InterruptedException.", "author": "zhijiangW", "createdAt": "2020-04-05T16:00:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzc1NDgzNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403754836", "bodyText": "IMO, resources should be freed in finally regardless of exceptions declared in method signature.\nCurrently (#11507 PR), any exceptions are propagated, caught somewhere (as Exception) just to be wrapped and rethrown again.\nIn one case there is finally block freeing resources; but it must free them regardless of this call.\nSo, there will be no changes in the caller code if we use checked exceptions (except for some problems with lambdas).\nBut I see checked exceptions are used in many places in Flink so I'm also fine with this option.", "author": "rkhachatryan", "createdAt": "2020-04-05T20:46:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMDQwMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404730400", "bodyText": "Yes, I understand and agree with you points to some extent. It is indeed a bit trouble to carry the specific exception in many different components, and also for the case to wrapper it in most lambda cases.\nMy previous example was for forcing the caller to release resources within try...finally to pass compiling if we announce the exception explicitly in interface method. Otherwise some callers might not have the good habit to always release resources within finally region, especially in tests.\nAnother minor concern was that we only announce the IllegalArgumentException for interface methods, and actually hide the other IOException , InteruphttedException to wrapper implicitly. My guessing is that we think the IllegalArgumentException is more important to bring alerts for callers. :)", "author": "zhijiangW", "createdAt": "2020-04-07T11:17:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MDU2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402051308", "body": "rethrow() -> checkError(), because it is not determined to throw exception.", "bodyText": "rethrow() -> checkError(), because it is not determined to throw exception.", "bodyHTML": "<p dir=\"auto\">rethrow() -&gt; checkError(), because it is not determined to throw exception.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T04:56:22Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;\n+\tprivate final int maxCheckpoints;\n+\tprivate volatile boolean isRunning;\n+\tprivate volatile Exception thrown;\n+\n+\tpublic ChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory) {\n+\t\tthis(streamFactoryFactory, DEFAULT_MAX_CHECKPOINTS);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl} with {@link #DEFAULT_MAX_CHECKPOINTS} as {@link #maxCheckpoints}.\n+\t */\n+\tChannelStateWriterImpl(CheckpointStorageWorkerView streamFactoryFactory, int maxCheckpoints) {\n+\t\tthis(streamFactoryFactory, DEFAULT_HANDOVER_CAPACITY, new ChannelStateSerializerImpl(), maxCheckpoints);\n+\t}\n+\n+\t/**\n+\t * Creates a {@link ChannelStateWriterImpl}.\n+\t *\n+\t * @param maxCheckpoints maximum number of checkpoints to be written currently or finished but not taken yet.\n+\t */\n+\tChannelStateWriterImpl(\n+\t\t\tCheckpointStorageWorkerView streamFactory,\n+\t\t\tint handoverCapacity,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tint maxCheckpoints) {\n+\t\tthis.handover = new ArrayBlockingQueue<>(handoverCapacity);\n+\t\tthis.results = new ConcurrentHashMap<>(maxCheckpoints);\n+\t\tthis.maxCheckpoints = maxCheckpoints;\n+\t\tthis.asyncWriter = new Thread(new ProcessRequestsLoop(maxCheckpoints, streamFactory, serializer));\n+\t\tthis.isRunning = true;\n+\t}\n+\n+\t@Override\n+\tpublic void start(long checkpointId, CheckpointOptions checkpointOptions) {\n+\t\tLOG.debug(\"start checkpoint {} ({})\", checkpointId, checkpointOptions);\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning && asyncWriter.isAlive(), \"not running\");\n+\t\tChannelStateWriteResult result = new ChannelStateWriteResult();\n+\t\tChannelStateWriteResult put = results.computeIfAbsent(checkpointId, id -> {\n+\t\t\tPreconditions.checkArgument(results.size() < maxCheckpoints, \"results.size() > maxCheckpoints\", results.size(), maxCheckpoints);\n+\t\t\tenqueue(new CheckpointStartRequest(checkpointId, result, checkpointOptions.getTargetLocation()));\n+\t\t\treturn result;\n+\t\t});\n+\t\tPreconditions.checkArgument(put == result, \"result future already present for checkpoint id: \" + checkpointId);\n+\t}\n+\n+\t@Override\n+\tpublic void addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add input data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) {\n+\t\tLOG.debug(\"add output data, checkpoint id: {}, channel: {}, startSeqNum: {}, num buffers: {}\",\n+\t\t\tcheckpointId, info, startSeqNum, data == null ? 0 : data.length);\n+\t\tenqueue(write(checkpointId, info, checkBufferType(data)));\n+\t}\n+\n+\t@Override\n+\tpublic void finishInput(long checkpointId) {\n+\t\tLOG.debug(\"finish input data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeInput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic void finishOutput(long checkpointId) {\n+\t\tLOG.debug(\"finish output data, checkpoint id: {}\", checkpointId);\n+\t\tenqueue(completeOutput(checkpointId));\n+\t}\n+\n+\t@Override\n+\tpublic ChannelStateWriteResult getWriteResult(long checkpointId) {\n+\t\tLOG.debug(\"requested write result, checkpoint id: {}\", checkpointId);\n+\t\tChannelStateWriteResult result = results.remove(checkpointId);\n+\t\tPreconditions.checkArgument(result != null, \"channel state write result not found for checkpoint id \" + checkpointId);\n+\t\treturn result;\n+\t}\n+\n+\tpublic void open() {\n+\t\tPreconditions.checkState(isRunning);\n+\t\tasyncWriter.start();\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tisRunning = false;\n+\t\tresults.clear();\n+\t\tasyncWriter.interrupt();\n+\t\twhile (asyncWriter.isAlive()) {\n+\t\t\ttry {\n+\t\t\t\tasyncWriter.join();\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tif (!asyncWriter.isAlive()) {\n+\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t}\n+\t\t\t\tLOG.debug(\"interrupted while waiting for the writer thread to die\", e);\n+\t\t\t}\n+\t\t}\n+\t\trethrow();\n+\t}\n+\n+\tprivate void enqueue(ChannelStateWriteRequest request) {\n+\t\trethrow();\n+\t\tPreconditions.checkState(isRunning);\n+\t\ttry {\n+\t\t\thandover.put(request);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new RuntimeException(\"Interrupted while trying to add new handover request\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void rethrow() {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MjA1MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402282050", "bodyText": "checkError() sounds ambiguously to me.\nHow about rethrowIfAny()?", "author": "rkhachatryan", "createdAt": "2020-04-02T12:42:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyMjQ2Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402422467", "bodyText": "That is fine for me. I only referred to the way in InputChannel#checkError. :)", "author": "zhijiangW", "createdAt": "2020-04-02T15:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA1MTMwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzA1Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402063057", "body": "I am wondering it might have the possibility to add a request after clearing it, to make the new added one never removed.\r\nE.g. \r\nthread 1: `#enqueue` to execute `rethrow` and `thrown` is null atm\r\nthread 2: set `thrown = ex` and clear the `handover` as above\r\nthread 1: `#enqueue` to execute `handover#put`\r\n", "bodyText": "I am wondering it might have the possibility to add a request after clearing it, to make the new added one never removed.\nE.g.\nthread 1: #enqueue to execute rethrow and thrown is null atm\nthread 2: set thrown = ex and clear the handover as above\nthread 1: #enqueue to execute handover#put", "bodyHTML": "<p dir=\"auto\">I am wondering it might have the possibility to add a request after clearing it, to make the new added one never removed.<br>\nE.g.<br>\nthread 1: <code>#enqueue</code> to execute <code>rethrow</code> and <code>thrown</code> is null atm<br>\nthread 2: set <code>thrown = ex</code> and clear the <code>handover</code> as above<br>\nthread 1: <code>#enqueue</code> to execute <code>handover#put</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T05:40:58Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3MDgxMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404370811", "bodyText": "You're right, it's a race condition, thanks for pointing out.\nI've added a cleanup call after adding to the queue.", "author": "rkhachatryan", "createdAt": "2020-04-06T20:34:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzA1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2MzU2OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402063568", "body": "It is weird to give a `RuntimeException` for the normal end. The `requestProcessor.cleanup` should allow a nullable exception.", "bodyText": "It is weird to give a RuntimeException for the normal end. The requestProcessor.cleanup should allow a nullable exception.", "bodyHTML": "<p dir=\"auto\">It is weird to give a <code>RuntimeException</code> for the normal end. The <code>requestProcessor.cleanup</code> should allow a nullable exception.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T05:42:55Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2NDg2MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402064861", "body": "what is the consideration to swallow the `InterruptedException` in this case. Do we want to exit this thread early when encountering `InterruptedException`? Also `LOG.warn` instead?", "bodyText": "what is the consideration to swallow the InterruptedException in this case. Do we want to exit this thread early when encountering InterruptedException? Also LOG.warn instead?", "bodyHTML": "<p dir=\"auto\">what is the consideration to swallow the <code>InterruptedException</code> in this case. Do we want to exit this thread early when encountering <code>InterruptedException</code>? Also <code>LOG.warn</code> instead?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T05:47:29Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2NDUwMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404364502", "bodyText": "AFAIK, one possible reason for InterruptedException is \"spurious wakeups\".\nHere, the \"right\" way to interrupt worker thread is to first set isRunning to false and then interrupt.\nSo if after the interrupt isRunning is true then it's a spurious wakeup and thread continues.", "author": "rkhachatryan", "createdAt": "2020-04-06T20:22:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA2NDg2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NDEzNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402094134", "body": "If we confirm this map has concurrent issues, then it should be defined as `ConcurrentHashMap` explicitly.", "bodyText": "If we confirm this map has concurrent issues, then it should be defined as ConcurrentHashMap explicitly.", "bodyHTML": "<p dir=\"auto\">If we confirm this map has concurrent issues, then it should be defined as <code>ConcurrentHashMap</code> explicitly.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:05:20Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriterImpl.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+import java.util.Map;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeInput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.completeOutput;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateWriteRequest.write;\n+\n+/**\n+ * {@link ChannelStateWriter} implemented using\n+ * {@link CheckpointStreamFactory.CheckpointStateOutputStream CheckpointStateOutputStreams}. Internally, it has\n+ * <ul>\n+ * <li>one stream per checkpoint; having multiple streams would mean more files written and more connections opened\n+ * (and more latency on restore)</li>\n+ * <li>one thread; having multiple threads means more connections, couples with the implementation and increases complexity</li>\n+ * </ul>\n+ */\n+@Internal\n+@ThreadSafe\n+public class ChannelStateWriterImpl implements ChannelStateWriter {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriterImpl.class);\n+\tprivate static final int DEFAULT_HANDOVER_CAPACITY = 10;\n+\tprivate static final int DEFAULT_MAX_CHECKPOINTS = 5; // currently, only single in-flight checkpoint is supported\n+\n+\tprivate class ProcessRequestsLoop implements Runnable {\n+\t\tprivate final ChannelStateWriteRequestProcessor requestProcessor;\n+\n+\t\tprivate ProcessRequestsLoop(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\t\tthis.requestProcessor = new ChannelStateWriteRequestProcessor(maxCheckpoints, streamFactoryFactory, serializer);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void run() {\n+\t\t\ttry {\n+\t\t\t\tloop();\n+\t\t\t} catch (Exception ex) {\n+\t\t\t\tthrown = ex;\n+\t\t\t} finally {\n+\t\t\t\thandover.clear();\n+\t\t\t\trequestProcessor.cleanup(thrown != null ? thrown : new RuntimeException(\"loop terminated, isRunning: \" + isRunning));\n+\t\t\t}\n+\t\t\tLOG.debug(\"loop terminated\");\n+\t\t}\n+\n+\t\tprivate void loop() throws Exception {\n+\t\t\twhile (isRunning || !handover.isEmpty()) {\n+\t\t\t\ttry {\n+\t\t\t\t\trequestProcessor.processRequest(handover.take());\n+\t\t\t\t} catch (InterruptedException e) {\n+\t\t\t\t\tif (isRunning || !handover.isEmpty()) {\n+\t\t\t\t\t\tLOG.info(\"interrupted while waiting for an item (continue waiting)\", e);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate final Thread asyncWriter;\n+\tprivate final BlockingQueue<ChannelStateWriteRequest> handover;\n+\tprivate final Map<Long, ChannelStateWriteResult> results;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg5MzIyOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r403893229", "bodyText": "Yes, I'll change it, thanks (I believe you meant ConcurrentMap not ConcurrentHashMap).", "author": "rkhachatryan", "createdAt": "2020-04-06T07:51:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NDEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NjE0Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402096143", "body": "nit: checkNotNull for two arguments", "bodyText": "nit: checkNotNull for two arguments", "bodyHTML": "<p dir=\"auto\">nit: checkNotNull for two arguments</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:09:41Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;\n+\t\tthis.serializer = serializer;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NzAwNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402097005", "body": "ditto: weird naming for me", "bodyText": "ditto: weird naming for me", "bodyHTML": "<p dir=\"auto\">ditto: weird naming for me</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:11:37Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequestProcessor.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * Maintains a set of {@link ChannelStateCheckpointWriter writers} per checkpoint and translates incoming\n+ * {@link ChannelStateWriteRequest requests} to their corresponding methods.\n+ */\n+final class ChannelStateWriteRequestProcessor {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateWriteRequestProcessor.class);\n+\n+\tprivate final Map<Long, ChannelStateCheckpointWriter> writers; // limited indirectly by results max size\n+\tprivate final CheckpointStorageWorkerView streamFactoryFactory;\n+\tprivate final ChannelStateSerializer serializer;\n+\n+\tChannelStateWriteRequestProcessor(int maxCheckpoints, CheckpointStorageWorkerView streamFactoryFactory, ChannelStateSerializer serializer) {\n+\t\tthis.writers = new HashMap<>(maxCheckpoints);\n+\t\tthis.streamFactoryFactory = streamFactoryFactory;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMjExMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402102112", "body": "I suggest removing this constructor to avoid introducing multiple constructors to maintain, except for easing tests purpose. But here is not that case. ", "bodyText": "I suggest removing this constructor to avoid introducing multiple constructors to maintain, except for easing tests purpose. But here is not that case.", "bodyHTML": "<p dir=\"auto\">I suggest removing this constructor to avoid introducing multiple constructors to maintain, except for easing tests purpose. But here is not that case.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:22:23Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwMzkyNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402103925", "body": "nit: better to keep the sequence as above arguments", "bodyText": "nit: better to keep the sequence as above arguments", "bodyHTML": "<p dir=\"auto\">nit: better to keep the sequence as above arguments</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:25:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwNzg5Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402107896", "body": "nit: it is weird for me to emphasis `flinkBuffers`, `buffers` should be ok.", "bodyText": "nit: it is weird for me to emphasis flinkBuffers, buffers should be ok.", "bodyHTML": "<p dir=\"auto\">nit: it is weird for me to emphasis <code>flinkBuffers</code>, <code>buffers</code> should be ok.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:33:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODEwMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402108103", "body": "nit: checkNotNull", "bodyText": "nit: checkNotNull", "bodyHTML": "<p dir=\"auto\">nit: checkNotNull</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:34:13Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeInput(info, flinkBuffers));\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeOutput(info, flinkBuffers));\n+\t}\n+}\n+\n+final class CheckpointStartRequest extends ChannelStateWriteRequest {\n+\tfinal ChannelStateWriteResult targetResult;\n+\tfinal CheckpointStorageLocationReference locationReference;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tsuper(checkpointId);\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEwODIyNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402108225", "body": "ditto: checkNotNull", "bodyText": "ditto: checkNotNull", "bodyHTML": "<p dir=\"auto\">ditto: checkNotNull</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:34:30Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriteRequest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.CheckpointStorageLocationReference;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+abstract class ChannelStateWriteRequest {\n+\tfinal long checkpointId;\n+\n+\tChannelStateWriteRequest(long checkpointId) {\n+\t\tthis.checkpointId = checkpointId;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn getClass().getSimpleName() + \", checkpointId=\" + checkpointId;\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeInput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeInput);\n+\t}\n+\n+\tstatic CheckpointInProgressRequest completeOutput(long checkpointId) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, ChannelStateCheckpointWriter::completeOutput);\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, InputChannelInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeInput(info, flinkBuffers));\n+\t}\n+\n+\tstatic ChannelStateWriteRequest write(long checkpointId, ResultSubpartitionInfo info, Buffer... flinkBuffers) {\n+\t\treturn new CheckpointInProgressRequest(checkpointId, writer -> writer.writeOutput(info, flinkBuffers));\n+\t}\n+}\n+\n+final class CheckpointStartRequest extends ChannelStateWriteRequest {\n+\tfinal ChannelStateWriteResult targetResult;\n+\tfinal CheckpointStorageLocationReference locationReference;\n+\n+\tCheckpointStartRequest(long checkpointId, ChannelStateWriteResult targetResult, CheckpointStorageLocationReference locationReference) {\n+\t\tsuper(checkpointId);\n+\t\tthis.targetResult = targetResult;\n+\t\tthis.locationReference = locationReference;\n+\t}\n+}\n+\n+final class CheckpointInProgressRequest extends ChannelStateWriteRequest {\n+\tfinal ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action;\n+\n+\tCheckpointInProgressRequest(long checkpointId, ThrowingConsumer<ChannelStateCheckpointWriter, Exception> action) {\n+\t\tsuper(checkpointId);\n+\t\tthis.action = action;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExNTA2MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402115061", "body": "nit: r -> runnable", "bodyText": "nit: r -> runnable", "bodyHTML": "<p dir=\"auto\">nit: r -&gt; runnable</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:47:39Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));\n+\t\t\tcomplete(\n+\t\t\t\tresult.resultSubpartitionStateHandles,\n+\t\t\t\tresultSubpartitionOffsets,\n+\t\t\t\t(chan, offsets) -> new ResultSubpartitionStateHandle(chan, underlying, offsets));\n+\t\t}\n+\t}\n+\n+\tprivate <I, H extends AbstractChannelStateHandle<I>> void complete(\n+\t\tCompletableFuture<Collection<H>> future,\n+\t\tMap<I, List<Long>> offsets,\n+\t\tBiFunction<I, List<Long>, H> buildHandle) {\n+\t\tfinal Collection<H> handles = new ArrayList<>();\n+\t\tfor (Map.Entry<I, List<Long>> e : offsets.entrySet()) {\n+\t\t\thandles.add(buildHandle.apply(e.getKey(), e.getValue()));\n+\t\t}\n+\t\tfuture.complete(handles);\n+\t\tLOG.debug(\"channel state write completed, checkpointId: {}, handles: {}\", checkpointId, handles);\n+\t}\n+\n+\tprivate void runWithChecks(RunnableWithException r) throws Exception {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEyMDE2Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402120167", "body": "chan -> info?", "bodyText": "chan -> info?", "bodyHTML": "<p dir=\"auto\">chan -&gt; info?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T07:55:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMTg0Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402131847", "body": "chan -> info?", "bodyText": "chan -> info?", "bodyHTML": "<p dir=\"auto\">chan -&gt; info?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T08:17:02Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateCheckpointWriter.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter.ChannelStateWriteResult;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory.CheckpointStateOutputStream;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.RunnableWithException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiFunction;\n+\n+import static org.apache.flink.runtime.state.CheckpointedStateScope.EXCLUSIVE;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Writes channel state for a specific checkpoint-subtask-attempt triple.\n+ */\n+@NotThreadSafe\n+class ChannelStateCheckpointWriter {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(ChannelStateCheckpointWriter.class);\n+\n+\tprivate final DataOutputStream dataStream;\n+\tprivate final CheckpointStateOutputStream checkpointStream;\n+\tprivate final ChannelStateWriteResult result;\n+\tprivate final Map<InputChannelInfo, List<Long>> inputChannelOffsets = new HashMap<>();\n+\tprivate final Map<ResultSubpartitionInfo, List<Long>> resultSubpartitionOffsets = new HashMap<>();\n+\tprivate final ChannelStateSerializer serializer;\n+\tprivate final long checkpointId;\n+\tprivate boolean inputCompleted = false;\n+\tprivate boolean outputCompleted = false;\n+\tprivate final Runnable onComplete;\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tCheckpointStartRequest startCheckpointItem,\n+\t\t\tCheckpointStreamFactory streamFactory,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(startCheckpointItem.checkpointId, startCheckpointItem.targetResult, streamFactory.createCheckpointStateOutputStream(EXCLUSIVE), serializer, onComplete);\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tCheckpointStateOutputStream stream,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete) throws Exception {\n+\t\tthis(checkpointId, result, serializer, onComplete, stream, new DataOutputStream(stream));\n+\t}\n+\n+\tChannelStateCheckpointWriter(\n+\t\t\tlong checkpointId,\n+\t\t\tChannelStateWriteResult result,\n+\t\t\tChannelStateSerializer serializer,\n+\t\t\tRunnable onComplete,\n+\t\t\tCheckpointStateOutputStream checkpointStateOutputStream,\n+\t\t\tDataOutputStream dataStream) throws Exception {\n+\t\tthis.checkpointId = checkpointId;\n+\t\tthis.result = checkNotNull(result);\n+\t\tthis.checkpointStream = checkNotNull(checkpointStateOutputStream);\n+\t\tthis.serializer = checkNotNull(serializer);\n+\t\tthis.dataStream = checkNotNull(dataStream);\n+\t\tthis.onComplete = checkNotNull(onComplete);\n+\t\trunWithChecks(() -> serializer.writeHeader(dataStream));\n+\t}\n+\n+\tvoid writeInput(InputChannelInfo info, Buffer... flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!inputCompleted);\n+\t\twrite(inputChannelOffsets, info, flinkBuffers);\n+\t}\n+\n+\tvoid writeOutput(ResultSubpartitionInfo info, Buffer[] flinkBuffers) throws Exception {\n+\t\tPreconditions.checkState(!outputCompleted);\n+\t\twrite(resultSubpartitionOffsets, info, flinkBuffers);\n+\t}\n+\n+\tprivate <K> void write(Map<K, List<Long>> offsets, K key, Buffer[] flinkBuffers) throws Exception {\n+\t\trunWithChecks(() -> {\n+\t\t\ttry {\n+\t\t\t\toffsets\n+\t\t\t\t\t.computeIfAbsent(key, unused -> new ArrayList<>())\n+\t\t\t\t\t.add(checkpointStream.getPos());\n+\t\t\t\tserializer.writeData(dataStream, flinkBuffers);\n+\t\t\t} finally {\n+\t\t\t\tfor (Buffer flinkBuffer : flinkBuffers) {\n+\t\t\t\t\tflinkBuffer.recycleBuffer();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\t}\n+\n+\tvoid completeInput() throws Exception {\n+\t\tLOG.debug(\"complete input, output completed: {}\", outputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!inputCompleted);\n+\t\t\tinputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tvoid completeOutput() throws Exception {\n+\t\tLOG.debug(\"complete output, input completed: {}\", inputCompleted);\n+\t\trunWithChecks(() -> {\n+\t\t\tPreconditions.checkState(!outputCompleted);\n+\t\t\toutputCompleted = true;\n+\t\t\tcomplete();\n+\t\t});\n+\t}\n+\n+\tprivate void complete() throws IOException {\n+\t\tif (inputCompleted && outputCompleted) {\n+\t\t\tonComplete.run();\n+\t\t\tdataStream.flush();\n+\t\t\tStreamStateHandle underlying = checkpointStream.closeAndGetHandle();\n+\t\t\tcomplete(\n+\t\t\t\tresult.inputChannelStateHandles,\n+\t\t\t\tinputChannelOffsets,\n+\t\t\t\t(chan, offsets) -> new InputChannelStateHandle(chan, underlying, offsets));", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjEzMzUxNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402133516", "body": "nit: `i, r` give some meaningful names and split the arguments in separate line.", "bodyText": "nit: i, r give some meaningful names and split the arguments in separate line.", "bodyHTML": "<p dir=\"auto\">nit: <code>i, r</code> give some meaningful names and split the arguments in separate line.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T08:20:05Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -18,19 +18,51 @@\n package org.apache.flink.runtime.checkpoint.channel;\n \n import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n import org.apache.flink.runtime.io.network.buffer.Buffer;\n-import org.apache.flink.runtime.state.StateObject;\n+import org.apache.flink.runtime.state.InputChannelStateHandle;\n+import org.apache.flink.runtime.state.ResultSubpartitionStateHandle;\n \n+import java.io.Closeable;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.Future;\n \n /**\n  * Writes channel state during checkpoint/savepoint.\n  */\n @Internal\n-public interface ChannelStateWriter extends AutoCloseable {\n+public interface ChannelStateWriter extends Closeable {\n+\n+\t/**\n+\t * Channel state write result.\n+\t */\n+\tclass ChannelStateWriteResult {\n+\t\tfinal CompletableFuture<Collection<InputChannelStateHandle>> inputChannelStateHandles;\n+\t\tfinal CompletableFuture<Collection<ResultSubpartitionStateHandle>> resultSubpartitionStateHandles;\n+\n+\t\tChannelStateWriteResult() {\n+\t\t\tthis(new CompletableFuture<>(), new CompletableFuture<>());\n+\t\t}\n+\n+\t\tChannelStateWriteResult(CompletableFuture<Collection<InputChannelStateHandle>> i, CompletableFuture<Collection<ResultSubpartitionStateHandle>> r) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwMjI0Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402202242", "body": "@VisibleForTesting", "bodyText": "@VisibleForTesting", "bodyHTML": "<p dir=\"auto\"><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/VisibleForTesting/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/VisibleForTesting\">@VisibleForTesting</a></p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:12:41Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402205044", "body": "we can pass class field `inputChannelHandleReaders` directly  in below `addReaders` to avoid temporary variables.", "bodyText": "we can pass class field inputChannelHandleReaders directly  in below addReaders to avoid temporary variables.", "bodyHTML": "<p dir=\"auto\">we can pass class field <code>inputChannelHandleReaders</code> directly  in below <code>addReaders</code> to avoid temporary variables.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:17:55Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4NDE2Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404184162", "bodyText": "The consideration here is concurrency: the maps constructed here are read and cleared in close() potentially by another thread.\nSo we need a memory barrier after construction to make the change visible to this thread.\nThis barrier is a write to final variables here.\nI'll add a comment about it.", "author": "rkhachatryan", "createdAt": "2020-04-06T15:31:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcyMDk4MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404720981", "bodyText": "I guess you are indicating the concurrent issue. Before the constructor is finished, some other threads might access intermediate inputChannelHandleReaders and resultSubpartitionHandleReaders.\nIf so, it seems not valid because no one can get and reference ChannelStateReaderImpl before the constructor finishes. In real codes, the constructing is done before creating Task by RPC thread, then no one would reference it to read or close until it is created to pass into task class.\nAnyway it is not big issue on my side, just to clarify the consideration.", "author": "zhijiangW", "createdAt": "2020-04-07T10:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc2MzA5Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404763097", "bodyText": "No, I meant that  after construction, the instance can be accessed by other threads.\nAnd AFAIK there is no memory barrier after constructor by default.\nSo without temporary variables, the only guarantee is that inputChannelHandleReaders points to a map, but not about contents of that map.", "author": "rkhachatryan", "createdAt": "2020-04-07T12:18:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NDYyOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404984628", "bodyText": "As long as you are not handing out this directly or indirectly, constructor should be atomic in terms of memory synchronization. No other thread can see this instance of ChannelStateReaderImpl and find any inconsistent state.\nChannelStateReaderImpl reader = new ChannelStateReaderImpl(...);\nreader.... // <- at this point all maps are good", "author": "AHeise", "createdAt": "2020-04-07T17:26:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTA5OTcwOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r405099708", "bodyText": "From JLS:\n\nAn object is considered to be completely initialized when its constructor finishes. A thread\nthat can only see a reference to an object after that object has been completely initialized is\nguaranteed to see the correctly initialized values for that object's final fields.\n\nI read it as \"you have no guarantee about non-final fields\". Which means there is no barrier in the end of the constructor.", "author": "rkhachatryan", "createdAt": "2020-04-07T20:42:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTA0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNTI1NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402205255", "body": "too long line, should split line for arguments", "bodyText": "too long line, should split line for arguments", "bodyHTML": "<p dir=\"auto\">too long line, should split line for arguments</p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:18:16Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIwNzA2OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402207068", "body": "nit: bufferBuilder -> buffer:", "bodyText": "nit: bufferBuilder -> buffer:", "bodyHTML": "<p dir=\"auto\">nit: bufferBuilder -&gt; buffer:</p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:21:41Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxNTU3MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402215570", "body": "nit: checkNotNull", "bodyText": "nit: checkNotNull", "bodyHTML": "<p dir=\"auto\">nit: checkNotNull</p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:36:38Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxNjk3MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402216971", "body": "Better to give some descriptions for these fields for better understanding, especially for `rem`.", "bodyText": "Better to give some descriptions for these fields for better understanding, especially for rem.", "bodyHTML": "<p dir=\"auto\">Better to give some descriptions for these fields for better understanding, especially for <code>rem</code>.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:39:16Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODI5Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402218297", "body": "nit: What is it indicating for : `Single-use`.", "bodyText": "nit: What is it indicating for : Single-use.", "bodyHTML": "<p dir=\"auto\">nit: What is it indicating for : <code>Single-use</code>.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:42:03Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4OTMxMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404189311", "bodyText": "I meant that once all data was read, the reader can't be used anymore (updated Javadoc).", "author": "rkhachatryan", "createdAt": "2020-04-06T15:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODI5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODY3Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402218677", "body": "should be clear for `TODO`", "bodyText": "should be clear for TODO", "bodyHTML": "<p dir=\"auto\">should be clear for <code>TODO</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T10:42:46Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4Nzk2Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404187962", "bodyText": "Removed todo", "author": "rkhachatryan", "createdAt": "2020-04-06T15:35:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIxODY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MzkxNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402253915", "body": "I guess we can get ride of `pos` field to only judge `rem <= 0` to advance offset. If so we can also avoid return `tuple2` in `serializer.readLength(stream)`", "bodyText": "I guess we can get ride of pos field to only judge rem <= 0 to advance offset. If so we can also avoid return tuple2 in serializer.readLength(stream)", "bodyHTML": "<p dir=\"auto\">I guess we can get ride of <code>pos</code> field to only judge <code>rem &lt;= 0</code> to advance offset. If so we can also avoid return <code>tuple2</code> in <code>serializer.readLength(stream)</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T11:53:00Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateStreamReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+\n+import static java.lang.Math.addExact;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateByteBuffer.wrap;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.HAS_MORE_DATA;\n+import static org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult.NO_MORE_DATA;\n+\n+/**\n+ * Reads the state of a single channel pointed by {@link org.apache.flink.runtime.state.AbstractChannelStateHandle AbstractChannelStateHandle}.\n+ * Single-use.\n+ * Uses {@link RefCountingFSDataInputStream} internally.\n+ */\n+@NotThreadSafe\n+class ChannelStateStreamReader implements Closeable {\n+\n+\tprivate final RefCountingFSDataInputStream stream; // todo: buffer?\n+\tprivate final Queue<Long> offsets;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate long pos = -1;\n+\tprivate int rem;\n+\tprivate boolean closed = false;\n+\n+\tChannelStateStreamReader(AbstractChannelStateHandle<?> handle, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tthis(streamFactory.forHandle(handle), handle.getOffsets(), streamFactory.getSerializer());\n+\t}\n+\n+\tprivate ChannelStateStreamReader(RefCountingFSDataInputStream stream, List<Long> offsets, ChannelStateDeserializer serializer) {\n+\t\tthis.stream = stream;\n+\t\tthis.stream.incNumReaders();\n+\t\tthis.serializer = serializer;\n+\t\tthis.offsets = new LinkedList<>(offsets);\n+\t}\n+\n+\tReadResult readInto(Buffer buffer) throws IOException {\n+\t\treturn readInto(wrap(buffer));\n+\t}\n+\n+\tReadResult readInto(BufferBuilder bufferBuilder) throws IOException {\n+\t\treturn readInto(wrap(bufferBuilder));\n+\t}\n+\n+\tprivate ReadResult readInto(ChannelStateByteBuffer buffer) throws IOException {\n+\t\tPreconditions.checkState(!closed, \"reader is closed\");\n+\t\treadWhilePossible(buffer);\n+\t\tif (haveMoreData()) {\n+\t\t\treturn HAS_MORE_DATA;\n+\t\t} else {\n+\t\t\tclose();\n+\t\t\treturn NO_MORE_DATA;\n+\t\t}\n+\t}\n+\n+\tprivate void readWhilePossible(ChannelStateByteBuffer buffer) throws IOException {\n+\t\twhile (haveMoreData() && buffer.isWritable()) {\n+\t\t\tif (pos < 0 || rem <= 0) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIyOTQwMg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404229402", "bodyText": "That's a good simplification, thanks!", "author": "rkhachatryan", "createdAt": "2020-04-06T16:33:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1MzkxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1NzkwNg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402257906", "body": "nit: i think it is better to place the factory class at the bottom of this class", "bodyText": "nit: i think it is better to place the factory class at the bottom of this class", "bodyHTML": "<p dir=\"auto\">nit: i think it is better to place the factory class at the bottom of this class</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:00:17Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI1ODE5Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402258193", "body": "too long line for splitting the arguments", "bodyText": "too long line for splitting the arguments", "bodyHTML": "<p dir=\"auto\">too long line for splitting the arguments</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:00:49Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NjE1Mg==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402266152", "body": "nit: `incRef` seems more fit into the class name. also `numReaders` -> `refCounter`", "bodyText": "nit: incRef seems more fit into the class name. also numReaders -> refCounter", "bodyHTML": "<p dir=\"auto\">nit: <code>incRef</code> seems more fit into the class name. also <code>numReaders</code> -&gt; <code>refCounter</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:15:30Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {\n+\t\tthis.streamSupplier = streamSupplier;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid incNumReaders() {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2NzA5NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402267095", "body": "nit: desired -> pos", "bodyText": "nit: desired -> pos", "bodyHTML": "<p dir=\"auto\">nit: desired -&gt; pos</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:17:18Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);\n+\t\t\t}\n+\t\t\treturn stream;\n+\t\t}\n+\n+\t\tChannelStateDeserializer getSerializer() {\n+\t\t\treturn serializer;\n+\t\t}\n+\t}\n+\n+\tprivate enum State {NEW, OPENED, CLOSED}\n+\n+\tprivate final SupplierWithException<FSDataInputStream, IOException> streamSupplier;\n+\tprivate FSDataInputStream stream;\n+\tprivate final ChannelStateDeserializer serializer;\n+\tprivate int numReaders = 0;\n+\tprivate State state = State.NEW;\n+\n+\tprivate RefCountingFSDataInputStream(SupplierWithException<FSDataInputStream, IOException> streamSupplier, ChannelStateDeserializer serializer) {\n+\t\tthis.streamSupplier = streamSupplier;\n+\t\tthis.serializer = serializer;\n+\t}\n+\n+\tvoid incNumReaders() {\n+\t\tcheckNotClosed();\n+\t\tnumReaders++;\n+\t}\n+\n+\tvoid decNumReaders() throws IOException {\n+\t\tcheckNotClosed();\n+\t\tnumReaders--;\n+\t\tif (numReaders == 0) {\n+\t\t\tclose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic int read() throws IOException {\n+\t\tensureOpen();\n+\t\treturn stream.read();\n+\t}\n+\n+\t@Override\n+\tpublic void seek(long desired) throws IOException {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI2OTc5Mw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402269793", "body": "map -> streams", "bodyText": "map -> streams", "bodyHTML": "<p dir=\"auto\">map -&gt; streams</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:21:50Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MDIyNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402270225", "body": "nit: checkNotNull", "bodyText": "nit: checkNotNull", "bodyHTML": "<p dir=\"auto\">nit: checkNotNull</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:22:30Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3MjU3NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402272574", "body": "forHandle->create/buildInputStream", "bodyText": "forHandle->create/buildInputStream", "bodyHTML": "<p dir=\"auto\">forHandle-&gt;create/buildInputStream</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:25:53Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NTU2OQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402275569", "body": "Will one state handle be read multiple times, so we need a map to avoid opening it multiple times?", "bodyText": "Will one state handle be read multiple times, so we need a map to avoid opening it multiple times?", "bodyHTML": "<p dir=\"auto\">Will one state handle be read multiple times, so we need a map to avoid opening it multiple times?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:30:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RefCountingFSDataInputStream.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.core.fs.FSDataInputStream;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.runtime.state.StreamStateHandle;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.SupplierWithException;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+@NotThreadSafe\n+class RefCountingFSDataInputStream extends FSDataInputStream {\n+\n+\t@NotThreadSafe\n+\tstatic class RefCountingFSDataInputStreamFactory {\n+\t\tprivate final Map<StreamStateHandle, RefCountingFSDataInputStream> map = new HashMap<>(); // not clearing: expecting short life\n+\t\tprivate final ChannelStateDeserializer serializer;\n+\n+\t\tRefCountingFSDataInputStreamFactory(ChannelStateDeserializer serializer) {\n+\t\t\tthis.serializer = serializer;\n+\t\t}\n+\n+\t\t<T> RefCountingFSDataInputStream forHandle(AbstractChannelStateHandle<T> handle) {\n+\t\t\tStreamStateHandle streamStateHandle = handle.getDelegate();\n+\t\t\tRefCountingFSDataInputStream stream = map.get(streamStateHandle);\n+\t\t\tif (stream == null) {\n+\t\t\t\tstream = new RefCountingFSDataInputStream(streamStateHandle::openInputStream, serializer);\n+\t\t\t\tmap.put(streamStateHandle, stream);", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNTY3OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404235678", "bodyText": "Yes, this is what map for.", "author": "rkhachatryan", "createdAt": "2020-04-06T16:43:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NTU2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI3NjU5OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402276598", "body": "#start misses one argument", "bodyText": "#start misses one argument", "bodyHTML": "<p dir=\"auto\">#start misses one argument</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:32:51Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402281766", "body": "we can use the following for simple:\r\n```\r\nIOUtils.closeAll(inputChannelHandleReaders.values());\r\nIOUtils.closeAll(resultSubpartitionHandleReaders.values());\r\n```", "bodyText": "we can use the following for simple:\nIOUtils.closeAll(inputChannelHandleReaders.values());\nIOUtils.closeAll(resultSubpartitionHandleReaders.values());", "bodyHTML": "<p dir=\"auto\">we can use the following for simple:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"IOUtils.closeAll(inputChannelHandleReaders.values());\nIOUtils.closeAll(resultSubpartitionHandleReaders.values());\n\"><pre><code>IOUtils.closeAll(inputChannelHandleReaders.values());\nIOUtils.closeAll(resultSubpartitionHandleReaders.values());\n</code></pre></div>", "author": "zhijiangW", "createdAt": "2020-04-02T12:41:39Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateReaderImpl.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;\n+import org.apache.flink.runtime.checkpoint.TaskStateSnapshot;\n+import org.apache.flink.runtime.checkpoint.channel.RefCountingFSDataInputStream.RefCountingFSDataInputStreamFactory;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.state.AbstractChannelStateHandle;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link ChannelStateReader} implementation. Usage considerations:\n+ * <ol>\n+ *     <li>state of a channel can be read once per instance of this class; once done it returns\n+ *     {@link org.apache.flink.runtime.checkpoint.channel.ChannelStateReader.ReadResult#NO_MORE_DATA NO_MORE_DATA}</li>\n+ *     <li>reader/writer indices of the passed buffer are respected and updated</li>\n+ *     <li>buffers must be prepared (cleared) before passing to reader</li>\n+ *     <li>buffers must be released after use</li>\n+ * </ol>\n+ */\n+@NotThreadSafe\n+@Internal\n+public class ChannelStateReaderImpl implements ChannelStateReader {\n+\tprivate static final Logger log = LoggerFactory.getLogger(ChannelStateReaderImpl.class);\n+\n+\tprivate final Map<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReaders;\n+\tprivate final Map<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReaders;\n+\n+\tpublic ChannelStateReaderImpl(TaskStateSnapshot snapshot) {\n+\t\tthis(snapshot, new ChannelStateSerializerImpl());\n+\t}\n+\n+\t@SuppressWarnings(\"WeakerAccess\")\n+\tChannelStateReaderImpl(TaskStateSnapshot snapshot, ChannelStateDeserializer serializer) {\n+\t\tRefCountingFSDataInputStreamFactory streamFactory = new RefCountingFSDataInputStreamFactory(serializer);\n+\t\tfinal HashMap<InputChannelInfo, ChannelStateStreamReader> inputChannelHandleReadersTmp = new HashMap<>();\n+\t\tfinal HashMap<ResultSubpartitionInfo, ChannelStateStreamReader> resultSubpartitionHandleReadersTmp = new HashMap<>();\n+\t\tfor (Map.Entry<OperatorID, OperatorSubtaskState> e : snapshot.getSubtaskStateMappings()) {\n+\t\t\taddReaders(inputChannelHandleReadersTmp, e.getValue().getInputChannelState(), streamFactory);\n+\t\t\taddReaders(resultSubpartitionHandleReadersTmp, e.getValue().getResultSubpartitionState(), streamFactory);\n+\t\t}\n+\t\tinputChannelHandleReaders = inputChannelHandleReadersTmp;\n+\t\tresultSubpartitionHandleReaders = resultSubpartitionHandleReadersTmp;\n+\t}\n+\n+\tprivate <T> void addReaders(Map<T, ChannelStateStreamReader> readerMap, Collection<? extends AbstractChannelStateHandle<T>> handles, RefCountingFSDataInputStreamFactory streamFactory) {\n+\t\tfor (AbstractChannelStateHandle<T> handle : handles) {\n+\t\t\tcheckState(!readerMap.containsKey(handle.getInfo()), \"multiple states exist for channel: \" + handle.getInfo());\n+\t\t\treaderMap.put(handle.getInfo(), new ChannelStateStreamReader(handle, streamFactory));\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readInputData(InputChannelInfo info, Buffer buffer) throws IOException {\n+\t\tlog.debug(\"readInputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, buffer);\n+\t\treturn getReader(info, inputChannelHandleReaders).readInto(buffer);\n+\t}\n+\n+\t@Override\n+\tpublic ReadResult readOutputData(ResultSubpartitionInfo info, BufferBuilder bufferBuilder) throws IOException {\n+\t\tlog.debug(\"readOutputData, resultSubpartitionInfo: {} , bufferBuilder {}\", info, bufferBuilder);\n+\t\treturn getReader(info, resultSubpartitionHandleReaders).readInto(bufferBuilder);\n+\t}\n+\n+\tprivate <K> ChannelStateStreamReader getReader(K info, Map<K, ChannelStateStreamReader> readerMap) {\n+\t\tPreconditions.checkArgument(readerMap.containsKey(info), String.format(\"unknown channel %s. Known channels: %s\", info, readerMap.keySet()));\n+\t\treturn readerMap.get(info);\n+\t}\n+\n+\t@Override\n+\tpublic void close() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0NTY0Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404245646", "bodyText": "Each of these two actions can still throw an exception; if both throw then one should be suppressed. This logic to handle that seems more complex to me than nested loops in try.", "author": "rkhachatryan", "createdAt": "2020-04-06T16:58:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU5NzcxOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404597718", "bodyText": "Yes, you are right.\nMy previous concern was whether it is proper way to rely on shaded.guava18 for this purpose (I am not quite sure). And we already introduced many basic functions in IOUtils for the similar usages. If the current option might also be widely used in other places, maybe it is worth the efforts to also be covered by IOUtils.", "author": "zhijiangW", "createdAt": "2020-04-07T07:35:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NTI1MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404985250", "bodyText": "Afaik it's fine to use guava now and I recommend to use Closer for all close-related, non-trivial operations.", "author": "AHeise", "createdAt": "2020-04-07T17:27:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MTc2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4MjYyNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402282625", "body": "ditto: flinkBuffers", "bodyText": "ditto: flinkBuffers", "bodyHTML": "<p dir=\"auto\">ditto: flinkBuffers</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:43:05Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI4NTgzNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402285834", "body": "nit: final", "bodyText": "nit: final", "bodyHTML": "<p dir=\"auto\">nit: final</p>", "author": "zhijiangW", "createdAt": "2020-04-02T12:48:27Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjM4OTc4NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402389785", "body": "`upToBytes` -> `bytesToRead` to be consistent with above `ChannelStateByteBuffer wrap(Buffer buffer)`", "bodyText": "upToBytes -> bytesToRead to be consistent with above ChannelStateByteBuffer wrap(Buffer buffer)", "bodyHTML": "<p dir=\"auto\"><code>upToBytes</code> -&gt; <code>bytesToRead</code> to be consistent with above <code>ChannelStateByteBuffer wrap(Buffer buffer)</code></p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:09:17Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMDYxNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402400614", "body": "Use `bufferBuilder.writableBytes()` to replace `writableBytes()` then we can remove this explicit interface method.", "bodyText": "Use bufferBuilder.writableBytes() to replace writableBytes() then we can remove this explicit interface method.", "bodyHTML": "<p dir=\"auto\">Use <code>bufferBuilder.writableBytes()</code> to replace <code>writableBytes()</code> then we can remove this explicit interface method.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:23:36Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402401111", "body": "I guess this wrap is never used atm", "bodyText": "I guess this wrap is never used atm", "bodyHTML": "<p dir=\"auto\">I guess this wrap is never used atm</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:24:12Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0NzE3Ng==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404247176", "bodyText": "It is used in ChannelStateSerializerImplTest.", "author": "rkhachatryan", "createdAt": "2020-04-06T17:00:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4OTEwOA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404989108", "bodyText": "I'm not sure what the general agreement is, but I'm not a huge fan of adding code just to make testing easier. The only sensible exception is to add accessors to private fields. My main concern is that we blow up the production code without adding any functionality. This additional would then need additional tests, so we are testing code that is only relevant for tests...\nIf this subclass is useful only for testing, why not add it in the ChannelStateSerializerTest or in some *Util? For example, TestBufferFactory adds a convenient way to create small test buffers. If that was part of the actual Buffer interface, it would be very confusing to me.", "author": "AHeise", "createdAt": "2020-04-07T17:33:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMTExMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwMjM4NA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402402384", "body": "better to give javadoc for this method, then it is easy to understand the arguments especially for the meaning of the return value.", "bodyText": "better to give javadoc for this method, then it is easy to understand the arguments especially for the meaning of the return value.", "bodyHTML": "<p dir=\"auto\">better to give javadoc for this method, then it is easy to understand the arguments especially for the meaning of the return value.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:25:45Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNzIxOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402407219", "body": "it seems redundant for defining this variable", "bodyText": "it seems redundant for defining this variable", "bodyHTML": "<p dir=\"auto\">it seems redundant for defining this variable</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:32:05Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];\n+\t\treturn new ChannelStateByteBuffer() {\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn !bufferBuilder.isFull();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn bufferBuilder.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int upToBytes) throws IOException {\n+\t\t\t\tint left = upToBytes;\n+\t\t\t\tfor (int toRead = getToRead(left); toRead > 0; toRead = getToRead(left)) {\n+\t\t\t\t\tint read = input.read(buf, 0, toRead);\n+\t\t\t\t\tint copied = bufferBuilder.append(java.nio.ByteBuffer.wrap(buf, 0, read));\n+\t\t\t\t\tPreconditions.checkState(copied == read);\n+\t\t\t\t\tleft -= read;\n+\t\t\t\t}\n+\t\t\t\tbufferBuilder.commit();\n+\t\t\t\treturn upToBytes - left;\n+\t\t\t}\n+\n+\t\t\tprivate int getToRead(int bytesToRead) {\n+\t\t\t\treturn min(bytesToRead, min(buf.length, writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(byte[] bytes) {\n+\t\tint written = 0;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI0OTkyNA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404249924", "bodyText": "Should be member variable.", "author": "rkhachatryan", "createdAt": "2020-04-06T17:04:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQwNzIxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402410595", "body": "TBH I am concerning of creating the temporary byte array for every buffer level, it might be not friendly for GC. And it also brings additional copy while reading. But i have not thought of a better option now. Maybe at-least to reuse the same `buf` for every wrap?", "bodyText": "TBH I am concerning of creating the temporary byte array for every buffer level, it might be not friendly for GC. And it also brings additional copy while reading. But i have not thought of a better option now. Maybe at-least to reuse the same buf for every wrap?", "bodyHTML": "<p dir=\"auto\">TBH I am concerning of creating the temporary byte array for every buffer level, it might be not friendly for GC. And it also brings additional copy while reading. But i have not thought of a better option now. Maybe at-least to reuse the same <code>buf</code> for every wrap?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:36:51Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateSerializer.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.checkpoint.channel;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.runtime.io.network.buffer.Buffer;\n+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.flink.shaded.netty4.io.netty.buffer.ByteBuf;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import static java.lang.Math.addExact;\n+import static java.lang.Math.min;\n+\n+interface ChannelStateSerializer {\n+\n+\tvoid writeHeader(DataOutputStream dataStream) throws IOException;\n+\n+\tvoid writeData(DataOutputStream stream, Buffer... flinkBuffers) throws IOException;\n+}\n+\n+interface ChannelStateDeserializer {\n+\n+\tvoid readHeader(InputStream stream) throws IOException;\n+\n+\t/**\n+\t * Reads the length of state.\n+\t *\n+\t * @return size of state in bytes and offset of the current position resulted from reading.\n+\t */\n+\tTuple2<Integer, Integer> readLength(InputStream stream) throws IOException;\n+\n+\tint readData(InputStream stream, ChannelStateByteBuffer buffer, int bytes) throws IOException;\n+}\n+\n+/**\n+ * Wrapper around various buffers to receive channel state data.\n+ */\n+@Internal\n+@NotThreadSafe\n+interface ChannelStateByteBuffer {\n+\n+\tboolean isWritable();\n+\n+\tint writableBytes();\n+\n+\tint writeBytes(InputStream input, int bytesToRead) throws IOException;\n+\n+\tstatic ChannelStateByteBuffer wrap(Buffer buffer) {\n+\t\treturn new ChannelStateByteBuffer() {\n+\n+\t\t\tprivate ByteBuf byteBuf = buffer.asByteBuf();\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isWritable() {\n+\t\t\t\treturn byteBuf.isWritable();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writableBytes() {\n+\t\t\t\treturn byteBuf.writableBytes();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic int writeBytes(InputStream input, int bytesToRead) throws IOException {\n+\t\t\t\treturn byteBuf.writeBytes(input, Math.min(bytesToRead, byteBuf.writableBytes()));\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\tstatic ChannelStateByteBuffer wrap(BufferBuilder bufferBuilder) {\n+\t\tfinal byte[] buf = new byte[1024];", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTMwMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404265300", "bodyText": "I think we discussed it offline and agreed to some non-optimized approach.\nWith current BufferBuilder we can't avoid extra copying without resorting to accessing its underlying memorySegment.\nAs for GC, I don't know what's better here:\n\nallocate for each ChannelStateByteBuffer.writeBytes: won't escape method => no GC, but allocation cost\nallocate for each ChannelStateStreamReader.readInto (as it is now): short-lived - likely low GC pressure, but some allocation cost\nreuse between  ChannelStateStreamReader.readInto (what you proposed): memory overhead (we don't know when to clear); concurrency overhead / GC pressure with thread-locals (other issues?)\n\nAll in all, I think it's not a performance-critical part so we can optimize it later if needed.", "author": "rkhachatryan", "createdAt": "2020-04-06T17:29:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNjk2Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404736967", "bodyText": "Yes, I remembered this discussion before and I agree this extra copy can not be avoided based on current codes. My previous assumption was that it would reuse the same bytes always like we did in SpillingAdaptiveSpanningRecordDeserializer#SpanningWrapper#buffer, to reduce GC pressure for many short-live objects.\nIf it is not easy to clear it, I am also fine with current way since it is not in critical path, only for recovery process. Then we can optimize it if necessary future.", "author": "zhijiangW", "createdAt": "2020-04-07T11:29:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMDU5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzUxMw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402413513", "body": "nit: seems no need to throw this exception explicitly, because the subclass implementation actually does not throw such exception.", "bodyText": "nit: seems no need to throw this exception explicitly, because the subclass implementation actually does not throw such exception.", "bodyHTML": "<p dir=\"auto\">nit: seems no need to throw this exception explicitly, because the subclass implementation actually does not throw such exception.</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:40:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NzUyMA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404267520", "bodyText": "It does when it calls ChannelStateWriterImpl#checkBufferType (it is in signature here only to give more information to the caller (developer)).", "author": "rkhachatryan", "createdAt": "2020-04-06T17:32:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzUxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxMzgyNw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402413827", "body": "ditto: no need to throw explicitly", "bodyText": "ditto: no need to throw explicitly", "bodyHTML": "<p dir=\"auto\">ditto: no need to throw explicitly</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:41:22Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxNjc2OA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402416768", "body": "#start missing one argument", "bodyText": "#start missing one argument", "bodyHTML": "<p dir=\"auto\">#start missing one argument</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:45:30Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQxNzMxNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402417315", "body": "remove this method directly?", "bodyText": "remove this method directly?", "bodyHTML": "<p dir=\"auto\">remove this method directly?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:46:16Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -46,60 +78,64 @@\n \t/**\n \t * Initiate write of channel state for the given checkpoint id.\n \t */\n-\tvoid start(long checkpointId);\n+\tvoid start(long checkpointId, CheckpointOptions checkpointOptions);\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.consumer.InputChannel InputChannel}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} (long)} and before {@link #finishInput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data);\n+\tvoid addInputData(long checkpointId, InputChannelInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Add in-flight buffers from the {@link org.apache.flink.runtime.io.network.partition.ResultSubpartition ResultSubpartition}.\n-\t * Must be called after {@link #start(long)} and before {@link #finish(long)}.\n+\t * Must be called after {@link #start} and before {@link #finishOutput(long)}.\n+\t * Buffers are recycled after they are written.\n \t * @param startSeqNum sequence number of the 1st passed buffer.\n \t *                    It is intended to use for incremental snapshots.\n \t *                    If no data is passed it is ignored.\n-\t * @param data zero or more buffers ordered by their sequence numbers\n+\t * @param data zero or more <b>data</b> buffers ordered by their sequence numbers\n+\t * @throws IllegalArgumentException if one or more passed buffers {@link Buffer#isBuffer()  isn't a buffer}\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_RESTORED\n \t * @see org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter#SEQUENCE_NUMBER_UNKNOWN\n \t */\n-\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n+\tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data) throws IllegalArgumentException;\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.\n \t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n-\t * using {@link #getWriteCompletionFuture}\n+\t * using {@link #getWriteResult}\n \t */\n \tvoid finishInput(long checkpointId);\n \n \t/**\n \t * Finalize write of channel state data for the given checkpoint id.\n \t * Must be called after {@link #start(long)} and all of the output data of the given checkpoint added.\n \t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n-\t * using {@link #getWriteCompletionFuture}\n+\t * using {@link #getWriteResult}\n \t */\n \tvoid finishOutput(long checkpointId);\n \n \t/**\n-\t * Must be called after {@link #start(long)}.\n+\t * Must be called after {@link #start}.\n \t */\n-\tFuture<Collection<StateObject>> getWriteCompletionFuture(long checkpointId);\n+\tChannelStateWriteResult getWriteResult(long checkpointId);\n \n \t@Override\n-\tvoid close() throws Exception;\n+\tvoid close();", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQyNTY2NQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r402425665", "body": "nit: getWritableBytes()?", "bodyText": "nit: getWritableBytes()?", "bodyHTML": "<p dir=\"auto\">nit: getWritableBytes()?</p>", "author": "zhijiangW", "createdAt": "2020-04-02T15:57:31Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java", "diffHunk": "@@ -117,6 +117,11 @@ public boolean isFull() {\n \t\treturn positionMarker.getCached() == getMaxCapacity();\n \t}\n \n+\tpublic int writableBytes() {", "originalCommit": "dad865f157135abd13585f9b560af76cac07b127", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "102a8f1f7c4926781fba187273cd6d324f8d0bd2", "url": "https://github.com/apache/flink/commit/102a8f1f7c4926781fba187273cd6d324f8d0bd2", "message": "[FLINK-16744][task][hotfix] refactor SubtaskCheckpointCoordinatorImpl\nMinor refactoring of  SubtaskCheckpointCoordinatorImpl\nto reduce its methods complexity", "committedDate": "2020-04-06T19:45:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwMjgxNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404802815", "body": "this seems never be used.", "bodyText": "this seems never be used.", "bodyHTML": "<p dir=\"auto\">this seems never be used.</p>", "author": "zhijiangW", "createdAt": "2020-04-07T13:20:47Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/over/BufferDataOverWindowOperatorTest.java", "diffHunk": "@@ -237,4 +241,9 @@ public StreamingRuntimeContext getRuntimeContext() {\n \tprivate void addRow(Object... fields) throws Exception {\n \t\toperator.processElement(new StreamRecord<>(GenericRow.of(fields)));\n \t}\n+\n+\tprivate interface EnvironmentSupport {", "originalCommit": "f1798f9618fd405fa87bfcac215fae4d4d30c469", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNTYyNQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404805625", "bodyText": "Yes, leftover from the previous version. Thanks.", "author": "rkhachatryan", "createdAt": "2020-04-07T13:24:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwMjgxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNDMyOQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404804329", "body": "nit: actually this is not used now in all places and we can add it by demands future. If we want to rich the builder now, it is better to place it in front of `#build()` to make related methods close with each other.", "bodyText": "nit: actually this is not used now in all places and we can add it by demands future. If we want to rich the builder now, it is better to place it in front of #build() to make related methods close with each other.", "bodyHTML": "<p dir=\"auto\">nit: actually this is not used now in all places and we can add it by demands future. If we want to rich the builder now, it is better to place it in front of <code>#build()</code> to make related methods close with each other.</p>", "author": "zhijiangW", "createdAt": "2020-04-07T13:22:58Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironmentBuilder.java", "diffHunk": "@@ -154,6 +159,12 @@ public MockEnvironment build() {\n \t\t\tsubtaskIndex,\n \t\t\tuserCodeClassLoader,\n \t\t\ttaskMetricGroup,\n-\t\t\ttaskManagerRuntimeInfo);\n+\t\t\ttaskManagerRuntimeInfo,\n+\t\t\tmemoryManager);\n+\t}\n+\n+\tpublic MockEnvironmentBuilder setMemoryManager(MemoryManager memoryManager) {", "originalCommit": "f1798f9618fd405fa87bfcac215fae4d4d30c469", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg5NDU4MQ==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404894581", "body": "nit: only missing `checkNotNull` for the last argument `actionExecutor`", "bodyText": "nit: only missing checkNotNull for the last argument actionExecutor", "bodyHTML": "<p dir=\"auto\">nit: only missing <code>checkNotNull</code> for the last argument <code>actionExecutor</code></p>", "author": "zhijiangW", "createdAt": "2020-04-07T15:20:25Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.runtime.tasks;\n+\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetaData;\n+import org.apache.flink.runtime.checkpoint.CheckpointMetrics;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.state.CheckpointStorageWorkerView;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+class SubtaskCheckpointCoordinatorImpl implements SubtaskCheckpointCoordinator {\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(SubtaskCheckpointCoordinatorImpl.class);\n+\n+\tprivate final CheckpointStorageWorkerView checkpointStorage;\n+\tprivate final String taskName;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\tprivate final ExecutorService executorService;\n+\tprivate final Environment env;\n+\tprivate final AsyncExceptionHandler asyncExceptionHandler;\n+\tprivate final StreamTaskActionExecutor actionExecutor;\n+\n+\tSubtaskCheckpointCoordinatorImpl(\n+\t\t\tCheckpointStorageWorkerView checkpointStorage,\n+\t\t\tString taskName,\n+\t\t\tStreamTaskActionExecutor actionExecutor,\n+\t\t\tCloseableRegistry closeableRegistry,\n+\t\t\tExecutorService executorService,\n+\t\t\tEnvironment env,\n+\t\t\tAsyncExceptionHandler asyncExceptionHandler) {\n+\t\tthis.checkpointStorage = checkNotNull(checkpointStorage);\n+\t\tthis.taskName = checkNotNull(taskName);\n+\t\tthis.closeableRegistry = checkNotNull(closeableRegistry);\n+\t\tthis.executorService = checkNotNull(executorService);\n+\t\tthis.env = checkNotNull(env);\n+\t\tthis.asyncExceptionHandler = checkNotNull(asyncExceptionHandler);\n+\t\tthis.actionExecutor = actionExecutor;", "originalCommit": "a233c1fb23c6c3abdb3a3dee745750b191470aa1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkwMTc0Nw==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404901747", "body": "From the commit \"[FLINK-16744][task][refactor] inline CheckpointingOperation\", it is unnecessary changes to move the position of this method, if we want to merge this commit separately.", "bodyText": "From the commit \"[FLINK-16744][task][refactor] inline CheckpointingOperation\", it is unnecessary changes to move the position of this method, if we want to merge this commit separately.", "bodyHTML": "<p dir=\"auto\">From the commit \"[<a class=\"issue-link js-issue-link\" rel=\"noopener noreferrer nofollow\" href=\"https://issues.apache.org/jira/browse/FLINK-16744\">FLINK-16744</a>][task][refactor] inline CheckpointingOperation\", it is unnecessary changes to move the position of this method, if we want to merge this commit separately.</p>", "author": "zhijiangW", "createdAt": "2020-04-07T15:29:22Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/SubtaskCheckpointCoordinatorImpl.java", "diffHunk": "@@ -61,11 +65,6 @@\n \t\tthis.actionExecutor = actionExecutor;\n \t}\n \n-\t@Override", "originalCommit": "725b18cbede97464a1fa77f984108e70c337789f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDkyMDE4MA==", "url": "https://github.com/apache/flink/pull/11515#discussion_r404920180", "body": "we should also adjust the references of `{@link #finish(long)}` in above `addInputData` and `addOutput` descriptions for the commit \"[FLINK-16744][task] split finish() in ChanStateWrite\"", "bodyText": "we should also adjust the references of {@link #finish(long)} in above addInputData and addOutput descriptions for the commit \"[FLINK-16744][task] split finish() in ChanStateWrite\"", "bodyHTML": "<p dir=\"auto\">we should also adjust the references of <code>{@link #finish(long)}</code> in above <code>addInputData</code> and <code>addOutput</code> descriptions for the commit \"[<a class=\"issue-link js-issue-link\" rel=\"noopener noreferrer nofollow\" href=\"https://issues.apache.org/jira/browse/FLINK-16744\">FLINK-16744</a>][task] split finish() in ChanStateWrite\"</p>", "author": "zhijiangW", "createdAt": "2020-04-07T15:53:14Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/ChannelStateWriter.java", "diffHunk": "@@ -73,10 +73,20 @@\n \tvoid addOutputData(long checkpointId, ResultSubpartitionInfo info, int startSeqNum, Buffer... data);\n \n \t/**\n-\t * Finalize write of channel state for the given checkpoint id.\n-\t * Must be called after {@link #start(long)} and all of the data of the given checkpoint added.\n+\t * Finalize write of channel state data for the given checkpoint id.\n+\t * Must be called after {@link #start(long)} and all of the input data of the given checkpoint added.\n+\t * When both {@link #finishInput} and {@link #finishOutput} were called the results can be (eventually) obtained\n+\t * using {@link #getWriteCompletionFuture}\n \t */\n-\tvoid finish(long checkpointId);", "originalCommit": "ead3567fb7f140353779ab3a4d52e67185485e39", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}