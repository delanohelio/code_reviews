{"pr_number": 8532, "pr_title": "ISPN-11723 Cluster Backup/Restore tool", "pr_author": "ryanemerson", "pr_createdAt": "2020-07-07T15:53:26Z", "pr_url": "https://github.com/infinispan/infinispan/pull/8532", "timeline": [{"oid": "b2e1e963cf535ecf1e3bcb990b342e53a1738756", "url": "https://github.com/infinispan/infinispan/commit/b2e1e963cf535ecf1e3bcb990b342e53a1738756", "message": "ISPN-11723 Cluster Backup/Restore tool\n\n- BackupManager interface exposed via ServerManagement\n- /v2/cluster/backup exposes cointainer backup\n- /v2/cluster/restore exposes cointainer restore\n- BackupManagerImplTest added\n- ClusterBackupIT added", "committedDate": "2020-07-08T16:52:08Z", "type": "forcePushed"}, {"oid": "fead33ed2934588be06b2246c559531ff5d35df6", "url": "https://github.com/infinispan/infinispan/commit/fead33ed2934588be06b2246c559531ff5d35df6", "message": "ISPN-11723 Cluster Backup/Restore tool\n\n- BackupManager interface exposed via ServerManagement\n- /v2/cluster/backup exposes cointainer backup\n- /v2/cluster/restore exposes cointainer restore\n- BackupManagerImplTest added\n- ClusterBackupIT added", "committedDate": "2020-07-09T09:09:12Z", "type": "forcePushed"}, {"oid": "01d48dd061fe91831a2ba93352be630f1e3a8916", "url": "https://github.com/infinispan/infinispan/commit/01d48dd061fe91831a2ba93352be630f1e3a8916", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T11:30:28Z", "type": "forcePushed"}, {"oid": "548a6c9d81e4ec1feca3dd2270e0dc148c779555", "url": "https://github.com/infinispan/infinispan/commit/548a6c9d81e4ec1feca3dd2270e0dc148c779555", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T12:54:31Z", "type": "forcePushed"}, {"oid": "eb18a78b0989bec9090e874f3867e3ceca7a1487", "url": "https://github.com/infinispan/infinispan/commit/eb18a78b0989bec9090e874f3867e3ceca7a1487", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T12:58:18Z", "type": "forcePushed"}, {"oid": "870674768f73027512fec040a2cc52ec6d70ee6e", "url": "https://github.com/infinispan/infinispan/commit/870674768f73027512fec040a2cc52ec6d70ee6e", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T14:26:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r452922681", "body": "`@param backup the bytes of the uploaded backup file.` <= what is this exactly? is the full data in a single byte{]?", "bodyText": "@param backup the bytes of the uploaded backup file. <= what is this exactly? is the full data in a single byte{]?", "bodyHTML": "<p dir=\"auto\"><code>@param backup the bytes of the uploaded backup file.</code> &lt;= what is this exactly? is the full data in a single byte{]?</p>", "author": "pruivo", "createdAt": "2020-07-10T15:41:36Z", "path": "server/core/src/main/java/org/infinispan/server/core/BackupManager.java", "diffHunk": "@@ -0,0 +1,31 @@\n+package org.infinispan.server.core;\n+\n+import java.nio.file.Path;\n+import java.util.concurrent.CompletionStage;\n+\n+import org.infinispan.factories.scopes.Scope;\n+import org.infinispan.factories.scopes.Scopes;\n+\n+/**\n+ * Handles all tasks related to the creation/restoration of server backups.\n+ *\n+ * @author Ryan Emerson\n+ * @since 11.0\n+ */\n+@Scope(Scopes.GLOBAL)\n+public interface BackupManager {\n+   /**\n+    * Create a backup of all containers configured on the server.\n+    *\n+    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n+    */\n+   CompletionStage<Path> create();\n+\n+   /**\n+    * Restore container content from the provided backup bytes.\n+    *\n+    * @param backup the bytes of the uploaded backup file.\n+    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n+    */\n+   CompletionStage<Void> restore(byte[] backup);", "originalCommit": "870674768f73027512fec040a2cc52ec6d70ee6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI0Mzg0OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457243848", "bodyText": "This should really be an InputStream or a ReadableByteChannel", "author": "tristantarrant", "createdAt": "2020-07-20T10:03:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI0OTcwNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457249707", "bodyText": "Sorry I forgot to get back to your original comment Pedro.\nAgreed it shouldn't be byte[], I will update this in the interface. We do have a bigger issue at the moment though, which is AFAIK we can only receive the bytes from a RestRequest via ContentSource#rawContent() which returns a byte[]. As backups will most likely be large, we should support Streams for uploads/downloads with HTTP2, maybe with a fallback of chunked transfer encoding for HTTP/1.1\n\\cc @gustavonalle", "author": "ryanemerson", "createdAt": "2020-07-20T10:12:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA3ODk3OQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458078979", "bodyText": "Do we really need to send a giant amount of data to the server?  Can't you just accept a Path to a file somewhere?\nIf we really need it, it's a great opportunity to expand the REST framework to support a stream of data, using chunked transfer, as it'd be supported both for HTTP/1 and HTTP/2", "author": "gustavonalle", "createdAt": "2020-07-21T13:04:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODExNjg1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458116851", "bodyText": "Do we really need to send a giant amount of data to the server? Can't you just accept a Path to a file somewhere?\n\nHow do you get the file from the various clients to the server if you don't upload it? The idea is that this will work in Openshift and can be triggered via the Cli and eventually the console.\nWe could also add the option of the server importing the contents of a local backup file on server startup. In which case the server can pass a InputStream of the local file to the restore method.", "author": "ryanemerson", "createdAt": "2020-07-21T13:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODExOTcxMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458119713", "bodyText": "If we really need it, it's a great opportunity to expand the REST framework to support a stream of data, using chunked transfer, as it'd be supported both for HTTP/1 and HTTP/2\n\nMy understanding is that chunked transfer was removed in HTTP/2 https://en.wikipedia.org/wiki/Chunked_transfer_encoding.", "author": "ryanemerson", "createdAt": "2020-07-21T14:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEyMzg4Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458123887", "bodyText": "Our REST server is using HTTP/1 tunnelled in HTTP/2 frames, so it should work.", "author": "gustavonalle", "createdAt": "2020-07-21T14:06:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEyNTE4Mw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458125183", "bodyText": "How do you get the file from the various clients to the server if you don't upload it?\n\nI was just wondering 1 TB backups being sent through HTTP from the client to the server and got a bit worried :)", "author": "gustavonalle", "createdAt": "2020-07-21T14:07:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE0MjgwNg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458142806", "bodyText": "One question: the other way around, i.e., producing the backup, does it first create it on disk and then send it to the client? If so, maybe chunking is not the best but https://en.wikipedia.org/wiki/Byte_serving", "author": "gustavonalle", "createdAt": "2020-07-21T14:30:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2NTY3OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458165678", "bodyText": "does it first create it on disk and then send it to the client\n\nYep. Currently this is a very simple implementation where it's stored as staging.zip, however if we take advantange of byte serving and assign an Id per backup request, we could allow for failed downloads to be resumed. Although we would probably need some form of garbage collection for backups whom's downloads never complete.", "author": "ryanemerson", "createdAt": "2020-07-21T15:00:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2OTkyMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458169920", "bodyText": "ok, we can always revisit it later and change from chunked -> bytes", "author": "gustavonalle", "createdAt": "2020-07-21T15:05:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczOTc2NA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458739764", "bodyText": "I've created https://issues.redhat.com/browse/ISPN-12145 to track the implementation of chunked transfer encoding.", "author": "ryanemerson", "createdAt": "2020-07-22T12:00:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "cba11f350f146453d2822f03c1baa48707a53912", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\nindex 549e9547ec..128bec3a3b 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\n", "chunk": "@@ -14,18 +16,74 @@\n  */\n @Scope(Scopes.GLOBAL)\n public interface BackupManager {\n+\n    /**\n-    * Create a backup of all containers configured on the server.\n+    * Create a backup of all containers configured on the server, including all available resources.\n     *\n     * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n     */\n    CompletionStage<Path> create();\n \n    /**\n-    * Restore container content from the provided backup bytes.\n+    * Create a backup of the specified containers, including the resources defined in the provided {@link ContainerResources}\n+    * object.\n+    *\n+    * @param params a map of container names and an associated {@link ContainerResources} instance.\n+    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n+    */\n+   CompletionStage<Path> create(Map<String, ContainerResources> params);\n+\n+   /**\n+    * Restore all content from the provided backup bytes.\n     *\n     * @param backup the bytes of the uploaded backup file.\n     * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n     */\n    CompletionStage<Void> restore(byte[] backup);\n+\n+   /**\n+    * Restore content from the provided backup bytes. The keyset of the provided {@link Map} determines which containers\n+    * are restored from the backup file. Similarly, the {@link ContainerResources} object determines which {@link ResourceType}s are\n+    * restored.\n+    *\n+    * @param backup the bytes of the uploaded backup file.\n+    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n+    */\n+   CompletionStage<Void> restore(byte[] backup, Map<String, ContainerResources> params);\n+\n+   enum ResourceType {\n+      CACHES(\"caches\"),\n+      CACHE_CONFIGURATIONS(\"cache-configs\"),\n+      COUNTERS(\"counters\"),\n+      PROTO_SCHEMAS(\"proto-schemas\"),\n+      SCRIPTS(\"scripts\");\n+\n+      final String name;\n+      ResourceType(String name) {\n+         this.name = name;\n+      }\n+\n+      @Override\n+      public String toString() {\n+         return this.name;\n+      }\n+   }\n+\n+   /**\n+    * An interface to encapsulate the various arguments required by the {@link BackupManager} in order to include/exclude\n+    * resources from a backup/restore operation.\n+    */\n+   interface ContainerResources {\n+\n+      /**\n+       * @return the {@link ResourceType} to be included in the backup/restore.\n+       */\n+      Set<ResourceType> includeTypes();\n+\n+      /**\n+       * @param type the {@link ResourceType} to retrieve the associated resources for.\n+       * @return a {@link Set} of resource names to process.\n+       */\n+      Set<String> getQualifiedResources(ResourceType type);\n+   }\n }\n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\nindex 128bec3a3b..3de2978e85 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\n", "chunk": "@@ -25,65 +31,65 @@\n    CompletionStage<Path> create();\n \n    /**\n-    * Create a backup of the specified containers, including the resources defined in the provided {@link ContainerResources}\n+    * Create a backup of the specified containers, including the resources defined in the provided {@link Resources}\n     * object.\n     *\n-    * @param params a map of container names and an associated {@link ContainerResources} instance.\n+    * @param params a map of container names and an associated {@link Resources} instance.\n     * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n     */\n-   CompletionStage<Path> create(Map<String, ContainerResources> params);\n+   CompletionStage<Path> create(Map<String, Resources> params);\n \n    /**\n     * Restore all content from the provided backup bytes.\n     *\n-    * @param backup the bytes of the uploaded backup file.\n+    * @param is a {@link InputStream} containing the bytes of the uploaded backup file.\n     * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n     */\n-   CompletionStage<Void> restore(byte[] backup);\n+   CompletionStage<Void> restore(InputStream is);\n \n    /**\n     * Restore content from the provided backup bytes. The keyset of the provided {@link Map} determines which containers\n-    * are restored from the backup file. Similarly, the {@link ContainerResources} object determines which {@link ResourceType}s are\n+    * are restored from the backup file. Similarly, the {@link Resources} object determines which {@link Resources.Type}s are\n     * restored.\n     *\n-    * @param backup the bytes of the uploaded backup file.\n+    * @param is a {@link InputStream} containing the bytes of the uploaded backup file.\n     * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n     */\n-   CompletionStage<Void> restore(byte[] backup, Map<String, ContainerResources> params);\n-\n-   enum ResourceType {\n-      CACHES(\"caches\"),\n-      CACHE_CONFIGURATIONS(\"cache-configs\"),\n-      COUNTERS(\"counters\"),\n-      PROTO_SCHEMAS(\"proto-schemas\"),\n-      SCRIPTS(\"scripts\");\n-\n-      final String name;\n-      ResourceType(String name) {\n-         this.name = name;\n-      }\n-\n-      @Override\n-      public String toString() {\n-         return this.name;\n-      }\n-   }\n+   CompletionStage<Void> restore(InputStream is, Map<String, Resources> params);\n \n    /**\n     * An interface to encapsulate the various arguments required by the {@link BackupManager} in order to include/exclude\n     * resources from a backup/restore operation.\n     */\n-   interface ContainerResources {\n+   interface Resources {\n+\n+      enum Type {\n+         CACHES(\"caches\"),\n+         CACHE_CONFIGURATIONS(\"cache-configs\"),\n+         COUNTERS(\"counters\"),\n+         PROTO_SCHEMAS(\"proto-schemas\"),\n+         SCRIPTS(\"scripts\");\n+\n+         final String name;\n+         Type(String name) {\n+            this.name = name;\n+         }\n+\n+         @Override\n+         public String toString() {\n+            return this.name;\n+         }\n+      }\n \n       /**\n-       * @return the {@link ResourceType} to be included in the backup/restore.\n+       * @return the {@link Type} to be included in the backup/restore.\n        */\n-      Set<ResourceType> includeTypes();\n+      Set<Type> includeTypes();\n \n       /**\n-       * @param type the {@link ResourceType} to retrieve the associated resources for.\n+       * @param type the {@link Type} to retrieve the associated resources for.\n        * @return a {@link Set} of resource names to process.\n        */\n-      Set<String> getQualifiedResources(ResourceType type);\n+      Set<String> getQualifiedResources(Type type);\n    }\n }\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\ndeleted file mode 100644\nindex 3de2978e85..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\n+++ /dev/null\n", "chunk": "@@ -1,95 +0,0 @@\n-package org.infinispan.server.core;\n-\n-import java.io.InputStream;\n-import java.nio.file.Path;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-\n-import org.infinispan.factories.scopes.Scope;\n-import org.infinispan.factories.scopes.Scopes;\n-\n-/**\n- * Handles all tasks related to the creation/restoration of server backups.\n- *\n- * @author Ryan Emerson\n- * @since 11.0\n- */\n-@Scope(Scopes.GLOBAL)\n-public interface BackupManager {\n-\n-   /**\n-    * Performs initialisation of all resources required by the implementation before backup files can be created or restored.\n-    */\n-   void init();\n-\n-   /**\n-    * Create a backup of all containers configured on the server, including all available resources.\n-    *\n-    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n-    */\n-   CompletionStage<Path> create();\n-\n-   /**\n-    * Create a backup of the specified containers, including the resources defined in the provided {@link Resources}\n-    * object.\n-    *\n-    * @param params a map of container names and an associated {@link Resources} instance.\n-    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n-    */\n-   CompletionStage<Path> create(Map<String, Resources> params);\n-\n-   /**\n-    * Restore all content from the provided backup bytes.\n-    *\n-    * @param is a {@link InputStream} containing the bytes of the uploaded backup file.\n-    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n-    */\n-   CompletionStage<Void> restore(InputStream is);\n-\n-   /**\n-    * Restore content from the provided backup bytes. The keyset of the provided {@link Map} determines which containers\n-    * are restored from the backup file. Similarly, the {@link Resources} object determines which {@link Resources.Type}s are\n-    * restored.\n-    *\n-    * @param is a {@link InputStream} containing the bytes of the uploaded backup file.\n-    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n-    */\n-   CompletionStage<Void> restore(InputStream is, Map<String, Resources> params);\n-\n-   /**\n-    * An interface to encapsulate the various arguments required by the {@link BackupManager} in order to include/exclude\n-    * resources from a backup/restore operation.\n-    */\n-   interface Resources {\n-\n-      enum Type {\n-         CACHES(\"caches\"),\n-         CACHE_CONFIGURATIONS(\"cache-configs\"),\n-         COUNTERS(\"counters\"),\n-         PROTO_SCHEMAS(\"proto-schemas\"),\n-         SCRIPTS(\"scripts\");\n-\n-         final String name;\n-         Type(String name) {\n-            this.name = name;\n-         }\n-\n-         @Override\n-         public String toString() {\n-            return this.name;\n-         }\n-      }\n-\n-      /**\n-       * @return the {@link Type} to be included in the backup/restore.\n-       */\n-      Set<Type> includeTypes();\n-\n-      /**\n-       * @param type the {@link Type} to retrieve the associated resources for.\n-       * @return a {@link Set} of resource names to process.\n-       */\n-      Set<String> getQualifiedResources(Type type);\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/BackupManager.java b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\nnew file mode 100644\nindex 0000000000..d297025976\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/BackupManager.java\n", "chunk": "@@ -0,0 +1,157 @@\n+package org.infinispan.server.core;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+\n+import org.infinispan.factories.scopes.Scope;\n+import org.infinispan.factories.scopes.Scopes;\n+\n+/**\n+ * Handles all tasks related to the creation/restoration of server backups.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+@Scope(Scopes.GLOBAL)\n+public interface BackupManager {\n+\n+   /**\n+    * An enum representing the current state of a Backup operation.\n+    */\n+   enum Status {\n+      COMPLETE,\n+      FAILED,\n+      IN_PROGRESS,\n+      NOT_FOUND\n+   }\n+\n+   /**\n+    * Performs initialisation of all resources required by the implementation before backup files can be created or\n+    * restored.\n+    */\n+   void init() throws IOException;\n+\n+   /**\n+    * @return the names of all backups.\n+    */\n+   Set<String> getBackupNames();\n+\n+   /**\n+    * Return the current {@link Status} of a Backup request.\n+    *\n+    * @param name the name of the backup.\n+    * @return the {@link Status} of the backup.\n+    */\n+   Status getBackupStatus(String name);\n+\n+   /**\n+    * Returns the {@link Path} of a backup file if it is complete.\n+    *\n+    * @param name the name of the backup.\n+    * @return the {@link Path} of the created backup file if {@link Status#COMPLETE}, otherwise null.\n+    */\n+   Path getBackupLocation(String name);\n+\n+   /**\n+    * Remove the created backup file from the server. When it's possible to remove a backup file immediately, then a\n+    * {@link Status#COMPLETE} is returned. However, if a backup operation is currently in progress, then the removal is\n+    * attempted once the backup has completed and {@link Status#IN_PROGRESS} is returned. Finally, {@link\n+    * Status#NOT_FOUND} is returned if no backup exists with the specified name.\n+    *\n+    * @param name the name of the backup.\n+    * @return a {@link CompletionStage} that returns a {@link Status} when complete to indicate what course of action\n+    * was taken.\n+    */\n+   CompletionStage<Status> removeBackup(String name);\n+\n+   /**\n+    * Create a backup of all containers configured on the server, including all available resources.\n+    *\n+    * @param name       the name of the backup.\n+    * @param workingDir a path used as the working directory for creating the backup contents and storing the final\n+    *                   backup. If null, then the default location is used.\n+    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the backup file that will be\n+    * created.\n+    */\n+   CompletionStage<Path> create(String name, Path workingDir);\n+\n+   /**\n+    * Create a backup of the specified containers, including the resources defined in the provided {@link Resources}\n+    * object.\n+    *\n+    * @param name       the name of the backup.\n+    * @param params     a map of container names and an associated {@link Resources} instance.\n+    * @param workingDir a path used as the working directory for creating the backup contents and storing the final *\n+    *                   backup. If null, then the default location is used.\n+    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the backup file that will be\n+    * created.\n+    */\n+   CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params);\n+\n+   /**\n+    * Restore content from the provided backup file.\n+    *\n+    * @param backup a path to the backup file to be restored.\n+    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n+    */\n+   CompletionStage<Void> restore(Path backup);\n+\n+   /**\n+    * Restore content from the provided backup file. The keyset of the provided {@link Map} determines which containers\n+    * are restored from the backup file. Similarly, the {@link Resources} object determines which {@link\n+    * Resources.Type}s are restored.\n+    *\n+    * @param backup a path to the backup file to be restored.\n+    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n+    */\n+   CompletionStage<Void> restore(Path backup, Map<String, Resources> params);\n+\n+   /**\n+    * An interface to encapsulate the various arguments required by the {@link BackupManager} in order to\n+    * include/exclude resources from a backup/restore operation.\n+    */\n+   interface Resources {\n+\n+      enum Type {\n+         CACHES(\"caches\"),\n+         CACHE_CONFIGURATIONS(\"cache-configs\"),\n+         COUNTERS(\"counters\"),\n+         PROTO_SCHEMAS(\"proto-schemas\"),\n+         SCRIPTS(\"scripts\");\n+\n+         final String name;\n+\n+         Type(String name) {\n+            this.name = name;\n+         }\n+\n+         @Override\n+         public String toString() {\n+            return this.name;\n+         }\n+\n+         public static Type fromString(String s) {\n+            for (Type t : Type.values()) {\n+               if (t.name.equalsIgnoreCase(s)) {\n+                  return t;\n+               }\n+            }\n+            throw new IllegalArgumentException(String.format(\"Type with name '%s' does not exist\", s));\n+         }\n+      }\n+\n+      /**\n+       * @return the {@link Type} to be included in the backup/restore.\n+       */\n+      Set<Type> includeTypes();\n+\n+      /**\n+       * @param type the {@link Type} to retrieve the associated resources for.\n+       * @return a {@link Set} of resource names to process.\n+       */\n+      Set<String> getQualifiedResources(Type type);\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"oid": "cba11f350f146453d2822f03c1baa48707a53912", "url": "https://github.com/infinispan/infinispan/commit/cba11f350f146453d2822f03c1baa48707a53912", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-16T16:35:30Z", "type": "forcePushed"}, {"oid": "82bd52a4ad5d4704767bed064483b437bf8f9391", "url": "https://github.com/infinispan/infinispan/commit/82bd52a4ad5d4704767bed064483b437bf8f9391", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-20T12:39:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5MjIyMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457592223", "body": "We should probably add at least minor documentation to these.", "bodyText": "We should probably add at least minor documentation to these.", "bodyHTML": "<p dir=\"auto\">We should probably add at least minor documentation to these.</p>", "author": "wburns", "createdAt": "2020-07-20T17:58:33Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java", "diffHunk": "@@ -17,4 +18,8 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   CompletionStage<RestResponse> backup();", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 84a566ed1e..9db0e47767 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -19,7 +19,16 @@\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n \n+   /**\n+    * Creates a backup file containing all of the current container content (caches, counters etc).\n+    */\n    CompletionStage<RestResponse> backup();\n \n+   /**\n+    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n+    * once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n    CompletionStage<RestResponse> restore(File backup);\n }\n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 9db0e47767..72aa203ad3 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -31,4 +48,11 @@\n     * @param backup the backup {@link File} containing the data to be restored.\n     */\n    CompletionStage<RestResponse> restore(File backup);\n+\n+   /**\n+    * Restores all content from a backup file available to the server instance.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 72aa203ad3..4d0f8dfadf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -18,41 +17,4 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n-\n-   /**\n-    * Creates a backup file containing the content of all containers in the cluster.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name);\n-\n-   /**\n-    * Retrieve a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Delete a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n-    * once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup);\n-\n-   /**\n-    * Restores all content from a backup file available to the server instance.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 4d0f8dfadf..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n+    * once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup);\n+\n+   /**\n+    * Restores all content from a backup file available to the server instance.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwNTExMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457605113", "body": "This isn't quite true. We should invoke Runnable in a blocking thread if the stage is completed on a non blocking thread. Looking closer `whenCompleteBlocking` has the same problem, maybe we should log a JIRA to take care of that though. We really need to add a blocking executor that checks the invoking thread if it is blocking or not before submitting.", "bodyText": "This isn't quite true. We should invoke Runnable in a blocking thread if the stage is completed on a non blocking thread. Looking closer whenCompleteBlocking has the same problem, maybe we should log a JIRA to take care of that though. We really need to add a blocking executor that checks the invoking thread if it is blocking or not before submitting.", "bodyHTML": "<p dir=\"auto\">This isn't quite true. We should invoke Runnable in a blocking thread if the stage is completed on a non blocking thread. Looking closer <code>whenCompleteBlocking</code> has the same problem, maybe we should log a JIRA to take care of that though. We really need to add a blocking executor that checks the invoking thread if it is blocking or not before submitting.</p>", "author": "wburns", "createdAt": "2020-07-20T18:21:53Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java", "diffHunk": "@@ -106,6 +106,21 @@\n    <I, O> CompletionStage<O> handleBlocking(CompletionStage<? extends I> stage,\n          BiFunction<? super I, Throwable, ? extends O> function, Object traceId);\n \n+   /**\n+    * Replacement for {@link CompletionStage#thenRunAsync(Runnable)} that invokes the {@code Runnable} in a blocking thread\n+    * (if the current thread is non-blocking) or in the current thread (if the current thread is blocking).", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk0NTM1NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457945355", "bodyText": "I definitely think this is a fix for a different PR. In this case I just used thenApplyBlocking as a basis of this implementation, so I assume that also has the same issue.", "author": "ryanemerson", "createdAt": "2020-07-21T08:59:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwNTExMw=="}], "type": "inlineReview", "revised_code": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\nindex 9cb1fcd6fc..da2b148831 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n", "chunk": "@@ -106,21 +106,6 @@\n    <I, O> CompletionStage<O> handleBlocking(CompletionStage<? extends I> stage,\n          BiFunction<? super I, Throwable, ? extends O> function, Object traceId);\n \n-   /**\n-    * Replacement for {@link CompletionStage#thenRunAsync(Runnable)} that invokes the {@code Runnable} in a blocking thread\n-    * (if the current thread is non-blocking) or in the current thread (if the current thread is blocking).\n-    * The returned stage, if not complete, resumes any chained stage on the non-blocking executor.\n-    * <p>\n-    * Note that if the current thread is blocking, the task is invoked in the current thread meaning the stage is\n-    * always completed when returned, so any chained stage is also invoked on the current thread.\n-    * @param stage stage, that may or may not be complete, to apply.\n-    * @param runnable blocking operation that runs some code.\n-    * @param traceId an identifier that can be used to tell in a trace when an operation moves between threads.\n-    * @param <I> input value type to the function.\n-    * @return a stage that is completed after the action is done or throws an exception.\n-    */\n-   <I> CompletionStage<Void> thenRun(CompletionStage<? extends I> stage, Runnable runnable, Object traceId);\n-\n    /**\n     * Replacement for {@code CompletionStage.thenApplyAsync()} that invokes the {@code Function} in a blocking thread\n     * (if the current thread is non-blocking) or in the current thread (if the current thread is blocking).\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\nindex da2b148831..55a3345e93 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n", "chunk": "@@ -106,6 +106,21 @@\n    <I, O> CompletionStage<O> handleBlocking(CompletionStage<? extends I> stage,\n          BiFunction<? super I, Throwable, ? extends O> function, Object traceId);\n \n+   /**\n+    * Replacement for {@link CompletionStage#thenRunAsync(Runnable)} that invokes the {@code Runnable} in a blocking thread\n+    * (if the current thread is non-blocking) or in the current thread (if the current thread is blocking).\n+    * The returned stage, if not complete, resumes any chained stage on the non-blocking executor.\n+    * <p>\n+    * Note that if the current thread is blocking, the task is invoked in the current thread meaning the stage is\n+    * always completed when returned, so any chained stage is also invoked on the current thread.\n+    * @param stage stage, that may or may not be complete, to apply.\n+    * @param runnable blocking operation that runs some code.\n+    * @param traceId an identifier that can be used to tell in a trace when an operation moves between threads.\n+    * @param <I> input value type to the function.\n+    * @return a stage that is completed after the action is done or throws an exception.\n+    */\n+   <I> CompletionStage<Void> thenRunBlocking(CompletionStage<? extends I> stage, Runnable runnable, Object traceId);\n+\n    /**\n     * Replacement for {@code CompletionStage.thenApplyAsync()} that invokes the {@code Function} in a blocking thread\n     * (if the current thread is non-blocking) or in the current thread (if the current thread is blocking).\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwNzQwNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457607407", "body": "You can change all of this to just `return stage.thenRun(runnable);`", "bodyText": "You can change all of this to just return stage.thenRun(runnable);", "bodyHTML": "<p dir=\"auto\">You can change all of this to just <code>return stage.thenRun(runnable);</code></p>", "author": "wburns", "createdAt": "2020-07-20T18:26:06Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java", "diffHunk": "@@ -187,6 +187,23 @@ protected void start() {\n       return continueOnNonBlockingThread(stage.thenApplyAsync(function, blockingExecutor), traceId);\n    }\n \n+   @Override\n+   public <I> CompletionStage<Void> thenRun(CompletionStage<? extends I> stage, Runnable runnable, Object traceId) {\n+      if (isCurrentThreadBlocking()) {\n+         if (trace) {\n+            log.tracef(\"Invoked thenRun on a blocking thread, joining %s in same blocking thread\", traceId);\n+         }\n+         try {\n+            CompletionStages.join(stage);", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\nindex a5e89f2489..83d922ee76 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n", "chunk": "@@ -194,9 +194,7 @@ protected void start() {\n             log.tracef(\"Invoked thenRun on a blocking thread, joining %s in same blocking thread\", traceId);\n          }\n          try {\n-            CompletionStages.join(stage);\n-            runnable.run();\n-            return CompletableFutures.completedNull();\n+            return stage.thenRun(runnable);\n          } catch (Throwable t) {\n             return CompletableFutures.completedExceptionFuture(t);\n          }\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\nindex 83d922ee76..0b1029dc4e 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n", "chunk": "@@ -187,21 +187,6 @@ protected void start() {\n       return continueOnNonBlockingThread(stage.thenApplyAsync(function, blockingExecutor), traceId);\n    }\n \n-   @Override\n-   public <I> CompletionStage<Void> thenRun(CompletionStage<? extends I> stage, Runnable runnable, Object traceId) {\n-      if (isCurrentThreadBlocking()) {\n-         if (trace) {\n-            log.tracef(\"Invoked thenRun on a blocking thread, joining %s in same blocking thread\", traceId);\n-         }\n-         try {\n-            return stage.thenRun(runnable);\n-         } catch (Throwable t) {\n-            return CompletableFutures.completedExceptionFuture(t);\n-         }\n-      }\n-      return continueOnNonBlockingThread(stage.thenRunAsync(runnable, blockingExecutor), traceId);\n-   }\n-\n    @Override\n    public <V> CompletionStage<V> whenCompleteBlocking(CompletionStage<V> stage,\n          BiConsumer<? super V, ? super Throwable> biConsumer, Object traceId) {\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\nindex 0b1029dc4e..f53e0d8a6a 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n", "chunk": "@@ -187,6 +187,21 @@ protected void start() {\n       return continueOnNonBlockingThread(stage.thenApplyAsync(function, blockingExecutor), traceId);\n    }\n \n+   @Override\n+   public <I> CompletionStage<Void> thenRunBlocking(CompletionStage<? extends I> stage, Runnable runnable, Object traceId) {\n+      if (isCurrentThreadBlocking()) {\n+         if (trace) {\n+            log.tracef(\"Invoked thenRun on a blocking thread, joining %s in same blocking thread\", traceId);\n+         }\n+         try {\n+            return stage.thenRun(runnable);\n+         } catch (Throwable t) {\n+            return CompletableFutures.completedExceptionFuture(t);\n+         }\n+      }\n+      return continueOnNonBlockingThread(stage.thenRunAsync(runnable, blockingExecutor), traceId);\n+   }\n+\n    @Override\n    public <V> CompletionStage<V> whenCompleteBlocking(CompletionStage<V> stage,\n          BiConsumer<? super V, ? super Throwable> biConsumer, Object traceId) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY0NDQ2Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457644467", "body": "No need for this variable.", "bodyText": "No need for this variable.", "bodyHTML": "<p dir=\"auto\">No need for this variable.</p>", "author": "wburns", "createdAt": "2020-07-20T19:34:26Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java", "diffHunk": "@@ -0,0 +1,117 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   private final AtomicBoolean backupInProgress = new AtomicBoolean();\n+   private final AtomicBoolean restoreInProgress = new AtomicBoolean();\n+\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final BackupWriter writer;\n+   final BlockingManager blockingManager;", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 81c04f2d6a..797abe9a86 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -31,16 +31,18 @@\n    final Path rootDir;\n    final BackupReader reader;\n    final BackupWriter writer;\n-   final BlockingManager blockingManager;\n    final Map<String, DefaultCacheManager> cacheManagers;\n \n    public BackupManagerImpl(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n                             Path dataRoot) {\n-      this.blockingManager = blockingManager;\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n       this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n       this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+   }\n+\n+   @Override\n+   public void init() {\n       rootDir.toFile().mkdir();\n    }\n \n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 797abe9a86..c99aa32c67 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -25,20 +30,21 @@\n \n    private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n \n-   private final AtomicBoolean backupInProgress = new AtomicBoolean();\n-   private final AtomicBoolean restoreInProgress = new AtomicBoolean();\n-\n    final Path rootDir;\n    final BackupReader reader;\n    final BackupWriter writer;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n    final Map<String, DefaultCacheManager> cacheManagers;\n \n-   public BackupManagerImpl(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n-                            Path dataRoot) {\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n       this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n       this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n    }\n \n    @Override\n", "next_change": {"commit": "efedcd6e4718f909ec002c586f289f19d8703c3c", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex c99aa32c67..1741d5c075 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -30,21 +32,25 @@\n \n    private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n \n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n    final Path rootDir;\n    final BackupReader reader;\n-   final BackupWriter writer;\n    final Lock backupLock;\n    final Lock restoreLock;\n    final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n \n    public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n                             Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n-      this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n-      this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry, rootDir);\n       this.backupLock = new Lock(\"backup\", cm);\n       this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n    }\n \n    @Override\n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 1741d5c075..e72057aea9 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -47,15 +48,15 @@ public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager c\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n       this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry, rootDir);\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n       this.backupLock = new Lock(\"backup\", cm);\n       this.restoreLock = new Lock(\"restore\", cm);\n       this.backupMap = new ConcurrentHashMap<>();\n    }\n \n    @Override\n-   public void init() {\n-      rootDir.toFile().mkdir();\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n    }\n \n    @Override\n", "next_change": {"commit": "273d51d75ac24b6893868ce0a373c07e368e1f24", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex e72057aea9..ca96b18bb1 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -59,6 +63,11 @@ public void init() throws IOException {\n       Files.createDirectories(rootDir);\n    }\n \n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n    @Override\n    public Status getBackupStatus(String name) {\n       return getBackupStatus(backupMap.get(name));\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\ndeleted file mode 100644\nindex ca96b18bb1..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,267 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.stream.Collectors;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n-import org.infinispan.lock.api.ClusteredLock;\n-import org.infinispan.lock.api.ClusteredLockManager;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletableFutures;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.infinispan.util.logging.LogFactory;\n-\n-/**\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class BackupManagerImpl implements BackupManager {\n-\n-   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n-\n-   final ParserRegistry parserRegistry;\n-   final BlockingManager blockingManager;\n-   final Path rootDir;\n-   final BackupReader reader;\n-   final Lock backupLock;\n-   final Lock restoreLock;\n-   final Map<String, DefaultCacheManager> cacheManagers;\n-   final Map<String, BackupRequest> backupMap;\n-\n-   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n-      this.blockingManager = blockingManager;\n-      this.rootDir = dataRoot.resolve(WORKING_DIR);\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n-      this.backupLock = new Lock(\"backup\", cm);\n-      this.restoreLock = new Lock(\"restore\", cm);\n-      this.backupMap = new ConcurrentHashMap<>();\n-   }\n-\n-   @Override\n-   public void init() throws IOException {\n-      Files.createDirectories(rootDir);\n-   }\n-\n-   @Override\n-   public Set<String> getBackupNames() {\n-      return new HashSet<>(backupMap.keySet());\n-   }\n-\n-   @Override\n-   public Status getBackupStatus(String name) {\n-      return getBackupStatus(backupMap.get(name));\n-   }\n-\n-   @Override\n-   public Path getBackupLocation(String name) {\n-      BackupRequest request = backupMap.get(name);\n-      Status status = getBackupStatus(request);\n-      if (status != Status.COMPLETE)\n-         return null;\n-      return request.future.join();\n-   }\n-\n-   private Status getBackupStatus(BackupRequest request) {\n-      if (request == null)\n-         return Status.NOT_FOUND;\n-\n-      CompletableFuture<Path> future = request.future;\n-      if (future.isCompletedExceptionally())\n-         return Status.FAILED;\n-\n-      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n-   }\n-\n-   @Override\n-   public CompletionStage<Status> removeBackup(String name) {\n-      BackupRequest request = backupMap.remove(name);\n-      Status status = getBackupStatus(request);\n-      switch (status) {\n-         case NOT_FOUND:\n-            return CompletableFuture.completedFuture(status);\n-         case COMPLETE:\n-         case FAILED:\n-            return blockingManager.supplyBlocking(() -> {\n-               request.writer.cleanup();\n-               return Status.COMPLETE;\n-            }, \"remove-completed-backup\");\n-         case IN_PROGRESS:\n-            // The backup files are removed on exceptional or successful completion.\n-            blockingManager.handleBlocking(request.future, (path, t) -> {\n-               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n-               request.writer.cleanup();\n-               return null;\n-            }, \"remove-inprogress-backup\");\n-            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n-      }\n-      throw new IllegalStateException();\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir) {\n-      return create(\n-            name,\n-            workingDir,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n-      if (getBackupStatus(name) != Status.NOT_FOUND)\n-         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n-\n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n-      CompletionStage<Path> backupStage = backupLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n-\n-               log.initiatingClusterBackup();\n-               return writer.create(params);\n-            });\n-\n-      backupStage = CompletionStages.handleAndCompose(backupStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = backupLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n-                  );\n-               }\n-               log.backupComplete(path.getFileName().toString());\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-\n-      backupMap.put(name, new BackupRequest(writer, backupStage));\n-      return backupStage;\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup) {\n-      return restore(\n-            backup,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n-      if (!Files.exists(backup)) {\n-         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n-         log.error(e);\n-         return CompletableFutures.completedExceptionFuture(e);\n-      }\n-\n-      CompletionStage<Void> restoreStage = restoreLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n-\n-               log.initiatingClusterRestore(backup);\n-               return reader.restore(backup, params);\n-            });\n-\n-      return CompletionStages.handleAndCompose(restoreStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = restoreLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n-                  );\n-               }\n-               log.restoreComplete();\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-   }\n-\n-   static class BackupRequest {\n-      final BackupWriter writer;\n-      final CompletableFuture<Path> future;\n-\n-      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n-         this.writer = writer;\n-         this.future = stage.toCompletableFuture();\n-      }\n-   }\n-\n-   static class Lock {\n-      final String name;\n-      final EmbeddedCacheManager cm;\n-      final boolean isClustered;\n-      volatile ClusteredLock clusteredLock;\n-      volatile AtomicBoolean localLock;\n-\n-      Lock(String name, EmbeddedCacheManager cm) {\n-         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n-         this.cm = cm;\n-         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n-      }\n-\n-      CompletionStage<Boolean> lock() {\n-         if (isClustered)\n-            return getClusteredLock().tryLock();\n-\n-         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n-      }\n-\n-      CompletionStage<Void> unlock() {\n-         if (isClustered)\n-            return getClusteredLock().unlock();\n-\n-         getLocalLock().compareAndSet(true, false);\n-         return CompletableFutures.completedNull();\n-      }\n-\n-      private ClusteredLock getClusteredLock() {\n-         if (clusteredLock == null) {\n-            synchronized (this) {\n-               if (clusteredLock == null) {\n-                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n-                  boolean isDefined = lockManager.isDefined(name);\n-                  if (!isDefined) {\n-                     lockManager.defineLock(name);\n-                  }\n-                  clusteredLock = lockManager.get(name);\n-               }\n-            }\n-         }\n-         return clusteredLock;\n-      }\n-\n-      private AtomicBoolean getLocalLock() {\n-         if (localLock == null)\n-            localLock = new AtomicBoolean();\n-         return localLock;\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nnew file mode 100644\nindex 0000000000..ca96b18bb1\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -0,0 +1,267 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n+import org.infinispan.lock.api.ClusteredLock;\n+import org.infinispan.lock.api.ClusteredLockManager;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n+   }\n+\n+   @Override\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n+   }\n+\n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n+   @Override\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n+      return create(\n+            name,\n+            workingDir,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n+      if (getBackupStatus(name) != Status.NOT_FOUND)\n+         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n+\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n+      CompletionStage<Path> backupStage = backupLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n+\n+               log.initiatingClusterBackup();\n+               return writer.create(params);\n+            });\n+\n+      backupStage = CompletionStages.handleAndCompose(backupStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = backupLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n+                  );\n+               }\n+               log.backupComplete(path.getFileName().toString());\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+\n+      backupMap.put(name, new BackupRequest(writer, backupStage));\n+      return backupStage;\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup) {\n+      return restore(\n+            backup,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n+      if (!Files.exists(backup)) {\n+         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n+         log.error(e);\n+         return CompletableFutures.completedExceptionFuture(e);\n+      }\n+\n+      CompletionStage<Void> restoreStage = restoreLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n+\n+               log.initiatingClusterRestore(backup);\n+               return reader.restore(backup, params);\n+            });\n+\n+      return CompletionStages.handleAndCompose(restoreStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = restoreLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n+                  );\n+               }\n+               log.restoreComplete();\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+   }\n+\n+   static class BackupRequest {\n+      final BackupWriter writer;\n+      final CompletableFuture<Path> future;\n+\n+      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n+         this.writer = writer;\n+         this.future = stage.toCompletableFuture();\n+      }\n+   }\n+\n+   static class Lock {\n+      final String name;\n+      final EmbeddedCacheManager cm;\n+      final boolean isClustered;\n+      volatile ClusteredLock clusteredLock;\n+      volatile AtomicBoolean localLock;\n+\n+      Lock(String name, EmbeddedCacheManager cm) {\n+         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n+         this.cm = cm;\n+         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n+      }\n+\n+      CompletionStage<Boolean> lock() {\n+         if (isClustered)\n+            return getClusteredLock().tryLock();\n+\n+         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n+      }\n+\n+      CompletionStage<Void> unlock() {\n+         if (isClustered)\n+            return getClusteredLock().unlock();\n+\n+         getLocalLock().compareAndSet(true, false);\n+         return CompletableFutures.completedNull();\n+      }\n+\n+      private ClusteredLock getClusteredLock() {\n+         if (clusteredLock == null) {\n+            synchronized (this) {\n+               if (clusteredLock == null) {\n+                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n+                  boolean isDefined = lockManager.isDefined(name);\n+                  if (!isDefined) {\n+                     lockManager.defineLock(name);\n+                  }\n+                  clusteredLock = lockManager.get(name);\n+               }\n+            }\n+         }\n+         return clusteredLock;\n+      }\n+\n+      private AtomicBoolean getLocalLock() {\n+         if (localLock == null)\n+            localLock = new AtomicBoolean();\n+         return localLock;\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex c99aa32c67..1741d5c075 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -53,8 +59,59 @@ public void init() {\n    }\n \n    @Override\n-   public CompletionStage<Path> create() {\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name) {\n       return create(\n+            name,\n             cacheManagers.entrySet().stream()\n                   .collect(Collectors.toMap(\n                         Map.Entry::getKey,\n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 1741d5c075..e72057aea9 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -109,9 +110,10 @@ private Status getBackupStatus(BackupRequest request) {\n    }\n \n    @Override\n-   public CompletionStage<Path> create(String name) {\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n       return create(\n             name,\n+            workingDir,\n             cacheManagers.entrySet().stream()\n                   .collect(Collectors.toMap(\n                         Map.Entry::getKey,\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\ndeleted file mode 100644\nindex e72057aea9..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,252 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n-\n-import java.io.IOException;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.stream.Collectors;\n-\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n-import org.infinispan.lock.api.ClusteredLock;\n-import org.infinispan.lock.api.ClusteredLockManager;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletableFutures;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.infinispan.util.logging.LogFactory;\n-\n-/**\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class BackupManagerImpl implements BackupManager {\n-\n-   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n-\n-   final ParserRegistry parserRegistry;\n-   final BlockingManager blockingManager;\n-   final Path rootDir;\n-   final BackupReader reader;\n-   final Lock backupLock;\n-   final Lock restoreLock;\n-   final Map<String, DefaultCacheManager> cacheManagers;\n-   final Map<String, BackupRequest> backupMap;\n-\n-   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n-      this.blockingManager = blockingManager;\n-      this.rootDir = dataRoot.resolve(WORKING_DIR);\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n-      this.backupLock = new Lock(\"backup\", cm);\n-      this.restoreLock = new Lock(\"restore\", cm);\n-      this.backupMap = new ConcurrentHashMap<>();\n-   }\n-\n-   @Override\n-   public void init() throws IOException {\n-      Files.createDirectories(rootDir);\n-   }\n-\n-   @Override\n-   public Status getBackupStatus(String name) {\n-      return getBackupStatus(backupMap.get(name));\n-   }\n-\n-   @Override\n-   public Path getBackupLocation(String name) {\n-      BackupRequest request = backupMap.get(name);\n-      Status status = getBackupStatus(request);\n-      if (status != Status.COMPLETE)\n-         return null;\n-      return request.future.join();\n-   }\n-\n-   private Status getBackupStatus(BackupRequest request) {\n-      if (request == null)\n-         return Status.NOT_FOUND;\n-\n-      CompletableFuture<Path> future = request.future;\n-      if (future.isCompletedExceptionally())\n-         return Status.FAILED;\n-\n-      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n-   }\n-\n-   @Override\n-   public CompletionStage<Status> removeBackup(String name) {\n-      BackupRequest request = backupMap.remove(name);\n-      Status status = getBackupStatus(request);\n-      switch (status) {\n-         case NOT_FOUND:\n-            return CompletableFuture.completedFuture(status);\n-         case COMPLETE:\n-         case FAILED:\n-            return blockingManager.supplyBlocking(() -> {\n-               request.writer.cleanup();\n-               return Status.COMPLETE;\n-            }, \"remove-completed-backup\");\n-         case IN_PROGRESS:\n-            // The backup files are removed on exceptional or successful completion.\n-            blockingManager.handleBlocking(request.future, (path, t) -> {\n-               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n-               request.writer.cleanup();\n-               return null;\n-            }, \"remove-inprogress-backup\");\n-            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n-      }\n-      throw new IllegalStateException();\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir) {\n-      return create(\n-            name,\n-            workingDir,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n-      if (getBackupStatus(name) != Status.NOT_FOUND)\n-         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n-\n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n-      CompletionStage<Path> backupStage = backupLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n-\n-               log.initiatingClusterBackup();\n-               return writer.create(params);\n-            });\n-\n-      backupStage = CompletionStages.handleAndCompose(backupStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = backupLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n-                  );\n-               }\n-               log.backupComplete(path.getFileName().toString());\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-\n-      backupMap.put(name, new BackupRequest(writer, backupStage));\n-      return backupStage;\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup) {\n-      return restore(\n-            backup,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n-      CompletionStage<Void> restoreStage = restoreLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n-\n-               log.initiatingClusterRestore();\n-               return reader.restore(backup, params);\n-            });\n-\n-      return CompletionStages.handleAndCompose(restoreStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = restoreLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(t))\n-                  );\n-               }\n-               log.restoreComplete();\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-   }\n-\n-   static class BackupRequest {\n-      final BackupWriter writer;\n-      final CompletableFuture<Path> future;\n-\n-      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n-         this.writer = writer;\n-         this.future = stage.toCompletableFuture();\n-      }\n-   }\n-\n-   static class Lock {\n-      final String name;\n-      final EmbeddedCacheManager cm;\n-      final boolean isClustered;\n-      volatile ClusteredLock clusteredLock;\n-      volatile AtomicBoolean localLock;\n-\n-      Lock(String name, EmbeddedCacheManager cm) {\n-         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n-         this.cm = cm;\n-         this.isClustered = cm.getCacheManagerConfiguration().isClustered();\n-      }\n-\n-      CompletionStage<Boolean> lock() {\n-         if (isClustered)\n-            return getClusteredLock().tryLock();\n-\n-         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n-      }\n-\n-      CompletionStage<Void> unlock() {\n-         if (isClustered)\n-            return getClusteredLock().unlock();\n-\n-         getLocalLock().compareAndSet(true, false);\n-         return CompletableFutures.completedNull();\n-      }\n-\n-      private ClusteredLock getClusteredLock() {\n-         if (clusteredLock == null) {\n-            synchronized (this) {\n-               if (clusteredLock == null) {\n-                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n-                  boolean isDefined = lockManager.isDefined(name);\n-                  if (!isDefined) {\n-                     lockManager.defineLock(name);\n-                  }\n-                  clusteredLock = lockManager.get(name);\n-               }\n-            }\n-         }\n-         return clusteredLock;\n-      }\n-\n-      private AtomicBoolean getLocalLock() {\n-         if (localLock == null)\n-            localLock = new AtomicBoolean();\n-         return localLock;\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nnew file mode 100644\nindex 0000000000..ca96b18bb1\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -0,0 +1,267 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n+import org.infinispan.lock.api.ClusteredLock;\n+import org.infinispan.lock.api.ClusteredLockManager;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n+   }\n+\n+   @Override\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n+   }\n+\n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n+   @Override\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n+      return create(\n+            name,\n+            workingDir,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n+      if (getBackupStatus(name) != Status.NOT_FOUND)\n+         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n+\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n+      CompletionStage<Path> backupStage = backupLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n+\n+               log.initiatingClusterBackup();\n+               return writer.create(params);\n+            });\n+\n+      backupStage = CompletionStages.handleAndCompose(backupStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = backupLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n+                  );\n+               }\n+               log.backupComplete(path.getFileName().toString());\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+\n+      backupMap.put(name, new BackupRequest(writer, backupStage));\n+      return backupStage;\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup) {\n+      return restore(\n+            backup,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n+      if (!Files.exists(backup)) {\n+         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n+         log.error(e);\n+         return CompletableFutures.completedExceptionFuture(e);\n+      }\n+\n+      CompletionStage<Void> restoreStage = restoreLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n+\n+               log.initiatingClusterRestore(backup);\n+               return reader.restore(backup, params);\n+            });\n+\n+      return CompletionStages.handleAndCompose(restoreStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = restoreLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n+                  );\n+               }\n+               log.restoreComplete();\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+   }\n+\n+   static class BackupRequest {\n+      final BackupWriter writer;\n+      final CompletableFuture<Path> future;\n+\n+      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n+         this.writer = writer;\n+         this.future = stage.toCompletableFuture();\n+      }\n+   }\n+\n+   static class Lock {\n+      final String name;\n+      final EmbeddedCacheManager cm;\n+      final boolean isClustered;\n+      volatile ClusteredLock clusteredLock;\n+      volatile AtomicBoolean localLock;\n+\n+      Lock(String name, EmbeddedCacheManager cm) {\n+         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n+         this.cm = cm;\n+         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n+      }\n+\n+      CompletionStage<Boolean> lock() {\n+         if (isClustered)\n+            return getClusteredLock().tryLock();\n+\n+         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n+      }\n+\n+      CompletionStage<Void> unlock() {\n+         if (isClustered)\n+            return getClusteredLock().unlock();\n+\n+         getLocalLock().compareAndSet(true, false);\n+         return CompletableFutures.completedNull();\n+      }\n+\n+      private ClusteredLock getClusteredLock() {\n+         if (clusteredLock == null) {\n+            synchronized (this) {\n+               if (clusteredLock == null) {\n+                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n+                  boolean isDefined = lockManager.isDefined(name);\n+                  if (!isDefined) {\n+                     lockManager.defineLock(name);\n+                  }\n+                  clusteredLock = lockManager.get(name);\n+               }\n+            }\n+         }\n+         return clusteredLock;\n+      }\n+\n+      private AtomicBoolean getLocalLock() {\n+         if (localLock == null)\n+            localLock = new AtomicBoolean();\n+         return localLock;\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}, {"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 1741d5c075..e72057aea9 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -120,11 +122,11 @@ private Status getBackupStatus(BackupRequest request) {\n    }\n \n    @Override\n-   public CompletionStage<Path> create(String name, Map<String, Resources> params) {\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n       if (getBackupStatus(name) != Status.NOT_FOUND)\n          return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n \n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, rootDir);\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n       CompletionStage<Path> backupStage = backupLock.lock()\n             .thenCompose(lockAcquired -> {\n                if (!lockAcquired)\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\ndeleted file mode 100644\nindex e72057aea9..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,252 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n-\n-import java.io.IOException;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.stream.Collectors;\n-\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n-import org.infinispan.lock.api.ClusteredLock;\n-import org.infinispan.lock.api.ClusteredLockManager;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletableFutures;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.infinispan.util.logging.LogFactory;\n-\n-/**\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class BackupManagerImpl implements BackupManager {\n-\n-   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n-\n-   final ParserRegistry parserRegistry;\n-   final BlockingManager blockingManager;\n-   final Path rootDir;\n-   final BackupReader reader;\n-   final Lock backupLock;\n-   final Lock restoreLock;\n-   final Map<String, DefaultCacheManager> cacheManagers;\n-   final Map<String, BackupRequest> backupMap;\n-\n-   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n-      this.blockingManager = blockingManager;\n-      this.rootDir = dataRoot.resolve(WORKING_DIR);\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n-      this.backupLock = new Lock(\"backup\", cm);\n-      this.restoreLock = new Lock(\"restore\", cm);\n-      this.backupMap = new ConcurrentHashMap<>();\n-   }\n-\n-   @Override\n-   public void init() throws IOException {\n-      Files.createDirectories(rootDir);\n-   }\n-\n-   @Override\n-   public Status getBackupStatus(String name) {\n-      return getBackupStatus(backupMap.get(name));\n-   }\n-\n-   @Override\n-   public Path getBackupLocation(String name) {\n-      BackupRequest request = backupMap.get(name);\n-      Status status = getBackupStatus(request);\n-      if (status != Status.COMPLETE)\n-         return null;\n-      return request.future.join();\n-   }\n-\n-   private Status getBackupStatus(BackupRequest request) {\n-      if (request == null)\n-         return Status.NOT_FOUND;\n-\n-      CompletableFuture<Path> future = request.future;\n-      if (future.isCompletedExceptionally())\n-         return Status.FAILED;\n-\n-      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n-   }\n-\n-   @Override\n-   public CompletionStage<Status> removeBackup(String name) {\n-      BackupRequest request = backupMap.remove(name);\n-      Status status = getBackupStatus(request);\n-      switch (status) {\n-         case NOT_FOUND:\n-            return CompletableFuture.completedFuture(status);\n-         case COMPLETE:\n-         case FAILED:\n-            return blockingManager.supplyBlocking(() -> {\n-               request.writer.cleanup();\n-               return Status.COMPLETE;\n-            }, \"remove-completed-backup\");\n-         case IN_PROGRESS:\n-            // The backup files are removed on exceptional or successful completion.\n-            blockingManager.handleBlocking(request.future, (path, t) -> {\n-               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n-               request.writer.cleanup();\n-               return null;\n-            }, \"remove-inprogress-backup\");\n-            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n-      }\n-      throw new IllegalStateException();\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir) {\n-      return create(\n-            name,\n-            workingDir,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n-      if (getBackupStatus(name) != Status.NOT_FOUND)\n-         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n-\n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n-      CompletionStage<Path> backupStage = backupLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n-\n-               log.initiatingClusterBackup();\n-               return writer.create(params);\n-            });\n-\n-      backupStage = CompletionStages.handleAndCompose(backupStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = backupLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n-                  );\n-               }\n-               log.backupComplete(path.getFileName().toString());\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-\n-      backupMap.put(name, new BackupRequest(writer, backupStage));\n-      return backupStage;\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup) {\n-      return restore(\n-            backup,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n-      CompletionStage<Void> restoreStage = restoreLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n-\n-               log.initiatingClusterRestore();\n-               return reader.restore(backup, params);\n-            });\n-\n-      return CompletionStages.handleAndCompose(restoreStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = restoreLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(t))\n-                  );\n-               }\n-               log.restoreComplete();\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-   }\n-\n-   static class BackupRequest {\n-      final BackupWriter writer;\n-      final CompletableFuture<Path> future;\n-\n-      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n-         this.writer = writer;\n-         this.future = stage.toCompletableFuture();\n-      }\n-   }\n-\n-   static class Lock {\n-      final String name;\n-      final EmbeddedCacheManager cm;\n-      final boolean isClustered;\n-      volatile ClusteredLock clusteredLock;\n-      volatile AtomicBoolean localLock;\n-\n-      Lock(String name, EmbeddedCacheManager cm) {\n-         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n-         this.cm = cm;\n-         this.isClustered = cm.getCacheManagerConfiguration().isClustered();\n-      }\n-\n-      CompletionStage<Boolean> lock() {\n-         if (isClustered)\n-            return getClusteredLock().tryLock();\n-\n-         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n-      }\n-\n-      CompletionStage<Void> unlock() {\n-         if (isClustered)\n-            return getClusteredLock().unlock();\n-\n-         getLocalLock().compareAndSet(true, false);\n-         return CompletableFutures.completedNull();\n-      }\n-\n-      private ClusteredLock getClusteredLock() {\n-         if (clusteredLock == null) {\n-            synchronized (this) {\n-               if (clusteredLock == null) {\n-                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n-                  boolean isDefined = lockManager.isDefined(name);\n-                  if (!isDefined) {\n-                     lockManager.defineLock(name);\n-                  }\n-                  clusteredLock = lockManager.get(name);\n-               }\n-            }\n-         }\n-         return clusteredLock;\n-      }\n-\n-      private AtomicBoolean getLocalLock() {\n-         if (localLock == null)\n-            localLock = new AtomicBoolean();\n-         return localLock;\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nnew file mode 100644\nindex 0000000000..ca96b18bb1\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -0,0 +1,267 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n+import org.infinispan.lock.api.ClusteredLock;\n+import org.infinispan.lock.api.ClusteredLockManager;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n+   }\n+\n+   @Override\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n+   }\n+\n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n+   @Override\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n+      return create(\n+            name,\n+            workingDir,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n+      if (getBackupStatus(name) != Status.NOT_FOUND)\n+         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n+\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n+      CompletionStage<Path> backupStage = backupLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n+\n+               log.initiatingClusterBackup();\n+               return writer.create(params);\n+            });\n+\n+      backupStage = CompletionStages.handleAndCompose(backupStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = backupLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n+                  );\n+               }\n+               log.backupComplete(path.getFileName().toString());\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+\n+      backupMap.put(name, new BackupRequest(writer, backupStage));\n+      return backupStage;\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup) {\n+      return restore(\n+            backup,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n+      if (!Files.exists(backup)) {\n+         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n+         log.error(e);\n+         return CompletableFutures.completedExceptionFuture(e);\n+      }\n+\n+      CompletionStage<Void> restoreStage = restoreLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n+\n+               log.initiatingClusterRestore(backup);\n+               return reader.restore(backup, params);\n+            });\n+\n+      return CompletionStages.handleAndCompose(restoreStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = restoreLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n+                  );\n+               }\n+               log.restoreComplete();\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+   }\n+\n+   static class BackupRequest {\n+      final BackupWriter writer;\n+      final CompletableFuture<Path> future;\n+\n+      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n+         this.writer = writer;\n+         this.future = stage.toCompletableFuture();\n+      }\n+   }\n+\n+   static class Lock {\n+      final String name;\n+      final EmbeddedCacheManager cm;\n+      final boolean isClustered;\n+      volatile ClusteredLock clusteredLock;\n+      volatile AtomicBoolean localLock;\n+\n+      Lock(String name, EmbeddedCacheManager cm) {\n+         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n+         this.cm = cm;\n+         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n+      }\n+\n+      CompletionStage<Boolean> lock() {\n+         if (isClustered)\n+            return getClusteredLock().tryLock();\n+\n+         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n+      }\n+\n+      CompletionStage<Void> unlock() {\n+         if (isClustered)\n+            return getClusteredLock().unlock();\n+\n+         getLocalLock().compareAndSet(true, false);\n+         return CompletableFutures.completedNull();\n+      }\n+\n+      private ClusteredLock getClusteredLock() {\n+         if (clusteredLock == null) {\n+            synchronized (this) {\n+               if (clusteredLock == null) {\n+                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n+                  boolean isDefined = lockManager.isDefined(name);\n+                  if (!isDefined) {\n+                     lockManager.defineLock(name);\n+                  }\n+                  clusteredLock = lockManager.get(name);\n+               }\n+            }\n+         }\n+         return clusteredLock;\n+      }\n+\n+      private AtomicBoolean getLocalLock() {\n+         if (localLock == null)\n+            localLock = new AtomicBoolean();\n+         return localLock;\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1MjIzMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457652233", "body": "I have never been a fan of doing stuff like this in a constructor. Maybe add a `makeDirectories` method to `BackupManager`?", "bodyText": "I have never been a fan of doing stuff like this in a constructor. Maybe add a makeDirectories method to BackupManager?", "bodyHTML": "<p dir=\"auto\">I have never been a fan of doing stuff like this in a constructor. Maybe add a <code>makeDirectories</code> method to <code>BackupManager</code>?</p>", "author": "wburns", "createdAt": "2020-07-20T19:49:03Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java", "diffHunk": "@@ -0,0 +1,117 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   private final AtomicBoolean backupInProgress = new AtomicBoolean();\n+   private final AtomicBoolean restoreInProgress = new AtomicBoolean();\n+\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final BackupWriter writer;\n+   final BlockingManager blockingManager;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                            Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n+      this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+      rootDir.toFile().mkdir();", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk2ODAyNg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457968026", "bodyText": "Good catch. As the rootDir is provided via Server.java I have moved the creation there.\nI've add a BackupManager#init method that can be used for all resource initialisation.", "author": "ryanemerson", "createdAt": "2020-07-21T09:38:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1MjIzMw=="}], "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 81c04f2d6a..797abe9a86 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -31,16 +31,18 @@\n    final Path rootDir;\n    final BackupReader reader;\n    final BackupWriter writer;\n-   final BlockingManager blockingManager;\n    final Map<String, DefaultCacheManager> cacheManagers;\n \n    public BackupManagerImpl(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n                             Path dataRoot) {\n-      this.blockingManager = blockingManager;\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n       this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n       this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+   }\n+\n+   @Override\n+   public void init() {\n       rootDir.toFile().mkdir();\n    }\n \n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 797abe9a86..c99aa32c67 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -25,20 +30,21 @@\n \n    private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n \n-   private final AtomicBoolean backupInProgress = new AtomicBoolean();\n-   private final AtomicBoolean restoreInProgress = new AtomicBoolean();\n-\n    final Path rootDir;\n    final BackupReader reader;\n    final BackupWriter writer;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n    final Map<String, DefaultCacheManager> cacheManagers;\n \n-   public BackupManagerImpl(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n-                            Path dataRoot) {\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n       this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n       this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n    }\n \n    @Override\n", "next_change": {"commit": "efedcd6e4718f909ec002c586f289f19d8703c3c", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex c99aa32c67..1741d5c075 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -30,21 +32,25 @@\n \n    private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n \n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n    final Path rootDir;\n    final BackupReader reader;\n-   final BackupWriter writer;\n    final Lock backupLock;\n    final Lock restoreLock;\n    final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n \n    public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n                             Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n-      this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n-      this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry, rootDir);\n       this.backupLock = new Lock(\"backup\", cm);\n       this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n    }\n \n    @Override\n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 1741d5c075..e72057aea9 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -47,15 +48,15 @@ public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager c\n       this.rootDir = dataRoot.resolve(WORKING_DIR);\n       this.cacheManagers = cacheManagers;\n       this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry, rootDir);\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n       this.backupLock = new Lock(\"backup\", cm);\n       this.restoreLock = new Lock(\"restore\", cm);\n       this.backupMap = new ConcurrentHashMap<>();\n    }\n \n    @Override\n-   public void init() {\n-      rootDir.toFile().mkdir();\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n    }\n \n    @Override\n", "next_change": {"commit": "273d51d75ac24b6893868ce0a373c07e368e1f24", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex e72057aea9..ca96b18bb1 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -59,6 +63,11 @@ public void init() throws IOException {\n       Files.createDirectories(rootDir);\n    }\n \n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n    @Override\n    public Status getBackupStatus(String name) {\n       return getBackupStatus(backupMap.get(name));\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\ndeleted file mode 100644\nindex ca96b18bb1..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,267 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.stream.Collectors;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n-import org.infinispan.lock.api.ClusteredLock;\n-import org.infinispan.lock.api.ClusteredLockManager;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletableFutures;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.infinispan.util.logging.LogFactory;\n-\n-/**\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class BackupManagerImpl implements BackupManager {\n-\n-   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n-\n-   final ParserRegistry parserRegistry;\n-   final BlockingManager blockingManager;\n-   final Path rootDir;\n-   final BackupReader reader;\n-   final Lock backupLock;\n-   final Lock restoreLock;\n-   final Map<String, DefaultCacheManager> cacheManagers;\n-   final Map<String, BackupRequest> backupMap;\n-\n-   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n-      this.blockingManager = blockingManager;\n-      this.rootDir = dataRoot.resolve(WORKING_DIR);\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n-      this.backupLock = new Lock(\"backup\", cm);\n-      this.restoreLock = new Lock(\"restore\", cm);\n-      this.backupMap = new ConcurrentHashMap<>();\n-   }\n-\n-   @Override\n-   public void init() throws IOException {\n-      Files.createDirectories(rootDir);\n-   }\n-\n-   @Override\n-   public Set<String> getBackupNames() {\n-      return new HashSet<>(backupMap.keySet());\n-   }\n-\n-   @Override\n-   public Status getBackupStatus(String name) {\n-      return getBackupStatus(backupMap.get(name));\n-   }\n-\n-   @Override\n-   public Path getBackupLocation(String name) {\n-      BackupRequest request = backupMap.get(name);\n-      Status status = getBackupStatus(request);\n-      if (status != Status.COMPLETE)\n-         return null;\n-      return request.future.join();\n-   }\n-\n-   private Status getBackupStatus(BackupRequest request) {\n-      if (request == null)\n-         return Status.NOT_FOUND;\n-\n-      CompletableFuture<Path> future = request.future;\n-      if (future.isCompletedExceptionally())\n-         return Status.FAILED;\n-\n-      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n-   }\n-\n-   @Override\n-   public CompletionStage<Status> removeBackup(String name) {\n-      BackupRequest request = backupMap.remove(name);\n-      Status status = getBackupStatus(request);\n-      switch (status) {\n-         case NOT_FOUND:\n-            return CompletableFuture.completedFuture(status);\n-         case COMPLETE:\n-         case FAILED:\n-            return blockingManager.supplyBlocking(() -> {\n-               request.writer.cleanup();\n-               return Status.COMPLETE;\n-            }, \"remove-completed-backup\");\n-         case IN_PROGRESS:\n-            // The backup files are removed on exceptional or successful completion.\n-            blockingManager.handleBlocking(request.future, (path, t) -> {\n-               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n-               request.writer.cleanup();\n-               return null;\n-            }, \"remove-inprogress-backup\");\n-            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n-      }\n-      throw new IllegalStateException();\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir) {\n-      return create(\n-            name,\n-            workingDir,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n-      if (getBackupStatus(name) != Status.NOT_FOUND)\n-         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n-\n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n-      CompletionStage<Path> backupStage = backupLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n-\n-               log.initiatingClusterBackup();\n-               return writer.create(params);\n-            });\n-\n-      backupStage = CompletionStages.handleAndCompose(backupStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = backupLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n-                  );\n-               }\n-               log.backupComplete(path.getFileName().toString());\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-\n-      backupMap.put(name, new BackupRequest(writer, backupStage));\n-      return backupStage;\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup) {\n-      return restore(\n-            backup,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n-      if (!Files.exists(backup)) {\n-         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n-         log.error(e);\n-         return CompletableFutures.completedExceptionFuture(e);\n-      }\n-\n-      CompletionStage<Void> restoreStage = restoreLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n-\n-               log.initiatingClusterRestore(backup);\n-               return reader.restore(backup, params);\n-            });\n-\n-      return CompletionStages.handleAndCompose(restoreStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = restoreLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n-                  );\n-               }\n-               log.restoreComplete();\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-   }\n-\n-   static class BackupRequest {\n-      final BackupWriter writer;\n-      final CompletableFuture<Path> future;\n-\n-      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n-         this.writer = writer;\n-         this.future = stage.toCompletableFuture();\n-      }\n-   }\n-\n-   static class Lock {\n-      final String name;\n-      final EmbeddedCacheManager cm;\n-      final boolean isClustered;\n-      volatile ClusteredLock clusteredLock;\n-      volatile AtomicBoolean localLock;\n-\n-      Lock(String name, EmbeddedCacheManager cm) {\n-         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n-         this.cm = cm;\n-         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n-      }\n-\n-      CompletionStage<Boolean> lock() {\n-         if (isClustered)\n-            return getClusteredLock().tryLock();\n-\n-         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n-      }\n-\n-      CompletionStage<Void> unlock() {\n-         if (isClustered)\n-            return getClusteredLock().unlock();\n-\n-         getLocalLock().compareAndSet(true, false);\n-         return CompletableFutures.completedNull();\n-      }\n-\n-      private ClusteredLock getClusteredLock() {\n-         if (clusteredLock == null) {\n-            synchronized (this) {\n-               if (clusteredLock == null) {\n-                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n-                  boolean isDefined = lockManager.isDefined(name);\n-                  if (!isDefined) {\n-                     lockManager.defineLock(name);\n-                  }\n-                  clusteredLock = lockManager.get(name);\n-               }\n-            }\n-         }\n-         return clusteredLock;\n-      }\n-\n-      private AtomicBoolean getLocalLock() {\n-         if (localLock == null)\n-            localLock = new AtomicBoolean();\n-         return localLock;\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nnew file mode 100644\nindex 0000000000..ca96b18bb1\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -0,0 +1,267 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n+import org.infinispan.lock.api.ClusteredLock;\n+import org.infinispan.lock.api.ClusteredLockManager;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n+   }\n+\n+   @Override\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n+   }\n+\n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n+   @Override\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n+      return create(\n+            name,\n+            workingDir,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n+      if (getBackupStatus(name) != Status.NOT_FOUND)\n+         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n+\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n+      CompletionStage<Path> backupStage = backupLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n+\n+               log.initiatingClusterBackup();\n+               return writer.create(params);\n+            });\n+\n+      backupStage = CompletionStages.handleAndCompose(backupStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = backupLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n+                  );\n+               }\n+               log.backupComplete(path.getFileName().toString());\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+\n+      backupMap.put(name, new BackupRequest(writer, backupStage));\n+      return backupStage;\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup) {\n+      return restore(\n+            backup,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n+      if (!Files.exists(backup)) {\n+         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n+         log.error(e);\n+         return CompletableFutures.completedExceptionFuture(e);\n+      }\n+\n+      CompletionStage<Void> restoreStage = restoreLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n+\n+               log.initiatingClusterRestore(backup);\n+               return reader.restore(backup, params);\n+            });\n+\n+      return CompletionStages.handleAndCompose(restoreStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = restoreLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n+                  );\n+               }\n+               log.restoreComplete();\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+   }\n+\n+   static class BackupRequest {\n+      final BackupWriter writer;\n+      final CompletableFuture<Path> future;\n+\n+      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n+         this.writer = writer;\n+         this.future = stage.toCompletableFuture();\n+      }\n+   }\n+\n+   static class Lock {\n+      final String name;\n+      final EmbeddedCacheManager cm;\n+      final boolean isClustered;\n+      volatile ClusteredLock clusteredLock;\n+      volatile AtomicBoolean localLock;\n+\n+      Lock(String name, EmbeddedCacheManager cm) {\n+         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n+         this.cm = cm;\n+         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n+      }\n+\n+      CompletionStage<Boolean> lock() {\n+         if (isClustered)\n+            return getClusteredLock().tryLock();\n+\n+         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n+      }\n+\n+      CompletionStage<Void> unlock() {\n+         if (isClustered)\n+            return getClusteredLock().unlock();\n+\n+         getLocalLock().compareAndSet(true, false);\n+         return CompletableFutures.completedNull();\n+      }\n+\n+      private ClusteredLock getClusteredLock() {\n+         if (clusteredLock == null) {\n+            synchronized (this) {\n+               if (clusteredLock == null) {\n+                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n+                  boolean isDefined = lockManager.isDefined(name);\n+                  if (!isDefined) {\n+                     lockManager.defineLock(name);\n+                  }\n+                  clusteredLock = lockManager.get(name);\n+               }\n+            }\n+         }\n+         return clusteredLock;\n+      }\n+\n+      private AtomicBoolean getLocalLock() {\n+         if (localLock == null)\n+            localLock = new AtomicBoolean();\n+         return localLock;\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex c99aa32c67..1741d5c075 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -53,8 +59,59 @@ public void init() {\n    }\n \n    @Override\n-   public CompletionStage<Path> create() {\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name) {\n       return create(\n+            name,\n             cacheManagers.entrySet().stream()\n                   .collect(Collectors.toMap(\n                         Map.Entry::getKey,\n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 1741d5c075..e72057aea9 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -109,9 +110,10 @@ private Status getBackupStatus(BackupRequest request) {\n    }\n \n    @Override\n-   public CompletionStage<Path> create(String name) {\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n       return create(\n             name,\n+            workingDir,\n             cacheManagers.entrySet().stream()\n                   .collect(Collectors.toMap(\n                         Map.Entry::getKey,\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\ndeleted file mode 100644\nindex e72057aea9..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,252 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n-\n-import java.io.IOException;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.stream.Collectors;\n-\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n-import org.infinispan.lock.api.ClusteredLock;\n-import org.infinispan.lock.api.ClusteredLockManager;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletableFutures;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.infinispan.util.logging.LogFactory;\n-\n-/**\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class BackupManagerImpl implements BackupManager {\n-\n-   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n-\n-   final ParserRegistry parserRegistry;\n-   final BlockingManager blockingManager;\n-   final Path rootDir;\n-   final BackupReader reader;\n-   final Lock backupLock;\n-   final Lock restoreLock;\n-   final Map<String, DefaultCacheManager> cacheManagers;\n-   final Map<String, BackupRequest> backupMap;\n-\n-   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n-      this.blockingManager = blockingManager;\n-      this.rootDir = dataRoot.resolve(WORKING_DIR);\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n-      this.backupLock = new Lock(\"backup\", cm);\n-      this.restoreLock = new Lock(\"restore\", cm);\n-      this.backupMap = new ConcurrentHashMap<>();\n-   }\n-\n-   @Override\n-   public void init() throws IOException {\n-      Files.createDirectories(rootDir);\n-   }\n-\n-   @Override\n-   public Status getBackupStatus(String name) {\n-      return getBackupStatus(backupMap.get(name));\n-   }\n-\n-   @Override\n-   public Path getBackupLocation(String name) {\n-      BackupRequest request = backupMap.get(name);\n-      Status status = getBackupStatus(request);\n-      if (status != Status.COMPLETE)\n-         return null;\n-      return request.future.join();\n-   }\n-\n-   private Status getBackupStatus(BackupRequest request) {\n-      if (request == null)\n-         return Status.NOT_FOUND;\n-\n-      CompletableFuture<Path> future = request.future;\n-      if (future.isCompletedExceptionally())\n-         return Status.FAILED;\n-\n-      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n-   }\n-\n-   @Override\n-   public CompletionStage<Status> removeBackup(String name) {\n-      BackupRequest request = backupMap.remove(name);\n-      Status status = getBackupStatus(request);\n-      switch (status) {\n-         case NOT_FOUND:\n-            return CompletableFuture.completedFuture(status);\n-         case COMPLETE:\n-         case FAILED:\n-            return blockingManager.supplyBlocking(() -> {\n-               request.writer.cleanup();\n-               return Status.COMPLETE;\n-            }, \"remove-completed-backup\");\n-         case IN_PROGRESS:\n-            // The backup files are removed on exceptional or successful completion.\n-            blockingManager.handleBlocking(request.future, (path, t) -> {\n-               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n-               request.writer.cleanup();\n-               return null;\n-            }, \"remove-inprogress-backup\");\n-            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n-      }\n-      throw new IllegalStateException();\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir) {\n-      return create(\n-            name,\n-            workingDir,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n-      if (getBackupStatus(name) != Status.NOT_FOUND)\n-         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n-\n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n-      CompletionStage<Path> backupStage = backupLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n-\n-               log.initiatingClusterBackup();\n-               return writer.create(params);\n-            });\n-\n-      backupStage = CompletionStages.handleAndCompose(backupStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = backupLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n-                  );\n-               }\n-               log.backupComplete(path.getFileName().toString());\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-\n-      backupMap.put(name, new BackupRequest(writer, backupStage));\n-      return backupStage;\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup) {\n-      return restore(\n-            backup,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n-      CompletionStage<Void> restoreStage = restoreLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n-\n-               log.initiatingClusterRestore();\n-               return reader.restore(backup, params);\n-            });\n-\n-      return CompletionStages.handleAndCompose(restoreStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = restoreLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(t))\n-                  );\n-               }\n-               log.restoreComplete();\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-   }\n-\n-   static class BackupRequest {\n-      final BackupWriter writer;\n-      final CompletableFuture<Path> future;\n-\n-      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n-         this.writer = writer;\n-         this.future = stage.toCompletableFuture();\n-      }\n-   }\n-\n-   static class Lock {\n-      final String name;\n-      final EmbeddedCacheManager cm;\n-      final boolean isClustered;\n-      volatile ClusteredLock clusteredLock;\n-      volatile AtomicBoolean localLock;\n-\n-      Lock(String name, EmbeddedCacheManager cm) {\n-         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n-         this.cm = cm;\n-         this.isClustered = cm.getCacheManagerConfiguration().isClustered();\n-      }\n-\n-      CompletionStage<Boolean> lock() {\n-         if (isClustered)\n-            return getClusteredLock().tryLock();\n-\n-         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n-      }\n-\n-      CompletionStage<Void> unlock() {\n-         if (isClustered)\n-            return getClusteredLock().unlock();\n-\n-         getLocalLock().compareAndSet(true, false);\n-         return CompletableFutures.completedNull();\n-      }\n-\n-      private ClusteredLock getClusteredLock() {\n-         if (clusteredLock == null) {\n-            synchronized (this) {\n-               if (clusteredLock == null) {\n-                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n-                  boolean isDefined = lockManager.isDefined(name);\n-                  if (!isDefined) {\n-                     lockManager.defineLock(name);\n-                  }\n-                  clusteredLock = lockManager.get(name);\n-               }\n-            }\n-         }\n-         return clusteredLock;\n-      }\n-\n-      private AtomicBoolean getLocalLock() {\n-         if (localLock == null)\n-            localLock = new AtomicBoolean();\n-         return localLock;\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nnew file mode 100644\nindex 0000000000..ca96b18bb1\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -0,0 +1,267 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n+import org.infinispan.lock.api.ClusteredLock;\n+import org.infinispan.lock.api.ClusteredLockManager;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n+   }\n+\n+   @Override\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n+   }\n+\n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n+   @Override\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n+      return create(\n+            name,\n+            workingDir,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n+      if (getBackupStatus(name) != Status.NOT_FOUND)\n+         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n+\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n+      CompletionStage<Path> backupStage = backupLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n+\n+               log.initiatingClusterBackup();\n+               return writer.create(params);\n+            });\n+\n+      backupStage = CompletionStages.handleAndCompose(backupStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = backupLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n+                  );\n+               }\n+               log.backupComplete(path.getFileName().toString());\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+\n+      backupMap.put(name, new BackupRequest(writer, backupStage));\n+      return backupStage;\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup) {\n+      return restore(\n+            backup,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n+      if (!Files.exists(backup)) {\n+         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n+         log.error(e);\n+         return CompletableFutures.completedExceptionFuture(e);\n+      }\n+\n+      CompletionStage<Void> restoreStage = restoreLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n+\n+               log.initiatingClusterRestore(backup);\n+               return reader.restore(backup, params);\n+            });\n+\n+      return CompletionStages.handleAndCompose(restoreStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = restoreLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n+                  );\n+               }\n+               log.restoreComplete();\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+   }\n+\n+   static class BackupRequest {\n+      final BackupWriter writer;\n+      final CompletableFuture<Path> future;\n+\n+      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n+         this.writer = writer;\n+         this.future = stage.toCompletableFuture();\n+      }\n+   }\n+\n+   static class Lock {\n+      final String name;\n+      final EmbeddedCacheManager cm;\n+      final boolean isClustered;\n+      volatile ClusteredLock clusteredLock;\n+      volatile AtomicBoolean localLock;\n+\n+      Lock(String name, EmbeddedCacheManager cm) {\n+         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n+         this.cm = cm;\n+         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n+      }\n+\n+      CompletionStage<Boolean> lock() {\n+         if (isClustered)\n+            return getClusteredLock().tryLock();\n+\n+         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n+      }\n+\n+      CompletionStage<Void> unlock() {\n+         if (isClustered)\n+            return getClusteredLock().unlock();\n+\n+         getLocalLock().compareAndSet(true, false);\n+         return CompletableFutures.completedNull();\n+      }\n+\n+      private ClusteredLock getClusteredLock() {\n+         if (clusteredLock == null) {\n+            synchronized (this) {\n+               if (clusteredLock == null) {\n+                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n+                  boolean isDefined = lockManager.isDefined(name);\n+                  if (!isDefined) {\n+                     lockManager.defineLock(name);\n+                  }\n+                  clusteredLock = lockManager.get(name);\n+               }\n+            }\n+         }\n+         return clusteredLock;\n+      }\n+\n+      private AtomicBoolean getLocalLock() {\n+         if (localLock == null)\n+            localLock = new AtomicBoolean();\n+         return localLock;\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}, {"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nindex 1741d5c075..e72057aea9 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -120,11 +122,11 @@ private Status getBackupStatus(BackupRequest request) {\n    }\n \n    @Override\n-   public CompletionStage<Path> create(String name, Map<String, Resources> params) {\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n       if (getBackupStatus(name) != Status.NOT_FOUND)\n          return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n \n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, rootDir);\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n       CompletionStage<Path> backupStage = backupLock.lock()\n             .thenCompose(lockAcquired -> {\n                if (!lockAcquired)\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\ndeleted file mode 100644\nindex e72057aea9..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n+++ /dev/null\n", "chunk": "@@ -1,252 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n-\n-import java.io.IOException;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.stream.Collectors;\n-\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n-import org.infinispan.lock.api.ClusteredLock;\n-import org.infinispan.lock.api.ClusteredLockManager;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletableFutures;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.infinispan.util.logging.LogFactory;\n-\n-/**\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class BackupManagerImpl implements BackupManager {\n-\n-   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n-\n-   final ParserRegistry parserRegistry;\n-   final BlockingManager blockingManager;\n-   final Path rootDir;\n-   final BackupReader reader;\n-   final Lock backupLock;\n-   final Lock restoreLock;\n-   final Map<String, DefaultCacheManager> cacheManagers;\n-   final Map<String, BackupRequest> backupMap;\n-\n-   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n-      this.blockingManager = blockingManager;\n-      this.rootDir = dataRoot.resolve(WORKING_DIR);\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = new ParserRegistry();\n-      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n-      this.backupLock = new Lock(\"backup\", cm);\n-      this.restoreLock = new Lock(\"restore\", cm);\n-      this.backupMap = new ConcurrentHashMap<>();\n-   }\n-\n-   @Override\n-   public void init() throws IOException {\n-      Files.createDirectories(rootDir);\n-   }\n-\n-   @Override\n-   public Status getBackupStatus(String name) {\n-      return getBackupStatus(backupMap.get(name));\n-   }\n-\n-   @Override\n-   public Path getBackupLocation(String name) {\n-      BackupRequest request = backupMap.get(name);\n-      Status status = getBackupStatus(request);\n-      if (status != Status.COMPLETE)\n-         return null;\n-      return request.future.join();\n-   }\n-\n-   private Status getBackupStatus(BackupRequest request) {\n-      if (request == null)\n-         return Status.NOT_FOUND;\n-\n-      CompletableFuture<Path> future = request.future;\n-      if (future.isCompletedExceptionally())\n-         return Status.FAILED;\n-\n-      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n-   }\n-\n-   @Override\n-   public CompletionStage<Status> removeBackup(String name) {\n-      BackupRequest request = backupMap.remove(name);\n-      Status status = getBackupStatus(request);\n-      switch (status) {\n-         case NOT_FOUND:\n-            return CompletableFuture.completedFuture(status);\n-         case COMPLETE:\n-         case FAILED:\n-            return blockingManager.supplyBlocking(() -> {\n-               request.writer.cleanup();\n-               return Status.COMPLETE;\n-            }, \"remove-completed-backup\");\n-         case IN_PROGRESS:\n-            // The backup files are removed on exceptional or successful completion.\n-            blockingManager.handleBlocking(request.future, (path, t) -> {\n-               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n-               request.writer.cleanup();\n-               return null;\n-            }, \"remove-inprogress-backup\");\n-            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n-      }\n-      throw new IllegalStateException();\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir) {\n-      return create(\n-            name,\n-            workingDir,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n-      if (getBackupStatus(name) != Status.NOT_FOUND)\n-         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n-\n-      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n-      CompletionStage<Path> backupStage = backupLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n-\n-               log.initiatingClusterBackup();\n-               return writer.create(params);\n-            });\n-\n-      backupStage = CompletionStages.handleAndCompose(backupStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = backupLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n-                  );\n-               }\n-               log.backupComplete(path.getFileName().toString());\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-\n-      backupMap.put(name, new BackupRequest(writer, backupStage));\n-      return backupStage;\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup) {\n-      return restore(\n-            backup,\n-            cacheManagers.entrySet().stream()\n-                  .collect(Collectors.toMap(\n-                        Map.Entry::getKey,\n-                        p -> new BackupManagerResources.Builder().includeAll().build()))\n-      );\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n-      CompletionStage<Void> restoreStage = restoreLock.lock()\n-            .thenCompose(lockAcquired -> {\n-               if (!lockAcquired)\n-                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n-\n-               log.initiatingClusterRestore();\n-               return reader.restore(backup, params);\n-            });\n-\n-      return CompletionStages.handleAndCompose(restoreStage,\n-            (path, t) -> {\n-               CompletionStage<Void> unlock = restoreLock.unlock();\n-               if (t != null) {\n-                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n-                  return unlock.thenCompose(ignore ->\n-                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(t))\n-                  );\n-               }\n-               log.restoreComplete();\n-               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n-            });\n-   }\n-\n-   static class BackupRequest {\n-      final BackupWriter writer;\n-      final CompletableFuture<Path> future;\n-\n-      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n-         this.writer = writer;\n-         this.future = stage.toCompletableFuture();\n-      }\n-   }\n-\n-   static class Lock {\n-      final String name;\n-      final EmbeddedCacheManager cm;\n-      final boolean isClustered;\n-      volatile ClusteredLock clusteredLock;\n-      volatile AtomicBoolean localLock;\n-\n-      Lock(String name, EmbeddedCacheManager cm) {\n-         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n-         this.cm = cm;\n-         this.isClustered = cm.getCacheManagerConfiguration().isClustered();\n-      }\n-\n-      CompletionStage<Boolean> lock() {\n-         if (isClustered)\n-            return getClusteredLock().tryLock();\n-\n-         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n-      }\n-\n-      CompletionStage<Void> unlock() {\n-         if (isClustered)\n-            return getClusteredLock().unlock();\n-\n-         getLocalLock().compareAndSet(true, false);\n-         return CompletableFutures.completedNull();\n-      }\n-\n-      private ClusteredLock getClusteredLock() {\n-         if (clusteredLock == null) {\n-            synchronized (this) {\n-               if (clusteredLock == null) {\n-                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n-                  boolean isDefined = lockManager.isDefined(name);\n-                  if (!isDefined) {\n-                     lockManager.defineLock(name);\n-                  }\n-                  clusteredLock = lockManager.get(name);\n-               }\n-            }\n-         }\n-         return clusteredLock;\n-      }\n-\n-      private AtomicBoolean getLocalLock() {\n-         if (localLock == null)\n-            localLock = new AtomicBoolean();\n-         return localLock;\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\nnew file mode 100644\nindex 0000000000..ca96b18bb1\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java\n", "chunk": "@@ -0,0 +1,267 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.lock.EmbeddedClusteredLockManagerFactory;\n+import org.infinispan.lock.api.ClusteredLock;\n+import org.infinispan.lock.api.ClusteredLockManager;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   final ParserRegistry parserRegistry;\n+   final BlockingManager blockingManager;\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final Lock backupLock;\n+   final Lock restoreLock;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+   final Map<String, BackupRequest> backupMap;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                            Map<String, DefaultCacheManager> cacheManagers, Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = new ParserRegistry();\n+      this.reader = new BackupReader(blockingManager, cacheManagers, parserRegistry);\n+      this.backupLock = new Lock(\"backup\", cm);\n+      this.restoreLock = new Lock(\"restore\", cm);\n+      this.backupMap = new ConcurrentHashMap<>();\n+   }\n+\n+   @Override\n+   public void init() throws IOException {\n+      Files.createDirectories(rootDir);\n+   }\n+\n+   @Override\n+   public Set<String> getBackupNames() {\n+      return new HashSet<>(backupMap.keySet());\n+   }\n+\n+   @Override\n+   public Status getBackupStatus(String name) {\n+      return getBackupStatus(backupMap.get(name));\n+   }\n+\n+   @Override\n+   public Path getBackupLocation(String name) {\n+      BackupRequest request = backupMap.get(name);\n+      Status status = getBackupStatus(request);\n+      if (status != Status.COMPLETE)\n+         return null;\n+      return request.future.join();\n+   }\n+\n+   private Status getBackupStatus(BackupRequest request) {\n+      if (request == null)\n+         return Status.NOT_FOUND;\n+\n+      CompletableFuture<Path> future = request.future;\n+      if (future.isCompletedExceptionally())\n+         return Status.FAILED;\n+\n+      return future.isDone() ? Status.COMPLETE : Status.IN_PROGRESS;\n+   }\n+\n+   @Override\n+   public CompletionStage<Status> removeBackup(String name) {\n+      BackupRequest request = backupMap.remove(name);\n+      Status status = getBackupStatus(request);\n+      switch (status) {\n+         case NOT_FOUND:\n+            return CompletableFuture.completedFuture(status);\n+         case COMPLETE:\n+         case FAILED:\n+            return blockingManager.supplyBlocking(() -> {\n+               request.writer.cleanup();\n+               return Status.COMPLETE;\n+            }, \"remove-completed-backup\");\n+         case IN_PROGRESS:\n+            // The backup files are removed on exceptional or successful completion.\n+            blockingManager.handleBlocking(request.future, (path, t) -> {\n+               // Regardless of whether the backup completes exceptionally or successfully, we remove the files\n+               request.writer.cleanup();\n+               return null;\n+            }, \"remove-inprogress-backup\");\n+            return CompletableFuture.completedFuture(Status.IN_PROGRESS);\n+      }\n+      throw new IllegalStateException();\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir) {\n+      return create(\n+            name,\n+            workingDir,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Path> create(String name, Path workingDir, Map<String, Resources> params) {\n+      if (getBackupStatus(name) != Status.NOT_FOUND)\n+         return CompletableFutures.completedExceptionFuture(log.backupAlreadyExists(name));\n+\n+      BackupWriter writer = new BackupWriter(name, blockingManager, cacheManagers, parserRegistry, workingDir == null ? rootDir : workingDir);\n+      CompletionStage<Path> backupStage = backupLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.backupInProgress());\n+\n+               log.initiatingClusterBackup();\n+               return writer.create(params);\n+            });\n+\n+      backupStage = CompletionStages.handleAndCompose(backupStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = backupLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when creating a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorCreatingBackup(t))\n+                  );\n+               }\n+               log.backupComplete(path.getFileName().toString());\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+\n+      backupMap.put(name, new BackupRequest(writer, backupStage));\n+      return backupStage;\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup) {\n+      return restore(\n+            backup,\n+            cacheManagers.entrySet().stream()\n+                  .collect(Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        p -> new BackupManagerResources.Builder().includeAll().build()))\n+      );\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(Path backup, Map<String, Resources> params) {\n+      if (!Files.exists(backup)) {\n+         CacheException e = log.errorRestoringBackup(backup, new FileNotFoundException(backup.toString()));\n+         log.error(e);\n+         return CompletableFutures.completedExceptionFuture(e);\n+      }\n+\n+      CompletionStage<Void> restoreStage = restoreLock.lock()\n+            .thenCompose(lockAcquired -> {\n+               if (!lockAcquired)\n+                  return CompletableFutures.completedExceptionFuture(log.restoreInProgress());\n+\n+               log.initiatingClusterRestore(backup);\n+               return reader.restore(backup, params);\n+            });\n+\n+      return CompletionStages.handleAndCompose(restoreStage,\n+            (path, t) -> {\n+               CompletionStage<Void> unlock = restoreLock.unlock();\n+               if (t != null) {\n+                  log.debug(\"Exception encountered when restoring a cluster backup\", t);\n+                  return unlock.thenCompose(ignore ->\n+                        CompletableFutures.completedExceptionFuture(log.errorRestoringBackup(backup, t))\n+                  );\n+               }\n+               log.restoreComplete();\n+               return unlock.thenCompose(ignore -> CompletableFuture.completedFuture(path));\n+            });\n+   }\n+\n+   static class BackupRequest {\n+      final BackupWriter writer;\n+      final CompletableFuture<Path> future;\n+\n+      BackupRequest(BackupWriter writer, CompletionStage<Path> stage) {\n+         this.writer = writer;\n+         this.future = stage.toCompletableFuture();\n+      }\n+   }\n+\n+   static class Lock {\n+      final String name;\n+      final EmbeddedCacheManager cm;\n+      final boolean isClustered;\n+      volatile ClusteredLock clusteredLock;\n+      volatile AtomicBoolean localLock;\n+\n+      Lock(String name, EmbeddedCacheManager cm) {\n+         this.name = String.format(\"%s-%s\", BackupManagerImpl.class.getSimpleName(), name);\n+         this.cm = cm;\n+         this.isClustered = SecurityActions.getGlobalConfiguration(cm).isClustered();\n+      }\n+\n+      CompletionStage<Boolean> lock() {\n+         if (isClustered)\n+            return getClusteredLock().tryLock();\n+\n+         return CompletableFuture.completedFuture(getLocalLock().compareAndSet(false, true));\n+      }\n+\n+      CompletionStage<Void> unlock() {\n+         if (isClustered)\n+            return getClusteredLock().unlock();\n+\n+         getLocalLock().compareAndSet(true, false);\n+         return CompletableFutures.completedNull();\n+      }\n+\n+      private ClusteredLock getClusteredLock() {\n+         if (clusteredLock == null) {\n+            synchronized (this) {\n+               if (clusteredLock == null) {\n+                  ClusteredLockManager lockManager = EmbeddedClusteredLockManagerFactory.from(cm);\n+                  boolean isDefined = lockManager.isDefined(name);\n+                  if (!isDefined) {\n+                     lockManager.defineLock(name);\n+                  }\n+                  clusteredLock = lockManager.get(name);\n+               }\n+            }\n+         }\n+         return clusteredLock;\n+      }\n+\n+      private AtomicBoolean getLocalLock() {\n+         if (localLock == null)\n+            localLock = new AtomicBoolean();\n+         return localLock;\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Njk2MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457656960", "body": "Is there a reason this isn't in the same code block as below? Unfortunately this will hand off the processing to a non blocking thread which will then just hand back off to a different blocking thread. If instead it is just one lambda it won't do this handoff.", "bodyText": "Is there a reason this isn't in the same code block as below? Unfortunately this will hand off the processing to a non blocking thread which will then just hand back off to a different blocking thread. If instead it is just one lambda it won't do this handoff.", "bodyHTML": "<p dir=\"auto\">Is there a reason this isn't in the same code block as below? Unfortunately this will hand off the processing to a non blocking thread which will then just hand back off to a different blocking thread. If instead it is just one lambda it won't do this handoff.</p>", "author": "wburns", "createdAt": "2020-07-20T19:58:11Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java", "diffHunk": "@@ -0,0 +1,140 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.STAGING_ZIP;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.logging.LogFactory;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupReader {\n+\n+   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final Path rootDir;\n+\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+   }\n+\n+   CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.ContainerResources> params) {\n+      final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n+\n+      CompletionStage<Void> createStagingFile = blockingManager.runBlocking(() -> {", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk1MDAxOA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457950018", "bodyText": "I was trying to make it more fine-grained, but after your explanation I can see that doesn't really make sense as the operations obviously depend on each other \ud83d\ude42", "author": "ryanemerson", "createdAt": "2020-07-21T09:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Njk2MA=="}], "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nindex 02a07a4ed2..d845923413 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -56,15 +56,13 @@ public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheMan\n    CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.ContainerResources> params) {\n       final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n \n-      CompletionStage<Void> createStagingFile = blockingManager.runBlocking(() -> {\n+      CompletionStage<?> processContainers = blockingManager.supplyBlocking(() -> {\n          try {\n             Files.copy(is, stagingFile);\n          } catch (IOException e) {\n             throw new CacheException(e);\n          }\n-      }, \"create-staging\");\n \n-      CompletionStage<?> processContainers = blockingManager.thenApplyBlocking(createStagingFile, Void -> {\n          try (ZipFile zip = new ZipFile(stagingFile.toFile())) {\n             Properties manifest = readManifestAndValidate(zip);\n \n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nindex d845923413..cc5a9ab59c 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -45,25 +44,18 @@\n \n    private final BlockingManager blockingManager;\n    private final Map<String, DefaultCacheManager> cacheManagers;\n-   private final Path rootDir;\n+   private final ParserRegistry parserRegistry;\n \n-   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                       ParserRegistry parserRegistry) {\n       this.blockingManager = blockingManager;\n       this.cacheManagers = cacheManagers;\n-      this.rootDir = rootDir;\n+      this.parserRegistry = parserRegistry;\n    }\n \n-   CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.ContainerResources> params) {\n-      final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n-\n-      CompletionStage<?> processContainers = blockingManager.supplyBlocking(() -> {\n-         try {\n-            Files.copy(is, stagingFile);\n-         } catch (IOException e) {\n-            throw new CacheException(e);\n-         }\n-\n-         try (ZipFile zip = new ZipFile(stagingFile.toFile())) {\n+   CompletionStage<Void> restore(Path backup, Map<String, BackupManager.Resources> params) {\n+      return blockingManager.runBlocking(() -> {\n+         try (ZipFile zip = new ZipFile(backup.toFile())) {\n             Properties manifest = readManifestAndValidate(zip);\n \n             List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\ndeleted file mode 100644\nindex cc5a9ab59c..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ /dev/null\n", "chunk": "@@ -1,121 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n-import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.nio.file.Path;\n-import java.nio.file.Paths;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipFile;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.logging.LogFactory;\n-import org.infinispan.commons.util.Version;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-\n-/**\n- * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-class BackupReader {\n-\n-   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n-\n-   private final BlockingManager blockingManager;\n-   private final Map<String, DefaultCacheManager> cacheManagers;\n-   private final ParserRegistry parserRegistry;\n-\n-   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n-                       ParserRegistry parserRegistry) {\n-      this.blockingManager = blockingManager;\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   CompletionStage<Void> restore(Path backup, Map<String, BackupManager.Resources> params) {\n-      return blockingManager.runBlocking(() -> {\n-         try (ZipFile zip = new ZipFile(backup.toFile())) {\n-            Properties manifest = readManifestAndValidate(zip);\n-\n-            List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n-            Set<String> requestedContainers = new HashSet<>(params.keySet());\n-            requestedContainers.removeAll(backupContainers);\n-            if (!requestedContainers.isEmpty()) {\n-               throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n-            }\n-\n-            AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-            for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n-               stages.dependsOn(restoreContainer(e.getKey(), e.getValue(), zip));\n-            }\n-            CompletionStages.join(stages.freeze());\n-         } catch (IOException e) {\n-            throw new CacheException(String.format(\"Unable to read zip file '%s'\", backup));\n-         }\n-      }, \"process-containers\");\n-   }\n-\n-   private CompletionStage<Void> restoreContainer(String containerName, BackupManager.Resources params, ZipFile zip) {\n-      // TODO validate container config\n-      EmbeddedCacheManager cm = cacheManagers.get(containerName);\n-      Path containerRoot = Paths.get(CONTAINER_KEY, containerName);\n-\n-      Properties properties = readProperties(containerRoot.resolve(CONTAINERS_PROPERTIES_FILE), zip);\n-\n-      Collection<ContainerResource> resources = ContainerResourceFactory\n-            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n-\n-      resources.forEach(r -> r.prepareAndValidateRestore(properties));\n-\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (ContainerResource cr : resources)\n-         stages.dependsOn(cr.restore(zip));\n-      return stages.freeze();\n-   }\n-\n-   private Properties readManifestAndValidate(ZipFile zip) {\n-      Path manifestPath = Paths.get(MANIFEST_PROPERTIES_FILE);\n-      Properties properties = readProperties(manifestPath, zip);\n-      String version = properties.getProperty(VERSION_KEY);\n-      if (version == null)\n-         throw new IllegalStateException(\"Missing manifest version\");\n-\n-      int majorVersion = Integer.parseInt(version.split(\"[\\\\.\\\\-]\")[0]);\n-      // TODO replace with check that version difference is in the supported range, i.e. across 3 majors etc\n-      if (majorVersion < 12)\n-         throw new CacheException(String.format(\"Unable to restore from a backup as '%s' is no longer supported in '%s %s'\",\n-               version, Version.getBrandName(), Version.getVersion()));\n-      return properties;\n-   }\n-\n-   private Properties readProperties(Path file, ZipFile zip) {\n-      try (InputStream is = zip.getInputStream(zip.getEntry(file.toString()))) {\n-         Properties props = new Properties();\n-         props.load(is);\n-         return props;\n-      } catch (IOException e) {\n-         throw new CacheException(\"Unable to read properties file\", e);\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nnew file mode 100644\nindex 0000000000..cc5a9ab59c\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -0,0 +1,121 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.logging.LogFactory;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupReader {\n+\n+   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final ParserRegistry parserRegistry;\n+\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                       ParserRegistry parserRegistry) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   CompletionStage<Void> restore(Path backup, Map<String, BackupManager.Resources> params) {\n+      return blockingManager.runBlocking(() -> {\n+         try (ZipFile zip = new ZipFile(backup.toFile())) {\n+            Properties manifest = readManifestAndValidate(zip);\n+\n+            List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n+            Set<String> requestedContainers = new HashSet<>(params.keySet());\n+            requestedContainers.removeAll(backupContainers);\n+            if (!requestedContainers.isEmpty()) {\n+               throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n+            }\n+\n+            AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+            for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n+               stages.dependsOn(restoreContainer(e.getKey(), e.getValue(), zip));\n+            }\n+            CompletionStages.join(stages.freeze());\n+         } catch (IOException e) {\n+            throw new CacheException(String.format(\"Unable to read zip file '%s'\", backup));\n+         }\n+      }, \"process-containers\");\n+   }\n+\n+   private CompletionStage<Void> restoreContainer(String containerName, BackupManager.Resources params, ZipFile zip) {\n+      // TODO validate container config\n+      EmbeddedCacheManager cm = cacheManagers.get(containerName);\n+      Path containerRoot = Paths.get(CONTAINER_KEY, containerName);\n+\n+      Properties properties = readProperties(containerRoot.resolve(CONTAINERS_PROPERTIES_FILE), zip);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n+\n+      resources.forEach(r -> r.prepareAndValidateRestore(properties));\n+\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (ContainerResource cr : resources)\n+         stages.dependsOn(cr.restore(zip));\n+      return stages.freeze();\n+   }\n+\n+   private Properties readManifestAndValidate(ZipFile zip) {\n+      Path manifestPath = Paths.get(MANIFEST_PROPERTIES_FILE);\n+      Properties properties = readProperties(manifestPath, zip);\n+      String version = properties.getProperty(VERSION_KEY);\n+      if (version == null)\n+         throw new IllegalStateException(\"Missing manifest version\");\n+\n+      int majorVersion = Integer.parseInt(version.split(\"[\\\\.\\\\-]\")[0]);\n+      // TODO replace with check that version difference is in the supported range, i.e. across 3 majors etc\n+      if (majorVersion < 12)\n+         throw new CacheException(String.format(\"Unable to restore from a backup as '%s' is no longer supported in '%s %s'\",\n+               version, Version.getBrandName(), Version.getVersion()));\n+      return properties;\n+   }\n+\n+   private Properties readProperties(Path file, ZipFile zip) {\n+      try (InputStream is = zip.getInputStream(zip.getEntry(file.toString()))) {\n+         Properties props = new Properties();\n+         props.load(is);\n+         return props;\n+      } catch (IOException e) {\n+         throw new CacheException(\"Unable to read properties file\", e);\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Nzg5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457657891", "body": "Same here, this should be able to just be one big `blockingManager.thenSupply` call which returns a CompletionStage and then use `thenCompose` to flatten it.", "bodyText": "Same here, this should be able to just be one big blockingManager.thenSupply call which returns a CompletionStage and then use thenCompose to flatten it.", "bodyHTML": "<p dir=\"auto\">Same here, this should be able to just be one big <code>blockingManager.thenSupply</code> call which returns a CompletionStage and then use <code>thenCompose</code> to flatten it.</p>", "author": "wburns", "createdAt": "2020-07-20T19:59:52Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java", "diffHunk": "@@ -0,0 +1,140 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.STAGING_ZIP;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.logging.LogFactory;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupReader {\n+\n+   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final Path rootDir;\n+\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+   }\n+\n+   CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.ContainerResources> params) {\n+      final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n+\n+      CompletionStage<Void> createStagingFile = blockingManager.runBlocking(() -> {\n+         try {\n+            Files.copy(is, stagingFile);\n+         } catch (IOException e) {\n+            throw new CacheException(e);\n+         }\n+      }, \"create-staging\");\n+\n+      CompletionStage<?> processContainers = blockingManager.thenApplyBlocking(createStagingFile, Void -> {\n+         try (ZipFile zip = new ZipFile(stagingFile.toFile())) {\n+            Properties manifest = readManifestAndValidate(zip);\n+\n+            List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n+            Set<String> requestedContainers = new HashSet<>(params.keySet());\n+            requestedContainers.removeAll(backupContainers);\n+            if (!requestedContainers.isEmpty()) {\n+               throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n+            }\n+\n+            return CompletionStages.allOf(\n+                  params.entrySet().stream()\n+                        .map(e -> restoreContainer(e.getKey(), e.getValue(), zip))\n+                        .collect(Collectors.toList())\n+            );\n+         } catch (IOException e) {\n+            throw new CacheException(String.format(\"Unable to read zip file '%s'\", stagingFile));\n+         }\n+      }, \"read-manifest\");\n+\n+      return blockingManager.thenRun(processContainers, () -> {", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk1NDk0MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457954940", "bodyText": "I have updated it to return processContainers.thenRun(() -> {...}); as we only require CompletionStage<Void>.", "author": "ryanemerson", "createdAt": "2020-07-21T09:16:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Nzg5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nindex 02a07a4ed2..d845923413 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -75,23 +73,23 @@ public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheMan\n                throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n             }\n \n-            return CompletionStages.allOf(\n-                  params.entrySet().stream()\n-                        .map(e -> restoreContainer(e.getKey(), e.getValue(), zip))\n-                        .collect(Collectors.toList())\n-            );\n+            AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+            for (Map.Entry<String, BackupManager.ContainerResources> e : params.entrySet()) {\n+               stages.dependsOn(restoreContainer(e.getKey(), e.getValue(), zip));\n+            }\n+            return stages.freeze();\n          } catch (IOException e) {\n             throw new CacheException(String.format(\"Unable to read zip file '%s'\", stagingFile));\n          }\n-      }, \"read-manifest\");\n+      }, \"process-containers\");\n \n-      return blockingManager.thenRun(processContainers, () -> {\n+      return processContainers.thenRun(() -> {\n          try {\n             Files.delete(stagingFile);\n          } catch (IOException e) {\n             log.errorf(\"Unable to remove '%s'\", stagingFile, e);\n          }\n-      }, \"cleanup\");\n+      });\n    }\n \n    private CompletionStage<Void> restoreContainer(String containerName, BackupManager.ContainerResources params, ZipFile zip) {\n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nindex d845923413..add2b5cfb2 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -92,7 +92,7 @@ public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheMan\n       });\n    }\n \n-   private CompletionStage<Void> restoreContainer(String containerName, BackupManager.ContainerResources params, ZipFile zip) {\n+   private CompletionStage<Void> restoreContainer(String containerName, BackupManager.Resources params, ZipFile zip) {\n       // TODO validate container config\n       EmbeddedCacheManager cm = cacheManagers.get(containerName);\n       Path containerRoot = Paths.get(CONTAINER_KEY, containerName);\n", "next_change": {"commit": "efedcd6e4718f909ec002c586f289f19d8703c3c", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nindex add2b5cfb2..726aeba206 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -99,8 +103,8 @@ public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheMan\n \n       Properties properties = readProperties(containerRoot.resolve(CONTAINERS_PROPERTIES_FILE), zip);\n \n-      Collection<ContainerResource> resources = ContainerResourceFactory.getInstance()\n-            .getResources(params, blockingManager, cm, containerRoot);\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n \n       resources.forEach(r -> r.prepareAndValidateRestore(properties));\n \n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\ndeleted file mode 100644\nindex 726aeba206..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n+++ /dev/null\n", "chunk": "@@ -1,141 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n-import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.STAGING_ZIP;\n-import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.Paths;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipFile;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.logging.LogFactory;\n-import org.infinispan.commons.util.Version;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n-import org.infinispan.server.core.logging.Log;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-\n-/**\n- * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-class BackupReader {\n-\n-   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n-\n-   private final BlockingManager blockingManager;\n-   private final Map<String, DefaultCacheManager> cacheManagers;\n-   private final ParserRegistry parserRegistry;\n-   private final Path rootDir;\n-\n-   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n-                       ParserRegistry parserRegistry, Path rootDir) {\n-      this.blockingManager = blockingManager;\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = parserRegistry;\n-      this.rootDir = rootDir;\n-   }\n-\n-   CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.Resources> params) {\n-      final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n-\n-      CompletionStage<?> processContainers = blockingManager.supplyBlocking(() -> {\n-         try {\n-            Files.copy(is, stagingFile);\n-         } catch (IOException e) {\n-            throw new CacheException(e);\n-         }\n-\n-         try (ZipFile zip = new ZipFile(stagingFile.toFile())) {\n-            Properties manifest = readManifestAndValidate(zip);\n-\n-            List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n-            Set<String> requestedContainers = new HashSet<>(params.keySet());\n-            requestedContainers.removeAll(backupContainers);\n-            if (!requestedContainers.isEmpty()) {\n-               throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n-            }\n-\n-            AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-            for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n-               stages.dependsOn(restoreContainer(e.getKey(), e.getValue(), zip));\n-            }\n-            return stages.freeze();\n-         } catch (IOException e) {\n-            throw new CacheException(String.format(\"Unable to read zip file '%s'\", stagingFile));\n-         }\n-      }, \"process-containers\");\n-\n-      return processContainers.thenRun(() -> {\n-         try {\n-            Files.delete(stagingFile);\n-         } catch (IOException e) {\n-            log.errorf(\"Unable to remove '%s'\", stagingFile, e);\n-         }\n-      });\n-   }\n-\n-   private CompletionStage<Void> restoreContainer(String containerName, BackupManager.Resources params, ZipFile zip) {\n-      // TODO validate container config\n-      EmbeddedCacheManager cm = cacheManagers.get(containerName);\n-      Path containerRoot = Paths.get(CONTAINER_KEY, containerName);\n-\n-      Properties properties = readProperties(containerRoot.resolve(CONTAINERS_PROPERTIES_FILE), zip);\n-\n-      Collection<ContainerResource> resources = ContainerResourceFactory\n-            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n-\n-      resources.forEach(r -> r.prepareAndValidateRestore(properties));\n-\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (ContainerResource cr : resources)\n-         stages.dependsOn(cr.restore(zip));\n-      return stages.freeze();\n-   }\n-\n-   private Properties readManifestAndValidate(ZipFile zip) {\n-      Path manifestPath = Paths.get(MANIFEST_PROPERTIES_FILE);\n-      Properties properties = readProperties(manifestPath, zip);\n-      String version = properties.getProperty(VERSION_KEY);\n-      if (version == null)\n-         throw new IllegalStateException(\"Missing manifest version\");\n-\n-      int majorVersion = Integer.parseInt(version.split(\"[\\\\.\\\\-]\")[0]);\n-      // TODO replace with check that version difference is in the supported range, i.e. across 3 majors etc\n-      if (majorVersion < 12)\n-         throw new CacheException(String.format(\"Unable to restore from a backup as '%s' is no longer supported in '%s %s'\",\n-               version, Version.getBrandName(), Version.getVersion()));\n-      return properties;\n-   }\n-\n-   private Properties readProperties(Path file, ZipFile zip) {\n-      try (InputStream is = zip.getInputStream(zip.getEntry(file.toString()))) {\n-         Properties props = new Properties();\n-         props.load(is);\n-         return props;\n-      } catch (IOException e) {\n-         throw new CacheException(\"Unable to read properties file\", e);\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\nnew file mode 100644\nindex 0000000000..cc5a9ab59c\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java\n", "chunk": "@@ -0,0 +1,121 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.logging.LogFactory;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupReader {\n+\n+   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final ParserRegistry parserRegistry;\n+\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                       ParserRegistry parserRegistry) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   CompletionStage<Void> restore(Path backup, Map<String, BackupManager.Resources> params) {\n+      return blockingManager.runBlocking(() -> {\n+         try (ZipFile zip = new ZipFile(backup.toFile())) {\n+            Properties manifest = readManifestAndValidate(zip);\n+\n+            List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n+            Set<String> requestedContainers = new HashSet<>(params.keySet());\n+            requestedContainers.removeAll(backupContainers);\n+            if (!requestedContainers.isEmpty()) {\n+               throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n+            }\n+\n+            AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+            for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n+               stages.dependsOn(restoreContainer(e.getKey(), e.getValue(), zip));\n+            }\n+            CompletionStages.join(stages.freeze());\n+         } catch (IOException e) {\n+            throw new CacheException(String.format(\"Unable to read zip file '%s'\", backup));\n+         }\n+      }, \"process-containers\");\n+   }\n+\n+   private CompletionStage<Void> restoreContainer(String containerName, BackupManager.Resources params, ZipFile zip) {\n+      // TODO validate container config\n+      EmbeddedCacheManager cm = cacheManagers.get(containerName);\n+      Path containerRoot = Paths.get(CONTAINER_KEY, containerName);\n+\n+      Properties properties = readProperties(containerRoot.resolve(CONTAINERS_PROPERTIES_FILE), zip);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n+\n+      resources.forEach(r -> r.prepareAndValidateRestore(properties));\n+\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (ContainerResource cr : resources)\n+         stages.dependsOn(cr.restore(zip));\n+      return stages.freeze();\n+   }\n+\n+   private Properties readManifestAndValidate(ZipFile zip) {\n+      Path manifestPath = Paths.get(MANIFEST_PROPERTIES_FILE);\n+      Properties properties = readProperties(manifestPath, zip);\n+      String version = properties.getProperty(VERSION_KEY);\n+      if (version == null)\n+         throw new IllegalStateException(\"Missing manifest version\");\n+\n+      int majorVersion = Integer.parseInt(version.split(\"[\\\\.\\\\-]\")[0]);\n+      // TODO replace with check that version difference is in the supported range, i.e. across 3 majors etc\n+      if (majorVersion < 12)\n+         throw new CacheException(String.format(\"Unable to restore from a backup as '%s' is no longer supported in '%s %s'\",\n+               version, Version.getBrandName(), Version.getVersion()));\n+      return properties;\n+   }\n+\n+   private Properties readProperties(Path file, ZipFile zip) {\n+      try (InputStream is = zip.getInputStream(zip.getEntry(file.toString()))) {\n+         Properties props = new Properties();\n+         props.load(is);\n+         return props;\n+      } catch (IOException e) {\n+         throw new CacheException(\"Unable to read properties file\", e);\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3MDA1NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457670055", "body": "Just use an AggregateCompletionStage instead of creating this list.", "bodyText": "Just use an AggregateCompletionStage instead of creating this list.", "bodyHTML": "<p dir=\"auto\">Just use an AggregateCompletionStage instead of creating this list.</p>", "author": "wburns", "createdAt": "2020-07-20T20:23:53Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java", "diffHunk": "@@ -0,0 +1,177 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+\n+   private final Path rootDir;\n+   private final ParserRegistry parserRegistry;\n+\n+   BackupWriter(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+      this.parserRegistry = new ParserRegistry();\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.ContainerResources> params) {\n+      List<CompletionStage<?>> stages = new ArrayList<>(params.size() + 1);", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk1NjUzNQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457956535", "bodyText": "I completely forgot that existed \ud83d\ude42", "author": "ryanemerson", "createdAt": "2020-07-21T09:18:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3MDA1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk2MjYxOQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457962619", "bodyText": "I have updated all instances that were previously using CompletionStages#allOf(Collection) and removed that static method.", "author": "ryanemerson", "createdAt": "2020-07-21T09:28:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3MDA1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nindex 46a8b87299..aa5dee6b0e 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -62,15 +60,15 @@\n    }\n \n    CompletionStage<Path> create(Map<String, BackupManager.ContainerResources> params) {\n-      List<CompletionStage<?>> stages = new ArrayList<>(params.size() + 1);\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n       for (Map.Entry<String, BackupManager.ContainerResources> e : params.entrySet()) {\n-         String container = e.getKey();\n-         EmbeddedCacheManager cm = cacheManagers.get(container);\n-         stages.add(createBackup(container, cm, e.getValue()));\n+         String containerName = e.getKey();\n+         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n+         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n       }\n \n-      stages.add(writeManifest(cacheManagers.keySet()));\n-      return blockingManager.thenApplyBlocking(CompletionStages.allOf(stages), Void -> createZip(), \"create\");\n+      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n+      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n    }\n \n    /**\n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nindex aa5dee6b0e..c6c85b4da7 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -76,11 +76,11 @@\n     *\n     * @param containerName the name of container to backup.\n     * @param cm            the container to backup.\n-    * @param params        the {@link BackupManager.ContainerResources} object that determines what resources are\n+    * @param params        the {@link BackupManager.Resources} object that determines what resources are\n     *                      included in the backup for this container.\n     * @return a {@link CompletionStage} that completes once the backup has finished.\n     */\n-   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.ContainerResources params) {\n+   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n       Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n       containerRoot.toFile().mkdirs();\n       GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n", "next_change": {"commit": "efedcd6e4718f909ec002c586f289f19d8703c3c", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nindex c6c85b4da7..f93e5936ac 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -76,8 +82,8 @@\n     *\n     * @param containerName the name of container to backup.\n     * @param cm            the container to backup.\n-    * @param params        the {@link BackupManager.Resources} object that determines what resources are\n-    *                      included in the backup for this container.\n+    * @param params        the {@link BackupManager.Resources} object that determines what resources are included in the\n+    *                      backup for this container.\n     * @return a {@link CompletionStage} that completes once the backup has finished.\n     */\n    private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n", "next_change": {"commit": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nindex f93e5936ac..9e8c0a6c3a 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -88,7 +88,11 @@ void cleanup() {\n     */\n    private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n       Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n-      containerRoot.toFile().mkdirs();\n+      try {\n+         Files.createDirectories(containerRoot);\n+      } catch (IOException e) {\n+         throw new CacheException(\"Unable to create directories \" + containerRoot.toString());\n+      }\n       GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n       BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n \n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\ndeleted file mode 100644\nindex 9e8c0a6c3a..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ /dev/null\n", "chunk": "@@ -1,183 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n-import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n-import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n-\n-import java.io.IOException;\n-import java.io.OutputStream;\n-import java.nio.file.FileVisitResult;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.SimpleFileVisitor;\n-import java.nio.file.attribute.BasicFileAttributes;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipOutputStream;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.util.Util;\n-import org.infinispan.commons.util.Version;\n-import org.infinispan.configuration.global.GlobalConfiguration;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.factories.GlobalComponentRegistry;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-\n-/**\n- * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-class BackupWriter {\n-\n-   private final String name;\n-   private final BlockingManager blockingManager;\n-   private final Map<String, DefaultCacheManager> cacheManagers;\n-   private final ParserRegistry parserRegistry;\n-   private final Path rootDir;\n-\n-   BackupWriter(String name, BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n-                ParserRegistry parserRegistry, Path rootDir) {\n-      this.name = name;\n-      this.blockingManager = blockingManager;\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = parserRegistry;\n-      this.rootDir = rootDir.resolve(name);\n-   }\n-\n-   void cleanup() {\n-      Util.recursiveFileRemove(rootDir);\n-   }\n-\n-   CompletionStage<Path> create(Map<String, BackupManager.Resources> params) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n-         String containerName = e.getKey();\n-         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n-         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n-      }\n-\n-      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n-      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n-   }\n-\n-   /**\n-    * Create a backup of the specified container.\n-    *\n-    * @param containerName the name of container to backup.\n-    * @param cm            the container to backup.\n-    * @param params        the {@link BackupManager.Resources} object that determines what resources are included in the\n-    *                      backup for this container.\n-    * @return a {@link CompletionStage} that completes once the backup has finished.\n-    */\n-   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n-      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n-      try {\n-         Files.createDirectories(containerRoot);\n-      } catch (IOException e) {\n-         throw new CacheException(\"Unable to create directories \" + containerRoot.toString());\n-      }\n-      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n-      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n-\n-      Collection<ContainerResource> resources = ContainerResourceFactory\n-            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n-\n-      // Prepare and ensure all requested resources are valid before starting the backup process\n-      resources.forEach(ContainerResource::prepareAndValidateBackup);\n-\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (ContainerResource cr : resources)\n-         stages.dependsOn(cr.backup());\n-\n-      stages.dependsOn(\n-            // Write the global configuration xml\n-            blockingManager.runBlocking(() ->\n-                  writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n-      );\n-\n-      return blockingManager.thenRunBlocking(\n-            stages.freeze(),\n-            () -> {\n-               Properties manifest = new Properties();\n-               resources.forEach(r -> r.writeToManifest(manifest));\n-               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n-            },\n-            \"create-manifest\"\n-      );\n-   }\n-\n-   private CompletionStage<Void> writeManifest(Set<String> containers) {\n-      return blockingManager.runBlocking(() -> {\n-         Properties manifest = new Properties();\n-         manifest.put(CONTAINER_KEY, String.join(\",\", containers));\n-         manifest.put(VERSION_KEY, Version.getVersion());\n-         storeProperties(manifest, \"Backup Manifest\", rootDir.resolve(MANIFEST_PROPERTIES_FILE));\n-      }, \"write-manifest\");\n-   }\n-\n-   private void writeGlobalConfig(GlobalConfiguration configuration, Path root) {\n-      Path xmlPath = root.resolve(GLOBAL_CONFIG_FILE);\n-      try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-         parserRegistry.serialize(os, configuration, Collections.emptyMap());\n-      } catch (XMLStreamException | IOException e) {\n-         throw new CacheException(String.format(\"Unable to create global configuration file '%s'\", xmlPath), e);\n-      }\n-   }\n-\n-   private Path createZip() {\n-      Path zipFile = rootDir.resolve(name + \".zip\");\n-      try (ZipOutputStream zs = new ZipOutputStream(Files.newOutputStream(Files.createFile(zipFile)))) {\n-         Files.walkFileTree(rootDir, new SimpleFileVisitor<Path>() {\n-            @Override\n-            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {\n-               if (!path.equals(zipFile)) {\n-                  String name = rootDir.relativize(path).toString();\n-                  zs.putNextEntry(new ZipEntry(name));\n-                  Files.copy(path, zs);\n-                  zs.closeEntry();\n-                  Files.delete(path);\n-               }\n-               return FileVisitResult.CONTINUE;\n-            }\n-\n-            @Override\n-            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n-               if (exc != null)\n-                  throw new IllegalStateException(exc);\n-\n-               if (!dir.equals(rootDir))\n-                  Files.delete(dir);\n-               return FileVisitResult.CONTINUE;\n-            }\n-         });\n-      } catch (IOException e) {\n-         throw new CacheException(e);\n-      }\n-      return zipFile;\n-   }\n-\n-   private void storeProperties(Properties properties, String description, Path dest) {\n-      try (OutputStream os = Files.newOutputStream(dest)) {\n-         properties.store(os, description);\n-      } catch (IOException e) {\n-         throw new CacheException(String.format(\"Unable to create %s file\", description), e);\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nnew file mode 100644\nindex 0000000000..5420706ff3\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -0,0 +1,188 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Util;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private static final Log log = LogFactory.getLog(BackupWriter.class, Log.class);\n+\n+   private final String name;\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final ParserRegistry parserRegistry;\n+   private final Path rootDir;\n+\n+   BackupWriter(String name, BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                ParserRegistry parserRegistry, Path rootDir) {\n+      this.name = name;\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = parserRegistry;\n+      this.rootDir = rootDir.resolve(name);\n+   }\n+\n+   void cleanup() {\n+      log.backupDeleted(name);\n+      Util.recursiveFileRemove(rootDir);\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.Resources> params) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n+         String containerName = e.getKey();\n+         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n+         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n+      }\n+\n+      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n+      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n+   }\n+\n+   /**\n+    * Create a backup of the specified container.\n+    *\n+    * @param containerName the name of container to backup.\n+    * @param cm            the container to backup.\n+    * @param params        the {@link BackupManager.Resources} object that determines what resources are included in the\n+    *                      backup for this container.\n+    * @return a {@link CompletionStage} that completes once the backup has finished.\n+    */\n+   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n+      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n+      try {\n+         Files.createDirectories(containerRoot);\n+      } catch (IOException e) {\n+         throw new CacheException(\"Unable to create directories \" + containerRoot.toString());\n+      }\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n+\n+      // Prepare and ensure all requested resources are valid before starting the backup process\n+      resources.forEach(ContainerResource::prepareAndValidateBackup);\n+\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (ContainerResource cr : resources)\n+         stages.dependsOn(cr.backup());\n+\n+      stages.dependsOn(\n+            // Write the global configuration xml\n+            blockingManager.runBlocking(() ->\n+                  writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n+      );\n+\n+      return blockingManager.thenRunBlocking(\n+            stages.freeze(),\n+            () -> {\n+               Properties manifest = new Properties();\n+               resources.forEach(r -> r.writeToManifest(manifest));\n+               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n+            },\n+            \"create-manifest\"\n+      );\n+   }\n+\n+   private CompletionStage<Void> writeManifest(Set<String> containers) {\n+      return blockingManager.runBlocking(() -> {\n+         Properties manifest = new Properties();\n+         manifest.put(CONTAINER_KEY, String.join(\",\", containers));\n+         manifest.put(VERSION_KEY, Version.getVersion());\n+         storeProperties(manifest, \"Backup Manifest\", rootDir.resolve(MANIFEST_PROPERTIES_FILE));\n+      }, \"write-manifest\");\n+   }\n+\n+   private void writeGlobalConfig(GlobalConfiguration configuration, Path root) {\n+      Path xmlPath = root.resolve(GLOBAL_CONFIG_FILE);\n+      try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+         parserRegistry.serialize(os, configuration, Collections.emptyMap());\n+      } catch (XMLStreamException | IOException e) {\n+         throw new CacheException(String.format(\"Unable to create global configuration file '%s'\", xmlPath), e);\n+      }\n+   }\n+\n+   private Path createZip() {\n+      Path zipFile = rootDir.resolve(name + \".zip\");\n+      try (ZipOutputStream zs = new ZipOutputStream(Files.newOutputStream(Files.createFile(zipFile)))) {\n+         Files.walkFileTree(rootDir, new SimpleFileVisitor<Path>() {\n+            @Override\n+            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {\n+               if (!path.equals(zipFile)) {\n+                  String name = rootDir.relativize(path).toString();\n+                  zs.putNextEntry(new ZipEntry(name));\n+                  Files.copy(path, zs);\n+                  zs.closeEntry();\n+                  Files.delete(path);\n+               }\n+               return FileVisitResult.CONTINUE;\n+            }\n+\n+            @Override\n+            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n+               if (exc != null)\n+                  throw new IllegalStateException(exc);\n+\n+               if (!dir.equals(rootDir))\n+                  Files.delete(dir);\n+               return FileVisitResult.CONTINUE;\n+            }\n+         });\n+      } catch (IOException e) {\n+         throw new CacheException(e);\n+      }\n+      return zipFile;\n+   }\n+\n+   private void storeProperties(Properties properties, String description, Path dest) {\n+      try (OutputStream os = Files.newOutputStream(dest)) {\n+         properties.store(os, description);\n+      } catch (IOException e) {\n+         throw new CacheException(String.format(\"Unable to create %s file\", description), e);\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nindex c6c85b4da7..f93e5936ac 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -86,8 +92,8 @@\n       GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n       BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n \n-      Collection<ContainerResource> resources = ContainerResourceFactory.getInstance()\n-            .getResources(params, blockingManager, cm, containerRoot);\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n \n       // Prepare and ensure all requested resources are valid before starting the backup process\n       resources.forEach(ContainerResource::prepareAndValidateBackup);\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\ndeleted file mode 100644\nindex f93e5936ac..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ /dev/null\n", "chunk": "@@ -1,179 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n-import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n-import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n-\n-import java.io.IOException;\n-import java.io.OutputStream;\n-import java.nio.file.FileVisitResult;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.SimpleFileVisitor;\n-import java.nio.file.attribute.BasicFileAttributes;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipOutputStream;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.util.Util;\n-import org.infinispan.commons.util.Version;\n-import org.infinispan.configuration.global.GlobalConfiguration;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.factories.GlobalComponentRegistry;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-\n-/**\n- * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-class BackupWriter {\n-\n-   private final String name;\n-   private final BlockingManager blockingManager;\n-   private final Map<String, DefaultCacheManager> cacheManagers;\n-   private final ParserRegistry parserRegistry;\n-   private final Path rootDir;\n-\n-   BackupWriter(String name, BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n-                ParserRegistry parserRegistry, Path rootDir) {\n-      this.name = name;\n-      this.blockingManager = blockingManager;\n-      this.cacheManagers = cacheManagers;\n-      this.parserRegistry = parserRegistry;\n-      this.rootDir = rootDir.resolve(name);\n-   }\n-\n-   void cleanup() {\n-      Util.recursiveFileRemove(rootDir.toFile());\n-   }\n-\n-   CompletionStage<Path> create(Map<String, BackupManager.Resources> params) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n-         String containerName = e.getKey();\n-         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n-         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n-      }\n-\n-      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n-      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n-   }\n-\n-   /**\n-    * Create a backup of the specified container.\n-    *\n-    * @param containerName the name of container to backup.\n-    * @param cm            the container to backup.\n-    * @param params        the {@link BackupManager.Resources} object that determines what resources are included in the\n-    *                      backup for this container.\n-    * @return a {@link CompletionStage} that completes once the backup has finished.\n-    */\n-   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n-      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n-      containerRoot.toFile().mkdirs();\n-      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n-      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n-\n-      Collection<ContainerResource> resources = ContainerResourceFactory\n-            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n-\n-      // Prepare and ensure all requested resources are valid before starting the backup process\n-      resources.forEach(ContainerResource::prepareAndValidateBackup);\n-\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (ContainerResource cr : resources)\n-         stages.dependsOn(cr.backup());\n-\n-      stages.dependsOn(\n-            // Write the global configuration xml\n-            blockingManager.runBlocking(() ->\n-                  writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n-      );\n-\n-      return blockingManager.thenRun(\n-            stages.freeze(),\n-            () -> {\n-               Properties manifest = new Properties();\n-               resources.forEach(r -> r.writeToManifest(manifest));\n-               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n-            },\n-            \"create-manifest\"\n-      );\n-   }\n-\n-   private CompletionStage<Void> writeManifest(Set<String> containers) {\n-      return blockingManager.runBlocking(() -> {\n-         Properties manifest = new Properties();\n-         manifest.put(CONTAINER_KEY, String.join(\",\", containers));\n-         manifest.put(VERSION_KEY, Version.getVersion());\n-         storeProperties(manifest, \"Backup Manifest\", rootDir.resolve(MANIFEST_PROPERTIES_FILE));\n-      }, \"write-manifest\");\n-   }\n-\n-   private void writeGlobalConfig(GlobalConfiguration configuration, Path root) {\n-      Path xmlPath = root.resolve(GLOBAL_CONFIG_FILE);\n-      try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-         parserRegistry.serialize(os, configuration, Collections.emptyMap());\n-      } catch (XMLStreamException | IOException e) {\n-         throw new CacheException(String.format(\"Unable to create global configuration file '%s'\", xmlPath), e);\n-      }\n-   }\n-\n-   private Path createZip() {\n-      Path zipFile = rootDir.resolve(name + \".zip\");\n-      try (ZipOutputStream zs = new ZipOutputStream(Files.newOutputStream(Files.createFile(zipFile)))) {\n-         Files.walkFileTree(rootDir, new SimpleFileVisitor<Path>() {\n-            @Override\n-            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {\n-               if (!path.equals(zipFile)) {\n-                  String name = rootDir.relativize(path).toString();\n-                  zs.putNextEntry(new ZipEntry(name));\n-                  Files.copy(path, zs);\n-                  zs.closeEntry();\n-                  Files.delete(path);\n-               }\n-               return FileVisitResult.CONTINUE;\n-            }\n-\n-            @Override\n-            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n-               if (exc != null)\n-                  throw new IllegalStateException(exc);\n-\n-               if (!dir.equals(rootDir))\n-                  Files.delete(dir);\n-               return FileVisitResult.CONTINUE;\n-            }\n-         });\n-      } catch (IOException e) {\n-         throw new CacheException(e);\n-      }\n-      return zipFile;\n-   }\n-\n-   private void storeProperties(Properties properties, String description, Path dest) {\n-      try (OutputStream os = Files.newOutputStream(dest)) {\n-         properties.store(os, description);\n-      } catch (IOException e) {\n-         throw new CacheException(String.format(\"Unable to create %s file\", description), e);\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nnew file mode 100644\nindex 0000000000..5420706ff3\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -0,0 +1,188 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Util;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private static final Log log = LogFactory.getLog(BackupWriter.class, Log.class);\n+\n+   private final String name;\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final ParserRegistry parserRegistry;\n+   private final Path rootDir;\n+\n+   BackupWriter(String name, BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                ParserRegistry parserRegistry, Path rootDir) {\n+      this.name = name;\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = parserRegistry;\n+      this.rootDir = rootDir.resolve(name);\n+   }\n+\n+   void cleanup() {\n+      log.backupDeleted(name);\n+      Util.recursiveFileRemove(rootDir);\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.Resources> params) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n+         String containerName = e.getKey();\n+         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n+         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n+      }\n+\n+      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n+      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n+   }\n+\n+   /**\n+    * Create a backup of the specified container.\n+    *\n+    * @param containerName the name of container to backup.\n+    * @param cm            the container to backup.\n+    * @param params        the {@link BackupManager.Resources} object that determines what resources are included in the\n+    *                      backup for this container.\n+    * @return a {@link CompletionStage} that completes once the backup has finished.\n+    */\n+   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n+      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n+      try {\n+         Files.createDirectories(containerRoot);\n+      } catch (IOException e) {\n+         throw new CacheException(\"Unable to create directories \" + containerRoot.toString());\n+      }\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n+\n+      // Prepare and ensure all requested resources are valid before starting the backup process\n+      resources.forEach(ContainerResource::prepareAndValidateBackup);\n+\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (ContainerResource cr : resources)\n+         stages.dependsOn(cr.backup());\n+\n+      stages.dependsOn(\n+            // Write the global configuration xml\n+            blockingManager.runBlocking(() ->\n+                  writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n+      );\n+\n+      return blockingManager.thenRunBlocking(\n+            stages.freeze(),\n+            () -> {\n+               Properties manifest = new Properties();\n+               resources.forEach(r -> r.writeToManifest(manifest));\n+               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n+            },\n+            \"create-manifest\"\n+      );\n+   }\n+\n+   private CompletionStage<Void> writeManifest(Set<String> containers) {\n+      return blockingManager.runBlocking(() -> {\n+         Properties manifest = new Properties();\n+         manifest.put(CONTAINER_KEY, String.join(\",\", containers));\n+         manifest.put(VERSION_KEY, Version.getVersion());\n+         storeProperties(manifest, \"Backup Manifest\", rootDir.resolve(MANIFEST_PROPERTIES_FILE));\n+      }, \"write-manifest\");\n+   }\n+\n+   private void writeGlobalConfig(GlobalConfiguration configuration, Path root) {\n+      Path xmlPath = root.resolve(GLOBAL_CONFIG_FILE);\n+      try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+         parserRegistry.serialize(os, configuration, Collections.emptyMap());\n+      } catch (XMLStreamException | IOException e) {\n+         throw new CacheException(String.format(\"Unable to create global configuration file '%s'\", xmlPath), e);\n+      }\n+   }\n+\n+   private Path createZip() {\n+      Path zipFile = rootDir.resolve(name + \".zip\");\n+      try (ZipOutputStream zs = new ZipOutputStream(Files.newOutputStream(Files.createFile(zipFile)))) {\n+         Files.walkFileTree(rootDir, new SimpleFileVisitor<Path>() {\n+            @Override\n+            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {\n+               if (!path.equals(zipFile)) {\n+                  String name = rootDir.relativize(path).toString();\n+                  zs.putNextEntry(new ZipEntry(name));\n+                  Files.copy(path, zs);\n+                  zs.closeEntry();\n+                  Files.delete(path);\n+               }\n+               return FileVisitResult.CONTINUE;\n+            }\n+\n+            @Override\n+            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n+               if (exc != null)\n+                  throw new IllegalStateException(exc);\n+\n+               if (!dir.equals(rootDir))\n+                  Files.delete(dir);\n+               return FileVisitResult.CONTINUE;\n+            }\n+         });\n+      } catch (IOException e) {\n+         throw new CacheException(e);\n+      }\n+      return zipFile;\n+   }\n+\n+   private void storeProperties(Properties properties, String description, Path dest) {\n+      try (OutputStream os = Files.newOutputStream(dest)) {\n+         properties.store(os, description);\n+      } catch (IOException e) {\n+         throw new CacheException(String.format(\"Unable to create %s file\", description), e);\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3NDI5Ng==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457674296", "body": "So should this method throw an exception when it isn't valid? I would expect the exception to be defined as being able to be thrown in the interface then.", "bodyText": "So should this method throw an exception when it isn't valid? I would expect the exception to be defined as being able to be thrown in the interface then.", "bodyHTML": "<p dir=\"auto\">So should this method throw an exception when it isn't valid? I would expect the exception to be defined as being able to be thrown in the interface then.</p>", "author": "wburns", "createdAt": "2020-07-20T20:32:10Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java", "diffHunk": "@@ -0,0 +1,64 @@\n+package org.infinispan.server.core.backup;\n+\n+import java.util.Properties;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.server.core.BackupManager;\n+\n+/**\n+ * An interface that defines how a {@link org.infinispan.server.core.BackupManager.ResourceType} is backed up and\n+ * restored by the {@link org.infinispan.server.core.BackupManager}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public interface ContainerResource {\n+\n+   /**\n+    * A method to ensure that the resources requested in the {@link BackupManager.ContainerResources}\n+    * are valid and can be included in a backup. This method is called for all {@link ContainerResource} implementations\n+    * before the backup process begins in order to allow a backup to fail-fast before any data is processed.\n+    */\n+   void prepareAndValidateBackup();", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\nindex f83e606806..305c0e06a1 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\n", "chunk": "@@ -19,8 +20,10 @@\n     * A method to ensure that the resources requested in the {@link BackupManager.ContainerResources}\n     * are valid and can be included in a backup. This method is called for all {@link ContainerResource} implementations\n     * before the backup process begins in order to allow a backup to fail-fast before any data is processed.\n+    *\n+    * @throws CacheException if an invalid parameter is specified, e.g. a unknown resource name.\n     */\n-   void prepareAndValidateBackup();\n+   void prepareAndValidateBackup() throws CacheException;\n \n    /**\n     * Writes the backup files for the {@link org.infinispan.server.core.BackupManager.ResourceType} to the local\n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\nindex 305c0e06a1..a3845fd39e 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\n", "chunk": "@@ -26,19 +26,19 @@\n    void prepareAndValidateBackup() throws CacheException;\n \n    /**\n-    * Writes the backup files for the {@link org.infinispan.server.core.BackupManager.ResourceType} to the local\n+    * Writes the backup files for the {@link BackupManager.Resources.Type} to the local\n     * filesystem, where it can then be packaged for distribution.\n     * <p>\n     * Implementations of this method depend on content created by {@link #prepareAndValidateBackup()}.\n     *\n     * @return a {@link CompletionStage} that completes once the backup of this {@link\n-    * org.infinispan.server.core.BackupManager.ResourceType} has finished.\n+    * BackupManager.Resources.Type} has finished.\n     */\n    CompletionStage<Void> backup();\n \n    /**\n     * Writes the name of the individual resources that have been included in this backup. The {@link\n-    * org.infinispan.server.core.BackupManager.ResourceType} associated with an implementation is the key, whilst the\n+    * BackupManager.Resources.Type} associated with an implementation is the key, whilst the\n     * value is a csv of resource names.\n     * <p>\n     * Implementations of this method depend on state created by {@link #backup()}.\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\ndeleted file mode 100644\nindex a3845fd39e..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\n+++ /dev/null\n", "chunk": "@@ -1,67 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import java.util.Properties;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipFile;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.server.core.BackupManager;\n-\n-/**\n- * An interface that defines how a container resource is backed up and\n- * restored by the {@link org.infinispan.server.core.BackupManager}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public interface ContainerResource {\n-\n-   /**\n-    * A method to ensure that the resources requested in the {@link BackupManager.Resources}\n-    * are valid and can be included in a backup. This method is called for all {@link ContainerResource} implementations\n-    * before the backup process begins in order to allow a backup to fail-fast before any data is processed.\n-    *\n-    * @throws CacheException if an invalid parameter is specified, e.g. a unknown resource name.\n-    */\n-   void prepareAndValidateBackup() throws CacheException;\n-\n-   /**\n-    * Writes the backup files for the {@link BackupManager.Resources.Type} to the local\n-    * filesystem, where it can then be packaged for distribution.\n-    * <p>\n-    * Implementations of this method depend on content created by {@link #prepareAndValidateBackup()}.\n-    *\n-    * @return a {@link CompletionStage} that completes once the backup of this {@link\n-    * BackupManager.Resources.Type} has finished.\n-    */\n-   CompletionStage<Void> backup();\n-\n-   /**\n-    * Writes the name of the individual resources that have been included in this backup. The {@link\n-    * BackupManager.Resources.Type} associated with an implementation is the key, whilst the\n-    * value is a csv of resource names.\n-    * <p>\n-    * Implementations of this method depend on state created by {@link #backup()}.\n-    *\n-    * @param properties the {@link Properties} instance to add the key/value property.\n-    */\n-   void writeToManifest(Properties properties);\n-\n-   /**\n-    * A method to ensure that the resources requested in the {@link BackupManager.Resources}\n-    * are contained in the backup to be restored. This method is called for all {@link ContainerResource}\n-    * implementations before the restore process begins in order to allow a restore to fail-fast before any state is\n-    * restored to a container.\n-    */\n-   void prepareAndValidateRestore(Properties properties);\n-\n-   /**\n-    * Restores the {@link BackupManager.Resources.Type} content from the provided {@link\n-    * ZipFile} to the target container.\n-    *\n-    * @param zip the {@link ZipFile} to restore content from.\n-    * @return a {@link CompletionStage} that completes once the restoration of this {@link\n-    * BackupManager.Resources.Type} has finished.\n-    */\n-   CompletionStage<Void> restore(ZipFile zip);\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\nnew file mode 100644\nindex 0000000000..a3845fd39e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java\n", "chunk": "@@ -0,0 +1,67 @@\n+package org.infinispan.server.core.backup;\n+\n+import java.util.Properties;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.server.core.BackupManager;\n+\n+/**\n+ * An interface that defines how a container resource is backed up and\n+ * restored by the {@link org.infinispan.server.core.BackupManager}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public interface ContainerResource {\n+\n+   /**\n+    * A method to ensure that the resources requested in the {@link BackupManager.Resources}\n+    * are valid and can be included in a backup. This method is called for all {@link ContainerResource} implementations\n+    * before the backup process begins in order to allow a backup to fail-fast before any data is processed.\n+    *\n+    * @throws CacheException if an invalid parameter is specified, e.g. a unknown resource name.\n+    */\n+   void prepareAndValidateBackup() throws CacheException;\n+\n+   /**\n+    * Writes the backup files for the {@link BackupManager.Resources.Type} to the local\n+    * filesystem, where it can then be packaged for distribution.\n+    * <p>\n+    * Implementations of this method depend on content created by {@link #prepareAndValidateBackup()}.\n+    *\n+    * @return a {@link CompletionStage} that completes once the backup of this {@link\n+    * BackupManager.Resources.Type} has finished.\n+    */\n+   CompletionStage<Void> backup();\n+\n+   /**\n+    * Writes the name of the individual resources that have been included in this backup. The {@link\n+    * BackupManager.Resources.Type} associated with an implementation is the key, whilst the\n+    * value is a csv of resource names.\n+    * <p>\n+    * Implementations of this method depend on state created by {@link #backup()}.\n+    *\n+    * @param properties the {@link Properties} instance to add the key/value property.\n+    */\n+   void writeToManifest(Properties properties);\n+\n+   /**\n+    * A method to ensure that the resources requested in the {@link BackupManager.Resources}\n+    * are contained in the backup to be restored. This method is called for all {@link ContainerResource}\n+    * implementations before the restore process begins in order to allow a restore to fail-fast before any state is\n+    * restored to a container.\n+    */\n+   void prepareAndValidateRestore(Properties properties);\n+\n+   /**\n+    * Restores the {@link BackupManager.Resources.Type} content from the provided {@link\n+    * ZipFile} to the target container.\n+    *\n+    * @param zip the {@link ZipFile} to restore content from.\n+    * @return a {@link CompletionStage} that completes once the restoration of this {@link\n+    * BackupManager.Resources.Type} has finished.\n+    */\n+   CompletionStage<Void> restore(ZipFile zip);\n+}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY4NzA3OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457687078", "body": "We should be able to use an AggregateCompletionStage here as well.", "bodyText": "We should be able to use an AggregateCompletionStage here as well.", "bodyHTML": "<p dir=\"auto\">We should be able to use an AggregateCompletionStage here as well.</p>", "author": "wburns", "createdAt": "2020-07-20T20:57:03Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java", "diffHunk": "@@ -0,0 +1,177 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+\n+   private final Path rootDir;\n+   private final ParserRegistry parserRegistry;\n+\n+   BackupWriter(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+      this.parserRegistry = new ParserRegistry();\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.ContainerResources> params) {\n+      List<CompletionStage<?>> stages = new ArrayList<>(params.size() + 1);\n+      for (Map.Entry<String, BackupManager.ContainerResources> e : params.entrySet()) {\n+         String container = e.getKey();\n+         EmbeddedCacheManager cm = cacheManagers.get(container);\n+         stages.add(createBackup(container, cm, e.getValue()));\n+      }\n+\n+      stages.add(writeManifest(cacheManagers.keySet()));\n+      return blockingManager.thenApplyBlocking(CompletionStages.allOf(stages), Void -> createZip(), \"create\");\n+   }\n+\n+   /**\n+    * Create a backup of the specified container.\n+    *\n+    * @param containerName the name of container to backup.\n+    * @param cm            the container to backup.\n+    * @param params        the {@link BackupManager.ContainerResources} object that determines what resources are included in\n+    *                      the backup for this container.\n+    * @return a {@link CompletionStage} that completes once the backup has finished.\n+    */\n+   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.ContainerResources params) {\n+      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n+      containerRoot.toFile().mkdirs();\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory.getInstance()\n+            .getResources(params, blockingManager, cm, containerRoot);\n+\n+      // Prepare and ensure all requested resources are valid before starting the backup process\n+      resources.forEach(ContainerResource::prepareAndValidateBackup);\n+\n+      List<CompletionStage<?>> stages = resources.stream()", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nindex 46a8b87299..aa5dee6b0e 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -94,24 +92,25 @@\n       // Prepare and ensure all requested resources are valid before starting the backup process\n       resources.forEach(ContainerResource::prepareAndValidateBackup);\n \n-      List<CompletionStage<?>> stages = resources.stream()\n-            .map(ContainerResource::backup)\n-            .collect(Collectors.toList());\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (ContainerResource cr : resources)\n+         stages.dependsOn(cr.backup());\n \n-      stages.add(\n+      stages.dependsOn(\n             // Write the global configuration xml\n             blockingManager.runBlocking(() ->\n                   writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n       );\n \n-      return blockingManager\n-            .thenRun(CompletionStages.allOf(stages),\n-                  () -> {\n-                     Properties manifest = new Properties();\n-                     resources.forEach(r -> r.writeToManifest(manifest));\n-                     storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n-                  },\n-                  \"create-manifest\");\n+      return blockingManager.thenRun(\n+            stages.freeze(),\n+            () -> {\n+               Properties manifest = new Properties();\n+               resources.forEach(r -> r.writeToManifest(manifest));\n+               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n+            },\n+            \"create-manifest\"\n+      );\n    }\n \n    private CompletionStage<Void> writeManifest(Set<String> containers) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\ndeleted file mode 100644\nindex aa5dee6b0e..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n+++ /dev/null\n", "chunk": "@@ -1,176 +0,0 @@\n-package org.infinispan.server.core.backup;\n-\n-import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n-import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n-import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n-import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n-\n-import java.io.IOException;\n-import java.io.OutputStream;\n-import java.nio.file.FileVisitResult;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.SimpleFileVisitor;\n-import java.nio.file.attribute.BasicFileAttributes;\n-import java.time.LocalDateTime;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipOutputStream;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.util.Version;\n-import org.infinispan.configuration.global.GlobalConfiguration;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.factories.GlobalComponentRegistry;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-\n-/**\n- * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-class BackupWriter {\n-\n-   private final BlockingManager blockingManager;\n-   private final Map<String, DefaultCacheManager> cacheManagers;\n-\n-   private final Path rootDir;\n-   private final ParserRegistry parserRegistry;\n-\n-   BackupWriter(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n-      this.blockingManager = blockingManager;\n-      this.cacheManagers = cacheManagers;\n-      this.rootDir = rootDir;\n-      this.parserRegistry = new ParserRegistry();\n-   }\n-\n-   CompletionStage<Path> create(Map<String, BackupManager.ContainerResources> params) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (Map.Entry<String, BackupManager.ContainerResources> e : params.entrySet()) {\n-         String containerName = e.getKey();\n-         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n-         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n-      }\n-\n-      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n-      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n-   }\n-\n-   /**\n-    * Create a backup of the specified container.\n-    *\n-    * @param containerName the name of container to backup.\n-    * @param cm            the container to backup.\n-    * @param params        the {@link BackupManager.ContainerResources} object that determines what resources are\n-    *                      included in the backup for this container.\n-    * @return a {@link CompletionStage} that completes once the backup has finished.\n-    */\n-   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.ContainerResources params) {\n-      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n-      containerRoot.toFile().mkdirs();\n-      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n-      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n-\n-      Collection<ContainerResource> resources = ContainerResourceFactory.getInstance()\n-            .getResources(params, blockingManager, cm, containerRoot);\n-\n-      // Prepare and ensure all requested resources are valid before starting the backup process\n-      resources.forEach(ContainerResource::prepareAndValidateBackup);\n-\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (ContainerResource cr : resources)\n-         stages.dependsOn(cr.backup());\n-\n-      stages.dependsOn(\n-            // Write the global configuration xml\n-            blockingManager.runBlocking(() ->\n-                  writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n-      );\n-\n-      return blockingManager.thenRun(\n-            stages.freeze(),\n-            () -> {\n-               Properties manifest = new Properties();\n-               resources.forEach(r -> r.writeToManifest(manifest));\n-               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n-            },\n-            \"create-manifest\"\n-      );\n-   }\n-\n-   private CompletionStage<Void> writeManifest(Set<String> containers) {\n-      return blockingManager.runBlocking(() -> {\n-         Properties manifest = new Properties();\n-         manifest.put(CONTAINER_KEY, String.join(\",\", containers));\n-         manifest.put(VERSION_KEY, Version.getVersion());\n-         storeProperties(manifest, \"Backup Manifest\", rootDir.resolve(MANIFEST_PROPERTIES_FILE));\n-      }, \"write-manifest\");\n-   }\n-\n-   private void writeGlobalConfig(GlobalConfiguration configuration, Path root) {\n-      Path xmlPath = root.resolve(GLOBAL_CONFIG_FILE);\n-      try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-         parserRegistry.serialize(os, configuration, Collections.emptyMap());\n-      } catch (XMLStreamException | IOException e) {\n-         throw new CacheException(String.format(\"Unable to create global configuration file '%s'\", xmlPath), e);\n-      }\n-   }\n-\n-   private Path createZip() {\n-      LocalDateTime now = LocalDateTime.now();\n-      // Name the backup in the format 'infinispan-[year][month][day][hour][minute].zip'\n-      String backupName = String.format(\"%s-%d%02d%02d%02d%02d.zip\", Version.getBrandName(), now.getYear(), now.getMonthValue(), now.getDayOfMonth(), now.getHour(), now.getMinute());\n-      Path zipFile = rootDir.resolve(backupName);\n-      try (ZipOutputStream zs = new ZipOutputStream(Files.newOutputStream(Files.createFile(zipFile)))) {\n-         Files.walkFileTree(rootDir, new SimpleFileVisitor<Path>() {\n-            @Override\n-            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {\n-               if (!path.equals(zipFile)) {\n-                  String name = rootDir.relativize(path).toString();\n-                  zs.putNextEntry(new ZipEntry(name));\n-                  Files.copy(path, zs);\n-                  zs.closeEntry();\n-                  Files.delete(path);\n-               }\n-               return FileVisitResult.CONTINUE;\n-            }\n-\n-            @Override\n-            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n-               if (exc != null)\n-                  throw new IllegalStateException(exc);\n-\n-               if (!dir.equals(rootDir))\n-                  Files.delete(dir);\n-               return FileVisitResult.CONTINUE;\n-            }\n-         });\n-      } catch (IOException e) {\n-         throw new CacheException(e);\n-      }\n-      return zipFile;\n-   }\n-\n-   private void storeProperties(Properties properties, String description, Path dest) {\n-      try (OutputStream os = Files.newOutputStream(dest)) {\n-         properties.store(os, description);\n-      } catch (IOException e) {\n-         throw new CacheException(String.format(\"Unable to create %s file\", description), e);\n-      }\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\nnew file mode 100644\nindex 0000000000..5420706ff3\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java\n", "chunk": "@@ -0,0 +1,188 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Util;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private static final Log log = LogFactory.getLog(BackupWriter.class, Log.class);\n+\n+   private final String name;\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final ParserRegistry parserRegistry;\n+   private final Path rootDir;\n+\n+   BackupWriter(String name, BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                ParserRegistry parserRegistry, Path rootDir) {\n+      this.name = name;\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.parserRegistry = parserRegistry;\n+      this.rootDir = rootDir.resolve(name);\n+   }\n+\n+   void cleanup() {\n+      log.backupDeleted(name);\n+      Util.recursiveFileRemove(rootDir);\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.Resources> params) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (Map.Entry<String, BackupManager.Resources> e : params.entrySet()) {\n+         String containerName = e.getKey();\n+         EmbeddedCacheManager cm = cacheManagers.get(containerName);\n+         stages.dependsOn(createBackup(containerName, cm, e.getValue()));\n+      }\n+\n+      stages.dependsOn(writeManifest(cacheManagers.keySet()));\n+      return blockingManager.thenApplyBlocking(stages.freeze(), Void -> createZip(), \"create\");\n+   }\n+\n+   /**\n+    * Create a backup of the specified container.\n+    *\n+    * @param containerName the name of container to backup.\n+    * @param cm            the container to backup.\n+    * @param params        the {@link BackupManager.Resources} object that determines what resources are included in the\n+    *                      backup for this container.\n+    * @return a {@link CompletionStage} that completes once the backup has finished.\n+    */\n+   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.Resources params) {\n+      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n+      try {\n+         Files.createDirectories(containerRoot);\n+      } catch (IOException e) {\n+         throw new CacheException(\"Unable to create directories \" + containerRoot.toString());\n+      }\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory\n+            .getResources(params, blockingManager, cm, parserRegistry, containerRoot);\n+\n+      // Prepare and ensure all requested resources are valid before starting the backup process\n+      resources.forEach(ContainerResource::prepareAndValidateBackup);\n+\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (ContainerResource cr : resources)\n+         stages.dependsOn(cr.backup());\n+\n+      stages.dependsOn(\n+            // Write the global configuration xml\n+            blockingManager.runBlocking(() ->\n+                  writeGlobalConfig(cm.getCacheManagerConfiguration(), containerRoot), \"global-config\")\n+      );\n+\n+      return blockingManager.thenRunBlocking(\n+            stages.freeze(),\n+            () -> {\n+               Properties manifest = new Properties();\n+               resources.forEach(r -> r.writeToManifest(manifest));\n+               storeProperties(manifest, \"Container Properties\", containerRoot.resolve(CONTAINERS_PROPERTIES_FILE));\n+            },\n+            \"create-manifest\"\n+      );\n+   }\n+\n+   private CompletionStage<Void> writeManifest(Set<String> containers) {\n+      return blockingManager.runBlocking(() -> {\n+         Properties manifest = new Properties();\n+         manifest.put(CONTAINER_KEY, String.join(\",\", containers));\n+         manifest.put(VERSION_KEY, Version.getVersion());\n+         storeProperties(manifest, \"Backup Manifest\", rootDir.resolve(MANIFEST_PROPERTIES_FILE));\n+      }, \"write-manifest\");\n+   }\n+\n+   private void writeGlobalConfig(GlobalConfiguration configuration, Path root) {\n+      Path xmlPath = root.resolve(GLOBAL_CONFIG_FILE);\n+      try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+         parserRegistry.serialize(os, configuration, Collections.emptyMap());\n+      } catch (XMLStreamException | IOException e) {\n+         throw new CacheException(String.format(\"Unable to create global configuration file '%s'\", xmlPath), e);\n+      }\n+   }\n+\n+   private Path createZip() {\n+      Path zipFile = rootDir.resolve(name + \".zip\");\n+      try (ZipOutputStream zs = new ZipOutputStream(Files.newOutputStream(Files.createFile(zipFile)))) {\n+         Files.walkFileTree(rootDir, new SimpleFileVisitor<Path>() {\n+            @Override\n+            public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException {\n+               if (!path.equals(zipFile)) {\n+                  String name = rootDir.relativize(path).toString();\n+                  zs.putNextEntry(new ZipEntry(name));\n+                  Files.copy(path, zs);\n+                  zs.closeEntry();\n+                  Files.delete(path);\n+               }\n+               return FileVisitResult.CONTINUE;\n+            }\n+\n+            @Override\n+            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n+               if (exc != null)\n+                  throw new IllegalStateException(exc);\n+\n+               if (!dir.equals(rootDir))\n+                  Files.delete(dir);\n+               return FileVisitResult.CONTINUE;\n+            }\n+         });\n+      } catch (IOException e) {\n+         throw new CacheException(e);\n+      }\n+      return zipFile;\n+   }\n+\n+   private void storeProperties(Properties properties, String description, Path dest) {\n+      try (OutputStream os = Files.newOutputStream(dest)) {\n+         properties.store(os, description);\n+      } catch (IOException e) {\n+         throw new CacheException(String.format(\"Unable to create %s file\", description), e);\n+      }\n+   }\n+}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4MzU1MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458083550", "body": "Jackson databind is being killed, please avoid using it and use the internal mJson instead ", "bodyText": "Jackson databind is being killed, please avoid using it and use the internal mJson instead", "bodyHTML": "<p dir=\"auto\">Jackson databind is being killed, please avoid using it and use the internal mJson instead</p>", "author": "gustavocoding", "createdAt": "2020-07-21T13:11:11Z", "path": "server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java", "diffHunk": "@@ -0,0 +1,186 @@\n+package org.infinispan.server.functional;\n+\n+import static org.infinispan.functional.FunctionalTestUtils.await;\n+import static org.infinispan.util.concurrent.CompletionStages.join;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.io.File;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardCopyOption;\n+import java.util.Arrays;\n+\n+import org.infinispan.client.rest.RestCacheClient;\n+import org.infinispan.client.rest.RestClient;\n+import org.infinispan.client.rest.RestCounterClient;\n+import org.infinispan.client.rest.RestEntity;\n+import org.infinispan.client.rest.RestResponse;\n+import org.infinispan.client.rest.RestTaskClient;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.test.CommonsTestingUtil;\n+import org.infinispan.commons.util.Util;\n+import org.infinispan.configuration.cache.ConfigurationBuilder;\n+import org.infinispan.counter.api.Storage;\n+import org.infinispan.counter.configuration.Element;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ArrayNode;", "originalCommit": "82bd52a4ad5d4704767bed064483b437bf8f9391", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c8a308c8256384661fae7f02f8091259132d0e5", "changed_code": [{"header": "diff --git a/server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java b/server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java\nindex d7b21cf2af..e187b39051 100644\n--- a/server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java\n+++ b/server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java\n", "chunk": "@@ -29,9 +31,6 @@\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n-import com.fasterxml.jackson.databind.JsonNode;\n-import com.fasterxml.jackson.databind.node.ArrayNode;\n-\n /**\n  * @author Ryan Emerson\n  * @since 11.0\n", "next_change": {"commit": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "changed_code": [{"header": "diff --git a/server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java b/server/tests/src/test/java/org/infinispan/server/functional/BackupManagerIT.java\nsimilarity index 69%\nrename from server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java\nrename to server/tests/src/test/java/org/infinispan/server/functional/BackupManagerIT.java\nindex e187b39051..58aa1ee447 100644\n--- a/server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java\n+++ b/server/tests/src/test/java/org/infinispan/server/functional/BackupManagerIT.java\n", "chunk": "@@ -35,12 +42,12 @@\n  * @author Ryan Emerson\n  * @since 11.0\n  */\n-public class ClusterBackupIT extends AbstractMultiClusterIT {\n+public class BackupManagerIT extends AbstractMultiClusterIT {\n \n-   static final File WORKING_DIR = new File(CommonsTestingUtil.tmpDirectory(ClusterBackupIT.class));\n+   static final File WORKING_DIR = new File(CommonsTestingUtil.tmpDirectory(BackupManagerIT.class));\n    static final int NUM_ENTRIES = 10;\n \n-   public ClusterBackupIT() {\n+   public BackupManagerIT() {\n       super(\"configuration/ClusteredServerTest.xml\");\n    }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4NTA3MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458085070", "body": "Please add documentation in the REST API for those two methods", "bodyText": "Please add documentation in the REST API for those two methods", "bodyHTML": "<p dir=\"auto\">Please add documentation in the REST API for those two methods</p>", "author": "gustavocoding", "createdAt": "2020-07-21T13:13:29Z", "path": "server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java", "diffHunk": "@@ -1,33 +1,52 @@\n package org.infinispan.rest.resources;\n \n+import static io.netty.handler.codec.http.HttpResponseStatus.INTERNAL_SERVER_ERROR;\n import static io.netty.handler.codec.http.HttpResponseStatus.NO_CONTENT;\n+import static io.netty.handler.codec.http.HttpResponseStatus.UNSUPPORTED_MEDIA_TYPE;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+import static org.infinispan.rest.framework.Method.GET;\n import static org.infinispan.rest.framework.Method.POST;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n import java.util.List;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n \n+import org.infinispan.commons.dataconversion.MediaType;\n import org.infinispan.rest.InvocationHelper;\n import org.infinispan.rest.NettyRestResponse;\n import org.infinispan.rest.framework.ResourceHandler;\n import org.infinispan.rest.framework.RestRequest;\n import org.infinispan.rest.framework.RestResponse;\n import org.infinispan.rest.framework.impl.Invocations;\n+import org.infinispan.rest.logging.Log;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.logging.LogFactory;\n \n /**\n  * @since 10.0\n  */\n public class ClusterResource implements ResourceHandler {\n+\n+   private final static Log LOG = LogFactory.getLog(ClusterResource.class, Log.class);\n+\n    private final InvocationHelper invocationHelper;\n+   private final BackupManager backupManager;\n \n    public ClusterResource(InvocationHelper invocationHelper) {\n       this.invocationHelper = invocationHelper;\n+      this.backupManager = invocationHelper.getServer().getBackupManager();\n    }\n \n    @Override\n    public Invocations getInvocations() {\n       return new Invocations.Builder()\n             .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"stop\").handleWith(this::stop)\n+            .invocation().methods(GET).path(\"/v2/cluster\").withAction(\"backup\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"restore\").handleWith(this::restore)", "originalCommit": "82bd52a4ad5d4704767bed064483b437bf8f9391", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "efedcd6e4718f909ec002c586f289f19d8703c3c", "changed_code": [{"header": "diff --git a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\nindex 7e7e324676..cb95fdf413 100644\n--- a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n+++ b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n", "chunk": "@@ -45,8 +34,8 @@ public ClusterResource(InvocationHelper invocationHelper) {\n    public Invocations getInvocations() {\n       return new Invocations.Builder()\n             .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"stop\").handleWith(this::stop)\n-            .invocation().methods(GET).path(\"/v2/cluster\").withAction(\"backup\").handleWith(this::backup)\n-            .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"restore\").handleWith(this::restore)\n+            .invocation().methods(DELETE, GET, POST).path(\"/v2/cluster/backups/{backupName}\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cluster/backups\").withAction(\"restore\").handleWith(this::restore)\n             .create();\n    }\n \n", "next_change": {"commit": "273d51d75ac24b6893868ce0a373c07e368e1f24", "changed_code": [{"header": "diff --git a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\nindex cb95fdf413..163233d391 100644\n--- a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n+++ b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n", "chunk": "@@ -34,6 +37,7 @@ public ClusterResource(InvocationHelper invocationHelper) {\n    public Invocations getInvocations() {\n       return new Invocations.Builder()\n             .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"stop\").handleWith(this::stop)\n+            .invocation().methods(GET).path(\"/v2/cluster/backups\").handleWith(this::getAllBackupNames)\n             .invocation().methods(DELETE, GET, POST).path(\"/v2/cluster/backups/{backupName}\").handleWith(this::backup)\n             .invocation().methods(POST).path(\"/v2/cluster/backups\").withAction(\"restore\").handleWith(this::restore)\n             .create();\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\nindex 163233d391..6efa29dd71 100644\n--- a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n+++ b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n", "chunk": "@@ -1,45 +1,33 @@\n package org.infinispan.rest.resources;\n \n import static io.netty.handler.codec.http.HttpResponseStatus.NO_CONTENT;\n-import static org.infinispan.rest.framework.Method.DELETE;\n-import static org.infinispan.rest.framework.Method.GET;\n import static org.infinispan.rest.framework.Method.POST;\n-import static org.infinispan.rest.resources.ResourceUtil.asJsonResponseFuture;\n \n import java.util.List;\n-import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n \n-import org.infinispan.commons.dataconversion.internal.Json;\n import org.infinispan.rest.InvocationHelper;\n import org.infinispan.rest.NettyRestResponse;\n import org.infinispan.rest.framework.ResourceHandler;\n import org.infinispan.rest.framework.RestRequest;\n import org.infinispan.rest.framework.RestResponse;\n import org.infinispan.rest.framework.impl.Invocations;\n-import org.infinispan.server.core.BackupManager;\n \n /**\n  * @since 10.0\n  */\n public class ClusterResource implements ResourceHandler {\n-\n    private final InvocationHelper invocationHelper;\n-   private final BackupManager backupManager;\n \n    public ClusterResource(InvocationHelper invocationHelper) {\n       this.invocationHelper = invocationHelper;\n-      this.backupManager = invocationHelper.getServer().getBackupManager();\n    }\n \n    @Override\n    public Invocations getInvocations() {\n       return new Invocations.Builder()\n             .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"stop\").handleWith(this::stop)\n-            .invocation().methods(GET).path(\"/v2/cluster/backups\").handleWith(this::getAllBackupNames)\n-            .invocation().methods(DELETE, GET, POST).path(\"/v2/cluster/backups/{backupName}\").handleWith(this::backup)\n-            .invocation().methods(POST).path(\"/v2/cluster/backups\").withAction(\"restore\").handleWith(this::restore)\n             .create();\n    }\n \n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\nindex 6efa29dd71..163233d391 100644\n--- a/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n+++ b/server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java\n", "chunk": "@@ -1,33 +1,45 @@\n package org.infinispan.rest.resources;\n \n import static io.netty.handler.codec.http.HttpResponseStatus.NO_CONTENT;\n+import static org.infinispan.rest.framework.Method.DELETE;\n+import static org.infinispan.rest.framework.Method.GET;\n import static org.infinispan.rest.framework.Method.POST;\n+import static org.infinispan.rest.resources.ResourceUtil.asJsonResponseFuture;\n \n import java.util.List;\n+import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n \n+import org.infinispan.commons.dataconversion.internal.Json;\n import org.infinispan.rest.InvocationHelper;\n import org.infinispan.rest.NettyRestResponse;\n import org.infinispan.rest.framework.ResourceHandler;\n import org.infinispan.rest.framework.RestRequest;\n import org.infinispan.rest.framework.RestResponse;\n import org.infinispan.rest.framework.impl.Invocations;\n+import org.infinispan.server.core.BackupManager;\n \n /**\n  * @since 10.0\n  */\n public class ClusterResource implements ResourceHandler {\n+\n    private final InvocationHelper invocationHelper;\n+   private final BackupManager backupManager;\n \n    public ClusterResource(InvocationHelper invocationHelper) {\n       this.invocationHelper = invocationHelper;\n+      this.backupManager = invocationHelper.getServer().getBackupManager();\n    }\n \n    @Override\n    public Invocations getInvocations() {\n       return new Invocations.Builder()\n             .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"stop\").handleWith(this::stop)\n+            .invocation().methods(GET).path(\"/v2/cluster/backups\").handleWith(this::getAllBackupNames)\n+            .invocation().methods(DELETE, GET, POST).path(\"/v2/cluster/backups/{backupName}\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cluster/backups\").withAction(\"restore\").handleWith(this::restore)\n             .create();\n    }\n \n", "next_change": null}]}}]}}]}}]}}, {"oid": "8c8a308c8256384661fae7f02f8091259132d0e5", "url": "https://github.com/infinispan/infinispan/commit/8c8a308c8256384661fae7f02f8091259132d0e5", "message": "Address wburns comments", "committedDate": "2020-07-21T13:49:34Z", "type": "forcePushed"}, {"oid": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "url": "https://github.com/infinispan/infinispan/commit/dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "message": "ISPN-11723 REST API docs", "committedDate": "2020-07-22T16:48:18Z", "type": "forcePushed"}, {"oid": "c6b1e7bfba81442df11dcd327c276e245ac98e21", "url": "https://github.com/infinispan/infinispan/commit/c6b1e7bfba81442df11dcd327c276e245ac98e21", "message": "ISPN-11723 REST API docs", "committedDate": "2020-07-22T17:05:18Z", "type": "forcePushed"}, {"oid": "cd56ef01031bc2d4b948b04110698f2eb4d80595", "url": "https://github.com/infinispan/infinispan/commit/cd56ef01031bc2d4b948b04110698f2eb4d80595", "message": "ISPN-11723 REST API docs", "committedDate": "2020-07-23T10:09:38Z", "type": "forcePushed"}, {"oid": "efedcd6e4718f909ec002c586f289f19d8703c3c", "url": "https://github.com/infinispan/infinispan/commit/efedcd6e4718f909ec002c586f289f19d8703c3c", "message": "Updated to allow for new RESTful api that splits resource creation and\nretrieval", "committedDate": "2020-07-30T10:08:24Z", "type": "forcePushed"}, {"oid": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "url": "https://github.com/infinispan/infinispan/commit/76138ebd042977a2d0f72f2d73e7a611212ae9d8", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-04T10:21:19Z", "type": "forcePushed"}, {"oid": "dc8e76f5c9749882ec867ed84d90e7fa95b373fa", "url": "https://github.com/infinispan/infinispan/commit/dc8e76f5c9749882ec867ed84d90e7fa95b373fa", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-05T10:31:28Z", "type": "forcePushed"}, {"oid": "5a7bffb7ec8256f0abb5a1623fc802849983a640", "url": "https://github.com/infinispan/infinispan/commit/5a7bffb7ec8256f0abb5a1623fc802849983a640", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-05T10:39:48Z", "type": "forcePushed"}, {"oid": "273d51d75ac24b6893868ce0a373c07e368e1f24", "url": "https://github.com/infinispan/infinispan/commit/273d51d75ac24b6893868ce0a373c07e368e1f24", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-06T10:04:01Z", "type": "forcePushed"}, {"oid": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "url": "https://github.com/infinispan/infinispan/commit/c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-06T13:54:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgyNzc5NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467827795", "body": "The REST related changes LGTM!", "bodyText": "The REST related changes LGTM!", "bodyHTML": "<p dir=\"auto\">The REST related changes LGTM!</p>", "author": "gustavocoding", "createdAt": "2020-08-10T10:58:42Z", "path": "server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java", "diffHunk": "@@ -108,6 +111,11 @@ public Invocations getInvocations() {\n \n             // Caches\n             .invocation().methods(GET).path(\"/v2/cache-managers/{name}/caches\").handleWith(this::getCaches)\n+\n+            // BackupManager\n+            .invocation().methods(GET).path(\"/v2/cache-managers/{name}/backups\").handleWith(this::getAllBackupNames)\n+            .invocation().methods(DELETE, GET, HEAD, POST).path(\"/v2/cache-managers/{name}/backups/{backupName}\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cache-managers/{name}/backups\").withAction(\"restore\").handleWith(this::restore)", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java b/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java\nindex 586cd701aa..ab99b169f5 100644\n--- a/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java\n+++ b/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java\n", "chunk": "@@ -111,11 +108,6 @@ public Invocations getInvocations() {\n \n             // Caches\n             .invocation().methods(GET).path(\"/v2/cache-managers/{name}/caches\").handleWith(this::getCaches)\n-\n-            // BackupManager\n-            .invocation().methods(GET).path(\"/v2/cache-managers/{name}/backups\").handleWith(this::getAllBackupNames)\n-            .invocation().methods(DELETE, GET, HEAD, POST).path(\"/v2/cache-managers/{name}/backups/{backupName}\").handleWith(this::backup)\n-            .invocation().methods(POST).path(\"/v2/cache-managers/{name}/backups\").withAction(\"restore\").handleWith(this::restore)\n             .create();\n    }\n \n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java b/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java\nindex ab99b169f5..586cd701aa 100644\n--- a/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java\n+++ b/server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java\n", "chunk": "@@ -108,6 +111,11 @@ public Invocations getInvocations() {\n \n             // Caches\n             .invocation().methods(GET).path(\"/v2/cache-managers/{name}/caches\").handleWith(this::getCaches)\n+\n+            // BackupManager\n+            .invocation().methods(GET).path(\"/v2/cache-managers/{name}/backups\").handleWith(this::getAllBackupNames)\n+            .invocation().methods(DELETE, GET, HEAD, POST).path(\"/v2/cache-managers/{name}/backups/{backupName}\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cache-managers/{name}/backups\").withAction(\"restore\").handleWith(this::restore)\n             .create();\n    }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDUxMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467984513", "body": "```suggestion\r\n    * Retrieves a backup file with the given name from the server.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Retrieve a backup file with the given name from the server.\n          \n          \n            \n                * Retrieves a backup file with the given name from the server.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Retrieve</span> a backup file with the given name from the server.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Retrieves</span> a backup file with the given name from the server.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "oraNod", "createdAt": "2020-08-10T15:27:43Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f57736b5792ba572c18792f105772d7eeea0b78", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 9dc9dcffa0..49c6f74a5e 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -78,7 +78,7 @@\n    CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n \n    /**\n-    * Retrieve a backup file with the given name from the server.\n+    * Retrieves a backup file with the given name from the server.\n     *\n     * @param name     the name of the backup.\n     * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 49c6f74a5e..ee706aa598 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -49,74 +46,4 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n-\n-   /**\n-    * Creates a backup file containing all resources in this container.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name) {\n-      return createBackup(name, null);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n-      return createBackup(name, null, resources);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n-    *                   backup file. A null value indicates that the server default should be used.\n-    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                   list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content associated with this containers name contained within the provided backup file. The backup\n-    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   default CompletionStage<RestResponse> restore(File backup) {\n-      return restore(backup, null);\n-   }\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backup    the backup {@link File} containing the data to be restored.\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n-    *                       provided list only contains \"*\" then all available resources of that type are restored.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex ee706aa598..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -46,4 +49,77 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n+    *                   indicates that all resources should be included in the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n+    *                  indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n+    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n+    *                       null value indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDYyOA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467984628", "body": "```suggestion\r\n    * Deletes a backup file from the server.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Delete a backup file from the server.\n          \n          \n            \n                * Deletes a backup file from the server.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Delete</span> a backup file from the server.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Deletes</span> a backup file from the server.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "oraNod", "createdAt": "2020-08-10T15:27:53Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Delete a backup file from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f57736b5792ba572c18792f105772d7eeea0b78", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 9dc9dcffa0..49c6f74a5e 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -78,7 +78,7 @@\n    CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n \n    /**\n-    * Retrieve a backup file with the given name from the server.\n+    * Retrieves a backup file with the given name from the server.\n     *\n     * @param name     the name of the backup.\n     * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 49c6f74a5e..ee706aa598 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -49,74 +46,4 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n-\n-   /**\n-    * Creates a backup file containing all resources in this container.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name) {\n-      return createBackup(name, null);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n-      return createBackup(name, null, resources);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n-    *                   backup file. A null value indicates that the server default should be used.\n-    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                   list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content associated with this containers name contained within the provided backup file. The backup\n-    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   default CompletionStage<RestResponse> restore(File backup) {\n-      return restore(backup, null);\n-   }\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backup    the backup {@link File} containing the data to be restored.\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n-    *                       provided list only contains \"*\" then all available resources of that type are restored.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex ee706aa598..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -46,4 +49,77 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n+    *                   indicates that all resources should be included in the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n+    *                  indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n+    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n+    *                       null value indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 9dc9dcffa0..49c6f74a5e 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -86,7 +86,7 @@\n    CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n \n    /**\n-    * Delete a backup file from the server.\n+    * Deletes a backup file from the server.\n     *\n     * @param name the name of the backup.\n     */\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 49c6f74a5e..ee706aa598 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -49,74 +46,4 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n-\n-   /**\n-    * Creates a backup file containing all resources in this container.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name) {\n-      return createBackup(name, null);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n-      return createBackup(name, null, resources);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n-    *                   backup file. A null value indicates that the server default should be used.\n-    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                   list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content associated with this containers name contained within the provided backup file. The backup\n-    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   default CompletionStage<RestResponse> restore(File backup) {\n-      return restore(backup, null);\n-   }\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backup    the backup {@link File} containing the data to be restored.\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n-    *                       provided list only contains \"*\" then all available resources of that type are restored.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex ee706aa598..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -46,4 +49,77 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n+    *                   indicates that all resources should be included in the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n+    *                  indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n+    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n+    *                       null value indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NTYzMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467985633", "body": "```suggestion\r\n    * Retrieves a backup file with the given name from the server.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Retrieve a backup file with the given name from the server.\n          \n          \n            \n                * Retrieves a backup file with the given name from the server.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Retrieve</span> a backup file with the given name from the server.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Retrieves</span> a backup file with the given name from the server.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "oraNod", "createdAt": "2020-08-10T15:29:24Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java", "diffHunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f57736b5792ba572c18792f105772d7eeea0b78", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 72aa203ad3..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -27,7 +27,7 @@\n    CompletionStage<RestResponse> createBackup(String name);\n \n    /**\n-    * Retrieve a backup file with the given name from the server.\n+    * Retrieves a backup file with the given name from the server.\n     *\n     * @param name     the name of the backup.\n     * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 607a7079ee..4d0f8dfadf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -18,41 +17,4 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n-\n-   /**\n-    * Creates a backup file containing the content of all containers in the cluster.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n-    * once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup);\n-\n-   /**\n-    * Restores all content from a backup file available to the server instance.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 4d0f8dfadf..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n+    * once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup);\n+\n+   /**\n+    * Restores all content from a backup file available to the server instance.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NTcwOQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467985709", "body": "```suggestion\r\n    * Deletes a backup file from the server.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Delete a backup file from the server.\n          \n          \n            \n                * Deletes a backup file from the server.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Delete</span> a backup file from the server.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first x-last\">Deletes</span> a backup file from the server.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "oraNod", "createdAt": "2020-08-10T15:29:32Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java", "diffHunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Delete a backup file from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f57736b5792ba572c18792f105772d7eeea0b78", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 72aa203ad3..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -27,7 +27,7 @@\n    CompletionStage<RestResponse> createBackup(String name);\n \n    /**\n-    * Retrieve a backup file with the given name from the server.\n+    * Retrieves a backup file with the given name from the server.\n     *\n     * @param name     the name of the backup.\n     * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 607a7079ee..4d0f8dfadf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -18,41 +17,4 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n-\n-   /**\n-    * Creates a backup file containing the content of all containers in the cluster.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n-    * once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup);\n-\n-   /**\n-    * Restores all content from a backup file available to the server instance.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 4d0f8dfadf..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n+    * once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup);\n+\n+   /**\n+    * Restores all content from a backup file available to the server instance.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 72aa203ad3..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -35,7 +35,7 @@\n    CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n \n    /**\n-    * Delete a backup file from the server.\n+    * Deletes a backup file from the server.\n     *\n     * @param name the name of the backup.\n     */\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 607a7079ee..4d0f8dfadf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -18,41 +17,4 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n-\n-   /**\n-    * Creates a backup file containing the content of all containers in the cluster.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n-    * once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup);\n-\n-   /**\n-    * Restores all content from a backup file available to the server instance.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\nindex 4d0f8dfadf..607a7079ee 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java\n", "chunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content from a backup file, by uploading the file to the server endpoint for processing, returning\n+    * once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup);\n+\n+   /**\n+    * Restores all content from a backup file available to the server instance.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation);\n }\n", "next_change": null}]}}]}}]}}, {"oid": "2f57736b5792ba572c18792f105772d7eeea0b78", "url": "https://github.com/infinispan/infinispan/commit/2f57736b5792ba572c18792f105772d7eeea0b78", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-11T08:55:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1MzgwNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469453807", "body": "We don't specify what null does here. I am guessing it means everything? I only ask one of the default methods passes it.", "bodyText": "We don't specify what null does here. I am guessing it means everything? I only ask one of the default methods passes it.", "bodyHTML": "<p dir=\"auto\">We don't specify what null does here. I am guessing it means everything? I only ask one of the default methods passes it.</p>", "author": "wburns", "createdAt": "2020-08-12T18:21:22Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 49c6f74a5e..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -73,7 +73,8 @@\n     * @param workingDir the path of the server directory to be used to create the backup content and store the final\n     *                   backup file. A null value indicates that the server default should be used.\n     * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n+    *                   indicates that all resources should be included in the backup.\n     */\n    CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n \n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 9582e42aaf..ee706aa598 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -49,77 +46,4 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n-\n-   /**\n-    * Creates a backup file containing all resources in this container.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name) {\n-      return createBackup(name, null);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n-      return createBackup(name, null, resources);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n-    *                   backup file. A null value indicates that the server default should be used.\n-    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n-    *                   indicates that all resources should be included in the backup.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content associated with this containers name contained within the provided backup file. The backup\n-    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   default CompletionStage<RestResponse> restore(File backup) {\n-      return restore(backup, null);\n-   }\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backup    the backup {@link File} containing the data to be restored.\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n-    *                  indicates that all resources in the backup should be restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n-    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n-    *                       null value indicates that all resources in the backup should be restored.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex ee706aa598..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -46,4 +49,77 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n+    *                   indicates that all resources should be included in the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n+    *                  indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n+    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n+    *                       null value indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1Mzg5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469453891", "body": "Same about null here.", "bodyText": "Same about null here.", "bodyHTML": "<p dir=\"auto\">Same about null here.</p>", "author": "wburns", "createdAt": "2020-08-12T18:21:31Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 49c6f74a5e..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -107,7 +108,8 @@\n     *\n     * @param backup    the backup {@link File} containing the data to be restored.\n     * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are restored.\n+    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n+    *                  indicates that all resources in the backup should be restored.\n     */\n    CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n \n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex 9582e42aaf..ee706aa598 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -49,77 +46,4 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n-\n-   /**\n-    * Creates a backup file containing all resources in this container.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name) {\n-      return createBackup(name, null);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are backed up.\n-    */\n-   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n-      return createBackup(name, null, resources);\n-   }\n-\n-   /**\n-    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n-    *\n-    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n-    *                   backup file. A null value indicates that the server default should be used.\n-    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n-    *                   indicates that all resources should be included in the backup.\n-    */\n-   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n-\n-   /**\n-    * Retrieves a backup file with the given name from the server.\n-    *\n-    * @param name     the name of the backup.\n-    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n-    */\n-   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n-\n-   /**\n-    * Deletes a backup file from the server.\n-    *\n-    * @param name the name of the backup.\n-    */\n-   CompletionStage<RestResponse> deleteBackup(String name);\n-\n-   /**\n-    * Restores all content associated with this containers name contained within the provided backup file. The backup\n-    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n-    *\n-    * @param backup the backup {@link File} containing the data to be restored.\n-    */\n-   default CompletionStage<RestResponse> restore(File backup) {\n-      return restore(backup, null);\n-   }\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backup    the backup {@link File} containing the data to be restored.\n-    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n-    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n-    *                  indicates that all resources in the backup should be restored.\n-    */\n-   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n-\n-   /**\n-    * Restores the specified content from the backup file that's associated with this container's name.\n-    *\n-    * @param backupLocation the path of the backup file already located on the server.\n-    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n-    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n-    *                       null value indicates that all resources in the backup should be restored.\n-    */\n-   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\nindex ee706aa598..9582e42aaf 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java\n", "chunk": "@@ -46,4 +49,77 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up. A null value\n+    *                   indicates that all resources should be included in the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are restored. A null value\n+    *                  indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources);\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backupLocation the path of the backup file already located on the server.\n+    * @param resources      a map of BackupManager.Resources.Type with the names of the resources to backup. If the\n+    *                       provided list only contains \"*\" then all available resources of that type are restored. A\n+    *                       null value indicates that all resources in the backup should be restored.\n+    */\n+   CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources);\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NTIxNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469455214", "body": "Do we need to escape any json characters here? Could the String contain valid json delimiters?\r\n\r\nGuessing the Json object does that for us.\r\n\r\nAlso does `Json.factory().make(resources)` not do what we want?", "bodyText": "Do we need to escape any json characters here? Could the String contain valid json delimiters?\nGuessing the Json object does that for us.\nAlso does Json.factory().make(resources) not do what we want?", "bodyHTML": "<p dir=\"auto\">Do we need to escape any json characters here? Could the String contain valid json delimiters?</p>\n<p dir=\"auto\">Guessing the Json object does that for us.</p>\n<p dir=\"auto\">Also does <code>Json.factory().make(resources)</code> not do what we want?</p>", "author": "wburns", "createdAt": "2020-08-12T18:23:59Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java", "diffHunk": "@@ -121,4 +128,75 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n+\n+   @Override\n+   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (workingDir != null)\n+         json.set(\"directory\", workingDir);\n+\n+      if (resources != null) {\n+         Json resourcesJson = Json.object();\n+         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));\n+         json.set(\"resources\", resourcesJson);\n+      }\n+      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n+      Request.Builder builder = backup(name).post(body);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> getBackup(String name, boolean skipBody) {\n+      Request.Builder builder = backup(name);\n+      if (skipBody)\n+         builder.head();\n+\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> deleteBackup(String name) {\n+      return client.execute(backup(name).delete());\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (resources != null) {\n+         resources.forEach((k, v) -> json.set(k, v.toArray(new String[0])));\n+      }\n+      RequestBody zipBody = new FileRestEntityOkHttp(MediaType.APPLICATION_ZIP, backup).toRequestBody();\n+\n+      RequestBody multipartBody = new MultipartBody.Builder()\n+            .addFormDataPart(\"resources\", json.toString())\n+            .addFormDataPart(\"backup\", backup.getName(), zipBody)\n+            .setType(MultipartBody.FORM)\n+            .build();\n+\n+      Request.Builder builder = restore().post(multipartBody);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      json.set(\"location\", backupLocation);\n+\n+      if (resources != null) {\n+         Json resourcesJson = Json.object();\n+         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgwMTAwNg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469801006", "bodyText": "Do we need to escape any json characters here? Could the String contain valid json delimiters?\n\nI don't think so, there shouldn't be any JSON passed in the Map.\n\nAlso does Json.factory().make(resources) not do what we want?\n\nYes \ud83d\ude42. I didn't know about that before.", "author": "ryanemerson", "createdAt": "2020-08-13T08:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NTIxNA=="}], "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\nindex 4339fcb12a..058e7d26c8 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n", "chunk": "@@ -182,11 +179,9 @@ public String name() {\n       Json json = Json.object();\n       json.set(\"location\", backupLocation);\n \n-      if (resources != null) {\n-         Json resourcesJson = Json.object();\n-         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));\n-         json.set(\"resources\", resourcesJson);\n-      }\n+      if (resources != null)\n+         json.set(\"resources\", Json.factory().make(resources));\n+\n       RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n       Request.Builder builder = restore().post(body);\n       return client.execute(builder);\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\nindex 058e7d26c8..25ea8b244a 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n", "chunk": "@@ -128,70 +121,4 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n-\n-   @Override\n-   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n-      Json json = Json.object();\n-      if (workingDir != null)\n-         json.set(\"directory\", workingDir);\n-\n-      if (resources != null) {\n-         Json resourcesJson = Json.object();\n-         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));\n-         json.set(\"resources\", resourcesJson);\n-      }\n-      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n-      Request.Builder builder = backup(name).post(body);\n-      return client.execute(builder);\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> getBackup(String name, boolean skipBody) {\n-      Request.Builder builder = backup(name);\n-      if (skipBody)\n-         builder.head();\n-\n-      return client.execute(builder);\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> deleteBackup(String name) {\n-      return client.execute(backup(name).delete());\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources) {\n-      Json json = resources != null ? Json.factory().make(resources) : Json.object();\n-      RequestBody zipBody = new FileRestEntityOkHttp(MediaType.APPLICATION_ZIP, backup).toRequestBody();\n-\n-      RequestBody multipartBody = new MultipartBody.Builder()\n-            .addFormDataPart(\"resources\", json.toString())\n-            .addFormDataPart(\"backup\", backup.getName(), zipBody)\n-            .setType(MultipartBody.FORM)\n-            .build();\n-\n-      Request.Builder builder = restore().post(multipartBody);\n-      return client.execute(builder);\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources) {\n-      Json json = Json.object();\n-      json.set(\"location\", backupLocation);\n-\n-      if (resources != null)\n-         json.set(\"resources\", Json.factory().make(resources));\n-\n-      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n-      Request.Builder builder = restore().post(body);\n-      return client.execute(builder);\n-   }\n-\n-   private Request.Builder backup(String name) {\n-      return new Request.Builder().url(baseCacheManagerUrl + \"/backups/\" + name);\n-   }\n-\n-   private Request.Builder restore() {\n-      return new Request.Builder().url(baseCacheManagerUrl + \"/backups?action=restore\");\n-   }\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\nindex 25ea8b244a..9728accf56 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n", "chunk": "@@ -121,4 +128,68 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n+\n+   @Override\n+   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (workingDir != null)\n+         json.set(\"directory\", workingDir);\n+\n+      if (resources != null)\n+         json.set(\"resources\", Json.factory().make(resources));\n+\n+      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n+      Request.Builder builder = backup(name).post(body);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> getBackup(String name, boolean skipBody) {\n+      Request.Builder builder = backup(name);\n+      if (skipBody)\n+         builder.head();\n+\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> deleteBackup(String name) {\n+      return client.execute(backup(name).delete());\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources) {\n+      Json json = resources != null ? Json.factory().make(resources) : Json.object();\n+      RequestBody zipBody = new FileRestEntityOkHttp(MediaType.APPLICATION_ZIP, backup).toRequestBody();\n+\n+      RequestBody multipartBody = new MultipartBody.Builder()\n+            .addFormDataPart(\"resources\", json.toString())\n+            .addFormDataPart(\"backup\", backup.getName(), zipBody)\n+            .setType(MultipartBody.FORM)\n+            .build();\n+\n+      Request.Builder builder = restore().post(multipartBody);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      json.set(\"location\", backupLocation);\n+\n+      if (resources != null)\n+         json.set(\"resources\", Json.factory().make(resources));\n+\n+      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n+      Request.Builder builder = restore().post(body);\n+      return client.execute(builder);\n+   }\n+\n+   private Request.Builder backup(String name) {\n+      return new Request.Builder().url(baseCacheManagerUrl + \"/backups/\" + name);\n+   }\n+\n+   private Request.Builder restore() {\n+      return new Request.Builder().url(baseCacheManagerUrl + \"/backups?action=restore\");\n+   }\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469457397", "body": "Do we not want the info from the stores?", "bodyText": "Do we not want the info from the stores?", "bodyHTML": "<p dir=\"auto\">Do we not want the info from the stores?</p>", "author": "wburns", "createdAt": "2020-08-12T18:27:49Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTc4MzM5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469783391", "bodyText": "This is something that I have been in two minds about. Originally I was thinking that if data is already persisted, then the stores can also be migrated by the user, but this isn't very user-friendly especially if stores are not shared and we have a large cluster. Having a centralised backup greatly simplifies this, so including stores by default makes more sense on second thought.\nIn the case of a large shared store, probably JDBC based, it's probably not desired to have the store content in the backup. Once the core backup/restore pieces are in place (CLI, Operator etc) we can add a parameter to toggle this behaviour.", "author": "ryanemerson", "createdAt": "2020-08-13T08:27:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAyMzI2NA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470023264", "bodyText": "Makes sense. This makes me wonder if we should have the default value be if the store it uses is shared or not.\nAlso I wonder if we should add support for the Flag SKIP_SHARED_CACHE_STORE in the ClusterPublisherManager", "author": "wburns", "createdAt": "2020-08-13T15:08:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzMDE1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470030151", "bodyText": "This makes me wonder if we should have the default value be if the store it uses is shared or not\n\nTbh I think this could be difficult to explain to the user in a transparent way. Having a consistent default and then documenting that it's possible to backup in-memory contents only is much simpler IMO. We can then add a note explaining that for larger shared stores it's probably desirable to enable this option.", "author": "ryanemerson", "createdAt": "2020-08-13T15:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzQwMQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470037401", "bodyText": "Also I wonder if we should add support for the Flag SKIP_SHARED_CACHE_STORE in the ClusterPublisherManager\n\nMakes sense. It would be perfect for this use-case", "author": "ryanemerson", "createdAt": "2020-08-13T15:27:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex f9252c0eaa..bbe8621266 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -183,51 +180,52 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-\n-         // Write in-memory cache contents to .dat file if the cache is not empty\n-         if (cache.isEmpty())\n-            return;\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n-               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n-               .subscribe(s);\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .buffer(BUFFER_SIZE)\n-                           .flatMap(Flowable::fromIterable)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .doOnError(t -> {\n-                              throw new CacheException(\"Unable to create cache backup\", t);\n-                           }),\n-               OutputStream::close\n-         ).subscribe();\n-      }, \"backup-cache-\" + cacheName);\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())\n+         return configStage;\n+\n+      ComponentRegistry cr = cache.getComponentRegistry();\n+      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+      String dataFileName = dataFile(cacheName);\n+      Path datFile = cacheRoot.resolve(dataFileName);\n+\n+      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> Files.newOutputStream(datFile),\n+                  output ->\n+                        Flowable.fromPublisher(p)\n+                              .map(e -> {\n+                                 CacheBackupEntry be = new CacheBackupEntry();\n+                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                                 be.internalMetadata = e.getInternalMetadata();\n+                                 be.created = e.getCreated();\n+                                 be.lastUsed = e.getLastUsed();\n+                                 return be;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create cache backup\", t);\n+                              }),\n+                  OutputStream::close\n+            ), \"write-cache-contents\");\n+\n+      return CompletionStages.allOf(configStage, contentStage);\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..2521d13cb5 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -219,9 +217,7 @@ public void prepareAndValidateBackup() {\n                                  return be;\n                               })\n                               .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n+                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n                   OutputStream::close\n             ), \"write-cache-contents\");\n \n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex 2521d13cb5..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -181,47 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1ODEzNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469458137", "body": "This is redundant. You can just return the value returned from invoking `entryPublisher`.", "bodyText": "This is redundant. You can just return the value returned from invoking entryPublisher.", "bodyHTML": "<p dir=\"auto\">This is redundant. You can just return the value returned from invoking <code>entryPublisher</code>.</p>", "author": "wburns", "createdAt": "2020-08-12T18:29:07Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n+               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n+               .subscribe(s);", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex f9252c0eaa..bbe8621266 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -183,51 +180,52 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-\n-         // Write in-memory cache contents to .dat file if the cache is not empty\n-         if (cache.isEmpty())\n-            return;\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n-               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n-               .subscribe(s);\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .buffer(BUFFER_SIZE)\n-                           .flatMap(Flowable::fromIterable)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .doOnError(t -> {\n-                              throw new CacheException(\"Unable to create cache backup\", t);\n-                           }),\n-               OutputStream::close\n-         ).subscribe();\n-      }, \"backup-cache-\" + cacheName);\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())\n+         return configStage;\n+\n+      ComponentRegistry cr = cache.getComponentRegistry();\n+      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+      String dataFileName = dataFile(cacheName);\n+      Path datFile = cacheRoot.resolve(dataFileName);\n+\n+      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> Files.newOutputStream(datFile),\n+                  output ->\n+                        Flowable.fromPublisher(p)\n+                              .map(e -> {\n+                                 CacheBackupEntry be = new CacheBackupEntry();\n+                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                                 be.internalMetadata = e.getInternalMetadata();\n+                                 be.created = e.getCreated();\n+                                 be.lastUsed = e.getLastUsed();\n+                                 return be;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create cache backup\", t);\n+                              }),\n+                  OutputStream::close\n+            ), \"write-cache-contents\");\n+\n+      return CompletionStages.allOf(configStage, contentStage);\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..2521d13cb5 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -219,9 +217,7 @@ public void prepareAndValidateBackup() {\n                                  return be;\n                               })\n                               .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n+                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n                   OutputStream::close\n             ), \"write-cache-contents\");\n \n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex 2521d13cb5..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -181,47 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1OTEzNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469459134", "body": "I am thinking it would be better to use `BlockingManager#supplyBlocking` and thenCompose invoke thenCompose on it. This way we won't be blocking a blocking thread unless it is processing a response to write to disk.", "bodyText": "I am thinking it would be better to use BlockingManager#supplyBlocking and thenCompose invoke thenCompose on it. This way we won't be blocking a blocking thread unless it is processing a response to write to disk.", "bodyHTML": "<p dir=\"auto\">I am thinking it would be better to use <code>BlockingManager#supplyBlocking</code> and thenCompose invoke thenCompose on it. This way we won't be blocking a blocking thread unless it is processing a response to write to disk.</p>", "author": "wburns", "createdAt": "2020-08-12T18:30:51Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg0NTIwMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469845203", "bodyText": "I'm not sure what you mean here. I have updated createCacheBackup to use BlockingManager#blockingPublisherToVoidStage, does ^ suggestion still apply with my latest changes?", "author": "ryanemerson", "createdAt": "2020-08-13T10:10:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1OTEzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAyMzkyNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470023924", "bodyText": "I suggested this originally and didn't go back to change this one. So using the new method is preferred.", "author": "wburns", "createdAt": "2020-08-13T15:09:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1OTEzNA=="}], "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex f9252c0eaa..bbe8621266 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -167,14 +164,14 @@ public void prepareAndValidateBackup() {\n    }\n \n    private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+      Configuration configuration = cm.getCacheConfiguration(cacheName);\n \n-         // Create the cache backup dir and parents\n-         Path cacheRoot = root.resolve(cacheName);\n-         mkdirs(cacheRoot);\n+      // Create the cache backup dir and parents\n+      Path cacheRoot = root.resolve(cacheName);\n+      mkdirs(cacheRoot);\n \n+      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n          // Write configuration file\n          String xmlFileName = configFile(cacheName);\n          Path xmlPath = cacheRoot.resolve(xmlFileName);\n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -164,14 +165,14 @@ public void prepareAndValidateBackup() {\n    }\n \n    private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-      Configuration configuration = cm.getCacheConfiguration(cacheName);\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n \n-      // Create the cache backup dir and parents\n-      Path cacheRoot = root.resolve(cacheName);\n-      mkdirs(cacheRoot);\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n \n-      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n          // Write configuration file\n          String xmlFileName = configFile(cacheName);\n          Path xmlPath = cacheRoot.resolve(xmlFileName);\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}, {"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -180,52 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      if (cache.isEmpty())\n-         return configStage;\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzE3Ng==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469463176", "body": "Can we not do this in subscribe instead?", "bodyText": "Can we not do this in subscribe instead?", "bodyHTML": "<p dir=\"auto\">Can we not do this in subscribe instead?</p>", "author": "wburns", "createdAt": "2020-08-12T18:38:00Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n+               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n+               .subscribe(s);\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .buffer(BUFFER_SIZE)\n+                           .flatMap(Flowable::fromIterable)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgwODcxMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469808713", "bodyText": "I don't think so, because subscribe returns a Disposable but we need to return a Publisher so that it can be consumed as the Flowable.using sourceSupplier. This is similar to the JpaStore#createBatchFlowable code.", "author": "ryanemerson", "createdAt": "2020-08-13T09:08:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzE3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzOTk2Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470039967", "bodyText": "\ud83d\udc4d Forgot it returns a Disposable :(", "author": "wburns", "createdAt": "2020-08-13T15:31:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzE3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex f9252c0eaa..bbe8621266 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -183,51 +180,52 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-\n-         // Write in-memory cache contents to .dat file if the cache is not empty\n-         if (cache.isEmpty())\n-            return;\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n-               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n-               .subscribe(s);\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .buffer(BUFFER_SIZE)\n-                           .flatMap(Flowable::fromIterable)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .doOnError(t -> {\n-                              throw new CacheException(\"Unable to create cache backup\", t);\n-                           }),\n-               OutputStream::close\n-         ).subscribe();\n-      }, \"backup-cache-\" + cacheName);\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())\n+         return configStage;\n+\n+      ComponentRegistry cr = cache.getComponentRegistry();\n+      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+      String dataFileName = dataFile(cacheName);\n+      Path datFile = cacheRoot.resolve(dataFileName);\n+\n+      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> Files.newOutputStream(datFile),\n+                  output ->\n+                        Flowable.fromPublisher(p)\n+                              .map(e -> {\n+                                 CacheBackupEntry be = new CacheBackupEntry();\n+                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                                 be.internalMetadata = e.getInternalMetadata();\n+                                 be.created = e.getCreated();\n+                                 be.lastUsed = e.getLastUsed();\n+                                 return be;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create cache backup\", t);\n+                              }),\n+                  OutputStream::close\n+            ), \"write-cache-contents\");\n+\n+      return CompletionStages.allOf(configStage, contentStage);\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..2521d13cb5 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -219,9 +217,7 @@ public void prepareAndValidateBackup() {\n                                  return be;\n                               })\n                               .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n+                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n                   OutputStream::close\n             ), \"write-cache-contents\");\n \n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex 2521d13cb5..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -181,47 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzIyMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469463220", "body": "This buffer and flatMap looks extraneous. What was the reason for them?", "bodyText": "This buffer and flatMap looks extraneous. What was the reason for them?", "bodyHTML": "<p dir=\"auto\">This buffer and flatMap looks extraneous. What was the reason for them?</p>", "author": "wburns", "createdAt": "2020-08-12T18:38:04Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n+               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n+               .subscribe(s);\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .buffer(BUFFER_SIZE)", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgxMTQyNQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469811425", "bodyText": "I honestly can't remember. Removed.", "author": "ryanemerson", "createdAt": "2020-08-13T09:12:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzIyMA=="}], "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex f9252c0eaa..bbe8621266 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -183,51 +180,52 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-\n-         // Write in-memory cache contents to .dat file if the cache is not empty\n-         if (cache.isEmpty())\n-            return;\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n-               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n-               .subscribe(s);\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .buffer(BUFFER_SIZE)\n-                           .flatMap(Flowable::fromIterable)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .doOnError(t -> {\n-                              throw new CacheException(\"Unable to create cache backup\", t);\n-                           }),\n-               OutputStream::close\n-         ).subscribe();\n-      }, \"backup-cache-\" + cacheName);\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())\n+         return configStage;\n+\n+      ComponentRegistry cr = cache.getComponentRegistry();\n+      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+      String dataFileName = dataFile(cacheName);\n+      Path datFile = cacheRoot.resolve(dataFileName);\n+\n+      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> Files.newOutputStream(datFile),\n+                  output ->\n+                        Flowable.fromPublisher(p)\n+                              .map(e -> {\n+                                 CacheBackupEntry be = new CacheBackupEntry();\n+                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                                 be.internalMetadata = e.getInternalMetadata();\n+                                 be.created = e.getCreated();\n+                                 be.lastUsed = e.getLastUsed();\n+                                 return be;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create cache backup\", t);\n+                              }),\n+                  OutputStream::close\n+            ), \"write-cache-contents\");\n+\n+      return CompletionStages.allOf(configStage, contentStage);\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..2521d13cb5 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -219,9 +217,7 @@ public void prepareAndValidateBackup() {\n                                  return be;\n                               })\n                               .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n+                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n                   OutputStream::close\n             ), \"write-cache-contents\");\n \n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex 2521d13cb5..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -181,47 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469464074", "body": "I noticed that we do an unbounded run of this. Should we limit how many blocking threads we are using? I worry about delaying actual operations on the server or even worse possibly getting some sort of livelock.", "bodyText": "I noticed that we do an unbounded run of this. Should we limit how many blocking threads we are using? I worry about delaying actual operations on the server or even worse possibly getting some sort of livelock.", "bodyHTML": "<p dir=\"auto\">I noticed that we do an unbounded run of this. Should we limit how many blocking threads we are using? I worry about delaying actual operations on the server or even worse possibly getting some sort of livelock.</p>", "author": "wburns", "createdAt": "2020-08-12T18:39:37Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ3OTI1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469479251", "bodyText": "It makes me wonder if we should add some extra methods to BlockingManager#BlockingExecutor to handle these types of cases.", "author": "wburns", "createdAt": "2020-08-12T19:07:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg2MDAwMg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469860002", "bodyText": "Agreed that we should limit the number of blocking threads are used by this, as even if there is a reasonably modest number of caches this could cause issues.\nI think BlockingManager.BlockingExecutor could provide all of the BlockingManager methods with the exception of limitedBlockingExecutor. That way we can do something like:\n     BlockingManager.BlockingExecutor executor = blockingManager.limitedBlockingExecutor(\"cache-backup-executor\", 5);\n     for (String cache : resources)\n         stages.dependsOn(createCacheBackup(cache, executor));\nTo reduce repetition in the BlockingManager interface, we can create another interface BlockingOperations and then do the following:\npublic interface BlockingManager extends BlockingOperations {\n\n    BlockingExecutor limitedBlockingExecutor(String name, int concurrency);\n\n    interface BlockingExecutor extends BlockingOperations {\n    }\n}\nBlockingManagerImpl would then just provide versions of the BlockingOperations methods that take a Scheduler|Executor as an additional parameter.", "author": "ryanemerson", "createdAt": "2020-08-13T10:39:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg2Mjg2Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469862867", "bodyText": "Similarly we could avoid BlockingOperations by adding a method that returns a BackupManager implementation that utilies a LimitedExecutor:\nBlockingManager limitedBlockingManager(int concurrency);", "author": "ryanemerson", "createdAt": "2020-08-13T10:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA3NzAxNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470077017", "bodyText": "I look forward to seeing this change in another PR \ud83d\udc4d", "author": "wburns", "createdAt": "2020-08-13T16:29:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA3ODYxMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470078610", "bodyText": "I have created ISPN-12226 to track the BlockingManager enhancements and ISPN-12227 for the changes to the BackupManager.", "author": "ryanemerson", "createdAt": "2020-08-13T16:32:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}], "type": "inlineReview", "revised_code": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex f9252c0eaa..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,282 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   // TODO what size?\n-   private static final int BUFFER_SIZE = 100;\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         // Create the cache backup dir and parents\n-         Path cacheRoot = root.resolve(cacheName);\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         // Write in-memory cache contents to .dat file if the cache is not empty\n-         if (cache.isEmpty())\n-            return;\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n-               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n-               .subscribe(s);\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .buffer(BUFFER_SIZE)\n-                           .flatMap(Flowable::fromIterable)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .doOnError(t -> {\n-                              throw new CacheException(\"Unable to create cache backup\", t);\n-                           }),\n-               OutputStream::close\n-         ).subscribe();\n-      }, \"backup-cache-\" + cacheName);\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDU3MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469464570", "body": "Can we not just use state transfer chunk size? This is what the publisher will use whenever we make an actual user facing API for it ;)", "bodyText": "Can we not just use state transfer chunk size? This is what the publisher will use whenever we make an actual user facing API for it ;)", "bodyHTML": "<p dir=\"auto\">Can we not just use state transfer chunk size? This is what the publisher will use whenever we make an actual user facing API for it ;)</p>", "author": "wburns", "createdAt": "2020-08-12T18:40:29Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex f9252c0eaa..bbe8621266 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -63,9 +63,6 @@\n \n    private static final String MEMCACHED_CACHE = \"memcachedCache\";\n \n-   // TODO what size?\n-   private static final int BUFFER_SIZE = 100;\n-\n    private final EmbeddedCacheManager cm;\n    private final ParserRegistry parserRegistry;\n \n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex bbe8621266..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,280 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-      Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-      // Create the cache backup dir and parents\n-      Path cacheRoot = root.resolve(cacheName);\n-      mkdirs(cacheRoot);\n-\n-      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-      }, \"write-cache-config\");\n-\n-      if (cache.isEmpty())\n-         return configStage;\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ3MzIyMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469473220", "body": "So what you have here is handled a lot better if you add a method like the following to the `BlockingManager`\r\n\r\n```java\r\n   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\r\n      CompletionStage<Void> stage = Flowable.defer(() -> {\r\n         Flowable<V> flowable = Flowable.fromPublisher(publisher);\r\n         if (isCurrentThreadBlocking()) {\r\n            return flowable;\r\n         }\r\n         if (trace) {\r\n            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Subscribing to %s on blocking thread\"));\r\n         }\r\n         flowable = flowable.subscribeOn(blockingScheduler);\r\n         if (trace) {\r\n            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Publisher subscribing thread is %s\"));\r\n         }\r\n         return flowable;\r\n      }).ignoreElements().toCompletionStage(null);\r\n\r\n      return continueOnNonBlockingThread(stage, traceId);\r\n   }\r\n```\r\nI believe the `doOnSubscribe` is in the correct spot, but you may want to verify. The goal is to print it in the blocking thread so you can match operations between.\r\n\r\nThen you can just replace with this method and remove the subscribe below. This way it will properly resume on a non blocking thread. To be honest you may want to evaluate all your usages of `runBlocking` to see if you want to use this instead.", "bodyText": "So what you have here is handled a lot better if you add a method like the following to the BlockingManager\n   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\n      CompletionStage<Void> stage = Flowable.defer(() -> {\n         Flowable<V> flowable = Flowable.fromPublisher(publisher);\n         if (isCurrentThreadBlocking()) {\n            return flowable;\n         }\n         if (trace) {\n            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Subscribing to %s on blocking thread\"));\n         }\n         flowable = flowable.subscribeOn(blockingScheduler);\n         if (trace) {\n            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Publisher subscribing thread is %s\"));\n         }\n         return flowable;\n      }).ignoreElements().toCompletionStage(null);\n\n      return continueOnNonBlockingThread(stage, traceId);\n   }\nI believe the doOnSubscribe is in the correct spot, but you may want to verify. The goal is to print it in the blocking thread so you can match operations between.\nThen you can just replace with this method and remove the subscribe below. This way it will properly resume on a non blocking thread. To be honest you may want to evaluate all your usages of runBlocking to see if you want to use this instead.", "bodyHTML": "<p dir=\"auto\">So what you have here is handled a lot better if you add a method like the following to the <code>BlockingManager</code></p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"   public &lt;V&gt; CompletionStage&lt;Void&gt; blockingPublisherToVoidStage(Publisher&lt;V&gt; publisher, Object traceId) {\n      CompletionStage&lt;Void&gt; stage = Flowable.defer(() -&gt; {\n         Flowable&lt;V&gt; flowable = Flowable.fromPublisher(publisher);\n         if (isCurrentThreadBlocking()) {\n            return flowable;\n         }\n         if (trace) {\n            flowable = flowable.doOnSubscribe(subscription -&gt; log.tracef(&quot;Subscribing to %s on blocking thread&quot;));\n         }\n         flowable = flowable.subscribeOn(blockingScheduler);\n         if (trace) {\n            flowable = flowable.doOnSubscribe(subscription -&gt; log.tracef(&quot;Publisher subscribing thread is %s&quot;));\n         }\n         return flowable;\n      }).ignoreElements().toCompletionStage(null);\n\n      return continueOnNonBlockingThread(stage, traceId);\n   }\"><pre>   <span class=\"pl-k\">public</span> <span class=\"pl-k\">&lt;</span><span class=\"pl-smi\">V</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">CompletionStage&lt;<span class=\"pl-smi\">Void</span>&gt;</span> blockingPublisherToVoidStage(<span class=\"pl-k\">Publisher&lt;<span class=\"pl-smi\">V</span>&gt;</span> publisher, <span class=\"pl-smi\">Object</span> traceId) {\n      <span class=\"pl-k\">CompletionStage&lt;<span class=\"pl-smi\">Void</span>&gt;</span> stage <span class=\"pl-k\">=</span> <span class=\"pl-smi\">Flowable</span><span class=\"pl-k\">.</span>defer(() <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {\n         <span class=\"pl-k\">Flowable&lt;<span class=\"pl-smi\">V</span>&gt;</span> flowable <span class=\"pl-k\">=</span> <span class=\"pl-smi\">Flowable</span><span class=\"pl-k\">.</span>fromPublisher(publisher);\n         <span class=\"pl-k\">if</span> (isCurrentThreadBlocking()) {\n            <span class=\"pl-k\">return</span> flowable;\n         }\n         <span class=\"pl-k\">if</span> (trace) {\n            flowable <span class=\"pl-k\">=</span> flowable<span class=\"pl-k\">.</span>doOnSubscribe(subscription <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> log<span class=\"pl-k\">.</span>tracef(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Subscribing to %s on blocking thread<span class=\"pl-pds\">\"</span></span>));\n         }\n         flowable <span class=\"pl-k\">=</span> flowable<span class=\"pl-k\">.</span>subscribeOn(blockingScheduler);\n         <span class=\"pl-k\">if</span> (trace) {\n            flowable <span class=\"pl-k\">=</span> flowable<span class=\"pl-k\">.</span>doOnSubscribe(subscription <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> log<span class=\"pl-k\">.</span>tracef(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Publisher subscribing thread is %s<span class=\"pl-pds\">\"</span></span>));\n         }\n         <span class=\"pl-k\">return</span> flowable;\n      })<span class=\"pl-k\">.</span>ignoreElements()<span class=\"pl-k\">.</span>toCompletionStage(<span class=\"pl-c1\">null</span>);\n\n      <span class=\"pl-k\">return</span> continueOnNonBlockingThread(stage, traceId);\n   }</pre></div>\n<p dir=\"auto\">I believe the <code>doOnSubscribe</code> is in the correct spot, but you may want to verify. The goal is to print it in the blocking thread so you can match operations between.</p>\n<p dir=\"auto\">Then you can just replace with this method and remove the subscribe below. This way it will properly resume on a non blocking thread. To be honest you may want to evaluate all your usages of <code>runBlocking</code> to see if you want to use this instead.</p>", "author": "wburns", "createdAt": "2020-08-12T18:55:57Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.COUNTERS;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.counter.api.CounterConfiguration;\n+import org.infinispan.counter.api.CounterManager;\n+import org.infinispan.counter.api.CounterType;\n+import org.infinispan.counter.api.StrongCounter;\n+import org.infinispan.counter.api.WeakCounter;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#COUNTERS}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CounterResource extends AbstractContainerResource {\n+\n+   private static final String COUNTERS_FILE = \"counters.dat\";\n+\n+   private final CounterManager counterManager;\n+   private final ImmutableSerializationContext serCtx;\n+\n+   CounterResource(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                   BackupManager.Resources params, Path root) {\n+      super(COUNTERS, params, blockingManager, root);\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      this.counterManager = gcr.getComponent(CounterManager.class);\n+      this.serCtx = gcr.getComponent(SerializationContextRegistry.class).getPersistenceCtx();\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      if (wildcard) {\n+         resources.addAll(counterManager.getCounterNames());\n+         return;\n+      }\n+\n+      for (String counterName : resources) {\n+         if (counterManager.getConfiguration(counterName) == null)\n+            throw log.unableToFindResource(type.toString(), counterName);\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      return blockingManager.runBlocking(() -> {", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\nindex 85d40aafc3..25a01a3ea3 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\n", "chunk": "@@ -68,29 +68,30 @@ public void prepareAndValidateBackup() {\n \n    @Override\n    public CompletionStage<Void> backup() {\n-      return blockingManager.runBlocking(() -> {\n-         mkdirs(root);\n-         Flowable.using(\n-               () -> Files.newOutputStream(root.resolve(COUNTERS_FILE)),\n-               output ->\n-                     Flowable.fromIterable(resources)\n-                           .map(counter -> {\n-                              CounterConfiguration config = counterManager.getConfiguration(counter);\n-                              CounterBackupEntry e = new CounterBackupEntry();\n-                              e.name = counter;\n-                              e.configuration = config;\n-                              e.value = config.type() == CounterType.WEAK ?\n-                                    counterManager.getWeakCounter(counter).getValue() :\n-                                    CompletionStages.join(counterManager.getStrongCounter(counter).getValue());\n-                              return e;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .doOnError(t -> {\n-                              throw new CacheException(\"Unable to create counter backup\", t);\n-                           }),\n-               OutputStream::close\n-         ).subscribe();\n-      }, \"write-counters\");\n+      return blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> {\n+                     mkdirs(root);\n+                     return Files.newOutputStream(root.resolve(COUNTERS_FILE));\n+                  },\n+                  output ->\n+                        Flowable.fromIterable(resources)\n+                              .map(counter -> {\n+                                 CounterConfiguration config = counterManager.getConfiguration(counter);\n+                                 CounterBackupEntry e = new CounterBackupEntry();\n+                                 e.name = counter;\n+                                 e.configuration = config;\n+                                 e.value = config.type() == CounterType.WEAK ?\n+                                       counterManager.getWeakCounter(counter).getValue() :\n+                                       CompletionStages.join(counterManager.getStrongCounter(counter).getValue());\n+                                 return e;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create counter backup\", t);\n+                              }),\n+                  OutputStream::close\n+            ), \"write-counters\");\n    }\n \n    @Override\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\ndeleted file mode 100644\nindex 25a01a3ea3..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\n+++ /dev/null\n", "chunk": "@@ -1,147 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.COUNTERS;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.counter.api.CounterConfiguration;\n-import org.infinispan.counter.api.CounterManager;\n-import org.infinispan.counter.api.CounterType;\n-import org.infinispan.counter.api.StrongCounter;\n-import org.infinispan.counter.api.WeakCounter;\n-import org.infinispan.factories.GlobalComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#COUNTERS}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CounterResource extends AbstractContainerResource {\n-\n-   private static final String COUNTERS_FILE = \"counters.dat\";\n-\n-   private final CounterManager counterManager;\n-   private final ImmutableSerializationContext serCtx;\n-\n-   CounterResource(BlockingManager blockingManager, EmbeddedCacheManager cm,\n-                   BackupManager.Resources params, Path root) {\n-      super(COUNTERS, params, blockingManager, root);\n-      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n-      this.counterManager = gcr.getComponent(CounterManager.class);\n-      this.serCtx = gcr.getComponent(SerializationContextRegistry.class).getPersistenceCtx();\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      if (wildcard) {\n-         resources.addAll(counterManager.getCounterNames());\n-         return;\n-      }\n-\n-      for (String counterName : resources) {\n-         if (counterManager.getConfiguration(counterName) == null)\n-            throw log.unableToFindResource(type.toString(), counterName);\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      return blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> {\n-                     mkdirs(root);\n-                     return Files.newOutputStream(root.resolve(COUNTERS_FILE));\n-                  },\n-                  output ->\n-                        Flowable.fromIterable(resources)\n-                              .map(counter -> {\n-                                 CounterConfiguration config = counterManager.getConfiguration(counter);\n-                                 CounterBackupEntry e = new CounterBackupEntry();\n-                                 e.name = counter;\n-                                 e.configuration = config;\n-                                 e.value = config.type() == CounterType.WEAK ?\n-                                       counterManager.getWeakCounter(counter).getValue() :\n-                                       CompletionStages.join(counterManager.getStrongCounter(counter).getValue());\n-                                 return e;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create counter backup\", t);\n-                              }),\n-                  OutputStream::close\n-            ), \"write-counters\");\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      return blockingManager.runBlocking(() -> {\n-         Set<String> countersToRestore = resources;\n-         String countersFile = root.resolve(COUNTERS_FILE).toString();\n-         ZipEntry zipEntry = zip.getEntry(countersFile);\n-         if (zipEntry == null) {\n-            if (!countersToRestore.isEmpty())\n-               throw log.unableToFindBackupResource(type.toString(), countersToRestore);\n-            return;\n-         }\n-\n-         try (InputStream is = zip.getInputStream(zipEntry)) {\n-            while (is.available() > 0) {\n-               CounterBackupEntry entry = readMessageStream(serCtx, CounterBackupEntry.class, is);\n-               if (!countersToRestore.contains(entry.name)) {\n-                  log.debugf(\"Ignoring '%s' counter\", entry.name);\n-                  continue;\n-               }\n-               CounterConfiguration config = entry.configuration;\n-               counterManager.defineCounter(entry.name, config);\n-               if (config.type() == CounterType.WEAK) {\n-                  WeakCounter counter = counterManager.getWeakCounter(entry.name);\n-                  counter.add(entry.value - config.initialValue());\n-               } else {\n-                  StrongCounter counter = counterManager.getStrongCounter(entry.name);\n-                  counter.compareAndSet(config.initialValue(), entry.value);\n-               }\n-            }\n-         } catch (IOException e) {\n-            throw new CacheException(e);\n-         }\n-      }, \"restore-counters\");\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent counter instances.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.COUNTER_BACKUP_ENTRY)\n-   public static class CounterBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      String name;\n-\n-      @ProtoField(number = 2)\n-      CounterConfiguration configuration;\n-\n-      @ProtoField(number = 3, defaultValue = \"-1\")\n-      long value;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\nnew file mode 100644\nindex 0000000000..25a01a3ea3\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java\n", "chunk": "@@ -0,0 +1,147 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.COUNTERS;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.counter.api.CounterConfiguration;\n+import org.infinispan.counter.api.CounterManager;\n+import org.infinispan.counter.api.CounterType;\n+import org.infinispan.counter.api.StrongCounter;\n+import org.infinispan.counter.api.WeakCounter;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#COUNTERS}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CounterResource extends AbstractContainerResource {\n+\n+   private static final String COUNTERS_FILE = \"counters.dat\";\n+\n+   private final CounterManager counterManager;\n+   private final ImmutableSerializationContext serCtx;\n+\n+   CounterResource(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                   BackupManager.Resources params, Path root) {\n+      super(COUNTERS, params, blockingManager, root);\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      this.counterManager = gcr.getComponent(CounterManager.class);\n+      this.serCtx = gcr.getComponent(SerializationContextRegistry.class).getPersistenceCtx();\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      if (wildcard) {\n+         resources.addAll(counterManager.getCounterNames());\n+         return;\n+      }\n+\n+      for (String counterName : resources) {\n+         if (counterManager.getConfiguration(counterName) == null)\n+            throw log.unableToFindResource(type.toString(), counterName);\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      return blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> {\n+                     mkdirs(root);\n+                     return Files.newOutputStream(root.resolve(COUNTERS_FILE));\n+                  },\n+                  output ->\n+                        Flowable.fromIterable(resources)\n+                              .map(counter -> {\n+                                 CounterConfiguration config = counterManager.getConfiguration(counter);\n+                                 CounterBackupEntry e = new CounterBackupEntry();\n+                                 e.name = counter;\n+                                 e.configuration = config;\n+                                 e.value = config.type() == CounterType.WEAK ?\n+                                       counterManager.getWeakCounter(counter).getValue() :\n+                                       CompletionStages.join(counterManager.getStrongCounter(counter).getValue());\n+                                 return e;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create counter backup\", t);\n+                              }),\n+                  OutputStream::close\n+            ), \"write-counters\");\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      return blockingManager.runBlocking(() -> {\n+         Set<String> countersToRestore = resources;\n+         String countersFile = root.resolve(COUNTERS_FILE).toString();\n+         ZipEntry zipEntry = zip.getEntry(countersFile);\n+         if (zipEntry == null) {\n+            if (!countersToRestore.isEmpty())\n+               throw log.unableToFindBackupResource(type.toString(), countersToRestore);\n+            return;\n+         }\n+\n+         try (InputStream is = zip.getInputStream(zipEntry)) {\n+            while (is.available() > 0) {\n+               CounterBackupEntry entry = readMessageStream(serCtx, CounterBackupEntry.class, is);\n+               if (!countersToRestore.contains(entry.name)) {\n+                  log.debugf(\"Ignoring '%s' counter\", entry.name);\n+                  continue;\n+               }\n+               CounterConfiguration config = entry.configuration;\n+               counterManager.defineCounter(entry.name, config);\n+               if (config.type() == CounterType.WEAK) {\n+                  WeakCounter counter = counterManager.getWeakCounter(entry.name);\n+                  counter.add(entry.value - config.initialValue());\n+               } else {\n+                  StrongCounter counter = counterManager.getStrongCounter(entry.name);\n+                  counter.compareAndSet(config.initialValue(), entry.value);\n+               }\n+            }\n+         } catch (IOException e) {\n+            throw new CacheException(e);\n+         }\n+      }, \"restore-counters\");\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent counter instances.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.COUNTER_BACKUP_ENTRY)\n+   public static class CounterBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      String name;\n+\n+      @ProtoField(number = 2)\n+      CounterConfiguration configuration;\n+\n+      @ProtoField(number = 3, defaultValue = \"-1\")\n+      long value;\n+   }\n+}\n", "next_change": null}]}}]}}]}}, {"oid": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "url": "https://github.com/infinispan/infinispan/commit/ca1605d5abf808eb41677c2f4a028aea86d931a4", "message": "Don docs feedback", "committedDate": "2020-08-13T10:57:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAxMTg1OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470011858", "body": "Looks like you can use\r\n```java\r\n      if (resources != null)\r\n         json.set(\"resources\", Json.factory().make(resources));\r\n```\r\nfrom the other method.", "bodyText": "Looks like you can use\n      if (resources != null)\n         json.set(\"resources\", Json.factory().make(resources));\nfrom the other method.", "bodyHTML": "<p dir=\"auto\">Looks like you can use</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"      if (resources != null)\n         json.set(&quot;resources&quot;, Json.factory().make(resources));\"><pre>      <span class=\"pl-k\">if</span> (resources <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">null</span>)\n         json<span class=\"pl-k\">.</span>set(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>resources<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">Json</span><span class=\"pl-k\">.</span>factory()<span class=\"pl-k\">.</span>make(resources));</pre></div>\n<p dir=\"auto\">from the other method.</p>", "author": "wburns", "createdAt": "2020-08-13T14:52:32Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java", "diffHunk": "@@ -121,4 +128,70 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n+\n+   @Override\n+   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (workingDir != null)\n+         json.set(\"directory\", workingDir);\n+\n+      if (resources != null) {", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\nindex 058e7d26c8..9728accf56 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n", "chunk": "@@ -135,11 +135,9 @@ public String name() {\n       if (workingDir != null)\n          json.set(\"directory\", workingDir);\n \n-      if (resources != null) {\n-         Json resourcesJson = Json.object();\n-         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));\n-         json.set(\"resources\", resourcesJson);\n-      }\n+      if (resources != null)\n+         json.set(\"resources\", Json.factory().make(resources));\n+\n       RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n       Request.Builder builder = backup(name).post(body);\n       return client.execute(builder);\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\nindex 9728accf56..25ea8b244a 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n", "chunk": "@@ -128,68 +121,4 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n-\n-   @Override\n-   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n-      Json json = Json.object();\n-      if (workingDir != null)\n-         json.set(\"directory\", workingDir);\n-\n-      if (resources != null)\n-         json.set(\"resources\", Json.factory().make(resources));\n-\n-      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n-      Request.Builder builder = backup(name).post(body);\n-      return client.execute(builder);\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> getBackup(String name, boolean skipBody) {\n-      Request.Builder builder = backup(name);\n-      if (skipBody)\n-         builder.head();\n-\n-      return client.execute(builder);\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> deleteBackup(String name) {\n-      return client.execute(backup(name).delete());\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources) {\n-      Json json = resources != null ? Json.factory().make(resources) : Json.object();\n-      RequestBody zipBody = new FileRestEntityOkHttp(MediaType.APPLICATION_ZIP, backup).toRequestBody();\n-\n-      RequestBody multipartBody = new MultipartBody.Builder()\n-            .addFormDataPart(\"resources\", json.toString())\n-            .addFormDataPart(\"backup\", backup.getName(), zipBody)\n-            .setType(MultipartBody.FORM)\n-            .build();\n-\n-      Request.Builder builder = restore().post(multipartBody);\n-      return client.execute(builder);\n-   }\n-\n-   @Override\n-   public CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources) {\n-      Json json = Json.object();\n-      json.set(\"location\", backupLocation);\n-\n-      if (resources != null)\n-         json.set(\"resources\", Json.factory().make(resources));\n-\n-      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n-      Request.Builder builder = restore().post(body);\n-      return client.execute(builder);\n-   }\n-\n-   private Request.Builder backup(String name) {\n-      return new Request.Builder().url(baseCacheManagerUrl + \"/backups/\" + name);\n-   }\n-\n-   private Request.Builder restore() {\n-      return new Request.Builder().url(baseCacheManagerUrl + \"/backups?action=restore\");\n-   }\n }\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\nindex 25ea8b244a..9728accf56 100644\n--- a/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n+++ b/client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java\n", "chunk": "@@ -121,4 +128,68 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n+\n+   @Override\n+   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (workingDir != null)\n+         json.set(\"directory\", workingDir);\n+\n+      if (resources != null)\n+         json.set(\"resources\", Json.factory().make(resources));\n+\n+      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n+      Request.Builder builder = backup(name).post(body);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> getBackup(String name, boolean skipBody) {\n+      Request.Builder builder = backup(name);\n+      if (skipBody)\n+         builder.head();\n+\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> deleteBackup(String name) {\n+      return client.execute(backup(name).delete());\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources) {\n+      Json json = resources != null ? Json.factory().make(resources) : Json.object();\n+      RequestBody zipBody = new FileRestEntityOkHttp(MediaType.APPLICATION_ZIP, backup).toRequestBody();\n+\n+      RequestBody multipartBody = new MultipartBody.Builder()\n+            .addFormDataPart(\"resources\", json.toString())\n+            .addFormDataPart(\"backup\", backup.getName(), zipBody)\n+            .setType(MultipartBody.FORM)\n+            .build();\n+\n+      Request.Builder builder = restore().post(multipartBody);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      json.set(\"location\", backupLocation);\n+\n+      if (resources != null)\n+         json.set(\"resources\", Json.factory().make(resources));\n+\n+      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n+      Request.Builder builder = restore().post(body);\n+      return client.execute(builder);\n+   }\n+\n+   private Request.Builder backup(String name) {\n+      return new Request.Builder().url(baseCacheManagerUrl + \"/backups/\" + name);\n+   }\n+\n+   private Request.Builder restore() {\n+      return new Request.Builder().url(baseCacheManagerUrl + \"/backups?action=restore\");\n+   }\n }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjUzMQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470036531", "body": "Technically this method can block as well. I would say we could use `Cache#sizeAsync` but that requires getting all elements. TBH, until we have a `Cache#isEmptyAsync` I would recommend just removing this if block. Although it would be quite simple to add this method to the cache if you wanted.", "bodyText": "Technically this method can block as well. I would say we could use Cache#sizeAsync but that requires getting all elements. TBH, until we have a Cache#isEmptyAsync I would recommend just removing this if block. Although it would be quite simple to add this method to the cache if you wanted.", "bodyHTML": "<p dir=\"auto\">Technically this method can block as well. I would say we could use <code>Cache#sizeAsync</code> but that requires getting all elements. TBH, until we have a <code>Cache#isEmptyAsync</code> I would recommend just removing this if block. Although it would be quite simple to add this method to the cache if you wanted.</p>", "author": "wburns", "createdAt": "2020-08-13T15:26:40Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+      Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+      // Create the cache backup dir and parents\n+      Path cacheRoot = root.resolve(cacheName);\n+      mkdirs(cacheRoot);\n+\n+      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTU2NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470041565", "bodyText": "I'll remove the if block ... this PR is already pretty large", "author": "ryanemerson", "createdAt": "2020-08-13T15:34:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjUzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..2521d13cb5 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -182,9 +183,6 @@ public void prepareAndValidateBackup() {\n          }\n       }, \"write-cache-config\");\n \n-      if (cache.isEmpty())\n-         return configStage;\n-\n       ComponentRegistry cr = cache.getComponentRegistry();\n       ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n       SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex 2521d13cb5..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -181,47 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzOTQzNQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470039435", "body": "Sorry I didn't notice this earlier, but this doesn't do what you want sadly.\r\n\r\nYou need to do something like https://github.com/infinispan/infinispan/blob/37abd44b44b51eb5b32b23f7f7ddb277f7661021/core/src/main/java/org/infinispan/stream/impl/DistributedCacheStream.java#L378", "bodyText": "Sorry I didn't notice this earlier, but this doesn't do what you want sadly.\nYou need to do something like \n  \n    \n      infinispan/core/src/main/java/org/infinispan/stream/impl/DistributedCacheStream.java\n    \n    \n         Line 378\n      in\n      37abd44\n    \n    \n    \n    \n\n        \n          \n           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()), distributedBatchSize);", "bodyHTML": "<p dir=\"auto\">Sorry I didn't notice this earlier, but this doesn't do what you want sadly.</p>\n<p dir=\"auto\">You need to do something like <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom color-bg-subtle\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/infinispan/infinispan/blob/37abd44b44b51eb5b32b23f7f7ddb277f7661021/core/src/main/java/org/infinispan/stream/impl/DistributedCacheStream.java#L378\">infinispan/core/src/main/java/org/infinispan/stream/impl/DistributedCacheStream.java</a>\n    </p>\n    <p class=\"mb-0 color-fg-muted\">\n         Line 378\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/infinispan/infinispan/commit/37abd44b44b51eb5b32b23f7f7ddb277f7661021\">37abd44</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\" data-paste-markdown-skip=\"\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L378\" class=\"blob-num border-0 px-3 py-0 color-bg-default js-line-number\" data-line-number=\"378\"></td>\n          <td id=\"LC378\" class=\"blob-code border-0 px-3 py-0 color-bg-default blob-code-inner js-file-line\"> .onErrorResumeNext(<span class=\"pl-smi\">RxJavaInterop</span><span class=\"pl-k\">.</span>cacheExceptionWrapper()), distributedBatchSize); </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>", "author": "wburns", "createdAt": "2020-08-13T15:30:57Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+      Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+      // Create the cache backup dir and parents\n+      Path cacheRoot = root.resolve(cacheName);\n+      mkdirs(cacheRoot);\n+\n+      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())\n+         return configStage;\n+\n+      ComponentRegistry cr = cache.getComponentRegistry();\n+      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+      String dataFileName = dataFile(cacheName);\n+      Path datFile = cacheRoot.resolve(dataFileName);\n+\n+      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> Files.newOutputStream(datFile),\n+                  output ->\n+                        Flowable.fromPublisher(p)\n+                              .map(e -> {\n+                                 CacheBackupEntry be = new CacheBackupEntry();\n+                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                                 be.internalMetadata = e.getInternalMetadata();\n+                                 be.created = e.getCreated();\n+                                 be.lastUsed = e.getLastUsed();\n+                                 return be;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create cache backup\", t);", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex bbe8621266..2521d13cb5 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -219,9 +217,7 @@ public void prepareAndValidateBackup() {\n                                  return be;\n                               })\n                               .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .doOnError(t -> {\n-                                 throw new CacheException(\"Unable to create cache backup\", t);\n-                              }),\n+                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n                   OutputStream::close\n             ), \"write-cache-contents\");\n \n", "next_change": {"commit": "83f0706eabce639bc97dab9171bd0656f0ecde11", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nindex 2521d13cb5..1d81783e81 100644\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -181,47 +181,44 @@ public void prepareAndValidateBackup() {\n          } catch (XMLStreamException | IOException e) {\n             throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n          }\n-      }, \"write-cache-config\");\n-\n-      ComponentRegistry cr = cache.getComponentRegistry();\n-      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-      String dataFileName = dataFile(cacheName);\n-      Path datFile = cacheRoot.resolve(dataFileName);\n-\n-      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n-            Flowable.using(\n-                  () -> Files.newOutputStream(datFile),\n-                  output ->\n-                        Flowable.fromPublisher(p)\n-                              .map(e -> {\n-                                 CacheBackupEntry be = new CacheBackupEntry();\n-                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                                 be.internalMetadata = e.getInternalMetadata();\n-                                 be.created = e.getCreated();\n-                                 be.lastUsed = e.getLastUsed();\n-                                 return be;\n-                              })\n-                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                              .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-                  OutputStream::close\n-            ), \"write-cache-contents\");\n-\n-      return CompletionStages.allOf(configStage, contentStage);\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n    }\n \n    private String configFile(String cache) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\ndeleted file mode 100644\nindex 1d81783e81..0000000000\n--- a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n+++ /dev/null\n", "chunk": "@@ -1,273 +0,0 @@\n-package org.infinispan.server.core.backup.resources;\n-\n-import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.OutputStream;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.util.Set;\n-import java.util.concurrent.CompletionStage;\n-import java.util.zip.ZipEntry;\n-import java.util.zip.ZipFile;\n-\n-import javax.xml.stream.XMLStreamException;\n-\n-import org.infinispan.AdvancedCache;\n-import org.infinispan.cache.impl.InvocationHelper;\n-import org.infinispan.commands.CommandsFactory;\n-import org.infinispan.commands.write.PutKeyValueCommand;\n-import org.infinispan.commons.CacheException;\n-import org.infinispan.commons.dataconversion.MediaType;\n-import org.infinispan.commons.marshall.Marshaller;\n-import org.infinispan.commons.marshall.MarshallingException;\n-import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n-import org.infinispan.configuration.cache.Configuration;\n-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n-import org.infinispan.configuration.parsing.ParserRegistry;\n-import org.infinispan.container.entries.CacheEntry;\n-import org.infinispan.context.impl.FlagBitSets;\n-import org.infinispan.distribution.ch.KeyPartitioner;\n-import org.infinispan.encoding.impl.StorageConfigurationManager;\n-import org.infinispan.factories.ComponentRegistry;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-import org.infinispan.marshall.persistence.PersistenceMarshaller;\n-import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n-import org.infinispan.metadata.Metadata;\n-import org.infinispan.metadata.impl.InternalMetadataImpl;\n-import org.infinispan.metadata.impl.PrivateMetadata;\n-import org.infinispan.protostream.ImmutableSerializationContext;\n-import org.infinispan.protostream.annotations.ProtoField;\n-import org.infinispan.protostream.annotations.ProtoTypeId;\n-import org.infinispan.reactive.RxJavaInterop;\n-import org.infinispan.reactive.publisher.PublisherTransformers;\n-import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n-import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n-import org.infinispan.registry.InternalCacheRegistry;\n-import org.infinispan.server.core.BackupManager;\n-import org.infinispan.util.concurrent.AggregateCompletionStage;\n-import org.infinispan.util.concurrent.BlockingManager;\n-import org.infinispan.util.concurrent.CompletionStages;\n-import org.reactivestreams.Publisher;\n-\n-import io.reactivex.rxjava3.core.Flowable;\n-\n-/**\n- * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n- * BackupManager.Resources.Type#CACHES}.\n- *\n- * @author Ryan Emerson\n- * @since 12.0\n- */\n-public class CacheResource extends AbstractContainerResource {\n-\n-   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n-\n-   private final EmbeddedCacheManager cm;\n-   private final ParserRegistry parserRegistry;\n-\n-   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n-                 BackupManager.Resources params, Path root) {\n-      super(CACHES, params, blockingManager, root);\n-      this.cm = cm;\n-      this.parserRegistry = parserRegistry;\n-   }\n-\n-   @Override\n-   public void prepareAndValidateBackup() {\n-      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n-\n-      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n-      for (String cache : caches) {\n-         Configuration config = cm.getCacheConfiguration(cache);\n-\n-         if (wildcard) {\n-            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n-            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n-               continue;\n-            }\n-            resources.add(cache);\n-         } else if (config == null) {\n-            throw log.unableToFindResource(type.toString(), cache);\n-         } else if (config.isTemplate()) {\n-            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n-         }\n-      }\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> backup() {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cache : resources)\n-         stages.dependsOn(createCacheBackup(cache));\n-      return stages.freeze();\n-   }\n-\n-   @Override\n-   public CompletionStage<Void> restore(ZipFile zip) {\n-      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n-      for (String cacheName : resources) {\n-         stages.dependsOn(blockingManager.runBlocking(() -> {\n-            Path cacheRoot = root.resolve(cacheName);\n-\n-            // Process .xml\n-            String configFile = configFile(cacheName);\n-            String zipPath = cacheRoot.resolve(configFile).toString();\n-            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n-               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n-               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n-               cm.defineConfiguration(cacheName, cfg);\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-\n-            // Process .dat\n-            String dataFile = dataFile(cacheName);\n-            String data = cacheRoot.resolve(dataFile).toString();\n-            ZipEntry zipEntry = zip.getEntry(data);\n-            if (zipEntry == null)\n-               return;\n-\n-            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n-            ComponentRegistry cr = cache.getComponentRegistry();\n-            CommandsFactory commandsFactory = cr.getCommandsFactory();\n-            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n-            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n-            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-\n-            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-            try (InputStream is = zip.getInputStream(zipEntry)) {\n-               while (is.available() > 0) {\n-                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n-                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n-                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n-                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n-                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n-\n-                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n-                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n-                  cmd.setInternalMetadata(entry.internalMetadata);\n-                  invocationHelper.invoke(cmd, 1);\n-               }\n-            } catch (IOException e) {\n-               throw new CacheException(e);\n-            }\n-         }, \"restore-cache-\" + cacheName));\n-      }\n-      return stages.freeze();\n-   }\n-\n-   private CompletionStage<Void> createCacheBackup(String cacheName) {\n-      return blockingManager.runBlocking(() -> {\n-         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n-         Configuration configuration = cm.getCacheConfiguration(cacheName);\n-\n-         Path cacheRoot = root.resolve(cacheName);\n-         // Create the cache backup dir and parents\n-         mkdirs(cacheRoot);\n-\n-         // Write configuration file\n-         String xmlFileName = configFile(cacheName);\n-         Path xmlPath = cacheRoot.resolve(xmlFileName);\n-         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n-            parserRegistry.serialize(os, cacheName, configuration);\n-         } catch (XMLStreamException | IOException e) {\n-            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n-         }\n-\n-         ComponentRegistry cr = cache.getComponentRegistry();\n-         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n-         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n-         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n-\n-         String dataFileName = dataFile(cacheName);\n-         Path datFile = cacheRoot.resolve(dataFileName);\n-\n-         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n-         Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n-               DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n-\n-         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n-         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n-         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n-         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n-         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n-\n-         Flowable.using(\n-               () -> Files.newOutputStream(datFile),\n-               output ->\n-                     Flowable.fromPublisher(p)\n-                           .map(e -> {\n-                              CacheBackupEntry be = new CacheBackupEntry();\n-                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n-                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n-                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n-                              be.internalMetadata = e.getInternalMetadata();\n-                              be.created = e.getCreated();\n-                              be.lastUsed = e.getLastUsed();\n-                              return be;\n-                           })\n-                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n-                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n-               OutputStream::close)\n-               .subscribe();\n-      }, \"backup-cache\");\n-   }\n-\n-   private String configFile(String cache) {\n-      return String.format(\"%s.xml\", cache);\n-   }\n-\n-   private String dataFile(String cache) {\n-      return String.format(\"%s.dat\", cache);\n-   }\n-\n-   private byte[] marshall(Object key, Marshaller marshaller) {\n-      try {\n-         return marshaller.objectToByteBuffer(key);\n-      } catch (IOException | InterruptedException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   @SuppressWarnings(\"unchecked\")\n-   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n-      try {\n-         return (T) marshaller.objectFromByteBuffer(bytes);\n-      } catch (ClassNotFoundException | IOException e) {\n-         throw new MarshallingException(e);\n-      }\n-   }\n-\n-   /**\n-    * ProtoStream entity used to represent individual cache entries.\n-    */\n-   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n-   public static class CacheBackupEntry {\n-\n-      @ProtoField(number = 1)\n-      byte[] key;\n-\n-      @ProtoField(number = 2)\n-      byte[] value;\n-\n-      @ProtoField(number = 3)\n-      byte[] metadata;\n-\n-      @ProtoField(number = 4)\n-      PrivateMetadata internalMetadata;\n-\n-      @ProtoField(number = 5, defaultValue = \"-1\")\n-      long created;\n-\n-      @ProtoField(number = 6, defaultValue = \"-1\")\n-      long lastUsed;\n-   }\n-}\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\nnew file mode 100644\nindex 0000000000..bde1fcdd7e\n--- /dev/null\n+++ b/server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java\n", "chunk": "@@ -0,0 +1,277 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.RxJavaInterop;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         Path cacheRoot = root.resolve(cacheName);\n+         // Create the cache backup dir and parents\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+\n+         // Create the publisher using the BlockingManager to ensure that all entries are subscribed to on a blocking thread\n+         Publisher<CacheEntry<Object, Object>> p = blockingManager.blockingPublisher(\n+               clusterPublisherManager.entryPublisher(null, null, null, true,\n+                     DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity())\n+         );\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()),\n+               OutputStream::close)\n+               .subscribe();\n+      }, \"backup-cache\");\n+   }\n+\n+   private String configFile(String cache) {\n+      return String.format(\"%s.xml\", cache);\n+   }\n+\n+   private String dataFile(String cache) {\n+      return String.format(\"%s.dat\", cache);\n+   }\n+\n+   private byte[] marshall(Object key, Marshaller marshaller) {\n+      try {\n+         return marshaller.objectToByteBuffer(key);\n+      } catch (IOException | InterruptedException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   @SuppressWarnings(\"unchecked\")\n+   private static <T> T unmarshall(byte[] bytes, Marshaller marshaller) {\n+      try {\n+         return (T) marshaller.objectFromByteBuffer(bytes);\n+      } catch (ClassNotFoundException | IOException e) {\n+         throw new MarshallingException(e);\n+      }\n+   }\n+\n+   /**\n+    * ProtoStream entity used to represent individual cache entries.\n+    */\n+   @ProtoTypeId(ProtoStreamTypeIds.CACHE_BACKUP_ENTRY)\n+   public static class CacheBackupEntry {\n+\n+      @ProtoField(number = 1)\n+      byte[] key;\n+\n+      @ProtoField(number = 2)\n+      byte[] value;\n+\n+      @ProtoField(number = 3)\n+      byte[] metadata;\n+\n+      @ProtoField(number = 4)\n+      PrivateMetadata internalMetadata;\n+\n+      @ProtoField(number = 5, defaultValue = \"-1\")\n+      long created;\n+\n+      @ProtoField(number = 6, defaultValue = \"-1\")\n+      long lastUsed;\n+   }\n+}\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTQ0NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470041445", "body": "We can add an `if (trace)`", "bodyText": "We can add an if (trace)", "bodyHTML": "<p dir=\"auto\">We can add an <code>if (trace)</code></p>", "author": "wburns", "createdAt": "2020-08-13T15:34:04Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java", "diffHunk": "@@ -246,6 +261,26 @@ protected void start() {\n       });\n    }\n \n+   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\n+      CompletionStage<Void> stage = Flowable.defer(() -> {\n+         Flowable<V> flowable = Flowable.fromPublisher(publisher);\n+         if (isCurrentThreadBlocking()) {\n+            log.tracef(\"Invoked on a blocking thread, running %s in same blocking thread\", traceId);", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\nindex b13f8b9c1c..f53e0d8a6a 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n", "chunk": "@@ -265,7 +265,9 @@ protected void start() {\n       CompletionStage<Void> stage = Flowable.defer(() -> {\n          Flowable<V> flowable = Flowable.fromPublisher(publisher);\n          if (isCurrentThreadBlocking()) {\n-            log.tracef(\"Invoked on a blocking thread, running %s in same blocking thread\", traceId);\n+            if (trace) {\n+               log.tracef(\"Invoked on a blocking thread, running %s in same blocking thread\", traceId);\n+            }\n             return flowable;\n          }\n          if (trace) {\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\nindex f53e0d8a6a..0b1029dc4e 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n", "chunk": "@@ -261,28 +246,6 @@ protected void start() {\n       });\n    }\n \n-   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\n-      CompletionStage<Void> stage = Flowable.defer(() -> {\n-         Flowable<V> flowable = Flowable.fromPublisher(publisher);\n-         if (isCurrentThreadBlocking()) {\n-            if (trace) {\n-               log.tracef(\"Invoked on a blocking thread, running %s in same blocking thread\", traceId);\n-            }\n-            return flowable;\n-         }\n-         if (trace) {\n-            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Subscribing to %s on blocking thread\", traceId));\n-         }\n-         flowable = flowable.subscribeOn(blockingScheduler);\n-         if (trace) {\n-            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Publisher %s subscribing thread is %s\", traceId, Thread.currentThread()));\n-         }\n-         return flowable;\n-      }).ignoreElements().toCompletionStage(null);\n-\n-      return continueOnNonBlockingThread(stage, traceId);\n-   }\n-\n    @Override\n    public BlockingExecutor limitedBlockingExecutor(String name, int concurrentExecutions) {\n       LimitedExecutor limitedExecutor = new LimitedExecutor(name, blockingExecutor, concurrentExecutions);\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\nindex 0b1029dc4e..f53e0d8a6a 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java\n", "chunk": "@@ -246,6 +261,28 @@ protected void start() {\n       });\n    }\n \n+   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\n+      CompletionStage<Void> stage = Flowable.defer(() -> {\n+         Flowable<V> flowable = Flowable.fromPublisher(publisher);\n+         if (isCurrentThreadBlocking()) {\n+            if (trace) {\n+               log.tracef(\"Invoked on a blocking thread, running %s in same blocking thread\", traceId);\n+            }\n+            return flowable;\n+         }\n+         if (trace) {\n+            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Subscribing to %s on blocking thread\", traceId));\n+         }\n+         flowable = flowable.subscribeOn(blockingScheduler);\n+         if (trace) {\n+            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Publisher %s subscribing thread is %s\", traceId, Thread.currentThread()));\n+         }\n+         return flowable;\n+      }).ignoreElements().toCompletionStage(null);\n+\n+      return continueOnNonBlockingThread(stage, traceId);\n+   }\n+\n    @Override\n    public BlockingExecutor limitedBlockingExecutor(String name, int concurrentExecutions) {\n       LimitedExecutor limitedExecutor = new LimitedExecutor(name, blockingExecutor, concurrentExecutions);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTgxNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470041814", "body": "We should note the stage will always be completed upon a non blocking thread if the current thread is not a blocking one.", "bodyText": "We should note the stage will always be completed upon a non blocking thread if the current thread is not a blocking one.", "bodyHTML": "<p dir=\"auto\">We should note the stage will always be completed upon a non blocking thread if the current thread is not a blocking one.</p>", "author": "wburns", "createdAt": "2020-08-13T15:34:42Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java", "diffHunk": "@@ -169,6 +184,19 @@\n     */\n    <V> Publisher<V> blockingPublisher(Publisher<V> publisher);\n \n+   /**\n+    * Subscribes to the provided blocking publisher using the the blocking executor, ignoring all elements and returning\n+    * a {@link CompletionStage} with a value of null when complete.\n+    * <p>\n+    * Note that if the current thread is blocking everything including subscription, publication and collection of\n+    * values will be done on the current thread.\n+    *", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3e0b7319afa90ef8dda846de3624827eebbbd964", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\nindex a71f2aa0bc..55a3345e93 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n", "chunk": "@@ -186,7 +186,10 @@\n \n    /**\n     * Subscribes to the provided blocking publisher using the the blocking executor, ignoring all elements and returning\n-    * a {@link CompletionStage} with a value of null when complete.\n+    * a {@link CompletionStage} with a value of null which completes on a non-blocking thread.\n+    * <p>\n+    * The returned {@link CompletionStage} will always be completed upon a non-blocking thread if the current thread is\n+    * non-blocking.\n     * <p>\n     * Note that if the current thread is blocking everything including subscription, publication and collection of\n     * values will be done on the current thread.\n", "next_change": {"commit": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\nindex 55a3345e93..da2b148831 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n", "chunk": "@@ -184,22 +169,6 @@\n     */\n    <V> Publisher<V> blockingPublisher(Publisher<V> publisher);\n \n-   /**\n-    * Subscribes to the provided blocking publisher using the the blocking executor, ignoring all elements and returning\n-    * a {@link CompletionStage} with a value of null which completes on a non-blocking thread.\n-    * <p>\n-    * The returned {@link CompletionStage} will always be completed upon a non-blocking thread if the current thread is\n-    * non-blocking.\n-    * <p>\n-    * Note that if the current thread is blocking everything including subscription, publication and collection of\n-    * values will be done on the current thread.\n-    *\n-    * @param publisher the publisher that, when subscribed to, blocks the current thread.\n-    * @param <V>       the published entry types.\n-    * @return a completion stage that completes once the publisher has completed.\n-    */\n-   <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId);\n-\n    /**\n     * Provides a {@link BlockingExecutor} which is limited to the provided concurrency amount.\n     * @param name name of the limited blocking executor.\n", "next_change": {"commit": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "changed_code": [{"header": "diff --git a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\nindex da2b148831..55a3345e93 100644\n--- a/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n+++ b/core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java\n", "chunk": "@@ -169,6 +184,22 @@\n     */\n    <V> Publisher<V> blockingPublisher(Publisher<V> publisher);\n \n+   /**\n+    * Subscribes to the provided blocking publisher using the the blocking executor, ignoring all elements and returning\n+    * a {@link CompletionStage} with a value of null which completes on a non-blocking thread.\n+    * <p>\n+    * The returned {@link CompletionStage} will always be completed upon a non-blocking thread if the current thread is\n+    * non-blocking.\n+    * <p>\n+    * Note that if the current thread is blocking everything including subscription, publication and collection of\n+    * values will be done on the current thread.\n+    *\n+    * @param publisher the publisher that, when subscribed to, blocks the current thread.\n+    * @param <V>       the published entry types.\n+    * @return a completion stage that completes once the publisher has completed.\n+    */\n+   <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId);\n+\n    /**\n     * Provides a {@link BlockingExecutor} which is limited to the provided concurrency amount.\n     * @param name name of the limited blocking executor.\n", "next_change": null}]}}]}}]}}, {"oid": "3e0b7319afa90ef8dda846de3624827eebbbd964", "url": "https://github.com/infinispan/infinispan/commit/3e0b7319afa90ef8dda846de3624827eebbbd964", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-13T16:20:43Z", "type": "forcePushed"}, {"oid": "afb9ba558954d23cc966607b1405019ca56cced9", "url": "https://github.com/infinispan/infinispan/commit/afb9ba558954d23cc966607b1405019ca56cced9", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-18T09:10:22Z", "type": "forcePushed"}, {"oid": "83f0706eabce639bc97dab9171bd0656f0ecde11", "url": "https://github.com/infinispan/infinispan/commit/83f0706eabce639bc97dab9171bd0656f0ecde11", "message": "Process cache config and content as a single blocking task", "committedDate": "2020-08-19T09:23:06Z", "type": "forcePushed"}, {"oid": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "url": "https://github.com/infinispan/infinispan/commit/637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "message": "ISPN-11723 Serialize modules default namespace\n\nThis allows the xml from a backup created in a past major version to be\ncorrectly parsed when imported by a future major version.", "committedDate": "2020-08-19T15:41:38Z", "type": "commit"}, {"oid": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "url": "https://github.com/infinispan/infinispan/commit/f491132143ab0b421e0fd0cd84c2efdd436d27cc", "message": "Utilise blockingPublisher", "committedDate": "2020-08-19T15:41:38Z", "type": "forcePushed"}, {"oid": "d5029152cd0b6edfd07cec7312e98e17295d88c6", "url": "https://github.com/infinispan/infinispan/commit/d5029152cd0b6edfd07cec7312e98e17295d88c6", "message": "ISPN-11723 Cluster Backup/Restore tool", "committedDate": "2020-08-19T16:15:10Z", "type": "commit"}, {"oid": "14fbe3fe8e53f935f107954343c563549308348f", "url": "https://github.com/infinispan/infinispan/commit/14fbe3fe8e53f935f107954343c563549308348f", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-19T16:15:10Z", "type": "commit"}, {"oid": "14fbe3fe8e53f935f107954343c563549308348f", "url": "https://github.com/infinispan/infinispan/commit/14fbe3fe8e53f935f107954343c563549308348f", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-19T16:15:10Z", "type": "forcePushed"}]}